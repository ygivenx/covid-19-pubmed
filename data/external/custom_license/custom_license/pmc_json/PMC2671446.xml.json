{
    "paper_id": "PMC2671446",
    "metadata": {
        "title": "Enhancing Time-Series Detection Algorithms for Automated Biosurveillance",
        "authors": [
            {
                "first": "Jerome",
                "middle": [
                    "I."
                ],
                "last": "Tokars",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Howard",
                "middle": [],
                "last": "Burkom",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Jian",
                "middle": [],
                "last": "Xing",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Roseanne",
                "middle": [],
                "last": "English",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Steven",
                "middle": [],
                "last": "Bloom",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Kenneth",
                "middle": [],
                "last": "Cox",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Julie",
                "middle": [
                    "A."
                ],
                "last": "Pavlin",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Four algorithm modifications, designed to address shortcomings in the C2 algorithm, were tested. The first modification tested was stratification by weekdays versus weekend days. Although many methods have been used to adjust for differing counts by day of week (11), these methods may require customization to specific datasets and a long data history (up to several years). Our simple method is to stratify the baseline days used to calculate \u00b5 and st into weekdays versus weekend days. This stratification is denoted the W2 algorithm. For example, a 7-day W2 baseline for weekdays contains the most recent 7 weekdays. For unstratified and stratified analyses, the 2 days immediately before the index day were excluded from the baseline, a standard practice for C2, to avoid contamination with the upswing of an outbreak.",
            "cite_spans": [
                {
                    "start": 263,
                    "end": 265,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Methods",
            "ref_spans": []
        },
        {
            "text": "The second modification tested was lengthening the baseline period. Because a 7-day period may provide insufficient data for an accurate and stable calculation of \u00b5 and st, we tested baseline periods of 7, 14, and 28 days. However, because we used data from <56 days before the index day, the stratified 28-day baseline will include only \u224816 days for weekend days.",
            "cite_spans": [],
            "section": "Methods",
            "ref_spans": []
        },
        {
            "text": "The third modification tested was adjustment for total daily visits. For the adjustment procedure, we used a formula in which n0 = count of visits on the index day for the chosen syndrome (e.g., visits for the respiratory syndrome), and d0 = the total number of facility visits on the index day, including visits that were both assigned and unassigned to any of the 11 syndromes. \u03a3ni = total syndrome visits summed for all i baseline days. \u03a3di = total facility visits summed for all i baseline days. The formula for the adjusted expected value was e0 = d0 \u00d7 \u03a3ni/\u03a3di, which differed considerably from the mean of the ni if d0 was high or low. Fewer visits for a given syndrome were thus expected on a day when the facility had fewer total visits. The estimated adjusted SD, s0, was taken as the mean absolute value of (ni \u2013 di \u00d7 \u03a3ni/\u03a3di) over i baseline days; that is, s0 = \u03a3 (abs(ni \u2013 di \u00d7 \u03a3ni/\u03a3di))/i. The test statistic adjusted for total visits was (n0 \u2013 e0)/s0, analogous to the C2 statistic (n0 \u2013 \u00b5)/st, where \u00b5 and st are the mean and SD of ni, the counts on baseline days. In the discussion below, we refer to this adjustment as the rate algorithm.",
            "cite_spans": [],
            "section": "Methods",
            "ref_spans": []
        },
        {
            "text": "The fourth modification tested was increased minimum value for SD. We studied minimum values of 0.2 and 1.0.",
            "cite_spans": [],
            "section": "Methods",
            "ref_spans": []
        },
        {
            "text": "To test these modifications, 2 datasets were used: records of Department of Defense (DoD) facility final diagnoses for September 2004\u2013November 2007 and records of hospital emergency department (ED) chief complaints for March 2006\u2013November 2007. The DoD data consisted primarily of data from outpatient clinics; however, \u224815% of the visits in this evaluation were from patients seen in emergency facilities and cannot currently be differentiated in the BioSense System. We studied the 11 syndrome groups designed to be indicative of infections resulting from exposure to pathogens plausibly used in a bioterrorist attack (4). The DoD data consisted of daily counts of patient visits with International Classification of Diseases, 9th Revision (ICD-9)\u2013coded diagnoses categorized into the 11 syndrome groups. The hospital ED data consisted of free-text chief complaints, which were first parsed for a specified set of keywords, abbreviations, and misspellings and then categorized into 10 of the syndrome groups (1 syndrome, specific infection, was used for diagnosis but not for chief complaint data). Some ICD-9 codes and chief complaints may be included in >2 syndromes. However, counts of different syndromes were analyzed separately, not added together, and therefore are not double-counted in the analyses. For both datasets, we analyzed counts aggregated by facility. We included facility-syndrome combinations that had mean counts >0.5 over all facility\u2013syndrome days in the study period. Many DoD clinics are closed on holidays. Therefore, for the DoD data, 11 days (days on which federal holidays are observed and the day after Thanksgiving) were recoded as weekend days for purposes of stratified algorithm calculations (5). Because hospital EDs typically are open on these holidays, no recoding for holidays was performed for this dataset.",
            "cite_spans": [
                {
                    "start": 621,
                    "end": 622,
                    "mention": "4",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1730,
                    "end": 1731,
                    "mention": "5",
                    "ref_id": "BIBREF13"
                }
            ],
            "section": "Methods",
            "ref_spans": []
        },
        {
            "text": "The mean count for each facility syndrome was calculated and categorized as follows: 0.5 to <2, 2 to <4, 4 to <6, 6 to <8, 8 to <10, 10 to <20, 20 to <40, and >40. Empirical distributions of the test statistic (e.g., number of SDs by which the observed count exceeds the expected value) were conducted separately for each dataset, algorithm, and mean count category; the 99th percentile value for each of these distributions was used as the cutoff value to define an alert rate of 1%. For example, for the standard C2 algorithm in DoD data with mean count 4 to <6, a cutoff value of 3.9 was used because 1% of the facility-syndrome days had a test statistic >3.9. Because no attempt was made to find and exclude real outbreaks from the data, these cutoff values define an alert rate rather than a false alert rate, the latter being equivalent to 1-specificity (12).",
            "cite_spans": [
                {
                    "start": 861,
                    "end": 863,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Methods",
            "ref_spans": []
        },
        {
            "text": "At a constant alert rate of 1% for all methods, the sensitivity for detecting additional counts was calculated by performing the following steps: 1) running the algorithm to determine expected values and SDs for each facility-syndrome-day; 2) finding the 99th percentile cutoff value for the test statistic for each dataset-algorithm-mean count category as explained above; 3) for each facility-syndrome day, determining whether the observed count plus additional counts is greater than or equal to the threshold value (threshold value = expected value + SD \u00d7 99th percentile cutoff value); and 4) calculating sensitivity as the percentage of days on which the additional counts would exceed the threshold value and therefore be detected. Using this method, a single computer run can calculate sensitivity for detecting single-day additional counts on all days in the dataset; if the additional counts are spread over multiple days, separate computer runs would be needed (7).",
            "cite_spans": [
                {
                    "start": 973,
                    "end": 974,
                    "mention": "7",
                    "ref_id": "BIBREF15"
                }
            ],
            "section": "Methods",
            "ref_spans": []
        },
        {
            "text": "The DoD diagnosis data contained 1,939,993 facility\u2013syndrome days from 308 facilities in 48 states with an overall mean of 7.7 counts per facility per day; of the 11 syndromes, respiratory visits comprised the highest percentage (16% of total facility\u2013syndrome days) and had the highest mean count (26.0 visits per facility per day) (Table 1). The hospital ED data contained 768,195 facility\u2013syndrome days from 340 facilities in 21 states and had an overall mean of 7.8 counts per facility per day; no visits for lymphadenitis and severe injury and death were included because no facilities had a mean count >0.5 per day for these syndromes.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 334,
                    "end": 341,
                    "mention": "Table 1",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "The DoD data had a strong day-of-week effect; 16%\u201321% of total weekly visits occurred per day on weekdays, and only 3%\u20134% of visits occurred per day on weekend days and holidays (Figure 1). The hospital ED data had a minimal day-of-week effect: 14%\u201316% of visits occurred per day on weekdays, and 14%\u201315% of visits occurred per day on weekend days.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 179,
                    "end": 187,
                    "mention": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "The accuracy of expected value calculation was evaluated by using mean absolute residuals. For lower residuals, expected values are closer to observed values than they are for higher residuals. Similarly, the expected value calculation is more accurate for lower residuals than for higher residuals. For the DoD data, lower residuals were seen with stratification (W2) and the rate algorithm: mean residual 4.2 for unstratified count algorithm versus 2.2 for stratified rate algorithm (Table 2). For the hospital ED data, residuals were lower for the rate algorithm, and stratification had a minimal effect. Varying the baseline duration and minimum SD had no effect on the accuracy of expected value calculation (data not shown).",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 486,
                    "end": 493,
                    "mention": "Table 2",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "The effect of modifications of the initial algorithm on the sensitivity for detecting additional counts was examined; each modification was added consecutively (Table 3). For the DoD data, sensitivity was 40.6% for the initial algorithm and increased to 43.9% when the rate method was used; 70.8% when the minimum SD was increased to 1.0; 79.4% when the baseline duration was increased to 28 days; and 82.0% when a stratified baseline was used. Comparing the initial algoithm to the best algorithm showed a 41.4% increase in sensitivity. For the hospital ED data, sensitivity was 40.2% for the initial algorithm and increased to 64.8% for the best method (minimum SD = 1, 28-day baseline, rate method, unstratified baseline); however, when the stratified baseline was used, sensitivity decreased to 62.1%; the initial algorithm compared with the best algorithm showed a 24.6% increase in sensitivity. When these sensitivity calculations were stratified by mean count for each facility-syndrome (data not shown), we found that the modifications increased sensitivity in all strata of the DoD data; for the hospital ED data, the rate method reduced sensitivity by 1.0% in the 8 to <10 count category and by 0.5% in the 10 to <20 count category, but increased sensitivity in other categories and overall.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 161,
                    "end": 168,
                    "mention": "Table 3",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "When we limited analysis to ED data with a mean count of 4 to <6 per day and explored sensitivity for detecting varying numbers of additional counts (Figure 2), we found, as expected, that as the number of additional counts increased, sensitivity increased. The difference between the initial and best algorithms was highest when sensitivity was \u224850% for the initial algorithm. That is, for 10 additional counts, sensitivity was 49.8% for the initial algorithm and 85.3% for the best algorithm, an improvement of 35.5%. However, if the initial C2 algorithm had either low or high sensitivity, the modifications had little effect.",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 150,
                    "end": 158,
                    "mention": "Figure 2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "As an example, we analyzed fever syndrome data from 1 ED. The mean count was 4.9 per day, and the 99th percentile threshold values were 3.86 SDs for the initial and 3.55 for the best algorithm. Over 632 days, the sensitivity for detecting 8 additional counts was 47.2% for the initial and 70.9% for the best algorithm (23.7% difference). Data for a 2-month period showed that the calculated SD (Figure 3, panel A) and the threshold value (i.e., count needed to trigger an alert; Figure 3, panel B) varied substantially for the initial algorithm but were comparatively stable for the best algorithm. During the 2-month period, 8 additional counts would be detected by initial and best algorithms on 30 days, by only the initial algorithm on 2 days, and by only the best algorithm on 19 days; neither algorithm detected the additional counts on 10 days (Figure 3, panel C).",
            "cite_spans": [],
            "section": "Results",
            "ref_spans": [
                {
                    "start": 395,
                    "end": 403,
                    "mention": "Figure 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 479,
                    "end": 487,
                    "mention": "Figure 3",
                    "ref_id": "FIGREF2"
                },
                {
                    "start": 852,
                    "end": 860,
                    "mention": "Figure 3",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "Our results demonstrate that simple modifications of the widely used C2 algorithm can substantially improve the ability to accurately recognize 1-day increases in disease syndrome activity. Depending on the dataset, mean count in the data, and the number of additional counts added, the enhanced methods may increase sensitivity by 20%\u201340%. These improvements were achieved without an increase in the alert rate, which was held constant at 1% for all methods. Although we chose a 1% alert rate for testing purposes, in practice, it is useful to vary the alert rate to fit the circumstances, and the BioSense application enables the alert rate to be varied between 0.1% and 2%. Regardless of the alert rate used, the modified methods have higher sensitivity. For the DoD and hospital ED datasets, sensitivity was improved by using a higher minimum SD of 1.0, a longer baseline duration of 28 days, and adjusting for total visits. Stratifying baseline days into weekdays versus weekends/holidays increased sensitivity in the DoD data, which has a strong day-of-week effect, but modestly decreased sensitivity in the hospital ED data, which does not have such an effect. Thus, the best analytic methods depend on dataset characteristics, especially the day-of-week effect, and could be varied by manual or automated selection. These findings can be used to improve both early event detection and situation awareness because accurate recognition of unusually high counts is needed for both uses.",
            "cite_spans": [],
            "section": "Discussion",
            "ref_spans": []
        },
        {
            "text": "These modifications were apparently effective for the following reasons. Accounting for total visits to the facility (i.e., rate method) produces a more accurate expected value and lower residuals (Table 2). Although number of total visits is not the ideal denominator, in general it is better than no denominator at all. An advantage of the rate method is that calculations may be made when only partial data for a given day are available. However, adjusting for total visits may reduce sensitivity slightly in some subgroups, as we found for the hospital ED data when the mean count was 8 to <20. Stratification by weekday versus weekend day improves expected value calculations when a substantial day-of-week effect exists, such as in the DoD data. When such an effect is not present, stratification causes days further from the index day to be used in the baseline period, therefore producing slightly less accurate expected values. Longer baseline durations have no effect on the accuracy of expected value calculation and improve sensitivity by producing more accurate and stable SD values. Using a higher minimum SD avoids nuisance alerts that may be prompted by small fluctuations in the daily visit count. This method also changes the distribution of test statistic values, which results in a lower 99th percentile cutoff value, which increases sensitivity for detecting moderate-to-high numbers of added counts. Using a higher minimum SD is beneficial if disease indicators with low and high counts are analyzed; an alternate approach is to use different methods for low- versus high-count data.",
            "cite_spans": [],
            "section": "Discussion",
            "ref_spans": [
                {
                    "start": 198,
                    "end": 205,
                    "mention": "Table 2",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "The issues focused on by our suggested modifications may alternately be addressed by various sophisticated mathematical modeling approaches. However, health departments, which are generally limited in resources and in analysis expertise, may resist use of decision-support methods that are expensive, difficult to implement, or not transparent to human data monitors. For example, sophisticated Serfling-type regression models have long been used by CDC for tracking the progress of influenza season (13,14) and have been used to analyze selected data in the BioSense system. However, these models have both strengths and weaknesses and have not been widely embraced for daily disease surveillance. Even if the expertise and hardware capability for applying them were made available to local health departments, many time series are unsuitable for this approach. We present simple and easily understood and implemented enhancements to C2 to extend its applicability and improve its performance. These enhancements may be applicable to other control chart-based algorithms as well.",
            "cite_spans": [
                {
                    "start": 501,
                    "end": 503,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 504,
                    "end": 506,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Discussion",
            "ref_spans": []
        },
        {
            "text": "Automated surveillance systems based on chief complaints and diagnoses have a number of uses: providing assistance in data collection; monitoring seasonal influenza (15); monitoring total ED visits during a crisis; and monitoring simple surrogates of infectious diseases, injuries, and chronic diseases during large outbreaks or disasters (16). The utility of these systems has not been demonstrated for monitoring small- or intermediate-sized outbreaks or illnesses defined primarily by laboratory testing. Even when using these suggested modifications, sensitivity for detecting additional counts at the facility level remains modest. However, the utility of automated biosurveillance will be expanded with the availability of better population coverage and more specific data, the use of multiple data types in combination, and improved detection algorithms, such as those proposed here.",
            "cite_spans": [
                {
                    "start": 166,
                    "end": 168,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 340,
                    "end": 342,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                }
            ],
            "section": "Discussion",
            "ref_spans": []
        },
        {
            "text": "The limitations of this study include using only data with a mean count >0.5 per day; analyses of sparser data might show different results. We studied only facility-level aggregation of data, selected patient types (e.g., hospital inpatients were not studied), selected data types (e.g., ED diagnoses were not studied), and broadly defined syndromes (the more granular subsyndromes, which are likely to yield lower counts, were not studied). Although we evaluated only a simple time-series detection method, optimizing performance of simple methods is useful before they can be meaningfully compared with more sophisticated methods, such as regression. Also, we studied effects of additional counts on single days rather than multiday outbreak effects; however, because the C2 algorithm considers data from only 1 day at a time, this is a reasonable initial approach. These results must be confirmed by trials of multiday signal injection and performance evaluated for multiple subgroups (e.g., syndrome, day of week, season). We adopted the approach of evaluating sensitivity at a fixed 1% alert rate defined empirically for each algorithm and dataset, as used by Jackson et al. (12). Our approach is in accord with a recent review that recommended basing alert thresholds on empirical data rather than on classical statistical theory (17). A major strength of the study is that BioSense is a national system that provided access to 2 major datasets with differing characteristics and to data from hundreds of facilities in many states. The length, geographic spread, and syndrome variation of the study datasets lend weight to the results.",
            "cite_spans": [
                {
                    "start": 1182,
                    "end": 1184,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 1338,
                    "end": 1340,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                }
            ],
            "section": "Discussion",
            "ref_spans": []
        },
        {
            "text": "The field of electronic biosurveillance is in its infancy and is rapidly changing. Early work focused on attempts to detect outbreaks (early event detection) by using broadly defined syndromes (e.g., respiratory syndrome) based on chief complaints and diagnoses. Emphasis has recently shifted to monitoring for ongoing outbreaks (situational awareness) and for specific disease indicators (e.g., cough, dyspnea) called subsyndromes. The field is now beginning to develop methods for case-based surveillance (i.e., automated application of a formal case definition using computerized data) (18). Each data type and disease indicator may have unique characteristics that require modifications of standard data analysis methods. However, because the adaptation of time-series methods to recognize outbreaks will be an ongoing need, the enhanced methods identified by this study are likely to have lasting usefulness.",
            "cite_spans": [
                {
                    "start": 590,
                    "end": 592,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                }
            ],
            "section": "Discussion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "FIGREF0": {
            "text": "Figure 1: Distribution of syndrome counts, by day of week and data source, for selected BioSense data used in algorithm modification study. Black bars show Department of Defense data, and white bars show hospital emergency department data.",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Figure 2: Sensitivity of detecting various numbers of additional counts, by using initial versus best algorithms for hospital emergency department chief complaint data, for selected BioSense data. Red line shows the initial algorithm (minimum SD = 0.2, 7-day baseline, count method, unstratified baseline), and black line shows the best algorithm (minimum SD = 1.0, 28-day baseline, rate method, unstratified baseline).",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Figure 3: Comparison of initial versus best algorithms for analysis of fever syndrome data at an example emergency department, October\u2013November 2006. A) SD comparison. Count, fever syndrome counts; SD (initial), SD by using initial algorithm (minimum SD = 0.2, 7-day baseline, count method, unstratified baseline); SD (best), SD by using best algorithm (minimum SD = 1.0, 28-day baseline, rate method, unstratified baseline). B) Count threshold comparison. Count, fever syndrome counts; threshold 1, minimum count needed to trigger an alert by using initial method; threshold 2, minimum count needed to trigger an alert by using best method (for the best algorithm, which accounts for rate, 8 counts were added to total visits for calculating the threshold). C) Detection of 8 additional counts. Count, daily fever syndrome counts; count + 8, daily count plus 8 counts; both methods, 30 days with the additional counts detected by both the initial and best methods; initial only, 2 days with the additional counts detected by using initial method only; and best only, 19 days with additional counts detected by using best method only.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "Implementing syndromic surveillance: a practical guide informed by early experience.",
            "authors": [],
            "year": 2004,
            "venue": "J Am Med Inform Assoc",
            "volume": "11",
            "issn": "",
            "pages": "141-50",
            "other_ids": {
                "DOI": [
                    "10.1197/jamia.M1356"
                ]
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "A simulation study comparing aberration detection algorithms for syndromic surveillance.",
            "authors": [],
            "year": 2007,
            "venue": "BMC Med Inform Decis Mak",
            "volume": "7",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1186/1472-6947-7-6"
                ]
            }
        },
        "BIBREF4": {
            "title": "Methods for current statistical analysis of excess pneumonia-influenza deaths.",
            "authors": [],
            "year": 1963,
            "venue": "Public Health Rep",
            "volume": "78",
            "issn": "",
            "pages": "494-506",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "Code-based syndromic surveillance for influenza-like illness by International Classification of Diseases, ninth revision.",
            "authors": [],
            "year": 2007,
            "venue": "Emerg Infect Dis",
            "volume": "13",
            "issn": "",
            "pages": "207-16",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "Monitoring health effects of wildfires using the BioSense system\u2014San Diego County, California, October 2007.",
            "authors": [],
            "year": 2008,
            "venue": "MMWR Morb Mortal Wkly Rep",
            "volume": "57",
            "issn": "",
            "pages": "741-4",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "Algorithms for rapid outbreak detection: a research synthesis.",
            "authors": [],
            "year": 2005,
            "venue": "J Biomed Inform",
            "volume": "38",
            "issn": "",
            "pages": "99-113",
            "other_ids": {
                "DOI": [
                    "10.1016/j.jbi.2004.11.007"
                ]
            }
        },
        "BIBREF9": {
            "title": "Electronic medical record support for public health (ESP): automated detection and reporting of statutory notifiable diseases to public health authorities.",
            "authors": [],
            "year": 2007,
            "venue": "Advances Dis Surv.",
            "volume": "3",
            "issn": "",
            "pages": "1-5",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "Framework for evaluating public health surveillance systems for early detection of outbreaks; recommendations from the CDC Working Group.",
            "authors": [],
            "year": 2004,
            "venue": "MMWR Recomm Rep",
            "volume": "53",
            "issn": "No. RR-5",
            "pages": "1-12",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "BioSense. Implementation of a national early event detection and situational awareness system.",
            "authors": [],
            "year": 2005,
            "venue": "MMWR Morb Mortal Wkly Rep",
            "volume": "54",
            "issn": "Suppl",
            "pages": "11-9",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [],
            "year": 2003,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": 2007,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "The bioterrorism preparedness and response Early Aberration Reporting System (EARS).",
            "authors": [],
            "year": 2003,
            "venue": "J Urban Health",
            "volume": "80",
            "issn": "suppl 1",
            "pages": "i89-96",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF15": {
            "title": "Comparing aberration detection methods with simulated data.",
            "authors": [],
            "year": 2005,
            "venue": "Emerg Infect Dis",
            "volume": "11",
            "issn": "",
            "pages": "314-6",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Should we be worried? Investigations of signals generated by an electronic syndromic surveillance system\u2014Westchester County, New York.",
            "authors": [],
            "year": 2004,
            "venue": "MMWR Morb Mortal Wkly Rep",
            "volume": "53",
            "issn": "Suppl",
            "pages": "190-5",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "A pilot study of aberation detection algorithms with simulated data.",
            "authors": [],
            "year": 2007,
            "venue": "Adv Dis Surv.",
            "volume": "4",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}