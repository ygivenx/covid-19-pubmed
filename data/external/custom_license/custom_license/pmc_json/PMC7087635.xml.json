{
    "paper_id": "PMC7087635",
    "metadata": {
        "title": "Classifying and Summarizing Information from Microblogs During Epidemics",
        "authors": [
            {
                "first": "Koustav",
                "middle": [],
                "last": "Rudra",
                "suffix": "",
                "email": "koustav.rudra@cse.iitkgp.ernet.in",
                "affiliation": {}
            },
            {
                "first": "Ashish",
                "middle": [],
                "last": "Sharma",
                "suffix": "",
                "email": "ashishshrma22@gmail.com",
                "affiliation": {}
            },
            {
                "first": "Niloy",
                "middle": [],
                "last": "Ganguly",
                "suffix": "",
                "email": "niloy@cse.iitkgp.ernet.in",
                "affiliation": {}
            },
            {
                "first": "Muhammad",
                "middle": [],
                "last": "Imran",
                "suffix": "",
                "email": "mimran@hbku.edu.qa",
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "The vulnerable groups look out for precautionary measures which can guard them against acquiring a disease. Our proposed system tries to extract various small-scale precautionary measures like signs and symptoms (such as \u2018fever\u2019, \u2018flu\u2019, \u2018vomiting\u2019, \u2018diarrhea\u2019), disease transmission mediums (\u2018Transmission of Ebola Virus By Air Possible\u2019) etc., from related informational categories of tweets in order to assist these vulnerable groups. Automatic extraction of such precautionary measures or symptoms is a challenging task due to a number of reasons. For instance, we observe that such an information is floated in two flavors\u2014(i) positive (confirmations): e.g. someone confirms that \u201cflu\u201d is a symptom of the Ebola virus or a tweet reports that people should follow x,y,z measures to avoid getting affected (ii) negative (contradictions): e.g. a tweet reports that \u201cfever\u201d is not a symptom of the Ebola virus. In this case, our system should clearly specify that \u201cfever\u201d is not a symptom of Ebola. In order to effectively tackle this, our system extracts the contextual information (positive or negative) of the terms related to precautionary measures such as symptoms, preventive suggestions and accordingly assists people during epidemics.",
            "cite_spans": [],
            "section": "Assisting Vulnerable Population ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "In this case, the target community is considered already affected by the epidemic (e.g. users have already fallen sick). The users in this community look for treatment-related information or find nearby hospitals which deal with the ongoing epidemic. In order to assist these users, we extract recovery and treatment information from tweets. In case of contagious diseases, it is necessary to alert the affected user groups so that further transmission of the disease can be stopped.",
            "cite_spans": [],
            "section": "Assisting Affected Population ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "During epidemics, government and other health monitoring agencies (WHO, CDC) look for information about victims, affected people, death reports, vulnerable people etc. so that they can judge the severity of the situation and accordingly take necessary actions like taking help of experts/doctors from other countries, setting up separate treatment centers. Many a time, travelers from foreign countries also get affected by sudden outbreaks. In such cases, local government has to inform their respective countries about the current status; sometimes they have to arrange special flights to send the affected people to their home countries. Considering all these perspectives, the proposed approach tries to extract relevant information about affected or vulnerable people.",
            "cite_spans": [],
            "section": "Assisting Health Organizations ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "To the best of our knowledge, all previous research works regarding health and social media (De Choudhury 2015; de Quincey et al. 2016; Yom-Tov 2015) focus on analyzing behavioral and social aspects of users who post information about a particular disease and predict whether a user is going to encounter such disease in future based on her current posts. However, a generic model which could assist different stakeholders during an epidemic is important. We make the following contributions in this work:\nContributionsWe develop a classifier which uses low-level lexical features to distinguish between different disease categories. Vocabulary independent features allow our classifier to function accurately in cross-domain scenarios, e.g., when the classifier trained over tweets posted during some past outbreak is used to predict tweets posted during a future/current outbreak.From each of the identified information classes, we propose different information extraction-summarization techniques, which optimize the coverage of specific disease related terms using an Integer Linear Programming (ILP) approach. Information extracted in this phase helps fulfill information needs of different affected or vulnerable end-users.",
            "cite_spans": [
                {
                    "start": 106,
                    "end": 110,
                    "mention": "2015",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 130,
                    "end": 134,
                    "mention": "2016",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 144,
                    "end": 148,
                    "mention": "2015",
                    "ref_id": "BIBREF34"
                }
            ],
            "section": "Assisting Health Organizations ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "Note that, our epidemic tweet classification approach was first proposed in a prior study (Rudra et al. 2017). The present work extends our prior work as follows. After classification of tweets into different informative categories (symptom, prevention etc.), we propose novel ILP based information extraction-summarization methods for each of the classes which extracts disease related terms and maximizes their coverage in final summary.",
            "cite_spans": [
                {
                    "start": 104,
                    "end": 108,
                    "mention": "2017",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "Assisting Health Organizations ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "Figure 1 provides an overview of our approach. Experiments conducted over real Twitter datasets on two recent disease outbreaks (World Health Organization (WHO) 2014; Centers for Disease Control and Prevention 2014) show that the proposed low-level lexical classifier outperforms vocabulary based approach (Imran et al. 2014) in cross-domain scenario (Section 4). Next, we show the utility of disease specific keyterms in capturing information from different disease related classes and summarizing those information (Section 5). We evaluate the performance of our proposed summarization scheme in Section 6. Our proposed ILP based summarization framework (MEDSUM) performs better compared to real time disaster summarization approach (COWTS) proposed by Rudra et al. (2015). Section 7 shows how extracted information satisfies needs of various stakeholders. Finally, we conclude our paper in Section 8.\n",
            "cite_spans": [
                {
                    "start": 161,
                    "end": 165,
                    "mention": "2014",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 210,
                    "end": 214,
                    "mention": "2014",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 320,
                    "end": 324,
                    "mention": "2014",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 769,
                    "end": 773,
                    "mention": "2015",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Assisting Health Organizations ::: Introduction",
            "ref_spans": [
                {
                    "start": 7,
                    "end": 8,
                    "mention": "1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Various methods have been proposed for mining health and medical information from clinical notes. Most of these works have focused on extracting a broad class of medical conditions (e.g., diseases, injuries, and medical symptoms) and responses (e.g., diagnoses, procedures, and drugs), with the goal of developing applications that improve patient care (Friedman et al. 1999, 2004; Heinze et al. 2001; Hripcsak et al. 2002). The 2010 i2b2/VA challenge (Uzuner et al. 2011) presented the task of extracting medical concepts, tests and treatments from a given dataset. Most of the techniques follow Conditional Random Field (CRF) or rule based classifiers. Roberts et al. (Roberts and Harabagiu 2011) built a flexible framework for identifying medical concepts in clinical text, and classifying assertions, which indicate the existence, absence, or uncertainty of a medical problem. The framework was evaluated on the 2010 i2b2/VA challenge data. Recently Goodwin and Harabagiu (2016) utilized this framework for building a clinical question-answering system. They used a probabilistic knowledge graph, generated from electronic medical records (EMRs), in order to carry out answer inference.",
            "cite_spans": [
                {
                    "start": 370,
                    "end": 374,
                    "mention": "1999",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 376,
                    "end": 380,
                    "mention": "2004",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 396,
                    "end": 400,
                    "mention": "2001",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 418,
                    "end": 422,
                    "mention": "2002",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 467,
                    "end": 471,
                    "mention": "2011",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 693,
                    "end": 697,
                    "mention": "2011",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 977,
                    "end": 981,
                    "mention": "2016",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "Mining Information from Clinical Notes ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "Scanfeld et al. (2010) used Q-Methodology to determine the main categories of content contained in Twitter users\u2019 status updates mentioning antibiotics. Lu et al. (2013) built a framework based on clustering analysis technique to explore interesting health-related topics in online health community. It utilized sentiment based features extracted from SentiWordNet (Esuli and Sebastiani 2007) and domain specific features from MetaMap. Denecke and Nejdl (2009) performed a comprehensive content analysis of different health related Web resources. It also classified medical weblogs according to their information type using features extracted from MetaMap. A framework based on Latent Dirichlet Allocation (LDA) to analyze discussion threads in a health community was proposed by Yang et al. (2016). They first extracted medical concepts, used a modified LDA to cluster documents and finally performed sentiment analysis for each conditional topic. Recently large scale researches have been done in exploring how microblogs can be used to extract symptoms related to disease (Paul and Dredze 2011), mental health (Homan et al. 2014) and so on.",
            "cite_spans": [
                {
                    "start": 17,
                    "end": 21,
                    "mention": "2010",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 164,
                    "end": 168,
                    "mention": "2013",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 387,
                    "end": 391,
                    "mention": "2007",
                    "ref_id": "BIBREF1"
                },
                {
                    "start": 455,
                    "end": 459,
                    "mention": "2009",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 793,
                    "end": 797,
                    "mention": "2016",
                    "ref_id": "BIBREF32"
                },
                {
                    "start": 1092,
                    "end": 1096,
                    "mention": "2011",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1127,
                    "end": 1131,
                    "mention": "2014",
                    "ref_id": "BIBREF9"
                }
            ],
            "section": "Mining Health Information from Social Media Data ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "Most of the methods proposed for extracting information from clinical text utilize earlier proposed systems (e.g., MetaMap (Aronson 2001), cTakes (Savova et al. 2010)) for mapping clinical documents to concepts of medical terminologies and ontologies (eg. UMLS (Bodenreider 2004), SNOMED CT (Stearns et al. 2001)). For a given text, these systems provide extracted terms concepts of clinical terminologies that can be used to describe the content of a document in a standardized way. However, tools like MetaMap were designed specifically to process clinical documents and are thus, specialized to their linguistic characteristics (Denecke 2014). The user-generated medical text from social media differs significantly from professionally written clinical notes. Recent studies have shown that directly applying Metamap on social media data leads to low quality word labels (Tu et al. 2016). There have also been works which propose methods for identifying the kind of failures MetaMap experiences when applied on social media data. Recently Park et al. (2014) characterized failures of MetaMap into boundary failures, missed term failures and word sense ambiguity failures.",
            "cite_spans": [
                {
                    "start": 132,
                    "end": 136,
                    "mention": "2001",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 161,
                    "end": 165,
                    "mention": "2010",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 274,
                    "end": 278,
                    "mention": "2004",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 307,
                    "end": 311,
                    "mention": "2001",
                    "ref_id": "BIBREF28"
                },
                {
                    "start": 640,
                    "end": 644,
                    "mention": "2014",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 885,
                    "end": 889,
                    "mention": "2016",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 1055,
                    "end": 1059,
                    "mention": "2014",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "Mining Health Information from Social Media Data ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "Researchers also put lot of effort in designing text classification techniques (Imran et al. 2014; Rudra et al. 2015) suitable for microblogs. In our recent work, we propose a low-level lexical feature based classifier to classify tweets posted during epidemics (Rudra et al. 2017).",
            "cite_spans": [
                {
                    "start": 93,
                    "end": 97,
                    "mention": "2014",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 112,
                    "end": 116,
                    "mention": "2015",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 276,
                    "end": 280,
                    "mention": "2017",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "Mining Health Information from Social Media Data ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "To our knowledge, all the existing methods try to extract knowledge from past medical records to infer solutions, diagnoses or treatment. However, these techniques will not work for sudden outbreaks for which past medical records are not available. There does not exist any real time classification-summarization framework to extract, classify, and summarize information from microblogs in real time. In this work, we take first step to this problem and propose a real time classification-summarization framework which can be applied to future epidemics.",
            "cite_spans": [],
            "section": "Mining Health Information from Social Media Data ::: Related Work",
            "ref_spans": []
        },
        {
            "text": "We collect the crisis-related messages using AIDR platform (Imran et al. 2014) from Twitter posted during two recent epidemics \u2014\nEbola: This dataset consists of 5.08 million messages posted between August 6th, 2014 and January 19th, 2015 obtained using different keywords (e.g., #Ebola, \u22ef).MERS: This dataset is collected during Middle East Respiratory Syndrome (MERS) outbreak, which consists of 0.215 million messages posted between April 27th and July 16th, 2014 obtained using different keywords (e.g., #MERS, \u22ef)",
            "cite_spans": [
                {
                    "start": 73,
                    "end": 77,
                    "mention": "2014",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "Epidemics ::: Dataset and Classification of Messages",
            "ref_spans": []
        },
        {
            "text": "First, we remove non-English tweets using the language information provided by Twitter. After this step, we got around 200K tweets for MERS which were collected over a period of two and half months. However, tweets for Ebola were collected over a period of six months and we observe that most of the tweets (around 80%) posted after first two months are just exact or near duplicates of tweets posted during the first two months. Hence, for consistency, we select the first 200,000 tweets in chronological order for both the datasets. We make the tweet-ids publicly available to the research community at http://cse.iitkgp.ac.in/~krudra/epidemic.html.",
            "cite_spans": [],
            "section": "Epidemics ::: Dataset and Classification of Messages",
            "ref_spans": []
        },
        {
            "text": "Tweets which contain disease related information are primarily of the following five types: (i) Symptom \u2013 reports of symptoms such as fever, cough, diarrhea, and shortness of breath or questions related to these symptoms. (ii) Prevention \u2013 questions or suggestions related to the prevention of disease or mention of a new prevention strategy. (iii) Disease transmission \u2013 reports of disease transmission or questions related to disease transmission. (iv) Treatment \u2013 questions or suggestions regarding the treatments of the disease. (v) Death report \u2013 reports of affected people due to the disease.",
            "cite_spans": [],
            "section": "Disease-Related Tweets ::: Types of Tweets Posted During Epidemics ::: Dataset and Classification of Messages",
            "ref_spans": []
        },
        {
            "text": "Non-disease tweets do not contribute to disease awareness and mostly contain sentiment/opinion of people.",
            "cite_spans": [],
            "section": "Non-disease Tweets ::: Types of Tweets Posted During Epidemics ::: Dataset and Classification of Messages",
            "ref_spans": []
        },
        {
            "text": "In this work, we try to extract information for both primary and secondary health care services. Symptom, prevention, and transmission classes are relevant to primary health care (vulnerable population) and information about treatment is necessary for secondary health care service (affected population). Finally, reports of dead and affected people are important for government and monitoring agencies.",
            "cite_spans": [],
            "section": "Non-disease Tweets ::: Types of Tweets Posted During Epidemics ::: Dataset and Classification of Messages",
            "ref_spans": []
        },
        {
            "text": "The next two sections discuss our proposed methodology comprising of first categorizing disease-related information (Section 4), and then summarizing information in each category (Section 5).",
            "cite_spans": [],
            "section": "Non-disease Tweets ::: Types of Tweets Posted During Epidemics ::: Dataset and Classification of Messages",
            "ref_spans": []
        },
        {
            "text": "For training the classifier, we consider 2000 randomly selected tweets (after removing duplicates and retweets) related to both the events. Three human volunteers independently observe the tweets, deciding whether they contribute to information about epidemic.1 We obtain unanimous agreement (i.e., all three volunteers assign same label to a tweet) for 87% of the tweets. For rest of the tweets, we follow majority verdict. Non-disease category contains greater number of tweets as compared to tweets present in individual disease related classes. Hence, we discard the large number of extra tweets present in non-disease for tackling class imbalance. Table 2 shows the number of tweets in the gold standard finally created.\n",
            "cite_spans": [],
            "section": "Gold Standard ::: Classification of Tweets",
            "ref_spans": [
                {
                    "start": 659,
                    "end": 660,
                    "mention": "2",
                    "ref_id": "TABREF9"
                }
            ]
        },
        {
            "text": "We aim to build a classifier which can be trained over tweets posted during past disease outbreaks and can directly be used over tweets posted for future epidemics. Earlier Rudra et al. (2015) showed that low level lexical features are useful in developing event independent classifier and they can outperform vocabulary based approaches. Hence, we take the approach of using a set of event independent lexical and syntactic features for the classification task.",
            "cite_spans": [
                {
                    "start": 187,
                    "end": 191,
                    "mention": "2015",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Classification Features ::: Classification of Tweets",
            "ref_spans": []
        },
        {
            "text": "A disease independent classification of tweets requires lexical resources which provide domain knowledge and associated terms. In this work, we consider large medical knowledgebase, Unified Medical Language System (UMLS) (Bodenreider 2004). It comprises over 3 million concepts (virus, flu etc.), each of which is assigned to more than one of the 134 semantic types. Next, MetaMap (Aronson 2001) is used for mapping texts to UMLS concepts. For example, if MetaMap is applied over the tweet \u2018Cover your mouth and wear gloves there is a mers warning\u2019 then we get following set of word-concept type pairs\u20141. cover-Medical device, 2. mouth-Body space, 3. mers-Disease or syndrome, 4. gloves-Manufactured object, and 5. warning-Regulatory activity. As mentioned in Section 2, MetaMap does not perform well in case of short, informal texts. Hence, raw tweets have to pass through some preprocessing phases so that MetaMap can be applied over processed set of tweets. The preprocessing steps are described below. \nWe remove unnecessary words (URLs, mentions, hashtag signs, emoticons, punctuation, and other Twitter specific tags) from the tweets. We use a Twitter-specific part-of-speech (POS) tagger (Gimpel et al. 2011) to identify POS tags for each word in the tweet. Along with normal POS tags (nouns, verbs, etc.), this tagger also labels Twitter-specific elements such as emoticons, retweets, URLs, and so on.We only consider words which are formal English words and present in an English dictionary (Aspell-python). We also remove out-of-vocabulary words commonly used in social media (Maity et al. 2016).MetaMap is originally designed to work for formal medical texts. In case of general texts (tweets), we observe that many common words (\u2018i\u2019, \u2018not\u2019, \u2018from\u2019) are mapped to certain medical concepts. For example, in the tweet \u2018concern over ontario patient from nigeria with flu symptoms via', \u2018from\u2019 and \u2018to\u2019 are marked as qualitative concept (qlco). Hence, we remove all the stopwords from tweets.",
            "cite_spans": [
                {
                    "start": 234,
                    "end": 238,
                    "mention": "2004",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 390,
                    "end": 394,
                    "mention": "2001",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1210,
                    "end": 1214,
                    "mention": "2011",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1600,
                    "end": 1604,
                    "mention": "2016",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "Classification Features ::: Classification of Tweets",
            "ref_spans": []
        },
        {
            "text": "After preprocessing, tweets are passed as input to MetaMap which returns the set of tokens present in the tweet as concepts of UMLS Metathesaurus along with their corresponding semantic type. Finally, semantic types obtained from MetaMap are utilized for finding the relevant features. Table 3 lists the classification features (binary).\n\n",
            "cite_spans": [],
            "section": "Classification Features ::: Classification of Tweets",
            "ref_spans": [
                {
                    "start": 292,
                    "end": 293,
                    "mention": "3",
                    "ref_id": "TABREF10"
                }
            ]
        },
        {
            "text": "For this experiment, we consider four state-of-the-art classification models from Scikit-learn package (Pedregosa et al. 2011)\u2014(i). Support Vector Machine (SVM) classifier with the default RBF kernel and gamma = 0.5, (ii). SVM classifier with linear kernel and l2 optimizer, (iii). Logistic regression, and (iv). Naive-Bayes classifier. SVM classifier with RBF kernel outperforms other classification models when our proposed set of features are used for training and Logistic regression model shows best performance where unigrams are considered as features. Hence, we take following two classification models for rest of the study.",
            "cite_spans": [
                {
                    "start": 121,
                    "end": 125,
                    "mention": "2011",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Model Selection ::: Performance ::: Classification of Tweets",
            "ref_spans": []
        },
        {
            "text": "We compare the performance of the two feature-sets under two different scenarios (i) in-domain classification, where the tweets of same disease are used to train and test the classifier using 10-fold cross validation, and (ii) cross-domain classification, where the classifier is trained with tweets of one disease, and tested on another disease. Table 4 shows the accuracies of the classifier using bag-of-words model (BOW) and the proposed features (PRO) on the tweets.\n",
            "cite_spans": [],
            "section": "Model Selection ::: Performance ::: Classification of Tweets",
            "ref_spans": [
                {
                    "start": 353,
                    "end": 354,
                    "mention": "4",
                    "ref_id": "TABREF11"
                }
            ]
        },
        {
            "text": "BOW model performs well in the case of in-domain classification (diagonal entries in Table 4) due to uniform vocabulary used during a particular event. However, performance of the proposed lexical features is at par with the bag-of-words model.",
            "cite_spans": [],
            "section": "In-domain Classification ::: Performance ::: Classification of Tweets",
            "ref_spans": [
                {
                    "start": 91,
                    "end": 92,
                    "mention": "4",
                    "ref_id": "TABREF11"
                }
            ]
        },
        {
            "text": "The non-diagonal entries of Table 4 represent the accuracies, where the event stated on the left-hand side of the table represents the training event, and the event stated at the top represents the test event. The proposed model performs better than the BOW model in such scenarios, since it is independent of the vocabulary of specific events. For cross-domain classification, we also measure precision, recall, F-score of classification for both sets of features. In order to take care of class imbalance, we consider weighted measure for precision, recall, and F-score. Table 5 shows recall, and F-score for each set of features where left hand side represents training event and right hand side represents test event. Our proposed set of features achieve high recall and f-score compared to bag-of-words model which indicates low level lexical features can show promising performance in classifying tweets posted during future epidemics.\n",
            "cite_spans": [],
            "section": "Cross-Domain Classification ::: Performance ::: Classification of Tweets",
            "ref_spans": [
                {
                    "start": 34,
                    "end": 35,
                    "mention": "4",
                    "ref_id": "TABREF11"
                },
                {
                    "start": 579,
                    "end": 580,
                    "mention": "5",
                    "ref_id": "TABREF12"
                }
            ]
        },
        {
            "text": "From Table 4, it is clear that in cross-domain scenario around 25% tweets are misclassified. In this part, we analyze different kind of errors present in the data and also identify the reasons behind such misclassification. We observe that in most of the cases, tweets from \u2018symptom\u2019, \u2018prevention\u2019, and \u2018transmission\u2019 classes are incorrectly tagged as \u2018non-disease\u2019 due to absence of the features presented in Table 3. When we train our proposed model using Ebola dataset and test it over MERS, tweets belonging to symptom, prevention, and disease transmission classes are misclassified as non-disease in 12%, 13% and 8% of the cases respectively. A few pair of classes like \u2018symptoms\u2019 and \u2018prevention\u2019, \u2018transmission\u2019 and \u2018prevention\u2019, etc. are inter-related. In these pairs, people often use information from one class in order to derive information for the other class. Thus, we find simultaneous use of multiple classes in the same tweet. In such cases, classifier is confused and selects a label arbitrarily. Table 6 shows examples of misclassified tweets, with their true and predicted labels. In most of the cases, we need some features which can discriminate between two closely related classes. In future, we will try to incorporate more low-level lexical features to improve classification accuracy.\n\n",
            "cite_spans": [],
            "section": "Analyzing Misclassified Tweets ::: Classification of Tweets",
            "ref_spans": [
                {
                    "start": 11,
                    "end": 12,
                    "mention": "4",
                    "ref_id": "TABREF11"
                },
                {
                    "start": 416,
                    "end": 417,
                    "mention": "3",
                    "ref_id": "TABREF10"
                },
                {
                    "start": 1020,
                    "end": 1021,
                    "mention": "6",
                    "ref_id": "TABREF13"
                }
            ]
        },
        {
            "text": "Now, given a tweet t, we check if it contains a symptom from the symptom dictionary. If a symptom s is found in t, then there can be two possibilities: \nPositive symptom: The user who posted tweet t might be reporting that symptom s would be observed in a user if she is affected by the ongoing epidemic. Eg. \u2018symptoms of MERS include fever and shortness of breath.\u2019Negative symptom: The user who posted tweet t might be conveying that symptom s would not be observed if a user is affected by the ongoing epidemic. Eg. \u2018#Ebola symptoms are different than upper respiratory tract pathogens, no cough, nasal congestion Dr. Wilson.\u2019\n",
            "cite_spans": [],
            "section": "Symptom Identification ::: Summarizing Symptoms ::: Summarization",
            "ref_spans": []
        },
        {
            "text": "We distinguish between the above two cases by using the terms having dependencies with the symptom term. We check if symptom s has a dependency (Kong et al. 2014) with any strongly negative term in the tweet t. Symptom s is a negative symptom of the disease if s has dependency with atleast one strongly negative term in t. If there is no such dependency with any negative term, then symptom s is a positive symptom of disease. We use Christopher Potts\u2019 sentiment tutorial6 to identify strongly negative terms (e.g., never, no, wont) and Twitter dependency parser to identify the dependency relations present in a tweet. For example, in case of the tweet \u2018CDC announces second case of MERS virus.\u2019, the dependency tree returns following six relations \u2014 (CDC, announces), (case, announces), (second, case), (of, case), (MERS, virus), (virus, of). Table 7 shows examples of some positive and negative symptoms. After identifying both positive and negative symptoms, we try to rank them on the basis of their corpus frequency i.e., number of tweets in the corpus (symptom class) in which the symptom has been reported. However, the same symptom s might occur in multiple tweets. If a symptom s is found as a positive symptom in one tweet and also captured as a negative symptom in another tweet, then s is considered as ambiguous. Next, we describe the method to deal with such ambiguous symptoms.\n",
            "cite_spans": [
                {
                    "start": 157,
                    "end": 161,
                    "mention": "2014",
                    "ref_id": "BIBREF15"
                }
            ],
            "section": "Symptom Identification ::: Summarizing Symptoms ::: Summarization",
            "ref_spans": [
                {
                    "start": 852,
                    "end": 853,
                    "mention": "7",
                    "ref_id": "TABREF14"
                }
            ]
        },
        {
            "text": "In this work, we are primarily interested in positive symptoms of a disease i.e. symptoms which represent that disease. As identified earlier, many ambiguous symptoms may occur in both positive and negative lists. However, the frequency of occurrence of a particular symptom s is not likely to be the same for both positive and negative classes. Hence, we compute the ratio of positive to negative corpus frequency of a particular ambiguous symptom s. If that ratio is \u2264 1, then we drop that symptom s from positive list.",
            "cite_spans": [],
            "section": "Removing Conflicting Symptoms ::: Summarizing Symptoms ::: Summarization",
            "ref_spans": []
        },
        {
            "text": "During epidemics, vulnerable users look for information about possible disease transmission mediums so that precautionary steps can be taken. Common users and health organizations post tweets regarding possible transmission possibilities of a disease for public awareness. It is observed that information about transmission mediums is mostly centered around keywords like \u2018transmission\u2019, \u2018transmit\u2019 etc. In this work, we use following set of transmission related keywords\u2014(i). transmission, (ii). transmit, (iii). transference, (iv). transferral, (v). dissemination, (vi). diffusion, (vii). emanation, (viii). channeling, (ix). spread, (x). transfer, (xi). relay.",
            "cite_spans": [],
            "section": "Summarizing Disease Transmissions ::: Summarization",
            "ref_spans": []
        },
        {
            "text": "To identify informative components centered around such keywords, we explore the dependency relation among the words in a tweet using a dependency tree (Kong et al. 2014). A dependency tree basically indicates the relation among different words present in a tweet. For example, dependency tree for the tweet \u2018Ebola virus could be transmitted via infectious aerosol\u2019 contains the following two dependency relations centered around keyword \u2018transmit\u2019\u2013 (via, transmit), (aerosol, transmit). In general, the POS tag of every transmission medium will be \u2018Noun\u2019 (eg. \u2018aerosol\u2019 in the previous example). Hence, we detect all nouns connected to keywords in the dependency tree within a 2-hop distance.",
            "cite_spans": [
                {
                    "start": 165,
                    "end": 169,
                    "mention": "2014",
                    "ref_id": "BIBREF15"
                }
            ],
            "section": "Summarizing Disease Transmissions ::: Summarization",
            "ref_spans": []
        },
        {
            "text": "It is observed that in some cases people post information about mediums not responsible for disease transmission. Table 8 shows example tweets providing information about transmission mediums in both positive and negative direction. To capture the actual intent of a message, we detect whether any negated context is associated with the keywords or not (same as proposed in symptom detection in Section 5.1). Finally, we rank the transmission mediums based on their corpus frequency, i.e., number of tweets in the transmission class in which they occur and remove ambiguous mediums (present in both positive and negative list) based on the ratio of their frequency of occurrence in positive and negative context (Section 5.1).\n",
            "cite_spans": [],
            "section": "Summarizing Disease Transmissions ::: Summarization",
            "ref_spans": [
                {
                    "start": 120,
                    "end": 121,
                    "mention": "8",
                    "ref_id": "TABREF15"
                }
            ]
        },
        {
            "text": "Users vulnerable to a disease are primarily looking for preventive measures. To provide a summary of those preventive measures, we take tweets categorized as \u2018preventive\u2019 by our classifier and some specific types of preventive terms which provide important information about preventive measures in epidemic scenarios\u2014(i) Therapeutic or preventive procedure, (ii) symptom words, (iii). anatomy words (terms related to terms related to body system, substance, junction, body part etc). We extract these preventive terms from tweets using Metamap and UMLs knowledge bases.\n",
            "cite_spans": [],
            "section": "Summarizing Prevention Information ::: Summarization",
            "ref_spans": []
        },
        {
            "text": "Considering that the important preventive information in an epidemic is often centered around preventive terms, we can achieve a good coverage of preventive information in a summary by optimizing the coverage of such important preventive terms. In order to capture preventive terms, we extract prevention (\u2018Therapeutic or preventive procedure\u2019), anatomy(\u2018Body location or region\u2019, \u2018Body substance\u2019, \u2018Body part, organ, or organ component\u2019), daily activity related concepts and terms using Metamap and UMLS. The importance of a preventive term is computed based on its frequency of occurrence in the corpus i.e., number of times a term t is present in the corpus of preventive tweets.",
            "cite_spans": [],
            "section": "Summarizing Prevention Information ::: Summarization",
            "ref_spans": []
        },
        {
            "text": "To generate a summary from the tweets in this category, we use an Integer Linear Programming (ILP)-based technique (Rudra et al. 2015) to optimize the coverage of the preventive terms. Table 9 states the notations used.\n",
            "cite_spans": [
                {
                    "start": 129,
                    "end": 133,
                    "mention": "2015",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Summarizing Prevention Information ::: Summarization",
            "ref_spans": [
                {
                    "start": 191,
                    "end": 192,
                    "mention": "9",
                    "ref_id": "TABREF16"
                }
            ]
        },
        {
            "text": "The summarization is achieved by optimizing the following ILP objective function:\n1\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$ max(\\lambda_{1}.\\sum\\limits_{i = 1}^{n}x_{i} \\, + \\, \\lambda_{2}.\\sum\\limits_{j = 1}^{m} Score(j).y_{j})  $$\\end{document}max(\u03bb1.\u2211i=1nxi+\u03bb2.\u2211j=1mScore(j).yj)subject to the constraints\n2\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{array}{@{}rcl@{}} &&\\sum\\limits_{i = 1}^{n} x_{i} \\cdot Length(i) \\leq L \\end{array} $$\\end{document}\u2211i=1nxi\u22c5Length(i)\u2264L\n3\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{array}{@{}rcl@{}} &&\\sum\\limits_{i\\in T_{j} } x_{i} \\geq y_{j}, j=[1 {\\cdots} m] \\end{array} $$\\end{document}\u2211i\u2208Tjxi\u2265yj,j=[1\u22efm]\n4\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\begin{array}{@{}rcl@{}} &&\\sum\\limits_{j\\in P_{i}} y_{j} \\geq |P_{i}| \\times x_{i}, i=[1 {\\cdots} n] \\end{array} $$\\end{document}\u2211j\u2208Piyj\u2265|Pi|\u00d7xi,i=[1\u22efn]where the symbols are as explained in Table 9. The objective function considers both the number of tweets included in the summary (through the xi variables) as well as the number of important preventive-terms (through the yj variables) included. The constraint in Eq. 2 ensures that the total number of words contained in the tweets that get included in the summary are at most of the desired length L (user-specified) while the constraint in Eq. 3 ensures that if the preventive term j is selected to be included in the summary, i.e., if yj = 1, then at least one tweet in which this preventive term is present is selected. Similarly, the constraint in Eq. 4 ensures that if a particular tweet is selected to be included in the summary, then the preventive terms in that tweet are also selected. In this summarization process, our objective is to capture more number of preventive terms rather than the number of tweets. Hence, \u03bb1 and \u03bb2 are set to 0 and 1 respectively.",
            "cite_spans": [],
            "section": "Summarizing Prevention Information ::: Summarization",
            "ref_spans": [
                {
                    "start": 1807,
                    "end": 1808,
                    "mention": "9",
                    "ref_id": "TABREF16"
                }
            ]
        },
        {
            "text": "We use GUROBI Optimizer (Gurobi 2015) to solve the ILP. After solving this ILP, the set of tweets i such that xi = 1, represent the summary.",
            "cite_spans": [
                {
                    "start": 32,
                    "end": 36,
                    "mention": "2015",
                    "ref_id": "BIBREF7"
                }
            ],
            "section": "Summarizing Prevention Information ::: Summarization",
            "ref_spans": []
        },
        {
            "text": "During such epidemic apart from health related issues some socio-political matters also arise because travelers from foreign nations also get affected due to the ongoing epidemic and sometimes local government has to arrange necessary equipment for their treatment as well as send them back to their countries. Local residents suffering from the epidemic also need support from government and health agencies. Under such constraints government generally keeps track of number of people dead or under treatment. In this part, we try to extract this kind of information snippet from large set of tweets which may help government to get a quick snapshot of the situation.\n",
            "cite_spans": [],
            "section": "Summarizing Death Reports ::: Summarization",
            "ref_spans": []
        },
        {
            "text": "Primarily, we observe that such information is centered around keywords like \u2018died\u2019, \u2018killed\u2019, \u2018dead\u2019, \u2019death\u2019, \u2018expire\u2019, \u2018demise\u2019 etc. Table 10 shows some examples of the tweets present in the \u2018death reports\u2019 class. While prior work (Rudra et al. 2015) considered all nouns and verbs as content words, in reality, all such keywords present in a tweet are not linked to health related events. Hence, in the present work, we identify the keywords for \u2018death reports\u2019 class from manually annotated corpus. As illustrated in Table 10, tweets contain location-wise information about dead people. Hence, it is necessary to capture location information in final summary. For summarization of death reports, we follow same ILP framework proposed in Section 5.3 but instead of optimizing preventive terms, here we optimize the coverage of death related terms. We consider numerals (e.g., number of casualties), keywords related to death reports, and location information as death related terms. We use Twitter-specific part-of-speech (POS) tagger (Gimpel et al. 2011) to identify POS tags for each word in the tweet. From these POS tags we select numerals for the summarization. We collect keywords related to death reports from manually annotated tweets. To identify location information, we use various online sources.7 Finally, ILP method maximizes the coverage of death related terms.\n",
            "cite_spans": [
                {
                    "start": 248,
                    "end": 252,
                    "mention": "2015",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1054,
                    "end": 1058,
                    "mention": "2011",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "Summarizing Death Reports ::: Summarization",
            "ref_spans": [
                {
                    "start": 142,
                    "end": 144,
                    "mention": "10",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 528,
                    "end": 530,
                    "mention": "10",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "Users who already get affected by the disease look for information about necessary medicines, treatment centers etc. For summarizing this information, we focus on tweets categorized as \u2018treatment\u2019 by our classifier and some specific types of treatment terms which provide important information about recovery procedure in epidemic scenario (i). clinical drug, (ii). pharmacologic substance (obtained from Metamap and UMLs). Table 11 provides examples of tweets containing treatment or recovery information.\n",
            "cite_spans": [],
            "section": "Summarizing Treatment Information ::: Summarization",
            "ref_spans": [
                {
                    "start": 430,
                    "end": 432,
                    "mention": "11",
                    "ref_id": "TABREF2"
                }
            ]
        },
        {
            "text": "Considering that the important recovery information in an epidemic is often centered around treatment terms, a good coverage of recovery information can be achieved by optimizing the coverage of important treatment terms. The importance of a treatment-term is computed based on its frequency of occurrence in the corpus i.e. number of times a treatment-term t occurs in the corpus of treatment related tweets. For summarization of treatment information, we follow the same ILP framework proposed in Section 5.3 but instead of optimizing preventive terms, here we optimize the coverage of treatment related terms.\n",
            "cite_spans": [],
            "section": "Summarizing Treatment Information ::: Summarization",
            "ref_spans": []
        },
        {
            "text": "We term our proposed MEDical dictionary based tweet SUMmmarization approach as MEDSUM. In the next section, we evaluate the performance of our proposed summarization models.",
            "cite_spans": [],
            "section": "Summarizing Treatment Information ::: Summarization",
            "ref_spans": []
        },
        {
            "text": "In Section 5.1, we propose an algorithm to identify the symptoms of a disease. We need gold standard list of symptoms to check the accuracy of our method. We extract the actual symptoms of a disease by using online sources (World Health Organization (WHO) 2014; Centers for Disease Control and Prevention 2014) and compare the output of our algorithm with the actual symptoms to compute precision score. The number of actual symptoms for Ebola and MERS is 20 and 5 respectively. Hence, our proposed method also extracts 20 and 5 symptoms for Ebola and MERS respectively.",
            "cite_spans": [
                {
                    "start": 256,
                    "end": 260,
                    "mention": "2014",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 305,
                    "end": 309,
                    "mention": "2014",
                    "ref_id": "BIBREF33"
                }
            ],
            "section": "Evaluation of Symptoms of a Disease ::: Experimental Results",
            "ref_spans": []
        },
        {
            "text": "In case of Ebola, we observe that thirteen out of twenty symptoms are present in the gold standard list of symptoms. Three of the remaining seven symptoms are synonyms of some original symptom (present in the list of thirteen symptoms). Similarly, in case of MERS, three out of five symptoms are present in the gold standard list. Among the remaining two symptoms, one is synonym of some original symptom. Finally, our proposed method is able to extract sixteen and four original symptoms for Ebola and MERS respectively. Table 12 shows the precision and recall of our proposed approach.\n",
            "cite_spans": [],
            "section": "Evaluation of Symptoms of a Disease ::: Experimental Results",
            "ref_spans": [
                {
                    "start": 528,
                    "end": 530,
                    "mention": "12",
                    "ref_id": "TABREF3"
                }
            ]
        },
        {
            "text": "We observe that missed out symptoms (seven for Ebola and two for MERS) are identified at later stages of the disease which are not available in the tweets. Hence, we are not able to capture all the relevant symptoms but symptoms extracted from the tweets are able to give users an initial indication of the disease.",
            "cite_spans": [],
            "section": "Evaluation of Symptoms of a Disease ::: Experimental Results",
            "ref_spans": []
        },
        {
            "text": "In Section 5.2, we showed that users post information about both kinds of mediums i.e., mediums responsible for transmission (positive mediums) and mediums not responsible for transmission of the disease (negative mediums). Here, we are interested in positive transmission mediums i.e. mediums responsible for disease propagation. We extract the actual transmission mediums for both the diseases from online sources (World Health Organization (WHO) 2014; Centers for Disease Control and Prevention 2014) and compare the output of our algorithm with the actual transmission mediums to compute the precision and recall. We have collected fourteen and twelve transmission media for Ebola and MERS respectively. Table 13 shows the precision and recall of the proposed algorithm for top 10 and 20 transmission mediums.\n",
            "cite_spans": [
                {
                    "start": 449,
                    "end": 453,
                    "mention": "2014",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 498,
                    "end": 502,
                    "mention": "2014",
                    "ref_id": "BIBREF33"
                }
            ],
            "section": "Evaluation of the Transmission Medium ::: Experimental Results",
            "ref_spans": [
                {
                    "start": 714,
                    "end": 716,
                    "mention": "13",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "It is clear from Table 13 that recall value will increase with more number of transmission mediums but precision goes down. However, many transmission mediums are identified at later stages which are not present in tweets posted during these epidemics. Still, it can provide a general overview about possible transmission mediums to the vulnerable people.",
            "cite_spans": [],
            "section": "Evaluation of the Transmission Medium ::: Experimental Results",
            "ref_spans": [
                {
                    "start": 23,
                    "end": 25,
                    "mention": "13",
                    "ref_id": "TABREF4"
                }
            ]
        },
        {
            "text": "For both the dataset and each of the information classes, three human volunteers (same as those involved in the classification stage) individually prepare summaries of length 200 words from the tweets of the corresponding class. To prepare the final ground truth summary of a particular disease and particular class, we first choose those tweets which are included in the individual summaries of all the volunteers, followed by those which are included by the majority of the volunteers. Thus, we create single ground truth summary of 200 words for each information class, for each dataset.",
            "cite_spans": [],
            "section": "Preparing Ground-Truth Summaries ::: Experimental Settings ::: Evaluation of Prevention, Treatment Mechanisms and Death Reports ::: Experimental Results",
            "ref_spans": []
        },
        {
            "text": "We compare the performance of our proposed summarization technique with disaster specific real time summarization technique COWTS proposed by Rudra et al. (Rudra et al. 2015).",
            "cite_spans": [
                {
                    "start": 169,
                    "end": 173,
                    "mention": "2015",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Baseline ::: Experimental Settings ::: Evaluation of Prevention, Treatment Mechanisms and Death Reports ::: Experimental Results",
            "ref_spans": []
        },
        {
            "text": "We use the standard ROUGE (Lin 2004) metric for evaluating the quality of the summaries generated. Due to the informal nature of tweets, we actually consider the recall and F-score of the ROUGE-1 variant. Formally, ROUGE-1 recall is unigram recall between a candidate / system summary and a reference summary, i.e., how many unigrams of reference summary are present in the candidate summary normalized by the count of unigrams present in the reference summary. Similarly, ROUGE-1 precision is unigram precision between a candidate summary and a reference summary, i.e., how many unigrams of reference summary are present in the candidate/system summary normalized by the count of unigrams present in the candidate summary. Finally the F-score is computed as harmonic mean of recall and precision.",
            "cite_spans": [
                {
                    "start": 31,
                    "end": 35,
                    "mention": "2004",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "Evaluation Metric ::: Experimental Settings ::: Evaluation of Prevention, Treatment Mechanisms and Death Reports ::: Experimental Results",
            "ref_spans": []
        },
        {
            "text": "Next, we show the performance of our proposed method for each of the information classes.",
            "cite_spans": [],
            "section": "Evaluation Metric ::: Experimental Settings ::: Evaluation of Prevention, Treatment Mechanisms and Death Reports ::: Experimental Results",
            "ref_spans": []
        },
        {
            "text": "Table 14 gives the ROUGE-1 F-scores and recall values for both the algorithms respectively. It is clear that MEDSUM performs better compared to COWTS because disaster specific content words are not able to capture preventive information during disease outbreak.\n",
            "cite_spans": [],
            "section": "Disease Prevention ::: Performance Comparison ::: Evaluation of Prevention, Treatment Mechanisms and Death Reports ::: Experimental Results",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 8,
                    "mention": "14",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "Table 15 gives the ROUGE-1 F-scores and recall values for both the algorithms respectively. It is clear that our proposed method performs better compared to COWTS because disease related keywords capture more specific death related information compared to disaster specific content words.\n",
            "cite_spans": [],
            "section": "Death Report ::: Performance Comparison ::: Evaluation of Prevention, Treatment Mechanisms and Death Reports ::: Experimental Results",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 8,
                    "mention": "15",
                    "ref_id": "TABREF6"
                }
            ]
        },
        {
            "text": "Table 16 gives the ROUGE-1 F-scores and recall values for both the algorithms respectively. It is clear that coverage of treatment related information like drugs, medicines helps in better summarization.\n",
            "cite_spans": [],
            "section": "Disease Treatment ::: Performance Comparison ::: Evaluation of Prevention, Treatment Mechanisms and Death Reports ::: Experimental Results",
            "ref_spans": [
                {
                    "start": 6,
                    "end": 8,
                    "mention": "16",
                    "ref_id": "TABREF7"
                }
            ]
        },
        {
            "text": "In general, we observe that health related informative words are helpful to achieve better information coverage compared to disaster specific words during epidemics.",
            "cite_spans": [],
            "section": "Disease Treatment ::: Performance Comparison ::: Evaluation of Prevention, Treatment Mechanisms and Death Reports ::: Experimental Results",
            "ref_spans": []
        },
        {
            "text": "Further, we perform statistical t-test over six (3(#classes) \u2217 2(#datasets)) ROUGE-1 F-scores (significance level 0.10) to check the statistical significance of MEDSUM over COWTS. The improvement appears to be statistically significant (the p-value is .0552).",
            "cite_spans": [],
            "section": "Disease Treatment ::: Performance Comparison ::: Evaluation of Prevention, Treatment Mechanisms and Death Reports ::: Experimental Results",
            "ref_spans": []
        },
        {
            "text": "Summarizing information for \u2018symptom\u2019, \u2018prevention\u2019, and \u2018transmission\u2019 classes helps assist vulnerable end-users and primary health care service. These communities are vulnerable to the disease and precautionary steps are extremely helpful to restrict further spreading of the disease. For example, if people are aware of possible transmission mediums (human-to-human, animal-to-human, air, aerosol etc) of the disease then they can avoid those possibilities and take relevant preventive measures.",
            "cite_spans": [],
            "section": "Vulnerable Population ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "Post-disease community is mostly looking for treatment related information like hospital, drugs, medicines etc. In Section 5.5, we particularly tried to maximize such information via ILP approach. This kind of information helps in secondary health care services where treatment of patients is going on.",
            "cite_spans": [],
            "section": "Affected Population ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "Government, health related organizations (WHO, CDC) looking for information about dead or affected people. Based on this kind of information they can decide whether medical response teams, new treatment centers etc. are necessary in certain regions or not.\n",
            "cite_spans": [],
            "section": "Health Organizations ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "As reported in Section 4, our proposed classifier is able to achieve around 80% accuracy in in-domain scenario and 75% accuracy in cross-domain scenario (25% tweets are classified wrongly). After classification, our proposed summarization framework summarizes the tweets present in the different disease related classes like \u2018symptoms\u2019, \u2018prevention\u2019 etc. In this part, we analyze the effect of misclassification on the summarization output. In the summarization, ILP framework tries to maximize the relevant class specific terms which represent a particular class. For example, in prevention category, ILP framework tries to maximize prevention related terms. If a prevention related tweet is misclassified then important terms present in that class are also wasted because such terms are not relevant to other classes (symptom, treatment etc.). Here, we measure the fraction of terms lost due to misclassification. For this analysis, ground truth is required; hence, we measure these values over manually annotated ground truth data (Section 4). We consider two different cross-domain scenarios where the model is trained over Ebola and tested over MERS and vice versa. Table 17 shows the fraction of terms missed out for symptom, prevention, and treatment class for both Ebola and MERS. For MERS, we lose around 6\u20138% terms for symptom, prevention and 17% terms for treatment class. Similarly, for Ebola, around 17%, 28%, and 35% terms are lost due to misclassification for symptom, prevention, and treatment classes respectively. Overall, misclassification has an impact on overall summarization output. In future, we will incorporate other distinguishing low level features to reduce misclassification rate and improve the performance of classification-summarization framework.\n",
            "cite_spans": [],
            "section": "Effect of Misclassification on Summarization ::: Discussion",
            "ref_spans": [
                {
                    "start": 1177,
                    "end": 1179,
                    "mention": "17",
                    "ref_id": "TABREF8"
                }
            ]
        },
        {
            "text": "During epidemic, it is necessary to summarize the information in real time because time is very critical in such scenarios. Hence, we analyze the execution time of various summarization approaches. For symptom and disease transmission, our proposed method takes around 172, and 257 seconds on average (over Ebola and MERS) respectively to generate summaries. For prevention, treatment, and death reports, proposed method takes around 7.39, 12.57, and 9.31 seconds respectively on average. Symptom and transmission mediums extraction take more time due to parsing overhead; still it is able to extract information in close to real time.",
            "cite_spans": [],
            "section": "Time Taken for Summarization ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "In this work, we observe that information is centered around some health related terms and we are trying to maximize the coverage of these terms in the final summary. We also measure the variation of running time with the number of tweets. We consider first 10,000 tweets from death report class of MERS (around 14,000 tweets) and measure the running time at ten equally spaced breakpoints (1000, 2000, \u22ef, 10000). From Fig. 2, we can observe that running time increases more or less linearly with the number of tweets. However, number of terms which contain information during catastrophes or epidemics are less in number and also grow slowly compared to other real-life events like sports, politics, movies (Rudra et al. 2015). Hence, our proposed method is scalable and able to provide summaries in real time over large number of disease related tweets.\n\n",
            "cite_spans": [
                {
                    "start": 722,
                    "end": 726,
                    "mention": "2015",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Time Taken for Summarization ::: Discussion",
            "ref_spans": [
                {
                    "start": 424,
                    "end": 425,
                    "mention": "2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "As most of the information during an epidemic is centered around some specific terms (prevention terms, drugs, treatment concepts), our proposed framework basically tries to maximize the coverage of these terms in the final summary. We believe that this framework may be extended to other crisis scenarios. However, health related terms (prevention terms, drugs, treatment concepts) will not work in those cases. We have to identify the terms which are capable of covering most of the important information during other kind of crisis scenarios.",
            "cite_spans": [],
            "section": "Time Taken for Summarization ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "Sudden disease outbreaks bring challenges for vulnerable and affected communities. They seek answers to their apprehensions; what are the symptoms of the disease, preventive measures, and treatment strategies. Health organizations also look for situational updates from affected population to prepare response. In this work, we target three communities; vulnerable people, affected people, and health organizations. To provide precise and timely information to these communities, we have presented a classification-summarization approach to extract useful information from a microblogging platform during outbreaks. The proposed classification approach uses low-level lexical class-specific features to effectively categorize raw Twitter messages. We developed a domain-independent classifier which performs better than domain-dependent bag-of-words technique. Furthermore, various disease-category specific summarization approaches have been proposed. Often information posted on Twitter related to, for example, symptoms seems ambiguous for automatic information extractors. To deal with these issues, we generate separate lists representing positive and negative information. We make use of ILP techniques to generate 200-words summaries for some categories. Extensive experimentation conducted on real-world Twitter datasets from Ebola and MERS outbreaks show the effectiveness of the proposed approach. In future, we aim to deploy the system so that it can be practically used for any future epidemic.",
            "cite_spans": [],
            "section": "Conclusion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Examples of various types of disease tweets (which contribute to information about epidemic) and non-disease tweets\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 10: Sample tweets posted during outbreak containing information about killed or died people\n",
            "type": "table"
        },
        "TABREF2": {
            "text": "Table 11: Sample tweets posted during outbreak containing recovery information\n",
            "type": "table"
        },
        "TABREF3": {
            "text": "Table 12: Precision and recall of our symptom identification method\n",
            "type": "table"
        },
        "TABREF4": {
            "text": "Table 13: Precision and recall of our transmission mediums detection method\n",
            "type": "table"
        },
        "TABREF5": {
            "text": "Table 14: Comparison of ROUGE-1 recall and F-scores (Twitter-specific tags, emoticons, hashtags, mentions, urls, removed and standard rouge stemming(-m) and stopwords(-s) option) for MEDSUM (the proposed methodology) and the baseline method COWTS for prevention class\nFor each evaluation metric, the result of better performing system has been boldfaced",
            "type": "table"
        },
        "TABREF6": {
            "text": "Table 15: Comparison of ROUGE-1 recall and F-scores (Twitter-specific tags, emoticons, hashtags, mentions, urls, removed and standard rouge stemming(-m) and stopwords(-s) option) for MEDSUM (the proposed methodology) and the baseline method COWTS for death reports\nFor each evaluation metric, the result of better performing system has been boldfaced",
            "type": "table"
        },
        "TABREF7": {
            "text": "Table 16: Comparison of ROUGE-1 recall and F-scores (Twitter-specific tags, emoticons, hashtags, mentions, urls, removed and standard rouge stemming(-m) and stopwords(-s) option) for MEDSUM (the proposed methodology) and the baseline method COWTS for treatment class\nFor each evaluation metric, the result of better performing system has been boldfaced",
            "type": "table"
        },
        "TABREF8": {
            "text": "Table 17: Fraction of class specific terms covered and missed in symptom, prevention, and treatment class for both Ebola and MERS\n",
            "type": "table"
        },
        "TABREF9": {
            "text": "Table 2: Number of tweets present in different classes\n",
            "type": "table"
        },
        "TABREF10": {
            "text": "Table 3: Lexical features used to classify tweets across different classes\n",
            "type": "table"
        },
        "TABREF11": {
            "text": "Table 4: Classification accuracies of tweets, using (i) bag-of-words features (BOW), (ii) proposed features (PRO). Diagonal entries are for in-domain classification, while the non-diagonal entries are for cross-domain classification. Values in the bracket represent standard deviations in case of in-domain accuracies\nIn-domain classification results are represented by italic entries. For each train-test pair, the accuracy of better performing system has been boldfaced",
            "type": "table"
        },
        "TABREF12": {
            "text": "Table 5: Recall (F-score) of tweets, using (i) bag-of-words features (BOW), (ii) proposed features (PRO)\nIn-domain classification results are represented by italic entries. For each train-test pair, the accuracy of better performing system has been boldfaced",
            "type": "table"
        },
        "TABREF13": {
            "text": "Table 6: Examples of misclassified tweets\n",
            "type": "table"
        },
        "TABREF14": {
            "text": "Table 7: Sample tweets posted during outbreak containing symptoms in positive and negative context\n",
            "type": "table"
        },
        "TABREF15": {
            "text": "Table 8: Sample tweets posted during outbreak containing information about transmission mediums in positive and negative context\n",
            "type": "table"
        },
        "TABREF16": {
            "text": "Table 9: Notations used in the summarization technique\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig. 1: Our proposed framework for classification-summarization of tweets posted during epidemic",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig. 2: Variation of running time with number of tweets",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Fox",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "The social life of health information, Vol. 2011",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "Representing information in patient reports using natural language processing and the extensible markup language",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Friedman",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hripcsak",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Shagina",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Journal of the American Medical Informatics Association",
            "volume": "6",
            "issn": "1",
            "pages": "76-87",
            "other_ids": {
                "DOI": [
                    "10.1136/jamia.1999.0060076"
                ]
            }
        },
        "BIBREF4": {
            "title": "Automated encoding of clinical documents based on natural language processing",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Friedman",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Shagina",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Lussier",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hripcsak",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Journal of the American Medical Informatics Association",
            "volume": "11",
            "issn": "5",
            "pages": "392-402",
            "other_ids": {
                "DOI": [
                    "10.1197/jamia.M1552"
                ]
            }
        },
        "BIBREF5": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "Use of natural language processing to translate clinical information from a database of 889,921 chest radiographic reports 1",
            "authors": [
                {
                    "first": "G",
                    "middle": [],
                    "last": "Hripcsak",
                    "suffix": ""
                },
                {
                    "first": "JH",
                    "middle": [],
                    "last": "Austin",
                    "suffix": ""
                },
                {
                    "first": "PO",
                    "middle": [],
                    "last": "Alderson",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Friedman",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Radiology",
            "volume": "224",
            "issn": "1",
            "pages": "157-163",
            "other_ids": {
                "DOI": [
                    "10.1148/radiol.2241011118"
                ]
            }
        },
        "BIBREF11": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF14": {
            "title": "The role of the internet in supporting and informing carers of people with cancer: a literature review",
            "authors": [
                {
                    "first": "NA",
                    "middle": [],
                    "last": "Kinnane",
                    "suffix": ""
                },
                {
                    "first": "DJ",
                    "middle": [],
                    "last": "Milne",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Supportive Care in Cancer",
            "volume": "18",
            "issn": "9",
            "pages": "1123-1136",
            "other_ids": {
                "DOI": [
                    "10.1007/s00520-010-0863-4"
                ]
            }
        },
        "BIBREF15": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "Automatically detecting failures in natural language processing tools for online community text",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "AL",
                    "middle": [],
                    "last": "Hartzler",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Huh",
                    "suffix": ""
                },
                {
                    "first": "DW",
                    "middle": [],
                    "last": "McDonald",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Pratt",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Journal of Medical Internet Research",
            "volume": "17",
            "issn": "8",
            "pages": "e212-e212",
            "other_ids": {
                "DOI": [
                    "10.2196/jmir.4612"
                ]
            }
        },
        "BIBREF20": {
            "title": "You are what you tweet: analyzing twitter for public health",
            "authors": [
                {
                    "first": "MJ",
                    "middle": [],
                    "last": "Paul",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Dredze",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Icwsm",
            "volume": "20",
            "issn": "",
            "pages": "265-272",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "Scikit-learn: machine learning in Python",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Pedregosa",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Varoquaux",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Gramfort",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Michel",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Thirion",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Grisel",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Blondel",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Prettenhofer",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Weiss",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Dubourg",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Vanderplas",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Passos",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Cournapeau",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Brucher",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Perrot",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Duchesnay",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Journal of Machine Learning Research",
            "volume": "12",
            "issn": "",
            "pages": "2825-2830",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF22": {
            "title": "The unified medical language system (umls): integrating biomedical terminology",
            "authors": [
                {
                    "first": "O",
                    "middle": [],
                    "last": "Bodenreider",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Nucleic Acids Research",
            "volume": "32",
            "issn": "suppl 1",
            "pages": "D267-D270",
            "other_ids": {
                "DOI": [
                    "10.1093/nar/gkh061"
                ]
            }
        },
        "BIBREF23": {
            "title": "A flexible framework for deriving assertions from electronic medical records",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Roberts",
                    "suffix": ""
                },
                {
                    "first": "SM",
                    "middle": [],
                    "last": "Harabagiu",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Journal of the American Medical Informatics Association",
            "volume": "18",
            "issn": "5",
            "pages": "568-573",
            "other_ids": {
                "DOI": [
                    "10.1136/amiajnl-2011-000152"
                ]
            }
        },
        "BIBREF24": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "Mayo clinical text analysis and knowledge extraction system (ctakes): architecture, component evaluation and applications",
            "authors": [
                {
                    "first": "GK",
                    "middle": [],
                    "last": "Savova",
                    "suffix": ""
                },
                {
                    "first": "JJ",
                    "middle": [],
                    "last": "Masanz",
                    "suffix": ""
                },
                {
                    "first": "PV",
                    "middle": [],
                    "last": "Ogren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Sohn",
                    "suffix": ""
                },
                {
                    "first": "KC",
                    "middle": [],
                    "last": "Kipper-Schuler",
                    "suffix": ""
                },
                {
                    "first": "CG",
                    "middle": [],
                    "last": "Chute",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "Journal of the American Medical Informatics Association",
            "volume": "17",
            "issn": "5",
            "pages": "507-513",
            "other_ids": {
                "DOI": [
                    "10.1136/jamia.2009.001560"
                ]
            }
        },
        "BIBREF27": {
            "title": "Dissemination of health information through social networks: twitter and antibiotics",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Scanfeld",
                    "suffix": ""
                },
                {
                    "first": "V",
                    "middle": [],
                    "last": "Scanfeld",
                    "suffix": ""
                },
                {
                    "first": "EL",
                    "middle": [],
                    "last": "Larson",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "American Journal of Infection Control",
            "volume": "38",
            "issn": "3",
            "pages": "182-188",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ajic.2009.11.004"
                ]
            }
        },
        "BIBREF28": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "2010 I2b2/va challenge on concepts, assertions, and relations in clinical text",
            "authors": [
                {
                    "first": "\u00d6",
                    "middle": [],
                    "last": "Uzuner",
                    "suffix": ""
                },
                {
                    "first": "BR",
                    "middle": [],
                    "last": "South",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Shen",
                    "suffix": ""
                },
                {
                    "first": "SL",
                    "middle": [],
                    "last": "DuVall",
                    "suffix": ""
                }
            ],
            "year": 2011,
            "venue": "Journal of the American Medical Informatics Association",
            "volume": "18",
            "issn": "5",
            "pages": "552-556",
            "other_ids": {
                "DOI": [
                    "10.1136/amiajnl-2011-000203"
                ]
            }
        },
        "BIBREF31": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "Mining health social media with sentiment analysis",
            "authors": [
                {
                    "first": "FC",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "AJ",
                    "middle": [],
                    "last": "Lee",
                    "suffix": ""
                },
                {
                    "first": "SC",
                    "middle": [],
                    "last": "Kuo",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Journal of medical systems",
            "volume": "40",
            "issn": "11",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1007/s10916-016-0604-4"
                ]
            }
        },
        "BIBREF33": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "How valuable is medical social media data? Content analysis of the medical web",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Denecke",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Nejdl",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Information Sciences",
            "volume": "179",
            "issn": "12",
            "pages": "1870-1880",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ins.2009.01.025"
                ]
            }
        },
        "BIBREF39": {
            "title": "",
            "authors": [],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        }
    }
}