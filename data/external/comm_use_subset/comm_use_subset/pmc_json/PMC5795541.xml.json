{
    "paper_id": "PMC5795541",
    "metadata": {
        "title": "Free-Form Deformation Approach for Registration of Visible and Infrared Facial Images in Fever Screening \u2020",
        "authors": [
            {
                "first": "Yedukondala",
                "middle": [
                    "Narendra"
                ],
                "last": "Dwith Chenna",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Pejhman",
                "middle": [],
                "last": "Ghassemi",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "T.",
                "middle": [
                    "Joshua"
                ],
                "last": "Pfefer",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Jon",
                "middle": [],
                "last": "Casamento",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Quanzeng",
                "middle": [],
                "last": "Wang",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Image registration involves spatial alignment of images through transformations and can be formulated as a spatial transformation that defines correspondence between two images. Depending on the application, a registration algorithm can be decomposed into three components: a similarity metric [11], a transformation model [12,13,14], and an optimization method [14,15,16].",
            "cite_spans": [
                {
                    "start": 295,
                    "end": 297,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 324,
                    "end": 326,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 327,
                    "end": 329,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 330,
                    "end": 332,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 363,
                    "end": 365,
                    "mention": "14",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 366,
                    "end": 368,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 369,
                    "end": 371,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                }
            ],
            "section": "Image Registration ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "Similarity Metrics determine the accuracy, robustness, and flexibility of a registration algorithm. They can be broadly classified into landmark-based and intensity-based metrics [11]. A landmark-based metric can be used to find transformation using unique landmarks in the reference and moving images. An intensity-based metric works directly with pixel intensity levels and offers flexibility and robustness [15], which makes it suitable for most image registration applications. In the case of different modalities, the intensity-based similarity metric based on correlation (e.g., normalize cross correlation (NCC)) or statistic measures (e.g., entropy-based mutual information (MI)) of pixel values are well suited for MMIR. Intensity-based metrics widely used for medical image registration, include sum of squared difference (SSD), NCC, and MI [11]. The SSD similarity metric is the simplest similarity metric for image registration. It can be calculated as:(1)ISSD=\u2211\u200b[Ireg(x,y)\u2212Iref(x,y)]2\nwhere ISSD is a measure of the SSD metric, Iref, and Ireg are the intensity matrices of the reference image and the transformed moving image (i.e., the registered image), respectively. ISSD is often used for images with similar modality, which gives an optimal solution if the images are aligned with white Gaussian noise. The NCC similarity metric is a more general similarity metric. It assumes a linear intensity relationship between images Iref and Ireg and can be expressed as:(2)INCC=\u2211\u200b(Iref(x,y)\u2212\u03bcref)(Ireg(x,y)\u2212\u03bcreg)\u2211\u200b(Iref(x,y)\u2212\u03bcref)2\u2211\u200b(Ireg(x,y)\u2212\u03bcreg)2\nwhere \u03bcref and \u03bcreg. are the mean image intensities of the reference and registered images, respectively. The MI similarity metric for image registration was first proposed by Woods et al. [17]. In the case of MMIR, regions with different intensity levels in an image would correspond to similar regions in another image that also contain similar number of intensity levels (maybe of different values). Ideally, the correspondence between these intensity levels might not change significantly across either of these images. Hill et al. [18] proposed a registration method by constructing a joint histogram, which is defined as a two-dimensional plot showing combinations of intensity levels (Figure 1). The value at location (i, j) in a joint histogram represents the number of pixels whose intensity level is i in one image and j in the other. A joint histogram shows decreased dispersion as registration accuracy increases. Shannon entropy (referred as entropy) is used as a metric to measure the dispersion in a joint histogram. If X = {x1, x2, \u2026, xn} is a finite discrete set and each element has probability pi, the entropy of X is given by: (3)H(X)=\u2212\u2211i=1npilog2pi.",
            "cite_spans": [
                {
                    "start": 180,
                    "end": 182,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 411,
                    "end": 413,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 852,
                    "end": 854,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 1751,
                    "end": 1753,
                    "mention": "17",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 2098,
                    "end": 2100,
                    "mention": "18",
                    "ref_id": "BIBREF9"
                }
            ],
            "section": "Image Registration ::: 1. Introduction",
            "ref_spans": [
                {
                    "start": 2253,
                    "end": 2261,
                    "mention": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Entropy only depends on the distribution of the random variables. This definition of entropy can be extended to images, where the probability distribution function is constructed using the histogram distribution of the pixel values in the image. Entropy of a joint histogram decreases as the alignment of images increases as shown in Figure 1. The MI metric IMI (A; B) can be defined as [11]:(4)IMI(A;B)=H(A)+H(B)\u2212H(A,B)\nwhere H(A), H(B), and H(A,B) are entropies of image A, image B, and joint histogram, respectively. The maximization of IMI can be achieved by minimizing the entropy of the joint histogram. Hence, the problem of registration is converted into an optimization problem involving maximization of the MI metric using different transformations. The MI metric is widely used for MMIR.",
            "cite_spans": [
                {
                    "start": 388,
                    "end": 390,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                }
            ],
            "section": "Image Registration ::: 1. Introduction",
            "ref_spans": [
                {
                    "start": 334,
                    "end": 342,
                    "mention": "Figure 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "A Transformation Model defines the relationship between the coordinates of two images. Let Iref, Imov, and Ireg denote the reference, moving, and registered images, respectively, the goal is to find a transformation matrix T(x, y) (or equivalently its inverse) which provides a mapping from Imov(x, y) to Ireg(x, y) so that Iref and Ireg have sufficient similarity. Transformation models can be classified as linear transformations (e.g., rigid, affine, projective) and non-linear transformations (e.g., curved (or elastic), FFD) [20,21]. Linear transformations are global (i.e., warping the whole image) [20] and may include translation, rotation, scaling, reflection, shear, and projection. Simple planar surfaces can be modeled through translation, rotation, scaling, and shear, which together define an affine transformation. Affine transformation preserves the parallelism of lines, but not their lengths or angles. It extends the degrees of freedom for the rigid transformation with scaling factor and shear. ",
            "cite_spans": [
                {
                    "start": 531,
                    "end": 533,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 534,
                    "end": 536,
                    "mention": "21",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 606,
                    "end": 608,
                    "mention": "20",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "Image Registration ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "In many cases, MMIR uses a non-linear transformation by locally displacing a moving image. FFD transformation algorithms are widely used for MMIR. They can be broadly classified into parametric and non-parametric algorithms. The parametric algorithms (e.g., B-spline algorithms [15]) are defined on a coarse grid of control points and contrast with non-parametric algorithms (e.g., Demons algorithm [12]) where a displacement vector is associated with every pixel in the moving image. Both the parametric and non-parametric transformations have many parameters and are computationally intense, which can be handled through a registration strategy based on a hierarchical Gaussian pyramid. In the case of parametric transforms, the displacement field at every pixel (x, y), T(x, y), is defined as a function of displacement vectors (u, v) in the neighborhood of coarse grid control points.\n(5)T(x, y)=(x+f(u), y+f(v))\nwhere u and v are vertical and horizontal displacement fields, and f is the weight of basis function used to define the transformation. Given a pair of images Iref and Imov, we wish to simultaneously recover u and v. The parametric algorithms use a combination of vectors to define the displacement at a general location in the image with nearer vectors having a greater influence. The inherent smoothness of cubic B-spline functions also defines smooth displacement vectors without the need for external smoothness constraints. In the case of non-parametric algorithms, an additional smoothness constraint on the transformation based on a weighted Gaussian function can be included. This smoothness constraint eliminates un-natural deformations in the transformation. ",
            "cite_spans": [
                {
                    "start": 279,
                    "end": 281,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 400,
                    "end": 402,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                }
            ],
            "section": "Image Registration ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "An Optimization method tries to minimize (or maximize) the specified similarity metric over the search space of possible parameters for the transformation model. An effective optimization method must be reliable and quick to find the best possible parameters of the transformation model. Selection of an optimization method depends on the application, transformation model, time constraints, and required accuracy of the registration. In non-linear registration applications, the optimizer is more complicated as a non-linear transformation model has more parameters than a linear one. Many registration problems can be solved using a gradient-descent-based optimization method, with existing numerical solvers [15,16]. ",
            "cite_spans": [
                {
                    "start": 712,
                    "end": 714,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 715,
                    "end": 717,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                }
            ],
            "section": "Image Registration ::: 1. Introduction",
            "ref_spans": []
        },
        {
            "text": "The coarse registration was based on an affine transformation with a MI similarity matric, followed by face detection. The face detection algorithm was based on work by Viola and Jones [23], a cascade boosted classifier using Haar-like digital image features trained with positive and negative examples. The pre-trained frontal face classifier available with the MATLAB computer vision library was used to obtain the location and size of the face region [24]. The coarse registration algorithm was implemented in MATLAB using the Mattes MI algorithm [11]. In this algorithm, single intensity pixel/sample was drawn from images. The marginal and joint probability density function (PDF) was evaluated at discrete positions using samples of pixel intensities. The regular step gradient descent optimizer [25] was used for implementation of this algorithm. ",
            "cite_spans": [
                {
                    "start": 186,
                    "end": 188,
                    "mention": "23",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 455,
                    "end": 457,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 551,
                    "end": 553,
                    "mention": "11",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 803,
                    "end": 805,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "2.1. Coarse Registration ::: 2. Implementation ",
            "ref_spans": []
        },
        {
            "text": "We used fine registration to improve registration accuracy of IR-visible image pairs and to enable accurate localization of the canthi regions. Unlike the affine transformation [24,26] used for coarse registration, the fine registration uses FFD and needs to define a vector field for each pixel in the image. To model the local deformations of a face that are difficult to describe via affine transformations, we evaluated both the Demons and the cubic B-spline algorithms, which are widely used in medical imaging as an FFD model. ",
            "cite_spans": [
                {
                    "start": 178,
                    "end": 180,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 181,
                    "end": 183,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "2.2. Fine Registration ::: 2. Implementation ",
            "ref_spans": []
        },
        {
            "text": "The Demons Algorithm [12] proposes non-linear registration as a diffusion process, which introduces entities called Demons that exert forces according to local image characteristics. These forces are inspired from optical flow equations [13]. The basic idea of Demons algorithm for non-linear registration is that the reference image acts as a local force which moves pixels in the moving image to match the reference image. During each iteration, the moving image is transformed using the moving vector dV = (dx, dy) for each pixel as follows:(6)dV(n+1)=(Imov (n)\u2212 Iref)\u00d7(\u2207Iref)(Imov(n) \u2212 Iref)+ |\u2207Iref|.\nwhere Iref represents the intensity of reference image, and Imov(n) represents the intensity of the moving image at the nth iteration. When n = 0, Imov(0) represents the intensity of the original moving image. Gaussian filter is used to smooth the displacement fields, which enables noise suppression and preserves geometric continuity of the deformed image. The gradient of the reference image \u2207Iref is computed only once during the iterations. Moreover, Demons algorithm assumes that the displacement vector is reasonably small or local. In some cases, such an assumption might be violated, which can be mitigated through a multi-scale approach that reduces the magnitude of these displacement vectors. For instance, the reference and moving images can be down-sampled to low-resolution images and the displacement fields at each stage can be up-sampled to a finer scale. Such a multi-scale approach also enables a large computational advantage for large image sizes. The Demons algorithm is widely used for similar modality images using the SSD error as the similarity metric [15,16]. We tried to reduce the differences between modalities by using common features in visible and IR images. We generated edge maps for visible and IR images using the canny edge detector for non-linear transformation. These edge maps emphasize the contour edges of face and show good similarity between visible and IR images [5,7]. The eye regions were used to predict the FFD for fine registration. As an iterative optimization method, effective stopping criteria needed to be defined. We used a tolerance criterion that stops the iterations if the mean square error (MSE) increases with the iterations or the threshold decreases for each iteration within a convergence tolerance. ",
            "cite_spans": [
                {
                    "start": 22,
                    "end": 24,
                    "mention": "12",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 238,
                    "end": 240,
                    "mention": "13",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1686,
                    "end": 1688,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 1689,
                    "end": 1691,
                    "mention": "16",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 2017,
                    "end": 2018,
                    "mention": "5",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 2019,
                    "end": 2020,
                    "mention": "7",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "2.2. Fine Registration ::: 2. Implementation ",
            "ref_spans": []
        },
        {
            "text": "Spline-based algorithms are among the most common and important transformation models used for non-linear registration in medical imaging. Spline-based registration algorithms use control points in the moving image and a spline function that defines the transformation away from these points. They can be broadly divided into two types based on thin-plate splines and B-splines. Thin-plate splines have global influence on the transformation. In contrast, B-splines are only defined near the control points. Any perturbation in the control points influences only the neighborhood of that point and the deformation is defined by manipulating the underlying mesh of the control points. This makes B-spline-based registration a computationally efficient alternative to other non-linear registrations. Implementation of B-spline uses a uniform mesh of the control points such that each set of m \u00d7 m pixels correspond to a single spline patch defined by four control points. The resolution of the control points defines the degrees of freedom and consequently the computational complexity. A large spacing of the control points allows modeling of global non-linear deformations, while a small spacing of control points allows modeling of highly local deformations. The displacement fields are estimated using two dimensional splines controlled by a small number of control points in the moving image. The B-spline basis function imposes an implicit smoothness on the motion field, without the need for additional smoothness constraints. The ui and vi defines the displacement vectors at each pixel in the x and y directions, respectively.\n(7)ui=u(xi,yi)= \u2211\u200bUiwij\n(8)vi=v(xi,yi)= \u2211\u200bVjwij\nwhere wij are called basis functions and are non-zero over a small interval. It emphasizes that the (u, v) are a known linear combination of (Uj, Vj) control points. We used this hierarchical registration with different control point mesh resolutions. The spacing between control points decreased at each level, which increases the resolution of the control point mesh. The horizontal and vertical control points halved in every step. The control point mesh at one level was refined by inserting new control points to create the control point mesh at the next level. Each control point mesh and associated spline-based FFD defined the transformation at each level of resolution. To avoid the overhead of calculating several B-spline FFDs separately, we represented the transformation by a single B-spline FFD whose control point mesh was progressively refined. Based on the order of basis function, the B-spline can be further classified into linear, quadratic, cubic, or higher-order B-spline registrations. The higher-order basis functions improve the registration accuracy at the cost of longer computation time. Cubic B-spline is quite widely used in medical image registration as it offers balanced tradeoff between registration accuracy and computation time [15,24]. Therefore, cubic B-Spline was used in this paper.",
            "cite_spans": [
                {
                    "start": 2947,
                    "end": 2949,
                    "mention": "15",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 2950,
                    "end": 2952,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "2.2. Fine Registration ::: 2. Implementation ",
            "ref_spans": []
        },
        {
            "text": "Similarity metrics of SSD and NCC were evaluated for the Demons and cubic B-spline algorithms, and the preliminary data (not listed in the paper to limit the paper length) showed that the SSD metrics was better than the NCC metrics. Therefore, all the fine registration data shown in this paper were based on the SSD metrics.",
            "cite_spans": [],
            "section": "2.2. Fine Registration ::: 2. Implementation ",
            "ref_spans": []
        },
        {
            "text": "The two-step coarse-fine registration strategy of visible and IR images was qualitatively evaluated. Figure 4 shows a pair of visible and IR images before and after the coarse registration. After coarse registration, the original images were cropped and only the face region in each image was used for the fine registration step. Figure 5 shows the registration results of the edge map pairs using coarse and coarse-fine registration methods. The edge maps were extracted from the Canny edge detector. The fine registration can be based on the Demons or the cubic B-spline algorithm. For simplicity, we call the two-step coarse-fine registration methods the coarse-Demons and coarse-spline methods, respectively. From Figure 5, prominent edge features like eyes, nose, and mouth with the coarse-Demons and coarse-spline methods have been better aligned compared to the coarse registration alone. ",
            "cite_spans": [],
            "section": "3.1. Registration Accuracy ::: 3. Results",
            "ref_spans": [
                {
                    "start": 101,
                    "end": 109,
                    "mention": "Figure 4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 330,
                    "end": 338,
                    "mention": "Figure 5",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 718,
                    "end": 726,
                    "mention": "Figure 5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "Figure 6 shows corresponding image registration results viewed through superimposed checkerboard pattern of visible and IR images in gray scale. It can be observed that the eyes and nose are not accurately aligned with the coarse registration, whereas the coarse-Demons and coarse-spline methods show better alignment. This demonstrates that applying a non-linear registration algorithm improves accurate matching of face images compared to the coarse registration alone.",
            "cite_spans": [],
            "section": "3.1. Registration Accuracy ::: 3. Results",
            "ref_spans": [
                {
                    "start": 0,
                    "end": 8,
                    "mention": "Figure 6",
                    "ref_id": "FIGREF5"
                }
            ]
        },
        {
            "text": "We quantitatively evaluated the two-step coarse-fine registration strategy of visible and IR images with markers attached to the subjects. Circular aluminum foil markers with a diameter of 7 mm were attached to different locations around the canthi regions of 6 volunteers to evaluate the registration accuracy. The markers and their correspondence in each set of visible and IR images (Figure 7) were manually selected to define control points. They were removed using the Spot Healing Brush Tool in Adobe Photoshop\u00ae before the image registration process to avoid any registration bias caused by them. After the image registration, the spatial transformation obtained was applied to the control points for a direct registration without further optimization. The distances between the transformed marker locations on the moving image and their corresponding locations on the reference image were used for registration accuracy analysis. The registration accuracy was analyzed with both MSE and recall [7,26] values. After image registration, the MSE of distances between each pair of transformed markers in the visible and IR images was calculated as a qualitative performance metric. We used Medical Image Registration Toolbox (MIRT) [24] for the cubic B-spline registration, to compare the coarse-spline method with the coarse and coarse-Demons methods. The registration MSE based on markers (Table 1) for the coarse registration was 5.0 \u00b1 1.6 pixels on 6 subjects. It improved to 3.6 \u00b1 1.5 pixels with the coarse-Demons method. The coarse-spline method only slightly improved the accuracy than the coarse method. The scale factor of images was measured to be ~0.8 mm/pixel. Therefore, error in localizing the canthi regions with the coarse-Demons method was converted to 2.8 \u00b1 1.2 mm. We evaluated the uncertainty in manual selection of aluminum markers by repeating the manual selection process for 30 times on the same set of images. This gave us a statistical measure of standard deviation in manual selection to be 0.5 mm.",
            "cite_spans": [
                {
                    "start": 1002,
                    "end": 1003,
                    "mention": "7",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 1004,
                    "end": 1006,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 1236,
                    "end": 1238,
                    "mention": "24",
                    "ref_id": "BIBREF16"
                }
            ],
            "section": "3.1. Registration Accuracy ::: 3. Results",
            "ref_spans": [
                {
                    "start": 387,
                    "end": 395,
                    "mention": "Figure 7",
                    "ref_id": "FIGREF6"
                },
                {
                    "start": 1395,
                    "end": 1402,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "The registration accuracy was also analyzed with the recall parameter that is defined as a fraction of the true positive correspondences to the ground truth. The recall values on all marker pairs were computed (Figure 8). The true positive correspondence was counted when the pair falls within a given accuracy threshold of the Euclidean distance between points in the registered image and the corresponding points in the reference image. The recall graphs plot the recall values against different threshold values, where the recall values are defined as the ratio of the number of markers within a threshold to the total number of markers. Figure 8a reports the recall values against the threshold values using registration methods of coarse, coarse-Demons, and coarse-spline, and with markers in the face region as the control points. The recall curves were based on average values from the subjects in Table 1. From Figure 8a, the algorithms using the coarse-Demons method outperforms the other methods. ",
            "cite_spans": [],
            "section": "3.1. Registration Accuracy ::: 3. Results",
            "ref_spans": [
                {
                    "start": 211,
                    "end": 219,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 641,
                    "end": 649,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 919,
                    "end": 927,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 905,
                    "end": 912,
                    "mention": "Table 1",
                    "ref_id": "TABREF0"
                }
            ]
        },
        {
            "text": "We also evaluated the registration accuracy for canthi localization using manually selected landmarks in the eye region as the control points (Figure 9). The point correspondence on contours around eye region like eyes corners, eye brows, and pupil as ground truth, were identifiable in both the visible and IR images. The registration accuracy was analyzed with both MSE (Table 2) and recall (Figure 8b) values. The MSE of distance between each pair of landmarks in visible and IR images was 5.1 \u00b1 1.9 pixels for the coarse registration on 10 individuals. It was improved to 3.2 \u00b1 1.6 pixels after the Demons registration with the coarse-Demons method. The coarse-spline method showed slightly better accuracy than the coarse method. Figure 8b reports the recall values against the threshold values using registration methods of coarse, coarse-Demons, and coarse-spline. The recall curves were based on average values from the subjects in Table 2. As shown in Figure 8b, the recall plots for the course-Demons method (green plot) were consistently better than the recall plots for other methods for different threshold values. The coarse and coarse-spline methods had similar accuracy. Comparison of Figure 8a with Figure 8b showed that the marker and landmark methods agree with each other.",
            "cite_spans": [],
            "section": "3.1. Registration Accuracy ::: 3. Results",
            "ref_spans": [
                {
                    "start": 143,
                    "end": 151,
                    "mention": "Figure 9",
                    "ref_id": "FIGREF8"
                },
                {
                    "start": 394,
                    "end": 402,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 735,
                    "end": 743,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 961,
                    "end": 969,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 1201,
                    "end": 1209,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 1216,
                    "end": 1224,
                    "mention": "Figure 8",
                    "ref_id": "FIGREF7"
                },
                {
                    "start": 373,
                    "end": 380,
                    "mention": "Table 2",
                    "ref_id": "TABREF1"
                },
                {
                    "start": 940,
                    "end": 947,
                    "mention": "Table 2",
                    "ref_id": "TABREF1"
                }
            ]
        },
        {
            "text": "The canthi regions are not susceptible to other factors (exertion, environment) because the blood in these regions is sufficiently supplied by the internal carotid artery and the heat loss is less than other regions such as the forehead. A recent study [25] and the IEC 80601-2-59 standard [1] indicate that the canthi regions (Figure 10) have the most stable temperature with good correlation to the core body temperature and thus are the best regions for fever screening. The canthi regions can be manually selected from a thermal image to read the temperature (manual approach). However, the manual approach is time consuming and lacks consistency. With the two-step coarse-Demons registration strategy we developed, the temperature at these regions can be quickly and automatically read (automatic approach). While Section 3.1 validates the accuracy of our two-step MMIR approach, this section addresses the MMIR approach based on clinical study data. We compared the automatic approach with the manual approach for reading inner canthi temperature. We used a Discriminative Response Map Fitting (DRMF)-based model [26] for facial key point detection as a tool to detect the canthi regions in the visible image. The detected canthi regions were mirrored to the IR image based on our coarse-Demons MMIR model, and the maximum temperatures (Ta) within the canthi regions were then automatically read from the IR image. At the same time, the canthi regions were manually selected from the IR image to read the maximum temperatures (Tm). The average values of the maximum temperatures from the left canthi (LC) and right canthi (RC) regions were used to compare the manual and automatic approaches.",
            "cite_spans": [
                {
                    "start": 254,
                    "end": 256,
                    "mention": "25",
                    "ref_id": "BIBREF17"
                },
                {
                    "start": 291,
                    "end": 292,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1120,
                    "end": 1122,
                    "mention": "26",
                    "ref_id": "BIBREF18"
                }
            ],
            "section": "3.2. Canthi Temperature Measurement ::: 3. Results",
            "ref_spans": [
                {
                    "start": 328,
                    "end": 337,
                    "mention": "Figure 10",
                    "ref_id": "FIGREF9"
                }
            ]
        },
        {
            "text": "We collected the canthi temperature data from 36 subjects through the manual and automatic approaches. We used Bland Altman plots (Figure 11) for combined graphical and statistical interpretation of the two measurement techniques. The plots were used to show the absolute differences between the two measurements against their mean (i.e., (Ta \u2212 Tm) versus (Ta + Tm)/2). The mean of absolute differences (Solid line in Figure 11) and the 95% limits (Dashed lines in Figure 11) of normal distribution (\u00b11.96SD) are calculated for the estimation of inner canthi temperature from the manual and automatic approaches. We observed a difference between the automatic and manual methods of 0.10 \u00b1 0.09 \u00b0C (mean \u00b1 1.96SD).",
            "cite_spans": [],
            "section": "3.2. Canthi Temperature Measurement ::: 3. Results",
            "ref_spans": [
                {
                    "start": 131,
                    "end": 140,
                    "mention": "Figure 11",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 418,
                    "end": 427,
                    "mention": "Figure 11",
                    "ref_id": "FIGREF10"
                },
                {
                    "start": 465,
                    "end": 474,
                    "mention": "Figure 11",
                    "ref_id": "FIGREF10"
                }
            ]
        },
        {
            "text": "For real-time canthi detection, the image registration speed is important. The speed for the coarse and fine registrations on a consumer laptop (Dell laptop, Intel Core i7-6600 U CPU @ 2.6 GHz, 16 GB RAM) were 5.9 s and 2.9 s, respectively. The registration speed can be affected by many factors such as the computer speed, algorithm parameters, programing language, and image contents. While the registration speed is not the focus of this paper, we believe the registration speed can be improved by using a powerful computer, further optimizing the algorithm parameters, translating the Matlab codes to a faster language such as C/C++ codes, and adjusting the image contents.",
            "cite_spans": [],
            "section": "4.1. Image Registration Speed  ::: 4. Discussion",
            "ref_spans": []
        },
        {
            "text": "The optical performance of a camera, and thus the image quality, might affect the registration accuracy. As mentioned in Section 2, the IR and visible images have 512 \u00d7 640 and 640 \u00d7 480 pixels, respectively, as shown in Figure 12a,b. For canthi-based temperature measurement, we are only interested in face and blackbody region of the input images. During the process of coarse-fine registration, the input images were first cropped to the face region during the coarse registration step (Figure 4). Theoretically, we should be able to get the same registration results if the region of interest around the face has the same number of pixels even though the total pixel numbers of the whole images are different. To evaluate this assumption, we cropped both the visible and IR images to 240 \u00d7 320 pixels (Figure 12c,d)\u2014the minimum required sizes based on the IEC standard [1]\u2014to simulate camera with smaller number of pixels, before performing image registration. Our results showed that registration of Figure 12c,d had the same accuracy as the registration of Figure 12a,b.",
            "cite_spans": [
                {
                    "start": 874,
                    "end": 875,
                    "mention": "1",
                    "ref_id": "BIBREF0"
                }
            ],
            "section": "4.2. Efffect of Image Quality on Registraton Accuracy  ::: 4. Discussion",
            "ref_spans": [
                {
                    "start": 221,
                    "end": 230,
                    "mention": "Figure 12",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 490,
                    "end": 498,
                    "mention": "Figure 4",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 806,
                    "end": 815,
                    "mention": "Figure 12",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 1005,
                    "end": 1014,
                    "mention": "Figure 12",
                    "ref_id": "FIGREF11"
                },
                {
                    "start": 1063,
                    "end": 1072,
                    "mention": "Figure 12",
                    "ref_id": "FIGREF11"
                }
            ]
        },
        {
            "text": "Theoretically, higher image resolution for the same scene will improve registration accuracy. However, a larger pixel number doesn\u2019t necessary mean a higher image resolution. The image resolution is affected by the camera\u2019s modulation transfer function [27], which is not the focus of this paper. The qualities of two images from two cameras with the same physical parameters (e.g., pixel number, field of view, focal length) might be different, which might in turn result in different registration accuracies.",
            "cite_spans": [
                {
                    "start": 254,
                    "end": 256,
                    "mention": "27",
                    "ref_id": "BIBREF19"
                }
            ],
            "section": "4.2. Efffect of Image Quality on Registraton Accuracy  ::: 4. Discussion",
            "ref_spans": []
        },
        {
            "text": "While the data in this paper showed that the coarse-Demons registration was statistically more accurate for the current imaging system, the actual registration approach and parameters should be optimized and evaluated for a different imaging system to achieve optimum registration accuracy. Observed results showed that the edge detection algorithm had a significant impact on registration accuracy. The cubic B-spline registration showed degradation in performance due to edge map outliers. If the edge detection is improved through customized pre-processing, the accuracy of cubic B-spline registration might be improved for a specific IRT system. ",
            "cite_spans": [],
            "section": "4.3. Effects of Other Factors on Registration Accuracy ::: 4. Discussion",
            "ref_spans": []
        },
        {
            "text": "In our study, the visible camera and IRT were placed at the closest possible locations with the center-to-center distance of their optical lenses being 3 cm. If these two cameras can be closer so that they will see the subject from the same angle, the image registration should be more accurate. The intensity and uniformity of the illumination can also affect the registration. Non-uniform and too low/high illumination might deteriorate the registration accuracy. ",
            "cite_spans": [],
            "section": "4.3. Effects of Other Factors on Registration Accuracy ::: 4. Discussion",
            "ref_spans": []
        },
        {
            "text": "In this paper, we proposed a system that uses a two-step coarse-fine registration method for visible and IR face images for body temperature measurement using canthi regions. We evaluated two widely used FFD algorithms\u2014the Demons algorithm and the cubic B-spline algorithm\u2014as the second step of a coarse-fine registration method. The algorithms used edge maps to improve registration accuracy. The registration accuracy of the coarse-Demons and coarse-spline methods were qualitatively compared using MSE values and recall graphs from markers and landmarks. The results show that the coarse-Demons method outperformed the coarse-spline algorithm, likely due to overfitting of the outliers by the latter method. The quantitative measure of registration accuracy was within 2.8 \u00b1 1.2 mm, which enables accurate and automatic localization of the canthi regions in IR images for temperature measurement. We used the coarse-Demons method for registration followed by canthi detection to read the temperature at the canthi regions from IR images. The temperature readings from the proposed automatic method were compared with the readings from the manual method through Bland Altman analysis. The comparison showed a difference of 0.10 \u00b1 0.09 \u00b0C (mean \u00b1 1.96SD) for the automatic and manual temperature readings.",
            "cite_spans": [],
            "section": "5. Conclusions",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF0": {
            "text": "Table 1: Registration Matching Error (Markers in the face region as control points), pixels.\n",
            "type": "table"
        },
        "TABREF1": {
            "text": "Table 2: Registration Matching Error (Landmarks around the eye region as control points), pixels.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Figure 1: Joint histograms for measuring registration accuracy using the MI metric: (a) low accuracy, high entropy; (b) high accuracy, low entropy [19].",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Figure 2: Block diagram of the two-step registration strategy.",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Figure 3: Block diagram of image registration.",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Figure 4: Visible (a,c) and IR (b,d) images before (a,b) and after (c,d) coarse registration.",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Figure 5: Edge map pairs view of registered visible (green) and IR (red) images with the (a) coarse, (b) coarse-Demons, and (c) coarse-spline methods.",
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Figure 6: Checkered view of registered images using the (a) coarse, (b) coarse-Demons, and (c) coarse-spline methods.",
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Figure 7: Aluminum Markers as control points for registration accuracy evaluation: (a) visible image; (b) IR image [19].",
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Figure 8: Recall graphs showing image registration accuracy of the coarse, coarse-Demons and coarse-spline models: (a) Markers in the face region as the control points based on the subjects in Table 1; (b) Landmarks around the eye region as the control points based on the subjects in Table 2.",
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Figure 9: Landmarks as control points for registration accuracy evaluation: (a) visible image; (b) IR image.",
            "type": "figure"
        },
        "FIGREF9": {
            "text": "Figure 10: Canthi regions in (a) a visible and (b) an IR images [19].",
            "type": "figure"
        },
        "FIGREF10": {
            "text": "Figure 11: Automatic versus manual canthi temperature measurement (a) and the Bland-Altman plot (b).",
            "type": "figure"
        },
        "FIGREF11": {
            "text": "Figure 12: Sizes of images used for registration: (a) full size visible image, 640 \u00d7 480 pixels; (b) full size IR image, 512 \u00d7 640 pixels; (c) cropped visible image, 240 \u00d7 320 pixels; (d) cropped IR image, 240 \u00d7 320 pixels.",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": 2017,
            "venue": "IEC 80601-2-59: Particular Requirements for the Basic Safety and Essential Performance of Screening Thermographs for Human Febrile Temperature Screening",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Nocedal",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Wright",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Numerical Optimization",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "Non-Rigid Multimodality Image Registration",
            "authors": [
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Mattes",
                    "suffix": ""
                },
                {
                    "first": "D.R.",
                    "middle": [],
                    "last": "Haynor",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Vesselle",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Lewellen",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Eubank",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "Med. Imag.",
            "volume": "",
            "issn": "",
            "pages": "1609-1620",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "Image matching as a diffusion process: An analogy with Maxwell\u2019s demons",
            "authors": [
                {
                    "first": "J.-P.",
                    "middle": [],
                    "last": "Thirion",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Med. Image Anal.",
            "volume": "2",
            "issn": "",
            "pages": "243-260",
            "other_ids": {
                "DOI": [
                    "10.1016/S1361-8415(98)80022-4"
                ]
            }
        },
        "BIBREF4": {
            "title": "Determining optical flow",
            "authors": [
                {
                    "first": "B.K.",
                    "middle": [],
                    "last": "Horn",
                    "suffix": ""
                },
                {
                    "first": "B.G.",
                    "middle": [],
                    "last": "Schunck",
                    "suffix": ""
                }
            ],
            "year": 1981,
            "venue": "Artif. Intell.",
            "volume": "17",
            "issn": "",
            "pages": "185-203",
            "other_ids": {
                "DOI": [
                    "10.1016/0004-3702(81)90024-2"
                ]
            }
        },
        "BIBREF5": {
            "title": "Implementation and evaluation of various demons deformable image registration algorithms on a GPU",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Gu",
                    "suffix": ""
                },
                {
                    "first": "H.",
                    "middle": [],
                    "last": "Pan",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "R.",
                    "middle": [],
                    "last": "Castillo",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "E.",
                    "middle": [],
                    "last": "Castillo",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Majumdar",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Guerrero",
                    "suffix": ""
                },
                {
                    "first": "S.B.",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Phys. Med. Biol.",
            "volume": "55",
            "issn": "",
            "pages": "207-219",
            "other_ids": {
                "DOI": [
                    "10.1088/0031-9155/55/1/012"
                ]
            }
        },
        "BIBREF6": {
            "title": "Image registration methods: A survey",
            "authors": [
                {
                    "first": "B.",
                    "middle": [],
                    "last": "Zitova",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Flusser",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Image Vis. Comput.",
            "volume": "21",
            "issn": "",
            "pages": "977-1000",
            "other_ids": {
                "DOI": [
                    "10.1016/S0262-8856(03)00137-9"
                ]
            }
        },
        "BIBREF7": {
            "title": "Mutual-information-based registration of medical images: A survey",
            "authors": [
                {
                    "first": "J.P.",
                    "middle": [],
                    "last": "Pluim",
                    "suffix": ""
                },
                {
                    "first": "J.A.",
                    "middle": [],
                    "last": "Maintz",
                    "suffix": ""
                },
                {
                    "first": "M.A.",
                    "middle": [],
                    "last": "Viergever",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "IEEE Trans. Med. Imaging",
            "volume": "22",
            "issn": "",
            "pages": "986-1004",
            "other_ids": {
                "DOI": [
                    "10.1109/TMI.2003.815867"
                ]
            }
        },
        "BIBREF8": {
            "title": "MRI-PET registration with automated algorithm",
            "authors": [
                {
                    "first": "R.P.",
                    "middle": [],
                    "last": "Woods",
                    "suffix": ""
                },
                {
                    "first": "J.C.",
                    "middle": [],
                    "last": "Mazziotta",
                    "suffix": ""
                },
                {
                    "first": "S.R.",
                    "middle": [],
                    "last": "Cherry",
                    "suffix": ""
                }
            ],
            "year": 1993,
            "venue": "J. Comput. Assist. Tomogr.",
            "volume": "17",
            "issn": "",
            "pages": "536-546",
            "other_ids": {
                "DOI": [
                    "10.1097/00004728-199307000-00004"
                ]
            }
        },
        "BIBREF9": {
            "title": "Assessment of Intraoperative Brain Deformation Using Interventional MR Imaging",
            "authors": [
                {
                    "first": "D.L.",
                    "middle": [],
                    "last": "Hill",
                    "suffix": ""
                },
                {
                    "first": "C.R.",
                    "middle": [],
                    "last": "Maurer",
                    "suffix": "Jr."
                },
                {
                    "first": "A.J.",
                    "middle": [],
                    "last": "Martin",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Sabanathan",
                    "suffix": ""
                },
                {
                    "first": "W.A.",
                    "middle": [],
                    "last": "Hall",
                    "suffix": ""
                },
                {
                    "first": "D.J.",
                    "middle": [],
                    "last": "Hawkes",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Rueckert",
                    "suffix": ""
                },
                {
                    "first": "C.L.",
                    "middle": [],
                    "last": "Truwit",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
            "volume": "",
            "issn": "",
            "pages": "910-919",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF10": {
            "title": "Multi-modality image registration for effective thermographic fever screening",
            "authors": [
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Dwith",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Ghassemi",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Pfefer",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Casamento",
                    "suffix": ""
                },
                {
                    "first": "Q.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of the 2017 Multimodal Biomedical Imaging XII",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1117/12.2253932"
                ]
            }
        },
        "BIBREF11": {
            "title": "Fusion of infrared and visible images based on nonsubsampled contourlet transform and sparse K-SVD dictionary learning",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Cai",
                    "suffix": ""
                },
                {
                    "first": "Q.",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Peng",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Song",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Infrared Phys. Techn.",
            "volume": "82",
            "issn": "",
            "pages": "85-95",
            "other_ids": {
                "DOI": [
                    "10.1016/j.infrared.2017.01.026"
                ]
            }
        },
        "BIBREF12": {
            "title": "",
            "authors": [
                {
                    "first": "A.A.",
                    "middle": [],
                    "last": "Goshtasby",
                    "suffix": ""
                }
            ],
            "year": 2005,
            "venue": "2-D and 3-D Image Registration: For Medical, Remote Sensing, and Industrial Applications",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF13": {
            "title": "A survey of medical image registration",
            "authors": [
                {
                    "first": "J.A.",
                    "middle": [],
                    "last": "Maintz",
                    "suffix": ""
                },
                {
                    "first": "M.A.",
                    "middle": [],
                    "last": "Viergever",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Med. Image Anal.",
            "volume": "2",
            "issn": "",
            "pages": "1-36",
            "other_ids": {
                "DOI": [
                    "10.1016/S1361-8415(01)80026-8"
                ]
            }
        },
        "BIBREF14": {
            "title": "Endoscope field of view measurement",
            "authors": [
                {
                    "first": "Q.",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Khanicheh",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Leiner",
                    "suffix": ""
                },
                {
                    "first": "D.",
                    "middle": [],
                    "last": "Shafer",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Zobel",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Biomed. Opt. Exp.",
            "volume": "8",
            "issn": "",
            "pages": "1441-1454",
            "other_ids": {
                "DOI": [
                    "10.1364/BOE.8.001441"
                ]
            }
        },
        "BIBREF15": {
            "title": "Rapid object detection using a boosted cascade of simple features",
            "authors": [
                {
                    "first": "P.",
                    "middle": [],
                    "last": "Viola",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Jones",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)",
            "volume": "",
            "issn": "",
            "pages": "I-511-I-518",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "EM detection of common origin of multi-modal cues",
            "authors": [
                {
                    "first": "A.K.",
                    "middle": [],
                    "last": "Noulas",
                    "suffix": ""
                },
                {
                    "first": "B.J.",
                    "middle": [],
                    "last": "Kr\u00f6se",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of the 8th International Conference on Multimodal interfaces",
            "volume": "",
            "issn": "",
            "pages": "201-208",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF17": {
            "title": "Analysis of IR thermal imager for mass blind fever screening",
            "authors": [
                {
                    "first": "E.Y.",
                    "middle": [],
                    "last": "Ng",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Kawb",
                    "suffix": ""
                },
                {
                    "first": "W.",
                    "middle": [],
                    "last": "Chang",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Microvasc. Res.",
            "volume": "68",
            "issn": "",
            "pages": "104-109",
            "other_ids": {
                "DOI": [
                    "10.1016/j.mvr.2004.05.003"
                ]
            }
        },
        "BIBREF18": {
            "title": "Robust discriminative response map fitting with constrained local models",
            "authors": [
                {
                    "first": "A.",
                    "middle": [],
                    "last": "Asthana",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Zafeiriou",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Cheng",
                    "suffix": ""
                },
                {
                    "first": "M.",
                    "middle": [],
                    "last": "Pantic",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
            "volume": "",
            "issn": "",
            "pages": "3444-3451",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "",
            "authors": [],
            "year": 2017,
            "venue": "ISO 12233: Photography\u2014Electronic Still Picture Imaging\u2014Resolution and Spatial Frequency Responses",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Feature guided Gaussian mixture model with semi-supervised EM and local geometric constraint for retinal image registration",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Jiang",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Inf. Sci.",
            "volume": "417",
            "issn": "",
            "pages": "128-142",
            "other_ids": {
                "DOI": [
                    "10.1016/j.ins.2017.07.010"
                ]
            }
        },
        "BIBREF21": {
            "title": "An Automatic Multi-Target Independent Analysis Framework for Non-Planar Infrared-Visible Registration",
            "authors": [
                {
                    "first": "X.",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                },
                {
                    "first": "T.",
                    "middle": [],
                    "last": "Xu",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "Z.",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Sensors",
            "volume": "17",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.3390/s17081696"
                ]
            }
        },
        "BIBREF22": {
            "title": "Infrared and visible image fusion via gradient transfer and total variation minimization",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "C.",
                    "middle": [],
                    "last": "Li",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Inf. Fusion",
            "volume": "31",
            "issn": "",
            "pages": "100-109",
            "other_ids": {
                "DOI": [
                    "10.1016/j.inffus.2016.02.001"
                ]
            }
        },
        "BIBREF23": {
            "title": "Visible and infrared image registration in man-made environments employing hybrid visual features",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Han",
                    "suffix": ""
                },
                {
                    "first": "E.J.",
                    "middle": [],
                    "last": "Pauwels",
                    "suffix": ""
                },
                {
                    "first": "P.",
                    "middle": [],
                    "last": "De Zeeuw",
                    "suffix": ""
                }
            ],
            "year": 2013,
            "venue": "Pattern Recognit. Lett.",
            "volume": "34",
            "issn": "",
            "pages": "42-51",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patrec.2012.03.022"
                ]
            }
        },
        "BIBREF24": {
            "title": "Non-rigid visible and infrared face registration via regularized Gaussian fields criterion",
            "authors": [
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "Y.",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                },
                {
                    "first": "J.",
                    "middle": [],
                    "last": "Tian",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Pattern Recognit.",
            "volume": "48",
            "issn": "",
            "pages": "772-784",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patcog.2014.09.005"
                ]
            }
        },
        "BIBREF25": {
            "title": "Infrared-visible image registration for augmented reality-based thermographic building diagnostics",
            "authors": [
                {
                    "first": "F.",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Seipel",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Visual. Eng.",
            "volume": "3",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1186/s40327-015-0028-0"
                ]
            }
        },
        "BIBREF26": {
            "title": "Registration of thermal and visible light images of diseased plants using silhouette extraction in the wavelet domain",
            "authors": [
                {
                    "first": "S.",
                    "middle": [],
                    "last": "Raza",
                    "suffix": ""
                },
                {
                    "first": "V.",
                    "middle": [],
                    "last": "Sanchez",
                    "suffix": ""
                },
                {
                    "first": "G.",
                    "middle": [],
                    "last": "Prince",
                    "suffix": ""
                },
                {
                    "first": "J.P.",
                    "middle": [],
                    "last": "Clarkson",
                    "suffix": ""
                },
                {
                    "first": "N.M.",
                    "middle": [],
                    "last": "Rajpoot",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Pattern Recognit.",
            "volume": "48",
            "issn": "",
            "pages": "2119-2128",
            "other_ids": {
                "DOI": [
                    "10.1016/j.patcog.2015.01.027"
                ]
            }
        }
    }
}