{
    "paper_id": "PMC5322923",
    "metadata": {
        "title": "An examination of the factorial and convergent validity of four measures of conspiracist ideation, with recommendations for researchers",
        "authors": [
            {
                "first": "Viren",
                "middle": [],
                "last": "Swami",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "David",
                "middle": [],
                "last": "Barron",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Laura",
                "middle": [],
                "last": "Weis",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Martin",
                "middle": [],
                "last": "Voracek",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Stefan",
                "middle": [],
                "last": "Stieger",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Adrian",
                "middle": [],
                "last": "Furnham",
                "suffix": "",
                "email": null,
                "affiliation": {}
            },
            {
                "first": "Michiel",
                "middle": [],
                "last": "van Elk",
                "suffix": "",
                "email": null,
                "affiliation": {}
            }
        ]
    },
    "body_text": [
        {
            "text": "Most early scales that were developed to measure conspiracist ideation relied on a similar underlying principle: that by presenting participants with a range of real-world conspiracy theories (e.g., the moon landings were faked), it would be possible to obtain an overall measure of conspiracist ideation (or, more accurately, global endorsement of conspiracy theories). A number of such scales have been developed (see Table 1), including the Belief in Specific Conspiracies Scale [3], the Conspiracy Theory Belief Scale [4], the Composite Conspiracy Beliefs Scales [5], and the Belief in Conspiracy Theories Inventory [6]. These scales vary widely in terms of the information provided about scale development, item construction and content, number of items, and internal consistency. Importantly, there has been a tendency for scholars to treat these scales as factorially unidimensional (i.e, by computing total scores) in the absence of analyses of their factor structures [3\u20135] or to treat the items individually [7].",
            "cite_spans": [
                {
                    "start": 483,
                    "end": 484,
                    "mention": "3",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 523,
                    "end": 524,
                    "mention": "4",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 568,
                    "end": 569,
                    "mention": "5",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 621,
                    "end": 622,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 978,
                    "end": 979,
                    "mention": "3",
                    "ref_id": "BIBREF2"
                },
                {
                    "start": 980,
                    "end": 981,
                    "mention": "5",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 1019,
                    "end": 1020,
                    "mention": "7",
                    "ref_id": "BIBREF6"
                }
            ],
            "section": "Endorsement of a range of conspiracy theories ::: Introduction",
            "ref_spans": [
                {
                    "start": 420,
                    "end": 427,
                    "mention": "Table 1",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "To date, only two of these measures have been subjected to factor analysis. One study [8] submitted the 17 items of the Conspiracy Theory Belief Scale to exploratory factor analysis (EFA) and extracted two distinct factors relating to generic conspiracy theories and climate change conspiracy theories. However, it is not apparent that the study had a sufficiently large size (N = 138) by conservative participant-to-item standards (i.e., a participant-to-item ratio of 10:1) [9] to conduct EFA. Moreover, the authors [8] elected to compute a total score (Cronbach \u03b1 = .78), arguing that item inter-correlations were high. This is problematic because item inter-correlations and high internal consistencies may still mask underlying latent factors [10] and, in any event, the internal consistency of the total score was below what has described as acceptable for novel measures (i.e., a internal consistency coefficient of .80) [9]. Other studies using this measure have likewise computed total scores and have reported higher internal consistency coefficients [11\u201313], but have neglected to examine the scale\u2019s factor structure. At least one study [12] has also used a truncated version of this scale in the absence of an examination of the scale\u2019s dimensionality.",
            "cite_spans": [
                {
                    "start": 87,
                    "end": 88,
                    "mention": "8",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 477,
                    "end": 478,
                    "mention": "9",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 519,
                    "end": 520,
                    "mention": "8",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 749,
                    "end": 751,
                    "mention": "10",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 929,
                    "end": 930,
                    "mention": "9",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1062,
                    "end": 1064,
                    "mention": "11",
                    "ref_id": "BIBREF10"
                },
                {
                    "start": 1065,
                    "end": 1067,
                    "mention": "13",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1150,
                    "end": 1152,
                    "mention": "12",
                    "ref_id": "BIBREF11"
                }
            ],
            "section": "Endorsement of a range of conspiracy theories ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "A different measure is the Belief in Conspiracy Theory Inventory (BCTI) [6]. In the parent study, the authors [6] subjected a pool of 15 items to EFA and reported that all but one of the items loaded onto a primary factor. They, therefore, computed a total BCTI score as the mean of the 14 remaining items, a method that has been used in one other study [14]. In a later study [15], an additional item was added to the list of 14 items and a total score was computed, but the authors neglected to report on the factorial validity of this adapted measure. Subsequent studies have mostly used the 15-item version of the BCTI and, although acceptable internal consistency coefficients have been reported [16], none of these studies have re-examined the factorial validity of the BCTI. In addition, the measure has been translated into German [15] and Malay [17], but in both instances the scale translators have not reported on the dimensionality of the measure. A shorter, 10-item version of the scale has also been translated into French [18], but again a total score was computed in the absence of evidence of a one-factor structure.",
            "cite_spans": [
                {
                    "start": 73,
                    "end": 74,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 111,
                    "end": 112,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 355,
                    "end": 357,
                    "mention": "14",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 378,
                    "end": 380,
                    "mention": "15",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 702,
                    "end": 704,
                    "mention": "16",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 840,
                    "end": 842,
                    "mention": "15",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 855,
                    "end": 857,
                    "mention": "17",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 1038,
                    "end": 1040,
                    "mention": "18",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "Endorsement of a range of conspiracy theories ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "In addition to the lack of evidence of factorial validity, these scales also suffer from a number of additional problems. As noted in Table 1, very few of these studies have provided estimates of convergent validity for the scales being used. Response options have also varied between studies for some scales and sample sizes in the studies have varied widely. Perhaps the most problematic aspect of these scales, however, relates to their construct validity. It is not clear to what extent these scales measure anything other than belief in a set of real-world conspiracy theories. Even if we accept that they measure individual differences in conspiracist ideation, such scales may be impractical, requiring constant updating to reflect changes in the popularity of particular conspiracy theories or to reflect local knowledge of conspiracy theories.",
            "cite_spans": [],
            "section": "Endorsement of a range of conspiracy theories ::: Introduction",
            "ref_spans": [
                {
                    "start": 134,
                    "end": 141,
                    "mention": "Table 1",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "Some scholars have developed measures of generic conspiracist ideation that do not make reference to specific conspiracy theories. Such generic conspiracist ideation, would in turn be expected to be positively associated with endorsement of specific conspiracy theories. There are a number of such scales (see Table 2), including the Conspiracy Theory Questionnaire [19], a subscale of the Epistemically Unwarranted Beliefs Scale [20], the Conspiracy Mentality Questionnaire (CMQ) [21], and the Generic Conspiracist Belief Scale (GCBS) [22]. Notably, the former two scales have not been subjected to factor analysis and one-factor structures have been assumed in the absence of empirical evidence in their favour. The latter two scales have been subjected to EFA and confirmatory factor analysis (CFA), but likewise suffer from a number of limitations.",
            "cite_spans": [
                {
                    "start": 367,
                    "end": 369,
                    "mention": "19",
                    "ref_id": "BIBREF18"
                },
                {
                    "start": 431,
                    "end": 433,
                    "mention": "20",
                    "ref_id": "BIBREF19"
                },
                {
                    "start": 482,
                    "end": 484,
                    "mention": "21",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 537,
                    "end": 539,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Measures of generic conspiracist ideation ::: Introduction",
            "ref_spans": [
                {
                    "start": 310,
                    "end": 317,
                    "mention": "Table 2",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "To take the CMQ first, two different versions of this scale appear to exist in the literature: a 12-item version [23] and a 5-item version [21]. The first of these has been subjected to CFA, which showed a one-factor solution to have acceptable fit, but CFA is an inappropriate analytic strategy for a novel scale. CFA indicates whether a hypothesised model has adequate fit, but tells scholars little about whether there may be alternative, better-fitting models. In addition, the authors [23] also appear to have neglected to report on the response option for this 12-item measure. On the other hand, the 5-item version has been subjected to EFA [21], with a one-factor solution extracted. Additionally, multi-group CFA showed that the one-dimensional model had adequate fit in German- and English-speaking samples, but indices for a Turkish-speaking sample were problematic. Even so, the 5-item CMQ may be difficult-to-understand and some studies have reported internal consistency coefficients below an acceptable cut-off [9] (see Table 2).",
            "cite_spans": [
                {
                    "start": 114,
                    "end": 116,
                    "mention": "23",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 140,
                    "end": 142,
                    "mention": "21",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 491,
                    "end": 493,
                    "mention": "23",
                    "ref_id": "BIBREF22"
                },
                {
                    "start": 649,
                    "end": 651,
                    "mention": "21",
                    "ref_id": "BIBREF20"
                },
                {
                    "start": 1027,
                    "end": 1028,
                    "mention": "9",
                    "ref_id": "BIBREF8"
                }
            ],
            "section": "Measures of generic conspiracist ideation ::: Introduction",
            "ref_spans": [
                {
                    "start": 1035,
                    "end": 1042,
                    "mention": "Table 2",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "Further problems with the CMQ include insufficient information about its construction and original item pool, as well as concerns related to its construct validity (i.e., it is not entirely clear that all items in the scale reflect conspiracist ideation, which may explain its low internal consistency in some studies). More specifically, of the five items included in the CMQ, only two (items #4 and #5 may directly assess conspiracist ideation as it is currently conceived. Item #3 is almost certainly factual, but may not necessarily require an underlying conspiracist belief. Items #1 and #2 likewise could be construed as statements of fact, without any underlying conspiracist motive.",
            "cite_spans": [],
            "section": "Measures of generic conspiracist ideation ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "The GCBS is perhaps the most widely used measure of generic conspiracist ideation. In the parent study, the authors [22] reported on the development of a pool of 75 initial items, which was reduced to 59 follow exclusion of negatively-worded items. Based on an EFA of the remaining items, five factors with acceptable internal consistencies were extracted. In a second study [22], the authors selected 15 \u201crepresentative\u201d items and reported that CFA showed a five-factor model to have acceptable fit and better fit than a one-factor model with all 15 items. Even so, they and all subsequent studies using the GCBS have shown a preference to work with total scores. Two further problems limit the validity of the GCBS. First, the authors did not have a sufficiently large sample size to conduct EFA in the parent study; further examinations of the scale\u2019s factor structure were also conducted with small samples with suspect generalisability (see Table 2). Second, the GCBS has been translated into French [24] and Macedonian [25], but factorial validity in these new cultural contexts has not been investigated.",
            "cite_spans": [
                {
                    "start": 117,
                    "end": 119,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 376,
                    "end": 378,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 1006,
                    "end": 1008,
                    "mention": "24",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1026,
                    "end": 1028,
                    "mention": "25",
                    "ref_id": "BIBREF24"
                }
            ],
            "section": "Measures of generic conspiracist ideation ::: Introduction",
            "ref_spans": [
                {
                    "start": 946,
                    "end": 953,
                    "mention": "Table 2",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "To the above list of measures, one study [18] recently added a one-item measure of conspiracist ideation. Although this measure was designed for use when scholars are pressed for time, and although it is not possible to examine the factor structure or report on the internal consistency of this measure, the authors reported that the one-item measure had adequate patterns of convergent validity (see Table 3) and acceptable test-retest reliability after 14 days (r = .75). Given the issues discussed above concerning dimensionality of conspiracist ideation, it is not immediately apparent to what extent a one-item measure offers practical utility over other measures that are already relatively brief. Moreover, in some cases (see Table 3), convergent validity estimates that have been reported for the scale have been moderate at best, raising questions about the extent to which it truly captures individual differences in conspiracist ideation.",
            "cite_spans": [
                {
                    "start": 42,
                    "end": 44,
                    "mention": "18",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "One-Item Conspiracy Measure ::: Introduction",
            "ref_spans": [
                {
                    "start": 401,
                    "end": 408,
                    "mention": "Table 3",
                    "ref_id": null
                },
                {
                    "start": 733,
                    "end": 740,
                    "mention": "Table 3",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "The issues discussed above should give pause to scholars who want to operationalise and measure individual differences in conspiracist ideation. While there has been a proliferation of a range of conspiracist ideation scales, measurement issues have not been paid adequate attention. This has resulted in a number of scales with uncertain psychometric properties. Where factor structures have been examined, it is not immediately clear that scholars have applied basic guidelines for conducting factor analyses, explored the possibility of alternative models, critically appraised the decision(s) to utilise total scores, or re-examined factorial validity when the scales were used in new linguistic or cultural groups. In other instances, scholars have not fully reported on scale construction, making it difficult for scholars interested in replication efforts. These are all issues that have the potential to substantially hamper efforts to measure conspiracist ideation.",
            "cite_spans": [],
            "section": "One-dimensional or multi-dimensional? ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "In addition, there remains some confusion in the theoretical foundations that have led to the construction of the afore-mentioned scales, particularly as to whether conspiracist ideation can be considered to be a one-dimensional or multi-dimensional construct. In terms of scales that measure endorsement of a range of conspiracy theories, the available evidence would seem to suggest that such measures should be one-dimensional. This is based on the finding that belief in conspiracy theories tends to be \u201cmonological\u201d [6, 26]. That is, belief in one conspiracy theory tends to make assimilation of other conspiracy theories more likely; as such, when participants are asked to complete measures that tap endorsement of multiple conspiracy theories, one should expect a monological belief system in which belief in a range of conspiracy theories are inter-correlated.",
            "cite_spans": [
                {
                    "start": 522,
                    "end": 523,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 525,
                    "end": 527,
                    "mention": "26",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "One-dimensional or multi-dimensional? ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "The dimensionality of conspiracist ideation, on the other hand, remains an open question. Although it is possible that conspiracist ideation is multi-dimensional, consisting of discrete beliefs about multiple conspiratorial acts [22], in practice most scholars have assumed that conspiracist ideation should be considered an internally coherent and one-dimensional trait. This is reflected in the use of total scores for the GCBS, as well as a one-dimensional factor structure of the CMQ. Likewise, the one-item measure of conspiracist ideation assumes that the construct can be reduced to a single dimension. Such assumptions appear to be predicated on the idea that conspiracist ideation can be considered to be a latent personality trait, akin to paranormal beliefs for example. While such an assumption seems intuitively plausible, it needs to be rigorously tested before firm conclusions can be drawn.",
            "cite_spans": [
                {
                    "start": 230,
                    "end": 232,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "One-dimensional or multi-dimensional? ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "Additional research is clearly needed to increase researchers\u2019 understanding of, and confidence in, measures used to assess conspiracist ideation. Here, we sought to cast fresh light on some of these measurement issues (i.e., factorial validity, convergent validity, and internal consistency) vis-\u00e0-vis the BCTI, the GCBS, the CMQ, and the one-item conspiracy measure. The three former measures were selected because they are currently the most widely-used measures in the literature and also because their parent studies have reported on the factorial validity of the measures. In addition, we included the one-item measure because it is the most recently validated. We elected to omit the Conspiracy Theory Belief Scale for a number of reasons: there appears to be a good deal of item overlap between items in this measure and the BCTI, and responses scales for this measure have varied across studies (see Table 1). In addition, unlike the BCTI (its most closely comparable scale), the GCBS, and the CMQ, the Conspiracy Theory Belief Scale has been used only relatively infrequently in the literature.",
            "cite_spans": [],
            "section": "The present study ::: Introduction",
            "ref_spans": [
                {
                    "start": 909,
                    "end": 916,
                    "mention": "Table 1",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "In terms of factorial validity, we gathered data from a large U.S. sample of adults, which allowed us to first examine the factor structures of these measures using EFA (to suggest an acceptable, best-fitting structure) and then use CFA in a randomly-selected split-half of the sample (to cross-validate the models). In terms of convergent validity, in addition to assessing scale inter-correlations, we also included a measure of belief in a 9/11 conspiracy theory (i.e., the belief that the September 11, 2011, terrorist attacks were orchestrated or allowed to occur by the U.S. government) and an anti-vaccination conspiracy theory (i.e., the belief that vaccinations do not serve their intended purpose). Finally, we also re-assessed internal consistency coefficients of the four target scales using Nunnally\u2019s [9] widely-cited, but often incorrectly interpreted, criterion.",
            "cite_spans": [
                {
                    "start": 816,
                    "end": 817,
                    "mention": "9",
                    "ref_id": "BIBREF8"
                }
            ],
            "section": "The present study ::: Introduction",
            "ref_spans": []
        },
        {
            "text": "This study was conducted in accordance with the principles expressed in the Declaration of Helsinki and was approved by the ethics committee of the Department of Psychology, University of Westminster (application number: VRE1516-1352). All participants provided written informed consent.",
            "cite_spans": [],
            "section": "Ethics statement ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "The study was approved by the relevant university ethics committee. Data were collected via Amazon\u2019s Mechanical Turk (MTurk) website on May 6\u20137, 2016. MTurk is a crowdsourcing Internet marketplace that allows individuals and businesses (Requesters) to ask \u201cworkers\u201d to complete tasks for payment. MTurk samples are increasingly being used in psychological studies, as it provides a source of high-quality data, and have been reported to be more demographically-diverse than standard Internet samples [27]. The project was advertised as a study on \u201cpolitical opinions and attitudes\u201d and included an estimated duration and compensation. The questionnaire was advertised to MTurk workers who achieved a > 98% approval rate and completed at least 1,000 hits. We limited participation to MTurk workers from the U.S. so as to achieve a relatively homogeneous sample in terms of cultural identity. After providing informed consent, participants were directed to the measures described below, which were presented in an anonymous form and in random order via the randomisation function with Qualtrics, which hosted the survey. In exchange for completing the survey, participants were paid $0.75. Forty-six participants with large amounts of missing data (i.e., missing more than 10% of the total data across all measures) [28] were excluded from the dataset prior to analyses. For all remaining participants, missing data (< 0.2% of total dataset) were completely at random (based on Little\u2019s MCAR analyses), so we used the mean replacement technique to estimate missing values. All participants received debriefing information at the end of the survey.",
            "cite_spans": [
                {
                    "start": 501,
                    "end": 503,
                    "mention": "27",
                    "ref_id": "BIBREF26"
                },
                {
                    "start": 1315,
                    "end": 1317,
                    "mention": "28",
                    "ref_id": "BIBREF27"
                }
            ],
            "section": "Procedures and participants ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "The final sample consisted of 448 women and 355 men, ranging in age from 18 to 70 years (M = 37.07, SD = 11.94). The majority of participants self-reported as White (84.4%), while 6.1% were of African American ancestry, 5.6% of Asian ancestry, and 3.8% as some other ethnic background. In terms of educational qualifications, 27.3% had completed high school, 4.0% were still in full-time education, 49.7% had an undergraduate degree, 15.6% had a postgraduate degree, and the remainder had some other qualification. In terms of marital status, 43.7% were married, 27.3% were single and not currently partners, 22.2% were partnered by not married, 5.4% were divorced, and the remainder were of another marital status.",
            "cite_spans": [],
            "section": "Procedures and participants ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "The version of the BCTI that we used was the 15-item, adapted version [15]. This version includes 14 items from the parent study [6] and an additional item added in a subsequent study [15]. The factor structure of this adapted version of the BCTI has not been previously investigated, but researchers have assumed that it retains its parent, one-factor structure. Internal consistency coefficients for this one-factor solution have tended to be acceptable (see Table 1). In the present study, all items were rated on a 9-point scale, ranging from 1 (Completely false) to 9 (Completely true). Higher scores on this scale reflect greater endorsement of a range of real-world conspiracy theories. BCTI items are reported in Table 4.",
            "cite_spans": [
                {
                    "start": 71,
                    "end": 73,
                    "mention": "15",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 130,
                    "end": 131,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 185,
                    "end": 187,
                    "mention": "15",
                    "ref_id": "BIBREF14"
                }
            ],
            "section": "Belief in Conspiracy Theories Inventory ::: Measures ::: Materials and methods",
            "ref_spans": [
                {
                    "start": 461,
                    "end": 468,
                    "mention": "Table 1",
                    "ref_id": null
                },
                {
                    "start": 721,
                    "end": 728,
                    "mention": "Table 4",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "Although there are 12- and 5-item version of the CMQ, we used the 5-item version of the scale because this is the more widely-used measure in the literature (see Table 2). Bruder et al. [21] reported that the 5-item CMQ had a one-dimensional structure using EFA and that the fit was adequate in German- and English-speaking samples using multi-group CFA. Although the response scale for this measure may be criticised for being difficult-to-understand, we maintained its original format in the present study. Participants were asked to respond on an 11-point scale ranging from 0% (Certainly not) to 100% (Certain). Higher scores on this scale reflect greater generic conspiracist ideation. CMQ items are reported in Table 5.",
            "cite_spans": [
                {
                    "start": 187,
                    "end": 189,
                    "mention": "21",
                    "ref_id": "BIBREF20"
                }
            ],
            "section": "Conspiracy Mentality Questionnaire ::: Measures ::: Materials and methods",
            "ref_spans": [
                {
                    "start": 162,
                    "end": 169,
                    "mention": "Table 2",
                    "ref_id": null
                },
                {
                    "start": 717,
                    "end": 724,
                    "mention": "Table 5",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "We used the 15-item version of the GCBS proposed [22]. The 15 items were selected by Brotherton and colleagues [22] from a larger pool of items to be representative of the five-factor solution reported in the parent study. The authors [22] reported that a five-factor solution had adequate fit using CFA and that this model also had better fit than a one-factor solution with all items. All subsequent studies have used total scores, rather than the five-factor solution, generally reporting acceptable internal consistency coefficients (see Table 2). In the present study, items were rated on a 5-point scale, ranging from 1 (Definitely not true) to 5 (Definitely true). Higher scores on this measure reflect greater generic conspiracist ideation. GCBS items are reported in Table 6.",
            "cite_spans": [
                {
                    "start": 50,
                    "end": 52,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 112,
                    "end": 114,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 236,
                    "end": 238,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Generic Conspiracist Beliefs Scale ::: Measures ::: Materials and methods",
            "ref_spans": [
                {
                    "start": 542,
                    "end": 549,
                    "mention": "Table 2",
                    "ref_id": null
                },
                {
                    "start": 776,
                    "end": 783,
                    "mention": "Table 6",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "We included the one-item conspiracy measure [18]. In this measure, participants are first presented with instructions that allude to some political and social events being debated. Participants are then asked to rate the following item: \u201cI think that the official version of the events given by authorities very often hides the truth\u201d. The item was rated on a 9-point scale, ranging from 1 (Completely false) to 9 (Completely true), so that higher scores reflect greater generic conspiracist ideation.",
            "cite_spans": [
                {
                    "start": 45,
                    "end": 47,
                    "mention": "18",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "One-Item Conspiracy Measure ::: Measures ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "As a measure of convergent validity, we included a subscale from the 9/11 Conspiracist Beliefs Scale [6]. The parent scale consisted of 17 items, but the authors [6] reported, using EFA, that the scale consists of two factors that measure general 9/11 conspiracist beliefs (10 items) and beliefs that the U.S. government conspired to cover-up what happened on September 11, 2011 (7 items). In the present study, only the former subscale was used, with items rated on a 9-point scale ranging from 1 (Completely false) to 9 (Completely true). To check that this subscale was indeed one-dimensional, we submitted the 10 items to principal-axis EFA using the total sample (N = 803). Bartlett\u2019s test of sphericity, \u03c72(45) = 9453.29, p < .001, and the Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy, KMO = .96, indicated that the 10 items had adequate common variance for factor analysis. An EFA with quartimax rotation revealed a single factor (\u03bb = 7.90, variance explained = 79.0%), with all items having excellent loadings (\u2265 .81). An overall subscale score was, therefore, computed as the mean of the relevant 10 items, so that higher scores reflect greater endorsement of general 9/11 conspiracist beliefs. Swami et al. [6] reported that this subscale had acceptable internal consistency (Cronbach \u03b1 = .95) and good patterns of construct and convergent validity. In the present study, Cronbach \u03b1 for this scale was .97.",
            "cite_spans": [
                {
                    "start": 102,
                    "end": 103,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 163,
                    "end": 164,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 1227,
                    "end": 1228,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                }
            ],
            "section": "9/11 conspiracy theories ::: Measures ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "As a second measure of convergent validity, we included an 8-item measure of belief in anti-vaccination conspiracy theories [13]. All items were rated on a 7-point scale, ranging from 1 (Strongly disagree) to 7 (Strongly agree). In the parent study, the authors [13] reported that total scores on the scale had acceptable internal consistency (Cronbach \u03b1 = .85), but neglected to examine the scale\u2019s factor structure. We therefore subjected the 8 items to principal-axis EFA using the total sample. Bartlett\u2019s test of sphericity, \u03c72(28) = 5306.46, p < .001, and the KMO measure of sampling adequacy, KMO = .90, indicated that the 8 items had adequate common variance for factor analysis. We initially computed a principal-axis EFA with quartimax rotation, but because the results indicated a multi-dimensional factor structure, we repeated the analysis using varimax rotation. The results indicated two factors with \u03bb > 1.0 (3.37 and 2.87, respectively) and parallel analysis indicated that both factors should be extracted. Item loadings are reported in S1 Table. Four items loaded onto the primary factor, which tapped the belief that vaccinations are used as a population tracking mechanism (Cronbach \u03b1 = .92, 42.1% of the variance explained). Four items loaded onto a secondary factor, tapping the belief that the dangers of vaccinations are being covered-up; however, two of these items also cross-loaded onto the primary factor, leaving two items in the secondary factor. Because Tabachnick and Fidell [29] do not recommend the use of subscales with less than three items, we elected to discard the secondary factor. The retained subscale included 4 items that tap the conspiracist belief that vaccinations are being used as population tracking mechanism (Cronbach \u03b1 = .92).",
            "cite_spans": [
                {
                    "start": 125,
                    "end": 127,
                    "mention": "13",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 263,
                    "end": 265,
                    "mention": "13",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 1509,
                    "end": 1511,
                    "mention": "29",
                    "ref_id": "BIBREF28"
                }
            ],
            "section": "Anti-vaccination conspiracy theories ::: Measures ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "Participants provided their demographic details consisting of sex, age, current marital status, highest educational qualifications, and ethnicity.",
            "cite_spans": [],
            "section": "Demographics ::: Measures ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "We used a two-step procedure to examine the factor structures of the BCTI, GCBS, and CMQ. First, data from one-half of the sample (n = 402) was randomly selected via a computer-generated random seed. The factor structures of the three scales were then assessed using principal-axis EFA for this subsample using SPSS v.22. This method allowed us to test for the best-fitting model for our dataset, without a priori limitations in terms of modelling [30]. The sample size for all three scales met conservative 10:1 participant-to-item requirements for EFA [9]. Following standard guidelines [31], items were submitted to EFA if they passed standard criteria for item distribution (standardised kurtosis values > 10.0 suggest a problem), average correlation with the other items (items with r < .40 should be dropped), and item-total correlation (items should be dropped with corrected-item total correlations are < .30). For the BCTI and CMQ, we used quartimax rotations because of the expectation of a single, orthogonal factor; for the GCBS, we used a varimax rotation because we expected an inter-correlated, multidimensional model [32\u201333].",
            "cite_spans": [
                {
                    "start": 449,
                    "end": 451,
                    "mention": "30",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 555,
                    "end": 556,
                    "mention": "9",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 590,
                    "end": 592,
                    "mention": "31",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 1134,
                    "end": 1136,
                    "mention": "32",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1137,
                    "end": 1139,
                    "mention": "33",
                    "ref_id": "BIBREF32"
                }
            ],
            "section": "Exploratory factor analysis ::: Statistical analyses ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "The number of factors to be extracted was determined by factor eigenvalues (\u03bb) above 1.0 (the EGV1 criterion), examination of the scree-plot, and\u2014where more than one factor was identified through rotation\u2014the results of parallel analysis [34]. The latter was used because scree-plot inspection and the EGV1 criterion are known to lead to over-extraction of factors [35]. Parallel analysis works by creating random datasets with the same number of cases and variables as the actual dataset [36] Factors in the actual data are only retained if their eigenvalues are greater than the mean of eigenvalues from the random data [34]. Factor loadings were interpreted using Tabachnick and Fidell\u2019s [29] recommendations (i.e., > .71 = excellent, > .63 = very good, > .55 = good, > .45 = fair, and > .32 = poor).",
            "cite_spans": [
                {
                    "start": 239,
                    "end": 241,
                    "mention": "34",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 366,
                    "end": 368,
                    "mention": "35",
                    "ref_id": "BIBREF34"
                },
                {
                    "start": 490,
                    "end": 492,
                    "mention": "36",
                    "ref_id": "BIBREF35"
                },
                {
                    "start": 623,
                    "end": 625,
                    "mention": "34",
                    "ref_id": "BIBREF33"
                },
                {
                    "start": 692,
                    "end": 694,
                    "mention": "29",
                    "ref_id": "BIBREF28"
                }
            ],
            "section": "Exploratory factor analysis ::: Statistical analyses ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "Data from the second split-half subsample (n = 401) was submitted for CFA using the Analysis of Moment Structures Program (AMOS v.23) [37]. Hypothesised modelling was based on the results of the earlier EFA, as well as hypothesised models from earlier studies where there were discrepancies. Standard goodness-of-fit indices were selected a priori to assess the measurement models. The normed model chi-square (\u03c7\u00b2normed) is reported with lower values of the overall model \u03c7\u00b2 indicating goodness-of-fit. A \u03c7\u00b2normed value of < 3.00 indicates good fit [38]. The Steiger-Lind root mean square error of approximation (RMSEA) and its 90% confidence interval provide a correction for model complexity. RMSEA values close to .06 indicate a good fit, with values ranging to .10 representing a mediocre fit [38]. The standardised root mean square residual (SRMR) assesses the mean absolute correlation residual and is a badness-of-fit index: the smaller the SRMR, the better the model fit. A cut-off value for SRMR is recommended to be \u201cclose to\u201d or < .09 [38]. The comparative fit index (CFI) measures the proportionate improvement in fit by comparing a target model with a more restricted, nested baseline model. The CFI reflects a goodness-of-fit index and is recommended to \u201cclose to\u201d or > .95 for adequate fit [38]. Even so, these recommended cut-off values should be considered subjective guidelines [39\u201340]. We also examined standardised parameter estimates.",
            "cite_spans": [
                {
                    "start": 135,
                    "end": 137,
                    "mention": "37",
                    "ref_id": "BIBREF36"
                },
                {
                    "start": 550,
                    "end": 552,
                    "mention": "38",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 798,
                    "end": 800,
                    "mention": "38",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 1047,
                    "end": 1049,
                    "mention": "38",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 1306,
                    "end": 1308,
                    "mention": "38",
                    "ref_id": "BIBREF37"
                },
                {
                    "start": 1397,
                    "end": 1399,
                    "mention": "39",
                    "ref_id": "BIBREF38"
                },
                {
                    "start": 1400,
                    "end": 1402,
                    "mention": "40",
                    "ref_id": "BIBREF39"
                }
            ],
            "section": "Confirmatory factor analysis ::: Statistical analyses ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "Factor loadings for CFA were interpreted using Comrey and Lee\u2019s [41] recommendations (i.e., > .71 = excellent, > .63 = very good, > .55 = good, > .45 = fair, and > .32 = poor). The potential to improve the accuracy of each model was also evaluated through consultation of modification indices. Modification indices are estimates that identify potentially significant adjustments that could be made to the model (e.g., a covariance of the error terms for two indicators [42]. However, any modification to the existing model should make theoretical sense, rather than simply from analytical addition or subtraction of a parameter [43]. Further, the fit of the model cannot be improved by allowing an indicator to load onto another latent variable [44].",
            "cite_spans": [
                {
                    "start": 65,
                    "end": 67,
                    "mention": "41",
                    "ref_id": "BIBREF40"
                },
                {
                    "start": 470,
                    "end": 472,
                    "mention": "42",
                    "ref_id": "BIBREF41"
                },
                {
                    "start": 629,
                    "end": 631,
                    "mention": "43",
                    "ref_id": "BIBREF42"
                },
                {
                    "start": 746,
                    "end": 748,
                    "mention": "44",
                    "ref_id": "BIBREF43"
                }
            ],
            "section": "Confirmatory factor analysis ::: Statistical analyses ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "For both subsamples, internal consistency coefficients were computed using Cronbach \u03b1. Although Nunnally [9] is widely interpreted as indicating that an internal consistency coefficient of .70 is acceptable, this is in fact a myth [45]. He, in fact, advocated a more conservative cut-off of .80, which we applied here. To assess convergent validity, we computed bivariate correlations between all included variables. According to Lipsey and Wilson [46], correlations of .10 are considered small, correlations of .25 are considered medium, and correlations of .40 are considered large.",
            "cite_spans": [
                {
                    "start": 106,
                    "end": 107,
                    "mention": "9",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 232,
                    "end": 234,
                    "mention": "45",
                    "ref_id": "BIBREF44"
                },
                {
                    "start": 449,
                    "end": 451,
                    "mention": "46",
                    "ref_id": "BIBREF45"
                }
            ],
            "section": "Supplemental analyses ::: Statistical analyses ::: Materials and methods",
            "ref_spans": []
        },
        {
            "text": "The BCTI items were examined for normality of distribution and were found to be lower than limits, pre-empting transformation. The size of Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy, KMO = .93, suggested that the BCTI items had adequate common variance for factor analysis, and Bartlett\u2019s test of sphericity, \u03c72(105) = 3120.96, p < .001, indicated that the correlation matrix was factorable. The results of the EFA revealed two factors with \u03bb > 1.0 (7.11 and 1.33). However, inspection of the scree-plot suggested one primary factor and a steep cut-off to the secondary factor. The results of parallel analysis showed that the mean of the first \u03bb for the random data was smaller than the real data counterpart, whereas the mean of the second \u03bb was larger than the second \u03bb for the real data. These findings suggest that a single factor should be extracted. All 15 items had good loadings on this factor (see Table 4), which explained 47.4% of the total item variance. Cronbach \u03b1 for the overall BCTI score, computed as the mean of all 15 items, was .92.",
            "cite_spans": [],
            "section": "Exploratory factor analysis ::: Belief in Conspiracy Theories Inventory ::: Results",
            "ref_spans": [
                {
                    "start": 919,
                    "end": 926,
                    "mention": "Table 4",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "CFA was conducted on all 15 items of the BCTI, where all items loaded onto a single latent variable, indicated by the initial EFA of the split-half subsample. Fit indices values were found to be: \u03c7\u00b2(90, N = 401) = 585.008, \u03c7\u00b2normed = 6.500, CFI = .824, RMSEA = .117 with 90% CI = .108-.126, SRMR = .063. Since the fit indices values of analysis were not found to be at acceptable intervals, suggested modification indices were taken into account to improve the model. Modification indices were consulted to free error covariances between items #7 and #10. The standardised estimates of factor loadings for this modified model were acceptable (see Fig 1 for the path diagram and standardised estimates). This one-dimensional structure provided an acceptable fit to the data: \u03c7\u00b2(89, N = 401) = 278.638, \u03c7\u00b2normed = 3.131, CFI = .933, RMSEA = .073 with 90% CI = .063-.083, SRMR = .047. We were, therefore, able to compute an overall score as the mean of all 15 items. Cronbach \u03b1 for the overall score was. .91.",
            "cite_spans": [],
            "section": "Confirmatory factor analysis ::: Belief in Conspiracy Theories Inventory ::: Results",
            "ref_spans": [
                {
                    "start": 647,
                    "end": 652,
                    "mention": "Fig 1",
                    "ref_id": "FIGREF0"
                }
            ]
        },
        {
            "text": "Tests of normality of distribution showed that the CMQ items were lower than limits. The size of KMO measure of sampling adequacy, KMO = .96, suggested that the BCTI items had adequate common variance for factor analysis, and Bartlett\u2019s test of sphericity, \u03c72(10) = 956.54, p < .001, indicated that the correlation matrix was factorable. The results of the EFA revealed a single factor with \u03bb = 3.15, which explained 63.0% of the variance. All 5 items had excellent loadings on this factor (see Table 5). Cronbach \u03b1 for the overall CMQ score, computed as the mean of all 5 items, was .85.",
            "cite_spans": [],
            "section": "Exploratory factor analysis ::: Conspiracy Mentality Questionnaire ::: Results",
            "ref_spans": [
                {
                    "start": 495,
                    "end": 502,
                    "mention": "Table 5",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "CFA was conducted on the 5 items of the CMQ, where all items loaded onto a single latent variable. Fit indices values were found to be: \u03c7\u00b2(5, N = 401) = 194.646, \u03c7\u00b2normed = 38.929, CFI = .812, RMSEA = .308 with 90% CI = .272-.346, SRMR = .081. Modification indices were consulted to free error covariances (items #1 and #2, and items #2 and #3). The standardised estimates of factor loadings for this model were acceptable (see Fig 2 for the path diagram and standardised estimates). This one-dimensional structure provided poor fit to the data: \u03c7\u00b2(3, N = 401) = 22.859, \u03c7\u00b2normed = 7.620, CFI = .980, RMSEA = .129 with 90% CI = .083-.180, SRMR = .028. These results suggest that one-dimensional factor structure of the CMQ in this split-half subsample was problematic and did not achieve adequate fit indices. For this reason, we did not compute a total score for this split-half subsample.",
            "cite_spans": [],
            "section": "Confirmatory factor analysis ::: Conspiracy Mentality Questionnaire ::: Results",
            "ref_spans": [
                {
                    "start": 428,
                    "end": 433,
                    "mention": "Fig 2",
                    "ref_id": "FIGREF1"
                }
            ]
        },
        {
            "text": "The GCBS items were examined for normality of distribution and were found to be lower than limits. The size of the KMO (.94) and Bartlett\u2019s test of sphericity, \u03c72(105) = 4292.37, p < .001, showed that the 15 GCBS items had adequate common variance for EFA. The results of the EFA revealed only two factors with \u03bb > 1.0 (5.50 and 4.19) and the scree-plot showed a steep cut-off between the primary and secondary factors. However, the results of parallel analysis indicated that both factors should be extracted: the mean of the first and second \u03bb for the random data were smaller than the real data counterparts. Eleven items loaded onto the first factor and 10 items loaded onto the second factor, but of these 5 items cross-loaded onto both factors (see Table 6). Tabachnick and Fidell [29] recommended that all cross-loading items should be eliminated, leaving 6 items for the first factor (Cronbach \u03b1 = .89) and 4 for the second (Cronbach \u03b1 = .85). Because of the diversity of items that loaded onto the first factor, we termed this factor General Conspiracist Beliefs. Three of the four items that loaded on the second factor related to extraterrestrial beliefs, so we termed this factor Extraterrestrial Conspiracist Beliefs.",
            "cite_spans": [
                {
                    "start": 788,
                    "end": 790,
                    "mention": "29",
                    "ref_id": "BIBREF28"
                }
            ],
            "section": "Exploratory factor analysis ::: Generic Conspiracist Beliefs Scale ::: Results",
            "ref_spans": [
                {
                    "start": 755,
                    "end": 762,
                    "mention": "Table 6",
                    "ref_id": "TABREF5"
                }
            ]
        },
        {
            "text": "Using CFA, we tested three separate models for the GCBS: a one-factor model where all 15 items loaded onto a single latent variable, a five-factor model where the 15 items loaded onto the five factors as per the parent study [22], and a 10-item, two-factor model as indicated by the initial EFA of the split-half subsample. Fit indices for the one-factor model were found to be poor: \u03c7\u00b2(90, N = 401) = 1122.934, \u03c7\u00b2normed = 12.477, CFI = .751, RMSEA = .169 with 90% CI = .161-.178, SRMR = .089. Modification indices were consulted to free error covariances (items #5 and #6, #8 and #9, and #14 and #15). However, the fit of this one-dimensional structure remained poor: \u03c7\u00b2(87, N = 401) = 652.389, \u03c7\u00b2normed = 7.499, CFI = .864, RMSEA = .127 with 90% CI = .118-.137, SRMR = .074 (see Fig 3 for standardised estimates of factor loadings). Based on these results, we concluded that there is little support for a one-dimensional structure of the GBCS.",
            "cite_spans": [
                {
                    "start": 226,
                    "end": 228,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Confirmatory factor analysis ::: Generic Conspiracist Beliefs Scale ::: Results",
            "ref_spans": [
                {
                    "start": 781,
                    "end": 786,
                    "mention": "Fig 3",
                    "ref_id": "FIGREF2"
                }
            ]
        },
        {
            "text": "Next, we examined the fit of the 15-item, five-factor model proposed by Brotherton et al. (2013). The fit indices for this structure were also found to be poor: \u03c7\u00b2(80, N = 401) = 1038.819, \u03c7\u00b2normed = 12.985, CFI = .769, RMSEA = .173 with 90% CI = .164-.183, SRMR = .090. Modification indices were not consulted to adjust the model as all modifications would lead to indicators being loaded onto another latent variable or have little theoretical sense. Fig 4 depicts the factor structure and standardised estimates of factor loadings for the five-factor model. Based on these results, we concluded that the five-factor model should be discarded.",
            "cite_spans": [],
            "section": "Confirmatory factor analysis ::: Generic Conspiracist Beliefs Scale ::: Results",
            "ref_spans": [
                {
                    "start": 453,
                    "end": 458,
                    "mention": "Fig 4",
                    "ref_id": "FIGREF3"
                }
            ]
        },
        {
            "text": "Finally, the 10 items that were retained in a two-factor structure from the first split-half subsample was analysed. This model was also found to have poor fit: \u03c7\u00b2(34, N = 401) = 261.125, \u03c7\u00b2normed = 7.680, CFI = .902, RMSEA = .129 with 90% CI = .115-.144, SRMR = .080. Modification indices were consulted to free error covariances between items under the same factor between items #14 and #15. The standardised estimates of factor loadings for this model were acceptable (see Fig 5 for the path diagram and standardised estimates). The resulting two-factor structure was more acceptable in terms of fit, though still problematic on a number of indices: \u03c7\u00b2(33, N = 401) = 191.556, \u03c7\u00b2normed = 5.805, CFI = .931, RMSEA = .110 with 90% CI = .095-.125, SRMR = .076. These results suggest that, even following modifications, the two-factor model of the GCBS continued to have poor fit and so was omitted from further analyses.",
            "cite_spans": [],
            "section": "Confirmatory factor analysis ::: Generic Conspiracist Beliefs Scale ::: Results",
            "ref_spans": [
                {
                    "start": 476,
                    "end": 481,
                    "mention": "Fig 5",
                    "ref_id": "FIGREF4"
                }
            ]
        },
        {
            "text": "Descriptive statistics for all variables are reported in Table 7. We computed inter-scale, bivariate correlations between all variables for the EFA and CFA split-halves separately. As can be seen in Table 7, there were significant inter-correlations between all variables for the EFA split-half, but evidence of convergent validity was strongest for the BCTI and weakest for the CMQ and one-item conspiracy measure. There were also significant inter-correlations between all variables for the CFA-split half. However, evidence of convergent validity was strongest for the BCTI and weakest for the one-item conspiracy measure.",
            "cite_spans": [],
            "section": "Convergent validity ::: Results",
            "ref_spans": [
                {
                    "start": 57,
                    "end": 64,
                    "mention": "Table 7",
                    "ref_id": null
                },
                {
                    "start": 199,
                    "end": 206,
                    "mention": "Table 7",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "Of the four measures we included in the present work, the BCTI showed the strongest evidence of factorial validity. Using EFA, we found support for the idea that the scale reduces to a single dimension, onto which all items load adequately. In addition, using CFA, we found that the one-dimensional model of the BCTI had acceptable fit and, in both sub-samples, overall scores had acceptable internal consistency. This is perhaps not surprising when we consider that belief in conspiracy theories is thought to be monological; that is, endorsement of one conspiracy theory makes acceptance of other conspiracy theories more likely [6, 8, 26]. In addition, of the four scales, the BCTI showed the strongest correlations with measures used to establish convergent validity. Of course, the main limitation of the BCTI is a conceptual one: it is uncertain to what extent the measure truly taps conspiracist ideation, as opposed to endorsement of a range of conspiracy theories (in the present study, correlations with generic measures of conspiracist ideation were generally strong). It is also unclear to what extent the BCTI will remain temporally stable in the long-term, as individual items may become obsolete, or to what extent individual items will be cross-culturally relevant.",
            "cite_spans": [
                {
                    "start": 632,
                    "end": 633,
                    "mention": "6",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 635,
                    "end": 636,
                    "mention": "8",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 638,
                    "end": 640,
                    "mention": "26",
                    "ref_id": "BIBREF25"
                }
            ],
            "section": "Belief in Conspiracy Theories Inventory ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "In our EFA, we found that the 5 items of the CMQ reduced to a single dimension with acceptable internal consistency. However, using CFA, we found that the one-dimensional model had poor fit, even following modifications. Moreover, in the EFA sub-sample, evidence of convergent validity was moderate at best. We believe the poor factorial and convergent validity of the CMQ may reflect underlying problems with the construct validity of this measure. Specifically, we suggest that some items of the CMQ may not tap conspiracist ideation, but may reflect rational beliefs about the current state of the world. For example, given current knowledge, item #3 (\u201cI think that government agencies closely monitor all citizens\u201d) could be construed as factual and requires no conspiracist mentality. The high mean scores for this measure (well above the scale mid-point) suggest that participants in this study were indeed rating some items of the CMQ as factually correct. In short, we suggest that there may be underlying problems with the construct validity of the CMQ, which affects its latent dimensionality.",
            "cite_spans": [],
            "section": "Conspiracy Mentality Questionnaire ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "In the parent study [22], the GCBS developers suggested that this scale consists of five factors and that the five-factor model had better fit than overall scores. In the present work, we failed to find support for either of these models using both EFA and CFA. Instead, our EFA suggested a truncated, two-factor model should be extracted. However, our CFA suggested that none of the models of the GCBS had adequate fit even following modifications, suggestive of inherent problems with the dimensionality of this measure. It is possible that part of the problem with this measure is confusion about its latent structure and whether it taps a single or multiple dimensions of conspiracist ideation (see below). At best, the GCBS may tap different dimensions of conspiracist ideation (e.g., general conspiracist ideation versus conspiracist beliefs about extraterrestrial life); at worst, it may tap multiple dimensions that do not cohere very well. Overall, the present findings raise concerns about the use of this measure.",
            "cite_spans": [
                {
                    "start": 21,
                    "end": 23,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                }
            ],
            "section": "Generic Conspiracist Beliefs Scale ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "We were unable to assess the factorial validity of the measure developed by Lantian et al. [18], given its single-item nature. However, our assessment of its convergent validity returned less than ideal results. This was to be expected given the inherently low reliability of any one-item measure, regardless of its content and purpose. Of the four measures included here, correlations between the one-item conspiracy measure and indices of convergent validity were the weakest.",
            "cite_spans": [
                {
                    "start": 92,
                    "end": 94,
                    "mention": "18",
                    "ref_id": "BIBREF17"
                }
            ],
            "section": "One-Item Conspiracy Measure ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "One general conclusion that might be drawn on the basis of the present dataset is that, while endorsement of a range of conspiracy theories is indeed monological, there are problems with the measurement of conspiracist ideation in scales currently in use. It is possible that the CMQ and GCBS are modelling a substantial amount of noise (e.g., measurement error, sampling fluctuations) and that latent factor structures depend on arbitrary properties in the data. As a result, the uncovered factor structures associated with these scales may differ between studies (as in the case between our dataset and earlier studies) or within studies (as in the differences between our EFA and CFA subsamples). The most straightforward solution here is that, where scholars use the CMQ or GCBS, they should examine the factor structures of these scales in their dataset rather than assuming these measures are one-dimensional.",
            "cite_spans": [],
            "section": "Looking to the future ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "Beyond this general point, we do not recommend the use of the CMQ and the one-item conspiracy measure in future studies. The CMQ appears to have poor factorial validity (and likely poor construct validity), whereas the one-item conspiracy measure appears to have weak convergent validity. Scholars who wish to measure generic conspiracist ideation may find it better to use the GCBS, but they should pay careful attention to (and report) its factor structure within studies. Our findings suggest the possibility that conspiracist ideation may be multi-dimensional and, as a result, scholars should not assume that the GBCS\u2014or other measures of conspiracist ideation\u2014are necessarily one-dimensional. More broadly, we suggest that there may utility in returning to a more careful consideration of theory, especially the conceptualisation of conspiracist ideation as a latent trait.",
            "cite_spans": [],
            "section": "Looking to the future ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "One way to resolve these issues would be to return to the 75 items developed by Brotherton et al. [22], and submit these items to exploratory factor analysis using a suitably large sample (i.e., a sample of no less than 750 individuals [9]. Doing so may highlight alternative factor structures that could then be re-assessed using CFA. Another way forward would be to subject all the items from conceptually similar scales (e.g., the CMQ and GCBS) to a single factor analysis, to examine the extent of conceptual overlap and possible item redundancy. In addition, future studies may also wish to revisit the factorial validity of the Conspiracy Theory Belief Scale, which we omitted in the present work. More broadly, we strongly recommend that all scholars working on conspiracist ideation pay closer attention to issues of measurement. Our data suggest that insufficient attention has been given to factorial and convergent validity, and that this may have introduced a degree of measurement bias into previously-reported findings. Indeed, it was concerning that even one of our measures of convergent validity [13] had not been submitted to factor analysis and that we found a divergent structure to what the authors of the parent study had assumed. Looking ahead, we highlight the need for improved assessments of the psychometric properties of scales used to measure conspiracist ideation. At a minimum, we recommend the reporting of factor analytic findings for all measures, particularly novel scales.",
            "cite_spans": [
                {
                    "start": 99,
                    "end": 101,
                    "mention": "22",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 237,
                    "end": 238,
                    "mention": "9",
                    "ref_id": "BIBREF8"
                },
                {
                    "start": 1114,
                    "end": 1116,
                    "mention": "13",
                    "ref_id": "BIBREF12"
                }
            ],
            "section": "Looking to the future ::: Discussion",
            "ref_spans": []
        },
        {
            "text": "One might argue that our findings are less reliable, for whatever reason, compared to the parents studies reported in Tables 1\u20133. Even were this the case, however, our findings highlight discrepancies in factorial validity that cannot, and should not, be overlooked. Indeed, our study benefits from a relatively large, culturally homogeneous sample and a two-step assessment of factorial validity. Nevertheless, there were limitations to the present study, too. First, our use of an online sample means that we cannot be certain about the generalisability of our findings. In particular, the present results may be geographically and culturally limited. In addition, we did not assess the temporal stability of the four measures, and this could be usefully (re)examined in future studies. Including alternative, and a broader range of, measures of convergent validity would also be a welcome addition in future studies.",
            "cite_spans": [],
            "section": "Limitations and conclusion ::: Discussion",
            "ref_spans": [
                {
                    "start": 125,
                    "end": 126,
                    "mention": "1",
                    "ref_id": null
                },
                {
                    "start": 127,
                    "end": 128,
                    "mention": "3",
                    "ref_id": null
                }
            ]
        },
        {
            "text": "In addition, because our sample was self-selecting, the possibility of sampling biases should be considered (e.g., those who were most interested in the topic may have been more likely to participate and complete the survey without dropping-out). Likewise, the inclusion of idiosyncratic instructions typically included with each measure may have also led to biased results, and this is something that future studies should consider. These limitations notwithstanding, the present findings suggest that scholars working on conspiracist ideation need to pay more detailed attention to measurement issues in their studies. If the findings from this field of research are to be taken seriously, measurement issues need to be thoughtfully considered and dealt with by scholars. For now, we suggest that scholars wishing to measure conspiracist ideation may need to return to the drawing board.",
            "cite_spans": [],
            "section": "Limitations and conclusion ::: Discussion",
            "ref_spans": []
        }
    ],
    "ref_entries": {
        "TABREF5": {
            "text": "Table 6: Values in bold indicate items that loaded onto a factor.\n",
            "type": "table"
        },
        "FIGREF0": {
            "text": "Fig 1: Item numbers in the figure reflect the item number in Table 4. The large circle is the latent construct, with the rectangles representing measured variables, and the small circles with numbers are the residual variables (variances). The factor loadings are standardised in parenthesises, and the unstandarised values outside, with both being reported following the guidelines of Kline [42]. Significance levels were determined by critical ratios (all p < .001). The factor loadings were fixed at the indicated value (1.00a).",
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Fig 2: Item numbers in the figure reflect the item number in Table 5. The large circle is the latent construct, with the rectangles representing measured variables, and the small circles with numbers are the residual variables (variances). The factor loadings are standardised in parenthesises, and the unstandarised values outside, with both being reported following the guidelines of Kline [42]. Significance levels were determined by critical ratios (all p < .001). The factor loadings were fixed at the indicated value (1.00a).",
            "type": "figure"
        },
        "FIGREF2": {
            "text": "Fig 3: Item numbers in the figure reflect the item number in Table 6. Item numbers in the figure reflect the item number in Table 6. The large circle is the latent construct, with the rectangles representing measured variables, and the small circles with numbers are the residual variables (variances). The factor loadings are standardised in parenthesises, and the unstandarised values outside, with both being reported following the guidelines of Kline (2011). Significance levels were determined by critical ratios (all p < .001). The factor loadings were fixed at the indicated value (1.00a).",
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Fig 4: Item numbers in the figure reflect the item number in Table 6. The large circles are the latent construct, with the rectangles representing measured variables, and the small circles with numbers are the residual variables (variances). The factor loadings are standardised in parenthesises, and the unstandarised values outside, with both being reported following the guidelines of Kline [42]. Significance levels were determined by critical ratios (all p < .001). Estimates of covariance between exogenous variables are displayed in italics. The factor loadings were fixed at the indicated value (1.00a).",
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Fig 5: Item numbers in the figure reflect the item number in Table 6. The large circles are the latent construct, with the rectangles representing measured variables, and the small circles with numbers are the residual variables (variances). The factor loadings are standardised in parenthesises, and the unstandarised values outside, with both being reported following the guidelines of Kline [42]. Significance levels were determined by critical ratios (all p < .001). Estimates of covariance between exogenous variables are displayed in italics. The factor loadings were fixed at the indicated value (1.00a).",
            "type": "figure"
        }
    },
    "back_matter": [],
    "bib_entries": {
        "BIBREF0": {
            "title": "",
            "authors": [],
            "year": 2014,
            "venue": "Power, politics, and paranoia: Why people are suspicious of their leaders",
            "volume": "",
            "issn": "",
            "pages": "218-236",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF1": {
            "title": "",
            "authors": [],
            "year": 2014,
            "venue": "Standards for educational and psychological testing",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF2": {
            "title": "Beliefs in conspiracies",
            "authors": [],
            "year": 1999,
            "venue": "Political Psychol",
            "volume": "20",
            "issn": "",
            "pages": "637-647",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF3": {
            "title": "Does it take one to know one? Endorsement of conspiracy theories is influenced by personal willingness to conspire",
            "authors": [],
            "year": 2011,
            "venue": "Br J Soc Psychol",
            "volume": "50",
            "issn": "",
            "pages": "544-552",
            "other_ids": {
                "DOI": [
                    "10.1111/j.2044-8309.2010.02018.x"
                ]
            }
        },
        "BIBREF4": {
            "title": "Political extremism predicts belief in conspiracy theories",
            "authors": [],
            "year": 2015,
            "venue": "Soc Psychol Pers Sci",
            "volume": "6",
            "issn": "",
            "pages": "570-578",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF5": {
            "title": "Unanswered questions: A preliminary investigation of personality and individual difference predictors of 9/11 conspiracist beliefs",
            "authors": [],
            "year": 2011,
            "venue": "App Cog Psychol",
            "volume": "24",
            "issn": "",
            "pages": "749-761",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF6": {
            "title": "The influence of control on belief in conspiracy theories: Conceptual and applied extensions",
            "authors": [],
            "year": 2015,
            "venue": "App Cog Psychol",
            "volume": "29",
            "issn": "",
            "pages": "753-761",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF7": {
            "title": "Dead and alive: Beliefs in contradictory conspiracy theories",
            "authors": [],
            "year": 2012,
            "venue": "Soc Psychol Pers Sci",
            "volume": "3",
            "issn": "",
            "pages": "767-773",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF8": {
            "title": "",
            "authors": [],
            "year": 1978,
            "venue": "Psychometric theory",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF9": {
            "title": "On the use, the misuse, and the very limited usefulness of Cronbach\u2019s alpha",
            "authors": [],
            "year": 2009,
            "venue": "Psychometrika",
            "volume": "74",
            "issn": "",
            "pages": "107-120",
            "other_ids": {
                "DOI": [
                    "10.1007/s11336-008-9101-0"
                ]
            }
        },
        "BIBREF10": {
            "title": "Belief in conspiracy theories and susceptibility to the conjunction fallacy",
            "authors": [],
            "year": 2014,
            "venue": "App Cog Psychol",
            "volume": "28",
            "issn": "",
            "pages": "238-248",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF11": {
            "title": "Someone is pulling the strings: Hypersensitive agency detection and belief in conspiracy theories",
            "authors": [],
            "year": 2016,
            "venue": "Thinking Reasoning",
            "volume": "22",
            "issn": "",
            "pages": "57-77",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF12": {
            "title": "The effects of anti-vaccine conspiracy theories on vaccination intentions",
            "authors": [],
            "year": 2014,
            "venue": "PLoS One",
            "volume": "9",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1371/journal.pone.0089177"
                ]
            }
        },
        "BIBREF13": {
            "title": "Examining conspiracist beliefs about the disappearance of Amelia Earhart",
            "authors": [],
            "year": 2012,
            "venue": "J Gen Psychol",
            "volume": "139",
            "issn": "",
            "pages": "244-259",
            "other_ids": {
                "DOI": [
                    "10.1080/00221309.2012.697932"
                ]
            }
        },
        "BIBREF14": {
            "title": "Conspiracist ideation in Britain and Austria: Evidence of a monological belief system and associations between individual psychological differences and real-world and fictitious conspiracy theories",
            "authors": [],
            "year": 2011,
            "venue": "Br J Psychol",
            "volume": "102",
            "issn": "",
            "pages": "443-463",
            "other_ids": {
                "DOI": [
                    "10.1111/j.2044-8295.2010.02004.x"
                ]
            }
        },
        "BIBREF15": {
            "title": "Associations between belief in conspiracy theories and the maladaptive personality traits of the Personality Inventory for DSM-5",
            "authors": [],
            "year": 2016,
            "venue": "Psych Res",
            "volume": "236",
            "issn": "",
            "pages": "86-90",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF16": {
            "title": "Social psychological origins of conspiracy theories: The case of the Jewish conspiracy theory in Malaysia",
            "authors": [],
            "year": 2012,
            "venue": "Front Psychol",
            "volume": "3",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.3389/fpsyg.2012.00280"
                ]
            }
        },
        "BIBREF17": {
            "title": "Measuring belief in conspiracy theories: Validation of a French and English single-item scale",
            "authors": [],
            "year": 2016,
            "venue": "Int Rev Psychol",
            "volume": "29",
            "issn": "",
            "pages": "1-14",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF18": {
            "title": "Belief in conspiracy theories: The role of paranomal belief, paranormal ideation, and schizotypy",
            "authors": [],
            "year": 2011,
            "venue": "Pers Ind Diff",
            "volume": "50",
            "issn": "",
            "pages": "1289-1293",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF19": {
            "title": "Examining the relationship between conspiracy theories, paranormal beliefs, and pseudoscience acceptance among a university population",
            "authors": [],
            "year": 2014,
            "venue": "App Cog Psychol",
            "volume": "28",
            "issn": "",
            "pages": "617-625",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF20": {
            "title": "Measuring individual differences in generic beliefs in conspiracy theories across cultures: Conspiracy Mentality Questionnaire",
            "authors": [],
            "year": 2013,
            "venue": "Front Psychol",
            "volume": "4",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF21": {
            "title": "Measuring belief in conspiracy theories: the Generic Conspiracist Beliefs Scale",
            "authors": [],
            "year": 2013,
            "venue": "Front Psychol",
            "volume": "4",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.3389/fpsyg.2013.00279"
                ]
            }
        },
        "BIBREF22": {
            "title": "Speaking (un-)truth to power: Conspiracy mentality as a generalised political attitude",
            "authors": [],
            "year": 2013,
            "venue": "Euro J Pers",
            "volume": "28",
            "issn": "",
            "pages": "25-43",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF23": {
            "title": "Nothing happens by accident, or does it? A low prior for randomness does not explain belief in conspiracy theories",
            "authors": [],
            "year": 2015,
            "venue": "Psychol Sci",
            "volume": "26",
            "issn": "",
            "pages": "1762-1770",
            "other_ids": {
                "DOI": [
                    "10.1177/0956797615598740"
                ]
            }
        },
        "BIBREF24": {
            "title": "Reducing conspiracy theory beliefs",
            "authors": [],
            "year": 2015,
            "venue": "Psihologija",
            "volume": "48",
            "issn": "",
            "pages": "251-266",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF25": {
            "title": "Belief in conspiracy theories",
            "authors": [],
            "year": 1994,
            "venue": "Political Psychol",
            "volume": "15",
            "issn": "",
            "pages": "31-42",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF26": {
            "title": "Amazon\u2019s Mechanical Turk: A new source of inexpensive, yet high-quality, data?",
            "authors": [],
            "year": 2013,
            "venue": "Pers Psychol Sci",
            "volume": "6",
            "issn": "",
            "pages": "3-5",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF27": {
            "title": "Handling item-level missing data: Simpler is just as good",
            "authors": [],
            "year": 2013,
            "venue": "Counsel Psychol",
            "volume": "41",
            "issn": "",
            "pages": "568-600",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF28": {
            "title": "",
            "authors": [],
            "year": 2007,
            "venue": "Using multivariate statistics",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF29": {
            "title": "",
            "authors": [],
            "year": 2013,
            "venue": "Applied quantitative analysis in the social sciences",
            "volume": "",
            "issn": "",
            "pages": "171-207",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF30": {
            "title": "Constructing validity: Basic issues in objective scale development",
            "authors": [],
            "year": 1995,
            "venue": "Psychol Assess",
            "volume": "7",
            "issn": "",
            "pages": "309-319",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF31": {
            "title": "Evaluating the use of exploratory factor analysis in psychological research",
            "authors": [],
            "year": 1999,
            "venue": "Psychol Methods",
            "volume": "4",
            "issn": "",
            "pages": "272-299",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF32": {
            "title": "",
            "authors": [],
            "year": 1991,
            "venue": "Measurement, design, and analysis: An integrated approach",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF33": {
            "title": "Factor retention decisions in exploratory factor analysis: A tutorial on parallel analysis",
            "authors": [],
            "year": 2004,
            "venue": "Org Res Methods",
            "volume": "7",
            "issn": "",
            "pages": "191-205",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF34": {
            "title": "The use of exploratory factor analysis in public health: A note on parallel analysis as a factor retention criterion",
            "authors": [],
            "year": 2010,
            "venue": "Am J Health Promo",
            "volume": "24",
            "issn": "",
            "pages": "178-181",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF35": {
            "title": "Efficient theory development and factor retention criteria: A case for abandoning the \u2018eigenvalue greater than one\u2019 criterion",
            "authors": [],
            "year": 2008,
            "venue": "J Business Res",
            "volume": "",
            "issn": "",
            "pages": "61162-170",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF36": {
            "title": "",
            "authors": [],
            "year": 2014,
            "venue": "IBM\u00ae SPSS\u00ae AmosTM 23 user\u2019s guide",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF37": {
            "title": "Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives",
            "authors": [],
            "year": 1999,
            "venue": "Struct Equation Model",
            "volume": "6",
            "issn": "",
            "pages": "1-55",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF38": {
            "title": "Masking misfit in confirmatory factor analysis by increasing unique variances: A cautionary note on the usefulness of cutoff values of fit indices",
            "authors": [],
            "year": 2011,
            "venue": "Psychol Methods",
            "volume": "16",
            "issn": "",
            "pages": "319-336",
            "other_ids": {
                "DOI": [
                    "10.1037/a0024917"
                ]
            }
        },
        "BIBREF39": {
            "title": "Construct validity of the multidimensional structure of bullying and victimization: An application of exploratory structural equation modelling",
            "authors": [],
            "year": 2011,
            "venue": "J. Educ Psychol",
            "volume": "103",
            "issn": "",
            "pages": "701-732",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF40": {
            "title": "",
            "authors": [],
            "year": 1992,
            "venue": "A first course in factor analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF41": {
            "title": "",
            "authors": [],
            "year": 2011,
            "venue": "Principles and practice of structural equation modelling",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF42": {
            "title": "Reporting structural equation modeling and confirmatory factor analysis results: A review",
            "authors": [],
            "year": 2006,
            "venue": "J Educ Res",
            "volume": "99",
            "issn": "",
            "pages": "323-337",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF43": {
            "title": "",
            "authors": [],
            "year": 2015,
            "venue": "Confirmatory factor analysis for applied research",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF44": {
            "title": "The sources of four commonly reported cutoff criteria: What did they really say?",
            "authors": [],
            "year": 2006,
            "venue": "Org Res Methods",
            "volume": "9",
            "issn": "",
            "pages": "202-220",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF45": {
            "title": "",
            "authors": [],
            "year": 2001,
            "venue": "Practical meta-analysis",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF46": {
            "title": "Belief in conspiracy theories and the need for cognitive closure",
            "authors": [],
            "year": 2013,
            "venue": "Front Psychol",
            "volume": "4378",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF47": {
            "title": "Analytic thinking reduces belief in conspiracy theories",
            "authors": [],
            "year": 2014,
            "venue": "Cognition",
            "volume": "133",
            "issn": "",
            "pages": "572-585",
            "other_ids": {
                "DOI": [
                    "10.1016/j.cognition.2014.08.006"
                ]
            }
        },
        "BIBREF48": {
            "title": "Putting the stress on conspiracy theories: Examining associations between psychological stress, anxiety, and belief in conspiracy theories",
            "authors": [],
            "year": 2016,
            "venue": "Pers Ind Diff",
            "volume": "99",
            "issn": "",
            "pages": "72-76",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF49": {
            "title": "Associations between schizotypy and belief in conspiracist ideation",
            "authors": [],
            "year": 2014,
            "venue": "Pers Ind Diff",
            "volume": "82",
            "issn": "",
            "pages": "136-141",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF50": {
            "title": "Girl in the cellar: A repeated cross-sectional investigation of belief in conspiracy theories about the kidnapping of Natascha Kampusch",
            "authors": [],
            "year": 2013,
            "venue": "Front Psychol",
            "volume": "4",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.3389/fpsyg.2013.00297"
                ]
            }
        },
        "BIBREF51": {
            "title": "Lunar lies: The impact of informational framing and individual differences in shaping conspiracist beliefs about the moon landings",
            "authors": [],
            "year": 2013,
            "venue": "App Cog Psychol",
            "volume": "27",
            "issn": "",
            "pages": "71-80",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF52": {
            "title": "Personality and individual difference correlates of attitudes toward human rights and civil liberties",
            "authors": [],
            "year": 2012,
            "venue": "Pers Ind Diff",
            "volume": "53",
            "issn": "",
            "pages": "443-447",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF53": {
            "title": "Better the devil you known than a world you don\u2019t? Intolerance of uncertainty and worldview explanations for belief in conspiracy theories",
            "authors": [],
            "year": 2016,
            "venue": "Pers Ind Diff",
            "volume": "98",
            "issn": "",
            "pages": "345-354",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF54": {
            "title": "Conspiracy theory and cognitive style: A worldview",
            "authors": [],
            "year": 2015,
            "venue": "Front Psychol",
            "volume": "6",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.3389/fpsyg.2015.00206"
                ]
            }
        },
        "BIBREF55": {
            "title": "Intention seekers: Conspiracist ideation and biased attributions of intentionality",
            "authors": [],
            "year": 2015,
            "venue": "PLoS One",
            "volume": "10",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": [
                    "10.1371/journal.pone.0124125"
                ]
            }
        },
        "BIBREF56": {
            "title": "Bored to fears: Boredom proneness, paranoia, and conspiracy theories",
            "authors": [],
            "year": 2015,
            "venue": "Pers Ind Diff",
            "volume": "80",
            "issn": "",
            "pages": "1-5",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF57": {
            "title": "Relationships between conspiracy mentality, hyperactive agency detection, and schizotypy: Supernatural forces at work?",
            "authors": [],
            "year": 2015,
            "venue": "Pers Ind Diff",
            "volume": "82",
            "issn": "",
            "pages": "136-141",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF58": {
            "title": "Some dare call it conspiracy: Labeling something a conspiracy theory does not reduce belief in it",
            "authors": [],
            "year": null,
            "venue": "Political Psychol",
            "volume": "",
            "issn": "",
            "pages": null,
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF59": {
            "title": "Does self-love or self-hate predict conspiracy beliefs? Narcissism, self-esteem, and the endorsement of conspiracy theories",
            "authors": [],
            "year": 2016,
            "venue": "Soc Psychol Pers Sci",
            "volume": "7",
            "issn": "",
            "pages": "157-166",
            "other_ids": {
                "DOI": []
            }
        },
        "BIBREF60": {
            "title": "On the detection and reception of pseudo-profound bullshit",
            "authors": [],
            "year": 2015,
            "venue": "Judgement Decision Making",
            "volume": "10",
            "issn": "",
            "pages": "549-563",
            "other_ids": {
                "DOI": []
            }
        }
    }
}