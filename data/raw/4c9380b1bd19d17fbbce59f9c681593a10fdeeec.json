{"title": "Pathogen Surveillance Through Monitoring of Sewer Systems", "body": "It is now possible to monitor sewage systems for pathogen occurrence in a community. An epidemiological approach to monitoring sewer systems is especially relevant for an early warning of pathogens used as biological weapons. In many situations, bioterrorist contamination events will result in the pathogen shedding to wastewater before a community level epidemic begins. Detecting the organism early allows the governments to respond on time and eliminate a potential catastrophe.\n\nMonitoring of human pathogens in sewage is possible because they may be excreted in a range of bodily fluids, skin, and hair during active infection (Feachem et al., 1983) . All of these materials will find their way into sewage systems during the process of waste elimination (toilet flushing) and cleaning (e.g., bathing, hand washing). In addition to release during active infection, pathogens can be washed into sewage systems from cleaning of indoor (floor washing, kitchen sink use) and outdoor (auto washing, driveway cleaning, storm water collection) facilities. Thus, sewer systems collect pathogens from over a wide area to a common carrier, where they are transported to a central facility for processing.\n\nWastewater presents a time dynamic collection point where many physical, chemical, and biological substances of our society are brought to a central location. Monitoring of centralized wastewater allows detection of intentional, natural, or accidental contamination events. Because of recent bioterrorism concerns in the U.S., routine monitoring is potentially useful since it can result in better preparedness of utilities and the public health response system (Meinhardt, 2005) . The qualitative microbial risk assessment (QMRA) framework can be used as a tool to develop and interpret this type of wastewater monitoring system. Because the threat level drives the risk assessment analysis, a monitoring system should be coordinated with findings from modeling studies on the survival and dispersion of contaminants (Kim et al., 2007; Romero et al., 2008; Sinclair et al., 2008) , the contaminant point of introduction (Danneels and Finley, 2004) , the health risk (Haas et al., 1999) , and the locations of early warning systems/ sensors in wastewater and water treatment systems (Murray et al., 2004) .\n\nA recent U.S. National Research Council study called for more resilient design/operation of wastewater and drinking water systems (USNRC, 2007) to improve response and recovery from adverse water quality events in collection systems, water distribution systems, and water/ wastewater treatment systems. Monitoring programs for pathogens or surrogates could potentially aid in the accomplishment of these goals.\n\nThe aim of this review of published literature and reports is to assess the feasibility of monitoring sewage systems as an early warning system for the release of pathogens from an intentional, natural, or accidental biological contamination event. We address issues from a QMRA perspective and explore methods to detect and monitor pathogens in wastewater. The review presents our conclusions on: (1) the potential biological agents that might be released into a sewage system, (2) the likely background level of those agents in sewage, (3) laboratory methods and detection, and (4) the probability of detecting select biological agents in sewage.\n\nA wide variety of pathogenic organisms pass through municipal wastewater treatment systems. One study found that a single toilet flush containing poliovirus was detectable at a nearby treatment plant for more than 4 days (Ranta et al., 2001) . The toilet flush study was designed to replicate the number of virus released from an infected individual. Pathogenic microorganisms can also grow in the host but not produce sickness in the infected host. It is estimated that 50% or less of those individuals infected with enteric viruses or bacteria actually become ill (Haas et al., 1999) . In the case of some respiratory pathogens, 90% or more of the persons infected will become ill (Belshe, 1991) .\n\nDuring the growth of the organism in the host, the organism will be found in various organs and bodily fluids. Organisms transmitted by the fecal-oral route are usually excreted in large numbers in the feces, since the initial or primary site of replication is in the intestinal tract. However, this does not preclude their replication in other parts of the body. For example, enteroviruses (e.g., poliovirus) will replicate in nerve tissue causing paralytic disease, while Hepatitis A virus will replicate in the liver causing damage there (Belshe, 1991) . Respiratory infections are usually the result of replication of the organism in the nose, throat, or lungs. Infection of other organs of the body often leads to the presence of the organisms in the blood and then the urine after their elimination by the kidneys. This explains the occurrence of insect-borne encephalitis viruses and enteric viruses in the urine (Pichichero et al., 1998) . Any type of infection ( Fig. 9 .1) within a community is likely to lead to pathogen excretion in bodily fluids/substances and therefore, transported into the community sewage system. This review considers biological agents prioritized by the Centers for Disease Control (CDC) as potential biological weapons that could be used by terrorists (Table 9 .1 and 9.2). They are listed in three categories (i.e., A, B, and C) of decreasing concern. Category A agents require the most intensive public preparedness efforts due to the potential for mass causalities, public fear, and civil disruption. Category B agents are also moderately easy to spread, but have lower mortality rates. Category C agents do not present a high public health threat, but could emerge as future threats (Rotz et al., 2002) . Many other pathogenic agents are present in sewage, but not on the CDC select agent list. Table 9 .2 lists some common blood and respiratory agents and emerging pathogens, all of which could potentially be engineered for mass dissemination and detected through monitoring of wastewater. The methods described in this paper apply to many other pathogens and are not limited to those agents listed in Tables 9.1 and 9.2.\n\nA literature search was conducted to determine the occurrence of the agents in bodily fluids, feces, skin, and sewage. As indicated in Table 9 .3 and a previous publication (Sinclair et al., 2008) , many select agents may occur in bodily excretions or secretions even though this may not be their primary site of replication. It would appear that all of the viral agents are excreted in the urine and most of the bacterial agents in the feces or saliva. Since none of the organisms cause enteric infections they have seldom been sought in sewage, however, Bacillus anthracis and Yersina pestis (plague) have been detected in sewage. The source of B. anthracis spores in the sewage was believed to be from an African import tannery operation (Perone and Gelosa, 1982) and presumably not from enteric infections, which would normally result in the presence of spores in the feces. Category B agents differ in that, and they include many enteric pathogens which are excreted in large numbers in the feces (Table 9 .3). All of the other agents in this category appear to be excreted in the feces; many of the viral agents are excreted in the urine. No studies were found that report examining sewage for their presence. The Category C viral agents appear to be excreted in the saliva and urine (Tables 9.3 and 9.4). No references for the presence of these agents in sewage could be found. Some typical blood-borne agents such as Hepatitis B virus (Alter et al., 1977) and Human Immuno-Deficiency virus (Levy, 1989) have been detected in sewage by molecular methods (Table 9 .4). The coronavirus, which causes Severe Acute Respiratory Disease (SARS), is Pathogen Surveillance Through Monitoring of Sewer Systems also excreted in the feces and other bodily fluids such as tears (Loon et al., 2004; Wang et al., 2005) (Table 9 .4).\n\nThe duration and concentration of pathogens released by a host during the course of an infection varies, with greater numbers being released in more severe infections. After infection, the number of organisms released usually rises rapidly reaching a peak when the symptoms appear in symptomatic infections. This is usually followed with a long decline in the amount of agent released by the host as long as death does not occur. For example, poliovirus appears in the throat and feces 7-10 days before clinical illness (fever) is apparent and may be excreted for more than 30 days after infection ( Fig. 9 .2). Poliovirus will also be detectable in the blood and urine during the course of infection (Pichichero et al., 1998) .\n\nHepatitis A virus appears in the stool of infected individuals 2-3 weeks before clinical illness (Belshe, 1991) . Parainfluenza, a virus related to influenza, can be detected in nasal secretions in less than 24 h after infection and up to 2 weeks afterward (Belshe, 1991) . In the case of SARS, the virus may still be present in the feces for 37 days after infection (Holmes, 2003) . Variola major, the virus that causes smallpox, is released for up to 19 days after infection at concentrations of 10 2 -10 5 per ml of urine (Table 9 .5) (Sarkar et al., 1973) . In many infections, the greatest concentrations are released during the first few days after the initial infection. Brucella abortus is excreted in concentrations as high as 10 6 per ml of urine for up to 12 weeks (Table 9 .6). Marburg virus and flaviviruses are excreted in the urine of animals for 10-12 days. In summary, all of the nonenteric agents of interest (Categories A, B, and C) are released in the host for at least days to weeks in concentrations likely to be detectable in sewage systems (Table 9 .6) (Sinclair et al., 2008) .\n\nMost of the existing data on the occurrence and concentration of pathogens was gathered using culture of viable or infective organisms. Molecular methods such as the polymerase chain reaction (PCR) or immuno-chemical methods (enzyme-linked immunoassays or ELISA) can detect both infectious and noninfectious organisms. These molecular techniques can detect concentrations from 1 to 10,000 greater than culture methods because some of the organisms may be inactivated (dead) or may not be able to grow on the selected media (bacteria) or cell culture (used for viruses). In the case of enteric viruses, the ratio of viruses detected by infectivity assay may be 100-50,000 times less than that detected by a molecular method (Ward et al., 1984) . This is because cell culture methods have a low efficiency in virus quantification from clinical and environmental samples; however, they do provide a robust measure of viral activity not feasible with molecular methods. Agents causing enteric and respiratory infections are released in large numbers in feces and respiratory secretions (Table 9 .4). Many of the Belshe (1991) enteric viruses such as the enteroviruses and adenoviruses may replicate both in the intestinal and respiratory tract. Using molecular methods the number of enteric viruses detected can approach peak concentrations of 10 12 organisms per gram of stool while protozoa can approach 10 6 -10 7 per gram. Cultivatable enteric bacterial pathogens such as Salmonella may also occur in concentrations as large as 10 11 per gram (Feachem et al., 1983) . By infectivity assays, the concentration of respiratory viruses ranges from 10 5 to 10 7 per ml of respiratory secretion. Even blood-borne viruses such as HIV will be found in the feces of infected persons (Ansari et al., 1992) and it appears that many viruses will occur in the urine during infection of the host (Table 9 .6), although these excreted viruses may not be infectious. Little information is available on the concentration of pathogenic viruses or bacterial agents of interest in the urine. The total amount of virus released by a person is, of course, also related to the amount of feces, urine, respiratory secretion, and skin that is released by the person. On average, a person excretes between 100 to 400 g of feces and 700-2000 ml of urine per day (Table 9 .7). (Sarkar et al., 1973) Days after infection Titer(mL) 3 1 0 3 -10 5 4 1 0 2 -10 5 5 1 0 2 -10 4 6 1 0 1 -10 4 7 1 0 1 -10 3 8 1 0 1 -10 2 10 10 1 -10 2 15 10 1 -10 2 19 10 1 20 0 Site of replication in the host GI, upper respiratory, nose, skin, internal organs Duration of release from the host Concentration in the source Incidence of disease in the population Water use per capita Season Survival in the sewer system A person with an enteric viral infection may excrete as many as 10 14 viral particles per day and over 10 15 during the course of an infection (Table 9 .8). Nonenteric bacterial agents of interest appeared to be released in concentrations from 10 0 to 10 8 by viability assays (Boone and Gerba 2007) . Respiratory pathogens end up in the feces from the swallowing of secretions.\n\nEcological studies of bovine tuberculosis in badgers introduce the concept of ''super-excretors,'' which maintain the disease and pass infectious organisms in their stool or urine continuously. Super-excretors are individuals who excrete larger numbers than average of a pathogen during an infection. These super-excretors were almost exclusively animals with a progressive infection, which does not resolve and contributed to a higher mortality (Delahay et al., 2000) . The occurrence of a similar ''super-spreader'' was also noted in a clinical epidemiological report of SARS in humans (Holmes, 2003) .\n\nThe occurrence and concentration of pathogens in sewage is dependent upon a number of factors listed in Table 9 .9. One of the most important considerations is the amount of pathogen released by a person daily from bodily fluid, feces, skin, and urine. Because one infected individual typically produces at least 100 g of feces per day, a pathogen present at 10 8 per gram will introduce at least 10 10 or more of the pathogen into the sewer system. Logically, pathogens excreted in urine and feces will be released several times during a 24-h period. Enteric and respiratory pathogens are almost always detected in sewage because of the long duration of release from the host during infection, the large concentrations released from the host, and the many infections that are asymptomatic.\n\nStudies have shown that the types and concentration of enteric microorganisms in sewage is directly related to the incidence of disease in the (Feachem et al., 1983) Feces (100-400 g/person/day) Urine (700-2000 ml/day) Skin-from bath and hand washing Saliva, respiratory secretions Blood Food Wash water (kitchen, drains) Storm water a a Some sewer systems are combined with the storm-water collection system. Pathogen Surveillance Through Monitoring of Sewer Systems community (Riordan 1962; Sellwood et al., 1981) . The concentration of enteric pathogens in sewage ranges from 0.1 to 100,000 per ml of sewage (Table 9 .8). While many biological agents of interest have been detected in sewage (Table 9. 3), the studies are limited and vary by location.\n\nCulture based methods can be used for the detection of pathogens in wastewater, but they may take days to weeks to perform. Alternative molecular methods, such as the PCR, have been successful in detecting bacterial, viral, and protozoan pathogens in sewage without the need for cultivation (Gilbride et al., 2006) . These new techniques detect live and dead organisms, have a high sensitivity for wastewater, and can reduce detection time to a few hours (He and Jiang, 2005; Holmes, 2003) . Some promising new wastewater methods use nucleic acid microarrays or antibody/receptor technologies to detect multiple pathogens simultaneously (Boehm et al., 2007) . Combining these multiplexed methods with fiberoptic sensors and lab-on-a-chip technology can allow utilities to rapidly screen, identify, and quantify multiple pathogens in real time.\n\nBecause these technologies rely on PCR DNA techniques, the many interfering substances in raw sewage pose a problem. Without proper sample extraction, the sample analytes are exposed to many varying inhibitors, which can negatively impact the DNA isolation and amplification steps. These methods are also limited by their inability to differentiate between viable and nonviable or nonculturable organisms ( Josephson et al., 1993) , a vital characteristic when assessing the microbial risk assessment for any given community.\n\nCertain methods are in development to automate the sample collection, sample processing, and concentration to separate analytes from inhibitors and deliver a suitable clean sample to a real-time detection microarray technology. These methods use latex beads, carbohydrates, Enteric viruses (infectivity assay) 10 8 10 10 10 2 Enteric viruses (PCR assay) 10 10 -10 12 10 12 -10 14 10 4 -10 5 Giardia 10 6 10 8 10-10 2 Cryptosporidium 10 6 10 8 0.1-10 2 a 100 g stool (150 g average in the U.S.). anion exchange resins, or similar substances as part of sample collection and sample processing step (Straub and Chandler, 2003) , but no fully automated method has been proposed for wastewater. A biosensor capable of identifying and quantifying a wide group of pathogens is necessary, but future development is needed in the areas of extraction from environmental samples, selection of a suitable target sequence of the pathogen (specificity), detection and differentiation of the signal from interfering sequences (sensitivity), and automation of all processes towards a functional real-time biosensor for wastewater (Gilbride et al., 2006) .\n\nA principal benefit of wastewater monitoring is that most pathogens of interest are expected to remain viable for at least several days in the sewerage environment (Table 9 .10). Enteric and respiratory agents are particularly stable, while data is limited for viral encephalitis agents because transmission in water and other liquid media does not occur naturally. Using molecular methods, survival of the pathogens in the viable form is not necessary for their detection, thus increasing the length of time for which the pathogen may be detected. In the case of select C. Lessons learned from poliovirus: Monitoring as an early warning system\n\nThe benefits of pathogen monitoring in sewage have been recognized for poliovirus for more than 40 years. The relationship between the occurrence of poliovirus in sewage and clinical incidence of disease in a community was first noted in the late 1960s (Nelson et al., 1967) . These early detection studies were designed as longitudinal epidemiological investigations to assess the success of polio vaccination campaigns (Riordan, 1962) . The results of these studies demonstrated that a definite correlation exists among the isolation of enteroviruses in sewage, and the isolation of viruses in stools, and the number of recognized clinical cases within the community. Using cell culture assay techniques (which measure only infective viruses) and only grab samples (i.e., no steps to concentrate the sample) poliovirus could be detected when only 0.27-0.4% of the population was excreting the virus. It was also demonstrated that small outbreaks and epidemics of enterovirus and adenovirus disease within a community can be predicted by monitoring a community's sewage. Virulent or wildtype (nonvaccine strain) poliovirus type 1 was detected in sewage 9 days before the first clinical case became evident (Kuwert et al., 1970) . In an outbreak of Coxsackievirus B5, the virus was detected in the sewage 10 days before clinical cases were positive (Nelson et al., 1967) . These studies make it clear that grab samples collected on a regular (weekly or every few days) basis could be used to assess the introduction of a new infectious agent in the community. This approach was later adapted to monitor the success of poliovirus vaccine campaigns internationally (WHO, 2003) .\n\nTo assess the sensitivity of poliovirus monitoring, one study (Ranta et al., 2001) flushed a one-time bolus of 1 l containing 2 \u00c2 10 10 infective poliovirus type 1 vaccine strain down a toilet 20 km (12 miles) from the sewage plant (Table 9 .11). Samples were automatically collected and assayed for the next 4 days. Infectious poliovirus was still detected after 800 million liters had passed through the system. The authors concluded that their monitoring system could detect one infected person in 10,000 residents of the community, assuming that 10 8 infective viruses are excreted by a child over a 4-day period of time. The study showed that pathogens appear to be greatly retarded in sewage systems, where a onetime event resulted in a detection period over 4 days. The pathogen was also easily detected in 200-ml samples for every 5 \u00c2 10 6 l of sewage flow.\n\nSurveillance of poliovirus in sewage has been used by several nations to assess the success of vaccination programs and to identify the potential need for vaccination to prevent outbreaks (Deshpande et al., 2003; Manor et al., 1999; Tambini et al., 1993) . The World Health Organization has published guidelines for the environmental surveillance of poliovirus circulation (WHO, 2003) . These guidelines assume that a single infected person will excrete 10 7 polioviruses per day and that one person infected in 100 could be detected using an infectivity assay without concentrating the sewage. However, if the tested sample is concentrated 100 fold then one infected person among 10,000 could be detected.\n\nThe Public Health Laboratories of Israel have been conducting an environmental surveillance of sewage on a monthly basis since 1989 (Manor et al., 1999) to assess the spread of the wild type poliovirus strains capable of causing paralytic disease. This was done to determine the success and need for vaccination programs. Between 1989 and 1998, four ''silent'' separate episodes of wild-type poliovirus circulation were detected when no clinical cases were observed. The study described how surveillance of the sewage is much more effective than surveillance of clinical cases. The greater sensitivity of sewage surveillance was also validated in Mumbai, India where wild type poliovirus was detected 3 months before any clinical cases were observed (Deshpande et al., 2003) .\n\nIn the poliovirus surveillance of sewage it is necessary to differentiate between vaccine strains and wild type strains of the virus. In the past this has been accomplished by using different cell lines or incubation (Belanov et al., 1996; Belshe, 1991; Mitscherlich and Marth, 1984; Sinclair et al., 2008) Hours to days Influenza (surfaces) 3 days conditions to limit the growth of the vaccine strains. However, today this can be accomplished by the use of molecular methods and sequence analysis. Sequences amplified directly from processed sewage samples by PCR using primer pairs specific for the indigenous type 1 genotype could be used to assess its occurrence in the presence of vaccine strains (Tambini et al., 1993) . Vaccine strains have unique sequences from wild type strains of pathogens allowing easy differentiation. In addition, sequence analysis of sewage isolations has been shown useful in tracking the spread of wild type poliovirus from one country and community to another (Deshpande et al., 2003; Manor et al., 1999) . This review of poliovirus is offered here as a case study and justification for the use of monitoring additional CDC select biological agents. With current molecular techniques and updated concentration methods, a much greater sensitivity and specificity can be achieved for poliovirus and many other CDC select agents.\n\nStudies with poliovirus demonstrated the feasibility of how monitoring sewage for virulent pathogens can be used to assess the success of vaccine programs. This review identified three important benefits of developing a wastewater monitoring system. Sewage surveillance system has been shown to be more sensitive than reporting of clinical cases of serious illness in a community. It was also demonstrated that pathogens can be greatly retarded in a sewage systems allowing a detection time over many days for a one-time release into a sewage system. Finally, it was shown that infectivity assays have the ability to detect one infected person in 10,000 individuals. Sewage surveillance can detect the presence or increased amount of infections from enteric pathogens excreted in the feces or urine during infection. However, the success of such a surveillance system for nonenteric pathogens has not been demonstrated, although they have been found in sewage. The sensitivity of a sewage surveillance system will depend on several important factors including the amount and duration of the agent released into the sewers, the frequency of monitoring, and the sensitivity of the monitoring method.\n\nNonenteric pathogens are released from the host for a minimum of several days. This has already been demonstrated for HIV, hepatitis B, and Y. pestis (see Tables 9.2 and IV) . Given this fact and the expected several day retardation in sewer systems, all or most of the nonenteric category agents will be present in the sewer system if there is an infection in the population served by the sewer system. Based upon the conclusions of the Helsinki experiment, which measured infectious poliovirus (Table 9 .11), one individual excreting 10 8 infectious virus per gram of feces for a period of 4 days could be identified in a population of 10,000. If we consider the concentration and amount of infectious agent in the fluid or feces released during infection, this same sensitivity should be achieved with the agents of smallpox, Brucella, botulism and perhaps influenza. Based on existing information in Table 9 .5 at least one person in 100 could be detected for most of the agents for which information is available.\n\nBecause many of the agents take several days to detect by conventional culture methods the preferred detection system would be by a rapid, but highly specific method such as the quantitative real time PCR or other similar molecular detection system. Because PCR can detect both culturable and nonculturable organisms, it can be expected to be more sensitive than methods that have been used in the past for sewage surveillance. Use of PCR should increase sensitivity by as much as 50,000 over cultivation methods (Ward et al., 1984) . Also, when using PCR to detect viruses in sewage, a 10fold loss in sensitivity is likely with current methods. This loss is due to interfering substances present in the sewage, but still leaves a method that may be 5000 times more sensitive than conventional culture methods. Increasing the volume of wastewater that is tested may also increase the sensitivity of current methods. Technology is available (Hurst and Crawford, 2002) which allows for the concentration of bacteria and viruses from up to 10 l of raw sewage. Thus, increasing the volume analyzed from 400 to 4000 ml could increase the sensitivity of detection another 10-fold.\n\nSurveillance of pathogens in wastewater has several advantages over aerosol and other monitoring methods. Longer survival times in soil, water, and wastewater (Sinclair et al., 2008) facilitate a retardation of pathogens in sewage which allows a longer sampling window than aerosols where organisms are much more susceptible to factors such as settling, desiccation, and relative humidity. Additionally, wastewater is collected in a central location, allowing monitoring to be defined or subdivided to specific areas. Lastly, wastewater systems can include many pathogens originating in aerosol, surface water, tap water, or fomites as storm-water and watersheds will often flow into sewerage systems.\n\nOf course background levels and alert levels of the agents of interest would have to be established. Most agents of interest are likely to occur at one time or another in wastewater or at least have some normal range of background. Further research would be needed to determine what these levels might be and normal variation of concentrations of the agents in wastewater. The types and concentration would be expected to vary by location and the size of the population, area served and type of connections (e.g., the presence of a slaughterhouse may increase the likelihood of finding animal pathogens).\n\nIn summary, given the potential enhanced sensitivity of molecular methods and current abilities to test larger volumes of all of the CDC select agents of interest (enteric and nonenteric), it is possible to detect if an infected individual enters a monitored population. Although the concentration and duration of release of all of the agents of interest are not known, it is still possible to detect at least one infection in populations of 1000 or more. This monitoring is especially useful when combined with other components of the QMRA framework such as modeling of sewage dispersion, back calculation of contaminant point of introduction, and calculations of the health risk. "}