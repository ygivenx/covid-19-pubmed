{"title": "Hot topics in infection control", "body": "State-of-the-art management of infections following solid organ transplantation W2 Prevention and surveillance of donor-derived infections in solid organ transplant recipients\n\nTo deal with donor-derived infections in organ transplant recipients, we have to take into account the two sides of the same coin. In one side we have safety, as it is the most important issue to care about. On the other side, organ shortage is, nowadays, the most important barrier for a successful transplantation. Actually, many patients die while they are awaiting a life-saving transplantation, so any policy regarding the risk for infection transmission through organ transplantation should minimize adverse events but maximizing the availability of life-saving organs. Transmission of infection has been clearly documented via organ and tissue allografts. Organ donors need to be adequately screened for the presence of latent or active infections that may be transmitted through transplantation. A first step in the screening process is a complete medical and social history including travel and epidemiological exposure. Additionally, several microbiological screening tests should be used in the evaluation of an organ donor as it has been stated by some recent scientific guidelines and national and international regulations. The parameters for the election of these assays should be based on clinical parameters. Increased sensitivity may incur false positive assay results result in discarding of uninfected donor tissues. However, the transmission of potentially fatal or life threatening diseases requires selection of an assay that optimizes sensitivity. Decisions must be based on the urgency of transplantation, the availability of alternate therapies or grafts, and of treatments for the disease screened. Some documented infections preclude organ donation (HIV, uncontrolled sepsis, rabies, etc), but many others (cytomegalovirus, most bacterial infections, HCV, HBV, etc) do not stop the organ donation process, but may modify the election of the recipient or to treat the recipient with the adequate antimicrobial therapy. It s clear that a mandatory and timely reporting of transmission events to procurement organizations and public health authorities is crucial in the management of donor-derived infections. Clinicians require education on reportable events including specified clinical syndromes and the mechanisms available for these reports. In general, allograft recipients with evidence of unexplained infection early after graft placement, with recovery or recognition of common or unusual organisms, or with uncommon clinical syndromes merit reporting.\n\nPractical approach to diagnose mixed anaerobic infections in ''real time'' W18 Antibiotic resistance determination; dilution methods vs. disk diffusion. The old story comes back U.S. Justesen* (Odense, DK)\n\nAntimicrobial susceptibility testing (AST) of anaerobic bacteria using dilution methods such as broth microdilution and agar dilution (described in the CLSI guideline M11-A7) has been and still is the gold standard. For many years these methods have been used primarily for research and surveillance of national and local susceptibility patterns in order to choose appropriate antimicrobial agents for empirical therapy. However, as increasing resistance has been observed for many of the frequently encountered anaerobic bacteria, there is a need for more simple methods in the routine clinical microbiology laboratory. Gradient strips are used as a simple but expensive method for AST. Disk diffusion on Wilkins-Chalgren agar (former CLSI recommended agar) for anaerobic bacteria has also been evaluated several years ago, and although results were promising at that time, the method has not been generally accepted. With the introduction of the EUCAST disk diffusion method the intention was to develop a standardised method for anaerobic bacteria. The following test conditions were suggested: the Brucella Blood Agar medium supplemented with hemin and vitamin K (BBA, currently recommended by the CLSI) with strictly controlled test conditions (temperature, atmosphere and time of incubation). The use of the disk diffusion method was limited to rapidly growing (<24 hours) anaerobic bacteria such as members of the Bacteroides fragilis group, Clostridium spp. and Fusobacterium necrophorum. Studies on BBA are in progress and preliminary studies with Bacteroides fragilis group and Fusobacterium necrophorum reference strains have been promising. Furthermore, studies with clinical isolates of Clostridium difficile shows that isolates with reduced susceptibility to metronidazole and vancomycin can be separated from wild-type isolates with disk diffusion. Clostridium perfringens or other Clostridium spp. may well be the next candidates to be evaluated for AST with disk diffusion. Although the reference methods are still the AST methods of choice for a large number of slow growing anaerobic species, disk diffusion seems to be a potential alternative for certain rapidly growing anaerobic bacteria.\n\nUpdate on viral hepatitis W21 How to deal with the guidelines for hepatitis C treatment\n\nIn the last years several national and international guidelines on the treatment of Hepatitis C have been published. By comparing different guidelines there are some ares of controversies on issues without clear evidences from large studies which in most of the guidelines were addressed by expert' opinion. These issues were: (i) treatment duration and usage of response guided therapy (ii) indications for liver biopsy (iii) treatment of special patients subgroups (IDU, HIV coinfected, patients on dialysis, children, liver transplanted patients) (iv) Treatment of patients with advanced cirrhosis. However because of the availability of Directly Active Antiviral the scenario is rapidly changing. New guidelines for the usage of these drugs have been recently published by the American Association for The Study of Liver Diseases and probbaly in next years more more guidelines are waited to be published.\n\nBacteriophages and plasmids in Helicobacters, where do they come from?\n\nHelicobacter pylori chronically infects the gastric mucosa in more than 50% of the human population, and has co-evolved with its human host. Genomic analysis of several strains has revealed an extensive H. pylori pan-genome which is likely to grow as more genomes are sampled. In Helicobacter, natural transformation has been described and both plasmids, and bacteriophages have been identified.\n\nSome plasmids have been already observed in Helicobacters in the form of free or cryptic plasmids. They do not share significant homology with other bacterial plasmids. To the contrary, very little is known about H. pylori phages. Reports of prophages in other Helicobacter species are also rare, in particular one in the genome of Helicobacter acinonychis and one in Helicobacter felis.\n\nRecent data indicate that there is a high percentage of isolates carrying a phage integrase gene. It is possible that they shape the genome at least in terms of the diversity of strains found worldwide as well as contribute to virulence evolution. Phylogenic analysis of the phage integrase gene showed a pattern of biogeographic separation. This is in agreement with a model of co-evolution between the virus and its bacterial host since biogeographic separation is also observed within H. pylori. A model of geographically constrained viral dispersal also fits, i.e. H. pylori from different geographical regions may have been infected by distinct phage lineages after the geographic separation of the bacterial host. Another hypothesis could be that after bacterial infection with the virus, the divergence of the bacterium is also accompanied by divergence of the integrated virus. It has been argued that H. acinonychis strain Sheeba is derived from H. pylori and that the prophage was acquired after the host jump from human to feline. An equally likely scenario is that the prophage was present in the bacterial genome before the host jump. There is ample evidence for continued exchange of genetic material between phages, bacterial genomes, and various other genetic elements. This explains the sometimes fuzzy distinction between phages, plasmids and pathogenicity islands (PAI), and the chimerical nature of some phage genomes. The origin of the cag PAI is currently unknown. An exciting hypothesis would be that cagPAI as well as newly described plasticity zones, which are being considered increasingly as true PAIs, have a phage origin.\n\nInfection on the menu: food-and waterborne hazards for the immunocompromised patient W37 What's coming out of the kitchen? Food-borne infection in vulnerable patients\n\nLund and O'Brien (2011) suggest that 15-20% of the population may be regarded as vulnerable to food borne infection. This is not a homogeneous group. Vulnerability is often considered in terms of increased likelihood of infection on exposure or increased risk of serious adverse outcome from infection but increased frequency or intensity of exposure should also be considered. Some vulnerable groups are clearly demarcated by physiological or pathological condition (pregnant women, HIV/AIDS etc). Therapies associated with increased risk include cytotoxic chemotherapy, immunomodulators (e.g. anti-TNF) and proton pump inhibitors. Infants and older people are also vulnerable although age boundaries between ''normal'' and increased risk are somewhat arbitrary. Poverty, poor education and lack of access to facilities for hygienic storage and preparation increase frequency and intensity of exposure. We can consider four categories of microbe (i) classical pathogens (e.g. salmonella) (ii) pathogens of at risk groups (e.g. L. monocytogenes) (iii) environmental organisms (e.g. Pseudomonas aeruginosa) and (iv) cultures promoted as probiotic (Lactobacillus casei) Industrially prepared or catered foods should be free of classical pathogens. A challenging issue in relation to pathogens of at risk groups is the extent to which food-safety for vulnerable groups can be addressed by labelling/education as opposed to zerotolerance. Environmental species that occur in fresh fruit and vegetables are associated with infection in neutropaenic patients but avoiding these foods does not reduce infection. Foods containing ''probiotic'' cultures have been associated with infection but this is not common. Balancing the protection of vulnerable groups with public preferences for diverse and traditionally/minimally processed foods is a challenge. Also one needs to ensure that the quality of life of vulnerable people is not unduly impaired by loss of favourite foods and beverages. Freshly prepared thoroughly cooked food and freshly prepared washed fruit and vegetables are safe. Boiling water for 1 minute is a failsafe for immunecompromised patients; but reputable bottled waters or properly filtered/ treated waters and pasteurised bottled/packaged beverages are unlikely to cause problems. Animal products that have not had thermal treatment or equivalent should be avoided, likewise certain processed/catered foods that are at high risk for contamination with L. monocytogenes.\n\nHospital-associated listeriosis: causes and consequences F. Allerberger* (Vienna, AT)\n\nInvasive listeriosis is a rare but serious infection (fatality 20-30%). Newborns, immunocompromised and the elderly are at highest risk.\n\nAlthough clusters of late-onset neonatal listeriosis have been identified in newborn nurseries, demonstrating that nosocomial transmission is possible, 99% of cases are foodborne. Nosocomial outbreaks of listeriosis are relatively infrequent, but at least eight outbreaks were reported in England and Wales from 1999 to 2011. In Germany in Oct. 2007 , one public health office reported that two patients had stayed in the same hospital before the onset of listeriosis. Active case finding with retrospectively investigated listeriosis notifications from the state Baden-W\u00fcrttemberg was performed. All available isolates from 2006 to 2008 were characterized by PFGE. Altogether, 16 cases were identified, with 11 patients linked to hospital A (begin Dec. 2006); their nine available isolates were indistinguishable from an isolate of a food sample previously obtained during a routine inspection in food company A. This ready-to-eat cold cut sausage (used for Wurstsalat) was identified as source of the outbreak. Food items served in hospitals could be classified as ''food intended for special medical purposes''-as defined in the Commission Directive1999/21/EC. This would include the absence of L. monocytogenes in 25 g food. However, this special food is only considered for patients with severe neutropenia (<0.5 \u00b7 10^9/L, \u20216 days). In fact, none of the patients reviewed from hospital A met this criterion and consequently all of them had received regular food during their stay in hospital. In Oct. 2010 in Texas, company B had to recall all products shipped since Jan. (outbreakbegin). The 10 patients (five fatal) were shown to have recently eaten in hospital settings. Food and environmental samples were collected from the hospitals; the strain was found in chicken salad made with prepackaged, diced celery. Tracing the celery back led to company B. Cut celery was sold to restaurant and institutional settings, not grocery stores. In Austria (total population: 8.3 millions) on average one out of three citizens stays in a hospital each year (2 678 627 hospitaladmissions; mean 6.8 day; median: 3.9 day). Due to the prevailing high hygienic standards of hospital kitchens, ready-to-eat food remain a residual risk. Every hospital-associated listeriosis outbreak should be seen as a chance to elucidate problems in our general food chain.\n\nVAR2CSA vaccine for malaria in pregnant women\n\nA vaccine that efficiently prevents infection with the malaria parasite Plasmodium falciparum is unlikely to become available in the near future. A vaccine to prevent disease is a feasible alternative approach, the development of which is a goal that appears achievable in the particular context of pregnancy-associated malaria. The evidence base for this assertion rests on several interconnected epidemiological, parasitological and immunological observations. At the epidemiological level it is known that, in areas with stable transmission of malaria, primigravid women are more susceptible than multigravidae, both to infection with P. falciparum and to its pathological consequences. The latter are directly related to the fact that parasite-infected erythrocytes (PfiE) accumulate in the placenta resulting, especially in primigravidae, in frequently intense monocytic inflammatory activity. Multigravidae are rendered less susceptible by the specific immunity they have acquired over the course of earlier pregnancies. That immunity is characterized by the antibody-based, gender-specific nature of the response to a particular parasite-derived protein antigen expressed on the surface of PfiE. The protein in question acts as a ligand that mediates adhesive interactions between PfiE and a placental receptor, chondroitin sulphate A (CSA), expressed on syncytiotrophoblasts. The antigen is referred to as VAR2CSA, a designation derived from the fact that it is encoded by a gene of the var family, members of which are responsible for the production of PfEMP1 proteins. Although indeed polymorphic, a characteristic of all PfEMP1 proteins, VAR2CSA displays a comparatively reduced degree of variability. The latter is emphasized by the fact that the antibodies acquired by multigravidae living in a given distinct geographical region can inhibit the adherence to CSA of infected erythrocytes from placentas of women living elsewhere. The detailed molecular understanding of the processes involved now available thus provides the foundation for the on-going efforts aimed at developing a VAR2CSA-based vaccine. Such a vaccine would represent an extremely valuable additional tool with which to reduce the burden of disease both in mothers and their offspring.\n\nRecommendations for management of Chagas disease in pregnancy and control of congenital infection\n\nApproximately 2 million women in fertile age are estimated to be chronically infected with Trypanosoma cruzi (Chagas disease) in the endemic areas of Latin America, as well as in non-endemic areas where Latin American people have migrated (mainly United States, Canada, Europe, Australia and Japan). The main impact of such chronic T. cruzi infection in pregnancy is the transmission of parasites to foetuses (occurring in 0.1% to 12% of infected pregnant women) and the development of a congenital Chagas disease. Detection of infection during pregnancy can be performed using serological tests. Serological testing is recommended for pregnant women who are living in disease endemic areas, or in disease non-endemic areas and are born or have lived previously in disease endemic areas or whose mothers were born in such areas. There is no way to identify, in advance, those infected mothers who will transmit the infection to their foetuses. Anti-parasitic treatment is not recommended during pregnancy and congenital infection cannot be prevented. There is presently an international consensus (WHO Technical Group on control of congenital Chagas disease) to recommend detection of congenital infection in newborns of infected mothers with treatment of positive neonates, as the best strategy for limiting short-term morbidity and mortality of acute congenital infection, and preventing long-term effects of Chagas disease. Detection of living parasites can be performed by microscopic examination of umbilical cord or neonate venous blood (microhematocrit test) or other parasitological tests (e.g. hemoculture). PCR assays can detect low amounts of T. cruzi DNA, but their standardization and validation are still under development. Detection of IgM and IgA antibodies and placental histopathology are not contributing to such diagnosis. In case of negative results close to birth, detection of specific antibodies using standard serological assays can be carried out 8-10 months after birth, i.e. when antibodies transferred from the mothers have been eliminated. A positive serological result at this time indicates that the infant is currently infected. Cases of congenital T. cruzi infection should be treated with benznidazol or nifurtimox as soon as the diagnosis has been confirmed. Treatment is generally successful and without the adverse reactions seen in adults if administered within the first year of life.\n\nColistin use in clinical practice W50 Colistin PK/PD: lessons from recent studies\n\nAfter being abandoned for many years because of suspected nephrotoxicity, colistin is increasingly used as a last line defence against MDR Gram-negative pathogens. But colistin is composed of at least 30 different polymyxin compounds, mainly colistin A and B, and it is administered intravenously or by nebulisation as a complex mix of colistin methanesulfonate (CMS) derivatives. Therefore it's pharmacokinetics is relatively complex and could not be investigated until specific analytical assay became available. Yet major studies have recently been conducted and colistin pharmacokinetics is nowadays mostly understood. It was demonstrated that in healthy volunteers, about 2/3 of the inactive CMS dose is lost by direct excretion in urine (1). Accordingly it was observed that in patients with relatively well preserved renal function and treated with the most usual maintenance dose (3 MIU/8), steadystate plasma concentrations of colistin could hardly reach values greater than 2 lg/mL (2). It was also observed that colistin concentrations are virtually constant between two consecutive administrations at steadystate with no real peak nor trough values. Furthermore colistin concentrations increase slowly after treatment initiation and it takes about 2 days before reaching steady-state suggesting the need for loading dose. These data were further confirmed in a study conducted on a greater number of critical care patients including some on hemodialysis or continuous renal replacement (3) . It was shown that CMS loading dose could be adjusted to body weight and maintenance dose to creatinine clearance (3) . However it was also concluded that colistin may best be used as part of a highly active combination, especially for patients with moderate to good renal function (creatinine clearance >70 mL/min) and/or for organisms with MICs of \u20211.0 lg/L (3).\n\nThese new data open perspectives in terms of colistin therapeutic drug monitoring and also suggest that alternative routes of administrations such as nebulisation could be seriously considered. Colistin has been re-introduced into clinical practice for the treatment of carbapenem-resistant Gram-negative bacteria by necessity. Studies in the last decade have attempted to reconstruct the path present-day medications undergo prior to clinical use. The median half-life of active colistin is 9.1 hours in critically-ill patients with normal renal function. Pharmacokinetic/pharmacodynamic studies show that doses higher than those conventionally used in Europe are needed. Loading doses, amounting to the total daily dose, are recommended in critically-ill patients. Colistimethate sodium (produg) and colistin are efficiently removed by hemodialysis; daily doses of 6 million international units (MIU) are recommended for patients undergoing continuous hemofiltration and 1 MIU with intermittent hemodialysis. The cerebrospinalfluid (CSF)/serum ratio of colistin is 25% and intra-thecal doses >60 000 IU/day are needed to reach trough concentrations above 2 mg/ L in the CSF. Colistin was associated with lower mortality than no effective treatment and higher unadjusted mortality than beta-lactams in non-randomized comparative clinical studies. Two studies comparing colistin to inappropriate antibiotic treatment showed lower mortality with colistin, pooled odds ratio 0.51 (95% CI 0.24-1.08). Prospective studies or matched retrospective studies (N = 7) showed a pooled OR for death of 1.40 (95% confidence intervals 1.07-1.84), indicating significantly higher mortality with colistin. Four non-matched retrospective studies reported a pooled OR for death of 2.65 (95% CI 1. 76-3.99) . However, in all these studies colistin was administered to sicker patients with carabapenem-resistant bacteria. Overall, nephrotoxicity rates were not higher with colistin in studies comparing colistin to other antiobiotics and colistin-induced nephrotoxicity is reversible in most patients. Emergence of colistin resistance has been described in high use settings. Synergy with carbapenem, rifampin and other antibiotics has been reported in-vitro. Randomized controlled trials are ongoing or in planning to assess this and other aspects of colistin use in clinical practice.\n\nPathogenesis and treatment of recurrent Clostridium difficile infections (CDI) W57 Clostridium difficile and symbiotic gut microbiota C. Rousseau*, P. Lepage, A. Collignon (Bondy, Jouy-en-Josas, FR)\n\nClostridium difficile is a major enteric pathogen responsible for antibiotic-associated diarrhoea and pseudomembranous colitis. Large spectrum antibiotics are major risk factors for C. difficile infections (CDI) leading to intestinal dysbiosis and disruption of the microbiota barrier effect. Then, C. difficile multiplies and colonizes the intestinal tract. Molecular methods based on 16S rDNA and metagenomics have given new insights into the composition of the intestinal microbiota. Three major phyla compose the adult intestinal microbiota: Bacteroidetes, Firmicutes (Clostridium leptum-Clostridium coccoides) and Actinobacteria. Each human being has his own gut microbiota at the species level. Several species, however, are shared by at least 50% of healthy human population, and constitute a phylogenetic core. The bacterial composition of the human microbiota varies greatly according to age. Several studies have profiled the microbiota in infants, adults and the elderly colonized by C. difficile. The loss of colonization resistance against C. difficile was associated with qualitative and quantitative changes in the microbiota. In asymptomatic infants colonized by C. difficile and adults with CDI, species diversity in the intestinal microbiota was not affected by the presence of C. difficile. In contrast, microbiota of adults with recurrent CDI presented a significant biodiversity decrease. Patients with multiple recurrent CDI have marked reduction of Bacteroides, C. coccoides and C. leptum groups with increases of Enterobacteriaceae and Veillonella spp. In young healthy infants, C. difficile colonization was associated with changes in the intestinal microbiota ecosystem: Bifidobacterium longum was associated with faecal microbiota of C. difficile non-colonized infants, while colonized infants presented more frequently Ruminococcus gnavus and Klebsiella pneumoniae species. Microbiota of elderly patients with CDI was characterized by a reduced number of Bacteroides and bifidobacteria and by a greater diversity of facultative species, lactobacilli and clostridia. A bacterial signature associated with the absence of C. difficile colonization will provide information about bacterial groups involved in the barrier effect against C. difficile. These data pave the way to define therapeutic approaches for microbiota modulation with an anti-C. difficile objective.\n\nFebrile neutropenia -past, present and future W64 Will febrile neutropenia shortly be a thing of the past?\n\nIntensive myelosuppressive chemotherapy has been introduced in the management of acute leukaemias in the 1970s and enabled substantial rates of long-term complete remission and survival. Infections emerging during bone marrow aplasia now became predominant causes of death, with the risk of severe infections directly corresponding to the duration of profound neutropenia. During the past decade, antineoplastic treatment strategies have elaborated which are based upon pathogenic molecular mechanisms, designated as ''targeted therapies'', ''small molecules'' or ''epigenetic strategies'', and in some instances, toxicities from conventional chemotherapy, including myelosuppression, have become less burdensome. One of the major advances in the treatment of acute myeloid leukaemias and myelodysplastic, particularly in elderly patients, has been the introduction of demethylating agents such as 5azacytidine, providing a treatment modality aiming at DNA repair in malignant myeloid precursor cells instead of cytotoxic eradication associated with transient, but profound and critically long-lasting marrow aplasia. This remarkably effective approach has enabled antileukaemic therapy also in fragile and co-morbid patients formerly excluded from myelosuppressive treatment modalities. However, since the malignant clone is not eradicated, this treatment is indefinite and typically results in emerging resistance and clinical relapse. And although further non-myeloablative treatment modalities including histone deacetylase inhibitors or multi-tyrosine kinase inhibitors have been developed also for leukaemia treatment in recent years, all these approaches will not substitute the classical myelablative chemotherapy in the treatment of acute leukaemias.\n\nOther fictional options to avoid febrile neutropenia could be (1) agents protecting physiological haematopoiesis from antineoplastic drug toxicity, (2) cytokines stimulating haematopoietic precursor cells much earlier and more effectively than G-CSF or and (3) optimization of infection prevention, however, on none of these fields substantial progress has been achieved over the past two decades. Therefore, febrile neutropenia will remain one of our most predominant clinical problems in the course of myelosuppressive antineoplastic treatment, mainly in the management of acute leukaemias, myelodysplastic syndromes, and allogeneic haematopoietic stem cell transplantation.\n\nFrom laboratory to clinic: diagnosis and management of infections due to intracellular and fastidious bacteria W70 Whipple's disease: from primary infection to late clinical manifestations G. Greub* (Lausanne, CH)\n\nWhipple disease was already described in 1907 by G. Whipple. However, its etiological agent, Tropheryma whipplei was only identified in 1991 by KH Wilson and cultivated in 2000 by D. Raoult. Until last years, whipple disease was only considered as a rare and chronic disease. Although abdominal involvement with malabsoption, diarrhea and/or weight loss represents the classical form of chronic whipple disease, neurological involvements, arthritis, endocarditis, and uveitis may also occur, alone or in combination.\n\nRecently, acute whipple disease with or without bacteremia have been documented among patients with gastroenteritis or lower respiratory tract infections. This symptomatic primoinfection also named earlyonset whipple disease appear to be much more common than the lateonset manifestations, supporting the hypothesis that evolution (i) to a chronic form of the disease, (ii) to healthy carriage or (iii) to spontaneous recovery might be -at least partially -genetically determined.\n\nIt is thus important to summarize recent knowledge and review the current knowledge on the epidemiology, clinical presentation, diagnostic approaches, treatment and pathogenesis of whipple disease.\n\nThe basis of tuberculosis diagnosis and management of cases W74 Host immune response in tuberculosis J. Friedland* (London, UK)\n\nThe caseating granuloma is recognised as the hallmark of the tissue response to infection by Mycobacterium tuberculosis. It is also clear that the immune response to infection is generally excellent since only about 1% of the 1.7 billion infected people worldwide have active disease. However, in those patients with active infection, there is widespread inflammatory tissue destruction. This talk will focus on the role of the innate immune system in both host defence to and the pathology of tuberculosis. The principal innate inflammatory cells involved in host defence are phagocytic cells of the macrophage lineage including multi-nucleate giant cells but others including stromal cells, neutrophils and NK cells are of key importance. The innate immune response acting through a series of pattern recognition receptors orchestrates the host response by secreting a range of mediators, cytokines and chemokines. Innate immunity targets the pathogen by secretion of molecules such as cathelicidins and defensins. In addition, by upregulating gene expression and secretion of matrix metalloproteinase enzymes, it is critical to the destruction of host tissue. This is both the pre-requisite for the spread of infection and the hallmark of severe infection leading to morbidity and mortality. Innate immune function is influenced by the physiological and metabolic environment. In this talk, the diverse aspects of innate immunity will be discussed and the potential for the novel application of immune modulators to improve patient outcomes will be examined.\n\nBiocides and nosocomial pathogens S85 Resistance mechanisms to antiseptics\n\nThe effective use of biocides is crucial to prevention of infection, particularly in light of the emergence and spread of highly antibiotic resistant pathogens. Biocides are increasingly used in a number of applications and concern has been raised that biocide exposure might act as a selective force for development to biocide resistance and that such mutants may be cross resistant to antibiotics. Our laboratory has studied the consequences of exposure of bacteria to various biocides in terms of survival and development of antibiotic resistance. We have assessed exposure to in use concentrations of biocides and sub-optimal exposures and determined the ability of strains to survive and characterised surviving mutants using a combination of flow cytometry, phenotypic characterisation, transcriptomic and genomic analysis and virulence assays. We have found bacteria can survive high level biocide exposure and that surviving mutants demonstrate a low-level multiple antibiotic resistance phenotype and that this is mediated by de-repression of multidrug efflux. Similarly biocide exposure results in selection of multidrug efflux mutants. However the propensity to select for antibiotic resistant mutants varies between different biocides we have evaluated and true biocide resistance is rare and hard to achieve. Biocides must be used appropriately and in line with recommended dilutions to ensure success, the potential for development of antibiotic resistance should be considered when developing novel biocide formulations.\n\nBiocide resistance and infection control\n\nBiocidal substances used in disinfectants and antiseptics play an important role in the prevention of healthcare associated infections. To prevent of the spread of antibiotic resistant bacteria appropriate disinfection and antisepsis is advised in corresponding guidelines. The question has been raised, whether repeated and continued use of biocidal substances can lead to the promotion of biocide resistance or even antibiotic resistance. In the assessment of available data on resistance it is crucial to use appropriate definitions. While antibiotic resistance is usually defined as a minimum inhibitory concentration above the level that is reached in affected human tissue, biocide resistance should be defined as a significantly increased biocidal concentration needed to pass accepted disinfectant test standards. Use of sublethal biocide concentrations can lead to phenotypic adaptation of microbes, which is different from resistance, which is hereditary. It can also select for unspecific resistance mechanisms, which confer cross resistance to antibiotics. This has not been observed, when biocides are used at microbicidal concentrations. In several studies clinical isolates from infected patients did not demonstrate any resistance to biocidal substances used in the same setting. While antibiotics target specific microbial structures or metabolic processes, biocides have broad and unspecific mechanisms of action and target sites. It is concluded that appropriate use of disinfectants and antiseptics in infection prevention using concentrations defined by tests according to accepted standards does not bear a relevant risk of the development of biocide resistance or promotion of antibiotic resistance.\n\nFrom laboratory to clinic: diagnosis and management of infections due to intracellular and fastidious bacteria Antimicrobial resistance in the 21st century; the Gram-negative Enterobacteriaceae strike back!\n\nThe ABC's of multidrug-resistant Enterobacteriaceae; CTX-M, CMY, KPC, NDM, OXA J. Pitout* (Calgary, CA)\n\nThe Enterobacteriaceae are among the most important causes of serious nosocomial and community-onset bacterial infections in humans and resistance to anti-microbial agents in these species have become an increasingly relevant problem for health care providers. The various members of beta-lactam antibiotics remain important drugs that are often used to treat serious infections caused by Enterobacteriaceae. Beta-lactamase production remains the most important contributing factor to beta-lactam resistance among Enterobacteriaceae. Betalactamases (often referred to as ''newer beta-lactamases'') with activity against the 3rd generation cephalosporins had been described in during the 1980 and 90's and had been escalating since the mid 2000's. The newer beta-lactamases consist the following: plasmid-mediated AmpC beta-lactamases (e.g. CMY types), extended-spectrum beta-lactamases (e.g. CTX-M-types) and carbapenemases (e.g. KPC types, the metallobeta-lactamases (e.g. VIM, IMP and NDM) and oxacillinases (e.g. . This presentation will give an brief overview using clinical examples on the importance and laboratory detection of Enterobacteriaceae that produce these newer beta-lactamases.\n\nMolecular epidemiology of multidrug-resistant Enterobacteriaceae\n\nMolecular characterization of multi-resistant Enterobacteriaceae requires two inseparable entities to be considered, the resistant bacteria and their resistance determinants. The bacteria can be characterized and compared by myriad phenotypic or genotypic methods; one may choose methods that are suitable for fine-focused local outbreak investigations or others that give panoramic perspectives of population structure. Against this background of resistant isolates, strains and clones, one must consider the complexity of genes, integrons, transposons and plasmids that confer resistance. These fundamental units of resistance spread through bacterial populations vertically, by association with successful strains or lineages, or horizontally between strains, species and genera. Applying an epidemiological aspect to these molecular investigations additionally requires us to factor in whether the resistant bacteria were isolated from humans (in hospital, nursing home, or community settings), animals (food production, companion or wild), foodstuffs, or environmental samples and should ideally include denominators, and demographic, temporal and geographic data. The depth of any investigation will ultimately depend on its goals and the resources available. The nature of multiresistance in Enterobacteriaceae is highly complex, involving spread or repeated selection of successful clonal lineages, and horizontal spread of resistance plasmids. Local investigations are useful for guiding infection control, but maximum information is obtained if they can be set into a national or international context. Currently, few well-coordinated global networks are seeking to address this issue.\n\nClinical issues of infections due to multidrug-resistant Enterobacteriaceae\n\nAfter controlling for usual confounders, multidrug-resistant (MDR) bacteria are associated with worse outcomes. This may be due to any of these reasons or their combinations: increased virulence (which is rarely proved), delayed appropriate therapy (because the probability of prescribing inappropriate empirical antimicrobial therapy is increased), and diminished efficacy or increased toxicity of available second-line drugs. In the case of Enterobacteriaceae, invasive infections caused by ESBL-producers have been shown to be associated with increased mortality; we may assume that the effect is similar for isolates producing other mechanisms of resistance. Infections caused by MDR-E occur more frequently in predisposed patients, as those with underlying diseases, admitted to healthcare centres or undergone invasive procedures, and who had recently received antimicrobial treatment, but may also happen increasingly in healthy patients with community-acquired infections. Thus, in front of patients with serious infections, clinicians frequently need to decide between the empirical use of very broad spectrum antimicrobials (and even second-line drugs) to cover MDR-E, or to reserve them in order to avoid further spread of resistance. Several clues may help in this decision making-process. First, pre-test probability may be estimated in base of local prevalence of antibiotic resistance. Second, evaluation of the individual risk factors for MDR-E may help to identify patients with lower or higher risk for infections caused by these organisms (post-test probability). And third, a careful assessment of the severity of acute disease and systemic inflammatory response syndrome would help to identify patients in which appropriate empirical therapy is an absolute priority. In the absence of randomised clinical trials, decisions for empirical therapy, de-escalation strategies, and use of alternative agents in different situations need to be based on a deep knowledge on the available microbiologic data, PK/PD models, and clinical studies. It follows that management of acute infections in the 21st century demands a certain degree of super-specialisation for performing an adequate and timely clinical work-up, correctly identifying the potential source of infection and severity, and the specific determinants that modify the potential risks, aetiologies and antimicrobial susceptibility, so that the decisions about antimicrobial therapy can be optimised.\n\nA new dawn for natural product antimicrobial drug discovery? Thiomarinol is a complex molecule produced by marine bacteria. It appears to be an amide formed by condensation of marinolic acid that is similar to the anti-MRSA antibiotic mupirocin (also known as pseudomonic acid), except for possessing 8-hydroxyoctanoic acid instead of 9-hydroxynonanoic acid, and a pyrrothine similar to holomycin. To understand how these antibiotics are made and provide genetic information for constructing hybrid pathways we have analysed the thiomarinol biosynthetic genes and used this to underpin further analysis on both pathways. As with the mupirocin cluster the thiomarinol cluster encodes its own isoleucyl-tRNA synthetase, the known target for mupirocin. Cloning these resistance genes from both the mup and the tml clusters in E coli showed that the TmlM protein confers complete resistance to thiomarinol but that the MupM only confers resistance to mupirocin. Targeted gene knockouts allowed the derivation of strains that produce the pyrrothine but no marinolic acid, marinolic acid but no pyrrothine or both of these components separately but with no production of thiomarinol. The mutant unable to produce marinolic acid was fed with mupirocin and was shown to produce a novel analogue of thiomarinol that was able to inhibit the growth of mupirocin-resistant MRSA. The tmlU gene is responsible for joining marinolic acid and pyrrothine together for production of thiomarinol but surprisingly when introduced into the mupirocin producer TmlU appears to interfere with the elongation of the 9 hydroxynonanoic acid component. We are also testing whether amide synthetases related to TmlU can substitute for it in this reaction, thus allowing a larger number of diverse substrates to be used. We are also manipulating the expression of genes of the mupirocin cluster in order to increase production but without accumulation of side products such as Pseudomonic acid B.\n\n[1] Fukuda, D., Haines, A.S., Song, Z., Murphy, A., Hothersall, J., Stephens, E.R., Cox, R., Crosby, J., Willis, C., Simpson, T.J., Thomas, C.M. (2011) A natural plasmid uniquely encodes two antibiotic pathways creating a potent hybrid. PLoS One 6, e0018031.\n\n[2] Murphy, A. C., Fukuda, D., Song, Z., Hothersall, J., Cox, R.J., Willis, C.L., Thomas. C.M. and Simpson, T.J. (2011) Novel Thiomarinol antibiotics active against MRSA are generated by mutagenesis and mutasynthesis of Pseudoalteromonas SANK73390. Angewandte Chemie International Edition 50, 3271-3274.\n\nFrom the deepest oceans L. Gram* (Lyngby, DK)\n\nOceanic environments cover 70% of our planet and make up 95% of our biosphere. The marine environment is home to a multitude of life forms existing under very different conditions (pressure, low temperature, saline conditions) and it is believed that the secondary metabolites produced by marine organisms hold great potential as novel compounds for the biotech industry. We isolated approximatly 500 antibacterial bacteria on a global research cruise with the purpose of purifying and identifying novel small molecules with antibacterial activity. The bacteria belonged to the Roseobacter clade, the Vibrionaceae family or the Pseudoalteromonas genus. We isolated several antibiotics such as pentabromopseudilins, andrimide and tropodithietic acid that have been found in marine bacteria before. We also isolated several antibiotics such as holomycin and indolmycin that are known antibiotics hithero only isolated from terrestrial Streptomycetes. The fact that we predominantly found already known antibiotics could be because we used the same growth conditions as many previous studies. Genome sequencing of one Pseudoalteromonas strain from which two antibiotics were isolated revealed that at least seven PKS/NRPS genes were found. Hence manipulating culture conditions, or expression in other hosts, may induce expression of hithero silent genes coding for bioactive metabolites. Certainly culturing one of the antibiotic producing Vibrionaceae on a substrate mimicking its natural conditions by containing exclusively chitin as C-and N-source, led to a dramatic alteration in secondary metabolite profile. Under these natural growth conditions, the antibiotic became almost the only metabolite produced. Some strains of the Vibrionaceae also produced compounds, so-called solonamides, that were not antibacterial per se but that specifically inhibited the quorum sensing system in Staphylococcus aureus likely via binding to the Agr. Also the quorum sensing system in Pseudomonas aeruginosa was inhibited by a yet un-identified compound produced by Roseobacter clade strains. Whilst it is known that both Roseobacter clade bacteria and Pseudoalteromonas species produce bioactive compounds, the Vibrionaceae have predominantly been researched due to their role as pathogenic or symbiotic bacteria. Our work demonstrates that this bacterial group likely also harbours organisms of biotechnological interest. Multidrug-resistant (MDR) strains of bacteria continue to provide considerable challenges for clinicians who face a deceasing arsenal of antibiotics, many of which are analogues of compounds for which resistance has already arisen. MDR strains of Mycobacterium tuberculosis, other Gram-positive pathogens such as S. aureus, Clostridium difficile and the intrinsically-resistant Gram-negative bacteria such as Salmonella enterica and Pseudomonas aeruginosa require the development of new classes of antibacterial which are 'opaque' to efflux, or alternative strategies to reduce the MDR phenotype, for example the use of efflux pump inhibitors (EPIs). Plants are an untapped source of antibacterial chemotypes and at present there are no examples of phytochemicals which are used clinically. This is unusual given the wide use of plant materials in traditional systems of medicine, which in many communities of the developing world are the only resource available for the treatment of topical or even systemic infections. We have been studying plants that are used medicinally for their antibacterial and resistance modifying properties and have isolated a number of compounds that display potential such as the garlic metabolite1 1 and the Hypericum2 natural product 2, which display MIC values of 0.1 and 2 mg/L against M. tuberculosis and S. aureus respectively. In collaboration we have also investigated the ability of plant-derived compounds such as the natural product three to inhibit multidrug efflux, having dual antibacterial and EPI activity. This lecture will cover the need for antibacterials and resistance-modifying agents and will propose plant natural products as a useful source of these molecules with examples from our work to date. Influence of directly acting antivirals on current treatment regimens for hepatitis C S99 Hepatitis C virus entry -molecular mechanism and clinical implications T.F. Baumert* (Strasbourg, FR)\n\nHepatitis C virus (HCV) is a major cause of liver cirrhosis and hepatocellular carcinoma world-wide. The development of efficient strategies for prevention and treatment of HCV infection has been hampered by rapid development of viral resistance and escape. Viral entry into target cells is a promising target for antiviral preventive and therapeutic strategies since it is essential for initiation, spread and maintenance of infection. Indeed, cross-neutralizing antibodies inhibiting HCV entry have been shown to be associated with control of HCV infection and prevention of HCV re-infection in cohorts with selflimited acute infection. HCV entry is a multistep process involving several host factors including heparan sulfate, CD81, scavenger receptor B1, claudin-1 and occludin. Using a functional genome-wide RNAi kinase screen we have recently identified a network of receptor tyrosine kinases (RTKs) as HCV entry factors. Functional studies indicate that kinases act on postbinding steps by interfering with CD81-claudin-1 co-receptor associations and membrane fusion. Using an infectious cell culture model, we demonstrate that targeting of host entry factors by receptor-specific monoclonal antibodies or inhibition of RTKs by approved protein kinase inhibitors block entry and infection of all HCV genotypes including viral escape variants that are resistant to autologous host immune responses. These results suggest that targeting host entry factors using receptor-specific monoclonal antibodies or small molecules constitutes a novel antiviral approach to prevent primary HCV infection, such as after liver transplantation and may also restrain virus spread in chronically infected patients.\n\nClinical challenges in community-acquired pneumonia S103 How should we deal with non responders?\n\nJ. Gon\u00e7alves-Pereira* (Lisbon, PT)\n\nAssessing non responders Although community acquired pneumonia (CAP) diagnosis may be straightforward, the criteria commonly used, physical examination and chest radiography, have high sensibility but low specificity. Furthermore microbiological documentation may not be possible, especially in viral infections, and its results usually are not available before 48 hours of presentation. The evaluation of the response to antibiotics may be even more problematic, because it relies on the normalization of those unspecific criteria previously used. Non response has been mostly defined by subjective criteria, like clinical deterioration within 72 hours, lack of response or worsening of clinical or radiologic status, persisting fever or clinical symptoms (malaise, cough, expectoration, dyspnoea). The pattern of C-Reactive Protein kinetics in CAP, namely failure to decrease its concentration, has also been associated with non response. Non response to antibiotics may simply unveil a wrong diagnosis. However in the presence of true CAP different factors related to the host, the bacteria and the antibiotic itself may lead to therapeutic failure. Host, Bacteria, Antibiotic Host age and comorbid conditions, genetic polymorphisms, namely in the Toll Like Receptor-4 gene and Tumor Necrosis Factor and the bacteria causing health care related CAP, especially Pseudomonas, have been implicated in slow response to CAP, which may mimic non response. But the most common causes of antibiotic failure is bacteria resistance to antibiotics and the presence of suppurative complications such as empyema or abscess. Finally polymicrobial CAP, including viral and bacterial co-infection, is usually more severe and more often associated with therapeutic failure and mortality. No compliance to antibiotic therapy, especially in the outpatient setting, is another cause of non response and should always be excluded. Antibiotics may also fail to achieve adequate concentrations, especially in the lung tissue, as a consequence of pharmacokinetic changes in the host during sepsis. Moreover adequate infection control may require larger antibiotic exposure. Although antibiotic therapy is of utmost importance, especially in severe CAP, adequate antibiotic therapy alone, even if used optimally, probably is not sufficient to reduce the associated mortality. Therefore interest in non-antibiotic, adjunctive therapy has continued to grow. However until now no single drug has proven to be beneficial in patients with CAP.\n\nMyocarditis is an inflammatory heart disease, usually caused by infectious agents. In Europe and North America the most common causes of myocarditis are viral agents. Patients with acute myocarditis present a range of symptomatology, from asymptomatic courses to severe manifestations leading to intensive care therapy. However, the diagnosis of myocarditis is based on histology, and thanks to endomyocardial biopsies it is possible to identify viral genomes by using molecular biology techniques (PCR, in situ hybridization). Moreover, idiopathic dilated cardiomyopathy, that is the underlying cause in around 50% of patients with heart failure, has been associated with myocarditis, because the incidence of biopsy-diagnosed myocarditis in patients with unexplained congestive heart failure can reach two thirds of cases. For a long time, enteroviruses have been considered to be the most common cause of acute viral myocarditis, with possible transition from acute myocarditis to dilated cardiomyopathy. Recent investigations have shown, however, that other viruses are also frequently encountered in acute myocarditis patients, suggesting that persistence of various virus species may play a pathogenic role in the transition from acute myocarditis to dilated cardiomyopathy. Thanks to a most extended use of endomyocardial biopsy in the diagnosis of myocarditis, new viral agents and new mechanisms of damage have been detected. Enterovirus, parvovirus B19, Cytomegalovirus, HHV6, and EB virus genomes have been identified in myocarditis, and mechanism of damage has been characterized. For example. during an acute myocarditis caused by enterovirus several mechanisms of myocyte damage can actually be recognized including: (i) the induction of an inflammatory reaction to the infectious agent; (ii) the release of destructive proteases from the host; and (iii) the activation of intracellular apoptotic pathways. The complex processes determined by viral infection will change the entire heart anatomical and functional structure, leading to activation of an adaptive mechanism known as heart remodeling, which involves heart dilation and ventricular dysfunction in patients with congestive heart failure. S108 Therapeutic approach to infectious myocarditis Myocarditis is defined as inflammation of the heart. This is induced either by any inflammatory process, or directly by infection. Among therapeutic means, we can distinguish non specific and specific goals. MR-scan could help greatly to diagnose quickly acute myocarditis and could help to chose appropriate treatments. Nevertheless, it could not assess particular infection. EMB remains gold-standard, even if scarcely performed. Specific treatments are recommended only for proved cardiac infection, that is theorically in case of positive endomyocardialbiopsy (EMB). Among numerous infectious agents, specific treatment is then available: bacterial infections (in case of severe sepsis, Lyme, tuberculosis, \u2026), parasitic (Chagas disease, toxoplasmosis,\u2026) and mainly in case of viral infections: coxsackiesviruses, CMV, EBV, HIV\u2026 Immunomodulation could endly offer new possibilities of treatments: cytokine modulation could help to redirect wrong immunological answer. Interferon could help in several situations, illustrating importance of immunomodulation. New medical hypotheses are actually explored, such as arrhythmias, and possibly specific actions of non specific treatments, or even interest of cardiac frequency. Non specific treatments aim at improving cardiac physiology: CEI, ARB, beta-blockers. In case of severe left ventricular dysfunction, spironolactone is also possible. Diuretics are often necessary for symptom relief. These treatments are probably also involved in other therapeutic ways, especially through anti-inflammatory effects (CEI or ARB mainly). In a recent French registry beta-blockers seemed to lower mortality. Anti-inflammatory treatments, such as aspirin or colchicine, are often proposed to decrease systemic and cardiac inflammation, but this point remains controversial. Methods: CHIF-NET is the first nationwide invasive fungal infection surveillance study in China that covered 12 tertiary hospitals in nine provinces. It is important to note that, only yeasts that isolated from blood or other sterile body sites were collected. All isolates were identified by amplification and sequencing of the internal transcribed (ITS) region. Antifungal susceptibility testing to fluconazole (FLC) and voriconazole (VOC) were performed using disk diffusion method according to CLSI document M44-A.\n\nResults: Overall, a total of 814 yeast isolates were collected, which were assigned to 27 species. Candida species accounted for~90% of all, followed by Cryptococcus species (8%) and Trichosporon species (1%). Within Candida genus, C. albicans the predominant (34%), followed by C. parapsilosis (18%), C. tropicalis (15%), C. glabrata (11%), C. metapsilosis (3%), C. krusei (2%), C. guilliermondii (2%) and other Candida spp. (2%).\n\nThe first three predominant specimen types were blood samples, (43%), drainage fluids (14%) and cerebrospinal fluids (CSF, 8%) . In all, 26% of yeasts isolated from blood were assigned to C. parapsilosis, which was previously reported to be closely-related with catheter-related candidemia. For yeasts isolated from CSF, Cryptococcus species were the commonest (58%). Results of antifungal susceptibility testing to FLC and VOC revealed that both C. albicans and C. parapsilosis were highly susceptible (nonsusceptible rates <2%). Although a higher rate of C. tropicalis isolates (5.7%, seven isolates) were resistant to FLC or VOC, six resistant isolates were found from the same hospital; thus, potential of an outbreak in this hospital should be considered. In comparison, C. glabrata showed much lower susceptibility to FLC and VOC (susceptible rates 60% and 80%, respectively), and some less-common yeast species e.g. C. quercitrusa, Pichia anomala and Yarrowia lipolytica also shown high resistance to azoles and more likely to be related to blood-stream infections.\n\nConclusion: Results of CHIF-NET 2009-2010 provides distinct evidence of the sustained activity of fluconazole and voriconazole against a broad range of yeast species, and species identification by molecular methods made the results more creditable.\n\nR. Maini*, K. Henderson, T. Lamagni, G. Nichols, N. Phin, V. Delpech, E. Sheridan (Colindale, UK)\n\nObjectives: Anecdotal reports suggest that the incidence of Pneumocystis jirovecii pneumonia may be on the increase. This study was undertaken to describe the epidemiology of Pneumocystis pneumonia in England from 2000 to 2010 using a number of data sources.\n\nMethods: Microbiological diagnoses were extracted from the Health Protection Agency routine laboratory surveillance system (LabBase2), and clinical ICD-10 codes were used to extract Pneumocystis pneumonia data from both NHS Information Centre Hospital Episode Statistics (HES) and Office for National Statistics (ONS) death certification data. Datasets were individually analysed for trend over time and then cross-compared. HIV surveillance data was used to analyse the occurrence of Pneumocystis pneumonia among new diagnoses of HIV. Conclusions: Data from numerous sources suggest an increase in the diagnosis of P. pneumonia primarily among non-HIV infected persons . The cause of this increase may be multi-factorial in aetiology. Recent changes in the microbiological methods used to detect P. jirovecii over the last few years have occurred, with many laboratories switching from immunofluorescence to PCR methods for organism detection. Further investigation into the impact of this change in diagnostic methods is required. Observed increases in the incidence of Pneumocystis pneumonia in renal transplant recipients indicate that further investigation in a range of potential risk groups is warranted.\n\nO115 Evaluation of the fungicidal activity of micafungin by flow cytometry A.P. Silva*, I. Faria-Ramos, S. Costa-de-Oliveira, C. Pina-Vaz, A.G. Rodrigues (Porto, PT)\n\nObjectives: Candida spp. is responsible for severe infections contributing to the increase of morbidity and mortality particularly of immunocompromised patients. Micafungin is a recent fungicidal drug by inhibiting the 1,3-beta-D-glucan synthetase. The standard susceptibility testing is time consuming and gives results only after 24 hours. We propose a new approach for micafungin susceptibility evaluation based upon flow cytometric assessment. Methods: Candida spp. susceptible (n = 20) and resistant (n = 8) strains to micafungin according to the CLSI protocol were assayed. Yeast cells were incubated with several concentrations of micafungin (0, 0.125, 0.25, 0.5, 1, 2, 4 Objectives: Multidrug-resistant organisms, including Extendedspectrum beta-lactamases (ESBL)-producing Enterobacteriaceae, are rapidly emerging worldwide. Contact isolation is recommended by authorities to limit spread of ESBL-however, the rate of transmission without contact isolation in the non-epidemic setting is unknown. In addition, the majority of ESBL cases are community-acquired; likely by commonly ESBL contaminated food. Therefore, we aimed to determine the rate of spread (R0) for ESBL-producing Enterobacteriaceae in a tertiary care-centre with five ICUs over an eleven-year study period using standard precautions without contact isolation. Figure 1 ). There was no evidence of infection of the two patients with ESBLproducing Klebsiella pneumoniae and E. coli, and therefore, detection was interpreted as colonization.\n\nConclusions: The estimated rate of spread of ESBL-producing Enterobacteriaceae is very low in a tertiary care University affiliated hospital with a high level of standard hygiene precautions. The low level of nosocomial transmission and the rapid emergence of community-acquired ESBL, -likely by contaminated meat or vegetables -challenge the recommendation of routine use of contact isolation in a non-epidemic setting to prevent spread. no longer used in patient care. Overflow holes became apparent in the outbreak ICU when an item list was made for the outbreak ICU and another ICU with respect to patient care, water use, type of water supply and sewage, waste disposal. These were removed, S-traps were changed, and two sinks were disconnected. New patients were identified and sinks remained positive despite strict separation between clean and wastewater and between wet and dry areas, further reinforcement of isolation measures and cleaning protocols. Only after the closure of the unit in July and August 2010 and extensive cleaning of the unit, sinks, and sewage tubes, no more EKP positive patients have been identified. On the other hand the sinks have remained positive.\n\nConclusions: Sinks can serve as an environmental source of EKP and may remain contaminated for many years. An outbreak with a low and fluctuating incidence due to an external source can remain undetected for long periods. Continuous fingerprinting of clinical isolates will lead to early detection Update in drug development S142 Antibacterial\n\nGlobal public health concern intensifies while medical science and business fail to cope with the indisputable and spreading pandemic of multi-drug resistant (MDR) pathogens. With the spread of known, as well as continuously emerging resistance mechanisms, fewer and fewer effective clinical treatment options remain and physicians often find themselves without a viable treatment option. The near absence of antimicrobial related investment in both large and small pharmaceutical companies means that the critical paucity of novel antibiotics that can be used to treat infections by MDR pathogens will continue for many years. Pharmaceutical pipelines barely trickle calling for alternative business and funding models. An intensified action plan recently introduced by the European Commission, along with joint international activities, will hopefully prime antibacterial pipelines. However, until the action plans bear fruit, several new antibacterial drugs based on known classes of antibiotics may become available in the next few years. While showing some benefit, these new analogs only partially address the clinical crisis of MDR pathogens. In this talk, we will look more deeply into how these new antibiotics will affect the clinical treatment options in the next 5-7 years. Critical time points in the course of antibiotic treatment S157 Importance of early antifungal therapy and its duration B. Barsic* (Zagreb, HR)\n\nThe fact that early antimicrobial therapy is crucial for a successful disease outcome is known since the introduction of antibiotics in clinical medicine. An universal goal is to start appropriate treatment as soon as possible. It is logical that these facts are also valid in patients with invasive fungal infections (IFI). The problem is that IFI are often not easily recognisable and that we can only suspect them in patients at risk. While prospective, randomized studies are lacking, retrospective studies used different criteria of timing, although majority defined time as a period between culture sampling and start of appropriate treatment. Despite this, results uniformly showed that delay is associated with poorer outcome. In patients with candidemia, the importance of timing was assessed analyzing the time period between the time when positive blood cultures were drawn and start of AFT. Delay in treatment \u202112 or \u202124 hours increased hospital mortality 1.5-2.06 fold. Negative impact of delayed diagnosis and consequent AFT was shown in patients with candidemia: a 24-delay in blood culture positivity would almost double the risk of patients' death. Studies in hematological patients with invasive aspergillosis or zygomycosis showed that delay of appropriate antifungal therapy (AFT) for more than 10 or 6 days after the appearance of first symptoms almost doubled the mortality rates. The negative impact of treatment delay on patients' outcome urges physicians to start AFT empirically at high-risk patients with clinically suspected IFI (empirical therapy) or after positive new diagnostic tests associated with imaging findings (pre-emptive therapy, mostly for moulds infections). To avoid overtreatment with new, expensive antifungals, rapid diagnostic tests are necessary. Background: Renal transplant recipients are at increased risk for developing invasive pneumococcal diseases, but may have a poor response to the 23-valent pneumococcal polysaccharide vaccine (PPV). The aim of this study was to compare antibody response of a sequential vaccination schedule of PPV with those of a sequential schedule of 7valent pneumococcal conjugate vaccine (7vPnC) followed by PPV twelve months later in adult renal transplant recipients. Methods: We conducted a randomized doubleblind controlled study to evaluate the quantitative serological responses to pneumococcal serotypes 4, 6B, 9V, 14, 18C, 19F, 23F, 1, 5, and 7F. Using isotypespecific ELISA, two-fold antibody response compared to baseline was determined 8 weeks after the first vaccination, before the second vaccination, and 8 weeks after the second vaccination, respectively. All patients filled out a 7-day diary after each vaccination to record systematic symptoms, to measure oral body temperature, and to determine the diameter of redness or swelling at the injection site. Of 320 screened patients, 80 patients were randomized, and 62 patients completed the study.\n\nResults: Compared to baseline eight weeks after revaccination with PPV significantly higher increases of antibody responses for serotypes 19F and 7F were seen in the PPV/PPV group than in the 7vPnC/PPV group (3.42 vs. 1.55, p = 0.049, and 5.66 vs. 2 .96 p = 0.04) respectively, A trend towards an improved response of the PPV/PPV group was also seen for serotype 9V (8.18 vs.4.28, p = 0.06) . The number of patients with seroconversion to serotype 4, 6B, 9V, 19F, 23F, 1, 5, 7F, defined as minimum 2-fold titer increase and serum concentrations of at least 1 lg/mL was greater in the PPV/PPV group than in the 7vPnC/PPV group, but significantly greater response was seen for serotype 7F only (p < 0.001). No significant difference in the percentage of patients responding to at least one serotype after revaccination with PPV was detected, 7vPnC/PPV 84.4% vs. PPV/ PPV 83.9%, p = 0.13. Conclusion: Although, higher immune response was seen in the PPV/ PPV than in 7vPnC/PPV group, significant increase in antibody response was seen for two serotypes only.\n\nO162 Antibody response to polysaccharide anti-Streptococcus pneumoniae vaccine in relation to the selected immunological parameters of patients with chronic lymphocytic leukaemia E. Grywalska*, I. Korona-Glowniak, A. Malm, J. Rolinski (Lublin, PL)\n\nObjectives: The aim of the present study was to investigate antibody response to vaccination against pneumococcal polysaccharide and to assess its relation with the selected parameters which may act as prognostic factors of vaccine effectiveness in chronic lymphocytic leukaemia (CLL) patients. Although vaccination against Streptococcus pneumoniae is recommended for immunocompromised patients, its protective effect and predictors for the response are not sufficiently characterized.\n\nMethods: This prospective study included 25 previously untreated patients with CLL. All individuals received 23-valent capsular polysaccharide pneumococcal vaccine (PPV23). A response to vaccination, according to the manufacturer's instructions, was defined as 2-fold increase between repeated tests (pre-vaccination, and day 30 post-vaccination) in the same patient. The anti-pneumococcal antibody concentration against pooled 23-vaccine serotypes was determined by ELISA. Blood samples were collected and values of peripheral blood cell count parameters and immunoglobulin (IgA, IgM, IgG) levels were measured using standard methods. In order to assess lymphocyte subpopulations, peripheral blood mononuclear cells were separated on lymphocyte separation medium and stained with combination of relevant fluorescein isothiocyanate (FITC) -phycoerythrin (PE) -and CyChrome-labelled monoclonal antibodies and analyzed using flow cytometry method.\n\nResults: The lack of PPV23 effectiveness was observed in 20 patients (80%). Mann-Whitney-U test revealed that among patients who did response to vaccination, there were statistically significant higher levels of IgG (p = 0.007) and IgM (p = 0.021), and lower absolute counts of CD5+ CD19+ (p = 0.000), CD3+ (p = 0.036), CD19+ (p = 0.024), CD3+ CD4+ (p = 0.007), CD3+ 25+ (p = 0.000), NKT (p = 0.010), CD4+ CD25+ HIGH (p = 0.028) cells as well as lower CD4 to CD8 ratio (p = 0.016). Moreover in those cases, where vaccine efficacy was noted, the median time elapsed from CLL diagnosis to the vaccination was significantly shorter (p = 0.005). An analysis with the use of the decision tree method showed that all patients with the CD5+ CD19+ cells percentage higher than 47% did not response to the vaccination ( Figure 1 ). There was a strong correlation between the percentage of CD5+ CD19+ cells and the elapsed time from CLL diagnosis (r = 0.546, p = 0.007).\n\nConclusions: Vaccination should be given as soon as the diagnosis of CLL is made. Determination of post-vaccination antibody levels has to become a standard in patients with CLL.\n\nO163 Cost-effectiveness of adult vaccination with 13-valent pneumococcal conjugate vaccine in the United Kingdom A. Charos*, V. Barzey, A. Lloyd, P. Balmer (Walton Oaks, London, UK)\n\nObjectives: Pneumococcal disease (PD) burden remains high among the elderly and, in particular, among those considered to be at high-risk of pneumococcal infection. It is anticipated that indirect protection from paediatric vaccination with Pneumococcal Conjugate Vaccine (PCV13) will reduce the burden of PD in adults over time, however at-risk groups aged \u202118 years and individuals aged \u202165 years who are at high risk of PD will benefit from direct protection. The study objective was to assess the cost-effectiveness of PCV13 vs. the 23-valent pneumococcal polysaccharide vaccine (PPSV23) adult vaccination in the United Kingdom (UK).\n\nMethods: A dynamic cohort model was developed depicting the lifetime risks and associated costs of PD. The model used timedependent serotype specific PD incidence rates to account for the indirect effects from infant vaccination with PCV13 and to estimate only the incremental benefits of adult vaccination. Disease cases were estimated using 2009/10 UK incidence, vaccine effectiveness, and indirect effects. Vaccine effectiveness for PCV13 was based on data for PCV7 in children adjusted for age and risk profile, assuming similar levels of effectiveness against the additional six serotypes. PPSV23 effectiveness was based on an analysis by the Health Protection Agency. The analysis uses a UK NHS payer perspective, therefore only direct costs and outcomes were included. Health outcomes were measured in terms of quality-adjusted life year (QALY). Cost and outcomes were discounted at a 3.5% annual rate. Assumptions and parameter uncertainty were tested in sensitivity analyses. Results: It is estimated that adult vaccination with PCV13 instead of PPSV23 is cost-effective at the current NHS list price. Despite uncertainty around individual parameters, sensitivity analyses suggest that results were robust and PCV13 adult vaccination would be costeffective due to the high risk of pneumococcal infection among these groups.\n\nConclusion: Under reasonable assumptions, direct protection from adult vaccination with PCV13 is expected to be cost-effective even when considering the potential herd impact from PCV13 use in infants. Prompt introduction of PCV13 adult vaccination is likely to be a more efficient use of NHS resources as direct adult vaccination will reduce the remaining PD burden more rapidly. Objectives: Deep sternal wound infection (DSWI) following cardiac surgery occurs in 0.5-3% of patients, is frequently attributable to Staphylococcus aureus, and is associated with increased morbidity/ mortality. A novel vaccine candidate (V710) containing the highly conserved S. aureus surface protein iron surface determinant B (IsdB) was shown to be immunogenic and generally well-tolerated in both healthy and immunocompromised subjects. The purpose of this study was to evaluate the efficacy and safety of V710 in preventing S. aureus bactaeremia and/or DSWI in patients undergoing cardiac surgery.\n\nMethods: This group-sequential, randomised, multicentre, doubleblind, placebo-controlled study evaluated the immunogenicity, safety and efficacy of a single intramuscular 60 lg dose of V710 in patients \u202118 years old scheduled to undergo full median sternotomy within 14-60 days of vaccination. The primary efficacy endpoint was prevention of S. aureus bactaeremia and/or DSWI, including mediastinitis, through postoperative Day 90. Secondary endpoints were all invasive infections and surgical-site infections caused by S. aureus through postoperative Day 90. This was an event-driven study, with the estimated total enrolment (N~15 000) based on the number of subjects required to accrue 107 primary efficacy endpoints. Three interim analyses, including futility assessments, and one final analysis of vaccine efficacy were planned. Results: At the recommendation of the independent Data Monitoring Committee the Sponsor terminated the study after the 2nd interim analysis (N = 7983 subjects randomised and vaccinated) based on efficacy and safety results. V710 was not significantly more efficacious than placebo for preventing either the primary or secondary endpoints. V710 was associated with a significantly higher incidence of vaccinerelated injection-site adverse events (AEs) (19% vs. 9%) and systemic AEs (17% vs. 15%), but with no significant difference in systemic vaccine-related AEs or serious AEs. There was a marginally significant increase in multi-organ failure in the vaccine recipients compared with the placebo group (rate per 100-person-years: 0.9 vs. 0.5; p = 0.042), but there was no significant difference in all-cause mortality (Table) . Table. Efficacy and safety summary.\n\nThe efficacy and safety data from this trial do not support the use of V710 in preventing S. aureus bactaeremia and/or DSWI in patients undergoing cardiac surgery utilising a median sternotomy. Objectives: Pertussis (PT) incidence has steadily increased in the United States since the 1980s. Mortality is the highest in children 3 months of age or younger. Incidence of PT quadrupled from 2000 to 2005 and was highest among those younger than 6 months. Because the first PT vaccine is recommended for administration in children at 2 months of age in the US, vaccination of persons caring for or exposed to infants is recommended to decrease transmission and thereby incidence of PT in this at-risk age group. At our rural hospital, opportunities are available to address the vaccination status of patients and a mechanism for administering pneumococcal and influenza vaccines is available. However, no assessment tool or mechanism was available for the nurses to determine appropriateness and administer PT vaccine without a physician order. To increase compliance with the Centers for Disease Control and Prevention (CDC) recommendations, a tool was developed for nurses to assess a patient's eligibility for PT vaccination and to order vaccine. After education sessions, the tool was implemented for the maternity ward in July 2011. The overall objective of this study was to examine the impact of the tool on the rate of vaccination for PT among post-partum women.\n\nMethods: The number of doses of PT vaccine ordered and administered was recorded monthly from January 2010 to October 2011. The number of doses ordered and billed was used as a surrogate marker for the number of doses administered to patients. A comparison of the preimplementation period (January 2010 to June 2011) was made to the post-implementation period (July-October 2011) and trends were noted. The number of admissions to maternity was also recorded per month and the number of doses per admission was calculated. Statistical analysis for homogeneity was done.\n\nResults: In the pre-implementation period, there were 320 doses ordered in 18 months (18 doses/month). In the post-implementation period, there were 500 doses ordered in 4 months (125 doses/month). The number of doses per admission for the pre-implementation period was 0.05 and in the post-implementation period was one. The number of doses billed and ordered were the same. Analysis indicated a significant increase in the number of doses ordered and billed in the two time periods. Conclusions: The tool significantly increased the number of patients vaccinated for PT in our rural hospital in accordance with the CDC guidelines.\n\nO166 Anti-pertussis toxin IgG antibody response and decay following primary and preschool vaccination with an acellular pertussis vaccine in UK infants and children using a modified oral fluid assay Background: Immunisation with pertussis vaccine can confound diagnostic assays detecting anti-pertussis toxin (PT) IgG in sera/oral fluid (OF) from cases with >2 week history of cough. In the absence of UK data we have used 1 years as the time interval before which results are considered potentially confounded. We sought to better define this interval by following infants/children post-vaccination using the OF anti-PT IgG capture ELISA assay. A threshold of \u202170 aU is considered indicative of recent infection. Objective: To model the decline in titres in arbitrary units (aU) to estimate the positive predictive value (PPV) of the assay and assist interpretation of results from OF/serum samples submitted for diagnostic purposes.\n\nMethods: The original OF assay was modified using PT from a commercial source and an anti-PT monoclonal detection antibody. Oral fluid swabs were collected at ca.1 month intervals from subjects following administration of DTaP primary or pre-school booster (PSB). For the post-primary analysis, swabs were taken up to 280 days following the third dose as well as on the date of the third dose and for the PSB analysis shortly after the dose then at intervals up to ca. 380 days after. Total IgG was also measured because this may impact the assay with potentially lower aU titres when total IgG is low (<1 mg/ mL). Results: Results were available for 72 infants post-primary vaccination who had 1-9 samples taken with valid titres (515 results). Results were also available for a total of 121 post-PSB results with 5-13 samples with valid titres (1253 results). The decline in titre was modelled by taking log [10] (titre) and performing regression analysis of this against time. For the primary post-third dose the relationship showed reduction of 54% for each doubling of time. For post-PSB titres reached were higher and reduction slower at 34% per doubling of time. Assuming prevalence of 0.3, post-primary data showed high (95%) PPV by 282 days post-vaccination post-PSB data showed PPV of 86% at 1000 days (at the threshold). Evidence of reduced titres was found only when total IgG was very low (<0.5 mg/mL). Conclusions: Modelling post-vaccination titres allowed calculation of the PPV of the assay and correction for low total IgG. By estimating prevalence, the interpretation of post-vaccination titres can be expressed with PPVs. Further work to determine the distribution of titres above the threshold will assist the interpretation of these results. Objectives: Group B streptococcal (GBS) infection is the leading cause of bacterial infections during pregnancy and newborn mortality. The existence of ten capsular serotypes among GBS strains has produced challenges in development of an effective polysaccharide vaccine. In this study various combinations of five recombinant polypeptides exhibiting immunogenic and protective properties have been examined in the neonatal mouse model. Furthermore the advantage of pentavalent polypeptide vaccine has been demonstrated.\n\nMethods: Recombinant polypeptides were constructed based on Bac, ScaAB, SspB1, ScpB and CspA. PCR-generated DNA fragments were cloned and expressed in E.coli. Three different mixtures of the polypeptides including two and five components were administered subcutaneously in female mice with alum adjuvant. Immunogenicity was evaluated by ELISA using anti-mouse IgG conjugated with HRP. GBS 5/70 strain serotype Iac was used for intraperitoneally challenge in newborn pups. Results: After cloning of the DNA fragments the appropriate recombinant polypeptides were successfully expressed and purified. The immunized mice were bred after the polypeptide vaccine booster. The offspring of all groups was infected intraperitoneally with GBS and monitored during next 3 days. Within 24 hours 100% of the newborn mice mortality was registered in the control group. 13% and 22% offspring survived in the groups of the mice immunized with two component vaccines. Meanwhile, 50% offspring survivals from the mice immunized with five component vaccine were noticed. IgG against all five components was detected in the females blood during immunization period as well as after mouse breeding. The IgG titer was estimated from 1:3, 2 \u00b7 10^4 to 1:1.0 \u00b7 10^6 depending on the recombinant polypeptide. IgG level against the individual components was at least two times higher after the administration of the five component vaccine in comparison with the two component ones. Specific IgG against vaccine components was also found in the blood of the surviving pups which might indicate the protective effect of maternal IgG.\n\nThe study has demonstrated the advantage of the pentavalent polypeptide vaccine: 50% neonatal mouse protection against GBS challenge and synergistic effect of specific IgG production. The study was supported by RFBR grant 10-04-00750a. , all proven cases, mostly within two months after diagnosis (n = 10, 59%). Twelve of these (71%) had preexisting risk factors for chronic Q fever. Only in five patients (29%) an episode of acute Q fever was diagnosed. Four deceased patients (24%) had endocarditis, 12 (71%) had vascular infection, and one patient (6%) had an unknown infection focus. These data show that mortality is 9% overall and 20% in proven cases. In proven cases, mortality of vascular Q fever infection is 24%, compared to 17% mortality for endocarditis, although this difference was not significant (p = 0.76). Conclusion: In the Netherlands, in contrast to reports from other countries, chronic Q fever manifests mainly as vascular infection, rather than endocarditis. Mortality of chronic Q fever is high: 9% overall and 20% in proven cases, which warrants awareness by clinicians. As an acute Q fever episode was diagnosed in only 29% of fatal proven chronic Q fever cases, screening programmes in high risk groups seem to be justified. Objectives: Early intervention including timely antibiotics in patients with severe sepsis on admission to hospital improves survival, but less is known about patients who develop sepsis in hospital and the potential to improve their care. The aim of this study was to develop and implement an intervention to improve care for these patients in an acute NHS hospital. Methods: Patients developing sepsis were identified prospectively by screening patients who had blood cultures taken in medical, surgical and orthopaedic wards. The primary study outcome measure was the proportion of septic patients that received antibiotics within four hours of sepsis onset. Baseline data were collected from Sept 08-Feb 09 and post-intervention from Oct 09-Mar 10. The design of the intervention was informed by the baseline clinical data and the findings of a questionnaire and interview survey of junior medical staff. A multifaceted intervention consisting of education, a care pathway, and audit and feedback was developed. The effect was evaluated by segmented regression analysis of interrupted time series (ITS) data. Results: Among the 241 baseline patients, only 91 (38%, 95%CI 32-44%) received antibiotics within 4 hours. The mean and median times to administration were 11.0 hours (95%CI 9.3-12.7 hours) and 6.0 hours (IQR 2.5-13.3 hours) respectively. Problems identified in the clinical data, and in the findings of 147 questionnaires (35% response rate) and ten interviews with junior doctors, included delays in the recognition of sepsis and in clinical decision-making. Post-intervention, 139/297 (47%, 95%CI 41-52%) patients met the primary outcome measure of antibiotics within 4 hours of sepsis onset and the 9% increase from baseline was statistically significant (X2 test p = 0.04). Run charts of the data pre-and post-intervention ( Figure) suggested a chaotic process and formal run chart analysis indicated nonrandom variation. Segmented regression analysis of ITS data did not show a statistically significant intervention effect (p value for change in level = 0.91, and for change in slope = 0.21).\n\nThe management of patients with sepsis in our hospital leaves room for improvement. Descriptive analysis indicated that this intervention had some effect, but this was not confirmed as a statistically significant intervention effect in ITS analysis. Further rigorous research informing quality improvement in this area is required.\n\nO172 Prognosis of bacteraemia in the very elderly: a prospective multicentre cohort (43% vs. 6%, p < 0.001) and presentation with severe sepsis or shock (59% vs. 17%, p < 0.001). At day-30, fluoroquinolone-resistant gram negative pathogen (40% vs. 17%, p = 0.04) was also associated. The sources associated with higher 14-day and 30-day mortality were: abdominal (40% and 60%, respectively), unknown (34% and 41%), respiratory (23% and 31%); these were considered as high risk sources in the multivariate analysis. For the most prevalent pathogens, 14-day and 30-day mortality were: E. coli (14% and 23%), coagulase-negative staphylococci (24% and 28%), S. aureus (18% and 36%), and K. pneumoniae (0) . In the multivariate analysis variables associated with mortality at day 14 were: high risk source (OR = 7.9, 95% CI = 1.8-33.9), Pitt score \u20212 (OR = 5.6, 95% CI = 1. 3-23.3) , inadequate empirical treatment (OR = 11.24, 95% CI = 1.6-80.2) and severe sepsis or shock at presentation (OR = 5.3, 95% CI = 1.4-20.7). In this model, an interaction between empiric treatment and high risk source was significant. At day 30, mortality was independently related to a high risk source (OR = 2.92, 95% CI = 1.1-7.5) and the presentation with severe sepsis or shock (OR:=3.81, 95% CI = 1.2-12.4).\n\nConclusions: Presentation with severe sepsis or shock and a high risk source of BSI were independent predictors of 14-day and 30-day mortality in VEP. Inadequate empirical treatment was also a predictor of early mortality in patients with high risk source. Other factors linked to treatment failure were severity of disease, co-morbidities and recurrence. Patients with treatment failure of the initial antibiotic had a longer mean hospital stay than those without (15.3 vs. 10.9 days) and a higher proportion were admitted to ICU (21.3% vs. 9.0%). Treatment failure was also associated with septic shock, and a higher proportion of patients with treatment failure required mechanical ventilation (21.8% vs. 8.9%), blood pressure support (fluid resuscitation: 19.6% vs. 8.0%) or parenteral nutrition (7.3% vs. 3.0%), and suffered acute renal failure necessitating replacement therapy (4.6% vs. 0.9%). There were no major differences in use of resources between patients with comorbidities and those without, although length of hospital stay was slightly longer in patients with co-morbidities (13.3 vs. 10.0 days).\n\nConclusions: Treatment failure with initial IV antibiotic in patients with CAP and HCAP results in increased resource use compared with no treatment failure. Adequate initial antibiotic treatment will minimise treatment failure and prevent associated increases in resource consumption. Objectives: It is important to detect the etiologic agent by the rapid diagnostic tests with high sensitive and specificity rates. Etiologic results may be learnt in less than hours with the new molecular diagnostic tests, therefore a proper antimicrobial therapy for the pneumonia can be managed early. This early targeted therapy can avoid the adverse reactions and the increased resistance profile of unnecessary antimicrobials and decrease the total cost. In this study it was aimed to evaluate the bacterial and viral etiology of CAP with polymerase chain reaction. Results: The rate of the specific agent detection with either conventional methods or PCR in the patients with community acquired pneumonia was 100%. S. pneumoniae was the most common agent (78%) similar with previous studies (Table 1) . Fifty four percent of the patients had more than one pathogen with mostly H. influenzae and rhinovirus. The viral agents which have increasing popularity in the last years were detected with a high ratio (36%) in our study (Table 2 ). They were detected as single agent in two patients and as concomitant agent in 16 patients. Unexpectedly, the most common viral agent was Rhinovirus. Coronavirus and Human Metapneumovirus were detected in one patient each.\n\nConclusion: PCR increased the ability to delineate the etiology upto 100% of CAP cases who had not used antibiotics in the previous 24 hours. These are the first data related to newly discovered viruses such as Human Metapneumovirus, coronavir\u00fcs 229E/OC43, Bocavirus in Turkey. In addition these data suggest that mix infections are more common than they are expected in CAP requiring hospitalization. We suggest the usage of the molecular diagnostic tests in lower respiratory tract infections. The human bocavirus was initially discovered in 2005 as the second pathogenic member of the parvovirus family, next to the human parvovirus B19. HBoV has since been shown to be extremely common worldwide and -to cause a systemic infection in children and adults often resulting in respiratory or gastrointestinal disease. Parvoviruses are assumed to replicate via their genomic terminal hairpin-like structures in a so-called rolling-hairpin model, resulting in head-to-head or tail-to-tail intermediates. Surprisingly, in case of HBoV-1, we identified head-to-tail intermediates in clinical samples that are not compatible with the rolling hairpin model but are a typical feature of the classical rolling circle replication. A further study by Kapoor and co-workers (2011) confirmed our observation and extended the conclusion as those head-to-tail structures may originate from episomal genomes that persist in the infected host cell.\n\nIn concert with a clinical case recently described by our group, the hypothesis of episomal persistence following rolling circle replication seems a likely explanation. In the described case a child suffering from an autoimmune disease unable to produce an antibody response was infected with HHV6 and coinfected by HBoV. The HBoV shedding was discontinued after cidofovir therapy that successfully suppressed HHV6 titres to levels below the detection limit. The simultaneous disappearance of HBoV and HHV6 may be interpreted as a dependency of HBoV DNA replication on the presence of a herpesviral replication machinery, that in turn is able to initiate rolling circle replication in cis and in trans. Moreover the underlying autoimmune disease gives raise to the hypothesis that the HBoV infection was limited directly or indirectly by the cidofovir treatment rather than by a reconstituted immune response previously shut down by the HHV6 infection. Moreover it appears that HBoV contributes to chronic lung diseases as we observed an association of HBoV with lung fibrosis in several cases, as identified by the Luminex RVP assay. Thereby it remains unclear to which extent the clinical course was aggravated by HBoV or caused by HBoV persistence in turn inducing chronic inflammation resulting in fibrosis. Thereby, one patient suffered from a co-infection with CMV, another herpesvirus potentially acting as a helpervirus and thus supporting the hypothesis that HBoV may alternatively replicate in a rolling circle mechamism supported by helper viruses. Objectives: Paediatric liver transplant (LTx) patients (pts) are at particular risk of developing EBV -related posttransplant lymphoproliferative disorders (PTLD). The risk of PTLD is higher in pts with high viremia. However, among transplant recipients is a group of pts with chronically high viral load (CHVL) who do not develop lymphoproliferations, so there is a need for new prognostic markers to define pts at risk of serious complications. Polymorphism within cytokine genes, might contribute to the pathogenesis of the disease. IL-12 plays a key role in anti-viral immune response. The A-to-C substitution within IL12B gene (SNP rs321227) affects the IL-12p40 production. The aim of the study was to analyse the polymorphism of IL-12p40 with regard to CHVL carriage in paediatric pts after LTx. Methods: One hundred seventy nine children after LTx were included in the study (median age at LTx 1.3 years, range 0.1-18). All pts were followed up for at least 12 months after LTx (median 30, range12-139). A group of 38 pts with CHVL (i.e. the presence of EBV DNA level >4000 copies/lg DNA in >60% of blood samples for min. 6 months) was selected. The remaining 141 pts with moderate or undetectable viremia consisted a control group. IL12B was genotyped by RFLP-PCR. The association between IL12B genotype and CHVL was analysed by multivariate logistic regression adjusting for confounders. To analyse the impact of IL12B polymorphisms on the length of CHVL carriage (defined as the time between 1st EBV DNA level >4000 copies and first two consecutive values below this level), the proportion of pts with persistent high viremia over 24-months period was assessed for each genotype. The Kaplan-Meier curves were compared using the log-rank test. The Cox proportional hazards model was adjusted for tacrolimus level.\n\nResults: Significantly increased frequency of AC genotype was found in CHVL carriers compared to controls (46.9% vs. 23.2%, respectively, OR = 3.5, 95% CI:1.4 -9.1, p = 0.002). Time-to-CHVL resolve analysis, revealed a relationship between IL-12p40 genotype and the length of CHVL-carriage. Significantly lower proportion of patients with AC genotype resolved high EBV DNA load at 24 months after the onset of CHVL carriage, when compared to dominant AA genotype, (53% vs. 81%, p = 0.01; Figure) .\n\nConclusion: Polymorphism within IL-12p40 gene might contribute to high EBV DNA load persistence in paediatric pts after LTx, which in turn influence the risk of PTLD development. Objective: Cytomegalovirus (CMV) is one of the most frequent opportunistic pathogens and a substantial cause of morbidity and mortality in immunosuppressed patients (pts). Polymorphism within cytokine genes may influence the susceptibility and the clinical course of infectious diseases. The immunogenetic factors influencing outcome of CMV infection in paediatric liver transplant recipients (LTx) have been little investigated. The aim of this study was to assess the polymorphisms in selected cytokine genes that my impact on CMV reactivation in children after LTx. Methods: One hundred twenty-six paediatric pts after LTx (median age at LTx 1.3 years, range 0.1-18.0) were included in this study. All pts were CMV seropositive prior to LTx and 105/126 pts received graft from a positive donor (in 21 pts -donor was negative). All children were followed up for at least 12 months after LTx (median 29, range 12-111 months). CMV reactivation (defined as positive CMV DNA in blood) was detected in 91/126 pt within 1st year post-LTx. The remaining 35 pts had undetectable CMV DNA for at least 12 months. Polymorphisms of: TNF-alpha -1031 T/C (rs1799964), TNF-alpha -308 G/A (rs1800629), TNFRI -201 C/A (rs4149570) IL-1 beta -511 C/T (rs16944), IL-1 beta +3954 C/T (rs1143634), IL-10 -1082 A/G (rs1800896), IL-10RA +5964 C/T (rs4252270), IL-12p40 3'UTR (rs3212227), IFN-gamma +874 A/T (rs2430561) MCP1 -2518 A/G (rs1024611) MCP1+ 1543 C/T (rs13900), CCR5del32 and IL-1RN VNTR, were analysed in all pts. The association between cytokine polymorphisms and CMV reactivation after LTx was assessed by multivariable logistic regression adjusting for potential confounders.\n\nResults: Significantly decreased frequencies of IL-1beta -511 CT and TT genotypes were found in pts with CMV reactivation compared to pts without CMV DNAemia after LTx (43% vs. 70%, OR = 0.34, 95% CI:0.13-0.88, p = 0.02). In addition, significantly overrepresented heterozygous TNFRI -201 CA genotype was detected in children who experienced CMV reactivation compared to CMV DNA-negative pts (53% vs. 23%, OR = 4.1, 95% CI: 1.4-11.6, p = 0.005). The rest of the polymorphisms analysed showed no significant association with virus reactivation.\n\nConclusion: Genetic polymorphism within IL-1beta and TNFRI genes may contribute to CMV reactivation in children after LTx. In addition, carriers of IL-1beta-511 CC and/or heterozygous TNFRI -201 genotype may especially benefit from anti-viral prophylaxis. Background: There are still controversies in the importance of several common human viruses and unexplained dilated cardiomyopathy, partially due to lack of standardized and reliable quantitative detection molecular assays in cardiac tissues.\n\nObjectives: To evaluate new reliable molecular assays in order to confirm the prevalence of several viral infections and to assess the viral genomic load levels in heart tissues.\n\nMethods: Fifty-two fixed explanted or post-mortem myocardial samples were obtained from 24 patients with idiopathic dilated cardiomyopathy (DCM). Control samples were collected from 14 adult patients who died accidentally or by committed suicide. Viral genomes (RNA/DNA) were detected and semi-quantified using broadrange PCR amplification assays coupled to electrospray ionization/ time-of-flight mass spectrometry analysis (PCR/ESI-TOF MS) and by classical quantitative real-time PCR (Q rt-PCR) assays. Results: Sixteen (67%) of the 24 DCM patients were positive for single or multiple viral genome detection (HHV6 = 1 (4%); Human Enterovirus (EV) = four (17%); PVB19 = five (21%); EV-PVB19 = six (25%)) and correlating well with EV and PVB19 detection by classical Q rt-PCR assays (kappa tests = 0.69 [0.44-0.92 Objectives: Dengue is an arthropod-borne flavivirus with worldwide distribution. Persistent infection has been described in other flaviviruses such as West Nile virus (WNV) and hepatitis C virus (HCV). Our group has recently reported live dengue virus persistence in urine during convalescence. Here we demonstrate that viral persistence is not only prolonged, but also ''differential'' in body compartments. Methods: Specimens from eleven adult patients with acute DEN2 infection by standard ELISA and serotype-specific reverse transcription PCR were included in this study. Viral RNA extracted from plasma, peripheral blood mononuclear cells (PBMCs), saliva and urine during febrile and convalescent periods was subjected to dengue-specific SYBR Green real time quantitative RT-PCR. Serial dilution of known concentration of DENV-2 (PFU/mL) was constructed as standard curve to determine the amount of viral shedding in each sample. Viral load of each sample was compared in the unit of PFU/microgram RNA. Results: All patients were secondary dengue infection. Ten were DHF (DHF I = 4, DHF II = 6) and the other was DF. Dengue virus was detected in both febrile and convalescent periods in nine of 11 patients. The viral RNA was detected in plasma (n = 9), PBMCs (n = 11), saliva (n = 8) and urine (n = 8) during febrile period and in plasma (n = 2), PBMCs (n = 1) and urine (n = 8) during convalescence. The viral loads shifted among samples and time points of infection. During the febrile period, viral loads in blood sample (plasma or PBMCs) were higher than those in saliva and in urine as well as those in convalescent samples. Interestingly, the viral loads in urine during late febrile phase were higher than those in the blood samples. Moreover in some patients, the viral loads in convalescent urine were higher than those in all corresponding febrile samples. Objective: Virus-mediated cell-to-cell fusion is a hallmark cytopathic effect accompanying infection by several enveloped viruses. While virus-to-cell fusion during entry has been extensively studied, little is known about cellular pathways involved in the process of cell-to-cell fusion. The non-enveloped reovirus fusion-associated small transmembrane (FAST) proteins are the smallest known membrane fusion proteins. Unlike enveloped virus fusogens, FAST proteins are non-structural and are not involved in virus entry. Their sole function is to induce syncytium formation following infection, making them an ideal model for the study of cellular pathways involved in syncytiogenesis. In this study, we conducted a comparative, temporal analysis of FAST protein-and influenza hemagglutinin (HA)-mediated cell-to-cell fusion in order to determine whether viral proteins designed for entry and those designed for cell-to-cell fusion elicit a similar response during fusion pore expansion and syncytium formation. Methods: HA and p14-FAST were transfected and HA fusion was triggered by trypsinization and incubation of cells at pH4.8. Pore formation was monitored by transfer of a cytoplasmic fluor between quail fibroblasts and Vero epithelial cells. Syncytium formation, quantified by counting syncytial nuclei, indicated pore expansion. In addition, we developed a novel method to analyze pore expansion by adding the membrane curvature agent lysophosphatidylcholine (LPC) during our temporal analysis of syncytium formation. Results: We report that while LPC does not inhibit FAST protein mediated pore formation, it does inhibit pore expansion resulting in a reversible ''stalled pore'' phenotype. In contrast, LPC inhibits both HAmediated pore formation and pore expansion, this ''stalled pore'' phenotype is also reversible. This is the first example of syncytium development arrest following a membrane fusion event.\n\nConclusion: While the fusion reactions instigated by enveloped virus and non-enveloped virus cell-to-cell fusogens differ, the syncytium formation stage is likely similar, and is a cellular response to an assault on the plasma membrane. By stalling pore expansion, we isolated a celldependent stage of cell fusion and showed that the FAST model mimics the effects of envelope virus-induced syncytium formation. Using this system, we identified several cellular proteins involved in syncytium formation, which are currently under investigation in our laboratory. Objectives: Noroviruses are estimated to cause 80-95% of all gastroenteritis cases worldwide, representing a considerable public health burden. The genotype GII.4 lineage is predominant in healthcare settings. The nucleotide sequence of the capsid P2 domain has been used to discriminate outbreaks. The aim of this study was to use whole genome sequencing to provide detail to elucidate transmission events within outbreaks. Methods: Nineteen complete norovirus genomes were determined by Sanger sequencing. These represented five separate outbreaks and two unlinked individuals, submitting samples between Jan 2010 and June 2011. Detailed corresponding epidemiological data was collected. The BEAST (Bayesian evolutionary analysis by sampling trees) package was used to reconstruct relationships and determine the rate of evolution within the defined timeframe. Results: The 19 complete GII.4 genomes (7560 nucleotides (nt) with 569 single nucleotide polymorphisms (SNPs)) were included in our analysis. The rate of evolution was estimated at 5 \u00b7 10-3 mutations per site per year (~3 mutations/genome/month), comparable with recent reports of rates between 4.3-9.0 \u00b7 0-3 mutations per site per year, calculated using Bayesian analysis of the GII.4 capsid (1623 nt) and polymerase (247 nt) fragments of the genome. Isolates within four of five outbreak clusters were identical according to the capsid P2 domain (455 nt) sequence alone. However, all but four isolates had one or more SNPs by whole genome sequencing (WGS)(see figure) . WGS confirmed one cluster of 5 isolates containing four identical isolates and the fifth containing only two SNPs. In the four clusters each containing identical P2 domains, WGS revealed 2, 10, 13 and 24 SNPs within each cluster suggesting that these were part of larger ongoing outbreaks.\n\nConclusion: Complete genome sequences, combined with detailed epidemiological data, provide sufficient resolution to identify transmission within hospital. The conventionally used P2 domain, however, is not adequate to discriminate between closely related isolates within outbreaks. Next generation sequencing technology will allow large numbers of whole genomic sequences to be generated rapidly informing ''real time'' outbreak control. Methods: A prospective surveillance of viral aetiology of febrile children with acute respiratory tract infections was conducted since May 2010. Two throat swabs were obtained concomitantly with an inform consent. One was sent for conventional viral isolation and the other for detecting adenovirus infection by an in-house real-time polymerase chain reaction (PCR) and subsequent sequence-based typing. The cases were divided into adenoviral and non-adenoviral groups. In addition, their medical records were reviewed. Appropriate statistics were adopted to compare the results of each group. A p value of <0.05 was considered statistically significant.\n\nResults: A total of 160 febrile children (84 male) were enrolled between May 2010 and July 2011. Viral aetiologies were identified in 72 cases by conventional cultures, including adenovirus (n = 51), coxsakievirus A9 (2), coxsakievirus B5 (5), echovirus (1), enterovirus (5), HSV type 1 (2), influenza A virus (3), parainfluenza virus type 1 (2) and parainfluenza virus type 2 (1). In addition to the 51 culture-positive adenoviruses, two additional culture-negative adenovirus infections were identified by the real-time PCR. All the nonadeno-cultures were PCR negative. Based on the partial hexon sequence typing, adenovirus type 3 (Ad3) was the predominant type (69.8%), followed by Ad2\n\n(1.9%) and 4 unclassified Ads (7.5%). Comparing the laboratory findings between the adenoviral (n = 53) and non-adenoviral (n = 107) groups, significantly higher leukocyte counts, higher neutrophil counts and higher CRP levels were in the adenoviral group (p < 0.001).\n\nConclusion: The in-house developed real-time PCR is comparable to the traditional culture method in detecting adenoviral infections. The Ad3 is the major type of the 2011 adenoviral epidemic in Taiwan and the spectrum of laboratory findings are different.\n\nPositive thinking now: infection management in practice S193 From antimicrobial PK/PD considerations to bedside applications in Gram-positive infections\n\nSeveral antibiotics are available for the treatment of serious Grampositive infections. Each agent has distinct pharmacokinetic and pharmacodynamic properties, which aid their differential use in clinical practice.\n\nVancomycin has been historically important for the intravenous (i.v) treatment of severe Gram-positive infections, especially when other treatments have failed and when bactericidal activity against resistant bacteria is needed. Its widespread use and the tendency for underdosing have led to the problematic emergence of reduced bacterial suscepti- [3] . Linezolid is a bacteriostatic antibiotic and, although well tolerated in the short term, all patients should be monitored because of the risk of myelosuppression and treatment should not extend beyond 28 days [3] . Appropriate selection and optimised use of these antibiotics for different clinical circumstances will promote the best patient outcomes and reduce the likelihood of development of resistance.\n\n[ . The impact of MSSA BSI is unquantified but is likely to be much larger. Using case-based discussion in an interactive session with the audience, this presentation will explore the common clinical conundrums associated with the management of S. aureus BSI. These conundrums include: initial empirical therapy for suspected BSI; definitive antimicrobial therapy; role of combining antistaphylococcals; source control; value of therapeutic drug monitoring; laboratory support and susceptibility testing; ongoing management; and monitoring implications for outcomes. Finally, the role of antibiotic stewardship in the management of S. aureus BSI will be addressed.\n\n[1] ECDC/EMEA Joint Technical Report. The bacterial challenge: time to react. 2009; doi 10.2900/2518\n\nAdaptation of P. aeruginosa to acute and chronic infections S206 Mutation, adaptation, and antibiotic resistance in P. aeruginosa chronic infections\n\nPseudomonas aeruginosa is one of the most frequent and severe causes of acute nosocomial infections. No less concerning, chronic respiratory infection by P. aeruginosa is the main cause of morbidity and mortality in cystic fibrosis (CF) and a frequent complication of other respiratory diseases such as chronic obstructive pulmonary disease (COPD) or bronchiectasis. Due to a complex multifactorial adaptive process, once established, P. aeruginosa chronic infections are almost impossible to eradicate with antibiotics. The underlying factors driving this situation include (i) the transition from the planktonic to the biofilm mode of growth, associated with a significant reduction of antimicrobial susceptibility, (ii) the extraordinary capacity of P. aeruginosa for acquiring resistance to nearly all available antibiotics through a complex interplay of intrinsic and mutation-driven resistance pathways, (iii) the intense genetic adaptation and phenotypic diversification process taking place within the CF lung and (iv) the frequent emergence and fixation of mutator phenotypes, often resulting from a nonfunctional DNA mismatch repair system caused by the inactivation of mutS or mutL genes leading to increased (up to 1000-fold) spontaneous mutation rates. Moreover, results from recent research argue that the four factors are intimately interconnected and act synergistically to establish life-long persistent infections that are highly recalcitrant to the activity of antimicrobial agents: the biofilm mode of growth is found to facilitate development of mutation-driven resistance, selection of mutators, genetic adaptation and phenotypic diversification; conversely, mutator phenotypes are shown to significantly enhance mutation-driven resistance, biofilm development, genetic adaptation and phenotypic diversification.\n\nDiagnosing fungal diseases: future perspectives S217 Epidemiology of IFIs: an update\n\nThe growing number of immunocompromised patients could account for the increased number of invasive fungal infections (IFIs) detected. However, the use of corticosteroids, intravascular devices, and other aggressive procedures may also be responsible for the increase in the number and different types of patients at risk of developing IFIs. An accurate study of the epidemiology of IFIs requires reliable diagnostic tools, yet our knowledge of epidemiology in IFIs is limited by the difficulty in establishing a diagnosis. Invasive candidiasis is the most common IFI and is particularly prevalent in patients carrying intravascular catheters, those undergoing abdominal surgery, and very-low-birth-weight newborns. Although Candida albicans is still the main etiologic agent in invasive candidiasis, other non-albicans Candida species are becoming increasingly prevalent. Knowledge of local epidemiology is important, as susceptibility to antifungal agents is mainly based on the species involved, which vary with geography. Furthermore, widespread use of antifungal agents is also contributing to antifungal resistance. Invasive aspergillosis and other mold infections have classically affected patients with hematological cancer in periods of deep and prolonged neutropenia and recipients of solid organ or bone marrow transplant. Today, the population at risk of acquiring mold infections is more heterogeneous and includes patients with chronic lung diseases receiving long-term corticosteroid therapy. Environmental factors may also contribute to invasive aspergillosis in patients with a relatively sound immune status, such as those undergoing major surgery. Invasive aspergillosis is caused mainly by Aspergillus fumigatus; however, recent advances in fungal taxonomy have uncovered a more complex species epidemiology. Finally, the increasing number of azole-resistant A. fumigatus isolates is making patient management difficult. Although restricted to the north of Europe, this problem has the potential to spread to other areas. My presentation reviews and updates current knowledge on the epidemiology of IFIs, with emphasis on populations at risk, causative agents, and problems related to antifungal resistance. There was no statistically significant difference in LTBI frequencies among the three groups (p = 0 773). Conclusion: Although HCWs and HIV infected patients are considered as having an increased risk of LTBI compared to population at large, our results showed that LTBI prevalence was similar among the three groups. According to the WHO, one-third of the world's population has LTBI, being at risk of developing disease. A much lower prevalence of LTBI was found in our study. One possible reason for these observations is the fact that WHO data is based on the Mantoux test, which is affected by prior BCG vaccination, providing lower specificity and false-positive results. Objectives: Pott's disease (PD) has reemerged in some European countries due to immigration. In the last 15 years Catalonia has increased from 6 to 7.5 million citizens, in 84% due to foreign people. The aim of this study was to review our series of PD, focusing on cases associated to immigration. Methods: A retrospective review of all consecutive episodes diagnosed at a university hospital, from 1993 to 2010. All patients had TB confirmed by bacteriologic and/or histological studies. We recorded socio-demographic characteristics, underlying diseases, clinical features, microbiological and histopathologic studies, treatment and outcome. Results: During the study period 45 episodes (21 men, median age 56 years) of PD were diagnosed. In the last 10 years percentage of immigrants from undeveloped countries increased (37% vs. 5%, p = 0.016). The most common underlying conditions were: alcoholism in 5, diabetes in 4, HIV in 3, liver transplant in 3, systemic steroids therapy in 2 and chronic renal failure in 2. Median duration of symptoms before diagnosis was 4 months (IQR 1-7). Clinical presentations were pain (88%), neurologic manifestations (49%), constitutional symptoms (27%) and fever (18%). Extraspinal involvement was diagnosed in 10 (22%) patients among which 50% had pulmonary TB. The main spinal sites of involvement were lumbarsacral in 18 (40%), thoracic in 16 (36%), thoraco-lumbar in five (11%) and multifocal in two (4%). M. tuberculosis was isolated in 30/38 (79%) vertebral specimens studied and 20/40 (50%) patients had suggestive histology. Complications included paravertebral abscess/ mass in 62%, medullar compression in 31% and spinal deformity in 24%. Median duration of antituberculous chemotherapy was 12 months. Surgical treatment was performed in 12 (27%) patients. Infection was cured in all cases, except for 2 TB-related deaths due to disseminated disease. At the end of follow up (median: 18 months) none of the cases relapsed and 19 (42%) patients had persistent sequelae. Compared to natives, immigrants were younger (34 vs. 57 years, p = 0.002) and required more often surgery (64% vs. 16%, p = 0.002), due to a higher proportion of paravertebral abscess (91% vs. 58%, p = 0.047) and medullar compression (70% vs. 26% p = 0.01).\n\nConclusions: In our setting the proportion of PD cases occurring in immigrants is increasing. Compared to natives, foreign born are younger and more frequently require surgery due to higher proportion of complications. Paradoxical aggravation is a well described outcome of treated tuberculosis also identified as the immune reconstitution inflammatory syndrome (IRIS) in HIV patients receiving HAART. Some cases have also been notified after biotherapy withdrawal. Objectives: We report the first case-series of anti-TNF induced TB-IRIS and compared them with non-IRIS TB patients in order to determine prevalence and IRIS risk factors. Methods: Anti-TNF associated TB-IRIS cases were collected from the French register RATIO (69 reported cases of anti-TNF associated TB) and national case-calls, 28 anti-TNF associated TB without IRIS during the 6 months following TB diagnosis were collected as controls and randomly matched two for one according to the year of TB diagnosis. Conditional logistic regression was done by using SAS software. Results: Between 2001 and 2010, 14 cases of anti-TNF associated TB-IRIS were collected. Patients were median 52 years-old, underlying inflammatory diseases were inflammatory arthritis (10), vasculitides (3) and psoriasis (1) lasting for a median of 9 years. Anti TNF-alpha drug was monoclonal antibodies (13) and soluble receptor (1) prescribed for a median of 37 weeks. TB presentation was mostly disseminated (12). Anti-TNF was stopped. As anti-TB antibiotics started, eight patients received steroids. After initial improvement, IRIS occurred in a median of 62 days after antituberculous therapy beginning, manifestations were fever, lymph node swelling, tuberculoma, cold abscesses, pleural, pericardial or abdominal effusion, pulmonary cavitation, or increased pulmonary lesions. All recovered but required increase of steroids dose (9), rituximab initiation (1), new antituberculous treatment (3) or surgery (3). Among RATIO cohort, IRIS prevalence was 7.14%. Case-control study identified disseminated tuberculosis (OR = 5.56, p = 0.03), strong immunodepression (OR = 4.59, p = 0.02) as IRIS risk factors. TB-IRIS was associated to a significantly longer antituberculous treatment 16 months vs. 8 months (OR = 1.45, p = 0.046).\n\nConclusion: Paradoxical worsening of anti-TNF induced-tuberculosis after biotherapy withdrawal occurs in highly immunosuppressed patients with disseminated tuberculosis and leads to prolonged antituberculous treatment.\n\nO228 The change and and its significance of immune function in patients with pulmonary tuberculosis complicated by COPD S. Tang*, Y. Shen, H. Sun, X. Hao (Shanghai, CN)\n\nObjective: To explore the change and its significance of immune function in patients with pulmonary tuberculosis complicated by COPD.\n\nMethods: The immune function of 118 cases of pulmonary tuberculosis with COPD (study group) hospitalized in January, 2008 to January, 2011 were detected, and to compare the results with 120 cases of patients with pulmonary tuberculosis (control group of TB), and with 110 cases of healthy people (control group of healthy people) who were in the hospital during the same period. The expression Percentages of NK cells and T lymphocyte subsets in peripheral whole blood samples were detected by flow cytometry double-labeled antibody. The levels of IgM, IgG, IgA were measured by immunoturbidimetry. The levels of sIL-2R, TNF-alpha, IL-6, IFN-gamma were measured using the sandwich ABC-ELISA method in all patients.\n\nResults: The percentages of NK cells, CD4 and CD4/CD8 ratio in the study group and in the control group of TB were lower than those in the control group of healthy people (p < 0.01).The level of CD8 was higher in the study group than those in the control group of healthy people (p < 0.001). The level of CD4 and CD4/CD8 ratio in the study group were lower than those in the control group of TB (p < 0.001). The levels of IgM, IgG, IgA in the study group were lower than those in the control group of healthy people (p < 0.05). There were no significant differences between the study group and the control group of TB on the levels of IgG, IgA (p > 0.05). There were no significant differences between the control group of TB and the control group of healthy people on the levels of IgG, IgM (p > 0.05). The levels of sIL-2R, TNF-alpha, IL-6, IFN-gamma in the study group and in the control group of TB were higher than those in healthy people (p < 0.05). The level of sIL-2R, IFN-gamma in the study group were higher than those in the control group of TB (p < 0.05). There were no significant differences between the study group and the control group of TB on the level of TNF-alpha, IL-6. Conclusion: The patients with pulmonary tuberculosis were mainly impaired in cellular immunity, humoral immune damage also play a role. The patients with pulmonary tuberculosis complicated by COPD were impaired both in cellular immunity and in humoral immunity, and its extent of immune impairment is more serious than that of the patients with pulmonary tuberculosis. Objectives: There is a lack of point-of-care (POC) diagnostics in tuberculosis (TB) diagnosis. Measurement of IP-10 released by whole blood stimulation with TB specific antigens has recently been proposed as a new tool for the diagnosis of latent (and active) TB with diagnostic accuracy at-par with the Quantiferon TB in tube-assay (QFT, Cellestis). Higher cytokine release of IP-10 in comparison to interferon-gamma (IFN-g) could permit measurement of IP-10 in a POC test. The aim of this study was to compare a new lateral flow based POC IP-10 detection device head-to-head with the QFT in patients with active TB and healthy controls.\n\nMethods: IP-10 was measured retrospectively in the supernatants of QFT tests in 29 patients with microbiologically confirmed active TB and 29 unexposed healthy students. IP-10 was measured using a multiplex assay (MPA, Biorad), a semi-quantitative lateral flow immunoassay (LFI, Milenia Biotec) and an in-house ELISA developed in Copenhagen, Denmark. Samples with a mitogen control >0.5 ng/mL were considered determinate in all assays. We compared the different assays using receiver operating characteristic curve (ROC) analysis and set cut off for positive POC test at maximum Youden Index.\n\nThe QFT and all IP-10 detection assays had a high Area under the curve (AUC) for the calculated ROCs as a measure of diagnostic value, AUC was 0.84 (LFI), 0.87 (MPA), 0.82 (ELISA) and 0.92 (QFT). The cut-off points for positive test were determined to be 0.56 ng/mL, 0.32 ng/mL, and 5.0 ng/mL for LFI, MPA, and ELISA, respectively. Sensitivity and specificity of IP-10 measurement were 83% and 83% (LFI), 83% and 93% (MPA), and 72% and 96% (ELISA), respectively. Sensitivity and specificity for QFT was 69% and 100% using the manufacturer's cut off of 0.35 IU/mL. IP-10 determined with LFI showed moderate correlation to MPA and QFT (r2 > 0.65 p < 0.001) and strong correlation to ELISA (r2 > 0.8, p < 0.001 Pearson). Conclusion: In our study the POC LFI measuring IP-10 had comparable sensitivity and specificity compared to QFT for the diagnosis of active TB. The three test methods to measure IP-10 after stimulation with TB-specific antigens correlated well to each other and to QFT. Prospective studies evaluating this new IP-10-POC test are thus warranted. The sensor is able to discriminate the signature of a causative organism using pattern recognition software. Studies have shown that they may be valuable in detection of Mycobacterium tuberculosis directly from patient sputa. We proposed a study evaluating the use of such a sensor for the detection of M. tb directly from the breaths of patients suspected of having pulmonary TB. Method: The objective was to compare the sensitivity and specificity of the sensor (NextDimension Technology, California) to that of TB microscopy, and culture or GeneXpert. TB suspects were recruited at PHC facilities in the Paarl area, Western Cape. Forty smear positive, culture/Xpert positives, 28 smear negative, culture/Xpert positive, and 48 smear negative, culture/Xpert negative TB suspects were recruited over a 6 month period (September 2010-February 2011). In addition, breath samples from 50 healthy volunteers were obtained. Thirty-nine percent of the study population was HIV-positive. The test, performed in triplicate, consisted of a patient exhaling into a bag, which was then attached to the sensor and the sample was analysed in real-time.\n\nResults: Linear discriminant analysis of the samples revealed the sensitivity and specificity of the sensor were as follows: 100%, 92% (all culture positives vs. healthy volunteers), 70%, 83% (smear positive, culture positive vs. culture negative), 36%, 70% (smear negative, culture positive vs. culture negative). The sensor was able to accurately discriminate the infected group from the healthy population, but less so with suspects having other aetiology for their lower respiratory tract symptoms.\n\nConclusion: This device shows promise as a rapid, point of care diagnostic for pulmonary tuberculosis. Further research is still required to improve the sensitivity and specificity of the device by choosing more selective sensors and VOC targets. Objective: UK national guidance recommends screening for tuberculosis (TB) in various at risk groups and treatment for latent tuberculosis if no evidence of active disease is found. We undertook a retrospective study to evaluate the management of latent tuberculosis in our hospital. Methods: All patients who had a diagnosis of latent tuberculosis made in the adult Infectious Diseases clinic in our hospital from September 2008 till October 2011 were included in the study. Notes were reviewed to establish the demographics, rationale for screening and outcome of chemoprophylaxis where accepted.\n\nResults: Fifty nine patients were included in the study. Majority of these patients were from sub-saharan Africa (62%) with over half of them under the age of 35. All patients were asymptomatic with a normal clinical examination and 54 (92%) had a normal chest x-ray (CXR). Those with an abnormal CXR had no previous history of treatment for TB.35 had a positive Mantoux test of which 33 went onto have a positive IGRA (interferon gamma release assay) test but 24 had a positive IGRA test only. 24 (41%) were screened as recent TB contacts, 19 (32%) as part of occupational health screening and 14 (24%) as part of port health screening. Five of these patients are awaiting further review regarding chemoprophylaxis and two were not offered chemoprophylaxis (one because of age and second because patient was returning back to an endemic area).\n\nOf the remaining 52 patients who were offered chemoprophylaxis 41 (79%) accepted it although two have deferred it for a few months. The uptake of chemoprophylaxis was highest (95%) among TB contacts and lowest (58%) among health care workers. The regimen used was Rifampicin and Isoniazid for three months. Chemoprophylaxis is ongoing in four patients and of the other 35 who started chemoprophylaxis 32 (91%) successfully completed it. Of the three who discontinued the regimen due to side-effects one had liver function abnormalities, one had pruritus and the third had tingling and numbness. 62% of patients receiving chemoprophylaxis reported no side-effects.\n\nConclusions: Majority of patients diagnosed with latent tuberculosis in our hospital are from sub-Saharan Africa and majority of them were screened as recent TB contacts. Acceptance of chemoprophylaxis for latent tuberculosis was high overall but comparatively low by health care workers. There was a high overall completion rate with very low incidence of serious side-effects. Objective: To evaluate the usefulness of a clinical protocol for preventing tuberculosis (TB) associated with tumour necrosis factor (TNF) antagonist therapies, and to assess the impact of both ceasing the 2-step tuberculin skin testing (TST) practice and introducing QuantiFERON \u00d2 -Gold In-Tube (QFT) in the diagnosis strategy. Methods: Observational cohort study of all patients due to start treatment with TNF antagonists, after being evaluated for TB infection (LTBI) according to a pre-established clinical protocol between Jan 2003 and Dec 2010. Protocol included (i) diagnosis of LTBI, based on clinical and radiological data followed by 2-step TST (1st period), 2step TST and QFT (2nd period) and 1-step TST and QFT (3rd period); and (ii) pre-emptive treatment (Pre-tx) with 9 months of isoniazid (H) when indicated. Patients were followed up while on Pre-tx and adherence was monitored by H metabolites in urine. Development of TB was assessed by reviewing the electronic medical reports including hospital and primary care data. The Ethics Committee of Bellvitge University Hospital approved the study.\n\nResults: Six hundred seventy-two patients (57% women, mean age 50 years.) were evaluated. 227 patients were diagnosed with LTBI (43%, 40% and 26% in the 1st, 2nd and 3rd period respectively; p < 0.05). 33% of patients received Pre-tx (41%, 40% and 24% respectively; p < 0.05). 481 started anti-TNF therapy. After a median follow-up of 3.8 years (2562 patient-years) for the whole cohort and 4.2 years (1537 patient-years) for patients at risk (on anti-TNF therapy), four (0.6%) patients developed TB (incidence: 156 per 100 000 patients/years; 95%CI 50-377 for the whole cohort, and 195; 95%CI 50-531 for patients at risk). Three out of four cases occurred in patients on anti-TNF therapy, one in each period. Another patient had negative TST and QFT, and did not receive neither Pre-tx nor anti-TNF therapy. Conclusion: Systematic evaluation and treatment of patients prior TNF-antagonist therapy, prevents TB in a great extent. Ceasing the twostep TST practice and introducing QFT substantially reduce diagnoses and pre-emptive treatments for LTBI without increasing the risk of TB. Objective: To evaluate the clinical efficacy and safety of using Linezolid to treat XDR-TB. Methods Since April 15th, 2009, we have applied Linezolid-based chemotherapy in the treatment of fourteen cases XDR-TB patients. We adopted individual-based chemotherapy regimens based on the patient medication history and drug susceptibility test results. Dosage of Linezolid: at the beginning: 600 mg, intravenous drip, bid, with duration from 1 week to 6 weeks; Later: reduce to 600 mg, intravenous drip, qd. Maximum duration of treatment is 11 months; minimum is 2 months, with an average 6 months and a half.\n\nResults: On the second day after medication, the body temperature returned to normal for the three febrile patients; the 14 patients showed significant improvement in cough, sputum; chest tightness, breath shortness and other symptoms also improved. In the 6th months after treatment of Linezolid, 10 patients presented cavity closure. Sputum smear negative conversion occurred in all pulmonary cases at a median of 64 days(range:8-210).Culture conversion occurred in all pulmonary cases at a median of 63 days(range:8-210).The relapse of both sputum and imaging occurred in two cases after 4 months of not using Linezolid. Six cases presented nausea, vomiting and other gastrointestinal reactions, but symptoms disappeared after reduction of Linezolid. Three patients developed peripheral neuropathy. Two patients developed declining of eyesight. Six cases had hematological adverse reactions.One patients developed leucopenia. Four patients developed middle anemia. One patients developed severe anaemia and needed blood transfusions. Conclusions Using Linezolid to treat XDR-TB can significantly improve clinical symptoms, promote lesion absorption and cavity closure, and accelerate sputum negative conversion. Therefore, it can help XDR-TB patients to improve life quality with mild adverse reaction but good drug tolerance. We suggest that Linezolid can be recommended for the treatment of XDR-TB. zolid can be recommended for the treatment of XDR-TB. Objectives: Tuberculosis meningitis (TBM) has a case fatality rate of >30%. Optimal treatment for TBM has not been established and follows the model of pulmonary TB treatment. Moxifloxacin, because of its potencyand good penetration into the cerebrospinal fluid (CSF) is a promising drug for TBM. Higher doses of moxifloxacin as well as rifampicin may increase drug exposure in blood and CSF, thereby improving survival. This study evaluates the pharmacokinetics (PK), safety and efficacy of such an intensified regimen for TBM in a hospital in Indonesia. Methods: We randomized 60 Indonesian TBM patients (10% HIVinfected) to standard dose (450 mg, 10 mg/kg) oral rifampicin or high dose (600 mg, 13 mg/kg) rifampicin administered i.v., and (in a second randomization) to moxifloxacin 400 mg, moxifloxacin 800 mg, or ethambutol 750 mg QD, for the first 14 days and in adjunction to standard INH, PZA and dexamethason. After the first two weeks of treatment all patients continued with standard TB treatment. Pharmacokinetic (PK) assessments were performed in blood and CSF within the first critical 4 days of treatment, adverse events attributable to TB treatment were assessed, and 1 month mortality was evaluated. This explorative study was powered to detect pharmacokinetic differences between groups.\n\nResults: So far PK data have been evaluated for 23 patients. Increasing the dose led to higher drug exposure in plasma for rifampicin (1.8 fold) and moxifloxacin (3-fold) . Mean CSF concentrations for rifampicin were low and showed only a small increase with a higher dose (0.50 vs. 0.37 mg/L). Mean CSF concentrations for moxifloxacin were 1.7 vs. 3.9 mg/L (p < 0.05) for standard vs. high dose moxifloxacin. Among the first 48 patients included, mild QTc prolongation occurred in 48% of patients taking moxifloxacin, while grade 3 (10%) and grade 4 (6%) hepatotoxicity was evenly distributed between groups. One-month mortality among the first 48 patients included, was substantially lower (31% vs. 57%, p = 0.07) in patients taking high-dose rifampicin i.v. compared to those taking standard dose orally. Conclusion: Intensified antibiotic treatment for TBM leads to more favorable PK in plasma (rifampicin and moxifloxacin) and in CSF (moxifloxacin), with acceptable toxicity. Preliminary data in this explorative study show a trend for lower mortality in patients taking high dose rifampicin. Larger studies should evaluate the effect of intensified treatment on survival of patients with TBM. Pseudomonas aeruginosa is an opportunistic pathogen which is ubiquitous in soil and water. It is however able to cause severe infections in humans and in cystic fibrosis (CF) patients it is the dominant cause of morbidity and mortality due to its persistence in the airways of these patients. Our main objective has been to characterize the evolutionary routes by which these bacteria switch from an environmental life-style to one associated with chronic infections. Helped by a substantial strain collection covering several hundred CF patients with lung infections lasting for up to 35 years we have been able to identify particularly successful clones whose changing genome sequences and global gene expression profiles have constituted an important platform for our analysis. The genome dynamics reflect in many cases the frequent appearance of hyper-mutator strains, in which mutations accumulate with rates which are up to 1000 fold increased relative to what is observed in non-mutator isolates. In these cases the airway populations of P. aeruginosa are highly diverse and adaptation to the changing environments in the CF airways seems to occur at the population level. In contrast, very successful non-mutator clones seem to harbor several mutations in global regulatory genes, which result in highly adapted cells and quite homogeneous airway populations. Through allelic replacement wild-type strains of P. aeruginosa have been constructed, which carry one or more of the identified regulatory mutations from clinical isolates, and the resulting strains display phenotypes with profiles resembling those of the clinical strains. These results suggest that a small number of specific regulatory mutations, altering networks of transcription in the bacteria, may provide the cells with adaptive features that lead to high fitness levels of the bacteria in their new environment. The latest results from these on-going studies of gene regulation in CF isolates and their synthetic counter-parts will be discussed.\n\nS260 Candida scores S. Ruiz-Santana*, C. Le\u00f3n on behalf of the CAVA II Study Group\n\nColonization and Candidemia (C)/Invasive Candidiasis (IC) are difficult to distinguish in ICU patients. Predictive models in adult nonneutropenic critically ill patients allow stratification and selection of high-risk patients for C/IC who may benefit from early antifungal therapy. Our group has developed and validated the ''Candida score'', a predictive model of IC, based on a scoring system for certain variables, which assigns a value of 1 point for surgery, multifocal colonization and parenteral nutrition, and a value of two points severe sepsis. A cutoff of \u20213 is highly reliable to identify patients at high risk of C/IC. Moreover, abdominal surgery increases significantly the risk of C/IC. Based on these results, early antifungal treatment can be specifically directed to patients with multifocal Candida colonization and associated Candida score \u20213 and, in particular, to those with abdominal surgery. This scoring system is simple and may be of help to clinicians to differentiate between Candida spp. colonization and occult invasive fungal infection when early antifungal treatment is considered. Serological tests have been recently added to the diagnostic armamentarium of C/IC, including detection of Candida albicans germ tube antibodies (CAGTA) and (1,3)-Beta-D-Glucan (BDG). A recent metaanalysis concluded that BDG has good diagnostic accuracy for distinguishing patients with and without invasive fungal infection. Proper use of this test requires good knowledge of its characteristics, particularly the fungal pathogens that remain undetected and the factors associated with a false-positive result. PCR-based methods to detect Candida spp. directly in blood samples may play an important role in improving the outcome of patients with IC through an earlier and more sensitive diagnosis. A recently published meta-analysis has demonstrated the usefulness of this method, which may accompany blood cultures, although serial sampling may be considered for patients at high risk for IC. This systematic review demonstrated that direct PCR in blood samples may have higher sensitivity for the diagnosis of IC than conventional blood cultures, with a specificity of 90%. Therefore, stratification of patients at high risk for IC with the use of a predictive model of IC together with measurements of biomarkers (BDG and CAGTA) and the possibility of having available diagnostic tests based on real time PCR may change the outcome of patients with IC.\n\nHuman papillomaviruses: recent advances S262 Recent advances in the diagnosis of HPV infection\n\nHuman papillomaviruses (HPV) are a group of remarkably diverse DNA viruses from the Papillomaviridae family, which are causally involved in the etiology of various benign and malignant neoplastic lesions of mucosal and skin epithelium. Approximately 40 different HPV types from the alpha genus are known to infect mucosal epithelium, with a subset of 10-12 HPV types being associated with lesions that can progress to cancer. These cancer-associated HPVs are designated as high-risk HPV types (hr-HPV) and are the etiological agents of virtually all cervical carcinomas and play the leading etiological role in the development of anal cancer and a substantial proportion of vaginal, penile, vulvar and oropharyngeal (mainly tonsillar) cancers. In view of the fact that persistent infection with hr-HPVs is a necessary etiological factor in the development of cervical carcinoma, HPV testing has become an important part of cervical carcinoma screening and detection algorithms in several countries. Testing for hr-HPVs has four main clinical applications: (i) triage of women with ASC-US or other borderline cytology, (ii) follow-up of women with abnormal screening cytology results who are negative at initial colposcopy/biopsy, (iii) prediction of the outcome after treatment of CIN2+ and (iv) primary screening of women aged 30 years and more in combination with Pap smear. Currently more than 80 different commercial assays for the detection of alpha HPVs are available (reviewed in Poljak M, Kocjan BJ. Exp Rev Anti Infect Ther 2010;8:1139-62) and can be provisory divided into five main groups: (i) DNA-based screening assays, which test for the presence of 13-14 hour-HPVs without determination of HPV type; (ii) assays that combine testing for 14 hours -HPVs and HPV-16 and HPV-18 genotyping; (iii) HPV DNA based genotyping assays, (iv) mRNA hr-HPV assays and (v) in situ hybridization HPV assays. The vast majority of HPV assays currently on the market are not useful for the established clinical applications and especially not for primary screening. Automation, price reduction and improvement of clinical specificity are the main goals for the future development of HPV assays.\n\nIs it important who you are when you get an infectious disease? S265 Responsiveness to vaccines: is it gender-related?\n\nImmune response to infectious agents and to vaccines are variable with regard to sex-based biological differences. Innate, humoral and cellmediated immune responses are different in men and women. Furthermore,during pregnancy immune responses and response to vaccination are altered. E.g., a study on humoral response to the trivalent inactivated influenza vaccine showed that healthy women generated a more robust antibody response. Additionally women report more severe reaction to influenza vaccines. Overall, studies to identify the differences to response to vaccines are scarce.Nevertheless, studies on sex-related immune response and response to vaccination are needed to define futures strategies for vaccination programs. Gender related responsiveness to vaccines are another issue to be addressed. Gender and immunisation has been a topic to be assessed by the WHO and partner for statistical analysis of demographic health surveys, qualitative systematic review and case studies. The compilation of the data showed that vaccinations outcomes with regard to both sexes were variable within the studies countries. Yet, women and children of disadvantaged groups in economy and education are more likely to be exposed to barriers to immunsation. from surgical patients. All isolates were re-identified to the species level using standard microbiological methods. PCR detection of mecA and lukS-PV/lukF-PV genes was performed. The isolates were characterised by spa-typing, RM test typing, agr typing and SCCmec typing. MLST was performed for selected isolates representing different centres. Results: All MRSA isolates were grouped into 11 clonal complexes, namely: CC5 (n = 296; 46%), CC22 (n = 148; 23%), CC8 (n = 115; 17.8%); CC80 (n = 34; 5.3%) CC30 (n = 21; 3.3%), CC398 (n = 13; 2%), CC45 (n = 6; 0.9%), CC1 (n = 5; 0.7%), CC59 (n = 2; 0.3%), CC152 (n = 2; 0.3%) and CC7 (n = 1; 0.1%). 567 (88.2%) isolates belonged to hospital-associated MRSA (HA-MRSA) lineages, 63 (9.8%) to community-associated MRSA (CA-MRSA) lineages, whereas 13 (2%) to livestock-associated MRSA (LA-MRSA) lineages. 10 (1.5%) isolates represented sporadic MRSA clones. Among HA-MRSA lineages the most predominant clones were: Southern German (ST228-I and related, n = 152) observed mostly in Switzerland, Italy and Serbia; EMRSA-15 (ST22-IVh and related, n = 148) observed mostly in Scotland and Spain and EMRSA-2/-6 (ST8-IVc, n = 93) observed mostly in France. CA-MRSA clones, European (ST80-IVc, n = 34) and Southwest Pacific (ST30-IVc and related, n = 18) dominated in Greece. Overall, the most disseminated clone was EMRSA-15, observed in seven out of nine centres, followed by EMRSA-2/-6 and Southern German clones, in five and three out of nine centres, respectively. The most prevalent SCCmec type was IV (n = 347) followed by SCCmec type I (n = 157), II (n = 61) and III (n = 20). Panton-Valentine leukocidin (PVL) was carried only by isolates belonged to CA-MRSA clones (n = 42). Conclusion: Although, each centre studied was characterised by specific composition of MRSA lineages, usually with one or a few prevalent clones, there were some clones, such as EMRSA-15 or Southern German, that had been widely disseminated in Europe and Israel.\n\nO267 European epidemiology of MRSA bacteraemia: effective prevention requires more than just good hospital policies M.A Borg*, E. Scicluna, U. Frank on behalf of the Implement Project Group\n\nObjectives: The incidence of MRSA bacteraemia in Europe shows substantial geographical variation. Better identification of effective infection prevention and control (IPC) practices is needed to inform more successful interventions. Methods: Between March and October 2011, the EU funded IMPLEMENT project surveyed practices, relevant to MRSA bacteraemia prevention, using an online questionnaire sent to members of European IPC societies. Background demographic information was also collected, including MRSA proportions in blood culture isolates. Statistical analysis was performed using chi-square test.\n\nResults: A total of 223 replies were received from IPC doctors or nurses in regional or academic hospitals located in 29 European countries. MRSA proportions among the respondents were: 105 hospitals \u00a35%; 47 hospitals = 5-20%; 71 hospitals \u202120%. Significantly more hospitals in the lower MRSA categories performed daily surveillance of MRSA bacteraemia incidence and performed root cause analysis to investigate possible aetiologies of these infections ( Figure 1 ). The proportion of hospitals reporting policies for the insertion and maintenance of peripheral and central venous catheters showed no correlation with MRSA prevalence; neither did the presence of policies for removal of peripheral cannulae at 72 hours or presence of IV line care teams. On the other hand, hospitals that performed competence assessment of their personnel's ability to insert and maintain these lines showed significantly lower MRSA proportions. Even in low prevalence hospitals, central venous catheter (CVC) care bundles were reported by no more than 45.5% of hospitals; in turn, only 72.1% of these institutions documented compliance whereas just 25% of them performed bundle audit and feedback at least every 6 months.\n\nConclusions: Whereas IPC policies are abundantly present in European hospitals, efforts to ensure that staff are competent in the performance of those same policies appear sub-optimal. In addition, a higher MRSA prevalence also seems to be related to less intensive surveillance and especially to lack of efforts to identify and correct causative aetiological factors through root cause analysis. Effective CVC care bundles are also still absent in most hospitals. IPC practices in European hospitals seem to lack the requirements of good practice and clearly need to learn from safer industries, such as aviation, if improvements in MRSA bacteraemia epidemiology are to be achieved. Methods: Sixteen hospital laboratories across England, Wales and Northern Ireland were requested to refer up to 10 consecutive MRSA and MSSA from bacteraemia cases within the period from January to July 2011. Patient demographic data were collated. Genetic characterisation included spa typing, mecA PCR, MLVA and SCCmec typing. Antibiotic susceptibilities were determined by agar dilution (BSAC method) and interpreted using EUCAST guidelines. Results: Overall, 165 isolates (107 MSSA; 58 MRSA) were referred from the participating laboratories. Patients were aged 0 to 96 years; >55% were from the 65+ age group. All but one MRSA tested were ciprofloxacin resistant. Resistance to erythromycin, clindamycin and fusidic acid was observed in 19, nine and four SA isolates respectively. Among MRSA, 27 spa types were identified; t032 was predominant (n = 23) and 81% of all the MRSAs belonged to CC22 (EMRSA-15, as inferred from spa typing data). Meticillin resistance in this group was associated with SCCmec type IV. Other SCCmec types detected included types I (t688), V (t904, t4303); some SCCmec elements proved non-typable (t024 and t190). Among the MSSAs, 44 spa typesclustered into eight inferred clonal complexes and 22 genetically unrelated lineages -were identified. Five major spa types (t002, t008, t012, t015, and t084) accounted for 26% of the total MSSA. MLVA increased discriminatory power: 116 distinct profiles were identified. Specifically, the predominant spa type among the MRSA (t032) was sub-divided into 9 distinct MLVA types. PVL was not detected in MRSA, but 4 MSSA (t355, t315 and t3841) were PVL-positive. Conclusion: Based on the spa type data, there were no significant changes in the genetic structure of SA bacteraemia in the UK in 2011 compared with 2006. The MSSA remain heterogeneous with multiple lineages identified. EMRSA-15 (CC22-SCCmec IV) remains the predominant MRSA clone associated with bacteraemia in the UK. Objectives: The aim of this study was to characterize invasive methicillin-resistant Staphylococcus aureus (MRSA) isolates collected during a 2011 6-month period in France and compare data with those obtained in 2006 using the same protocol. Methods: We conducted a prospective multicenter study of invasive (bacteraemia) MRSA strains, including the first five consecutive blood culture isolates, collected between January and July 2011 in 29 hospitals located throughout France. The strains were extensively characterized using antibiotic susceptibility patterns, agr typing, spa typing, SCCmec typing, toxin profiling and DNA microarrays (StaphyType, Alere). Clones were designated by their sequence type (ST) followed by their SCCmec type (I to VI) .\n\nResults: A total of 127 isolates were included (see Figure 1 ). Five main clones were identified: the ST8-IV Lyon clone (or UK-EMRSA-2, n = 74, 58.3%), the ST5-VI New Paediatric clone (n = 22, 17.3%), the ST5-IV old Paediatric clone (n = 10, 7.9%), the ST22-IV (or UK-EMRSA-15, n = 8; 6.3%), the ST5-I Geraldine clone (n = 3; 2.4%) and the ST80-IV European CA-MRSA clone (n = 3, 2.4%). The seven remaining isolates were related to six other clones. The Lyon clone remains the most prevalent MRSA clones in France compared to a similar previous study in 2006. Since 2006, the evolution is marked by the significant increased rate of the ST5-MRSA-VI New Pediatric clone (p = 0.015) and the concerning emergence of the ST22-IV clone (p = 0.006). Besides, this latter has been involved recently in several outbreaks within French neonatal units. Data from DNA microarrays provide a accurate picture of virulence and resistance profiles of the various invasive clones circulating in France and their genetic plasticity.\n\nOur results highlight (i) the interest of epidemiological surveillance of MRSA circulating in each European country to be able to follow the dynamic of the various clones and adapt the management of invasive MRSA infections, (ii) the dynamic of MRSA clones demonstrating the potential dissemination and/or emergence of specific MRSA clones at country scale in a short period of time. Using ApaI-PFGE, seven pulsotypes (A-G) were detected, with types A and B accounting for 67% of the strains. SCCmec type V was found in 23 isolates and the other three were SCCmec type IV. Six different spa types were identified: t011 (68%), t1197 (8%), t1451 (4%), t1255 (8%), t108 (8%) and t889 (4%). One strain was spa negative both by PCR and microarray analysis. Tet-R was mediated by tet(M) and tet(K) in 18 isolates. Ciprofloxacin resistance was 65%. Resistance to erythromycin and clindamycin, erm(C) mediated, was 27%. Multiresistance was detected in 11 isolates (42%) and four (15%) showed expanded resistance patterns (R to six or more antibiotic classes). All isolates carried genes codifying a type 5 capsule. None of the strains carried PVL genes, or exfoliative toxin genes etA, etB and etD. The enterotoxin gene cluster and the tst gene were also negative. Conclusion: Although a rare pathogen, in the last two years the number of MRSA-ST398 isolates infecting or colonizing pts has increased significantly in our setting. Pts harboring this clone were often debilitated by underlying diseases. Genetic variability was high among the MRSA-ST398 isolates and near half of the isolates were resistant to multiple antibiotics. Objectives: There are four distinct serotypes of dengue virus (DENV) and each of these serotypes may cause disease ranging from mild febrile illness to devastating manifestations including Dengue hemorrhagic fever and Dengue shock syndrome. Disease severity of DENV infection appears to be controlled by the presence of cross-reactive DENV antibodies directed against the envelope (E) and precursor membrane (prM) by facilitating antibody-dependent enhancement of infection. We recently reported that immature DENV turns highly infectious in the presence of prM antibodies. These antibodies facilitate efficient binding and cell entry of immature particles into Fc-receptor expressing cells. In addition, enzymatic activity of furin present in the endosome is critical to render the internalized immature virus infectious. In this study, we analyzed if antibodies recognizing the E protein can also promote viral infectivity of immature virus particles.\n\nMethods: Immature DENV-2 strain 16681 particles were produced in furin-deficient LoVo cells. The infectious properties of immature and standard DENV-immune complexes were investigated in FcRexpressing human monocyte cell line U937, the murine macrophage cell line P388D1, and in human PBMCs by plaque assay in the presence and absence of furin inhibitor. Results: The vast majority of anti-E mAbs tested enhanced viral infectivity of immature dengue in a furin-dependent manner. Furthermore, we found that in the presence of non-neutralizing immune serum, immature virions, which are normally non-virulent, can cause lethal disease in mice.\n\nMost of the E antibodies tested facilitated binding and uptake of immature virions into an endocytic pathway of the target cell. While most antibodies promoted infection, some did not. Anti-E mAbs that do not stimulate viral infectivity may interfere with the conformational change of the virion prior to furin cleavage, or with the fusion process itself. Taken together, our results support the notion that antibodies against the structural proteins prM and E both can enhance infectivity of prM-containing immature and partially mature flavivirus particles. We are currently running experiments using acute sera samples of patients developing different disease outcomes to assess whether immature particles contribute to disease pathogenesis and we anticipate to present these results at the conference as well. Objectives: We recently reported that Herpes simplex virus-1 (HSV-1) infects the enteric nervous system (ENS) through the orogastric route resulting in gastrointestinal inflammation and dysfunction. Since the ENS possesses the molecular machinery to recognize and react to viral infections we decided to decode the functional relevance of toll-like receptor (TLR) 2 in mediating the response to HSV-1 and investigate whether innate immunity driven responses can harm neuronal functional integrity. Methods: Adult C57Bl/6 (WT) and TLR2 knock-out (KO) mice were inoculated with HSV-1 intranasally and after 4 weeks (W) intragastrically (IG). Mice were sacrificed 1-8W post IG. RNA was extracted from longitudinal muscle myenteric plexus (LMMP) to evaluate viral transcripts. Distal ileum segments were assessed for changes in muscle tension, using electric field stimulation in isolated organ baths, and for ENS integrity by immuno-fluorescence on whole mount preparations. Immune cells from mucosa and LMMP were analyzed by fluorescent activated flow cytometry (FACS). Results: In WT mice HSV-1 latency-associated transcripts (LATs) were detected by 2W post IG, while ICP4 and gC mRNAs were detected only at 6W. Activated CD11+ CD49d+ macrophages infiltrated mucosa at the early stage of infection whereas resident F4/ 80 + cells shown bare phagocytic activity. HSV-1 reactive CD3+ CD8+ lymphocytes were identified in LMMP at 8W post IG. Indeed, at 1 and 8W post IG ileal contractility was reduced and ENS structure damaged (i.e. loss of neuronal HuC/D and glial S100beta immunoreactivity). In TLR2KO mice ICP4 and gC mRNA were detected in the LMMP 1W post IG infection while LATs appeared only at 4W. Indeed, in TLR2KO mice no infiltrating cells were identified but resident mucosal macrophages preserved the phagocytic activity and INF-g production as detected by FACS analysis. During the infection, TLR2KO mice failed to develop a strong adaptive immune response. Intestinal contractility increased at 1-3W post IG infection. Objective: Peritonsillar abscess (PTA) is the most frequent complication of acute tonsillitis, and one of the most prevalent causes for acute admission to Otorhinolaryngology Departments. Viral infections have been shown to predispose to the development of acute bacterial complications, such as acute otitis media, sinusitis, and pneumonia. Our aim was to examine whether viruses also play a role in the pathogenesis of PTA. Methods: We have examined both palatine tonsils, from 25 patients undergoing acute tonsillectomy for PTA, using PCR-based assays specific for Herpes Simplex Virus-1 (HSV-1), Herpes Simplex Virus-2 (HSV-2), Adenovirus, Epstein-Barr Virus (EBV), Influenza A and B, and Respiratory Syncytial Virus (RSV) A and B. We similarly examined tonsils from 55 patients undergoing elective tonsillectomy due to recurrent tonsillitis (RT) and/or tonsillar hypertrophy (TH), or persistent sore throat syndrome (PSTS). This elective group served as a control group, as they did not have clinically apparent infection at the time of surgery. Only patients aged 8-30 years, without antibiotic treatment during the month preceding surgery, were included in the study.\n\nResults: The mean ages of the PTA and the elective tonsillectomy groups were comparable (18.8 years and 19.1 years, respectively). Only HSV-1 (5/80, 6.3%), Adenovirus (11/80, 13.8%), and EBV (71/ 80, 88.8%) were detected in our study population. There were no statistically significant differences in the frequency with which these viruses were identified in the PTA group vs. the elective tonsillectomy group, nor between patients with RT, TH or both RT and TH. Quantification of EBV load demonstrated no differences between the PTA group and the elective tonsillectomy group, and in the PTA group no differences between the abscessed and the non-abscessed, contralateral tonsil. Concordance between contralateral tonsils was found to be poor for HSV-1 and Adenovirus (20 and 27% concordance, respectively), and high for EBV (94%), likely reflecting the relative viral load of these viruses in the tonsils.\n\nConclusions: In summary, our data do not support a significant role for the examined viruses in the pathogenesis of PTA. However, the study highlights the tonsil as a reservoir for HSV-1, Adenovirus, and EBV in adolescents and young adults. Furthermore, we show that the degree of concordance between contralateral tonsils is variable depending on the virus under study. . This approach enhances the specificity and the accuracy of early diagnosis and with the precise administration of antiretroviral drugs, HIV can be managed sustainably. Our POC prototype is based on Multi-marker Cantilever Nanosensors platform that integrates sample sorting (nanopillars) and surface capture chemistries. This technology offers many opportunities for direct detection of proteins such as antigens and antibodies against infectious organisms and potentially for the direct detection of organisms themselves without the need for labelling. Nanopillars acts as microfluidic sieve to separate and concentrate different markers of infection from clinical samples which are present in low copies. The antigens are detected and quantified by flowing across an array of cantilever nanosensors functionalised with carefully selected high affinity capture molecules raised against different (sub) types of HIV virions. Subsequently, the specific biomolecular binding event is translated into a nanomechanical signal analysed by the interference pattern created when they are illuminated by a laser.\n\nHere we find the sensor geometry and receptor chemistry are key to the limit of HIV multiple marker detection particularly in the regimens that allow for early diagnosis. We show that the cantilever arrays have the potential for high-throughput multi-target screening and are amenable for large scale production of compact, portable POC device to be used anywhere in the world.\n\nO277 Nanomechanical sensors for micro-organism growth detection G. Lukacs*, N. Maloney, M. Hegner (Dublin, IE)\n\nObjectives: Fast detection of viable microorganisms is of great importance in several different fields of Microbiology. Due to an increase in antibiotic resistant microorganisms, fast growth detection methods are needed in a clinical environment for antibiotic susceptibility testing. Existing culture methods are time consuming, material heavy and Live/Dead cell discrimination is difficult. The use of microcantilever arrays for microbial growth detection provides a rapid technique for monitoring growth in clinical and industrial applications.\n\nMethods: This biological sensor is based on oscillating cantilevers (Dynamic mode). The resonance frequency response of a cantilever array (CLA) is tracked using the laser beam deflection method ( Figure  1. ). Frequency shifts are caused by additional mass loading onto the cantilevers. The cantilevers are functionalized with an agarose layer supplemented with culturing medium. Aspergillus niger spores were seeded on the cantilever surface using the ink-jet printing technique. During microbial growth microorganisms assimilate nutrition and water from the nutritive layer and humid air, which results in an increase in the mass on the cantilever. Results: The use of CLA's allows Aspergillus niger growth to be detected within a few hours. Different magnitudes of frequency response due to a different number of viable spores on cantilevers were observed. Initial resonance frequency decrease was detected during fungal growth. The subsequent hypha growth along the cantilevers longitudinal axis resulted in a resonance frequency increase. The use of a reference cantilever allows a differential signal to be recorded. Thus, the true change in resonance frequency can be extracted from the data. The currently used cantilever arrays (eight cantilevers per array) provide the opportunity to perform parallel measurements of different growth conditions (eg.antibiotic susceptibility testing).\n\nConclusion: The growth of various microorganisms can be detected and monitored by using microcantilever sensors. When compared to conventional methods, cantilever sensors use less culturing medium and the functionalisation and detection can be automatized. The technique is label free and the use of multiple cantilevers provides the opportunity to test various antimicrobial agents in parallel. In collaboration with CalTech and Novartis we will further develop our device to provide a user-friendly multiplexed portable version for industrial and hospital measurements.\n\nO278 Specific interferon-gamma measurement to diagnose previous exposure to Coxiella burnetii in pre-vaccination screening Objectives: During the recent Q fever epidemic in the Netherlands, vaccination with the whole bacterial Coxiella burnetii vaccine Q-vax \u00d2 (CSL) was offered to subjects with an increased risk for chronic Q fever. Vaccination is reported to have serious side effects in individuals Novel methods to diagnose infections who had (subclinical) infection with C. burnetii before. According to the manufacturer guidelines, vaccination candidates should therefore be tested by serology and by an intradermal skintest. We developed a feasible antigen-specific interferon-gamma (IFN-g -assay to diagnose previous infection with C. burnetii. In the recent Dutch vaccination campaign we compared this assay with serology and skintest. Methods: For the IFN-g assay heparinised blood was collected and incubated with inactivated whole C. burnetii Nine Mile phase I bacteria for 24 hours. A negative control (no stimulus) and a non-specific control (PHA) were incubated simultaneously. The IFN-g concentration was measured in the supernatant by ELISA. The assay was performed in 1525 vaccination candidates who were also tested serologically and by skin test prior to vaccination. Results: Of 1294 individuals had conclusive results in the IFN-g assay, 1166 individuals had evaluable results for all three tests and were included in the analysis. In the 212 individuals with either a positive serology (n = 136; IgG phase 2 titer \u202132) or a positive skintest (n = 76; induration \u20215 mm), IFN-g production was 402 \u00b1 73 pg/mL (mean \u00b1 SE), significantly (p < 0.0001) higher than 28 \u00b1 6 pg/mL in the 954 seronegative and skin test negative individuals (Figure 1 ). When a positive serology or skin test was used as a marker for as a previous infection with C. burnetii, the ROC-curve of the assay shows a test accuracy of 0.83 (95% confidence interval 0.80-0.87). Interestingly, the IFN-g production in the 9 patients with a serologic profile compatible with chronic Q fever (defined by the Dutch guidelines for chronic Q fever as IgG phase 1 \u2021 1024) was very high (1716 \u00b1 1053 pg/mL). Conclusion: The Q fever-specific IFN-g assay is a useful method for the detection of individuals who had previous contact with C. burnetii and can be used in pre-vaccination screening. The value of the test in the diagnosis of chronic Q fever deserves further evaluation. Objective: Q fever is a highly contagious zoonotic disease caused by Coxiella burnetii. The presentation of Q fever in humans is variable, from asymptomatic, acute and chronic disease to Q fever fatigue syndrome. It is diagnosed principally by serology and antibody patterns between phase I and II which differentiate between acute, convalescent and chronic Q fever. However, the current serological methods do not discriminate sufficiently or early enough between acute and chronic Q fever during the convalescent stage, making preventative treatment problematic.\n\nMethods: We used a recently developed protein microarray to characterize the humoral immune response between acute and chronic Q fever patients from the Dutch outbreak to search for new serological markers to identify chronic Q fever. The array contained 93% of the proteome of C. burnetii. The serological profile in samples from 13 acute and 12 clinically proven chronic patients were compared to control samples. The antibody kinetics and the influence of antibiotic treatment on the antibody response was studied in follow-up samples from 25 patients. Results: Several serological markers were significantly present at higher levels in patients diagnosed with chronic Q fever compared to the acute patients. These detected markers may therefore be a better indicator for chronic disease than the level of the IgG phase 1 in the Immuno Fluorescence Assay. A decrease in antibody responses was observed in follow up serum samples after acute infection and during treatment of chronic Q fever. We observed possible reactivation in at least two chronic Q fever patients, indicated by an increase in the antibody responses to the identified markers after discontinuation of their antibiotic treatment.\n\nConclusion: While the Dutch Q fever outbreak has been challenging, the true challenge might still be ahead of us as we try to identify patients at risk, allowing us to prevent and treat chronic Q fever cases in the future. The serological markers we have identified may help us to identify patients at risk for the development chronic Q fever at an earlier stage than is now currently possible. They might also be used during follow up to monitor treatment response. would not prescribe an antibiotic upon presentation and 64.4% would wait for symptoms to persist for 7 days in order to administer antibiotics. Responders stated that in 80% of CAP pts they choose to treat as outpatients. Amoxicillin-macrolide combination was selected by 13.5%. In COPD exacerbations antibiotic administration was chosen by 89%. Anthonisen criteria was applied by 17% and a macrolide was chosen by 30%. Female physicians and those in urban regions scored better in prescribing habits and application of clinical criteria. Specialty affected antibiotic choice in CAP (amoxicillin-macrolide was chosen by 12% I or P vs. 19% GP, p = 0.001) and COPD exacerbations (macrolides in 27% I or GPs vs. amoxicillin-clavulanate in 31% P, p = 0.001). In 88% physicians stated that they were asked to prescribe an antibiotic in retrospect. This was more common in areas outside Athens (p = 0.03) and seemed to correlate significantly with the prescription of antibiotics for sore throat(p = 0.014).\n\nConclusions: There is significant room for improvement in prescribing habits and choice of 1st line agents among community-practicing physicians in respect with respiratory tract infections. Use of simple clinical tools (e.g. 7 days' watchful-waiting rule for sinusitis, Anthonisen's criteria) and strep-test needs to be expanded and embedded in daily practice as a means of appropriate antibiotic prescribing. Patients' pressure to prescribe antibiotics may affect physicians' habits in certain cases. Education of both physicians and patients, especially in non-metropolitan areas, could provide a viable solution in combatting antibiotic overprescribing. Objectives: Many countries require a sick note to claim sickness leave or benefits, necessitating patients to consult a physician and often resulting in an antimicrobial prescription. Socio-economic, cultural and health-regulatory determinants have been demonstrated to be correlated with antimicrobial consumption. Therefore we evaluated the possible relation between different legitimate periods of uncertified sickness leave and antibiotic consumption. Methods: Data on the length of sickness leave without medical certification (SLWC) were collected via e-mail surveys, the European Foundation for the Improvement of Living and Working Conditions and various websites. Countries with self-certification were coded as intrinsically having the longest period. Data on antibiotic consumption between 2000 and 2008 were obtained from the European Surveillance of Antimicrobial Consumption database. Using two-tailed Spearman's rho correlations, we compared the SLWC with the mean antibiotic consumption and also the relation between SLWC and other potentially influential parameters such as uncertainty avoidance index (UAI) and power distance index (Deschepper et al, 2008) , age group distribution, physician density and national income (Masiero et al, 2010) and physician consultation rates (Chahwakilian 2011) (Data Organisation for Economic Co-operation and Development, 2000-2008) .\n\nResults: Sickness leave data could be obtained for 30 European countries. The median SLWC was 3.0 days, ranging between 1 and 14 days. There was an important inverse correlation between SLWC and antimicrobial consumption (rho = -0.387; p = 0.035) (Figure 1 ), with also a similarly high correlation with UAI (rho = -0.483; p = 0.013).\n\nControlling for the UAI greatly reduced the correlation between SLWC and antimicrobial consumption (rho = -0.175; p = 0.40). Of the other factors, none were found to be correlated with SLWC.\n\nThese results indicate that legal requirements regarding sickness leave such as for self-limiting infections, at least partially influence the antimicrobial consumption patterns and interact with cultural aspects. In order to reduce antimicrobial consumption the different legislative bodies and healthcare regulators should screen their regulations on inadvertent counter-productive effects.\n\nO283 Analysis of antibiotic prescriptions done by general practitioner for urinary tract infections J. Prouzergue, E. Denes*, S. Ducroix-Roubertou, C. Aupetit, P. Weinbreck (Limoges, FR)\n\nObjectives: In July 2008, in France, guidelines for the prescription of antibiotics for urinary tract infections (UTI) were edited. These guidelines tried to spare fluoro-quinolones to avoid the emergence of resistant bacteria. So the first lines preferred treatments comprise preferentially fosfomycine-trometamol or nitrofurantoine for cystitis and 3rd generation cephalosporin for nephritis and prostatitis. As general practitioners take in charge a lot of UTI, we wanted to know if they knew and followed these guidelines. Methods: We performed a prospective study. The point of call was urinalysis done in an outpatient biological lab that performs bacteriological analysis for many other labs either in town or in the suburbs. Using this selection method coupled with the criteria of urinalysis diagnosis, we were sure that patients presented an UTI. Patients were excluded if it was a nosocomial infection, if the prescription was done by an urologist, if they were less than 18, if they had permanent urinary catheter. Each GP was called on the phone to retrieve characteristics of the antibiotic prescription.\n\nResults: Our study included 185 urinalysis which were prescribed by 121 GPs. The study population was primarily women (85.4%) with a mean age of 62 years. Diagnoses done by GPs were acute cystitis: 72.4%, prostatitis: 13.5%, nephritis: 11.9%, asymptomatic bacteriuria: 5.4%. Main antibiotics used were: Quinolone (59.5%), furan (17.8%), Cotrimoxazole (6.5%). Only 20.5% of the prescriptions were compliant with the guidelines (i.e. the whole prescription was good: the molecule, the dose, the length of treatment). The right molecule, but not the dose or the length of prescription was chosen in 8.1% of the prescriptions. 42% of the prescriptions for nephritis were wrong, and employed molecule that did not diffuse in the kidney (First-generation quinolone, furan). This mistake was also seen for prostatitis in 24%. Of 70% of the asymptomatic bacteriuria were treated with antibiotics. For cystitis, the inappropriate prescription was accompanied by an over cost of about 694 , namely 7.4 per treatment.\n\nConclusion: GP's prescriptions for UTI do not follow the guidelines, even if they were published 2 years before this study, and thus should have been known and applied. Even if GPs assert that there are aware of the resistant strains emergence, it seems that they did not take into account the ''quinolones spare spirit'' which was one of the backbones of these guidelines.\n\nO284 Clinical microbiology liaison and broad-spectrum antibacterial use in primary care: a joint acute trustprimary care interventional study C. Hill, A. Peel*, R. Sharma, A. Guleri (Blackpool, UK)\n\nBackground: Treatment with quinolones, cephalosporins and coamoxiclav has been associated with an increased risk of developing Clostridium difficile Infection(CDI). Blackpool Teaching Hospitalsprimary care partnership in healthcare associated infections, antibiotic stewardship and infection control programme across whole health economy has been teamworking since last several years. We present a review of strategic planning, initiatives and results of reduction in prescriptions of these agents on C. diificile infections in primary care. Objectives: Sepsis is an important cause of neonatal morbidity and mortality, especially in preterm, very low birth infants. Early diagnosis of pathogens and prompt treatment are critical in preventing severe and life-threatening complications in these patients. However, the clinical recognition of sepsis in neonates is difficult, because the signs and symptoms are often non-specific and blood cultures are rarely positive.\n\nRecently available molecular assays aid rapid detection of microorganisms and improve the diagnostic flow-chart. Methods: A commercial multiplex real-time PCR (LightCycler SeptiFast assay, Roche Molecular Systems) was used in a male, preterm, low birth infant (birth weight 840 g), who had been diagnosed with Stenotrophomonas maltophilia bloodstream infection and received antimicrobial treatment with teicoplanin, netilmycin and ciprofloxacin for 10 days without improvement. LightCycler Septifast assay uses a renovated technology that enables the direct detection from blood samples of a wide panel of bacterial and fungal microorganisms commonly involved in systemic infections. Molecular test was performed in only 0.5 mL of blood, instead of 1.5 mL, unlike to manufacturer's instructions, due to difficulties to draw blood from the small veins. In parallel, new cultures were requested, including peripheral blood and umbilical catheter tip cultures. Results: Within 6 hours upon reception of blood for SeptiFast, DNA of S. maltophilia, Esherichia coli and Candida albicans was amplified in the blood sample and reported to the Neonatal Intensive Care Unit. Antifungal treatment with amphotericin B and 5-flucytocine was then promptly added to his therapy. In the following days, culture-based approaches confirmed molecular results. Blood culture was positive for Gram-negative rods, and after two additional days definitive identification of S. maltophilia was obtained as the initial blood culture. E. coli was grown after 24 hour of incubation in the umbilical catheter tip culture. C. albicans was not recovered neither from blood culture, after 5 days of incubation, nor from catheter tip one, but rectal swabs cultures detected the yeast. Conclusion: The present report gave indications that even in a very low blood volume draw polymicrobial septicemia can be rapidly detected using SeptiFast assay.\n\nO296 Impact of aminoglycoside combination therapy on outcome, length of stay, adverse events, and cost in the treatment of health-care associated pneumonia Objective: Bacterial resistance is an increasing problem that threatens the use of antibiotics to treat infections. Specifically, multi-drug resistant (MDR) gram-negative organisms have become a major concern because of limited treatment options, increased lengths of stay (LOS), costs, and mortality associated with infections. In a study of costs associated with MDR Pseudomonas aeruginosa mean cost of hospitalization was $54 081 (mean LOS = 18 days) for patients with MDR isolates vs. $22 116 for susceptible isolates. These increased costs could in part be attributed to a delay in appropriate empiric therapy and the delay's adverse affect on clinical outcome and mortality. A similar study of P. aeruginosa bacteremias indicated hospital mortality was statistically higher for inappropriate empiric therapy compared to appropriate empiric therapy (30.7% vs. 17.8%; p = 0.079). Healthcare Associated Pneumonia (HCAP) has been described to differentiate pneumonia patients with risk factors for more resistant pathogens.\n\nRecommendations include combination therapy with antipseudomonal beta-lactam and aminoglycoside, which improves the probability of initial appropriate therapy. Another potential impact is synergistic bactericidal effect that may result in faster resolution of symptoms compared to monotherapy. This study will determine the impact of addition of an aminoglycoside in the treatment of HCAP.\n\nMethods: Data were collected retrospectively including all geriatric patients with a diagnosis of HCAP during a two-year period (2009) (2010) . The study group consisted of patients that were treated with an anti-pseudomonal beta-lactam plus aminoglycoside and the control group with an anti-pseudomonal beta-lactam without aminoglycoside. Data was collected for length of stay, inpatient costs, readmission, adverse events attributed to therapy, and clinical outcomes.\n\nResults: Two hundred twenty-seven patients were included for analysis (104 patients received aminoglycoside combination therapy and 123 patients received beta-lactam therapy without an aminoglycoside). Mean observed LOS was 1.83 days shorter with aminoglycoside therapy that resulted in lower overall inpatient costs ($247 416). No significant difference was identified in comparison of readmissions and adverse events attributed to therapy. Conclusion: Short course, high dose aminoglycoside combined with initial anti-pseudomonal beta-lactam therapy in HCAP may have a pharmacoeconomic impact by shortening the LOS and to reduce overall cost.\n\nO297 %fT>MIC of ceftazidime predicts probability of microbiological outcome in the treatment of nosocomial pneumonia caused by Gram-negative bacteria\n\nA.E. Muller*, N. Punt, J.W. Mouton (Rotterdam, Maastricht, Nijmegen, NL)\n\nObjectives: Ceftazidime (CAZ) is a broad spectrum cephalosporin active against Gram-negative micro-organisms (GN) including P. aeruginosa. %fT>MIC has been shown to correlate with microbiological outcome (MO) in animal models and in in-vitro pharmacokinetic models. However, clinical data are still lacking. We explored the relationship of CAZ exposure and MO of Gram-negatives in patients with nosocomial pneumonia (NP) treated with CAZ (2 g t.i.d. infused over 2 hours) to determine the PK/PD index value correlated with outcome using data from a recent randomized, doubleblind phase 3 clinical trial (NCT00210964) comparing the efficacy of ceftobiprole with the combination CAZ and linezolid Methods: Pharmacokinetic (PK) and demographic data from patients in three clinical trials including the NP study were extracted from existing databases to construct a population PK model of CAZ using NONMEM. Individual concentration time curves and %fT>MIC were determined for every individual patient using covariates and/or data from sparse sampling. The MICs used in the analyses were the highest MICs of any GN micro-organism cultured at baseline or end of treatment (EOT Conclusions: ASP initial assessment of extended infusion doripenem demonstrates a trend towards improved outcomes and lower costs. In an era of escalating P. aeruginosa resistance, ASPs must implement alternative dosing strategies for existing antibiotics to optimize patient outcomes.\n\nO299 Software to enable optimally precise dosage adjustment of voriconazole to achieve predefined serum concentration targets in critically patients '' program (LAPK) . The ability of the RightDose to provide estimates for the voriconazole regimen that enabled predefined serum concentrations (e.g. a trough concentration of 1 mg/L) to be obtained was assessed in silico.\n\nResults: Using the prior information contained in the density file from the population analysis, the concentration-time profile of each of 10 patients could be predicted with a high degree of accuracy, despite some patients having nonlinear pharmacokinetics. An updated multiple model file was obtained for each patient. The Big Doser program provided the predicted dosages that were required to achieve a predefined trough concentration of 1 mg/L for individual patients. The process of dosage optimisation can begin with the first dosing interval, meaning that therapeutic and nontoxic serum concentrations can be potentially achieved in the first 48-72 hours of dosing.\n\nConclusion: This software potentially enables to achievement of desired voriconazole serum concentrations in an optimally precise manner and is a potentially useful tool for clinicians. Further prospective clinical studies are required to assess the performance of the software in critically ill patients.\n\nAntimicrobial resistance in the environment Method: A number of environmental sites in a newly built nursing home (n = 21) were selected for monitoring prior to (n = 57) and post habitation (n = 126) by residents. Selected sites included five sites within two single rooms (SR), 4 sites in shared areas (SA) and seven sites in the day-care (DC) area. Copan Eswabs were enriched overnight in peptone water, cultured onto a series of chromogenic agars for detection of Extended Spectrum beta-Lactamase (ESBL) producing Enterobacteriaceae, meticillin-resistant Staphylococcus aureus (MRSA) and vancomycin-resistant Enterococci (VRE). Suspect isolates for MRSA were confirmed using PastorerxTM STAPH-PLUS kit and antimicrobial susceptibility testing; ESBL was confirmed by disk synergy testing, PCR and sequencing; VRE were confirmed by growth on blood and on bile aesculin agar, resistance to vancomycin by CLSI disk diffusion methods and VITEK identification.\n\nResults: Environmental contamination with MRSA was not detected on initial rounds of testing but was detected once staff of the existing NH had begun to work on commissioning. Subsequent to habitation MRSA was detected on 52/126 swabs collected over an 8 week period and from all areas. MRSA was most commonly found on floors (9/12), bed frames (9/ 12), bed side lockers (9/12), arm chairs (5/12), toilet seats (6/18), tables (4/ 12) and door handles (10/48 Objectives: Hospitals are important as foci of intense antimicrobial use. Selection for dissemination of antimicrobial resistance (AMR) within the hospital setting are well recognised but the potential for hospital effluent to carry AMR bacteria into the environment have not been as well studied. In general hospital effluent enters municipal streams and then wastewater treatment plants (WWTP) before it is discharged into the environment. We have evaluated the impact of hospital effluent on AMR Escherichia coli in municipal effluent and the ability of secondary wastewater treatment to remove AMR E. coli. Methods: Water from two municipal effluent systems was evaluated.\n\nOne system (WWTP1) received effluent from a major teaching hospital and the second (WWTP2) did not. WWTP influent and effluent were each sampled on 15 occasions for total E. coli and AMR E. coli by a modified most probably number method (Galvin et al. 2010) . A twosample t-test was used to evaluate differences between two systems and the impact of wastewater treatment on total and AMR E. coli numbers.\n\nResults: AMR E. coli (including resistance to ampicillin, tetracycline and ciprofloxacin) were detected in influent to and effluent from both WWTPs. Both plants significantly reduced the total number of E. coli (WWTP1 p < 0.05, WWTP2 p < 0.05) and generally reduced the number of AMR E. coli. There was no statistically significant difference between the two systems with respect of E. coli to ampicillin, sulphonamide or ciprofloxacin in the wastewater inflow to the WWTP however E. coli resistant to tetracycline and streptomycin were significantly more numerous in influent including hospital effluent.\n\nConclusions: AMR E. coli are common in municipal wastewater. There is very significant variation from sample to sample in terms of numbers of E. coli numbers of AMR E. coli present. Secondary WWTP reduce the number of total E. coli and AMR E. coli discharged into the general environment. The results do not show evidence of any consistent impact of hospital effluent on numbers of E. coli resistant to ampicillin, sulphonamide or ciprofloxacin in influent to a WWTP but suggest that there may be an impact on numbers of E. coli resistant to tetracycline and streptomycin. Objective: Potential risks of aquacultures for the public health include the development of antibiotic resistant (ABR) bacteria/genes reservoir that can reach human through food chain. Our goal was to assess the occurrence and flux of ABR genes among Enterococccus in two AB free trout aquacultures receiving water from secondary rivers. Methods: Two Portuguese trout aquacultures (TRA-A and TRA-B) where AB are not used but feed contain copper (Cu) is given to fishes were studied (winter and summer; 2010-2011). Samples were collected from river water/sediments located upstream (n = 11) and downstream (n = 11) of the TRA, water/sediments from juvenile/adults fish tanks (13), feed (5) and fish (4). They were enriched in peptone water and plated in Slanetz-Bartley plain and supplemented with AB. Susceptibility to 12 AB was studied by disc diffusion (CLSI The aim of the study was to investigate the antibiotic resistance (AR) profiles and the virulence hallmarks of environmental bacteria isolated from wastewater and the receiving river.\n\nMaterial and methods: All samples have been analyzed by classical microbiological analysis (for the identification of faecal coliforms, E. coli enterococci, Pseudomonas aeruginosa), in accordance with the SR EN ISO documents. The antibiotic susceptibility profiles were assessed by classical disk diffusion method (CLSI, 2011), double disk diffusion test (DDDT), chromogenic and E-tests. The adherence to the cellular substrate was assessed on Hela cells and the soluble virulence factors were quantified using specific media with different biochemical substrata for revealing haemolysins, lecithinase, gelatinase, lipase, DN-ase, amylase and iron chelating agents. Simple and multiplex PCR assays were used to identify the genetic support of resistance genes for beta-lactams (blaTEM, blaSHV, blaCTX-M, blaVIM, blaIMP, blaPSE, blaCMY), aminoglycosides (aac(6')-Ib, aac(6')-Ie+aph(2'), tetracyclines (tetA and tetB). Results: The 64 isolated bacterial strains were identified as Klebsiella sp., Citrobacter sp., Enterobacter sp., Aeromonas sp., Burkholderia sp., Cryseomonas sp., Pseudomonas sp., Enterococcus sp. and Escherichia coli. The Enterobacteriaceae tested strains exhibited resistance to tetracycline, aztreonam, aminoglycosides and 14.70% of the total strains exhibited an acquired antibiotic resistance phenotype. Enterococcus strains isolated from wastewater showed both high level erythromycin (73.68%) and tetracycline resistance (61.53%). Different beta-lactam resistance genes were identified among different species, i.e. blaVIM, blaTEM, blaCTX-M and blaCMY. The majority of the aquatic strains exhibited high ability of adherence to the cellular substrate and produced lipase and lecithinase, which could act as pore-forming toxins in case of tissue colonization.\n\nThe results of the present study have shown that the wastewater can provide favorable conditions for the growth of a diverse bacterial community, which constitutes a basis for the selection and spread of antibiotic resistance and virulence determinants, with high risk for human host colonization and for the dissemination of a particular mechanism of resistance in a community. Objectives: In an era of increasing emergence of azole-resistance in Aspergillus fumigatus, combining antifungal agents may be an alternative approach to improve therapeutic outcomes in azoleresistant invasive aspergillosis (IA). The efficacies of antifungal agents can be described by pharmacodynamic indices (PDIs), such as area under the concentration-time curve above the MIC (AUC > MIC). We explored whether the same PDIs that explain efficacy during monotherapy would explain efficacy during combination therapy in an animal model of IA. Methods: Female CD-1 mice were infected intravenously 24 hours prior to start therapy with VCZ-susceptible and VCZ-resistant Aspergillus fumigatus. Fourteen days efficacy data (survival) were determined for various combination regimens of 2.5, 5, 10 and 20 mg/ kg voriconazole (VCZ) plus anidulafungin (AFG) and for each of these agents singly. Groups of 11 mice were treated intraperitoneally once daily, for seven consecutive days. The parameters for each dose as determined from pharmacokinetic experiments, was used to calculate PDI for each strain. Multiple regression analysis was used to determine the importance of various PDIs during monotherapy. The efficacies of the combination regimens were then predicted on the basis of a linear regression analysis for the single agents with the highest r2 value and then predictions were compared with the observed outcome of combination therapy to determine the presence of synergism. Objectives: Voriconazole (VCZ) has become the drug of choice for the treatment of invasive aspergillosis. Although strains with reduced in vitro susceptibility to VCZ have been described, clinical breakpoints have not yet been defined. Pharmacokinetic/pharmacodynamic analysis can help to identify VCZ resistant isolates. The aim of our study was to investigate the efficacy of VCZ against Aspergillus fumigatus (AFM) using a novel in vitro pharmacokinetic/pharmacodynamic (PK/PD) model for identifying drug-resistant isolates. Methods: Two clinical isolates of AFM with VCZ CLSI MICs of 0.125 mg/L (wild type strain), and 2 mg/L (CYP51 mutation TR/ L98H) were included. standard VCZ dosages 4 mg/kg were simulated in a new in vitro PK simulation system with a half-life of 6h and C max of 1.75 mg/L as observed in patients (Purkins et al, AAC 2002). The new system consists of an internal compartment (IC, a 10 mL dialysis tube made out of semi-permeable cellulose membrane allowing the free diffusion of molecules with MW <20 kDa) placed inside an external compartment (EC, a 700 mL glass beaker) whose content is diluted with a peristaltic pump at the same rate as the clearance of VCZ in human plasma. Aspergillus conidia (10^3/mL) were inoculated inside the IC and VCZ was added in the IC and EC. Drug levels were determined by microbiological methods and fungal growth by measuring galactomannan concentrations in the IC with a sandwich-ELISA (Biorad). The area under the drug concentration-time curve AUC0-24 (PK parameter) and the area under the galactomannan concentration-time curve AUCGI (PD parameter) were determined for each dose and isolate for 24 hour. The percent of growth inhibition at each dose was calculated as 1-AUCGI,VOR/AUCGI,GC where AUCGI,VOR is the AUCGI at a certain VCZ dose whereas AUCGI,GC is the AUCGI of the drug free control. Results: The simulated dose 4 mg/kg of VCZ resulted in fAUC0-24 of 10 mg/hour/L which corresponds to the lower 95% fAUC0-24 (58% protein binding) observed in patients receiving the standard dose of 4 mg/kg (10-44 mg/hour/L, Purkins et al, AAC 2002) . By taking into account the population variability of fAUC0-24 second in patients, growth inhibition 100% was observed for the isolate with an MIC of 0.125 mg/L, but 0% for the isolate with an MIC of 2 mg/L. Conclusion: PK/PD analysis of VCZ's in vitro activity strongly indicates that AFM isolates with VCZ CLSI MICs \u20212 mg/L should be classified as resistant. Objectives: In vivo/in vitro correlation of antifungal combination testing is necessary in order to reliably assess the efficacy of combination regimens. We therefore attempted to correlate in vitro checkerboard testing of posaconazole (POS) and amphotericin B Objectives: Selective Digestive tract Decontamination (SDD) and Selective Oropharyngeal Decontamination (SOD) are associated with improved patient outcome and lower carriage rates of antibioticresistant bacteria (ARB) in ICU-patients in the Netherlands. In both regimens patients receive oropharyngeal decontamination with colistin and tobramycin (4/daily). In SDD (but not in SOD) patients receive intestinal decolonization (colistin and tobramycin (4/daily)) and a 4-day course of cefotaxime. We determined unit-wide effects of SDD and SOD on intestinal carriage with ARB in a 16-center cluster-randomized cross-over CRCO study in The Netherlands, comparing 12 months of SDD and SOD. \n\nGonorrhoea is the second most common bacterial sexually transmitted infection in most countries across Europe. Public health control is dependent on prevention measures and effective antimicrobial therapy and will be threatened by the emergence of resistance and therapeutic failure to current therapies. Surveillance of gonococcal infections is of paramount importance to monitor the prevalence of antimicrobial resistance and detect drifts in susceptibility in order to inform national and international guidelines. Many countries in Europe maintain national programmes, but with a mobile population it is essential to have a European wide approach to provide timely and co-ordinated information to prevent the spread of antimicrobial resistant gonorrhoea across Europe. Surveillance for gonococcal antimicrobial resistance across Europe was initiated in 2004, and since 2008 has been a component of the European network for the surveillance for sexually transmitted infections, which is co-ordinated by the European Centre for Disease Prevention and Control (ECDC). The aims of the microbiology component are to improve the quality of laboratory surveillance of gonorrhea, Chlamydia (including LGV) and syphilis and to strengthen surveillance of Neisseria gonorrhoeae susceptibility in EU/EEA Member States and candidate countries. A network of reference and expert laboratories participates in the European Gonococcal Antimicrobial Susceptibility Programme, Euro-GASP. The programme consists of a number of components including sentinel surveillance of gonococcal resistance to therapeutic antimicrobial agents, external quality assurance, assessment of laboratory capacity, training courses and use of molecular typing for public health purposes. As decreased susceptibility and therapeutic failure emerges to the current agents of choice in most countries, the extended spectrum cephalosporins, it is paramount that data is obtained and disseminated in a timely manner. To achieve this objective, sentinel surveillance of antimicrobial resistance has been established in 21 countries. Initially testing was centralised and provided annual data but recently has been extended to include decentralised testing and to provide data twice yearly. A key component of Euro-GASP is to provide training to increase capacity in non-participating countries to improve coverage and representativeness.\n\nNeisseria gonorrhoeae is responsible for causing gonorrhoea, one of the most common sexually transmitted diseases. Although remarkable progress has been made in lowering the incidence of the disease, the worry is that gonorrhoea is becoming a much more difficult infection to treat, increasing the morbidity and the cost. Recently, scientific communities have been discussing the emergence of an N. gonorrhoeae strain resistant to all antimicrobial drugs available. The new strain is called H041, isolated in Japan, and contains genetic mutations making it resistant to penicillin, ciprofloxacin, tetracycline, and also thirdgeneration cephalosporin, including ceftriaxone widely recommended and the first line treatment for gonorrhoea around the world. For that, the multidrug resistant gonococcus may be considered a superbug that initiates a future era of untreatable gonorrhoea. The resistance to ESCs (extended-spectrum cephalosporins) such as cefixime and ceftriaxone, has been documented to be due to the presence of multiple chromosomal changes in the penA gene that form the basis for this reduced susceptibility/resistance. So, the antimicrobial resistant (AMR-NG), multidrug resistant (MDR-NG) and more recently the extensively drug resistant N. gonorrhoeae (XDR-NG) to different class of antibiotics, are an important public health concern for gonorrhoea. Data from the European surveillance of antimicrobial resistance in gonorrhoea by M. Cole et al 2011, showed that 5% of isolates had decreased susceptibility to cefixime, an upward trend in the minimum inhibitory concentrations of ceftriaxone and a high prevalence of resistance to ciprofloxacin (63%) and azithromycin (13%). In Italy, from 2007 to 2011 around 700 isolates have been tested for their antimicrobials susceptibility. In particular, among 114 gonococci isolated in 2009, seven showed a MDR phenotype due to a resistance to four different antibiotics including cefixime (MIC \u2021 0.125 mg/L). Enhancing systematic and sentinel surveillance for AMR and MDR gonorrhoea by promoting the susceptibility testing and studying the genetic mechanisms of the resistance are priority as key points for a control strategy and for combating the spread of MDR gonococci. A sustained and integrated international effort to reduce rates of gonorrhoea and the misuse of antibiotics is required to stem further emergence and spread of multidrug-resistant strains.\n\nNon-mammalian models of infection S319 Dictyostelium: a model to study the pathogenesis of mycobacterial infections T. Soldati* (Geneva, CH) Pathogenic mycobacteria such as Mycobacetrium tuberculosis and M. marinum utilise common strategies to invade phagocytes of the innate immune system, manipulate their otherwise bactericidal phagocytic apparatus and increase the success of cell-to-cell transmission. M. marinum is the closest relative to mycobacteria of the tuberculosis complex and provides a powerful model to study the pathogenesis of tuberculosis in genetically tractable model organisms, such as Drosophila and zebrafish. The soil amoeba Dictyostelium discoideum has become a popular experimental model to study the cell-autonomous innate immune response, because D. discoideum and human phagocytes share several conserved functions, such as engulfment killing and digestion of microorganisms by phagocytosis. Using D. discoideum a host, we identify and characterize mycobacterial and host factors that modulate resistance to infection and cell-to-cell spreading. We study bacteria sensing and killing and the role of NADPH-oxidases in ROS production. We study the specific roles of the three NOX isoforms in ROS production and susceptibility to mycobacteria infection. We also study the roles of three paralogs of the CD36 family of scavenger receptor type B. One is present at the surface and acts as a receptor, while the other two are lysosomal and are implicated in trafficking of hydrolases. Like M. tuberculosis in macrophages, M. marinum interferes with phagosome maturation by modulating membrane trafficking events to and from its compartment. We developed both quantitative-comparative proteomic techniques and live cell imaging with various probes of the phagolysosomal pathway to study the mechanisms of maturation arrest. In a final stage of infection, M. marinum and M. tuberculosis escape from their vacuole to the cytosol.\n\nWe study the complex importance of a putative mycobacterial poreforming toxin and of the autophagy pathway in the genesis, maintenance and breakage of that compartment. Overall, our studies demonstrate the conservation of both pathogen virulence strategies and host defence mechanisms, ensuring the success of D. discoideum as a powerful and simple host-pathogen model system to study mechanisms of mycobacterial infection. In that context, our most recent efforts are directed at using this alternative system to screen for small chemicals that interfere with the infection, either as anti-mycobacteria virulence or host immunity-boosting compounds. Results: Ratios of the two strains were skewed towards one or other predominating. This effect was lost on phagocyte depletion. Mathematical modelling of pathogen dynamics was consistent with a small number of bacteria surviving within phagocytes leading to disseminated infection. This was confirmed in a mouse septic arthritis model, in which injected bacteria form abscesses in the kidney. Using two marked strains, these abscesses arose more commonly than expected from predominantly one bacterial population or the other, again suggesting a niche exists in which these bacteria can evade host defence and ultimately re-establish foci of infection. To test whether this niche was within a sub-population of phagocytes, individual populations of neutrophils or macrophages were depleted in the zebrafish. Neutrophil-depleted larvae showed better survival compared to macrophage depleted, but lower variance of the ratios of the two SA strains, suggesting neutrophils might provide a niche in which SA can avoid host killing. Conclusion: We predict that understanding the nature of this phagocyte niche will enable its manipulation, and provide a novel therapeutic strategy for the treatment of SA disease. The finding of evolutionary conserved innate immune signaling pathways governing antimicrobial response in Drosophila highly stimulated the understanding of metazoans immune mechanisms. Two major pathways, Toll and Imd, are activated in Drosophila fat body cells following bacterial infections leading to the synthesis of large quantities of antimicrobial peptides secreted in the hemolymph. These pathways can also be differentially activated in exposed epithelial tissues (trachea, gut, genitalia). Following bacterial recognition by immune receptors, signaling is ensured by conserved molecules such as proteases, adaptators, kinases and NF-kB transcription factors. Ubiquitination is also a signaling mechanism conserved from flies to humans; we notably demonstrated that Imd ubiquitination by lysine 63linked Ub chains is required for signal transduction and is controlled by the deubiquitinase USP36/Scny. Beside this humoral response, Drosophila differentiates phagocytic cells, deriving from the hemocyte blood cells lineage, ensuring bacterial phagocytosis as well as cytokines and antimicrobial peptides secretion. By expressing the Pseudomonas aeroginusa ExoS toxin targeting RhoGTPases, we specifically disrupted hemocytes phagocytic function in vivo and demonstrated the essential contribution of Rac2 and phagocytosis in Drosophila immunity together with the feasibility of using transgenesis to investigate the in vivo mechanisms of action of a bacterial toxin.\n\nIn fact, the finding by several laboratories that human pathogens are using similar virulence factors to infect insects and mammals opened avenues in using Drosophila as a non-mammalian host to monitor bacterial virulence. For example, the role of type III secretion system and quorum sensing in Pseudomonas aeruginosa-induced flies killing has been demonstrated.\n\nTo date, an original field of research consists in exploring hostpathogen interactions by using oral route of infection with either natural Drosophila pathogens or human pathogens and evaluating the local immune response including tissue damage and repair. In this line, we and others observed that some Pseudomonas strains can establish biofilms in the Drosophila crop or anterior midgut and display reduced virulence towards their host. Undoubtedly, flies still have a high amount of information to deliver about molecular mechanisms and physiology of anti-bacterial defense and bacterial virulence in a living organism. C. elegans is a widely-used model in biology. It has been adopted by a growing community of researchers investigating pathogen virulence and host defences. We use C. elegans to dissect the molecular and cellular basis of innate immunity to fungal infection. C. elegans responds specifically to different types of infection through the activation of distinct signaling pathways. Fungal infection of the epidermis results in the production of multiple effector proteins, including antimicrobial peptides such as NLP-29 or CNC-2. Through a candidate approach and a small-scale EMS screen, using fluorescent reporters, we have identified many components of the innate immunity cascades involved in the regulation of the nlp-29 and cnc-2 genes. We showed that a conserved pathway involving a protein kinase C acting upstream of a p38 MAPK cascade (Ziegler et al., 2009 ) and a noncanonical TGF-beta pathway (Zugasti and Ewbank, 2009) regulate nlp-29 and cnc-2, respectively. The two pathways are linked by a STAT factor that is required for the expression of both genes (Dierking et al., 2011) .\n\nWe are currently focusing mainly on the regulation of nlp-29 and conducting parallel high-throughput approaches in order to get a more complete understanding of the networks regulating this gene. We conducted a large-scale EMS screen and isolated 59 independent alleles that block the induction of an nlp-29 reporter after infection. They are being cloned by direct whole-genome resequencing. We have also conducted a complementary RNAi screen using libraries covering the whole genome and an automated analysis platform. Together, our results will give a global view of the genes and pathways that regulate antifungal peptide gene expression. The relevance of our findings to mammalian innate immunity will be discussed.\n\n[1] Dierking K., Polanowska J., Omi S., Engelmann I., Gut M., Lembo F., Ewbank J.J., and Pujol N. (2011) . Unusual Regulation of a STAT Protein by an SLC6 Family Transporter in C. elegans Epidermal Innate Immunity. Cell Host Microbe 9, 425.\n\n[2] Ziegler K., Kurz C.L., Cypowyj S., Couillault, C., Pophillat, M., Pujol, N., and Ewbank, J.J. (2009 (Figure) . Pars plana vitrectomy was performed and an approximate 1-centrimetre-length round worm was removed. The immature adult of Angiostrongylus cantonensis was identified by parasitologist. The bursa indicated that this is a male worm (Figure) . Because of absence of headache and eosinophilia, lumbar puncture was not performed and anthelminth drugs were not prescribed. After 4-month-follow-up, he still has no CNS symptoms, but his eyesight has not improved due to retinal detachment.\n\nConculsion: The prevalence of Angiostrogylus is rare comparing to other ocular parasites, such as Toxocara, Gnathostoma, and Cysticercosis; however, this parasite causes severe disability to patient. History taking about patient's eating habit and careful fundoscopic examination will lead to proper diagnosis and better treatment outcome. Moreover, prevention of the disease by encouraging thorough cooking of mollusks and other paratenic hosts is important. Results: The study included 26 men and 37 women with an average age of 33 years. The mean time of permanence in spain was 958 days. The most frequents countries of origin were Equatorial Guinea (27%), Ecuador (20.6%), Senegal (9.5%), Nigeria (9.5%), and Ethiopia (4.8%). Eighteen percent of patients were immigrants and the rest were travellers. The most frequents symptoms were abdominal pain (60%), eosinophilia (28%) and the rest are asymptomatic. All patients showed positive serological test and in one patient the microscopic visualization was positive. Thirteen patients have eosinophilia in blood (mean 2552 cells/mm3, limits 540-17 000 cells/mm3). HIV co-infection was present in eight patients (70%) with a median CD4 T cell count of 250 cells/mm 3 . One patient had a HTLV-I coinfection. Other underlying diseases were: hepatitis C (9.5%),chronic hepatitis B (5%), All patients were treated with ivermectin. None patients developed hyperinfection syndrome. In all patients the serology became negative six months before the treatment. Two patients leave the follow-up and the rest are yet to follow. All patients survived.\n\nConclusions: The presence of infection for S. stercolaris is frequent in high-risk patients although without symptoms. To prevent potentially fatal hyperinfection syndrome, it is necessary realized screening with several stool examinations and serologic testing in risk groups and in infected instituted the treatment. Objectives: Dientamoeba fragilis was originally described as an apathogenic protozoan organism, but over the years many reports have provided evidence for the pathogenic potential of this protozoa. Patients with a D. fragilis infection suffering from chronic gastro-intestinal complaints that remain unexplained after thorough investigation are therefore often treated with the intention to eradicate the D. fragilis infection from the gut. Since no consensus exists about treatment for dientamoebiasis, we performed a retrospective follow-up study to compare the efficacy of paromomycin, clioquinol and metronidazole. Methods: Patients were included when between January 2004 and January 2011 D. fragilis was demonstrated in a stool sample and results of a follow-up stool sample were available. Paromomycin (three daily doses of 500 mg for 7-10 days), clioquinol (three daily doses of 250 mg for 7 days), metronidazole (three daily doses of 500 mg for 7-10 days), were prescribed off-label and after informed consent of the patient. Other patients received no treatment; a wait and see policy. D. fragilis was demonstrated in stools of 451 patients (8%), of which 127 cases could be included in this study, because for these patients follow up TFT results were available.\n\nResults: Treatment with paromomycin (n = 63) resulted in parasitological cure of D. fragilis in 98% of cases and in one patient the parasite load was reduced by 16%. Treatment with clioquinol (n = 15) eradicated D. fragilis in 87% of cases and in two patients the parasite load was reduced after treatment by 50 and 83%. Treatment with metronidazole (n = 10) resulted in parasitological cure of D.\n\nfragilis in 70% of cases, but in three patients in the parasite load was not reduced and even increased in two of them. When patients received no treatment (wait and see policy, n = 39), D. fragilis was spontaneously cleared in 46% of cases. The parasite load in untreated patients not clearing D. fragilis was rather variable; in most patients a decrease in parasite load was noted but substantial increases were also observed. Conclusion: Our results showed that D. fragilis infections were spontaneously cleared in 46% but increased in 25% of untreated cases.\n\nAlthough metronidazole is often listed as the drug of choice, paromomycin was shown to be the most effective drug for eradication of D. fragilis in adults with a parasitological cure rate of almost 100%. The aim of the present study was to analyze the Blastocystis subtypes among the isolates from pediatric patients in Saint-Petersburg and identify the correlation between the subtype and gastrointestinal symptoms. Methods: One thousand and seventy-three stool samples were collected from healthy children or children with gastrointestinal disorders. Seventy eight isolates were positive for Blastocystis. The isolates were analyzed with specific primers for 1-9 type employing PCR. Results: Analysis of the level of Blastocystis colonization showed that subtype 3 was the most common in both symptomatic and asymptomatic groups (73%). Subtype 2 was detected in 24% of all isolates, subtype 1 in 15%, subtype 4 in 2.5% and subtype 7 in 3.8%. Subtypes 2 (32%) and 3 (24%) were found in the isolates from asymptomatic the group without gastrointestinal symptoms. In symptomatic groups we mainly detect subtypes 3 (43.4%) and 1 (22.6%) separately or together (24.5%), subtype 4 in 3.7% and subtype 7 in 5.6% of isolates. Interestingly, only patients from the group with subtype 7 were not sensitive for metronidazole after treatment. Conclusion: The present study suggests that subtype 3 is the most common genotype in pediatric patient in Saint-Petersburg. It is quite possible that subtype 2 is a non-pathogenic genotype of Blastocystis. At the same time subtype 7 might be associated with metronidazole resistance of Blastocystis. These facts clearly demonstrate that there is a need of preliminary identification of the parasite before the treatment. Human giardiasis is considered a zoonotic infection, although the role of animals in the transmission to humans is still unclear. When considering the zoonotic potential of each genotype, the Assemblage A and B are believed to represent a major risk for human health since both appear to be infective to a wide range of wild and domestic host species.\n\nIn this study, we analysed 140 DNA samples isolated from human and animal stool specimens, to get more insight in the different G. lamblia assemblages/genotypes present in Portugal and the potential involvement of animals, domestic and sylvatic, in the transmission of G. lamblia infection. Human faecal samples were collected from clinical laboratories and schools. The dog samples were obtained in kennel situations and wolves DNA faecal samples were obtained during fields studies on wolves taxonomy in protected Natural Park of Tr\u00e1s-dos Montes, all from north of Portugal. The parasitological study was performed by microscopy observation (direct examination and after concentration by Copropack S.A.F, Biomedics, S.L.) and G. lamblia coproantigen detection was performed by immunochromatography kit. The tpi and beta-giardin gene locus was amplified by nested-PCR and PCR products were submitted to PCR-RFLP analysis and sequenced with dRodamina Terminator Cycle Sequencing kit. The reading was performed using an ABI PRISM 310 automatic DNA Sequencer and the obtained sequences were individually analyzed by computer platforms Chroma Lite 2.01 (Technelysium Pty Ltd), BLAST, ClustalW and MEGA 4.0.\n\nResults showed that the Giardia human isolates (n = 34) were divided into the two main assemblages, A (94.1%) and B (5.9%). The canine isolates (n = 31) belonged to the assemblages A (67.7%), assemblage C (6.5%) and assemblage D (6.5%). We also identified 2 co-infections including the assemblages A and C (6.5%) and 4 co-infections including the assemblages A and D (12.9%) in dogs. An interesting finding was the identification of an A2 genotype, traditionally linked to human G. lamblia infections, in a dog sample. The wolves isolates (n = 20) were include only in the genotype A1. Phylogenetic analysis revealed a close relationship between human and animal assemblage A isolates. These findings suggest that domestic and sylvatic animal may play an important role in zoonotic transmission cycles of the parasite. This work was supported FCT POCTI (FEDER).\n\nO338 How long does it really take for anti-toxoplasma IgG antibody avidity to reach a full maturation? Objectives: In a previous Cochrane review we showed that oral iron supplementation in malaria endemic areas was not associated with increased mortality or clinical malaria. We preformed a broader metaanalysis and systematic review in order to assess the effect of any type of iron supplementation for children in malaria endemic areas on malaria-related outcomes and overall mortality. Methods: Systematic review and meta-analysis of randomized controlled trials comparing any iron supplementation (oral, parenteral or food/drink fortification) vs. placebo, no treatment or a control intervention that does not include iron, in children living in malaria endemic areas. Trials that do not report malaria-related outcomes were be excluded. Primary outcomes included clinical malaria and overall mortality. Risk of bias was assessed using domain-based evaluation. All data were extracted independently by two reviewers. Relative risks (RR) with 95% confidence intervals (CI) were pooled using fixed effects meta-analysis, when heterogeneity was not significant (inconsistency measure <50% Background: Malaria morbidity and mortality in Uganda continue to escalate despite standard prevention and control measures currently inplace. Whereas prompt and accurate laboratory diagnosis of malaria is the key to the effective management of malaria, clinical syndromic diagnosis has been the most widely used in Uganda and other resource poor countries. Objective: To determine the incidence of anti-malarial drug abuse among patients clinically diagnosed with malaria in Bushenyi, Uganda. Methodology: A cross-sectional study was undertaken at outpatient departments of ten health center (IIs) in Bushenyi, Uganda between April and June, 2011. Rapid diagnostic Test for malaria parasites was performed on recruited 217 female patients (66.2%) and 111 male patients (33.8%) who were clinically diagnosed with malaria. Fifteen health workers at the ten participating health centre IIs were interviewed on criteria used to prescribe anti-malarial drugs and ten key informants interviewed on how they perceived being treated without laboratory results. Rapid diagnostic test were used for the malaria test Results: All (100%) health workers found in the 10 participating health Centre IIs in Bushenyi district were aware of the new policy of routine malaria laboratory diagnosis of all malaria case suspects, but they were all still using the presumptive treatment of malaria basing on clinical signs and symptoms because they had no access to laboratory services. Anti-malarial drugs were wrongly prescribed for febrile patients in 93.6% of the total time malaria was diagnosed in the health centers. Thus this study shows that antimalarial drugs were correctly administered to febrile patients in 6.4% of the total time malaria fever were suspected confirming the fact that 93.6% of the febrile patients who received malaria drugs simply abused it because they had no malaria disease. Conclusion: In our study we did not find a significant difference in mortality between patients with BSI due to ESBL positive E. coli and BSI with non-ESBL producing E. coli. However, patients who suffered a BSI from an ESBL producing E. coli stay significantly longer in the hospital than patients with a BSI due to a non-ESBL producing E. coli strain. Furthermore we have to determine how many patients with sepsis due to an ESBL positive E.coli strain directly received adequate antimicrobial therapy. Microbiological reports were probabilistically linked to England Hospital Episode Statistics (HES) data, which captures data on admission and discharge dates. Reports for children who had a positive blood culture taken two or more days after admission were defined as HA BSI and were analysed in terms of pathogen and AMR.\n\nResults: A total of 8699 episodes of paediatric BSI were reported to LabBase during the study period, of which 82% were successfully linked to HES inpatient records. Of these 1734 (28%) episodes of BSI fulfilled the criteria for HA BSI. The median age at time of BSI was two years. The most commonly reported organisms were coagulasenegative staphylococci (30%), Enterococcus spp. (13%), Staphylococcus aureus (11%), Escherichia coli (8%) and Klebsiella spp. (7%). The overall resistance to nationally recommended empiric therapy for sepsis (broad-spectrum antipseudomonal beta-lactam antibacterial) was 1-4%.\n\nConclusion: This study linked a high proportion of national microbiology data with clinical data. The proportion of HA BSI was quite low and reflects the high number of cases presenting from the community or with a positive blood culture within two days of admission, although a proportion of these cases may have had recent healthcare contact. AMR to recommended national empiric therapy for HA BSI was low. This study demonstrates that data linkage is a very useful tool for expanding epidemiological investigation and determining the proportions of HA BSI in children. We have treated 10 cases of enterococcal endocarditis with ampicillin plus gentamicin association, 10 cases with daptomycin alone or in association with ampicillin and two cases with other therapies. Surgery was necessary in 12 (55%) cases of enterococcal endocarditis. Specifically, HLAR enterococcal endocarditis were treated with ampicillin plus daptomycin association in three cases (one out of three was due to E. faecium), with daptomycin alone in two cases, with ampicillin alone in one case, and with ampicillin plus levofloxacin in one case. The association of daptomycin plus ampicillin was successfully used in two other cases of enterococcal endocarditis.\n\nWe report an overall 6-month mortality rate of 9.1% among enterococcal endocarditis. All patients treated with daptomycin, alone or in association with ampicillin, had a favourable outcome. Conclusion: As reported by the main case series, enterococci resulted as the third cause of infectious endocarditis in our study. Enterococcus faecalis represented the main enterococcal isolated strain. HLAR is an increasingly common resistance mechanism, accounting for 36.4% of our enterococcal endocarditis cases. Although limited by its number, our report shows good results of daptomycin use either alone or in association with ampicillin for the treatment of these infections. tigecycline, tetracycline, chloramphenicol, rifampicin and ciprofloxacin were determined with broth microdilution method; for daptomycin the Etest method was used. Results were interpreted with the EUCAST and CLSI breakpoints. Patients' clinical and epidemiological data provided in the questionnaire were also analyzed. Results: Among patients 56% were men and 42% women (2%, gender not reported). Age distribution was as follows: 2.3% newborns, 5.8% age 1-25, 15.5% age 25-50, 37.8% age 50-65 and 37.8% above 65 years old (no data for 0.8%). Mortality rate was 17.0%. The most frequent causes of hospitalization were bloodstream infections (bacteraemia 42.8.%, and septicaemia 21.6%); other diseases included abdominal infections, chest infections, endocarditis, pelvic infections and meningitis. Risk factors involved: hospitalization during last 6 months (47.1%), ICU stay (22.4%) and surgery (24.7%). Among isolates 141 (54.4%) were classified as Enterococcus faecalis, 113 (43.6%) as Enterococcus faecium and 5 (2.0%) as other Enterococcus spp. The ratios of nonsusceptibility among E. faecalis and E. faecium were as follow: penicillin 0% and 92%, ampicillin 1.4% and 97.3%, vancomycin 16.3% and 10.6%, teicoplanin 0.7% and 6.2%, gentamicin 54.6% and 86.7%, streptomycin 53.2% and 88.5%, linezolid 0% and 0.9%, tigecycline 2.1% and 9.7%, tetracycline 90.0% and 56.6%, chloramphenicol 29.8% and 21.2%, rifampicin 67.4% and 94.7, ciprofloxacin 60.3% and 100%, daptomycin 0% and 0%, respectively. Conclusion: Nearly the same number of E. faecalis and E.faecium was observed in invasive infections from May 2011 till June 2011 in Poland. The infections affected mainly patients older than 50 years and mortality rate was 17%. High ratio of non-susceptibility to older antibiotics was observed with the exception of glycopeptides, but very good susceptibility to new antibiotics: tigecycline, linezolid and daptomycin was detected. specialities. MDR was more prevalent in isolates from blood of patients aged 1-44 years (7%) than in those of 45-74 (4%) or \u202175 years (2%); the 5 individual agents all showed the same downward trend of NS with increasing age. Isolates from children under one were less commonly MDR (2%), with most agents, especially ciprofloxacin, showing less NS than in older patients. RTI P. aeruginosa showed a similar pattern of NS with age. Blood isolates originating from the genitourinary tract were less often MDR (1%) compared with those from other known sources (4-6%). Conclusion: The main factors predicting increased MDR in P. aeruginosa were ICU location and younger age (except infants); genitourinary focus of infection was associated with reduced MDR. Multiple NS in blood and respiratory infections was not unduly prevalent in recent years, with 7-13% of isolates NS to \u20212 agents, 3-7% NS to \u20213, and 1-2% NS to \u20214. Occasional isolates (<1%) were NS to all five tested agents. Overall, Enterobacteriaceae were resistant to third generation cephalosporins in 18.2%, to aminosides in 11.9% and to fluoroquinolones in 17.9%. The resistance rate of A.baumannii was 25.8% for ceftazidim and 6.8% for imipenem. The resistance rate of P. aeruginosa to ceftazidim and imipenem were 13.8% and 15.5%, respectively.\n\nConclusion: The trend of resistance was likely an increase of resistance for invasive E. coli, a high prevalence of resistance to third-generation cephalosporins, fluoroquinolones and aminosides for K. pneumoniae isolates, an increase prevalence of resistance to carbapenems for A. baumannii and a decrease of resistance to methicillin for S. aureus. However, as compared to EARS-Net surveillance who report a north to south gradient, our data likely suggest that infection control measures in our hospitals in Marseille, lead to a lower prevalence of resistance in bacteria from bloodstream infections as compared to the national data. West Nile virus (WNV) is a mosquito-borne Flavivirus belonging to the Japanese encephalitis antigenic complex in the family Flaviviridae. WNV is maintained in an enzootic cycle between birds and ornithophilic mosquitoes, mainly Culex species, while humans, horses, and other mammals are considered incidental or dead-end hosts. Infection in humans mainly occurs asymptomatically or, in approximately 20% of cases, with a febrile illness, while, in <1% of infections, it occurs with a neuroinvasive disease, which is often severe or even lethal in elderly and immunocompromised individuals. First isolated in 1937 in the district of West Nile in Uganda, in the last 30 years the virus has been responsible for several human and equine outbreaks in Europe and in the Mediterranean basin. In recent years, epidemics caused by WNV in humans and horses have become more frequent in Southern European countries, such as Italy and Greece. The increasing number of WNV outbreaks is associated with the emergence of novel viral strains, which display higher virulence and greater epidemic potential for humans. In addition, both WNV lineage 1 and lineage 2 have been isolated in recent years in European countries. Recent research findings on WNV epidemiology, biology, vaccines and drugs under development will be presented.\n\nT. Avsic-Zupanc* (Ljubljana, SI)\n\nHantaviruses, which are hosted by small mammals, are emerging pathogens having gained more and more attention in the last decades. Most hantaviruses are rodent-borne, although several novel hantaviruses with unknown pathogenic potential have been identified in a variety of insectivores (shrews and a mole). Each hantavirus is primarily carried by a distinct rodent/insectivore species and is maintained by cyclical transmission between persistently infected rodents, with incidental infection of humans. Hantaviruses are found worldwide and are known to cause two serious and often fatal human diseases: hemorrhagic fever with renal syndrome (HFRS) in Asia and Europe and hantavirus cardiopulmonary syndrome (HCPS) in the Americas. The mortality rates vary from 12% in HFRS up to 50% in HCPS. Both diseases are acute febrile infections, usually acquired through inhalation of aerosols or dust particles contaminated with virus containing rodent excreta. HFRS is characterized by renal failure and hemorrhagic manifestations that vary from petechiae to severe internal bleeding. Pneumonia and cardiovascular dysfunction are characteristic of HCPS. Increased permeability of micro vascular endothelium seems to be a common effect of hantavirus infection. Although, the pathogenesis of hantavirus infection is poorly understood, it is suggested that not the direct viral cytopathology, but immune mechanisms may play an important role in a complex pathogenesis. The diagnosis of acute hantavirus infection is primarily based on serology, since viral RNA cannot be regularly detected in the blood or urine of patients. For immunization, inactivated virus vaccines are licensed in certain Asian countries. Moreover, several classical and molecular vaccine approaches are in pre-clinical stages of development.\n\nNo specific therapy is used in Europe, although both Ribavirin and interferon-a have been successfully used in trials in China. Both, the amplitude and the magnitude of hantavirus outbreaks have been increasing. The environmental changes may affect the geographic distribution, abundance, and the dynamic of the carrier rodent species, and thus the epidemiology of hantavirus disease. Hantaviruses and diseases that they cause deserve the attention of researchers, public health officials and increased clinician awareness with a regard to their impact on public health.\n\nAutomation of the bacteriology lab; what, when and why S382 How to choose the optimal automation for your lab\n\nInoculation of samples on agar media and broth is a repetitive and fastidious work that is amenable to automation. Several automated inoculation systems are now available with different procedures and characteristics. Some such as the Wasp (COPAN) and Innova (Becton-Dickinson) mainly represent a mechanization of human tasks, using sterile calibrated loops whereas others such as Previ-Isola (BioMerieux) and Inoqula (KIESTRA) represent true innovative automation, that use a sterile comb or sterile bead, respectively. Each system has some advantages and disadvantages. Some clues (summarized in a recent review article: Greub & Prod'hom Clin Microbiol Infect 2011) will be provided to temptatively help clinical microbiologists in making their decision. Indeed, the choice of one of these systems should take into account the characteristics of the instrument as well as the characteristics of the laboratory and the type of samples that will be processed.\n\nOther important aspects that are important to guide the choice include (i) the compatibility of the LIS system and (ii) the compatibility with downstream automated procedures such as automated colony picking systems and/or automated agar plates reading.\n\nWhat does it take for a plasmid to ''go global''? It's all in the genes..... Global antibiotic resistance issues reflect complex global problems. Any antibiotic use selects for resistant bacteria and we use antibiotics extensively to treat and prevent infections in humans and animals; the sequelae impact also on the environment. Resistance is as old as antibiotic production, and many of the resistance genes that we recognize today evolved millennia ago. These genes have moved through bacterial ecosystems to genera in the environment and in animal (including human) hosts, and some eventually reach a species that causes infection and is subjected to susceptibility testing. Multiresistant Enterobacteriaceae are one of the greatest challenges encountered by clinical microbiologists, and we have witnessed two waves since 2000. Broad usage of oxyimino-cephalosporins selected first for ESBL producers, particularly those with CTX-M enzymes and, to a lesser extent, bacteria with acquired AmpCs. These were countered by increasing use of carbapenems for serious infections, and in consequence we now face an international onslaught of Enterobacteriaceae that have acquired a diverse array of carbapenemases. These acquired beta-lactamases are usually encoded on plasmids that encode resistance to multiple other antibiotic classes. Genome sequencing reveals that these plasmids are built in modular fashion; a fundamental selfreplicating backbone of essential genes then accumulates resistance genes through successive rounds of transposition and recombinational events. Plasmids can be considered ''successful'' if they are readily transmissible between bacterial strains, species or genera and/or if they are hosted by a successful bacterial strain or clone. Both scenarios have contributed to the global dissemination of ESBLs and carbapenemases, with exposure to antibiotics the most obvious and direct selective pressure. With few new antibiotics in development, preserving the efficacy of those we have must be a priority for all prescribers.\n\nThe time and the place (public health system breakdown, geography/catastrophe -tsunami/earthquake)\n\nAntibiotic resistance is definitely under a rising trend worldwide. Nosocomial but also community-acquired multidrug resistant bacteria are now reported quite often, leading to complicated therapeutical strategies, and ultimately to therapeutical failures and poor outcomes. That means that even in good sanitary conditions and highly advanced healthcare settings, the management of infections related to those multidrug resistant bugs is quite difficult. Obviously, any public health system breakdown, induced by any catastrophe/war, and leading to poor sanitation, emergency practices, poor access to medication, severe pathologies and trauma, and limited healthcare workers is rising up the risk for occurrence, spread and epidemicity of those resistant bacteria.\n\nThe unfortunate frequent and current experience of such situations has to be considered to improve their future management. Also, this has to be an opportunity to analyse the epidemiology of resistance when those events happen in some geographical areas where very limited data were available, in order to prevent the dissemination of those bugs in other areas.\n\nClinical and experimental immunology Objectives: Staphylococci (S. aureus and coagulase-negative staphylococci [CNS]) may infect bone and fibroblast cells in order to persist intracellularly as small colony variants (SCV). As such bacteriainfected cells may be the target of natural killer (NK) cells, that are innate lymphocytes specialized in the recognition and killing of intracellular pathogens, we hypothesized that a low peripheral natural killer cell activity may be a risk factor for bone and joint infection (BJI) by SCV staphylococci.\n\nMethods: Cross-sectional study including 10 immunocompetent patients, followed in our institution, with past or currently treated chronic BJI due to staphylococci with SCV phenotype (SCV + BJI group; eight with an orthopaedic implant; seven due to S. aureus, three to CNS), defined by typical phenotypic aspect of colonies from preoperative specimen cultures. Control groups include: (i) nine patients with chronic staphylococci BJI without SCV phenotype (SCV-BJI group; all with implant; five due to S. aureus, four to CNS); (ii) six patients with chronic BJI due to other pathogens (other BJI group; three with implants); and (iii) 19 healthy volunteers (HV). PBMC isolated from patients were analyzed for surface CD3, CD8, CD56, CD57, CD69, NKG2D, CD16, NKp30, 2B4, DNAM1 and intracellular perforin and NKG7 expression using multiparameter flow cytometry. In a separate set of experiments, PBMC were stimulated for 4 hours with or without K562 cells (classical NK cell targets). Degranulation (CD107a exposure) and intracellular IFN-g expression by gated NK cells were measured by flow cytometry. Objectives: In human leishmaniasis Th1/Th2 dichotomy and the role of CD8+ T cells in protection is not clearly defined. In this study based on CCR7 expression total memory vs. na\u00efve CD8+ T cell populations were isolated from volunteers with self-healed cutaneous leishmaniasis (CL) and cytokine productions were analysed. Methods: Leishmanin skin test (LST) was performed for all volunteers. Blood samples were collected from 13 volunteers with history of CL caused by either L. major or L. tropica and 18 healthy volunteers from non-endemic area. Using enrichment cocktail mAbs and magnetic nanoparticles CD14+CD16-monocytes and total memory CD8+ T cells were isolated from autologous peripheral blood mononuclear cells (PBMC). For na\u00efve T cells, non-naive cells depleted and CD8+ T cells positively selected using CD8 microbeads. Monocyte derived macrophages (MDM) were produced by incubation of adherent monocytes in cRPMI at 37\u00b0C, 5% CO2 for 6 days. Isolated T lymphocyte populations were co-cultured with 1:10 autologous MDM in the presence of PHA or soluble Leishmania antigen (SLA). Cytokine productions were titrated on culture supernatant after 72 hours incubation at 37\u00b0C with 5% CO2. Part of the SLA cultured cells was harvested, stimulated with PMA/Ionomycin calcium, permeabilized, stained for intracellular IFN-g, and analyzed using flow cytometer. Results: The mean diameters of skin indurations were significantly higher in CL volunteers (8.7 \u00b1 3.62 mm) compared to healthy controls (0 mm) (p < 0.005). The mean \u00b1 SD percentage of memory T cells was 5 \u00b1 1.8% and of na\u00efve T cells was 9 \u00b1 2.2% retrieving from PBMC. Stimulation of isolated CD8+ memory T cells from CL volunteers induced a significantly higher IFN-g production compared with that of controls (p < 0.005). No significant difference was seen in the production of IFN-g from naive T cells and in the production of IL-10 from na\u00efve or memory T cells between CL and controls. Significantly higher numbers of memory CD8+ T cells from CL volunteers were positive for intracellular IFN-g than the same cells from controls (p < 0.001). No significant difference was found in the frequency of IFN-g positive na\u00efve CD8+ T cells between CL and controls.\n\nConclusion: The role of CD8+ T cells as a source of IFN-g production has been suggested before, in this study memory population is shown responsible for IFN-g production in volunteers with history of CL.\n\nPurification of different memory subsets is needed for further study.\n\nO394 The cytomegalovirus protein pUL32 is highly conserved among clinical strains although a major target of the humoral and cellular immune response Objectives: The Cytomegalovirus (CMV) large tegument protein pUL32 (pp150) generates a strong humoral and cellular immune response to the multiple epitopes that are dispersed over the 150 kDa protein. In analogy to other CMV antigens, host immune pressure may be expected to generate genetic diversity in the UL32-gene. Particularly CMV strains in patients with chronic lymphocytic leukaemia (CLL) may be under a strong evolutionary force. The immunoglobulin (Ig) expressed on selected leukemic cells interacts with pUL32 and these cells constitute >90% of the leukocyte fraction in CLL patients. Nevertheless, knowledge on genomic diversity of the UL32 gene coding for pUL32 among clinical strains is very limited, so far. Methods: We screened 200 consecutive CLL patients for the presence of CMV-DNA and sequenced the UL32 gene to determine the genomic diversity among clinical CMV strains. Results were analyzed with respect to CMV-seropositivity and sequence of the Ig expressed on leukemic cells. As references, UL32 sequences of CMV strains were used that were detected in patients with primary CMV infection (n = 5), in additional CLL patients treated with an anti-CD52 antibody (n = 4), or previously studied and available via PubMed (n = 14).\n\nResults: CMV-DNA was detected in 3% and CMV-specific IgG antibodies in 71.5% of the 200 CLL patients. Interestingly, CMV-DNA was detectable in 2 CMV-seronegative patients. IgVH gene usage was associated neither with detection of CMV-DNA nor with CMVseropositivity. Phylogenetic analysis of the different UL32 sequences (n = 28), including the five sequences from CLL patients, revealed a low sequence variability (<1%). Moreover, the variability of UL32 observed between clinical strains was not restricted to specific stretches of the gene but was uniformly distributed over the entire analyzed sequence.\n\nConclusion: In contrast to other CMV antigens, such as glycoprotein B, pUL32 was found to be highly conserved among clinical CMV strains. The function of pUL32 appears to be essential to CMV considering the low evolutionary rate of UL32 despite a presumably strong host immune pressure. Incorporation of pUL32 into novel vaccine strategies has the potential to generate a strong immune response in all vaccinated individuals. Introduction: Immune senescence, which may be defined as the age dependent dysregulation and dysfunctionality of the immune system, is associated with increased susceptibility to infectious diseases and with poor protective immunity after vaccination. Recent evidence from observational studies suggests that persistent infection with human Cytomegalovirus (HCMV) might propagate immune senescence, potentially by a HCMV-induced loss of na\u00efve T cells or cytokine dysregulation.\n\nObjectives: To directly investigate whether and how persistent HCMV infection influences vaccine induced primary immune responses in healthy elderly individuals. Methods: We performed a prospective controlled vaccination trial in 137 healthy elderly volunteers subdivided in two groups of HCMVpositive (n = 69) and HCMV-negative (n = 68) individuals using a licensed vaccine against Tick Borne Encephalitis Virus (TBEV; FSME-Immun CC \u00d2 ). Vaccine induced TBEV-specific antibody and T cell responses were analysed longitudinally by ELISA, neutralisation test (NT) and IFNg-ELISpot. HCMV-specific T cell responses were quantified by IFNg-ELISpot and intracellular cytokine staining. Polychromatic flow cytometry and CBA flex was applied for detailed analyses of PBMC populations and circulating cytokines, respectively. Immunogenicity of TBEV-vaccine was used as a marker for immunocompetence and negatively correlated with immune senescence. Predictors of vaccine immunogenicity were analysed by multivariable logistic regression. Results: Geometric mean titer (GMT) of TBEV-specific ELISA, neutralizing antibodies and T cell frequencies were significantly lower in HCMV-positive compared to HCMV-negative elderly, particularly early after primary immunization (NT week 8: 13.5 vs. 30.5; p = 0.002). HCMV-infection was associated with profound alterations of lymphocyte subset distribution, of T cell activation, differentiation and regulation and of blood dendritic cells but not with significant changes in cytokine levels. In the multivariable model, poor immunogenicity of TBEV-vaccine was associated with HCMVinfection, numbers of HCMV-specific CD8+ T cells, smoking and with low levels of daily physical activity, but not with cytokine levels or na\u00efve T cell numbers.\n\nConclusions: Our data demonstrate that HCMV-infection impairs protective immunity after TBEV vaccination in healthy elderly individuals, probably by a T cell based mechanism that propagates immune senescence. Several studies on the role of hemozoin (Hz), which is released during plasmodium blood stage, show that it can have an immunosuppressive effect (disruption of macrophage/dendritic cell function), although findings are still controversial. This project aims to study the possible effects of Hz on infection and immunization.\n\nObjectives: First we studied the kinetics of Hz in a rodent model. Then the effect of Hz on the immune response to vaccination with irradiated malaria sporozoites was investigated.\n\nMethods: C57BL/6 mice were infected with Plasmodium berghei NK65 and treated with chloroquine (CQ). Mice were sacrificed and organs (liver, spleen, bone marrow and blood) investigated for the presence of Hz. To look at the interference of Hz in vaccination, C57BL/6 mice were infected with P. berghei NK65 followed by treatment with CQ (mice cleared parasite but Hz still remains in the organs). Mice were then immunized with whole irradiated sporozoites and after 10 days challenged with live sporozoites. Liver infection load was determined 42 hours after challenge by real-time PCR. In parallel mice were injected with Hz and then immunized followed by challenge. Native and synthetic Hz was produced and characterized by several methods. Results: Our results showed that Hz was detectable in the host for up to 200 days with the spleen as the major organ for Hz deposition. Immunized mice which had a previous malaria infection seemed to have a reduced protection relative to na\u00efve immunized mice. Also, mice injected with Hz at time of vaccination had undetectable levels of antibodies against sporozoites. Hz characterization by SEM showed that Hz produced by us is structurally equivalent to others, with crystals in the size range of 0.7-1.6 um. Conclusions: In highly endemic areas continuous infections with malaria can potentially lead to a certain level of Hz accumulation in host organs. Thus if Hz has a role in immunesuppression it can potentially interfere with the response to other infections or to vaccination. Our results seem to indicate that this maybe the case, because Hz appeared to cause a degree of immunesuppression capable of reducing the protective efficacy of a malaria vaccine, using whole irradiated parasites. This was shown by a higher liver infection on mice with a previous blood stage and undetectable antibody production against sporozoites when immunization was given together with hemozoin. Objectives: Staphylococcus aureus Panton-Valentine leukocidin (PVL) is a pore-forming toxin associated with skin and soft tissue infections (SSTIs), severe osteomyelitis and necrotising pneumonia. PVL prevalence in S. aureus strains is highly variable worldwide. Recent epidemiological data indicate that prevalence rates of PVL-positive isolates are highest in Africa, but they decline from West and Central Africa to North Africa. Whether variations in PVL prevalence influence immunity to PVL in the general population is unknown. We addressed this question by comparing the levels of PVL antibodies in the general populations of France (Europe), Algeria (North Africa) and Senegal (West Africa).\n\nMethods: Blood samples were drawn from adult populations with no evidence of infection from Lyon, France (n = 200); Alger, Algeria (n = 25); and Dakar, Senegal (n = 229). PVL and alpha-toxin antibody levels were determined by ELISA. Because alpha-toxin is present in all S. aureus strains, its antibody level was considered to reflect the level of population exposure to S. aureus. Results: As compared to France, the median PVL antibody level was 1.7-fold higher in the Algerian population and 7.5-fold higher in the Senegalese population (p < 0.001 for all differences, Mann-Whitney U-test). PVL seropositivity rates in France, Algeria and Senegal were 3.5%, 16.0% and 71.6%, respectively (p < 0.01 for all differences, Chisquare test). On the other hand, there was no significant difference in alpha-toxin antibody levels among patients of the three countries, showing that the observed differences in PVL antibody levels were not biased by variations in population exposure to S. aureus. Conclusion: PVL antibody levels in the general populations of France, Algeria and Senegal vary widely and match variations of PVL-positive S. aureus strains prevalence with an increasing north-south gradient. We conclude that immunity to PVL in a given population is related to the local PVL prevalence. In the light of recent reports suggesting that PVL-directed immunity protects against severe deep-seated infections, but might enhance susceptibility to SSTIs, this finding has important implications for understanding the varying clinical patterns of PVLassociated infections between low and high PVL prevalence areas.\n\nO398 Effectiveness of immunotherapy using S. aureus autovaccine in chronic staphylococcal diseases\n\nObjectives: Increasing antibiotic resistance of S. aureus strains continues to restrict therapeutic potential in diseases caused by the pathogen. Therefore, treatment of chronic staphylococcal infections continues to employ autovaccines, prepared from killed S. aureus strains, isolated from the patient. This study aimed at evaluation of S. aureus autovaccine efficacy in the context of developing cytokine response. Materials and Methods: Treatment with S. aureus autovaccine was applied in the group of 49 adult patients, including 26 patients with chronic suppurative cutaneous S. aureus infection and 23 patients with chronic S. aureus infection of upper respiratory tract. Strains of S. aureus were isolated from dermal lesions or throat smears and identified using ID 32 STAPH test (bioMerieux). Levels of human cytokines were estimated using high sensitivity ELISA tests (R&D and eBioscience). Determination of serum cytokine levels were performed: I -before autovaccine use, II -in the middle of therapy using S. aureus autovaccine and III -24-72 hours following termination of the therapy using S. aureus autovaccine (a series of 20 subcutaneous injections). On the other hand, bacteriological examination targeted at S. aureus were conducted twice: at the first term and the third term (smears from dermal lesions, if they were present or throat smears).\n\nResults: At the first term mean levels of the studied cytokines were as follows: TNF-a 0.56 \u00b1 0.16 pg/mL, IL-1b 0.3 \u00b1 0.17 pg/mL, IFN-g 2.22 \u00b1 1.31 pg/mL, IL-4 0.24 \u00b1 0.14 pg/mL, IL-10 1.49 \u00b1 1.41 pg/ mL, IL-17A 3.44 \u00b1 1.3 pg/mL. At the second term significantly elevated levels of studied cytokines were disclosed in only 21 patients. Their mean levels were as follows: TNF-a 1.23 \u00b1 0.32 pg/ mL, IL-1b 1.33 \u00b1 0.64 pg/mL, IFN-g 6.0 \u00b1 0.93 pg/mL, IL-17A 9.57 \u00b1 3.02 pg/mL. At the IIIrd term significantly elevated levels of studied were disclosed in 39 patients (79.6%) and their means amounted to: TNF-a 1.36 \u00b1 0.33 pg/mL, IL-1b 1.46 \u00b1 0.62 pg/mL, IFN-g 6.48 \u00b1 1.15 pg/mL, IL-17A 10.32 \u00b1 2.7 pg/mL. Levels of IL-4 and IL-10 did not differ significantly between the terms. In parallel, at the IInd stage the patients did not manifest presence of S. aureus. Conclusions: In most of patients (79.6%) with chronic symptomatic S. aureus infections treatment with S. aureus autovaccine induces an increased cytokine response of monocytes/macrophages, Th1 and Th17 lymphocytes, which seems to determine its clinical efficacy accompanied by elimination of the pathogen. Objectives: To evaluate the effect of levamisole combined with the standard treatment vs. the standard treatment on the phagocytic function of polymorphonuclear leucocyte (PMNs) and monocytes and to determine also the antibody dependent cytotoxicity of isolated monocytes in patients with active brucellosis. Methods: Patients were randomly divided into two groups: Group-I who received standard treatment (doxycycline, 100 mg twice daily and streptomycin, 1.0 g once daily over 3 weeks) and group II who received standard treatment as in group-I plus levamisole (100 mg once daily over 3 weeks). Demographic data and clinical features of the patients were documented on a designed form. Chemiluminenescence (CL) of the oxidative burst was used to determine the PMNs and monocytes phagocytic activity in the blood samples collected. Further, the isolated monocytes' ADCC was detected using nucleated target cell suspension at 630 nm. Objectives: The outcome of S. aureus bloodstream infections (BSI) depends on a variety of factors some of which are host mediated and some of which are organism mediated. LL-37 is a cationic polypeptide found in humans and is a key component of the innate immune system responsible for killing phagocytosed bacteria and immunoregulation.\n\nWe assessed the susceptibility of S. aureus isolates causing BSI to killing by LL-37. Methods Ten S. aureus isolates causing complicated and ten causing uncomplicated BSI were randomly selected to assess their susceptibility to LL-37. Both methicillin-susceptible S. aureus (MSSA) and methicillin-resistant S. aureus (MRSA) isolates were included (n = 16 and n = 4). All isolates were positive for the multiple peptide resistant factor (mprF) gene which codes for lysylphosphatidylglycerol (L-PG) synthase except one causing complicated infection and one causing uncomplicated infection. Bactericidal activity was determined from viable cell counts following incubation of 5 \u00b7 10 5 CFU/mL S. aureus with 2.5 lg/mL LL-37 for 1 hour compared to assays containing no LL-37. Objectives: Recent work in our lab has demonstrated that polyclonal Bcell activation with TI-II antigen mimics (e.g a-d-dextran) are able to inhibit the TCR-induced proliferation and activation of T-cells. Based on the fact that TI-II antigens are present in bacteria, we investigated whether N. meningitidis was able to induce B-cell activation but suppress T-cell proliferation and activation. Methods: Primary human PBMCs were exposed to fixed N. meningitidis (whole bacteria) or to purified Neisseria outer membrane vesicles. A flow cytometry assay was designed to measure stimulatory interactions of B and T-cells. Proliferation was measured using a CFSE dilution assay, while cellular activation was assessed by expression of activation markers. Enrichment experiments by negative selection provided pure primary T and B populations for cell-contact experiments.\n\nResults: Interestingly, the smallest ratio bacteria per cell (1:1) of fixed wild type meningococcus resulted in profound inhibition of T-cell proliferation and activation. Higher bacterial count (100:1) failed to inhibit T-cell activation and the inhibition on T-cell proliferation was mild. The same experiment performed with a lipooligosaccharides (LOS) deficient mutant showed a similar suppressive pattern, being the smallest inocula the most effective dose and suggesting that LOS is not the mechanism of inhibition. Purified fresh and heated outer membrane vesicles of both N. meningitidis and N. lactamica demonstrated to contain the suppressive factor, being effective even at small concentrations and implying that the capsule is not the key factor either. Purification experiments have suggested that B-cells might be the cell type responsible of this phenomenon; however they seem to require other accessory cells from the PBMCs to achieve a regulatory phenotype. Latest experiments with E. coli and S. pneumoniae have clarified that such suppressive effect may be exhibited by bacteria other than N. meningitidis, but that the resultant inhibition is dose sensitive and varies among organisms. Conclusion: Small bacterial inocula of N. meningitidis and its outer membrane vesicles are able to inhibit T-cell proliferation and activation. Still unclear whether the B and T-cell contact is required or if a soluble factor within the PBMCs is a key factor. Other microorganisms seem to exhibit the same phenomenon. Further work examining specific bacterial components and scavenger receptors (CD5 and CD6) is necessary.\n\nO402 Delayed conversion to oral therapy in communityacquired pneumonia is mainly caused by physician's misconceptions, lack of guideline knowledge and organisational factors. Results from a prospective cohort study Background: In hospitalised patients with community-acquired pneumonia (CAP), an early switch from intravenous (IV) to oral antibiotics in clinically stable patients is safe, resulting in a shorter length of hospital stay (LOS). However, implementation rates an early switch strategy in clinical practice have not been evaluated.\n\nIdentification of barriers to an early switch strategy may form the basis of a targeted intervention to improve implementation. Objectives: To evaluate whether physicians base the switch to oral treatment on guideline advice, which patient and physician factors influence a switch to oral treatment and whether physicians perceive barriers to an early switch.\n\nMethods: A prospective cohort study in 3 Dutch teaching hospitals (October 2010 and April 2011). Consecutive adult patients admitted for IV treatment of CAP were identified by screening admission lists. On day three of antibiotic treatment, clinical response was scored by objective parameters for clinical stability and treating residents were interviewed on their switch strategies and potential barriers in individual cases. Additionally, all residents and specialists responsible for the treatment choices were interviewed to evaluate their knowledge and adherence to guideline advice. Results: Of 162 enrolled patients, 13 (8%) were excluded, leaving 149 patients for analysis. They were treated by 107 physicians, of which 97 (91%) were interviewed. Based on clinical parameters, a switch to oral antibiotics was possible in 68/149 (46%) patients on day 3 of treatment, but not performed in 27/68 (40%). Patient factors delaying the switch were a high CURB-score on admission (p = 0.04), oxygen treatment (p = 0.04), high temperature (p = 0.00) and high respiration rate (p = 0.04) on day 3. The clinical experience of physicians was not related to duration of IV therapy. Physicians' barriers (n = 47) to an early switch in clinically stable patients were mainly practical considerations (n = 13, 28%), organisational factors (n = 8, 17%) and misconceptions (n = 26, 55%). Strikingly, 91/97 of (94%) physicians were not aware of guideline advice and 59/116 (51%) of patients marked as clinically stable by residents, did not meet objective parameters for clinical stability. Conclusion: The switch from IV to oral antibiotics is often unnecessary delayed in patients hospitalised with CAP. A tailored intervention, aimed at the identified barriers, is likely to reduce the duration of IV treatment and consequently LOS. y . delayed in patients hospitalised with CAP. A tailored intervention, aimed at the identified barriers, is likely to reduce the duration of IV treatment and consequently LOS.\n\nO403 Antibiotic treatment of community-acquired pneumonia: rationale of a cluster-randomised cross-over study design According to Dutch guidelines, empirical treatment for patients with Community-Acquired Pneumonia (CAP) requiring hospitalisation but not ICU admission, consists of either monotherapy with a beta-lactam, beta-lactam and macrolide combination therapy or quinolone monotherapy. However, the scientific evidence for each of these strategies is conflicting. Well designed prospective studies are, therefore, necessary. Observational studies are hampered by bias by indication as the choice of therapy may be influenced by different determinants, such as severity of disease or the patients' overall prognosis. As a result, younger patients are more frequently treated with antibiotics with atypical coverage compared to older patients. Although it is -theoreticallypossible to adjust for these differences in multivariate analysis, many determinants may be hidden which will result in (residual) confounding. Randomized Controlled Trials (RCT) avoid bias by indication, but may suffer from information bias. Individual randomisation in RCT's requires written informed consent from participating patients. Therefore, in most RCT's, patients have already started with antibiotic treatment before consent is obtained. As the initial antibiotic may differ from the antibiotic after randomization, and since initial treatment is crucial for outcome, such a design may severely compromise an accurate evaluation. Given the drawbacks of these designs, we have designed a multi centre cluster-randomized cross-over study to evaluate the (cost-) effectiveness of three antibiotic treatment strategies (beta-lactam monotherapy, betalactam and macrolide combination therapy or fluorchinolon monotherapy). All patients admitted with (suspicion of) CAP on general wards in 8-10 Dutch hospitals are eligible for inclusion. Each hospital uses one of the three treatment arms as standard empirical therapy during a period of four consecutive months, after which preferred treatment will rotate to one of the other two regimens. The order of change is randomised per hospital, thereby controlling for inter-hospital variables and minimizing seasonal influences. The primary endpoint is day-90 mortality. The results will be analysed in a per-protocol (with stratification based on CAP severity) as well as an intention-to-treat analysis.\n\nConclusion: This study provides an innovative design to evaluate the costs and effects of current empirical treatment of CAP without the pitfalls of RCT's or observational studies.\n\nO404 Use of procalcitonin to guide the antibiotic therapy in patients with an acute exacerbation of COPD in a resource-limited setting: a case-control study V. Nangia*, K. Gandhi (Delhi, IN) Objective: Not all of the exacerbations of Chronic Obstructive Pulmonary Disease(COPD) are triggered by bacterial infections and hence may not require antibiotic therapy. This is an interventional study to assess if a procalcitonin -guided therapeutic strategy can reduce antibiotics usage in acute exacerbations of COPD.\n\nMethods: A total of 100 consecutive patients being hospitalized for acute exacerbations of COPD were enrolled in this single center, prospective, computer randomized study. In the cases or procalcitonin group, after the first dose of antibiotic, further course was carried out only if serum procalcitonin level was elevated while the patients in the control group, received antibiotics as per acceptable standards, as decided by the attending physician. The primary end point was total antibiotic usage during hospitalisation and upto 6 weeks. Secondary end points included measures of clinical outcomes like success, selfreported functional status, lung functions, steroid dosage, length of inhospital stay and death.\n\nResults: The mean days of antibiotics received during hospitalization was significantly lower in the procalcitonin group (Mean \u00b1 S.D: 2.10 \u00b1 2.62 vs. 7.02 \u00b1 2.6; p < 0.001) with 71.1% risk reduction of antibiotic exposure. The total dosage of antibiotics received were also significantly lesser in procalcitonin group (4.4 \u00b1 6.2 vs. 12.92 \u00b1 6.7; p < 0.001). Even at 6 weeks, the mean days of antibiotic exposure was significantly lower in the procalcitonin group (3 \u00b1 5.63 vs. 10.42 \u00b1 5.59; p < 0.001) as was the mean total dosage of antibiotics received(5.18 \u00b1 8.09 vs. 16.7 \u00b1 8.06; p < 0.001). There also was significant risk reduction of antibiotic exposure (71.2%). The inter group statistical analysis was done using Chi-square and ANOVA test with p value \u00a30.05 considered as significant. Both the groups were well matched in their demographic and clinical profiles. The mean length of hospital stay was no different (7.5 \u00b1 2.5 vs. 7.3 \u00b1 2.3; p = 0.780) in either group. The clinical improvement, lung functions, usage of steroids, non invasive ventilator support and other supportive therapies were similar in both the groups. Conclusion: Serum procalcitonin serves as a good and reliable biomarker to differentiate between bacterial and non bacterial exacerbations of COPD and thus guides the usage of antibiotics. It is likely to have a tremendous impact on economic burden of the disease, specifically in resource limited settings, in a country like India. Objectives: Findings from a previous hospital-acquired pneumonia (HAP) study indicated that efficacy of tigecycline (TGC) 50 mg q12h was lower than that of imipenem-cilastatin (IMI), especially in subjects with ventilator associated pneumonia (VAP). The primary objective of this study was to compare the efficacy and safety of two higher TGC dosage regimens with an IMI regimen in HAP subjects. Methods: In this Phase 2, multicentre, double-blind study, subjects with HAP (stratified VAP and non-VAP) were randomized to one of three treatment arms: TGC 75 mg q12 hour; TGC 100 mg q12 hour; or IMI 1 g q8 hour and received treatment for up to 14 days. The primary and secondary endpoints were the clinical response in clinically evaluable (CE) and clinical modified intent-to-treat (c-mITT) populations at test-of-cure (TOC), respectively. Results: Of 105 subjects who received study drugs, 67 subjects (63.8%) were clinically evaluable. The median age of subjects was 64 years, 68% were male, 39% had VAP, 30% had an APACHE II score >15, 20% were prior antibiotic failures, and median therapy duration was 8 days. Clinical responses are shown in the table below. Eighty-six (82%) subjects reported treatment emergent adverse events (TEAEs). The most frequently reported TEAEs, gastrointestinal disorders (incidence, 37%) had a numerically higher incidence in the TGC 100 mg group (43%). Serious AEs of sepsis/septic shock were numerically higher in the TGC 75 mg (n = 5) than TGC 100 mg (n = 2) and IMI (n = 2) groups. Seventeen deaths occurred in 7 (19.4%), 3 (8.6%), and 7 (20.6%) subjects who received TGC 75 mg, TGC 100 mg, and IMI respectively.\n\nA signal for improved efficacy at the TGC 100 mg q12h dose level was observed; however, this conclusion is speculative given the small study size. Background: XF-73 is a novel porphyrinic antibacterial with demonstrated bactericidal activity in vitro against Staphylococcus aureus (SA) with a low potential for inducing mutational resistance. Two Phase I studies, conducted in two study sites, have evaluated safety, tolerability, pharmacokinetics (PK) and anti-staphylococcal activity, of XF-73 intranasal gel, in multiple ascending doses. Methods: Subjects were healthy adults confirmed to be nasal carriers of SA. Safety assessments included haematology, biochemistry, urinalysis, ECG, vital signs and nasal examinations. XF-73 or placebo was administered to the anterior nares two or three times daily, for 5 days. Anti-staphylococcal activity was assessed throughout and after treatment by nasal swabs and subsequent culture. Results: Sixty Eight subjects received XF-73 (25 female, 43 male); nine subjects received placebo as control. Five XF-73 concentrations were tested; 0.125-2.0 mg/g, applied for 5 days, two or three times a day. Treatment was well tolerated at all doses. Mild and short lived nasal AEs were reported by 21 (31%) subjects in XF-73 groups, typically mild, transient changes in sensation lasting between 10 hours and 1 day. None of these AEs had any consequence for XF-73 administration or were assessed as clinically significance. Nasal examinations following dosing did not reveal any drug related signs, such as increased secretions or erythema. There were no significant changes in laboratory parameters, ECG or vital signs. PK assessments were all below the detection limit for XF-73, indicating no detectable systemic absorption. Meaningful reductions in SA colonisation were evident at XF-73 concentrations of 0.25, 0.5 and 2.0 mg/g. In a subset of 24 heavily colonized individuals (semi-quantitative culture) at 0.5 (n = 16) and 2.0 mg/g (n = 8), all (100%) registered a reduction in SA load; at the end of treatment SA carriage was absent in 14 (58%), scant in 8 (33%), reduced to a moderate in 2 (9%). Conclusions: Repeated intranasal administration of XF-73 over 5 days is well tolerated at concentrations up to 2.0 mg/g b.d. and there are good preliminary indications of anti-staphylococcal activity to justify further investigation. Propionibacterium acnes is a Gram-positive aerotolerant anaerobe that is found predominately on the skin where it forms part of the resident microbiota. It represents the major opportunistic pathogen within the ''cutaneous'' group of propionibacteria and has been linked, sometimes controversially, to a range of infections and conditions. Historically, the role of P. acnes in certain infections has almost certainly been underestimated due to diagnostic protocols that have poor sensitivity for the detection of the bacterium combined with dismissal as a contaminant when it is recovered. Today, data emerging from P. acnes whole genome sequencing projects, phylogenetic and genetic population analyses, and studies at the transcriptome and proteome level are challenging our understanding of this bacterium and its capacity to cause disease. In particular, isolates from the four genetic divisions (IA, IB, II and III) of P. acnes differ with regard to inflammatory potential and the production of specific virulence determinants, including proteins with phase/ antigenic variation signatures, CAMP factor homologues, haemolysins, and lipase. Recent studies have found a very clear association between isolates from the type IA division, including a globally dispersed clonal lineage, and acne vulgaris. In contrast, isolates from the type IB, II and III divisions are rarely associated with this condition, although they appear to be more frequently recovered from soft tissue and medical implant-related infections. In addition to a discussion of P. acnes epidemiology in relation to acne, we will consider recent data from studies investigating a possible link between P. acnes infection of the prostate gland and prostate cancer development, and review the growing body of evidence that supports P. acnes as an important pathogen in relation to biofilm infections of prosthetic joints.\n\nS433 New aspects of the pathogenic potential of Propionibacterium acnes from its comparative genome sequence analyses\n\nThe recent description of the human skin microbiome has contributed valuable new information on the composition and distribution of microorganisms associated with our skin. The Gram-positive bacterium Propionibacterium acnes is ubiquitously found on the skin, where it resides within sebaceous follicles of the face and back. The presence of P. acnes is thought to be beneficial, e.g. protecting against colonization by harmful microorganisms. However, emerging evidence suggests that P. acnes can act as an opportunistic pathogen in a number of inflammatory diseases. Above all, the bacterium is well known for its association with acne vulgaris, the most common skin disease, which affects up to 80% of all adolescents. However, despite decades of research, the exact role of the bacterium in acne remains an enigma. Recent research has highlighted the potential importance of P. acnes strain identity for determining disease outcome of colonization. This assumption is based on the fact that there are disparities between acne isolates and strains isolated from healthy individuals. Moreover, strain identity seems to have a major impact on host tissue adhesion and inflammatory potential of P. acnes. We decided to apply comparative genome and transcriptome analysis to pinpoint the major differences between ''commensal'' and ''diseaseassociated'' strains of P. acnes. Our data highlight the presence of genomic regions and islands and their possible contributions to pathogenicity. Targeting strain-specific P. acnes factors is a novel therapeutic strategy to cure acne and other P. acnes -associated diseases, with the added advantage of minimal disturbance to the fragile balance of our skin microbiota. In a second study, we applied a microarray-based approach to compare host cell responses to P. acnes, thereby using different tissue-derived cell types. We found that infection scenarios differed drastically between cell types in terms of the triggered cellular signaling events. Our data also suggests that host-tissue tropism, in part, determines P. acnes invasion, inflammatory capacity and persistency of infection; this could contribute to severe P. acnes pathologies at non-skin infection sites.\n\nThe year in clinical microbiology The year 2011 clearly showed a major evolution in clinical microbiology with the availability of novel diagnostic tools based on high-level technologies. However, many questions are often asked to the laboratory about the use of these systems and the clinical relevance of the results obtained with these new technologies. We are now facing a time where we can unravel the role of unsuspected microorganisms or even question the impact of the microbial flora. We can also quickly obtain a correct identification in addition to a resistance mechanism thereby enabling improved infection control on both, bacterial and viral agents.\n\nMass spectrometry (MALDI-TOF, ESI-TOF or even LC-MS/MS), in parallel to integrated nuclear amplification systems allow the characterisation of pathogens with few reagents and a very short turn-around time with a potential impact on patient care (e.g. for tuberculosis) or for the surveillance of microbial resistance. Characterisation of the microbial flora by metagenomic approaches -in the presence or absence of an active infection-might allow the definition of specific microbial patterns under defined pathological conditions. Finally, obtaining a nearly 100% correct identification rapidly, as for muco\u00efd bacteria or yeasts, is of outmost importance for the epidemiological surveillance of infections in cystic fibrosis or immunosuppressed patients, for example. Altogether, microbiology is entering an era of new technologies that we will try to review, not as a listing of devices, but as useful and clinically relevant solutions for the best management of infectious diseases.\n\nThe year 2011 clearly showed a major evolution in clinical microbiology with the availability of novel diagnostic tools based on high-level technologies. However, many questions are often asked to the laboratory about the use of these systems and the clinical relevance of the results obtained with these new technologies. We are now facing a time where we can unravel the role of unsuspected microorganisms or even question the impact of the microbial flora. We can also quickly obtain a correct identification in addition to a resistance mechanism thereby enabling improved infection control on both, bacterial and viral agents. Mass spectrometry (MALDI-TOF, ESI-TOF or even LC-MS/MS), in parallel to integrated nuclear amplification systems allow the characterisation of pathogens with few reagents and a very short turn-around time with a potential impact on patient care (e.g. for tuberculosis) or for the surveillance of microbial resistance. Characterisation of the microbial flora by metagenomic approaches -in the presence or absence of an active infection-might allow the definition of specific microbial patterns under defined pathological conditions. Finally, obtaining a nearly 100% correct identification rapidly, as for muco\u00efd bacteria or yeasts, is of outmost importance for the epidemiological surveillance of infections in cystic fibrosis or immunosuppressed patients, for example. Altogether, microbiology is entering an era of new technologies that we will try to review, not as a listing of devices, but as useful and clinically relevant solutions for the best management of infectious diseases. Objectives: The objectives were to understand the origin and success of the blaNDM-1 metallo-beta-lactamase gene. Methods: Multiple alignments were performed of 2 kb of DNA found upstream and downstream of available blaNDM-1 genes. This was followed by alignments of sequences found upstream of aphA6 and blaNDM-1 resistance genes using Geneious Pro 5.5.3 software Biomatters Ltd, NZ. GC% was calculated using a sliding window of 45bp and total GC% content of genes was calculated using DNASTAR software.\n\nResults: GC% graphs of the blaNDM-1 gene and upstream sequence indicate a large change in GC% of between 33% upstream blaNDM-1 to 61% within the blaNDM-1 gene. Interestingly the GC% changes dramatically within the blaNDM-1 gene. NDM-1 shares its first 6 amino acids with AphA6, an observation that is unlikely to have happened by chance. Alignment of sequence upstream of aphA6 found in Acinetobacter baumanii (JF343537) and blaNDM-1 genes indicate that both genes have identical sequence including an ISAba125 element inserted 100bp upstream of both start codons. Furthermore the identity continues 19bp into the blaNDM-1 gene to precisely the point that the GC% dramatically changes.\n\nConclusion: This is unequivocal evidence that blaNDM-1 was formed by an in frame fusion event between an aphA6 gene and a previous metallo-beta-lactamase gene. This fusion has caused an additional six amino acids to be added to the N-terminus of the pre-protein which explains its recently described ragged N-terminus by changing cleavage sites and also the membrane targeting of NDM-1. This fusion may have happened by two routes. Firstly a deletion event between an upstream aphA6 composite transposon could have occurred removing sequence upstream of the start codon and the majority of the aphA6 gene or secondly, this structure could have been constructed by an ISCR16-like element which initially captured blaNDM-1 and then moved it into the NDM-1 -a growing problem aphA6 gene. Analysis of sequence adjacent to the oriIS of the ISCR16/ blaNDM-1 structures in both Acinetobacter and other species indicate that it has inserted in a region with a similar GC% to A. baumanii adding evidence to such an hypothesis. The construction of blaNDM-1 by this fusion event has also given blaNDM-1 new promoter sequences by a natural genetic engineering event which may be linked to its recent success. The identical sequence upstream blaNDM-1 and aphA6 genes indicates that the fusion is recent, in line with current knowledge of NDM-1 emergence.\n\nA. Wailan, D.L. Paterson, A. Silvey, H.E. Sidjabat* (Brisbane, AU)\n\nObjectives: The recent emergence of a new carbapenem resistance mechanism, the New Delhi beta-lactamase-1 (NDM-1), represents a significant threat. This Class B carbapenemase is found in numerous species of Enterobacteriaceae, not only in nosocomial pathogens, but also in the human intestinal flora (E. coli). The NDM-1 gene is able to spread rapidly by residing in plasmids capable of a type of horizontal gene transfer process called conjugation. This study investigated the rate of conjugation or plasmid transfer frequency of NDM carrying plasmids to E. coli, which resembles the acquisition of the NDM gene by normal human flora in the gastrointestinal tract.\n\nMethods: A total of five NDM producing Enterobacteriaceae (2 K. pneumoniae, 2 E. coli and 1 E. cloacae) were used as donor strains. The recipient strain was a sodium azide resistant E. coli J53. Conjugation was performed overnight with the donor to recipient ratio of 1:1 on MacConkey agar. The transconjugants were analysed for the acquired plasmids through phenotypic and genotypic tests which included S1 nuclease digestion. The conjugative machinery of IncA/C plasmid (tra genes) was determined prior to, and after, the conjugation process.\n\nResults: The replicon type of NDM plasmids from K. pneumoniae and E. coli were IncA/C type; while that of the E. cloacae was IncFII. All but one NDM plasmids of the five donor strains could be transferred by conjugation. The conjugation rates of InA/C NDM plasmids from K. pneumoniae and E. coli were 9.0 \u00b7 10^4 and 1.4 \u00b7 10^4 transconjugants per recipient, respectively. We also observed a synergistic effect of meropenem and ceftazidime combinations with sodium azide mitigating NDM producing transconjugant growth. The inclusion of sub-MIC ciprofloxacin into the environment in vitro enhanced the conjugation rate by~40 times for NDM plasmid. Conjugation can alter the tra operon which may lead to defective conjugation machinery within transconjugants. Conclusion: The spread of the NDM plasmid can occur at an astounding rate through the process of conjugation. This process can be enhanced by introduction of ciprofloxacin into the environment before conjugation to either stimulate plasmid transfer or increase the frequency. Furthermore, the plasmid can become modified during the conjugation process to generate an alternative sized plasmid or multiple plasmids which can potentially enhance the spread of the NDM gene.\n\nO444 Characterisation of an IncFII-type NDM-1 encoding plasmid from an Escherichia coli ST131\n\nR. Bonnin, P. Nordmann, A. Carattoli, L. Poirel* (Le Kremlin-Bic\u00eatre, FR; Rome, IT)\n\nObjectives: NDM-1-mediated resistance to carbapenems in Enterobacteriaceae has been now reported worldwide. Our study was initiated by the isolation of a multidrug-resistant E. coli strain GUE that had been community-acquired in India. The aim of our work was to characterize the features of an IncFII-type plasmid, with a special focus on NDM-1 and its associated genetic structure. Methods: The complete sequencing work flow was performed using the Illumina Genome Analyzer IIx system (Illumina Inc., San Diego, CA). Then, the assemblies were carried out using Velvet2 assembler in order to produce contigs from Illumina GAIIx reads. PCR-gap closure was performed to final assembly of plasmid.\n\nResults: BLAST analysis of the complete nucleotide sequence performed in comparison with the reference IncFII plasmid pC15-1a bearing the blaCTX-M-15 extended-spectrum beta-lactamase gene confirmed that pGUE-NDM belonged to IncFII-type plasmid and showed a significant synteny between the two scaffolds, with the exception of regions containing accessory genes. The blaNDM-1 gene was localized in a multidrug resistance (MDR) region of 20 181 bp. This region was bracketed by two copies of insertion seqeunce IS26 in opposite orientations, creating an IS26-made composite transposon. In order to get further insights into the blaNDM-1 gene successful dissemination, a comparison of the genetic structures previously identified with that identified in plasmid pGUE was performed. It appeared that a common module was always identified. This module was composed of the ISAba125 fragment containing the -35 promoter region, the blaNDM-1 gene, the bleomycin resistance gene, and a truncated phosphoribosylanthranilate isomerase. Conclusion: Our study characterized an IncFII plasmid which backbone is known to be successful considering that it currently represents the major vehicle for dissemination of the blaCTX-M-15 gene. The functional part of the scaffold corresponded to that of other identified IncF plasmids. The originality was linked to the way the blaNDM-1 containing module had been acquired, resulting from a series of recombination events involving insertion sequence IS26.\n\nO445 blaNDM-1-carrying Acinetobacter johnsonii emerged in hospital sewage\n\nObjectives: To investigate the presence of blaNDM-1 in the hospital sewage that could accumulate high density of antimicrobial-resistant organisms and serve as a ''hot spot'' for the transfer of resistance genes. Methods: Hospital sewage obtained from the influx of the wastewater treatment plant in our hospital was diluted to 1:10. An aliquot (100 lL) was streaked onto a plate containing 8 mg/L meropenem and then incubated at 37\u00b0C overnight. Colonies grown on the plate were screened for blaNDM by PCR. Species identification was established by partially sequencing the 16S rRNA gene. Clonal relatedness of isolates carrying blaNDM was determined by ERIC-PCR. Mating was attempted to obtain conjugative plasmids carrying blaNDM using Escherichia coli J53 as the recipient. The genetic context of blaNDM was investigated by PCR mapping and inverse PCR using self-ligated HincII-or HindIII-restricted genomic DNA as templates.\n\nResults: Seventy colonies grew on the plate containing meropenem, two of which carried blaNDM, which was confirmed as blaNDM-1 by sequencing the whole coding sequence. The two isolates were both identified as Acinetobacter johnsonii, a species usually found in the aquatic environment and rarely caused clinical infections. The two isolates had different ERIC-PCR patterns, suggesting different clonal origins. Despite repeated attempts, no transconjugants were obtained from the two isolates. In both cases, blaNDM-1 was adjacent to a complete version of ISAba125 upstream and ble (mediating bleomycin resistance) and trpF (encoding the phosphoribosylanthranilate isomerase) downstream (Figure) . On the other side of ISAba125 there located aphA6 (specifying aminoglycoside 3'-phosphotransferase), ISAba14 and cinH (encoding a recombinase).\n\nConclusion: Sewage of a hospital in western China was found containing blaNDM-1, which might have a clinical origin and could be a threat to the public health. Hospital sewage is an important but often overlooked reservoir of antimicrobial resistance determinants and warrants more attentions. The aphA6-ISAba125-blaNDM-1 structure was likely due to recombination between two copies of ISAba125. This suggests that ISAba125 could serve as a hot spot for homologous recombination, generating variations in genetic contexts of blaNDM-1. Background: CMV-recipients receiving a graft from a Cytomegalovirus (CMV)+ donor (R-D+) are at high risk of developing CMV infection or disease. Universal prophylaxis, for at least 3 months, is the preferred option but there are still doubts about the best strategy to use in these patients (pt). Methods: Kidney and liver R-D+ pt from the RESITRA cohort (Transplantation Infections Spanish Network Study) were analysed. Development of CMV infection or disease according to the prophylaxis received was studied. Results: One hundred and ninty five out of 2410 kidney or liver transplant pt were R-D+ for CMV. 33 (17%) R-D+ pt developed CMV disease, of which 14 (42%) were late-onset diseases. Universal prophylaxis during 3 months was administered to 126 pt (65%). Eighteen (14%) of these pt developed CMV infection, 13 (10%) of them also developed CMV disease. Among 69 pt who did not receive universal prophylaxis, 31 (45%) developed CMV infection and 20 (29%) of them, also developed CMV disease. Focus on these 20 pt who did not receive universal prophylaxis and developed CMV disease, 16 out of 20 pt developed CMV disease directly without observed CMV replication previous CMV disease development and therefore without the possibility of an early pre-emptive therapy. Among 11 pt who developed CMV infection without CMV disease they had received a pre-emptive therapy. Mean time to CMV infection in pt receiving and not receiving universal prophylaxis was 142 and 78 days, respectively. There was a trend towards developing late CMV disease in the universal prophylaxis group (p < 0.01). In multivariate analysis, not receiving universal prophylaxis (OR 5.9, 95% CI 2.8-12.6), the presence of rejection requiring steroids (OR 3.4, 95% CI: 1.2-9.1), and receiving a kidney transplant compared with liver transplant (OR 3.3, 95% CI 1.2-9.2) were independent factors associated with increased risk of CMV infection. On the other hand, not receiving universal prophylaxis (OR 4, 3, 95% CI 1, 9) , and receiving a kidney transplant compared with liver transplant (OR 1,5, 95% CI 1,1-1,9) were independent factors associated with increased risk of CMV disease.\n\nThe results support the benefit of universal prophylaxis for at least 3 months in R-D+ patients and the risk associated to a strategy based on pre-emptive therapy in these pt. In addition, other factors, such as the use of steroids to treat rejection and the type of transplant, may alter the natural history of CMV infection in these pt. Background: Although is generally considered that cytomegalovirus (CMV) infection have an important role in long-term evolution of solid organ transplant (SOT) recipients, there really is very little consistent information that prove this correlation. Methods: We analyzed a cohort of SOT recipients at our institution (2003) (2004) (2005) who survived more than 180 days after transplant (Tx). Patients were followed for at least 5 years. Episodes of CMV infection (detected by pp65 antigenemia and/or real-time PCR) and disease were prospectively followed until death or graft loss. In the other hospital, patients received no antiviral prophylaxis until they had evidence of CMV infection (deferred therapy, DT group). By using propensity score, the data of two groups were matched and 1:4 comparison of UP and DT was done.\n\nResults: A total of 544 patients underwent kidney transplantation, and among them 59 in UP group, and 236 in DT group were matched. All of the enrolled patients were CMV immunoglobulin G positive. Baseline characteristics and duration of dialysis were well matched in both groups. CMV viremia that required antiviral treatment occurred in 5 (8.5%) patients in UP group, and 18 (7.6%) in DT group (p = 0.789).\n\nGraft loss was also similar in both group (6.8% vs. 5.5%, P = 0.755). However, seven patients in DT group experienced organ involved CMV disease, whereas no in UP group. No patient was died due to CMV related event.\n\nConclusion: UP showed no advantage over DT for preventing CMV episodes that required antiviral treatment and mortality in kidney transplantation recipients at intermediate risk of CMV disease. (1)). CMV antigenemia test was positive in only six patients (24%). Antiviral treatment was used in 80% of patients. The time of hospitalization was significantly greater in the CMV group (p < 0.001), however there was no difference in the surgery needed within 3 months after IBD flare. In the multivariate analysis, the independent risk factors associated with the development of CMV disease in a patient with an IBD flare were age (1.037; 95%CI: 1.001-1.1063), ulcerative colitis (2.33; 95%IC: 1.127-4.823) and corticosteroid resistance (6.905; 95%IC: 1.692-28.169). However, the risk factors associated with the development of CMV disease in the 21 patients in whom IBD diagnosis was done before CMV disease, were also immunosuppressive treatment with cyclosporine or infliximab (5.599; 95%CI: 1.060-19.995) and low level of albumin (0.378; .\n\nConclusions: CMV disease is a significant and increasing infectious complication in patients with IBD, which significantly increases hospitalization time but not the need for additional surgery. Ulcerative colitis, older age and corticosteroid resistance are risk markers for developing this complication in IBD patients with a flare. Immunosuppressive therapy with cyclosporine and infliximab is also a risk factor in patients with previously-diagnosed IBD. Phage Therapy was proposed as a therapeutic treatment against bacterial infections almost a century ago by Felix d'Herelle, about 10 years before the discovery of penicillin. Despite a rapid world diffusion of this therapy, the lack of scientific knowledge on bacteriophages/bacteria relationships and the discovery of antibiotics precipitated its abandon except, mainly, in East European countries. While antibiotics became a routine therapy in the second half of the last century, the scientific knowledge on bacteriophages led to the birth of molecular biology. Today the increasingly public health problems caused by antibioticresistant bacteria are a major driving force in the renewed interest in phage therapy. Together with the re-discovery that bacteriophages were used to treat bacterial infections in humans for years in some East European countries, recent works performed with animal models highlight the potential of the use of bacteriophages in medicine.\n\nIn the past few years, we have shown using mice that bacteriophages can be used to treat acute lung infections caused by Pseudomonas aeruginosa. This work, performed on two different P. aeruginosa strains with two different bacteriophages, was later extended to the demonstration that bacteriophages could also be used to prevent and protect mice from lethal lung infection up to 4 days. These investigations led us to the identification of two new groups of bacteriophages. More recently we investigated the relationships between bacteriophages and the intestinal flora. We first showed that bacteriophages were able to infect bacteria growing on biofilms formed in vitro and ex vivo. Second, using a mouse model colonized with an enteroaggregative O104:H4 Escherichia coli strain, we demonstrated that bacteriophages can replicate continuously over several weeks. Upon addition of an initial high dose of bacteriophages we could show that the ileal concentration of the E. coli strain was strongly reduced. However, this strain could not be totally cleared from the gut. In the light of these two examples, phage therapy is getting closer to reality and does not anymore resemble to a myth, even if numerous questions have still not yet found answers. Despite reductions in disease attributable to widespread use of proteinconjugate polysaccharide vaccines (PCV), the pneumococcus retains its role as a principal pathogen of the respiratory tract, causing many or most cases of otitis media, acute sinusitis, and pneumonia and occasional exacerbations of chronic lung disease. Diseases outside the respiratory tract include bacteremia with no recognized focus, meningitis, septic arthritis, endocarditis, peritonitis and osteomyelitis. The complex polysaccharide capsule repels ingestion and killing by innate immune mechanisms or by polymorphonuclear leukocytes. Peptidoglycan, the principal constituent of cell wall, and pneumolysin each stimulate an intense inflammatory response. Disease of the respiratory tract results when the host fails to clear organisms and inflammatory products accumulate. Treatment of extra-CNS infection has remained straightforward, with most pneumococci remaining susceptible to betalactam antibiotics in commonly used doses and to fluoroquinolones. Even meningitis, in most cases, responds to commonly recommended high doses of third-generation cephalosporins. Some newer antibiotics such as ceftaroline appear to be effective against penicillin-resistant organisms. Widespread use of 7-valent PCV has led to emergence of replacement strains, and use of 13-valent PCV is almost certain to have the same effect, limiting the usefulness of any polysaccharide-based vaccine in the future. Pneumolysin, a major virulence factor of pneumococci, and proteins that are expressed on the surface are currently under investigation as potential vaccine components.\n\nIn the last two decades, after the first six community-based studies on gyneacological Schistosoma (S.) haematobium, WHO has recommended that the disease should be referred to as urogenital schistosomiasis, a term currently in use in the francophone scientific literature. Studies have shown that women may have genital lesions even without urinary ova or symptoms. Furthermore, lesions are present in all adult age groups, independent of adult risk water contact, and refractory to treatment for at least 12 months. The cervix, the Fallopian tubes, and the vagina are the most common gynaecological sites to present ova. Lesions are caused by host responses to dead or viable schistosomiasis eggs and may render women with genital schistosomiasis susceptible to HIV. The typical genital changes, such as sandy patches and pathological blood vessels may make women susceptible to super-infection, cause contact bleeding, decreased fertility, abortions, discharge and bleeding. Further research is needed to find a simple low-tech diagnosis, treatment for chronic lesions, and to explore the preventive effects of mass drug administration on symptoms, sandy patches, HPV and the HIV epidemic.\n\nToys, gadgets and e-sources for ID and CM specialists S457 How do digital toys make life easy in hospital?\n\nIf one would have the chance to look back in the far future, it will not be surprising to see that he would label the time we are living as the ''second Renaissance''. The mind thrilling progress of Internet is the main catalyzer of our period. Internet is a process and continuously producing new remarkable changes. Lately, two articles pinpointed two major changes. The first one was ''WWW is dead'', which states that routine webpages are not popular anymore and social media is replacing them. A look at the progress of Facebook is the best example. The second article was headed ''The end of laptops''. Of course there is a wide usage of laptops but condolences to Mr. Steve Jobs; Apple changed everything. Although the Armageddon ship of this development is Smartphones (mainly iphone); in medical practice, tablet PC's will be the main tool.\n\nThere are several advantages of these tools: they are small, they are very mobile, they have high capacity, they are affordable, they do not have to store everything, they are multitasked, they are open to development, they can easily broadcast, and data sharing is easy. Now, there are two main operating systems: iOS 5 and Android. The introduction of Icloud and other online data storage opportunities enable access and share of all our data between our computers and other devices.\n\nMainly because of the mobility, the advantages of the Internet access and high capacity, these devices are beginning to find an important place in medical practice. The use of various medical and paramedical small software enable us to use these devices like a well developed computer and perform most of the tasks on these gadgets. For example, viewing radiological images, using hospital information systems on the bedside, giving medical and pharmaceutical orders and searching medical databases are all possible. Nowadays, a lot of applications are finding ways to be used in the daily medical practice in medical institutions and daily medical practice.\n\nA few examples will be given. The revolution has not ended yet. The future of the internet is wide open to developments and these developments may lead us to new horizons that can not be predicted at this time. An example will be given. . Since 2008, a trend to involvement of northern areas in Veneto Region was observed, and, in 2011, most cases were identified in areas that were not affected in the previous years. WNV NAT screening of blood, tissue, and organ donation identified four WNV RNA-positive blood donors and one WNV RNA-positive organ donor, who were resident in the same areas where symptomatic human cases were identified. A WNV-positive organ donor was missed by NAT testing and transmitted infection to three out of five recipients, two of whom (the kidney recipients) developed WNND and excreted WNV RNA in their urine. Rapid detection of these cases allowed prevention of further transmissions to other tissue recipients. Following this experience, we monitored WNV RNA in the urine of WNV NAT-positive blood donors. In these subjects, WNV RNA remained positive in urine long after becoming undetectable in peripheral blood. Whole genome sequencing of two human WNV strains isolated in Veneto Region in 2011 demonstrated that they were WNV lineage 1, clade 1a, and phylogenetically related to WNV strains circulating in Italy and in the Western Mediterranean basin in the previous years. About 1% divergence was observed between the genome of the WNV strains isolated in 2011 and the strain isolated in 2009 in Veneto Region. Conclusions: For the forth consecutive year, in 2011, human cases of WNV disease occurred in Veneto Region. In affected regions, WNV NAT screening of blood and organ donations detected a relatively high rate of positive cases. WNV RNA detection in urine represented a sensitive test. Genetic comparison of WNV strains isolated in Italy in the recent years indicated that the virus might been re-introduced by migratory birds several times and than it might have circulated and evolved. Conclusions: A comparison of data during these outbreaks indicates a shift from mild illness towards a larger and more severe manifestation of the disease, which could be interpreted as an epidemiologic transition pattern in Lahore and other regions of the country.Serologic and virologic conditions are now highly indicative of a further locally acquired outbreak of DHF of a larger magnitude in the future. This highlights the need for rigorous vector control measures and vaccine development. Continuing education of clinicians and primary care physicians is crucial for early recognition of DHF, especially in patients with a prior history of DF. Several studies have demonstrated that Toscana virus (TOSV) was a prominent cause of CNS infections and febrile illness in Mediterranean countries, and more specifically in southern France. However, there is still little data reflecting the circulation of TOSV in the general population; a previous study conducted on 92 sera from blood donors reported that approximately 12% possessed IgG specific of Toscana virus, suggesting previous infection (de Lamballerie et al. 2007) . A recent study conducted in blood donors found prevalence of the same order of magnitude (Brisbarre et al. 2011) . However, the small number of samples precluded to investigate the distribution according to the age. A total of 387 sera which were collected in patients admitted and/or hospitalized in the Public Hospitals of Marseille and for which Toscana virus serology was prescribed were included in the study. These sera had been collected from 2004 to 2011. Approximately 12% of the general population has been in contact with TOSV demonstrating a very active circulation.\n\nA detailed analysis of all suspect cases during this period (clinical data, sequential serum specimens, CSF samples) using laboratory techniques such as virus isolation in Vero cell line, real-time RT-PCR and further sequence-base confirmation, as well as seroconversion assessment using indirect immunofluorescence, virus neutralization tests, plaquereduction neutralization assays were used. They allowed to document unambiguously a total of 13 cases of acute infection with TOSV. The geographic, demographic, clinical, and virological characteristics of these cases were investigated. They were compared with data of the literature to better understand the clinical and epidemiological picture of TOSV which remains a neglected pathogen, the importance of which is largely underestimated.\n\nIn conclusion, seroprevalence data and record of clinical cases together indicate that TOSV is the most prevalent autochthonous arbovirus in southeastern France far ahead West Nile virus, dengue virus and chikungunya virus. Background: Respiratory infections remain a major cause of morbidity and mortality worldwide. Novel respiratory viruses, such as human coronaviruses (HCoV), bocaviruses, and human metapneumovirus, are recognized as common causes of respiratory disease. HCoV drew the attention of the scientific community after the identification of SARScoronavirus in 2003. Since then, at least two additional coronaviruses (HCoV-NL63; HCoV-HKU1) associated with human illness have been discovered. No reports exist in the literature describing the existence of these viruses in Peru. Methods: Respiratory samples were collected from influenza like illness (ILI) cases who are participating in a population-based respiratory surveillance study in Peru. This study, initiated in June 2009, follows approximately 7000 participants, from 1500 households living in four geographically distinct locations across Peru: Lima (central coast/ urban), Tumbes (tropical coast/rural), Cusco (highlands/semi-rural), Puerto Maldonado (Amazon rainforest/urban). Samples were tested by real-time RT-PCR for influenza A and B. A sub-group of 173 samples, negative for influenza was selected to perform additional testing for additional respiratory viruses using a multiplex Luminex RVP assay. Results: Of the 173 samples, 11 (6.4%) were positive for HCoV, 8 (4.6%) for HCoV-HKU1, 2 (1.2%) for HCoV-NL63, 1 (0.6%) for HCoV-229E. None were positive for HCoV-OC43. The majority of the cases were male, under the age of 5to (7/11; 64%).), One participant was 7 months old, while three were adults (31, 32 and 59 years old). Participants with HCoV infections started their ILI disease episodes between mid April and mid December; however 9/11 participants started their disease between mid May and July, the winter season in Peru. HCoV cases were observed from all four sites, three from Lima, four from Cusco and two each from Puerto Maldonado and Tumbes. Discussion: To our knowledge this is the first report of HCoV infection in humans from Peru. The prevalence in our study is similar to previous reports. A clear seasonality for HCoVs was also found. HCoV infections were from four sites in Peru, suggest that HCoVs circulate in urban and rural areas in Peru. HKU1 infections were most common in our populations, which is in contrast to other studies where viruses such as HCoV-OC43 are most prevalent. We only found positive samples in 2010; this could be explained by a biennial behavior as previously reported. Objectives: Alert and surveillance are major issues in the field of infectious diseases (ID) and several examples during past decades have highlighted that warning systems can reveal major pathogen and outbreaks. A weekly monitoring of microbiologic data that involves both syndromic and targeted surveillance has been implemented since 2002 in Marseille University Hospitals (UH) using EPIMIC, an in house computer program. Methods: EPIMIC uses Microsoft Excel software and analyses weekly numbers of clinical samples send for microbiological diagnosis to core/ point-of-care laboratories of Marseille UH and the weekly numbers of positive testing. Surveillance is (i) primarily syndrome-based, using the nature of the samples regardless of pathogens sought, and (ii) secondarily focused on pathogens including those critical in terms of mortality or implication in nosocomial infections and antimicrobial resistance. EPIMIC calculates for each set of data the mean value and standard deviation (SD) and new data are compared instantly to historical ones. Any significant increase beyond the mean value +2 SD, generates a red color signal. All data are plotted in graphics.\n\nResults: Between 11/2002 and 03/2011 (8.5 years), 11 130 000 events have been entered in EPIMIC, corresponding to 381 parameters including 38 categories of samples, 137 pathogens, 79 diagnostic tests, and 39 antibacterial resistance patterns. New parameters have been gradually added, and the mean duration of surveillance is 4.6 years (range, 2 months-8.4 years). Beside monitoring infections/pathogens with known seasonality, EPIMIC proved efficient by the detection of several abnormal/previously unknown events including notably: (i) an increased incidence of Klebsiella pneumoniae bloodstream infections during summer; (ii) a low incidence of influenza infections in 2010; (iii) an increase in 01/2011-02/2011 of pharyngitis with group A Streptococcus (GAS) and association of GAS invasive infections with Influenza; (iv) an increase in 02/2011 of imipenem-resistant Acinetobacter baumannii; and (v) an increase of hepatitis E cases during first trimester 2011. Conclusion: EPIMIC is a home-made, simple and versatile program that has proven efficient to detect abnormal events related to ID, which is well suited to their unpredictability. Future improvements may include optimization of critical threshold for alert, specific monitoring for some clinical units, and automation of data transfer from lab computer systems.\n\nO470 Neutrophil MMP-8/-9 is increased in tuberculosis: evidence from in vitro studies and patients with pulmonary disease C. Ong*, P. Elkington, C. Ugarte-Gil, F. Roncaroli, J. Friedland (London, UK)\n\nObjectives: Neutrophils are the major phagocytic cells in the lungs of patients with active pulmonary tuberculosis (TB). A matrix degrading phenotype in TB results in tissue damage, where the activity of matrix metalloproteinases (MMPs) is unopposed by their tissue inhibitors (TIMPs). We investigated factors regulating neutrophil MMP secretion in TB in vitro and in patients. Methods: Neutrophils from healthy volunteers were infected with Mycobacterium tuberculosis (Mtb) or stimulated with conditioned media from Mtb-infected monocytes (CoMTB). Analysis of MMP-8/-9 secretion and TIMP-1/-2 was by ELISA, Luminex array and zymography. Gene expression of MMP-8/9 was investigated using real-time PCR. Neutrophil granule formation was assessed by confocal microscopy. Induced sputum samples from 137 healthy controls and TB patients were analysed. Brain biopsies from patients with central nervous system-TB were studied by immunohistochemistry. Results: Neutrophil MMP-8/-9 secretion is upregulated by Mtb over time and is dependent on TB multiplicity of infection. CoMTB stimulated neutrophils resulted in a 2 and 3 fold up-regulation of MMP-8/-9 secretion respectively (both p < 0.001). TIMP-2 is increased 2-fold (p < 0.001) but not TIMP-1. MMP-8 and -9 is increased 16 and 160 fold respectively compared to TIMP-2. MMP-8/-9 gene expression was increased 3.5 fold and 7 fold respectively by CoMTB stimulation at 24 hours (both p < 0.001). Confocal microscopy demonstrated colocalisation of early endosome marker Rab-5 with MMP-8 and -9 indicating that MMP-8/-9 are newly synthesised. MMP-8/-9 is significantly elevated in induced sputum samples from TB patients compared to healthy controls and both correlate with the neutrophil markers neutrophil gelatinase associated lipocalin and myeloperoxidase. Brain biopsy specimens from patients with CNS-TB demonstrated neutrophils surrounding TB granulomas with MMP-8 and -9 present. Conclusions: Neutrophil MMP-8/-9 gene expression and secretion is upregulated following direct infection with TB or stimulation by monocyte-dependent TB networks. The increase in MMP/TIMP ratio will result in a proteolytic environment which may lead to patient morbidity associated with tissue destruction. Introduction: Tuberculosis (TB) is characterised by extensive tissue destruction, causing mortality, morbidity and mycobacterial spread. The greatest burden of disease lies in Southern Africa and has been fuelled by the HIV epidemic. In HIV co-infection, TB causes divergent pathology, with markedly reduced inflammatory host damage evident in advanced immunocompromise. The matrix metalloproteinases (MMPs), key proteases in extracellular matrix remodelling, are implicated in TB tissue destruction, but little is known about their role in TB-HIV coinfection.\n\nObjective: To investigate the hypothesis that differential MMP activity in TB-HIV underlies the greater pathological spectrum in TB-HIV coinfection by: 1 Quantifying MMPs and cytokines in induced sputum of patients with newly diagnosed pulmonary TB, with and without HIV co-infection, in comparison to control patients.\n\n2 Correlating MMPs and cytokines in induced sputum with clinical measures of immunopathology: pulmonary cavitation, chest x-ray infiltration score, sputum smear status, and also with CD4 count. Results: Fourty-four induced sputum samples from patients in Cape Town, South Africa, were analysed for MMPs and cytokines by multiplex array. In TB patients, MMP-1, -2, -3 and -8 were significantly increased compared to controls. In HIV-infected TB patients with advanced HIV (CD4 count <200), MMP-1, -2, -8 and -9 were significantly reduced (p = 0.02, 0.03, 0.03, 0.003 respectively). MMP-1 correlated with clinical parameters of tissue destruction, including chest x-ray infiltration score (p = 0.029, r = 0.456) and sputum AFB score (0.015, r = 0.523), and MMP-1 was significantly increased in cavitatory vs. non-cavitatory TB (p \u00a3 0.001, see Figure 1 ). In contrast, no difference between cytokines in TB patients with and without HIV infection was detected. TNF-alpha concentrations correlated with chest x-ray infiltration score but no other parameter of immunopathology.\n\nConclusion: Advanced HIV infection is associated with reduced MMP concentrations, potentially explaining reduced inflammatory immunopathology. MMP-1 associates most closely with clinical parameters of tissue destructive pathology, providing further evidence for a causative role. Defining the role of MMPs in immunopathology in TB-HIV co-infection may enable development of immunomodulatory therapies to reduce TB-related morbidity. Objectives: To examine the respiratory burst of both monocytes and polymorphonuclear leucocytes (PMNs) and to determine the monocyte antibody dependent cellular cytotoxicity (ADCC). Methods: Patients presenting with compatible symptoms, relevant imaging, positive tuberculous cultures and suggestive histological tissue with diagnosis of tuberculosis were consecutively enrolled in the study. The patients were compared with age and sex matched healthy volunteers. Demographic data and clinical features of the patients were documented on a designed form. The isolated PMNs and isolated monocyte respiratory bursts were studied by stimulation with phorbol myristate (PMA) with the measurement of chemiluminescence (CL) responses. ADCC of isolated monocytes was determined utilizing the turbidimetric measurement of nucleated target cell suspension at 630nm. Results: Thirteen patients with culture positive pulmonary tuberculosis and six patients with extra-pulmonary were consecutively enrolled in the study. They were made up of 13 males and six females with mean age \u00b1SD of 40 \u00b1 3.2 years. The patients were compared with age and sex matched nineteen healthy volunteers. The main symptoms in the our patients were in decreasing order: fever, cough and weight loss. The respiratory burst of whole blood of patients were significantly different as compared with controls with mean CL response 25.15 \u00b1 7.31 vs. 10.75 \u00b1 1.32 respectively (p < 0.05). Likewise mean CL responses of the respiratory bursts in PMNs was also significantly different between patients and controls as the mean responses were 1377.80 \u00b1 213.16 vs. 954.70 \u00b1 91.46 (p < 0.001). However, the mean CL response of monocytes did not show any difference between patients and controls (26.47 \u00b1 6.14 vs. 23.54 \u00b1 8.55 Mycobacterium avium subsp. paratuberculosis (MAP) is the etiological agent of Johne's disease, a chronic granulomatous enteritis of cattle and other domesticated and wild ruminant species. Symptoms include intestinal inflammation, poor nutrient uptake, severe diarrhoea, emaciation and, if untreated, ultimately death of the infected host. The pathogen has also been strongly implicated as a causative agent of Crohn's disease in humans, yet evidence in support of this remains inconclusive. Nevertheless, Johne's disease is prevalent worldwide and has a significant impact on the global agricultural economy. Novel prophylactic and therapeutic strategies are required to control its spread.\n\nIn the present study the efficacy of expressing recombinant MAP proteins from a probiotic Lactobacillus strain, for therapeutic applications, is investigated. Through bioinformatic screening of the complete MAP genome, a set of 25 MAP genes encoding putatively antigenic secreted, cytosolic and surface expressed proteins has been identified. Five selected MAP genes were fused to the pNZ8048 expression vector to create transcriptional fusions for controlled expression utilizing the Nisin Inducible Controlled Expression (NICE) system. Subsequently, these fusion vectors (pNZ8048:MAP+) were transformed into Lb. salivarius and induced at mid-log phase with 0.2% v/v nisin for 4 h statically at 37\u00b0C. mRNA isolation and RT-PCR analysis (Roche Lightcycler480) were used to confirm the expression of MAP genes within the host strain. Levels of nisin dose-dependant control over expression were also examined. Protein analysis was carried out using SDS PAGE and the Agilent 2100 Bioanalyzer. The controlled over-expression of MAP proteins/antigens from a GRAS (Generally Regarded as Safe) host has numerous therapeutic applications. In addition to controllable subunit vaccine overexpression, modulation of host immune responses via direct oral administration of the antigen expressing Lb. salivarius strain may form the basis of an prophylactic vaccine for animals and perhaps even humans.\n\nSeen in the parasitology clinic S476 Trichinosis\n\nTrichinellosis, produced by the larval stage of nematoda parasite belonging to Trichinella spp. is widespread both in humans and animals. Domestic pig is by far the most important source of infection. The parasite is present on all the continents, except Antarctica, but areas where raw pork, horse or game animal meat is consumed, are much more involved. The geographical distribution, documented in 55 countries, is related to cultural, religious and food habits, being more common in areas where raw pork meat is widely consumed. During the advanced stage of the disease, Trichinella larvae become encapsulated, or can remain non-encapsulated.\n\nThe clinical course of the disease is related to Trichinella species, infected dose (number of Trichinella larvae/gram), immunological background of the host, previous Trichinella infections. Acute trichinellosis is easier to be detected in population, the diagnosis and consequently appropriate treatment is often in time and the evolution and good prognosis are common. However, complications (cardiovascular, neurological, ocular, respiratory, and digestive) can be associated. Mortality rate is estimated at 0.2%. Chronic trichinellosis can determine a long course of the disease, or, can be hazardously discovered. Sequels are very often associated. The diagnosis is based on morphological identification of the parasite, serology (screening and confirmatory) and molecular diagnosis. Eosinophilia and increased muscle enzymes are relevant. The appropriate treatment should be initiated as soon as possible.\n\nIn many states, including EU member states, the notification of the disease is compulsory. In spite the control measures, applied in many countries, in Europe there are still endemic foci.\n\nGram-negative bacilli S492 Current epidemiology of OXA-carbapenemases in Klebsiella N. Woodford* (London, UK)\n\nCarbapenemases belonging to the OXA-48-like sub-group (OXA-48, -162, -163 and -181) have escaped from environmental bacteria of the genus Shewenella and are increasingly detected in clinical isolates of the Enterobacteriaceae. OXA-48 beta-lactamase was initially identified in Turkey, but there have been scattered reports, mainly in Klebsiella pneumoniae isolates, from several countries in the Middle-East and the Mediterranean region, especially north Africa. Hospital outbreaks caused by producers of this carbapenemase have been described in Turkey and more recently in several European countries. K. pneumoniae strains of sequence type 395 have been implicated in the European spread of OXA-48 carbapenemase, although the resistance gene has been detected in many clones and, indeed, other genera. The blaOXA-48 gene is usually located on transposon Tn1999, which has been found in OXA-48-positive Enterobacteriaceae of diverse geographic origin on highly-related conjugative plasmids of c. 62-kb. A recently described variant, OXA-181 carbapenemase, differs from OXA-48 by just four amino acids, but its gene is associated with an ISEcp1 element on a distinct transposon, Tn2013, and on much smaller plasmids of c. 7-kb. Accurate detection of these enzymes in Enterobacteriaceae may pose problems for diagnostic and reference laboratories unless confirmatory molecular tests are used; many producers remain susceptible in vitro to imipenem and/or meropenem and, in the absence of other resistance mechanisms such as ESBLs, also to oxyimino-cephalosporins. Highlevel resistance to piperacillin-tazobactam and temocillin may be useful markers for OXA-48-like enzymes in strains that show reduced carbapenem susceptibility. International studies are needed to monitor spread of OXA-48 and other carbapenemases. Results: In 2010 the mandatory MRSA bacteraemia surveillance recorded 1630 MRSA bacteraemia cases in England, giving a rate of 3.12 cases per 100 000 population with MRSA accounting for 15% of all S. aureus bacteraemias. This is in contrast to the situation merely 4 year previously, where the same surveillance programme reported 6771 MRSA cases giving a rate over four fold higher than in 2010, at 13.33 cases per 100 000 population and 38% of S. aureus bacteraemias being MRSA. This represents a c. 76% reduction in MRSA in 4 years. The low 2010 MRSA rate coincided with 16 (9.5%) NHS Trusts recording no Trust apportioned MRSA bacteraemia cases i.e. cases discovered on or after the third day post hospital admission.\n\nThe mandatory surveillance was launched in the latter part of 2001, when MRSA bacteraemia in England had reached a peak of c. 7300 cases (c. 40% of all S. aureus bacteraemias), thus using this dataset alone it cannot be estimated when MRSA rates were last as low as they are currently. Voluntary surveillance, can provide data pre 2002, however, as a voluntary scheme, LabBase2 risk under-ascertainment, thus, MRSA rates calculated from the former are lower than those from the latter (Figure 1 ). For example, LabBase2 2010 surveillance captured 1203 MRSA cases compared to 1603 from the mandatory giving MRSA rates of 2.3 and 3.1 respectively. Considering the data from LabBase2 on its own the 2.3 2010 MRSA rate is the lowest rate since 1995 where the MRSA rate was 1.6 with 14% of all S. aureus bacteraemia being due to MRSA. If the 2010 mandatory rate is compared with those from LabBase2 then it is the lowest rate since 1996 where the rate calculated from LabBase2 was 3.03, however this will be an underestimate.\n\nConclusion: Rates of bacteraemia due to MRSA in England have dropped at an unprecedented degree in recent years with the rate in 2010 of 3.1 per 100 000 population being the lowest rate, almost certainly, since 1995.\n\nO496 Computer-assisted surveillance of nosocomial bloodstream infections by compilation of data from electronic hospital registries\n\nObjectives: To report the implementation and results of a computerassisted monitoring of nosocomial bloodstream infections (BSI). Furthermore, to calculate species specific rates of nosocomial BSI, and to compare drug resistance patterns for selected hospital and community acquired infections. Methods: All patients with a positive blood culture at Lillebaelt Hospital during 2008-2011 were included in the study. An episode of BSI was defined as a positive blood culture with a significant pathogen and concomitantly treatment of the patient with antibiotics. A new episode of BSI was defined as a new culture of the same microorganism after 1 week or later or as growth of another pathogen two days or more after a previous positive blood culture. Nosocomial infections (HAI) were defined as positive blood cultures obtained more than two days after hospital admission. Information on microbiological findings and admission data was compiled from electronic registries in the Hospital.\n\nResults: A total of 2248 episodes of BSI were detected. The distribution of Gram-positive and negative strains, yeast and anaerobic bacteria was 53%, 43%, 3%, and 1%, respectively. Nosocomial infections comprised 22% of all BSI detected during the study. However, the proportion of HAI was <6% for Streptococcus pneumoniae, Haemophilus influenzae, and Group A and B betahemolytic streptococci, whereas more than 60% of the episodes with Candida species, Enterococcus faecium, and Serratia marcescens were of nosocomial origin. Escherichia coli and Staphylococcus aureus were most commonly isolated; 20% and 11% were HAI, respectively. MRSA caused 4% of HAI with S. aureus and none of the community acquired BSI (CAI). Percentage of penicillin-resistance was 77% and 74%, respectively. E. coli with ESBL were seen in 6% of HAI and 4% of CAI. Surprisingly, resistance to ampicillin, cefuroxime, ciprofloxacin, and gentamicin was highest in E. coli BSI episodes of CAI origin. Rates of BSI for selected species are presented, e.g., the E. coli nosocomial BSI rates for Department of Oncology were 0.12, 0.15, 0.27, and 0.51 per 1000 bed days in 2008-2011. Conclusion: Computer-assisted surveillance of hospital and community acquired blood stream infections, and the corresponding drug resistance patterns of relevance for empiric treatment of patients should be implemented at a hospital. Incidence rates of selected nosocomial BSI may assist in evaluation of infection control measures. Background: Infections caused by carbapenemase-producing Enterobacteriaceae are a major concern to public health. OXA-48 is an emerging carbapenemase, especially in the Mediterranean basin. Patients and Methods: An observational prospective study was conducted in the setting of an outbreak at a 1328-bed university hospital in Madrid, Spain. All adult patients with OXA-48 positive blood cultures between July 2010 and November 2011 were included. OXA-48 genes were searched by PCR.\n\nResults: Twenty six patients (65% men) with bacteremia caused by an OXA-48 producing bacteria, were included (21 K. pneumoniae, 4 E. coli and 1 K. oxytoca). MIC50 for Ertapenem was >32 mcg/mL, for Imipenem 4 mcg/mL and for Meropenem was 2 mcg/mL. Median age was 73 (41 to 92) and median Charlson Index was 5 (0-12). All were nosocomial except three that were health-care related, no communityacquired episodes were observed. Median time from hospital admission to positive blood cultures was 29 days (0-167). Up to 18 patients had surgery during the admission. 4 patients had urinary catether, two central venous catheters and five had both at the time of bacteremia. Median antibiotic DDD received before bacteremia was 47 and carbapenem DDD was 23. The source of the infection was intrabdominal in 8/26 patients (31%), urinary in 7/26 (27%), catheterrelated in 3/26 (11%), primary bacteremia 4/26(15%) and others 4/ 26(15%). Regarding severity of presentation, median Pitt Score was 2 (0-11). Eighteen patients received active antimicrobial therapy against the isolate. The most used antibiotic were: tigecycline, amikacin, fosfomycin and colistin, in any combination. Median delay between the date of isolation and the start of an appropriate antimicrobial therapy (MIC sensitive) was 3 days (0-8) and for an adequate treatment (right dose and route of administration) was 7 days (0-8). 18 patients died during admission (69%), 11 treated and seven non-treated. Relationship between bacteremia and death was direct in 10 cases, not related in seven, and unknown in 1.Median time from blood cultures to death was 13 days (0-128). Among those who survived, median time from blood cultures to discharge was 40 days (11-87). Conclusions: BSI caused by OXA-48 produccing enterobacteria are associated with an ominous prognosis, this could be related with dificulties in identification, limited therapeutic options and toxicity of available treatments. Efforts should be made to identify outbreaks and to adopt appropriate measures to control nosocomial spread. (Figure 1) . Over time the male excess has remained fairly constant but with variation by age group. Where reported, the main sources of MRSA and MSSA bacteraemia were lines (36% & 28% respectively) and skin and soft tissue infections (28% & 30% respectively), with much variation by meticillin-resistance, gender and age group. Amongst those aged < 1year lines predominated for both genders (60-70%). Urinary tract infections (UTIs) were more common amongst males compared to females (MRSA 15% vs. 5% [p = 0.0011]; MSSA 9% vs. 5% [p = 0.154]) however this variation was minimal in the <1 year group and most apparent in the 75 + group.\n\nConclusions: Over 60% of S. aureus reports are amongst men, however analysis by organism and age group shows variation. The source of bacteraemia may be driving the gender and age specific trends observed but further analysis is required. Objectives: Obtaining data on trends in the incidence of central lineassociated bloodstream infections (CLABSI) in the population of a large teaching institution is difficult, because days of catheter exposure/ patient is usually measured in the intensive care unit (ICU) only. An alternative could be monitoring catheter-related bloodstream infections (CRBSI) confirmed in the microbiology department. We evaluated recent trends in the incidence and aetiology of CRBSI in a large teaching institution and their correspondence with CLABSI. Methods: We assessed the incidence and aetiology of CRBSI (synchronous presence of the same microorganism in blood culture and in a significant semiquantitative count in the catheter tip) during an 8-year period (2003-2010) by comparing adult ICUs that implemented care bundles with other hospital departments. Results: We recorded 479 710 admissions, 14 713 episodes of BSI (30.67 episodes/1000 admissions) and 1208 episodes (8.2%) of CRBSI. The incidence of CRBSI ranged from 1.9 to 3.6 episodes/1000 admissions, with a mean of 2.5 episodes/1000 admissions. No significant overall reductions in the incidence of CRBSI were detected (p = 0.6). However, after adjusting for the number of blood cultures drawn, we observed a significant 47% reduction (95% CI: 17-66%; p = 0.005) in the incidence rate in adult ICUs, where care bundles had been applied. This trend was similar for both CLABSI and CRBSI.\n\nWe documented an important shift in aetiology, with a significant reduction (9% per year; 95%CI, 3-15%; p = 0.006) in Staphylococcus aureus infections ( Conclusion: We show that the microbiology department could be an excellent watchtower for monitoring the incidence and aetiology of CRBSI in an institution. We observed significant reductions in the incidence of CRBSI in adult ICUs, but not in the remaining hospital departments. A shift in the aetiologic spectrum of CRBSI may be in progress, with a gradual decrease in Gram-positive CRBSI and significant increases in Gram-negative and Candida infections Objective: The increasing use of permanent pacemakers (PM), and implantable cardioverter defibrillators (ICD), has been followed by a sharp increase in Cardiac Device-Related Infective Endocarditis (CDIE). We aimed to characterize CDIE profile, temporal trends, and prognosis. Methods: CDIE diagnosed at Rennes University Hospital -a 1435 bed tertiary care center -during years 2000-2008, were identified through computerized database system and validated by two experts. Patients were included if they presented all of the followings:( i) clinical signs of infection (local, or sepsis); (ii) microbiological documentation through blood and/or lead cultures; (iii) lead or valvular vegetation detected by echocardiography. Data were retrospectively extracted from medical charts. Prognostic factors were searched for using multivariate Cox proportional hazard models. To analyse temporal trends, data were compared with data from the previous study performed in our institution (1992) (1993) (1994) (1995) (1996) (1997) (1998) (1999) , using similar inclusion criteria and methods.\n\nResults: Sixty-six men and 20 women were included, with a median age of 74.5 years (IQR, 66-80). Cardiac devices were implanted because of atrioventricular block (n = 45), and nodal disease (n = 27), and included 83 PMs, and 3 ICD. Median delay between last intervention on cardiac device and CDIE diagnosis was 580 days (IQR, 174-1606) . Most patients presented with fever (n = 68, 79%), positive blood cultures (n = 66, 77%), and fulfilled Duke criteria for definite IE (n = 85, 99%). Most frequent pathogens were coagulasenegative staphylococci (CNS) (n = 39, 46%), Staphylococcus aureus (n = 22, 26%), other gram-positive cocci (n = 11, 13%), and gram-negative rods (n = 8, 9%). Percutaneous extraction of devices was attempted in 79 cases (94%) and successful (total extraction) in 58 cases (73%). Fifteen deaths (17%) were attributable to CDIE. Factors independently associated with 1 year-mortality were chronic obstructive pulmonary disease (aOR 1. . REP is a medical record linkage system that indexes the medical records from all individuals seen by a healthcare provider and residing in OC. We used criteria established by the Centers for Control and Prevention to ascertain the diagnosis of DSWI. Time period specific incidence rates (in-hospital or within 30 days out of hospital) were calculated. A score-based predictive model for DSWI was developed from the logistic regression model using a regression coefficient-based scoring method. To generate a simple integer-based point score for each predictor variable, scores were assigned by dividing beta coefficients by the absolute value of the smallest coefficient in the model and rounding to the nearest integer. The overall risk score was calculated by adding each component together. Discrimination of the model was assessed using the area under the receiver operator curve (AUC). We validated the prediction rule internally using the bootstrap method.\n\nResults: Thousand four hundred and twenty-four residents of OC underwent CABG surgery, of whom 1189 (84%) had isolated CABG and 235 (16%) had combined CABG and valve surgery. The incidence rate of DSWI 1.5% (95% CI 0.9%, 2.2%). We derived a model that includes 5 . AUC of the model=0.80 indicating a strong discriminative ability by the model. Predicted probabilities of DSWI for any possible score are shown in the table (Figure) .\n\nIn this first US population-based surveillance study of CABG patients, we derived a simple model to predict the risk of DSWI.\n\nPatients can be educated about this risk and potential interventions can be incorporated into treatment to diminish the proclivity for infection in high-risk patients. Objective: Adherence to current recommendations (CR) for the management of prosthetic joint infection (PJI) has been associated with better outcome. We aim to validate these recommendations in a multicentre cohort of PJI and to analyse the risks factors for treatment failure.\n\nMethods: Prospective cohort analysis of 281 patients with PJI followed at 13 hospitals in Andalusia (Spain) from October 2006 to October 2010. PJI was defined using standard criteria; modified Tsukayama classification was used. Management was compared with CR (Zimmerli, N Engl J Med 2004). Surgical management was categorized as in accordance to CR or more aggressive, and less aggressive. Antimicrobial therapy was classified as: adequate (all of the following: total duration >6 weeks if prosthesis removal or >8 if retention; early use of antibiotics according to susceptibility testing after surgery; use of antimicrobials with biofilm activity and/or good oral bioavailability); partially adequate (two of the three previous criteria); and inadequate otherwise. Cure was defined as lack of clinical signs and symptoms of infection, C-reactive protein (CRP) <10 mg/L and absence of prosthesis loosening. Logistic regression analysis was performed to study risks factors for treatment failure.\n\nResults: Type of infections: 71 acute postsurgical, 181 chronic, 29 acute haematogenous. Surgical CR (SCR) was followed in 236 (84%) patients and antibiotic CR in 180 (64%). Adherence to SCR was associated with knee/hip PJI (85% vs 55% in shoulder/ankle; p = 0.06), acute PJI (97% vs. 77% in chronic PJI; p < 0.001), non methicillinresistant S. aureus infection (88% vs. 70%; p = 0.04), and CRP >250 mg/L (100% vs. 83%; p = 0.05). Adherence to SCR had higher cure rate (77% vs. 47%, p < 0.001), as had adherence to antimicrobial CR (adequate: 78%; partially adequate: 66%; inadequate: 11%; p < 0.001). Independent factors associated with failure of first surgical procedure performed to treat the PJI were: hemiarthroplasty (OR 2.6; 95% CI: 1.3-5.6; p = 0.01), S. aureus infection (OR 2; 95% CI: 1.1-3.7; p = 0.03), surgical treatment not according to CR (OR 4; 95% CI: 1.9-8.7; p < 0.001), and inadequate antimicrobial treatment (OR 16.4; 95% CI: 1.8-147; p = 0.01).\n\nConclusions: This is the first multicentre study to confirm the validity of CR in PJI. Adherence to SCR needs to be improved in chronic PJI and shoulder/ankle PJI. Objectives: The objective of this study was to review the epidemiology and microbiology of arthroplasty infections with particular reference to surgical antibiotic prophylaxis.\n\nMethods: This retrospective cohort study was conducted across 10 hospitals over a 3 year period (January 2006-December 2008). Cases of prosthetic joint infection involving the hip or knee were identified using the database of the Victorian Healthcare Associated Infection Surveillance System (VICNISS). The definition of prosthetic joint infection was based on the CDC/NHSN definition of organ/space surgical site infection. Information pertaining to antibiotic prophylaxis was collected and the appropriateness of the agent was compared to the antimicrobial susceptibility of subsequently isolated pathogens. Descriptive statistics were used to summarise and report the data. All analyses were performed using Stata 10.1 (StataCorp College Station, TX, 2009).\n\nResults: There were 163 cases of prosthetic joint infection identified. From review of the microbiological culture results, methicillin resistant Staphylococcal species were isolated in 48% of infections (methicillin resistant Staphylococcus aureus in 26% and methicillin resistant coagulase negative Staphylococcal species in 22%). In addition gram negative bacilli and Enterococcal species were frequently seen in polymicrobial infections. The majority of patients received cefazolin (88%) as antibiotic prophylaxis at the time of arthroplasty. On the basis of the microbiological results the surgical antibiotic prophylaxis was inadequate in 63% of patients.\n\nConclusions: This study highlights the need for continual assessment and adaption of local guidelines to reflect local ecology. This higher rate of methicillin resistant Staphylococcal species encountered in this cohort argues to combined glycopeptide and cefazolin for surgical antibiotic prophylaxis guidelines. Objectives: Obesity is increasing in England. An increased BMI is associated with an increased risk of a number of diseases, including surgical site infection (SSI). To assess the impact of increased BMI on the risk of SSI in England, data submitted to the HPA Surgical Site Infection Surveillance Service were analysed. Methods: Surveillance data for operations in five surgical categories: abdominal hysterectomy, coronary artery bypass graft, hip replacement, knee replacement and large bowel surgery, undertaken between 01/01/ 2006 and 31/12/2010 by participating NHS hospitals in England were extracted for analysis. Body mass index was classified as underweight (<18.5 kg/m 2 ), normal (18.5-24.9), overweight (25-29.9), obese I (30-34.9), obese II (35-39.9) or obese III (>40). Patients' pre-operative physical health was measured using ASA score. Infections meeting standard clinical criteria were detected during the initial inpatient stay or at re-admission to hospital. Multivariable logistic regression was undertaken to examine the independence of BMI and other risk factors on the risk of SSI. All analyses were performed in Stata.\n\nResults: Data were submitted by 212 hospitals on a cumulative total of 326 880 operations undertaken between 2006 and 2010. BMI data were available for 141 408 patients (43.3%); of these 112 048 (79.3%) were overweight or obese. The risk of SSI was significantly increased for overweight (RR = 1.15, p = 0.03) and obese patients (RR = 1.27, p < 0.001) compared to patients of a normal weight. After adjusting for surgical category, ASA score, operation duration and wound class, the risk of SSI increased with increasing BMI (overweight vs. normal, OR = 1.44, p < 0.001 and obese III vs normal, OR = 3.85, p < 0.001). The effect of obesity varied according to surgical category with large bowel surgery being most affected by patients' BMI (obese vs. not obese OR = 2.03, p < 0.001) and abdominal hysterectomy being least affected (obese vs. not obese OR = 1.83, p = 0.085). Conclusion: Being overweight or obese substantially increases the risk of SSI. Given the increasing prevalence of obesity in England, it is likely that BMI will increasingly contribute to the overall risk of a patient developing an SSI. This has implications for the management of obese surgical patients. The effect of increased BMI has implications for antimicrobial prophylaxis and for patients' glycaemic control and suggests areas for further clinical research.\n\nInterest in IT solutions to improve patient management S519 The clinician's perspective\n\nIn the last decade, relentless efforts have been made by microbiologists to develop rapid, cost-effective and reliable methods for diagnosis. Automated culture systems, mass spectrometry and DNA based diagnosis have drastically reduced the time needed for pathogen identification in clinical specimens. However, recent studies on rapid bacterial identification of MSRA in blood culture failed to show a clinical impact, when not coupled with an immediate communication of results to the on-ward clinician by either an infectious diseases specialist or a pharmacist. Clearly, rapid microbial identification is most useful if it reaches the clinician in charge immediately and is interpreted correctly. Ideally, an ID specialist could be used to make the link between the lab and the clinician in charge 24/7 for the most relevant specimen. However, what is possible within the funding of clinical studies may not be in real life. IT solutions could provide an alternative approach. Nowadays, most physicians are familiar with handheld devices used at the bedside to check creatinin clearance, drug interactions and so on. The on-ward physician could expect in the near future to receive messages on his ward cell phone such as: ''Mister X, positive blood culture (four vials) with Gram negative rods, Stenotrophomonas maltophilia. This bacterium is naturally resistant to carbapenems and aminoglycosides''. If the hospital already uses an electronic antimicrobial stewardship (AMS) program, the latter could even add: ''Your patient is actually treated by imipenem. Consider empiric use of co-trimoxazol plus ceftazidime''. In institutions using an antibiotic guide, the latter could be electronically linked with the microbiological results (hyperlink). Rapid microbiological diagnosis linked with advanced IT solutions has the potential to positively improve time to adequate treatment of our patients, as well as infection control. However, there are still many questions to resolve. How to identify the physician that is actually at bedside? How to ensure that the ''live'' information is strictly limited to what is most critical for the clinician? How to avoid inappropriate interpretation of lab results? There lies the ''talon d'Achille'' of advanced IT solutions such as electronic AMS programs linked with microbiological results.\n\nS520 How to improve communication from bench to bedside?\n\nCurrently, Labor Berlin is serving 12 hospitals in Berlin comprising three campuses of the Charit\u00e9 -University Medicine Berlin, nine community hospitals of the Vivantes Group Berlin, and an increasing number of hospitals inside and outside of Berlin, the majority of which representing tertiary and specialty care hospitals. We are in the process of implementing full microbiology laboratory automation to provide timely information relevant for patient care. So far, the majority of processes are controlled by a laboratory information system (LIS) that is also transmitting the results to the hospital information system (HIS). At present, urgent results, such as the identification of bacteria causing bloodstream infections or the antimicrobial susceptibility data of multiresistant pathogens are communicated via phone by clinical microbiologists, which also regularly participate on clinical rounds to discuss critical patients. However, the mere number of hospitals and there geographic distribution makes direct communication ever more difficult. We are, hence, forced to apply new information technology to collect clinical data required both for prioritizing tests and for interpreting test results. This requires an intelligent, versatile and open middle ware that not only controls the lab organization but also communicates with existing laboratory or clinical information systems without compromising data safety and security or strangling the capacity of exiting IT divisions. The use of smartphones or other personal digital assistants over wireless broadband or 3G networks represents a promising way for real-time clinical alerts with or without decision support both for antimicrobial therapy or hospital hygiene. Implementation of mobile communication platforms may significantly improve the management of infectious diseases thus preventing further development and spread of antimicrobial resistance.\n\nS522 System interoperability to improve the treatment and surveillance of infections\n\nToday, most laboratories have their in vitro diagnostic devices connected to their information management system, either directly or via an intermediate system steering the work of a set of devices, exchanging the work orders and their corresponding results up and down the stream. This connectivity of the IVD devices to the laboratory information system is achieved for all specialties, microbiology included. It enables the clinical laboratory to streamline its internal processes while improving the level of quality of those processes, thus contributing to meet the requirements of overall quality management standards such as ISO 15189. However, this connectivity is often still relying on non-standard communication protocols as well as on locally agreed coded vocabularies to identify objects such as the types of specimens, the analytes, the microorganism or the antibiotics. This results in a high cost of deployment and maintenance of these interfaces, for both the vendors and the users. Moreover, this lack of standardized protocols and coded vocabularies weighs on the laboratory capability to communicate its results to the stakeholders surrounding it: The information systems of clinicians waiting for the laboratory reports, the shared electronic health records operated by the region or country to improve continuity and coordination of care, and the public health repositories, who need to track and consolidate knowledge on the ongoing status of infections on broader territories, such as Europe with ESCMID for example. A better handling of these laboratory results and especially microbiology results can only occur with an end-to-end connectivity relying on stable standards and consistent vocabularies, used in the same way by all systems potentially dealing with such laboratory results. The international organization Integrating the Healthcare Enterprise (IHE) is contributing to this goal of end-to-end connectivity, by providing a consistent set of profiles of standards in the IHE Laboratory domain, covering the various use cases of laboratory information exchange. Recently this set of profiles has been complemented with the help of another international organization -the IVD Industry Connectivity Consortium (IICC). This 2 years joined effort of IHE and IICC has produced a new profile called ''Laboratory Analytical Workflow''.\n\nWith the complete set of IHE profiles provided for the laboratory domain, not only, clinical information systems but also public health systems and clinical research systems can consolidate and compare results coming from different laboratories, and apply safely reasoning rules on these results, thus improving both the treatment and the surveillance of the infections described by these results.\n\nS529 Should all patients harbouring ESBL-producing organisms be isolated?\n\nIsolation as a mean to control the spread of multidrug-resistant (MDR) organisms is subject to controversy. Isolation makes sense if a bacteria is efficaciously transmitted by direct contact, and patients (or their surrounding surfaces) harbouring them are important reservoirs. In a recent systematic review of published articles, multifaceted strategies including contact precautions and isolation has been shown to be associated with increased probability of controlling the spread of MDR gram negatives. However, because isolation may be associated with adverse effects, pros and cons should be carefully considered. Many clonal outbreaks of ESBL-producing Klebsiella pneumoniae in which colonised patients are key reservoirs have been described. Moreover, some clones of K. pneumoniae are well known by their great ability to spread by cross-transmission within healthcare centres. This usual epidemiologic behaviour makes it prudent to recommend isolation for all patients colonised or infected with ESBL-producing K. pneumoniae. This recommendation may be applied to other species of Klebsiella and Enterobacter. The decision is more difficult in the case of ESBLproducing Escherichia coli. Two arguments can be used to recommend isolation in these cases: the fact that some ESBL-producing E. coli has been shown to spread clonally, and the fact that the mobile genetic elements associated with ESBLs may be cross-transmitted using E. coli or other enterobacteria as a vehicle. However, clonal spread of E. coli actually occurs in the community, and whether acute care centers plays a relevant role in further amplifying the spread is far from clear. Well proven nosocomial outbreaks caused by ESBL-producing E. coli in which cross-transmission is important are scarce and usually affected small numbers of patients. Finally, the prevalence of colonisation with ESBL-producing E. coli in the community in many areas may be too high to feasibly detect and isolate all them. Thus, combining activities aimed at improving hand hygiene and prudent use of antibiotics which select for these organisms (mainly, cephalosporins and fluoroquinolones) while carefully tracking all nosocomial cases so that any outbreak can be readily detected is a reasonable alternative to isolation for all pateints harbouring ESBL-producing E. coli. An exception to this might be patients admitted to ICUs, for which isolation may be prudent. Clostridium difficile infection (CDI) is the commonest cause of hospital acquired diarrhoea in adults but the clinical significance of CDI in children is less certain. This talk describes colonisation and infection with CDI in childhood in terms of risk factors, epidemiology and management. A proposed scoring system for assessing the severity of CDI with specific criteria for children is discussed. Proteomics is particularly suitable for characterizing human pathogens with high life cycle complexity, such as fungi. Protein content and expression levels may be affected by growth states and life cycle morphs. Identification and typing of fungi by conventional methods are often difficult, time-consuming and frequently, for unusual species, inconclusive. Moreover, substantial changes in medical, intensive care and organ transplantation practices are drastically increasing emerging therapy-refractory/uncommon fungi. Herein we report on proteomic phenotypes from MALDI-TOF MS employed as analytical and typing expression profiling of yeasts, yeastlike species and strain variants in order to achieve fungal proteomics population studies. MS-based dentifications (IDs) can be successfully compared to reference biochemical-based systems (e.g.,Vitek-2) and corroborated by genotyping IDs, targeting 25-28S rRNA hypervariable D2 regions. MS IDs show a high analytical performance and profiling heterogeneity which complement or even outclass existing yeast typing tools. This variability reflects the high biological complexity of yeasts and may be properly exploited to provide epidemiological tracing and infection dispersion patterns. Furthermore, filamentous and other fungi (e.g., Aspergillus, Emericella, Fusarium, Geosmithia, Neosartorya, Penicillium, Pseudallescheria, Scedosporium, Talaromyces, Fomitopsis) may be correlated to laboratory-adapted reference ''proteomic phenotypes'' which extend the diagnostic powerful of basic databases. Growth time-courses at 30\u00b0C on Sabouraud agar medium define the 120 hour point as the best peptide extraction condition for full recovery of conidia-or asci-producing multihyphal morph structures and the highest intra-and inter-class profiling correlation, allowing engineered derived libraries. MS mould IDs may be referred to genotyping and to routine morphotyping IDs. Fingerprinting classifiers, selected by Wilcoxon/Kruskal-Wallis algorithm, and computed by different algorithms, allow model construction. Proteomic phenotyping is revolutionizing diagnostic mycology as fully reflecting species/morph varieties but often overcoming taxonomic hindrance. If we are to gain further insights into the description of fungi of relevant medical interest, we need to implement customized fingerprinting databases ''ad-hoc'' generated. MALDI-TOF MS proteomic phenotyping boosts patient-tailored identification protocols in diagnostic mycology. Several studies have been performed in which MALDI-TOF MS has been used for the identification of anaerobic bacteria e.g. Prevotella sp., Fusobacterium sp., Clostridium sp., Bacteroides sp. and gram-positive anaerobic cocci (GPAC). In each of these studies MALDI-TOF MS was shown to be superior over conventional identification methods. The importance of an extensive database containing the reference spectra was also shown in these studies. Several of these studies first compiled a database which was subsequently used to identify unknown strains. Strains not identified by MALDI-TOF MS were mostly species of which no reference spectra were present in the database.\n\nIn a multicenter study two commercially available MALDI-TOF MS systems, Bruker MS and Shimadzu MS, were compared in their ability to identify anaerobic bacteria. The Shimadzu MS system performed better than the Bruker MS system. However, an update of the Bruker MS database resulted in an improved performance, comparable to that of the Shimadzu MS system. This confirms the importance of an extensive database. At this moment a correct species identification is obtained, when compared to the 16S rRNA gene sequencing, for roughly 60% of the anaerobic bacteria encountered in human clinical specimens. More strains can be identified when the available databases are optimized for the identification of anaerobic bacteria.\n\nS539 MALDI-TOF mass spectrometry for the detection of antimicrobial resistance mechanisms J. Hrabak* (Plzen, CZ)\n\nMatrix-assisted laser desorption/ionisation time-of-flight mass spectrometry (MALDI-TOF MS) is routinely used for the identification of bacteria and fungi and has the potential to be applied in complex diagnostic processes. Because MALDI-TOF MS is capable of detecting a broad spectrum of molecules, including structural modifications at the molecular level, the detection of different mechanisms of resistance to antimicrobials may soon become available. Two main approaches can be used for this purpose: (i) the identification of molecular epidemiological markers specific to drug-resistant cells and (ii) the detection of the destruction or modification of antibiotic molecules. The former approach has been used for the detection of methicillin-resistant strains of Staphylococcus aureus and for the elucidation of polymyxin resistance in Gram-negative bacteria resulting from structural changes in their lipopolysaccharides. The latter approach was first applied for detecting the modification of beta-lactams by beta-lactamases. Methods for the detection of carbapenemases based on the hydrolysis of meropenem or ertapenem were recently validated. MALDI-TOF MS was able to detect small changes in carbapenem molecules (e.g., sodium salt variant of these antibiotics). Therefore, it can be hypothesised that assays for the detection of modifications of other antibiotic molecules (e.g., aminoglycosides) can be rapidly developed. The greatest challenge in determining the mechanisms of drug resistance is the quantification of antibiotic concentrations. In general, the quantification of molecules using MALDI-TOF MS may be difficult but is possible. This method could be helpful in the study of efflux and porins. I believe that MALDI-TOF MS can provide many new applications that will be applicable not only in research on drug resistance mechanisms but also the development of routine microbiological diagnostics.\n\nA. Karger*, L. Geue (Greifswald, Wusterhausen, DE) Mass spectrometric analysis of bacterial raw extracts has revolutionised microbiology in the recent years. Analysis by matrix-assisted laser desorption/ionisation time-of-flight mass spectrometry (MALDI-TOF MS) for this purpose is rapid and economic, the resulting spectra can be very informative. These extraordinary features for the identification of bacteria have lead to the extension of the approach for the characterisation of other microorganisms like yeasts or fungi, and also of tissue cultures and whole animals, especially arthropods. The interest of many users focuses on the question of how detailed MALDI-typing can be at best. Concerning bacteria, it is of greatest interest to which taxonomic level samples can be classified and, in a number of cases, if biovars or serotypes can be reliably distinguished. In contrast to the identification of proteins or peptides by mass spectrometry, the identification of the analyte by MALDI-typing is not based on the comparison of the experimental spectrum with masses calculated from a sequence database but rather on the comparison of the analyte spectrum with a library of reference spectra from authentic samples. Although widely applied, some theoretical aspects of mass spectrum-based classification have not been fully addressed yet. A number of commercial and inhouse softwares implementing different classification algorithms are in use, complicating cross-platform comparison of typing results. One step in most algorithms used for classification is data reduction, i.e. the selection of masses from the reference or sample spectra that are useful for classification. This is especially necessary for the distinction of closely related organisms like subspecies or serotypes, as their spectra will only present a limited number of differing masses. In an effort to characterise the spatial and temporal distribution of Shiga toxinproducing Escherichia coli (STEC) isolates representing the serotypes O165:H25, O26:H11/H32, and O156:H25, we have analysed MALDItype spectra by systematic variation of the data reduction step in our classification algorithm. With optimised parameters, the classification of all three O-serotypes was possible with a false rate below 1%. For all combinations of two of the three groups, parameters could be adjusted to accurately distinguish the two groups.\n\nWhat's new in sepsis? ISF Awardee Lecture S541 Malaria predisposes to bacterial sepsis: is malaria pigment the key factor?\n\nM. Boura*, A. Go\u00eds, R. Frita, T. H\u00e4nscheid (Lisbon, PT)\n\nIntroduction: Plasmodium falciparum infection is referred by several studies as a risk factor for bacterial sepsis, especially with non-typhi Salmonella. The professional phagocytes (monocytes and granulocytes) are the first line of defense against external pathogens. If this mechanism is impaired, it could lead to dissemination of bacterial infection, contributing to increase the morbidity and mortality. Malaria pigment (haemozoin), a sub-product of parasite's metabolism released in blood stream after erithrocytic lysis is ingested by these cells, where it may persist.\n\nObjective: To study if the malaria pigment ingested by monocytes and granulocytes has some influence in their function, in particular the subsequent phagocytosis and killing of bacteria (Salmonella enterica serovar Typhimurium).\n\nMethods: Monocytes and Granulocytes were pre-incubated with different amounts of malaria pigment. After this pre-incubation phagocytic capacity was assessed by incubation with a pH dependent dye conjugated with Escherichia coli particles (pHrodo TM ). These particles only fluoresce in acidic environment, such as found in phagossomes which can be measured by flow cytometry. GFP transfected Salmonella were used to assess phagocytosis of live bacteria and killing of these bacteria in pigment containing phagocytes.\n\nResults: Monocytes pre-incubated for 6 hours with 50 micromolar of malaria pigment have their phagocytic ability impaired relatively to the control by a factor of 90%. The same effect is observed in granulocytes, when incubated with the same concentration of malaria pigment, having their phagocytic capacity decreased by 50% relatively to the control. This effect is dose and time dependent. The phagocytic assay using Salmonella also revealed differences between pigment containing and non-containing monocytes. Salmonella phagocytosed by monocytes previously pre-incubated with malaria pigment showed a higher viability in comparison to control. Conclusion: Malaria pigment seems to impair the pahogocytic/ acidifying capacity of phagocytes. Furthermore phagocytes ability to kill bacteria seems decreased by malaria pigment. This may explain why malaria patients acquire disseminated bacterial infections more easily.\n\nUnderstanding pathogenesis and epidemiology by genomics and proteomics O546 High-throughput MLST -Bringing molecular typing to the next level S.A. Boers*, W.A. van der Reijden, R. Jansen (Haarlem, NL)\n\nIntroduction: MultiLocus Sequence Typing (MLST) is a widely used system for typing microorganisms by sequence analysis of seven housekeeping genes. MLST protocols are published for many species and online databases have proven to be a powerful resource in studying the (global) epidemiology. The main advantage of MLST compared to other typing techniques is the unambiguity and transferability of sequence data. The main disadvantage is the high costs to generate the sequence data.\n\nObjective: Here we introduce the High Throughput MLST (HiMLST) method that employs Next Generation Sequencing (NGS), which delivers large quantities of high quality MLST data at low prices. Methods: The HiMLST protocol consists of two steps. In the first step the seven MLST targets are amplified by PCR in multi-well plates. During this PCR the amplicons of each strain are provided with a unique DNA tag, the Multiplex Identifier (MID). In the second step all amplicons are pooled and sequenced in a single NGS run (GS Junior, Roche). After the sequencing run, the MLST profile of each individual strain can be easily generated using its unique MID.\n\nResults: With the HiMLST we have generated 96 MLST profiles in a single run. The HiMLST was employed for Legionella pneumophila, Staphylococcus aureus, Pseudomonas aeruginosa and Streptococcus pneumoniae and will be applicable to many other species. Moreover, the use of MIDs allows the combined sequencing of different species in a single NGS run. Currently, the HiMLST reduces the cost of MLST by a factor 10 compared to traditional methods. It is expected that the costs can be reduced further by introducing low volume PCRs and automated processing of reagents and sequence data. In this way, the HiMLST capacity can be doubled while retaining the high quality of the sequences.\n\nConclusion: The introduction of HiMLST paves the way for a broad employment of the MLST as a high quality and cost effective method for typing microbial species.\n\nO547 Good performance of Objectives: Methicillin-resistant Staphylococcus aureus (MRSA) represents a serious threat for public health worldwide. Of particular concern is the MRSA clone USA300. This lineage is predominant in the United States but has disseminated to other countries in recent years. Noteworthy, Pulsed-field gel electrophoresis (PFGE), which is the ''gold standard'' for typing S. aureus, cannot be used to distinguish between the ''classical'' community-acquired USA300 clone with the spa-type t008 (ST8-IVa, Panton-Valentine leukocidin positive) and a related nosocomial clone with the spa-type t024 (ST8-IVa, PVL negative). Therefore, the objective of this study was to determine the applicability of Multiple-Locus Variable number tandem repeat Fingerprinting (MLVF) in the discrimination of these two related clones. In addition, we compared the exoproteomes of the respective strains, because the secreted proteins represent a major reservoir of S. aureus virulence factors. Methods: 78 USA300(-like) isolates were collected at the Statens Serum Institute in Denmark. Multiplex PCR with subsequent electrophoretic separation with an Agilent 2100 Bioanalyzer was performed as described by Sabat et al. 2003 . Secreted proteins were collected and analyzed by SDS-PAGE. Results: MLVF grouped the 78 isolates into two distinct clusters: A (n = 40) and B (n = 38). Importantly, all isolates of cluster A had spatype t024, whereas all isolates of cluster B had spa-type t008. Furthermore, both clusters were composed of several patterns, but within each cluster most of the strains yielded the same pattern. Thus, the majority of the strains within each cluster are genetically closely related. The exoproteome analyses complemented the MLVF data, since differences in the secreted proteins of S. aureus isolates in clusters A and B were clearly detectable.\n\nConclusion: MLVF has the discriminatory power needed to distinguish between the community-acquired USA300 clone and closely related lineages with the same PFGE profile. Additionally, MLVF allows a differentiation of isolates with the same spa-type into sub-clusters, which will be relevant for further epidemiological studies. In addition, exoproteome analyses on the community-acquired USA300 clone and related nosocomial lineages will provide better insights into their virulence potential. Ultimately, this will lead to a better understanding of critical determinants for staphylococcal fitness and pathogenesis. Objectives: To determine the impact rapid epidemiological typing has on the control and transmission of C. difficile. Method: A prospective study was conducted in 15 hospitals in the United Kingdom over 12 months. All faeces samples that were confirmed as toxin positive for C. difficile from periods of increased incidence (PII) which was defined as two or more patients developing C. difficile in a 28 day period on a ward were submitted for typing. Hospitals were randomised into control or test arm, with all isolates in the test arm being typed using modified MLVA typing and isolates in the control arm being typed using PCR ribotyping; all results were fed back in a timely manner. Following the reporting of results from a PII a questionnaire was sent to each Trust to evaluate whether they considered that the typing result had aided their management. The total number of patients positive for C. difficile 48 hours after admission was collected for each hospital and modelled using a negative binomial regression model, including the logarithm of the number of beds in the Trust as an offset term to compensate for the different Trust sizes.\n\nResults: There were a total of 785 samples from 245 PIIs, with a range of 0 to 58 PIIs being reported by hospitals. The number of cases involved in a PII ranged from 2 to 15, with the mean duration of a PII being 19.9 days in the MLVA arm and 19.1 in the ribotyping. Of the 785 samples, typing results were available for 318 (83%) in the ribotyping arm and 351 (88%) in the MLVA arm, 166 samples could not be typed due to not enough sample or isolate could not be cultured. The mean turnaround time for MLVA was 5.3 days as opposed to 13.6 days for ribotyping. Of the 785 cases investigated 208 were considered to be part of an outbreak by the method used for investigation. The number of patients acquiring C. difficile >48 hours after hospital admission during the study period was 814 in the MLVA arm and 868 in the ribotyping arm and the binomial regression model confirmed no differences between the intervention and control group. In response to the questionnaire 43% of respondents in the MLVA arm stated that the results had aided their management as opposed to 8% in the ribotyping arm. Conclusion: MLVA typing provided a rapid turnaround providing results that aided the management of outbreaks. However, due to the multifaceted nature of controlling C. difficile the study did not demonstrate a difference between the two groups. (SID = 93, 4% [92, 6%] ). The emm89 (n = 62) and emm1 (n = 55) isolates were the most prevalent and constitute the two main PFGE clusters, accounting for 37% of the collection. The most frequent SAg gene was smeZ (96%), followed by speG (94%), speC (58%), speJ (40%), speA (33%), ssa (21%), speH and speK (16%), speI (14%), speM (7%) and finally speL (6%). The emm89 and emm1 clusters were mainly characterized by the presence of speC, speG, smeZ and speA, speG, speJ, smeZ, respectively. It was detected one isolate resistant to chloramphenicol and two nonsusceptible to levofloxacin. Macrolide resistance was detected in 10% of isolates, mostly with the cMLSB phenotype. Tetracycline resistance was detected in 47 isolates, of which 12 were also resistant to macrolides.\n\nConclusion: The prevalence of clusters carrying emm1 and emm89 suggests an important role of these emm types in skin and soft tissue infections in Portugal. The emm1 cluster was also previously identified as the dominant cluster among invasive isolates in Portugal. As expected, except for speJ, SAgs encoded by chromosomal genes (smeZ and speG) were present in the great majority of the isolates while those associated with prophages were more variable. Objectives: Recent studies have demonstrated that the capsular locus of S. pneumoniae serotype 11A is associated with a high degree of genetic heterogeneity. A new serotype, named 11E, was discovered among strains previously identified as serotype 11A, carrying a capsular locus with a mutated or disrupted wcjE gene. In addition, the genomic analysis of three serotype 11A pneumococcal strains revealed a discordance between the serotype and the capsular locus, which corresponded to that associated with the 11D serotype. The aim of this study was to verify which capsular locus was present in serotype 11A pneumococcal strains circulating in Italy.\n\nMethods: Thirty-one pneumococcal strains serotyped as 11A according to the Quellung reaction and obtained from invasive diseases in Italy in the years 1997-2010, were analysed. Since most of the nucleotide diversity between capsular loci 11A, 11D and 11E, resides in wcjE, coding for a putative O-acetyl transferase, the entire gene was amplified and sequenced.\n\nResults: Out of 31 strains, two carried a wcjE gene 100% identical to 11A and 20 carried a wcjE gene 99-100% identical to 11D. Among the latter, two strains carried an amino acid substitution due to distinct single nucleotide polymorphisms (SNPs). The remaining nine strains showed a disrupted wcjE gene, being consistent with serotype 11E. In particular, five strains showed a wcjE gene disrupted by transposable elements (IS1515 insertion in four strains and IS1167 insertion in one strain) while four strains showed unique mutations including duplications, insertions and SNPs resulting in either late start codon or premature stop codon with respect to the wild type sequence. These mutations have not been previously described.\n\nConclusions: This study highlighted that in Italy the more prevalent capsular genotype, associated with serotype 11A, corresponds to 11D. In addition, the presence of isolates with an 11E genotype has been demonstrated, suggesting that conventional serotyping could have masked the real epidemiology of this serogroup. It is likely that the 11 serogroup typing scheme would be reconsidered in the near future. Objectives: The impact of the CD4 nadir reflecting the timing of cART initiation on the immune functionality to recall antigens in the longterm is not yet well understood. A preserved polyfunctional CD4 T-cell profile characterised by double / triple cytokine secreting CD4 cells is thought to be of advantage.\n\nMethods: In a proof-of-principle pilot study we evaluated the influenza A-specific polyfunctional CD4 T-cell profile (IFN-g, TNF-a, IL-2) in three HIV-positive patients on HAART with a high (>500/uL) and low (<50/uL) CD4 nadir each compared to three healthy HIV-negative controls before (BL) and 2 weeks (w2) fig.) .\n\nA low CD4 nadir is associated with a functional impaired influenza A-specific CD4 T-cell response after immunisation despite absolute CD4 T-cell recovery under cART compared to healthy controls and HIV-pos. patients on cART with a CD4 nadir >500/ul. These preliminary findings need to be verified in a lager cohort, but argue for a substantial benefit of an early cART initiation. Overall proliferation capacities of PBMCs were equal in both groups but the distribution of T cell subsets within proliferating cells was significantly different with lower frequencies of T^EMRA (22.5% p = 0.010) and higher frequencies of T^EM (50.4% p = 0.02) and CD25 high T^EM (26.4% p = 0.015) in InRs (CRs:34.4%; 33.2%; 9.1%). Of InRs less PBMCs (4.6%), CD4+ (5.2%) and CD7-cells (4.4%) secreted IL-2 upon SEB stimulation (CRs: 9.1% p = 0.043; 11.1% p = 0.010; 11% p = 0.023) also exhibiting a distinct distribution of T cell subpopulations with less T^EMRA (11.2% p = 0.042), T^n (5.7% p = 0.005) and T^CM (7.6% p = 0.008) and more T^EM (75.4% p = 0.05) and CD7-cells (54.6% p = 0.027) (CRs: 24,7%; 14.8%; 14.7%; 45.7%; 23.3%).\n\nConclusion: Terminally differentiated CCR7-CD7-cells accumulate within the CD4 population and among T^regs in InRs. As terminal differentiation is associated with compromised effector functions, impairment of T^regs might contribute to persistent immune activation which in turn leads to a higher frequency of CD7-cells within the CD4+ T cells lacking the ability of adequate proliferation in order to reconstitute T cell loss. Upon stimulation those T cell subsets accumulate that show compromised IL-2 secretion capacities (CD7-) as well as those unable to home (CCR7-) into secondary lymphoid organs like T^EM cells. As IL2 is an essential growth factor for T^eff and T^reg cells, low IL-2 levels might explain persistent CD4 cell depletion as well as chronic immune stimulation in InRs.\n\nO560 Incidence and characteristics of tenofovir resistance(K65R mutation) in non-B subtype HIV-1infected patients who failed non-tenofovir-containing antiretroviral therapy O. Putcharoen*, S. Sirivichayakul, S. Mekprasan, K. Ruxrungtham (Bangkok, TH)\n\nObjective: Tenofovir(TDF) is a potent nucleoside reverse transcriptase inhibitor (NRTI). K65R mutation is usually selected in patients who fail TDF. However, K65R can be selected by d4T or ddI in non-B subtype HIV-1 and potentially limit use of TDF in subsequent antiretroviral regimen. Only AZT exerts activity against K65R.In developing countries, the most widely used antiretroviral therapy (ART) is non-TDF containing regimens such as d4T, ddI, AZT and 3TC.We aimed to determine the incidence and characteristics of K65R mutation in patients who failed non-TDF containing ART. Objectives: Twenty multi-drug resistance (MDR) patients, who achieved a successful virological suppression with darunavir/ritonavir (DRV/r) containing regimens, were followed for 72 weeks to examine the evolution of intracellular drug resistance associated mutation (RAMs) pattern. The main aim of this analysis was to assess the ability of the archived viral variants to re-emerge during ART and to establish their role in therapy failure. Methods: All patients belonging from a larger cohort of antiretroviral multi-drug experienced HIV-1 subjects, enrolled at the ''Sapienza'' University Hospital, were included in the study. All subjects have already been failed several therapeutic regimens, with a mean treatment time of 17.6 \u00b1 3.6 years. At the time of the inclusion in the study (80 \u00b1 16 weeks from the DRV/r start) all subjects had reached a HIV-1 RNA level below the limit of detection (<50 copies/mL). HIV-DNA was extracted from peripheral blood mononuclear cells, amplified and sequenced using the TruGene assay. Intracellular drug resistance mutations were detected at T0 (baseline) and, in most patients, after 18, 36, 54 and, in all patients, 72 weeks from the start of study.\n\nResults: During 72 weeks of follow-up all patients had an undetectable viremia. At baseline, all subjects had RAMs in proviral DNA, all of which related to previous ART. Interestingly, 18 patients had intracellular mutations associated to DRV resistance at T0. Specifically, using REGA rules, six of 18 subjects showed a genotypic resistance to DRV (score \u2021 3.5), eight had an intermediate susceptibility (score \u2021 2; <3.5) and four were fully susceptible to DRV (score < 2). After 72 weeks of follow up, 14 patients had an intracellular DRV genotypic score unchange; whilst in four patients the genotypic score changed due to loss and/or acquisition of some DRV RAMs. Considering the patients all together, the number of RAMs increased in 8/20 patients (median value: four mutations; range 2-9) and decreased in 6/20 patients (median value: three mutations; range 2-10). In the remaining patients the number of mutations detected after 72 weeks was similar to that observed at T0 (\u00b11 mutation).\n\nConclusions: Although performed in a small group of patients, our study suggest that in patients treated with a salvage therapy, the presence of MDR virus in cellular reservoirs, may change, but does not affect virological response during 150 weeks of follow up. Objectives: Few data exist on the distribution of HIV-1 subtypes in the Gambia and Guinea-Bissau. We aimed to increase the current database in this field, which is important for maintaining molecular diagnostics, choosing epitopes for HIV vaccines and exploring potential differences in clinical outcomes and response to antiretroviral therapy (ART) between subtypes. As ART was introduced in 2005 in the Gambia, we also aimed to survey the presence of baseline HIV drug resistance in newly diagnosed ART-na\u00efve individuals since 2005. Results: MIF levels were 2.7-fold higher in HIV-infected patients than in HIV-negative controls (13.7 \u00b1 5.4 vs. 5 \u00b1 1.9 ng/mL, means \u00b1 SD, p < 0.0001). Median MIF levels in AHI (20.6 ng/mL) were significantly higher than those chronic infection na\u00efve to ART (16.3 ng/L), chronic infection on effective ART (11.6 ng/mL) or chronic infection on failing ART (11.9 ng/mL). MIF levels from patients on effective ART were 1.4-fold lower than those from patients na\u00efve to ART (p = 0.027 The last decade the landscape of the medical specialty of microbiology in the European Union (EU) has changed dramatically when many new countries, recognising microbiology as a full specialty, joined the EU and delegates reached a majority in the European Union of Medical Specialists/ Union Europ\u00e9enne des M\u00e9decins Sp\u00e9cialistes (UEMS). As a consequence a new monospecialist UEMS Section of Medical Microbiology became a reality in 2008 in Brussels (1, 2, 3). One of the aims of the UEMS is the harmonisation of medical specialties and specialist training. This is based on the so called EU Doctors' Directive.\n\nA recent inquiry revealed that the differences in time spent for and in focus on the various fields of clinical and scientific interest in microbiology during training are showing a wide variety in EU countries. Therefore consensus is needed on minimum requirements for the performance of the specialty at an optimal level, appropriate to EU standards. The profile of the specialty and terms for training has been defined many years ago. This profile still is the basis for the training programme and the detailed logbook. According to UEMS Chapter on Training of medical Specialists in the European Community (4) the training program and the logbook have to be implemented and standards and assessment of the quality of training centers and trainers have to be developed. The UEMS Chapter 6 on training, containing these requirements for a 5 year training program, has been adopted during a recent Council meeting in 2011 in Naples (5) Diagnosis of Chagas disease (CD) during the acute phase relies on the direct observation of the parasite in blood. Microhematocrit and Strout's method are the reference techniques while PCR is recommended for congenital cases because of its higher sensitivity. In immunocompromised patients' reactivations, Trypanosoma cruzi may also be detected in other body fluids and tissues. Parasitological methods have low sensitivity for chronic CD thus diagnosis is based on serological testing (usually indirect haemagglutination, indirect immunofluorescence and ELISA), being necessary at least two techniques with a positive result to establish a diagnosis of chronic CD. In this setting, PCR techniques are not enough sensitive for diagnosis but may have a role in discordant cases. Currently, only two drugs with proven efficacy against T. cruzi infection are marketed. The use of benznidazole is generally preferred over nifurtimox because of its better safety profile, tissue penetration and possible higher efficacy. Tolerability of both drugs is not good and a significant number of patients develop adverse reactions that lead to treatment interruption in up to 40% of cases. Assessment of treatment efficacy is difficult because it is affected by the phase of CD, dose, length of treatment, and the end-points evaluated in clinical studies. Trypanocidal treatment has proven to be efficacious in acute, congenital, early chronic infections (children under 18) and reactivations, while its usefulness is much more doubtful in patients with late chronic disease, and probably has no role in advanced organ involvement. As for treatment monitorization serology is the most reliable test for cure. However, while in children serology negativization can take 3-6 years after therapy, in adults with chronic CD this may take up to 10-20 years. Parasitological methods (xenodiagnosis and blood cultures) are poorly sensitive, and PCR could be a useful tool but still awaits for standardization and clinical validation. There are many challenges to overcome about CD. We need more sensitive and standardized T. cruzi detection techniques, to identify markers for disease progression, and validated surrogate markers for response to therapy. There is also an urgent need for better drugs, with improved efficacy and tolerability, paediatric formulations and newer treatment strategies focused on therapy length, drug combinations, retreatment of therapy failures, and management for immunosupressed patients All isolates were susceptible to both vancomycin and daptomycin. There was weak correlation between vMIC and dMIC, (rs = 0.21, p = 0.003). Factors associated with vMIC were increased age, renal failure, the presence of an intravascular catheter, health-care associated acquisition, and IDU, whereas mortality at 30 days was not associated with vMIC (Table 1 ). In the univariate analysis, age, COPD, housing status, and health-care associated acquisition were associated with mortality; however these were not statistically significant in the multivariate analysis.\n\nConclusion: Susceptibility testing revealed that 100% of blood culture MRSA isolates remained susceptible to vancomycin and daptomycin. Advanced age, renal failure, the presence of an intravascular catheter, and health-care associated acquisition were associated with having a higher vMIC. There was no association found between higher vMIC and mortality. Invasive Fungal infections (IFI) are important causes of morbidity and mortality in immune-compromised patients. Diagnosis relies on culturebased methods, which lack sensitivity and delay diagnosis. PCR for the diagnosis of IFI offers an attractive method for early diagnosis. However, a lack of standardization of fungal PCR assays has limited its acceptance as a diagnostic tool. There is currently no consensus on the optimal blood fraction from which to isolate Candida DNA. A PCR detection limit of <10 CFU/mL in whole blood (WB)have been associated with improved test performance for Candida. A consensus concerning the type of specimen, volume, the extraction method, target, PCR format and platform has to be reached. In 2006, the European Aspergillus PCR Initiative (EAPCRI) was formed. The aim of the initiative was to provide optimal standardized protocols for the clinical evaluation of the Aspergillus PCR to determine its diagnostic role and allow inclusion in disease diagnosis criteria. A standardisation for Aspergillus PCR assay in (WB) and serum has been proposed by the EAPCRI. For the detection of Aspergillus in WB: the importance of the nucleic acid extraction protocol in achieving satisfactory analytical sensitivity was highlighted. For PCR testing of WB: blood volumes (>3 mL) should be be efficiently lysed before bead beating to disrupt the fungal cell and use of an internal control PCR to exclude false negativity. DNA should be eluted in volumes of <100 L. For the dection of Aspergillus in serum: A positive association between sensitivity and the use of larger sample volumes, an internal control PCR and PCR targeting the ITS region was shown. Negative association between sensitivity and the use of larger elution volumes (>100 uL) and PCR targeting the mitochondrial genes was demonstrated. A multi-centre clinical trial is required to determine the clinical validity and utility of both Candida and Aspergillus WB and serum PCR testing, and a multi-centre comparison of WB and serum PCR is required to determine the optimal specimen for PCR diagnosis.\n\nClinical parasitology in western hospitals: the essentials S613 Therapy of parasitic infections: a large task for few drugs E. Caumes* (Paris, FR)\n\nThe overall mortality rate of imported Plasmodium falciparum malaria in Europe is about 0.3%. Quinine has been the only option for parenteral therapy. However intravenous artesunate becomes a more widely available. It is more effective than quinine in severe malaria in endemic countries. Artesunate is a fast-acting acting drug, efficicient against several parasite stages including gametocytes with reduction of cytoadherence. However data on tolerability and safety are limited. The continuous advances in the field of antiretroviral therapy dramatically improved the natural history and the prognosis of HIV infection and AIDS. Due to the high efficacy of new drugs and drug classes, the rate of virologically suppressed patients in our Outpatient services is currently around 90%. Nevertheless, several side effects have been described for each antiretroviral and antiretroviral drug class; this, in addition to the aging phenomenons, increases the risk of concomitant cardiovascular, renal and bone diseases in our patients.\n\nThe current treatment guidelines recommend as first line antiretroviral therapies three drug regimens with a ''backbone'' of two nucleos(t)ide reverse transcriptase inhibitors (N(t)RTIs) and a ''third drug'' to be chosen among non-nucleoside reverse transcriptase inhibitors (NNRTIs) and ritonavir-boosted protease inhibitors (PIr). Regimens containing less than three antiretroviral drugs are currently not recommended based on the high risk of virological failure and selection of drug resistance mutations (DRM) with previous experience of NRTIonly based approaches, except for boosted PIs monotherapy which is optional in patients with intolerance to NRTIs or requiring treatment simplification provided that they never experienced virological failures or admitted in exceptional circumstances. Nevertheless, the investigation of possible new treatment paradigms remains attractive due to the high potency and low risk of selection of drug resistance mutations with PIr based therapies and the established long term toxicity of even newer and currently preferred N(t)RTIs, in particular the renal and bone toxicity of tenofovir and the debated potential association with increased cardiovascular risk of abacavir, which has been described in some cohort studies. New treatment strategies are thus being evaluated in order to try to respond to the unmet medical needs of HIV-infected patients with metabolic complications and increasing risk of concomitant cardiovascular or renal diseases. This talk will review the evidence regarding the safety and the efficacy of alternative treatment paradigms based on older and newer antiretroviral drugs and drug classes and will also try to define the optimal candidates for these regimens. We observed both the carriage of similar KPC-harboring plasmids within genetically distinct strains and the inter-hospital spread of the two major clones ST258 and ST512, belonging to CC258. KPC-3 was also identified in clones ST646, ST650 and ST14 . The blaVIM gene was identified in clones ST646, ST647 and ST648. The blaKPC-3 gene was located on plasmids similar to those previously described in clone ST258 from Israel. The ST258 clone identified in two hospitals harbored an additional IncA/C plasmid, carrying the CMY-2 AmpC beta-lactamase. One patient had an intra-abdominal infection sustained by a ST258 KPC-3-producing clone, but during the treatment with colistin a carbapenem susceptible isolate lacking the plasmid carrying KPC-3 was isolated from the same site and successfully treated with carbapenems. Another patient developed sepsis sustained by a ST512 KPC-3-producing clone, but on the same day a ST512 strain, susceptible to carbapenems and negative to KPC-3, was isolated from urines. In this strain a rearrangement occurred on plasmid, causing the loss of the blaKPC-3 gene. Conclusion: Our findings evidenced an unexpected and high spread of carbapenemase-producing KP in our urban area. Different strains were identified carrying the KPC-3 gene, but all of them were associated to a common plasmid of the pKpQIL type. This plasmid represents the major vehicle of diffusion of KPC-3 among the different strains circulating in this area. However, two major clones where identified: ST512 and ST258, also indicating suggesting inter and intra-hospital spread. Conclusions: In conclusion we report a clonal outbreak of KPCproducing K. oxytoca in Austria involving five patients and lasting for 5 months. While outbreaks of KPC-producing K. pneumoniae have been described frequently no outbreak of KPC-producing K. oxytoca has yet been described to the best of our knowledge. These observations provide some insight in the epidemiology and clinical importance of KPC carbapenemases that pose a serious clinical threat also when produced by K. oxytoca. Objectives: Nosocomial infections sustained by carbapenem-resistant Klebsiella pneumoniae (KP) are a global health problem. Active surveillance has been maintained in 2011 in 10 hospitals of Rome, demonstrating that the increasing carbapenem resistance in KP was associated to the production of the carbapenemase KPC-3 in two major clones:ST512 and ST258. The entire plasmid content of these strains was investigated by high-throughput sequencing to ascertain the contribution of plasmids to the success of these clones. Methods: Full sequencing of plasmids was performed applying the 454-Genome Sequencer FLX procedure on libraries obtained on total plasmid DNA purified from two archetypal ST258 and ST512 strains. Contigs with at least 15-fold coverage obtained by GS-FLX gAssembler software were assembled by the PCR-based gap closure method. Results: Up to four different plasmids were identified within the strains. The IncFIIk-FIBk plasmid, carrying KPC-3 was identified in both strains and was very similar to plasmid pKpQIL identified in KP ST258 strains from Israel (GU595196). With respect to the former pKpQIL a composite transposon IS26-aphA1-IS26, conferring kanamycin resistance was acquired in the pKpQIL from the ST258 strain identified in Italy. Both strains contained another IncFIIk-FIB-like plasmid, we named pKPN-IT, which was highly related to plasmid pKPN3 identified in KP from USA, conferring resistance to arsenic, copper and silver. Plasmid pKPN-IT showed a Fec-like iron(III) dicitrate transport system, a glutation ABC-transport system, a class 1 integron carrying trimethoprim and streptomycin resistance genes (dfrA12, orfE, aadA2) and the chloramphenicol and macrolide resistance genes (catA1, mphA). One ST258 strain also carried an IncA/C plasmid carrying the AmpC CMY-2 beta-lactamase. Other novel plasmids belonging to untypable groups were also identified within these strains.\n\nThe presence of multiple resistance and putative virulence plasmids within KP-KPC-3 clones endowed the strains with a formidable set of resistance genes against toxic compounds, metals and antimicrobial drugs. The presence of the iron (III) uptake system is likely involved in the capacity of the bacterium to acquire iron in the human host. Our study contributes to the description of the characteristics of KP clones that currently represent a serious potential risk for nosocomial settings. Background: Complex epidemiology of KPC-producing Enterobacteriaceae (KPC-E) with non-ST258 K. pneumoniae (Kpn) clones was documented in our hospital. Since colonized patients are the main reservoir of multiresistant bacteria, we determined the length of carriage (LOC) with KPC-E in patients with infection and/or colonization with these isolates. Methods: From September-09 to June-11, 19 patients (nine females; median age 75 years, range 24-86) were infected and/or colonized by KPC-E and under routine colonization screening and contact precautions. Swab cultures (chromID-ESBL medium, bioMerieux) from throat and rectum were taken weekly until three consecutive negative cultures, or discharge. Identification (MALDI-TOF) and phenotypic-KPC production (modified Hodge test and boronic acid disc method) was confirmed. KPCs were identified by PCR and sequencing, and the harbouring clones characterized by PFGE and MLST. LOC is defined as the time elapsing between the first and last documented positive culture for KPC-E, and CP (clonal persistence) as the ratio between the average days of colonization per clone and the average days of follow-up per patient. Results: Seventy-five throat and 80 rectal specimens were obtained. KPC-E isolates were recovered in 25.3% (19/75) throat and 52.5% (42/ 80) rectal swabs. Rectal colonization was demonstrated in 68.4% (13/ 19) of the patients, half of them concomitantly with positive pharyngeal cultures. None of the patients had only pharyngeal colonization. The mean duration of follow-up after the first positive KPC-E culture were 28.5 \u00b1 32.4 days (median 18, range . LOC with KPC-E in the patients with positive surveillance cultures (68.4%, 13/19) was 22.5 \u00b1 19.8 days (median 20, range 3-69). KPC-E clones were: K. pneumoniae (12/13 patients) ST20 (2/12), ST384 (6/12), ST454 (1/12) and ST659 (3/12) and two E. coli (Eco) in two patients. One patient was co-colonized with Kpn-ST659 and an Eco clone. Kpn clones showed different CP values (Kpn-ST384, 0.79; ST20, 0.73; ST454, 0.41; and ST659, 0.58). Both Eco clones were detected during all the follow-up period (CP = 1) Conclusions. Rectum was the most sensitive sampling site for detecting KPC-E colonization. Pharyngeal colonization was not present in the absence of rectal carriage. K. pneumoniae clones exhibited different lengths-of-colonization (LOC) values. Such variability encourages the need of identifying clonal factors involved in to long persistence that could enhance clone transmissibility. Clinical strains were isolated from different body sites (blood, urine, rectal swabs or sputum), during the patient hospitalization, in particular when the antibiotic resistance profile changed. Species identification and antimicrobial susceptibilities were obtained by Vitek2 System (bioM\u00e9rieux). All of isolates were suspected for KPC production based on synergistic activity with phenylboronic acid. Imipenem, meropenem, ertapenem, colistin and tigecycline susceptibility was assessed also by E test. A total of 52 isolates were chosen as representative and further investigated by genotyping. PCR for blaKPC-like genes and sequencing were performed. PFGE and multilocus sequence typing (MLST) were used to investigate clonal relatedness. Results: All 52 isolates resulted KPC-positive, harbouring blaKPC-3 gene. Carbapenem MICs ranged from 4 mg/L to >32 mg/L and 18 isolates were resistant to colistin (in the range of 4-24 mg/L), whereas only five isolates were still sensitive to tigecycline. PFGE analysis revealed the spread of one prevalent clone belonging to ST512 and showing seven pulsotypes clonal variants (pt A1-A7), and two sporadic clones, belonging to ST258 (pt A8) and ST101 (pt B). Several isolates with distinct genotypes in the same patient were found, suggesting that the colonizing strain may occasionally be replaced.\n\nThe phenotypic and molecular heterogeneity of the CC258 circulating in our hospital supports the hypothesis that K. pneumoniae infection and colonization was a very dynamic process, where the ST512 clone could be the result of a single locus mutation occurred in the high risk clone ST258 worldwide distributed. The emergence of colistin-resistant could be attributed to selection pressure from excessive and inadequate colistin use.\n\nO630 Co-production of kpc-2 and ges-like in Aeromonas spp. isolates from a hospital effluent in Brazil Metallo-beta-lactamase-encoding genes were not identified. Among KPC-2 producers, four isolates also carried the blaGES-like gene (n = 2, A. caviae; n = 2, A. hydrophila). Both isolates of each species shared the same ERIC-PCR pattern. The MICs (in mg/L) ranges of the four isolates were as follows: amoxacillin/ clavulanic acid (8/4->16/8), cefotaxime (32->128), ceftriaxone (>128), ceftazidime (64->128), cefepime (>32), aztreonam ( \u202164), ertapenem ( \u20214), imipenem (2-16), meropenem (\u00a31->8), gentamicin (1-4), tetracycline (0.5), ciprofloxacin ( \u20212), trimethoprim/sulfametoxazole (\u00a30.5/9.5->2/38) and chloramphenicol (1-16).\n\nConclusion: High carbapenem-resistant rates were observed in Aeromonas spp. from a hospital effluent in Brazil. The presence of blaKPC-2 and blaGES-like in such waterborne pathogens may hamper the appropriate treatment of infections. Additionally, since these genes are often located in broad-host range plasmids with notable potential to spread, our findings strengthen the role of Asp as an environmental reservoir of resistance genes to broad-spectrum antimicrobials in the environment.\n\nBacterial pathogenesis: what is new (from virulence factors to biofilm)?\n\nO631 Intestinal anaerobic bacteria: in vitro ability to adhere and to grow as mono-or dual-species biofilm C. Vuotto*, G. Donelli, R. Cardines, P. Mastrantonio (Rome, IT)\n\nObjectives: On the basis of our recent data on the close association existing between the clogging of biliary stents and the development in their lumen of a polymicrobial biofilm, twelve anaerobic strains isolated from explanted stents and belonging to the genera Bacteroides, Clostridium, Fusobacterium, Finegoldia, Prevotella and Veillonella were investigated for their ability to adhere, to grow in sessile mode and to form in vitro mono-or dual-species biofilms. Methods: The ability to adhere and to form biofilm in vitro was evaluated by the quantitative biofilm production assay. Then, strains were investigated when growing as mono-and dual-species biofilms by Field Emission Scanning Electron Microscopy (FESEM) and Confocal Laser Scanning Microscopy (CLSM). Experiments on dual-biofilm formation were planned on the basis of the anaerobic strains isolated from each clogged biliary stent, by selecting those in which a couple of anaerobic strains belonging to different species contributed to the polimicrobial biofilm development.\n\nResults: We demonstrated the ability of the tested strains to adhere and to grow in a sessile mode to a different extent. Further, it was possible to point out a synergistic interaction of the involved species in forming dual-species biofilm. The FESEM analysis allowed us to distinguish between the two biofilm-forming bacterial species on the basis of their different features (rods or spear-shaped bacilli vs. cocci). Further, this morphological approach offered the chance to approximately evaluate the relative contribution of the two interacting species to form the mixed biofilm. Conclusion: As far as we know this is the first report on the ability to in vitro adhere and to form single/dual-species biofilms exhibited by anaerobic strains belonging to the species Bacteroides oralis, Clostridium difficile, Clostridium baratii, Clostridium fallax, Clostridium bifermentans, Finegoldia magna, Fusobacterium necrophorum. Further, the in vitro development of dual-species biofilms by the couples Fusobacterium necrophorum + Veillonella spp, Bacteroides fragilis + Finegoldia magna, and Finegoldia magna + Clostridium difficile has a particular significance because of the above mentioned selective criteria. This finding is in favour of the possible coaggregation of some species belonging to the intestinal microbiota to form in vivo sessile-growing polimicrobial communities. Multiresistant gram-positive bacteria are a continuing and rising threat in hospitals worldwide. Complex mechanisms enable these pathogens to exchange genetic information, especially the distribution of resistance determinants leads to their propensity to cause hospital outbreaks as well as endemic spread. Here, we report that one of the very factors responsible for genetic exchange, namely a specific protein of the so-called type four secretion systems, represents an Achilles heel that can be harnessed to fight these often untreatable infections. A prototypical gram-positive type four secretion system is present on plasmid pIP501, and several proteins of the transfer region have been expressed in E. coli. Rabbit sera were raised against two proteins, i.e. ORF10 and ORF13, that code for an ATPase and a putative channel component. The rabbit sera were used in an opsonophagocytic assay and sera raised against ORF13 showed 77% killing of the homologous strain at a dilution of 1:10. Using absorption of the sera with increasing amounts of purified protein this killing could be inhibited by up to 44.5%. Testing of a larger collection of strains from different species revealed that 3/4 (75%) E. faecalis, 2/4 (50%) E. faecium, and 5/5 (100%) S. aureus were effectively killed by anti-ORF13 at a dilution of 1:10, including one vancomycin-resistant S. aureus strain and several USA300 CA-MRSA. Western Blot analysis demonstrated crossreactive protein bands in two of three tested E. faecalis-, three of four E. faecium and a total of five S. aureus strains, respectively. The homologous strain E. faecalis JH2-2pIP501 (expressing protein Orf13) shows a band at 37.5 kDa. Using a mouse bacteremia model, significant reductions in colony counts were seen in animals that had received anti-ORF13 as compared to animals that had received antisera against ORF10 and were challenged with the homologous E. faecalis, as well as with an E. faecium and a CA-MRSA strain. Animals infected with the homologous E. faecalis that were not carrying plasmid pIP501 were not protected. These data demonstrate that ORF13 is the target of opsonic and protective antibodies and may therefore be a promising and broadly cross-protective vaccine candidate targeting multi-resistant gram-positive pathogens.\n\nO633 A rat model for Kingella kingae pathogenesis N. Balashova* (Newark, US)\n\nObjectives: Kingella kingae, a Gram negative coccobacillus of the Neisseriaceae family, is a normal inhabitant of the human oropharyngeal flora and an emerging pathogen. The development of new methods for the bacteria isolation and PCR-identification techniques in the 1990s led to the recognition of K. kingae as a leading cause of septic arthritis and osteomyelitis in children younger than 2 years old. The bacterium is also a cardiovascular pathogen causing infective endocarditis. K. kingae produces a potent protein toxin of the RTX-group, RtxA. Methods: Kingella kingae septic arthritis isolate PYKK081 was grown on Columbia agar containing 5% sheep blood and 2 lg/mL vancomycin for 24 hours at 37\u00b0C, a number of bacteria was identified by colony forming units count. Active RtxA was purifed from PYKK081 cytosolic fraction. The toxin-deficient mutant was created using mariner transposon mutagenesis. Three-week old Sprague-Dawley rats were used in animal models. Mammalian cell lines were obtained from ATCC. Results: Kingella kingae toxicity: Cohorts of rats were injected intraperitoneally with different doses (from 1 \u00b7 10^9 to 1 \u00b7 10^6 cells/animal) of PYKK081, 50% lethal dose (LD50) was 1.3 \u00b7 10^8 cells/animal. Septic arthritis model: Right rat knee joints were injected intraarticularly with different doses (from 1 \u00b7 10^5 to 1 \u00b7 10^2 cells) of PYKK081. Left knee joint was injected with saline. Thirty one percent of animals injected with 1 \u00b7 10^5 and 1 \u00b7 10^4 bacterial cells demonstrated features of acute inflammation in the infected joint for first 72 hours. Histopathological examination of the joint and adjacent bones 7 days after infection revealed the signs of chronic inflammation. RtxA: The secreted RtxA (>1 lg/mL) had toxic effect on human, rat, rabbit and mouse white blood cells. When tested at high concentrations (>40 lg/mL), the toxicity of RtxA was also detected on other cell types including human synovial cells and osteoblasts. The toxic effect of the isogenic rtxA mutant on the mammalian cells under the same conditions was not detected. Conclusion: This is the first study toward the development of in vivo model for K. kingae pathogenesis. The bacterium is shown to cause infections in rat offspring. A rat model of knee septic arthritis due to K. kingae is proposed. RtxA primarily affects multiple types of leukocytes suggesting the toxin role in host immune response evasion. RtxA is responsible for the major cytotoxic effect of K. kingae on mammalian cells.\n\nO634 Legionella longbeachae respiratory infection in neutrophil-depleted mice P. Pusic*, F. Wensveen, Z. Trobonjaca, M. Doric, I. Gobin (Rijeka, HR)\n\nObjectives: Neutrophil infiltration is known to play a crucial role in protecting lungs from respiratory pathogens, including Legionella. Legionella longbeachae infections in humans are primarily prevalent in Australia, but there is a global increase in reported cases over the past decades. In comparison to other Legionella, L. longbeachae has an unusually high lethality in mice and causes focal bronchopneumonia, with massive recruitment of inflammatory cells in the lungs. Our goal was to investigate the role of neutrophils in respiratory infection with L. longbeachae. To this extent mice were treated with anti-Gr-1 monoclonal antibody (mAb) before and after infection and survival, bacterial loads, pathology and leukocyte content of the lung was analyzed and compared with untreated animals. Methods: Control C57Bl/6 mice (6-8 weeks old) were inoculated intratracheally with a sublethal dose of 10^3 L. longbeachae NSW150. At various time points after inoculation, mice were sacrificed and leukocytes were isolated from the lungs. Myeloid cells were stained for FACS analysis. Mice were injected either with 25 or 250 ug/dose anti-Gr-1 18 hours before and 24 hours after infection. For the survival assay mice were observed for 14 days post-infection. For enumeration of bacterial load at different time points CFU in lungs and liver was determined. Histological sections of lungs were prepared and stained with hemotoxylin and eosin. Statistical significance was assessed using two-way analysis of variance or a Student's t test in GraphPad Prism software.\n\nResults: The flow cytometry analysis revealed predominance of CD11b^+/Gr-1^+ neutrophils in the first 48 hours post-infection. Anti-Gr-1 mAb treated mice showed increased susceptibility to infection, as well as higher bacterial burdens and more severe histopatologic changes in lungs compared to non-treated infected mice. The observed effects were less severe in low-dose anti-Gr-1 Ab treated mice then in high-dose treated mice. Conclusion: In neutrophil-depleted mice L. longbeachae causes more severe infection and neutrophils play an important role in host resistance against this bacterium. Introduction: Mycobacterium tuberculosis (Mtb) causes approximately 2 million deaths a year. Extensive lung destruction is the hallmark of pulmonary tuberculosis and is caused by breakdown of extracellular matrix by host matrix metalloproteinases (MMPs). Hypoxia upregulates the gene expression and secretion of many inflammatory mediators via hypoxia-inducible factor (HIF), the master regulator of the adaptive response to hypoxia. Tissue hypoxia has been demonstrated in animal models of tuberculosis (Tb) but investigation of hypoxia in human disease has not been performed. Objective: To investigate the hypothesis that hypoxia increases MMP activity in Tb infection in a HIF-1a dependent manner Methods: Human respiratory epithelial cells and primary human monocyte-derived macrophages (MDMs) were either directly infected with Mtb H37RV or stimulated with the Conditioned Media from Tb infected monocytes (CoMTb). Experiments were conducted in real hypoxia (1% or 10% O2 with 5% CO2) or chemical hypoxia using dimethyloxalyl glycine (DMOG). MMP and TIMP concentration were measured by ELISA and Luminex array, gene expression by PCR and promoter activity by dual luciferase assay. Total HIF-1a protein was measured by western blot analysis. Results: Hypoxia increased Mtb-induced MMP-1 secretion 3.5 fold (p < 0.001) and MMP-9 secretion 2.1 fold (p < 0.01) compared with Mtb infected cells in normoxia. Additionally, hypoxia decreased secretion of the specific Tissue Inhibitor of Metalloproteinase (TIMP-1) which inhibit MMPs in a 1:1 manner. In A549 respiratory epithelial cells, 1% O2 upregulated MMP-1 gene expression 95 fold at 6 hours and markedly increased MMP-1 promoter activity (p < 0.001). NF-kB blockade with Helenalin significantly down-regulated MMP-1 secretion in hypoxia (1% O2) in MDMs. In contrast, 10% O2 decreased MMP-1 secretion in by 80.6% in MDMs (p < 0.001) and 50.4% in lung epithelial cells (p < 0.001) compared with normoxia. Western blot analysis from MDMs infected with Mtb in normoxia demonstrated accumulation of HIF-1a, maximal at 24 hours. In respiratory epithelial cells, HIF-1a stabilisation occurred at 6 hours and was via a networking effect rather than direct infection with Mtb. This is the first time that Tbdriven HIF accumulation has been described.\n\nparental strain. The murl1 mutation was found to drastically impair biofilm formation at 48, 72 and 96 hours of incubation. Both murl1 and murl2 mutations affected bacterial attachment to HeLa cells, with no viable counts obtained after eukaryotic cell lysis. SEM showed almost no attachment of murl1 mutant to eukaryotic cells, when compared with the parental strain (see Figure 1 ). Conclusion: L-D Glutamate interconversion is a key process for A. baumannii to form abiotic biofilms and attach to HeLa eukaryotic cells. Thus, the Glutamate racemase murl1 gene could ultimately provide and effective target for controlling biofilms and pathogenicity. Objectives: Mulitidrug resistant efflux pumps can confer low level resistance to a variety of antibiotics, detergents and dyes. Salmonella is known to have nine MDR efflux systems belonging to four families of efflux pumps; resistance-nodulation division (RND) family, multidrug and toxic compound extrusion (MATE) family, ATP binding cassette (ABC) family and major facilitator superfamily (MFS). Here, we show that genetic inactivation of these efflux systems results in an inability to form a competent biofilm. We have used the well characterized AcrAB-TolC system as a model to investigate the hypothesis that inactivation of efflux systems changes the expression of other biofilm related genes.\n\nMethods: A panel of 17 single and double mutants lacking components of the major MDR efflux systems of Salmonella were investigated. Biofilms were quantified using various models and under various conditions, the most useful and high throughput of these is the crystal violet biofilm assay. Various phenotypic assays were used to visualise curli (proteinaceous filaments) and cellulose (polysaccharide) production, important components of a Salmonella biofilm extracellular matrix. Differences in expression of biofilm related genes between wild-type and efflux mutants were determined using qRT-PCR. Results: Sixteen of the 17 efflux mutants formed significantly less biofilm than wild-type in all biofilm assays tested. The reason for this biofilm defect was a lack of curli expressed on their cell surface. qRT-PCR showed that this defect in curli expression was as a result of repression at the transcriptional level. In addition to genetic inactivation of the multidrug resistance efflux pumps, chemical inactivation with efflux pump inhibitors (EPIs) PA beta N, CCCP and chlorpromazine, also inhibits the formation of biofilms in the wild-type strain. Inactivation or inhibition of MDR efflux alters global regulatory pathways which mediate repression of curli.\n\nConclusions: These data suggest that inactivation of acrB or tolC triggers a regulation pathway that ultimately decreases transcription of the curli operons and inhibits the formation of mature biofilms. It also shows that this phenomenon is not specific to AcrAB-TolC or even RND efflux pumps but is a generic effect seen with four different classes of multidrug resistance efflux pump. Objectives: Staphylococcus aureus is a dangerous bacterial pathogen whose virulence is expressed through various forms ranging from pyogenic tissue invasion to systemic toxic shock syndromes. In this latter situation the prototypical superantigen is TSST-1 (Toxic Shock Syndrome Toxin 1), encoded by tst, which is carried on a mobile genetic element and not present in all S. aureus strains. Thus transcriptional regulation of tst is only partially understood. Evidence exists for regulation by the catabolite regulator protein CcpA, the twocomponent SrrAB sensor, the quorum sensing system agr, and the global accessory regulator, SarA. In this study, we have further dissected the role of sarA, sarS (sarH1), RNAIII, with particular emphasis on the alternative stress sigma factor sigmaB.\n\nMethods: Transcriptional analysis of toxin and transcription factors expression levels were performed by qRTPCR and TSST-1 expression analysis by western blot. Classical bacterial genetics procedure such as directed mutagenesis and phage-mediated transduction were used for obtaining mutant S. aureus strains.\n\nResults: By examining tst promoter regulation in the context of its native sequence context within the SaPI1 pathogenicity island of strain RN4282, a strain historically used for the discovery of this toxin, we have discovered that sigmaB and sarA emerge as particularly important modulators. SigmaB strongly represses the expression of the toxin through at least two distinct regulation pathways. Furthermore, sarS, another member of the sarA family, was shown to impart an additional level of negative regulation. Conclusion: Collectively, our results extend our understanding of complex multifactorial regulation of tst, with several layers of negative regulation. These new findings suggest that sporadic mutation in a few key negative regulators can profoundly affect and enhance tst expression.\n\nOld and new strategies targeting health-care associated infections: where do we stand? Objective: To assess the effectiveness of a hand hygiene improvement program (HHIP) in 13 European intensive care units (ICUs); and to quantify the effect of known determinants. Methods: We conducted a 26-month intervention study with the ICU as unit of inference. After a 6 month baseline period (phase 1), a HHIP was implemented for 6 months (intensive HHIP, phase 2), using the WHO ''My 5 Moments for Hand Hygiene'' concept. Observations were performed at random dates, time-intervals and bed spaces. In the last 14 months of the study, focus shifted towards another (non-related) intervention, whilst HHIP continued (continued HHIP, phase 3). Mixed effects logistic regression modelling was performed, with random effects for phase and hospital. Results: 44 764 hand hygiene opportunities were observed in 13 European ICUs. Hand hygiene compliance (HHC) varied widely between ICUs in baseline (range 7-88%; mean 52% (95%CI of peers' high compliance, and ABHR as a cue to memory for HH. Nurses can also be influenced by a message that their peers expect them to comply, while doctors should be reminded that ABHR is always available. Risk factors: 60.3% of new +ves and 51% of negatives were checklist positive for one or more risk-factor. In an average trust, screening only checklist +ve patients would reduce the number of screens from 858-478 a week, and identify 82% of positives. Screening only those in high risk specialties would reduce the number of screens to 94 a week, but identify only 10% of +ves. Conclusions: Uptake of admission screening was low (especially emergency and day-case admissions) as was the yield of MRSA+ve patients. The use of checklist activated screening would reduce the number of MRSA admission screens by 50% but identify 82% of all +ves. Screening high risk specialties only would reduce screens by c90% but identify only 10% of +ves. Health Economic modelling will use this data to determine the most cost effective screening policy.\n\nO645 Comparison of two strategies to reduce health-care associated methicillin-resistant Staphylococcus aureus rates in surgical patients: a multicentre intervention study We aimed to compare the effect of two strategies on healthcareassociated MRSA isolation rates in surgical patients.\n\nMethods: This prospective intervention study was conducted from March 2008 to July 2010 in 33 surgical wards of 10 hospitals in nine countries in Europe and Israel. It consisted of 6 month minimum Baseline, 12 month Intervention and 6 month Washout Phases. There were two interventions: (i) Enhanced standard control (EC) -standard precautions with intensive hand hygiene (HH) promotion; (ii) Rapid Test (RT) -admission MRSA screening with topical decolonisation therapy and contact isolation for patients who tested positive for MRSA. Four hospitals were assigned to each strategy and two hospitals used a combination of both strategies (MIX). Multiple segmented multilevel Poisson regression was used to compare monthly rates of healthcare-associated MRSA isolated from clinical specimens, adjusting for clustering and potential confounders.\n\nResults: There were 135 235 admissions to the surgical wards during the study period. For EC and MIX arms, HH compliance increased from 49 to 64% in the Baseline to Intervention Phases (p < 0.001). In RT hospitals during the Intervention Phase, 75% of patients were screened and MRSA prevalence on admission was 2.1%. In addition, there was an increase in the rate of administration of topical decolonisation therapy (34-70%, p < 0.001) and adherence to contact precautions ( Conclusion: Compared to enhanced standard control measures with HH promotion, MRSA screening was more effective at initially reducing rates of MRSA isolated from clinical specimens. Combining these two strategies resulted in more marked reductions in MRSA rates over time.\n\nO646 Change of a policy of primarily PCR-based MRSA screening to a wider use of culture-screening halved nosocomial MRSA acquisition-even under disestablishment of protective isolation precaution in a high-prevalence region in Germany Objectives: The aim of the study was to detect the prevalence of MRSA on admission and the number of nosocomial MRSA cases (NC) in a tertiary care hospital before and after change of an already traditionally implemented screening and infection control policy (ICP). Methods: During study period 1 (1/2010-12/2010) MRSA screening policy was in accordance to the criteria of the Robert Koch Institute (RKI) and included additionally all intensive care unit (ICU) patients. Screening was performed via PCR (Xpert MRSA, Cepheid) (ICU and preoperatively) or culture (other wards). Patients with unknown MRSA status were isolated in a private room until the screening result was available. In case of surgical intervention MRSA positive patients were set at the end of the program and possible contact surfaces were protected by plastic sheets.\n\nIn 2011 we intensified education of the staff concerning screening indications according to RKI criteria 2008 and a general screening was introduced in all medical wards. For ICU patients the Xpert MRSA PCR was replaced by Light Cycler MRSA Advanced test (Roche). All other patients were screened by culture (CHROMagar MRSA, BD). ICU patients with unknown MRSA status were treated with barrier precautions instead of protective isolation. No protective isolation was done on other wards. Surgical interventions were scheduled independently from the MRSA status and without additional surface protection measures.\n\nThe intervention was fully implemented in 4/2011, so we defined the period from 4/2011 to 9/2011 as study period 2, the first quarter of 2011 being a changeover period. A NC was defined as a MRSA detection after the 3th day of admission.\n\nResults: The MRSA prevalence and incidence density of NC for study period 1 and 2 are shown in figure 1. The median admission prevalence did not change significantly (1 and 1,1). The median incidence density of NC declined from 0.28 to 0.15/1000 patient days. The Xpert MRSA PCR showed false positive results in up to 20% and yielded unnecessarily to an isolation incidence density of 3.37/1000 patient days. The mean number of patients screened increased from 14.3% to 29.7% whilst the number of MRSA PCRs declined slightly.\n\nConclusion: A more targeted and economically more attractive policy comprising the avoidance of protective single room isolation and surface coverage, change of MRSA screening PCR and full implementation of screening according to the RKI led to a significant decrease of nosocomial MRSA cases. Objectives: We aimed to evaluate the cost-benefit of infection control interventions to prevent spread of methicillin-resistant Staphylococcus aureus (MRSA) in hospitals.\n\nMethods: Systematic review of published clinical studies reporting on costs and savings of infection control interventions aimed at preventing spread of MRSA in hospitals. Studies had to report both costs and saving associated with the intervention. We excluded interventions limited to the operating room and studies where costs are determined only for laboratory testing or materials. We searched PubMed, NCI and references using terms relating to cost or economical analyses and MRSA. Data were independently extracted by two authors. We used the Quality of Health Economic Studies (QHES) tool adapted for clinical studies (maximal score 86) for quality assessment. We report the save/ cost ratio (values >1 indicating savings larger than costs) and the savecost difference discounted to 2011 US$ (positive values indicating net saving).\n\nResults: Eight studies published between 1988 and 2009 were included in the current analysis, performed in locations with different baseline MRSA prevalence (Table) . A hospital-wide search and destroy policy was evaluated in four studies. It included screening on admission of patients at risk, isolation, decolonization and follow-up screening, with variable healthcare worker screening, suspension from work, visitor and environmental screening. Another two studies performed less comprehensive hospital-wide interventions. Two studies were limited to specialized setting (orthopedic wards and intensive care unit). The QHES score ranged between 7 and 58. Most studies did not report on the perspective of the cost analysis and did not perform sensitivity analyses, incremental analysis or discounting. Cost components considered included personnel, materials, medications and laboratory. Savings resulted from avoidable bed days, antibiotics and prevented infections. All studies reported that the infection control interventions were economically justified, since the save/cost ratio was >1. The median ratio was 3.61 (range 1.17-13.56). Higher ratios were associated with small hospitals and interventions of short duration. The net global saving discounted to 2011 dollars ranged between 1061 and 101 121.\n\nConclusion: All published studies report a positive save-cost difference for intervention control interventions aimed at prevention and eradication of MRSA in hospitals. Objectives: Recent data showed that the burden of multidrug-resistant microorganism is going to exponentially increase in a few years. Therefore, a significant implementation of isolation procedures in Gram-negative bacilli (GNB). Strategies to improve the timely implementation of appropriate antimicrobial therapy are clinically warranted. TheraDoc \u00d2 is an electronic data capture system that has the ability to send real-time alerts to clinicians via email or electronic page when culture information is updated. The objective of this study was to assess if TheraDoc \u00d2 could be utilized to decrease TTAT and improve outcomes of patients with GNB.\n\nMethods: This was a retrospective case-control study performed at the Detroit Medical Center (DMC). The control group consisted of patients with Gram-negative bacteremia in 2009 prior to implementation of TheraDoc \u00d2 . The case group consisted of patients with GNB from December 2010 through August 2011, after TheraDoc \u00d2 had been implemented. During the case group period, each time blood culture result for GNB was update by the microbiology laboratory, a page was immediately sent to antimicrobial stewardship pharmacists with updated information. Pharmacists then made antimicrobial recommendations to providers based on culture results, institutional guidelines and clinical data.\n\nResults: Thirty eight cases and 108 controls were studied. The groups were well matched for baseline characteristics with the exception of more patients in the case group having COPD (29% vs. 14% p = 0.04), while control patients had higher Pitt bacteremia scores (PBS) (2.0 (IQR 1-3) vs. 1.0 (IQR 0-2). In the majority of patients in both groups, the urine (40%) was the primary source of infection; and the most common GNB pathogen was Eschericia coli (36%). Compared to controls, case patients experienced a significantly shorter delay in receipt of effective therapy, as measured from the time culture was initially positive for GNB to the time of receipt of effective therapy (p = 0.014) (Table) .\n\nCases had a significantly decreased duration of bacteremia (p = 0.02) and shorter duration of hospitalization after bacteremia (p = 0.001).\n\nConclusions: Automated alerts were used to significantly decrease the time to receipt of effective antimicrobial therapy by a mean of 3.6 hours. The improved timeliness of implementation of effective antimicrobial therapy was associated with a decrease in duration of hospitalization of more than 3 days.\n\nO652 Intelligent electronic trigger tool to optimise intravenous to oral antibiotic switch T. Sprong*, H. Pot, T. Dofferhoff, J. Schouten, A. Houterman, M. Nabuurs-Franssen, K. Kramers, A. Voss, H. Huntjens-Fleuren (Nijmegen, NL) Objective: Timely switching from intravenous antibiotics to oral is important to improve patient safety and reduce costs associated with intravenous therapy. For this reason, numerous interventions have been devised, and have shown to improve antibiotic switching. However, these interventions are usually time-consuming and therefore expensive and difficult to implement. We have introduced an intervention that relies on a computerized trigger, which intelligently identifies patients who are candidates for antibiotic switching. This was combined with weekly discussing switch therapy during the microbiology-infectious disease multidisciplinary meeting. With this intervention we aimed to improve the rate of intravenous to oral antibiotic switching. Methods: Intervention was performed on all the internal medicine wards in a large teaching hospital. Daily an automated trigger tool selected patients eligible for switch based on data from the pharmaceutical and patient system. Patients were identified as eligible when parenteral antibiotics were used for 48-72 hours. Patients were ineligible for switch when CRP was rising, neutrophils were <0,5*109/ mL or leukocytes <1*109/mL, inability to receive oral therapy or when an antibiotic was prescribed for which nor oral option was available. Before daily rounds, per candidate for antibiotic switch, a form was generated and given to the resident caring for the patient. Information concerning the ability to switch and reasons which impeded the switch were recorded. Median iv days per iv prescription and number of iv prescriptions \u202172 hours in the intervention period were compared to a similar period the year preceding the intervention. Results: Of 156 forms generated in 603 iv antibiotic prescriptions, 92 (59%) were filled in and returned. In 52% of cases this form led to an iv-oral switch. Median number of IV days was reduced by 1 (3 vs. 2, p < 0.0001). Number of iv prescriptions longer than 72 hours was reduced by 45% (44% vs. 24%). Reasons for not switching antibiotic therapy were inability to receive oral therapy (36%), clinical instability (21%) and stopping antibiotic therapy in 16% of the patients. Conclusions: We designed an intervention which uses an computerized trigger to identify patients who are candidates for antibiotic switch therapy in combination with frequent but short term education of residents. This was effective in promoting antibiotic switch therapy and reducing number of IV days >72 hours. Objective: The outcome in patients with sepsis is better if the initial empirical antimicrobial treatment is adequate, and several studies have shown that adherence to guidelines on antibiotic use positively influences the clinical outcome. However, adequate empiric therapy is not the only relevant determinant of outcome. Quality indicators (QI) are measurable elements which can be used to assess the actual quality of care provided. They can be systematically derived from guidelines. Objective of the present study was to develop a valid set of QI which can accurately measure quality of antimicrobial treatment in hospitalized adults with sepsis. Such QI for sepsis are at present lacking. We derived the QI from the recently published, evidence-based Dutch guideline on antimicrobial treatment of adult patients with sepsis (www.swab.nl/guidelines). Methods: A RAND-modified, five step Delphi procedure was used. A multidisciplinary panel of 13 experts appraised and prioritized all graded recommendations retrieved from the Dutch consensus guideline for antimicrobial therapy on sepsis. The selection of the QI potentially relevant for clinical outcome, antimicrobial resistance and costs was done using two questionnaire mailings with a face-to-face consensus meeting between rounds, over a period of 3 months. Results: Forty recommendations were initially derived from the sepsis guideline. After appraising these recommendations in the first questionnaire, 31 potential QI remained. During the consensus meeting 17 potential QI were merged into four generic QI, leaving 20 potential QI. Prioritizing these by the experts resulted into a final set of five potential QI: take two blood cultures together with cultures from suspected sites of infection, prescribe empirical antibiotic therapy according to the national guideline, start antibiotics intravenously, start antibiotics as soon as possible (preferably within an hour) and streamline antibiotic therapy. Conclusion: With this systematic, stepwise method combining evidence and expert opinion, a new, concise and therefore measurable set of process QI for antimicrobial therapy in sepsis was obtained. These QI can give insight into the actual quality of the given care and could be used to determine for which aspects there is room for improvement. Testing the feasibility, reliability and case-mix sensitivity of these indicators in practice will be the next step before using them in quality improvement projects.\n\nO654 Improving hospital antimicrobial prescribing using quality indicators J. Sneddon, A. Patton, D. Nathwani*, E. Watson on behalf of the Scottish Antimicrobial Prescribing Group\n\nObjective: To use quality indicators for antimicrobial prescribing to support reduction in Clostridium difficile infection (CDI) and improve prescribing practice. Methods: In 2008, the Scottish Antimicrobial Prescribing Group (SAPG) issued national guidance on restriction of antibiotics associated with high risk of CDI within antimicrobial prescribing policies. In 2009 Scottish Government introduced a target for a 50% reduction in CDI by 2011 and SAPG developed and implemented the following quality indicators to support achievement of this target. A. Indication recorded and empirical antibiotic choice compliant with local policy. Target \u202195% compliance. B. Duration of surgical prophylaxis <24 hours and choice compliant with local policy. Target \u202195% compliance. In 2011 the CDI target was revised to use a ''best in class'' approach and the quality indicators were revised to focus on achieving reliable and sustainable improvement. Indicator A required that any deviations from policy were documented. Indicator B focused on using a single dose in elective colorectal surgery.\n\nResults: By March 2011 CDI rates in Scotland had reduced by 77%. For indicator A, in acute admission units median compliance was 93% for indication documented and 83% for compliance with local policy. For indicator B compliance was >90% in a variety of surgical specialties. Following revision of the indicators, in September 2011 for indicator A median compliance was 93% for indication documented and 83% for compliance with local policy and analysis of information on deviation from policy showed common themes. A breakthrough collaborative of clinical teams comprising managers, medical, nursing and pharmacy staff was set up to map the process of prescribing an antibiotic and design tests of change to improve clinical practice. For indicator B, by September 2011 median compliance with antibiotic policy was 100% and median compliance with single dose was 95%. The measures are being integrated within the surgical checklist to achieve sustainability. Conclusion: Prescribing indicators are an effective means of improving antimicrobial prescribing. The combination of measures for scrutiny with improvement methodology can lead to reliable and sustainable improvements in prescribing practice.\n\nO655 ''Different strokes'': A co-relational modelling study of common (community and acute hospital) HCAI reduction targets, variable dynamics and antibiotic prescribing Methods: A multidisciplinary team composed of the antimicrobial pharmacist, the consultant microbiologist and the medical team reviewed all IV antimicrobial prescriptions on scheduled weekly rounds on medical wards. The rationale behind the choice of antimicrobial agent, dose, duration and the need for review of 48 hours IV to oral switch was discussed and recommendations made. The recommendations consisted of eight categories: Stop (inappropriate choice), stop IV course, document stop date, document review date, oral switch, awaiting further investigations, continue (appropriate indication for long duration) and continue (oral route compromised). Results: Over a 5 month period (June to October 2011), 69 patients (107 IV antimicrobial courses) were discussed. Duration of IV ranged from 2-17 days when reviewed. 23% of antimicrobial courses were stopped and 24% had a stop date recommended. 14% of antimicrobial courses were switched to oral antimicrobials and 14% had a review date recommended. For 11% of the courses further investigations were recommended. 14% of courses were deemed to be appropriate and therefore continued. The graph shows detailed results.\n\nOver the period of the study the antimicrobial expenditure steadily declined from \u00a338700 to \u00a324850 demonstrating a saving of \u00a313850.\n\nThe round is an effective initiative in stopping antimicrobial courses (47%) as well as instigating switch to oral (14%) when clinically indicated. The rounds were also effective in highlighting patients that required further microbiology input (11%) which were followed up with appropriate investigations. The rounds also led to a reduction of \u00a313850 in antimicrobial expenditure. However other confounding variables such as clinical activities and seasonal variation may have had an impact and this will be explored in ongoing studies. Feedback from clinical teams has shown this to be a positive educational experience.\n\nO657 Improving the hospital antibiotic use: we can do it! A successful French experience F. Ollivier, J. Caillon, N. Foucher, S. Thibaut, E. Batard, F. Ballereau* (Nantes, FR)\n\nObjectives: Within the framework of the ''National Plan to preserve the effectiveness of antibiotics'', the regional health authorities have commissioned the MedQual Network to conduct a project to improve the good use of antibiotics (AB) in the regional hospitals. Methods: All public and private hospitals practicing medicine, surgery and obstetrics were affected by this regional program. Since 2007, within a regional Antibiotics Commission, actions have been implemented, such as the validation of local protocols for AB treatment or surgical prophylaxis and sharing them on a website, the broadcasting of messages to the appropriate use of AB developed by a working group, the organization of regional trainings, the harmonization of indicators for monitoring AB consumption and bacterial resistance and the proposal of a tool for decision support to guide improvement actions (according to D. Monnet). We performed a cross-sectional study in 2007 and 2010 to assess the evolution of implementation of antibiotic stewardship by collecting the annual indicators of antibiotics consumption and bacterial resistance. Results: Of the 56 regional hospitals, 36 participated in the crosssectional survey (64%). Between 2007 and 2010, the degree of implementation of measures to manage antibiotics has increased: 89% of hospitals have antibiotics advisors (vs. 68% in 2007, p < 0.01), 95% use local protocols for antibiotic therapy and prophylaxis (vs. 70% in 2007, p < 0.001), 58% have antibiotics prescription software (vs. 14%, p < 0.001). For 80.5% of hospitals, the pharmacist dispenses antibiotics with pharmaceutical analysis (vs. 47%, p < 0.001). For monitoring the indicators of AB use and bacterial resistance, the participation of hospitals has increased over the last 3 years (31 in 2007 and 46 in 2010). Among the 26 hospitals who participated in annual data collection, AB consumption decreased by 8% in 3 years, with a significant decrease in the use of fluoroquinolones (37.27 DDD/1000 PD vs. 47.7DDD/1000 PD, p < 0.05).\n\nConclusion: The regional monitoring has created a professional dynamics for the good use of antibiotics. Every year, the participation of regional hospitals in the project increases. After The success of this regional program allows its extension to other categories of hospitals (rehabilitation centers and nursing home) is required in 2012. Objectives: Regular feedback of antibiotic usage data helps promote rational prescribing, reduce inappropriate use, and potentially slow the development and spread of resistance.1,2 Such ''antimicrobial stewardship'' strategies are recommended in the Health and Social Care Act 2008, which English hospitals have to take account of for registration with the Care Quality Commission.3 Our objective was to describe the frequency and types of antibiotic usage data fed back to clinicians in English hospitals. Methods: An electronic audit was e-mailed to the antimicrobial pharmacist of each acute hospital NHS Trust in England (n = 151). The survey software (Adobe Acrobat \u00d2 ) recorded responses, before analysis in Excel \u00d2 . Results: The response rate was 79%. Figure 1 shows reports on antibiotic usage provided to clinical teams, and their frequency. Information on expenditure was more commonly provided (78%) than Daily Defined Doses (DDDs, 70%) or packs/prescriptions (29%). 80% of DDD reports were split into parenteral and oral forms; 53% reported use by speciality, and 43% by outpatient vs. inpatient use. Antibiotic point prevalence studies (PPS) were conducted by 86% of Trusts, but fed back less frequently to clinicians than expenditure or to the LUMC where PCR ribotyping was performed. Web-based questionnaires were used to collect clinical and epidemiological data. Results: In total, 1052 patients were included in the survey and 926 (88%) isolates were obtained. The mean incidence was 15 per 10 000 hospital admissions. Type 001 was the most frequently found type (20%), followed by type 014 (13%), 078 (12%) and 002 (6%). Type 027 was found in 3%. Twelve outbreaks were observed, mainly associated with type 001. Of 694 patients clinical information was available. Half of them were female, the mean age was 67 years. 177 patients (26.6%) were defined as community-onset CDI. Most patients (70.5%) used antibiotics prior to the start of diarrhoea. A total of 129 patients (20.2%) had severe CDI. After 30 days, 68 patients with CDI (12.8%) died; two deaths were attributable to CDI and 16 deaths were contributable to CDI. Half of these patients had CDI due to type 001. Other types involved in attributable or contributable death were type 014, 005, 228, 045. Conclusion: We conclude that the incidence of CDI is stable in the Netherlands and that types 001 and 014 are still predominant types. The incidence rate of C. difficile PCR ribotype 027 remains low as previously reported. Extrapolating the data of sentinel surveillance to all hospitals in The Netherlands, it is estimated that more than 2700 hospitalized patients annually will develop CDI of which 100 will succumb attributable or contributable to CDI. Incidence per 10000 bed-days (excluding repeat positives within 14 days) was calculated over calendar time for EIA-positive culture-positive CDI and for the 10 most common strains, and compared across strains using stacked negative binomial regression with natural cubic splines to reflect nonlinear calendar trends. Results: Over the study period, incidence of EIA-positive culturepositive CDI declined from 9.4 per 10000 bed-days in Q4 2007-2.9 in Q1 2011 (per-annum decline (incidence rate ratio) 22%, 95% CI 18-27%). Of 943 EIA-positive culture-positive CDI in OUH inpatients, the 10 most common sequence types (STs) were 179 (19%) ST1 (PCR-ribotype 027), 81 (9%) ST2 (ribotypes 014/020), 81 (9%) ST8 (ribotype 002), 60 (6%) ST6 (ribotype 005), 50 (5%) ST3 (ribotypes 001/072), 44 (5%) ST44 (ribotype 015), 40 (4%) ST5 (ribotype 023), 36 (4%) ST42 (ribotype 106), 34 (4%) ST10 (also ribotype 015) and 27 (3%) ST11 (ribotype 078) (311 (33%) other less common STs). In Q4 2007, ST1 and ST42 accounted for 36 (36%) and 8 (8%) of the 98 CDI -but neither ST was observed in 16 CDI in Q1 2011, and they accounted for only 11 (8%) and 2 (2%) of the 133 CDI during 2010, per-annum declines of 65% (95% CI 58-71%) and 64% (95% CI 48-75%) respectively over the study period. Other STs apart from ST11 also declined over the study period, but at a significantly slower rate than ST1 and ST42 (12% pa (95% CI 3-18%): p < 0.0001 vs. ST1/ ST42). In contrast, there was marginal evidence that ST11 was not declining in the same way as other common STs, but instead increasing, with an estimated annual increase in incidence of 32% (95% CI 10% decrease to 95% increase; p = 0.045 vs. other STs, p < 0.0001 vs. ST1/ST42), although to an absolute level which still remained relatively low. Conclusion: Declines in CDI in Oxfordshire inpatients were driven by declines in ST1 and ST42 suggesting that these may have been particularly susceptible to hospital-based interventions. ST11 (PCRribotype 078) may be increasing in Oxfordshire.\n\nO663 Did an intervention to reduce Clostridium difficile infection have any unintended consequences on 30-day mortality?\n\nP. Davey*, A. Patton, J. Sneddon, D. Nathwani, C. Marwick on behalf of the Scottish Antimicrobial Prescribing Group\n\nBackground: In 2008, the Scottish Antimicrobial Prescribing Group issued national guidance on the restriction of antibiotics associated with higher risk of Clostridium difficile infection. This study aimed to determine if the implementation of this guidance in local antibiotic prescribing policies had any unintended consequences on 30-day mortality (from admission) in one NHS board in Scotland.\n\nMethods: A quasi experimental study design with interrupted time series analysis using segmented regression was used. Data were obtained from October 2006 to December 2009 and split into a preintervention and post-intervention period by the introduction of a restricted antibiotic policy in October 2008. Monthly data on antibiotic use, CDI incidence and mortality were used and adjusted for clinical activity using hospital admissions data. Results: Analysis was performed on patients admitted through the acute medical admissions unit (medicine) and patients admitted to any of six surgical wards (surgical). There were no changes in crude 30-day all cause mortality for patients in medicine and surgery. Subgroup analysis by Age and Charlson Comorbidity Index (CCI) score revealed no changes following the intervention. A separate study at the same hospital showed that patients that had a blood culture taken were four times more likely to die within 30 days of admissions than those that did not and that most of the increased risk of death was attributable to sepsis. To ensure that an increase in deaths from sepsis was not masked by a decrease in deaths from other causes, 30-day mortality was analysed in patients that had blood cultures taken. Statistical analysis confirmed no significant abrupt or sustained change after the intervention in medicine or surgery and the direction of all changes was negative demonstrating a reduction in mortality post intervention. In the medicine cohort the change in slope was a reduction by 3 deaths per 1000 patients per month, p = 0.19 (95%CI -4.5 to +1.5). Subgroup analysis by Age and CCI score did not show any evidence of increase in mortality.\n\nThe study provides reassurance that introducing an antibiotic policy restricting the use of broad-spectrum antibiotics does not have any unintended consequences on 30-day mortality for patients with sepsis. individuals with ribotype 078 were admitted from a care home. Over the 2 year period, the emergence of ribotype 027 was identified in one community and one acute setting. The rate of CDI among inpatients aged 65 years and over has decreased significantly since 2009 (p < 0.001; Figure 1 ).\n\nConclusion: NI has a unique CDI profile, with ribotype 078 dominating during the last 2 years. The CDRN ribotype service has contributed to a significant reduction in CDI, primarily through the early and rapid detection of possible outbreaks in the acute and community setting. By ribotyping all C. difficile positive isolates this programme avoids any selection bias. To the best of our knowledge this extensive ribotype programme does not exist elsewhere. Further studies to examine the morbidity and mortality associated with ribotype 078 are planned.\n\nO665 Emerging outbreaks of Clostridium difficile in regional long-term care facilities Objectives: Since 2005 multiple outbreaks of Clostridium difficile infections (CDI) have been reported in the Netherlands. These outbreaks occurred mainly in hospitals and were caused by PCR ribotype 027 and 001. Since October 2009, an increase of residents of long term care facilities (LTCF) diagnosed with CDI was noticed. A retrospective survey was performed to estimate the incidence and outcome of CDI in LTCF.\n\nMethods: A regional laboratory, responsible for diagnostics of 14 LTCF and one general hospital with 670 beds, participated in the survey. Between June 2008 and April 2011, all requests for Clostridium difficile diagnostics by LTCF were reviewed. Diagnostics included both a rapid toxin test (Immunocard, Toxins A and B, Meridian) and selective cultures of C. difficile. A case with CDI was defined as a diarrhoeal patient with a positive tested stool sample (either a positive toxin test or a toxin producing C. difficile detected in culture). Patient records were used to determine the outcome of CDI within a period of 3 months after the episode. Isolates from positive stool samples were sent to the reference laboratory of the Leiden University Medical Centre for PCR ribotyping and further characterization. Multiple-locus variable-number tandem-repeat analysis (MLVA) was applied to study the genetical relatedness.\n\nResults: Between June 2008 and April 2011, 444 stool samples from LTCF residents were tested for CDI. Sixty-one (24.8%) residents out of nine LTCF were positive for CDI. The overall mortality assessed for 53 residents was 17% within 3 months after the CDI episode. Of 30 available C. difficile isolates, 8 different PCR ribotypes were found with type 027 as the predominant type (63.3%), followed by type 002 (6.7%) and type 078 (6.7%). Type 027 was mainly found in 3 of 9 LTCF with an outbreak in the adjacent hospital. MLVA applied on 13 isolates from LTCF and the hospital revealed clonal spread of one specific type. The CDI incidence in the hospital during the study period was 1.42 per 1000 admissions, with type 027 as the predominant type (62.5%). Conclusion: Clonal spread of C. difficile PCR ribotype 027 was found in three regional LTCF and its neighbouring hospital. A prospective surveillance has been initiated and intervention strategies are being developed.\n\nO666 Impact of the type diagnostic method on Clostridium difficile infection rates in a single institution participating in a mandatory reporting programme Background: Mandatory reporting of institutional Clostridium difficile infection (CDI) incidence rates is becoming increasingly common in numerous jurisdictions. However, the type of laboratory method used to diagnose CDI on stool samples is usually left at the discretion of each participating institution.\n\nObjective: To examine prospectively the difference in CDI incidence rates obtained by two standard laboratory methods. Methods: We conducted a prospective cohort study of all patients admitted at IUCPQ for which a C. difficile diagnostic assay was ordered between August 1st, 2010 and July 31st, 2011. All submitted specimens were tested in parallel by commercial PCR targeting toxin B tcdB gene, and by a two-tiers algorithm based on EIA detection of glutamate deshydrogenase (GDH) and toxins A and B (ToxA/B), followed by cell culture cytotoxicity assay (CCNA) in case of positive GDH but negative ToxA/B EIA. Healthcare-associated CDI incidence rates were compared, and incidence rate ratios were calculated using univariate Poisson regression. Results: Overall, 1321 stool samples (from 888 patients) were tested in parallel during the study period representing 95 750 patient-days of surveillance. A total of 224 specimens (17.0%) were positive by PCR, and 162 (12.3%) were positive by EIA/CCNA (absolute difference, 62 cases; p < 0.001 by chi-square test). Furthermore, 158 cases were positive by both PCR and EIA/CCNA algorithm, 66 cases were positive by PCR but negative by EIA/CCNA, and four cases were negative by PCR but positive by EIA/CCNA. The overall incidence rate was 8.9 per 10 000 patient-days (95% CI, 7.1-10.9) by PCR, and 5.8 per 10 000 patient-days (95% CI, 4.4-7.4) by EIA/CCNA. Among the 13 administrative periods of the study, incidence rates were above the government-imposed target of 9.0 cases per 10 000 patient-days for 7 periods (54%) using PCR, and 4 periods (31%) using EIA/CCNA. The incidence rate ratio comparing PCR and EIA/CCNA was 1.52 (95% CI, 1.08-2.13; p = 0.015). There was a wide variation in the magnitude of discordance between the two diagnostic methods depending on the administrative period, from 0 to 6.7 cases per 10 000 patient-days. Conclusion: Performing PCR instead of EIA/CCNA is associated with a more than 50% increase in CDI incidence density. In the context of mandatory and public reporting of CDI rates, rates should be stratified according to the diagnostic method to improve intra-and inter-hospital comparison.\n\nO667 Investigation of potential Clostridium difficile outbreaks within a week using rapid desktop whole genome sequencing Objective: To demonstrate whether newly available rapid desktop whole genome sequencing (WGS) can investigate potential Clostridium difficile infection (CDI) outbreaks within clinically relevant time scales. Methods: During Sep-Oct 2011, two clusters of CDI cases were identified in our hospital group in Oxfordshire. Three CDI cases occurred over 3 days on a long-stay medical ward, and three over 22 days in an elective surgery unit. DNA from cultured isolates and the last preceding CDI isolate from each location (12 days and 6 months earlier respectively) was sequenced, four isolates at a time, using the Illumina MiSeq platform in runs lasting 27 hours. Paired 150 base pair reads were mapped to the CD630 reference genome with STAMPY. Variant calls were made using SAMTOOLS, PICARD and Python scripts. Velvet de novo assemblies were used to determine 'in-silico' multi-locus sequence types (MLST) to provide a traditional genotyping comparison to WGS. Results: All eight isolates were successfully sequenced (mean 78.1% of the reference genome called after filtering). Total sample preparation, sequencing and analysis time from receipt of the last positive culture was <1 week. All four medical patients shared time and space on the same ward after diagnosis of the 1st case. Sequence data revealed >4000 single nucleotide variants (SNVs) between each of the three cases occurring within 3 days excluding the possibility of transmission. However one of the isolates was genetically identical (0 SNVs) to the case from 12 days before, highlighting the likely importance of this case in transmission which had not been considered by the initial infection control investigation. While similar conclusions would have been drawn using MLST, the exact genetic match between the two related cases would not have been known. In contrast, within the surgical unit where all three clustered cases spent time together, MLST data suggested two of the three cases were potentially related, however these two cases were actually 129 SNVs apart refuting the possibility of transmission between them. Intriguingly one of the surgical cases differed by only 7 SNVs from a medical case despite neither patient having been to the same hospital in the last year and the cases living 30 miles apart. Conclusion: Comparing whole genomic sequences distinguishes related from unrelated isolates in a potential CDI outbreak setting. The rapid turnaround of desktop sequencing demonstrates the prospect of using this approach in focused outbreak investigation.\n\nO668 Clostridium difficile whole genome sequences from patients in Leeds and Oxfordshire demonstrate substantial geographical segregation of clinical strains"}