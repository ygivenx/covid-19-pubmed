{"title": "", "body": "Public health surveillance (also called field epidemiology) as defined by Centres for Disease Control and Prevention (CDC) is the ongoing systematic, collection, analysis and interpretation of outcome-specific data essential to the planning, implementation and evaluation of public health practises closely integrated with the timely dissemination of these data to those who need to know (1) . The IDSR is a strategy of the WHO Afro region adopted by the member states in 1998 as a regional strategy for strengthening weak national surveillance systems in the African region (2, 3) . The DSNOs under the supervision of the Medical Officers of Health (MOHs) are responsible for surveillance activities within their Local Government catchment area. Therefore, their role is very crucial to the success of the IDSR strategy.\n\nThe study was conducted in Lagos State, South Western Nigeria, in June 2011. A quassi experimental, before and after study was done. Participants were DSNOs and assistant DSNOs of the 20 Local Governments in Lagos State. Training materials were received from the Lagos State Ministry of Health,World Health Organisation (WHO) and the Central Public Health Laboratory, Lagos. Pre-and posttests were conducted using questions developed for the purpose. Participants scores were categorised as fail (B50%) and pass (50% and above). The impact of the training was assessed by statistical evaluation of the pre-and posttests results.\n\nParticipants were 25 DSNOs and assistant DSNOs including 11 (44%) males and 14 (56%) females. Their mean age was 39.7 years (SD, 7.8 years) with ages ranging from 25 to 57 years.\n\nThey had been employed for an average of 3.6 years (SD, 2.4 years). Most (88%) of the participants were married. Only about a third has had relevant working experience prior to this job. The mean pretest score was 34.0% (SD, 2.1), which increased to 56.3% (SD, 2.3) at posttest. The mean paired difference in score between post-and pretest of 22.3% (SD, 10.4) was statistically significant p 00.000. There was also a statistically significant difference between the proportion of participants who passed the posttest but failed the pretest [16 (69.6%)] and the proportion who passed the pretest but failed the posttest [0 (0%)]; p 00.000. The mean score of male participants was higher at the pretest (35.6% vs. 32.0%) while the females performed better at the posttest (57.3% vs. 55.6%), although this difference was not statistically significant. The ages of participants and the number of years of employment were also not statistically associated with their performance in the pre-and posttests. \n\nIn the last decade, the scope of public health (PH) surveillance has grown, and biosurveillance capacity has expanded in Duval County. In 2004, the Duval County Health Department (DCHD) implemented a standalone syndromic surveillance (SS) system, which required the manual classification and entry of emergency department (ED) chief complaints by hospital staff. At that time, this system, in conjunction with other external systems (e.g., CDC ILInet, FluStar and NRDM) were used to conduct surveillance for health events. Recommendations from a 2007 ISDS panel were used to strengthen surveillance within Duval County. Later that year, the Florida DOH moved to a statewide SS system and implemented ESSENCE, which has been expanded to include (1) ED record data from 176 hospitals (8 within Duval County); (2) reportable disease case records from Merlin; (3) Florida Poison Information Network consultations; and, (4) Florida Office of Vital Statistics death records (1) . ESSENCE has subsequently become a platform for rapid data analysis, mapping and visualization across several data sources (1) . As a result, ESSENCE has improved business processes within DCHD well beyond the initial scope of event detection. These improvements have included (1) expansion of the ability to create visualizations (e.g., epi-curves, charts and maps); (2) reduction in the time required to produce reports (e.g., newsletters and media responses); (3) reduction in staff training needs; and (4) augmentation of epidemiology processes (e.g., active case finding, emergency response and quality improvement [QI] ) and closing the PH surveillance loop.\n\nTo quantify the impact of ESSENCE on PH activities, an evaluation of epidemiology business processes pre-and post-ESSENCE was conducted. Staff time, computer programs/ systems utilized and computational steps were compared for tasks within three quantifiable areas: visualization creation, report production and activities during PH responses. Visualizations included production of a map, chart, table and epidemic curve for the same data. Report production tested the ability to create nontextual documents with multiple graphics. Conducting ad hoc ED surveillance was compared between ESSENCE and e-mail/telephone methods. QI reviews were compared between ESSENCE and Merlin Analysis Tools. The number of software or systems requiring training, which were replaced by ESSENCE, was reviewed. Computational steps included page clicks, exporting/importing data between systems and data management. Testing was conducted by a single reviewer proficient in current systems performing the task a single time to completion. Time and computational steps were measured from the initiation of a task to the completion of a usable product and then averaged across the three quantifiable areas.\n\nESSENCE created visualizations on average 89% faster than previous methods, requiring 43% fewer computational steps. For the production of reports ESSENCE was 86% faster, requiring only 4.55 minutes compared to 27.83. For tasks relating to PH responses, initiating ad hoc ED surveillance was 96% faster through ESSENCE without comparing resource savings during follow-up monitoring. However, conducting QI reviews was faster using previous systems with modules designed for such tasks. ESSENCE also reduced the need for staff training, as one system was used for most tasks instead of five (Excel, ArcGIS, Access, SAS/SPSS and Merlin).\n\nUsing ESSENCE had advantages compared to previous methods that extended beyond basic processes. The analytic and computational abilities of the system are more advanced, more accessible and more user friendly than those of previous systems. The ability to save and share queries and visualization dashboards as well as the added efficiency of navigation reduce redundancy and improve user functionality. Ultimately, the user experience is enhanced, and resources are optimized. In the future, ESSENCE will continue to expand available data sources as well as increase analytical capacity based on user feedback and identified system needs.\n\nBiosurveillance; syndromic; epidemiology; business processes Reference 1. Kite-Powell A, Hamilton J, Wojcik R, Loschen W, Hopkins R. Florida's ESSENCE system*from syndromic surveillance to routine epidemiologic analysis across syndromic and nonsyndromic data sources. Emerg Health Threats J 2011;4(Suppl 1).\n\n*Taj Azarian E-mail: tajazari@gmail.com\n\nThe Public Health*Seattle & King County (PHSKC) syndromic surveillance system has been collecting emergency department (ED) data since 1999. These data include hospital name, age, sex, zip code, chief complaint, diagnoses (when available), disposition and a patient and visit key. Data are collected for 19 of 20 King County EDs, for visits that occurred the previous day. Over time, various problems with data quality have been encountered, including data drop-offs, missing data elements, incorrect values of fields, duplication of data, data delays and unexpected changes in files received from hospitals. In spite of close monitoring of the data as part of our routine syndromic surveillance activities, there have occasionally been delays in identifying these problems. Since the validity of syndromic surveillance is dependent on data quality, we sought to develop a visualization to help monitor data quality over time, in order to improve the timeliness of addressing data quality problems.\n\nMethods SAS version 9.2 (Carey, NC) was used to create two groups of visualizations: (1) a separate heatmap for each hospital, showing how each individual ED performs on each of 13 data quality measures and (2) a separate heatmap for each data quality measure, showing how data quality varies by ED. The heatmaps summarize data by month and year, though other visualizations (e.g., daily or weekly) are also possible. For each row on the heatmap, a color change indicates that data quality has shifted over time. Blocks with stable color over time suggests that there has not been a change in data quality. White space on the heatmap highlights periods of time where data were not recorded by the system and can provide a visual cue for newly added EDs, hospital closures or data drop-offs. The heatmaps are generated monthly for each of 13 data quality measures. SAS code for generating the heatmaps will be provided at the session.\n\nTwo heatmaps are provided as examples of our visualization approach (see Fig. 1 ). Since applying this visualization to our syndromic data, PHSKC has identified several data quality errors that are likely to have gone undetected or been slow to detect otherwise, including out of range ages and sudden data drop-offs. Consequently, we have adopted the methodology to other nonsyndromic data sources, including notifiable condition reporting to the health department.\n\nSyndromic surveillance systems commonly encounter problems with data quality. These problems can result in imprecise counts and can adversely affect detection of trends, outbreaks and situational awareness. The heatmap visualizations have been a useful tool for PHSKC to identify problems with data quality in a timely manner. The code can be easily adapted to display other data quality measures, stratifications and data sources beyond the ED setting. \n\nThe Washington Comprehensive Hospital Abstract Reporting System (CHARS) has collected discharge data from billing systems for every inpatient admitted to every hospital in the state since 1987 (1) . The purpose of the system is to provide data for making informed decisions on health care. The system collects age, sex, zip code and billed charges of the patient, as well as hospital names and discharge diagnoses and procedure codes. The data have potential value for monitoring the severity of outbreaks such as influenza but not for prospective surveillance: Reporting to CHARS is manual, not real-time, and there is roughly a 9-month lag in release of information by the state. In 2005, Public Health*Seattle & King County (PHSKC) requested that hospitals report pneumonia and influenza admissions (based on both admission and discharge codes) directly to the PHSKC biosurveillance system; data elements included hospital name, date/time of admission, age, sex, home zip code, chief complaint, disposition and diagnoses. In 2008, reporting was revised to collect separate admission and discharge diagnoses, whether the patient was intubated or was in the ICU and a patient/visit key. Hospitals transmit data daily for visits that occurred up to 1 month earlier.\n\nPreviously, we identified a strong concordance between the volume of influenza diagnoses recorded across the PHSKC and CHARS systems over time (2) . However, discrepancies were observed, particularly when stratified by hospital. We undertook an evaluation to identify the causes of these discrepancies.\n\nWe included patients with a diagnosis of influenza (ICD9 codes 487.0, 487.1, 487.8, 488.0 or a textual variant of 'influenza', excluding 'H. influenza'). We also focused on 2008 data exclusively, since at the time of the analysis, more recent CHARS data were unavailable. Of the 20 hospitals in King County, 10 provided admissions data in 2008, but data from only 9 hospitals were available in CHARS for comparison. For each of the 180 influenza hospitalizations identified by the PHSKC system, we manually attempted to find a matching record in CHARS according to hospital name, discharge month/ year, age, sex and zip code. We flagged all influenza admissions in the PHSKC system that did not have a matching record in CHARS. Next, we asked hospitals with unmatched records to reverse-identify patients and retrieve their medical charts for PHSKC review.\n\nIn 2008, the PHSKC system (which searches through admission and discharge diagnoses) identified 180 patients hospitalized with influenza, compared with 161 patients identified by CHARS (which is based on discharge diagnoses exclusively). Thus far, PHSKC has reviewed 46 charts from 8 hospitals to validate system accuracy; review of data from the remaining hospital is pending. We identified 3 hospitals that were transmitting incorrect data to PHSKC and requested correction and resubmission of historical data from these hospitals. Preliminary analysis revealed that 35 of the 180 influenza hospitalizations captured by the PHSKC system (19%) were missed by CHARS; however, 15 of these patients (43%) were admitted with presumptive diagnoses of influenza but were determined not to have influenza by the time of discharge. Also, 28 of 161 influenza hospitalizations (17%) captured by CHARS were missed by the PHSKC system; however, we had no means of reverse-identifying CHARS records and, therefore, could not evaluate the validity of these data by chart review.\n\nThis evaluation identified several problems with data quality, which were substantial though not universal across hospitals. We plan to continue the analysis using 2009 data, to ensure that data quality issues have been resolved. A key limitation of this analysis is that CHARS is an imperfect gold standard for identifying King County influenza admissions; we could not independently identify admissions based on laboratory data to determine which system performed better.\n\nWith the proliferation of social networks, the web has become a warehouse of patient discussions and reports, estimated at 10 billion records and growing at a rate of 40 percent per year. First Life Research, Ltd. (FLR), has searched and mapped thousands of these discussions and indexed hundreds of millions of reports (currently 960M) and is engaged in building web-based solutions that enable the public and public health practitioners to access massive health-related information and knowledge generated from the crowd.\n\nFLR's competency is the ability to identify, analyze, index and aggregate user-generated content by collecting billions of testimonials from social networks. It utilizes cutting edge technologies for massive data aggregation and applies advanced natural language processing (NLP) techniques for continuous analyses, in order to convert this unstructured data into refined information. The insights gained can be used to support and enable better informed decision making processes, both for patients and healthcare providers.\n\nA platform of data investigations utilizing the 'Wisdom of the Crowd' focusing on biosurveillances aspects as follows:\n\n1.\n\nPharmacovigilance\u00c1brand monitoring and safety alerts: Crowd trial provides a dashboard of parameters on medications, their side effect profile, interactions and drug's comparative advantage. 2. Social Health at a glance:\n\nTemporal overview of prevalence and statistics of the most engaging health issue discussed across the social web, represented by aggregation of the reports (citations) generated by the e-patients (Table 1 ). 3. Health trends detected by harnessing the social web:\n\nThis public feedback exists in real-time, large scale and enables ongoing observational studies by tapping into the health reports involving a massive sample size (Fig. 1) .\n\nThe value of crowd trial to public health is new and complementary to what the existing monitoring processes provide. Moreover, user-generated content contains valuable feedback on medication usage and health information.\n\nThus the emerging wisdom of the crowd analytics potentially represents a new phase and eventually new tools using data evaluation based on large scale population inputs, and it will benefit greatly all public health environment. Introduction People usually celebrate holidays by inviting family and friends to have food at home or by gathering and eating at restaurants or in other public venues. This increased exposure to food with a common source can create conditions for outbreaks of gastrointestinal illnesses. Holidays can also be targeted by bioterrorists who seek to maximize physical damage, psychological impact and publicity around dates of patriotic or religious significance. They might aim at contaminating food and water supplies, especially with CDC-defined category B agents that can cause diseases such as salmonellosis, shigellosis, cholera, crytosporidiosisand infections with Escherichia coli O157:H7 and the Epsilon toxin of Clostridium perfringens. Hence, there is a need to quantify whether gastrointestinal illnesses increase around holidays. This can also help determine a baseline of the incidence to which future holiday periods should be compared to. This research does not focus on specific reportable diseases. That will be the purpose of forthcoming research. Instead, ED visits with gastrointestinal symptoms are used to leverage the capability of syndromic surveillance for early detection.\n\nA query with the string\u02c6vomit\u02c6, or,\u02c6diarrhea\u02c6, or,\u02c6gastroenter-itis\u02c6(VDG) was performed in the Electronic Surveillance System for Early Notification of Community-based Epidemics (ES-SENCE) during a 7-day period surrounding the 10 Federal Holidays of each year of the quadrennial 2007\u00c12010. The count of ED patients during the 7-day period was compared to the count of a 28-day background by calculating a ratio between the 2 periods for both, the 4-year average and year-specific. The analysis was broken down by age groups (0\u00c14, 5\u00c117, 18\u00c164, 65 and plus and all-age). Database analysis was conducted using SAS 9.2.\n\nPresident's Day and Labor Day were associated with the highest 4-year average increases (12% each). Decreases in the 4-year average only occurred around two of the holidays, Independence Day ((7%) and Memorial Day ( (5%). Age groups 0\u00c14 and 5\u00c1 17 had their largest 4-year average spikes around Labor Day (' 24% among 0\u00c14 and '30% among 5\u00c117), right after the beginning of classes as well as around President's Day (12% and 13%). The 18\u00c164 age group had its largest 4-year average increases during Christmas (19%) and Thanksgivings Days (15%). As for the 65' age group, Christmas (15%) and President's Day (14%) showed the largest increases. The span was much wider when analyzing year-specific holidays, from ' 40% after Martin Luther King Day in 2010 to (17% after Independence Day on the same year. Factors other than holidays could have also influenced the increases in ED visitors, such as the beginning of classes in August of each year and the H1N1 influenza epidemic in 2009. This research hinges on the comparison of the holiday period to a 28-day background. Future tracking of VDG should also be based on comparing the current holiday period to its mean of previous years to control for seasonal or day-specific effects. The availability of only 4 years of data prevented us from removing the seasonal effect in this research.\n\nESSENCE can help to track the incidence of gastrointestinal symptoms in the community during holiday periods. The incidence of reportable gastrointestinal diseases during holiday periods should also be ascertained in a future research.\n\nSyndromic; surveillance; holidays; gastrointestinal; illness \n\nINDICATOR is a multistream open source platform for biosurveillance and outbreak detection, currently focused on Champaign County in Illinois. It has been in production since 2008 and is currently receiving data from emergency department (ED), patient advisory nurse (PAN), outpatient convenient care clinic (CC), school absenteeism, animal control and weather sources. (Table 1) .\n\nWe performed simple pairwise correlation between signals using the longest period of mutual data availability, e.g., between convenient care data and patient advisory nurse data, we compared the period between April 2007 and August 2011. We also offset signals by up to 14 days in each direction to investigate whether there were lag relationships between them.\n\nILI surveillance source: Analysis of the relationships between the signals for PAN, ED and CC are heavily influenced by a strong day of the week effect in the PAN data. Considering all of the data, including periods of high and low ILI activity, the correlation between ED and PAN shows a stronger relationship when the ED signal lags the PAN by 1 day (r 00.653 vs. r 0 0.617). There is a less clear relationship between ED and CC with the strongest correlation occurring when CC lags ED by 2 days (r 00.669 vs. r 00.659). The relationship between CC and PAN is unclear. These relationships are also all valid when just considering the period of the 2009 H1N1 pandemic, but interestingly not the last strong seasonal influenza in 2008. For the 2008 season, for which we do not have ED data, the signal for CC clearly lags the signal for PAN with a peak correlation at a lag of 6 days (r00.561 vs. r00.413). ILI and climate: There are significant negative correlations between all three signals and daily temperature, e.g., CC and Tmin (r0(0.265, df 02004, p B 0.0001), but not precipitation, e.g., CC (r 0(0.011) when considering all data. There are no clear relationships between temperature or precipitation and CC or PAN during the 2008 seasonal outbreak, but there is a clear negative correlation between temperature and CC, PAN and ED during the 2009 H1N1 pandemic, e.g., ED and Tmin (r0(0.366, df 0 119, pB 0.001). There was no clear correlation with precipitation.\n\nZoonotic reports: There are some very strong correlations between the signals, such as the correlation between daily minimum temperature and patients seeking treatment for insect bites (r 00.602, df0821, pB0.0001), with a less strong correlation between precipitation and insect bites peaking with a bite lag of 24 days (r00.163, pB0.0001). Not as expected is the correlation between animal bites and Tmin (r 00.178, pB0.001).\n\nThere are clear indications of temporal relationships between different surveillance signals, with PAN consistently giving a 1-day lead over ED for ILI. The strong relationship between temperature and ILI cases during the 2009 H1N1 pandemic is most likely coincidental since the onset in Champaign County coincided with the change of season in September/October. The lack of a relationship between ILI and weather during the 2008 seasonal outbreak remains to be understood.\n\nILI; zoonoses; correlation; multistream; weather Introduction Syndromic surveillance of ED and PCC data has been widely used for the detection, tracking and monitoring of health events (e.g., bioterrorism, disease outbreaks and environmental exposures) over the past decade (1) . In recent years, these data have been found to be useful for public health programs not normally associated with syndromic surveillance (e.g., injury prevention, drug abuse and environmental health (1)). In 2010, the first calls referencing exposure to products marketed as 'legal highs' and 'bath salts' were received by PCCs in the United States (2) . Synthetic drugs, such as those commonly known as bath salts, often are labeled as 'not for human consumption' and, thereby, circumvent normal legal control procedures that control the sale and distribution of recreational drugs (3) . The purpose of this study was to evaluate the emerging trends for the use of bath salts in Ohio.\n\nSyndromic surveillance data from ED chief complaints were collected and analyzed from Ohio's syndromic surveillance application, EpiCenter for 2010\u00c12011. Because the term bath salts refers to a grouping of drugs, and the effects of ingestion or inhalation of these drugs can vary widely, a specific classifier was created to define ED visits related to bath salts. This classifier included many variations of the common street names for bath salts. Human exposure calls to the PCCs in Ohio related to use of bath salts were also collected and analyzed from the National Poison Data System (NPDS) during the same time period. These data were combined and a correlation analysis was performed, using SAS v 9.2 to evaluate the relationship between the two data types and to illustrate the trends in designer drug use for bath salts. Due to small daily counts of both ED visits and PCC exposure calls, the data were totaled by month for all time-series and correlation analyses.\n\nIn 2010, there were very small numbers (nB5) of both ED visits and PCC calls for bath salts. In 2011, ED visits and PCC calls related to bath salts increased dramatically. ED visits for bath salts totaled 166 and PCC calls totaled 480 through July 2011. A time-series chart of these data, analyzed by month, as shown in figure 1 . Pearson correlation analysis showed a strong relationship between ED visits and PCC calls for bath salts (r 00.83, p 00.02).\n\nThese results suggest an emerging, upward trend in the use of bath salts in Ohio beginning in early 2011. Syndromic surveillance provides a useful and inexpensive way to track trends in designer drug use. In order to identify these types of trends, knowledge of the subject matter and common name of the substance being tracked is essential. Although this type of analysis significantly underestimates the number of people using drugs, it can be used to identify the arrival and pace of adoption of a new drug. This information can be used by prevention programs and lawmakers to reduce the likelihood of widespread adoption. In mid-July 2011, Ohio passed legislation banning the sale of products containing the chemicals found in bath salts. The law took effect on October 15, 2011. The Ohio Department of Health will continue to monitor ED and PCC data for the next designer drug.\n\nSyndromic surveillance; designer drugs; 'bath salts' \n\nWith an estimated 500 million people infected each year, dengue ranks as one of the most significant mosquito-borne viral human diseases and one of the most rapidly emerging vectorborne diseases (1) . A variety of obstacles including bureaucracy and lack of resources have interfered with timely detection and reporting of dengue cases in many endemic countries (2) . Surveillance efforts have turned to modern data sources, such as Internet search queries, which have been shown to be effective for monitoring influenza-like illnesses (3, 4) . However, few have evaluated the utility of web search query data for other diseases, especially those of high morbidity and mortality or where a vaccine may not exist.\n\nBolivia, Brazil, India, Indonesia and Singapore were chosen for analysis based on data availability and adequate search volume. For each country, a univariate linear model was built by fitting a time series of the fraction of Google search query volume for specific dengue-related queries from that country against a 'gold standard' time series of dengue case counts for a time-frame within 2003\u00c12010. The specific combination of queries used was chosen to maximize model fit. Spurious spikes in the data were also removed prior to model fitting. The final models, fit using a training subset of the data, were cross-validated against both the overall dataset and a holdout subset of the data. All search queries were fully anonymized. This methodology is similar to the approach used to develop Google flu trends (3) .\n\nDengue generated over a million Google search queries every month. Some queries showed that the user was looking for more information about the disease, while others were looking for symptoms or treatments. Model-fitted 'expected' epidemic curves matched official case counts 'observed' epidemic curves quite well for all 5 countries in most countries (Fig. 1) , with validation correlations ranging from 0.82 to 0.99. Dengue queries were not as influenced by mass panic-induced searching.\n\nWeb search query data were found to be capable of tracking dengue activity in Bolivia, Brazil, India, Indonesia and Singapore. Whereas traditional dengue data from official sources are often not available until after some substantial delay, web search query data are available in near real-time and could serve as a useful low-cost complement to traditional surveillance. Even if peaks are no earlier, there is value in 'nowcasting'*predicting the present where there are delays in gaining access to current official data (5) . More broadly, these results also contribute to a growing pool of evidence demonstrating the capability of relatively novel sources such as webbased data to assist with public health goals. The product of this work is freely available at www.google.org/denguetrends. \n\nDengue fever is endemic in over 100 countries and there are an estimated 50\u00c1100 million cases annually (1) . There is no vaccine for dengue fever yet, and the mortality rate of the severe form of the disease, dengue hemorrhagic fever, ranges from 10-20% but may be greater than 40% if dengue shock occurs (2) . A predictive method for dengue fever would forecast when and where an outbreak will occur before its emergence. This is a challenging task, and truly predictive models for emerging infectious diseases are still in their infancy.\n\nPredictive disease modeling attempts to exploit the complicated relationship between disease outbreaks and measurable environmental, biological, ecological and sociopolitical variables. Previous studies (3\u00c15) identified factors associated with dengue outbreaks such as: past cases, ambient temperature, precipitation, Normalized Difference Vegetation Index, Enhanced Vegetation Index, Southern Oscillation Index, sea surface temperature anomalies and socioeconomic factors. We obtained and preprocessed these variables to get one value per district per week. The epidemiological dengue fever case data used span 2001\u00c12009 and cover several districts in Loreto, Peru. We computed incidence rate per 1000 residents, enabling us to deal with significantly different population sizes in the different districts. The method predicts incidence rates 4 weeks in advance. We developed logistic regression (LR) models using part of the data set available. The second part, not previously used for model development, was used for testing. The ROC curve and positive predictive value (PPV) for the test set are shown in Fig. 1 . High specificity is easier to obtain than high sensitivity. The preliminary results are encouraging: when sensitivity is 0.375, we obtain a specificity of 0.987 and a PPV of 0.6.\n\nEffective methodologies to predict outbreaks of dengue fever may facilitate public health interventions to mitigate the impact of the disease. For best results, the researchers must have access to data streams with timely, detailed and accurate values of predictor variables. High PPV is of principal importance as health officials may be unlikely to spend resources on mitigation efforts based on model predictions without evidence of accuracy on past outbreaks.\n\nDengue; disease prediction; logistic regression \n\nBlock 3 of the U.S. Military ESSENCE system affords routine access to multiple sources of data. These include administrative clinical encounter records in the Comprehensive Ambulatory Patient Encounter Record (CAPER), records of filled prescription orders in the Pharmacy Data Transaction Service (PDTS), developed at the DoD Pharmacoeconomic Center, Laboratory test orders and results in HL7 format and others. CAPER records include a free-text Reason for Visit field, analogous to chief complaint text in civilian records, and entered by screening personnel rather than the treating healthcare provider. Other CAPER data fields are related to case severity. DoD ESSENCE treats the multiple, recently available data sources separately, requiring users to integrate algorithm results from the various evidence types themselves. This project used a Bayesian network (BN) approach to create an ESSENCE module for analytic integration, combining medical expertise with analysis of 4 years of data using documented outbreaks.\n\nThe strategy was to emulate a domain expert's use of ESSENCE by means of a BN whose inputs were outputs of alerting algorithms (1) applied to data streams chosen for specificity to acute illness in outpatient encounters, laboratory tests and prescribed medications in the chosen syndromes. Efforts were restricted to 5 syndrome groups seen as amenable to fusion of the ESSENCE sources: influenza-like illness, gastrointestinal, fever, rash and neurological.\n\nMajor subtasks included modifying the ESSENCE chief complaint processor (2) for CAPER syndrome classification, selection and judicious use of fields in chemistry and microbiology test data, selection of generic code number (GCN) groups of prescribed medications, development and implementation of an algorithm testbed for the various streams to be fused and elicitation of domain expertise to design BNs for practical decision support.\n\nInitial findings from fusion using severity concepts in CAPER data yielded sharp alerting reduction from pure algorithmic methods, with a timeliness loss of 1 day in 2 known outbreaks, no days in 4 others. The alert reduction was dramatic in datasets from small facilities, typically reducing the alert rate from 20 per year to below 5. In larger facilities, the reduction was less dramatic but often over 50%. Time series chosen from the laboratory test and GCN groupings were tested using additional known outbreaks. Results of fusing all algorithmic output streams will be presented.\n\nThe VA has employed ESSENCE for health monitoring since 2006 (1) . Epidemiologists at the Office of Public Health (OPH) monitor the VA population at the national level. The system is also intended for facility-level monitoring to cover 152 medical centers, nearly 800 community-based outpatient clinics (CBOC), and other facilities serving all 50 states, the District of Columbia and U.S. territories. For the entire set of facilities and current syndrome groupings, investigation of the full set of algorithmic alerts is impractical for the group of monitors using ESSENCE. Signals of interest may be masked by the nationwide alert burden. Customized querying features have been added to ESSENCE, but standardization and IP training are required to assure appropriate use.\n\nWe derived and refined default alerting filters relevant to the monitor's purview, beginning with three jurisdictional levels: (1) facility; (2) facility group or station, including all clinics and divisions associated with a parent VA medical center; and (3) superuser, referring to routine system-wide monitors. The filters were based on the number of patients, statistical significance of alerts and a composite severity measure. This measure was derived from case-based criteria developed for the Department of Defense ESSENCE (2) and adapted by OPH epidemiologists for the VA population. These criteria are based on separate monitoring of evaluation\\management codes for complex cases, OPH-selected procedure codes, 'bounce-backs' to an emergency setting, patient age distributions anomalous for a VA facility and extreme spikes; case disposition was not yet available. We tested candidate filters by tabulating alert rates and sensitivity to known outbreaks using 13 months of all-VA historical outpatient data. For the superuser, the filter required at least one severity factor among records composing an alert, at least 3 cases (5 for the common syndromes) and only p-values B 0.01. These restrictions were reduced in localized user filters.\n\nThe full set of unfiltered ESSENCE alerts at levels of high and moderate significance, applied for 8 syndrome groupings to all medical centers, CBOCs and other facilities sending outpatient and emergency department data, was on average 410 per day (539 per week day). Table 1 illustrates the sharp drop in alerting using filters developed to present only sets of records selected for investigation at each level. Additional results will show the sensitivity of the resultant hierarchical system to documented outbreaks at the various levels.\n\nHierarchical filtering can furnish practical, canonical alert criteria applied to algorithm alerts. As circumstances change, users may reconfigure for increased sensitivity or altered coverage with ESSENCE customization tools. The planned addition of new data elements (laboratory/micro, pharmacy and radiology) will further refine alerting. These refinements can increase detection/response capability by focusing attention on signals of interest with a reasonable alert burden. Novel approach to statewide biosurveillance using emergency medical services (EMS) information\n\nThe purpose of the National Collaborative for Bio-preparedness (NCB-P) is to enhance biosurveillance and situational awareness to better inform decision-making using a statewide approach. EMS represents a unique potential data source because it intersects with patients at the point of insult or injury, thus providing information on the timing and location of care. North Carolina uses a standardized EMS data collection system, the Prehospital Medical Information System (PreMIS), to collect information on EMS encounters across the state using the National EMS Information System (NEMSIS) template (1) . Since NEMSIS is planned to be incorporated by EMS agencies in every state, an EMS-based approach to biosurveillance is extensible nationally.\n\nCarolina from 2009 to 2010 were utilized in the project. Based upon a previous analysis of emergency department (ED) presentations, an interdisciplinary team (EMS, emergency department, epidemiology and public health) then developed an approach to assign EMS records to 1 of the 20 symptom-based illness categories (gastrointestinal illness, respiratory, etc). EMS encounter records were characterized into these illness categories using a novel text analytic program (SAS Institute, Cary, NC). Baseline patterns of EMS encounters were developed for each illness category across the state, local regions (3-digit zip code) over time. Event alerts were identified across the state and by regions in illness categories using either change detection with cumulative sum (CUSUM) analysis (3 standard deviations) or a novel text-proportion (TAP) analysis approach (SAS Institute).\n\nyear period were analyzed. The initial analysis focused upon gastrointestinal illness given the potential relationship of gastrointestinal distress to infectious outbreaks, food contamination and intentional poisonings (ricin). After accounting for seasonality, a significant gastrointestinal event was detected in February 2010 (see red circle on graph in Fig. 1 ). This event coincided with the announcement of a norovirus outbreak (2) . The use of CUSUM approach (yellow circle on graph) detected the alert event as early as January 24, 2010. Using the novel TAP approach on a regional basis detected the alert as early as December 6, 2009 .\n\nAdvantages of EMS data include being an early point of contact with patients and providing information on the location of insult or injury. Surveillance based on EMS information system data can detect outbreaks of illness of interest to public health.\n\nA novel text proportion technique shows promise as a useful early event detection method.\n\nBiosurveillance; analytics; detection; emergency; preparedness References (2) . College-aged drinkers tend to binge drink at a higher frequency than the general population, putting them at greater risk for unintentional injuries and unsafe sex practices (3) . Identifying collegespecific patterns for alcohol-associated morbidity have important policy implications to reduce excessive drinking and associated harms on and around college campuses.\n\nAn ''alcohol'' syndrome was developed based on alcohol-related chief complaint keywords sensitive and specific to acute or chronic alcohol ED visits, and validated by an ICD-9 field. The data were aggregated by day from 2008 to 2010, by age and age group. These data were analyzed using general linear modeling (PROC GENMOD), a time trend analysis, and a temporal SaTScan using age groups. Potential time periods of interest were major holidays, days of week, and college start and end periods.\n\nAlcohol-related ED visits for college-age patients have increased since 2003. When analyzed with respect to holidays and days of week, college-age specific trends begin to emerge: college-aged ED visits differ from the general population by day of week (Fig. 1) . Additionally, college age groups can be distinguished from other ages on certain days of the year. Most notably, early summer and early fall show these age-specific increases, and this age group drives some holiday spikes, such as New Year's Day/ Eve.\n\nFurther analyses need to be performed to refine a college drinker age group from syndromic data, as well as potentially identify this population spatially, such as in college-dense areas.\n\nIn addition, a larger collaboration with the DiSTRIBuTE network as an extrapolation of this work (4). This would ideally help to improve the definition of an alcohol syndrome and expand the identification of these problem drinkers in other jurisdictions. \n\nThe spatial scan statistic proposed by Kulldorff (2) has been widely used in spatial disease surveillance and other spatial cluster detection applications. In one of its versions, such scan statistic was developed for inhomogeneous Poisson process. However, the underlying Poisson process may not be suitable to properly model the data. Particularly, for diseases with very low prevalence, the number of cases may be very low and zero excess may cause bias in the inferences. Lambert (3) introduced the zero-inflated Poisson (ZIP) regression model to account for excess zeros in counts of manufacturing defects. The use of such model has been applied to innumerous situations. Count data, like contingency tables, often contain cells having zero counts. If a given cell has a positive probability associated to it, a zero count is called a sampling zero. However, a zero for a cell in which it is theoretically impossible to have observations is called structural zero.\n\nWe assume that the case-counts in the regions follow independent ZIP random variables with the same probability p of a structural zero. The ZIP model allows for additional flexibility when compared to the Poisson. When structural zeros occur, the ZIP model accounts, in average, for a reduction in the casecounts. The ZIP model allows for superdispersion or extra-Poisson variation, while the Poisson model often understimates the observed dispersion. Regarding the likelihood ratio test formulation for the ZIP model we describe our Scan-ZIP statistic considering (a) we know when a zero count is a structural one and (b) we do not know, for sure, whether or not a zero count is a structural one. For the latter case, the Scan-ZIP statistic is obtained through an EM procedure.\n\nOur methodology was evaluated by means of a numerical case study. We constructed artificial clusters using a map consisting of 203 hexagonal cells arranged in a regular grid, 15 of which are structural zeros. An example can be seen in Fig. 1 . Gray regions indicate the ''true'' cluster while the )'s indicate structural zeros. We compare the Poisson, ZIP and ZIP'EM scans in terms of power, sensitivity and positive predictive value (PPV). The Scan-ZIP and Scan-ZIP'EM methods presented systematically and significantly better results when compared to the Scan-Poisson, as shown in Table 1 for the given cluster of Fig. 1 . More examples and a real data application will also be presented.\n\nThe Scan-ZIP statistic has shown to be more suitable for the detection and inference of spatial clusters for data with zero excess as it outperforms the Scan-Poisson statistic in terms of power of detection, sensitivity and PPV.\n\nSpatial clusters; spatial scan statistic; zero-inflated Poisson (1). However, this system may not represent the true epidemic situation of infectious disease in community, particularly those who do not seek medical care (2) . Moreover, the epidemiological settings, sources of the infection and social network all together may still facilitate the transmissions. These rooted problems cannot be rapidly solved.\n\nWe present our web-based technical framework designed with social network theory. Using cloud computing technology, user only needs internet to access our system and webpage, and database was built by Joomla Framework, HTML, CSS, PHP and MySQL. National Health Insurance Database (NHID), which has over 98% Taiwan citizen coverage rate in 2009, and National Notifiable Reporting System (NNRS) were used to evaluate our system; data of syndrome groups by ICD-9CM codes from these two systems during 2009, with pandemic influenza, were first analyzed.\n\nDaily symptoms can report into database, with time-spatial information. Statistic methods (e.g., CUSUM) were built in server (Fig. 1) . The real-time data, with cloud-computing, can be calculated online. Also the system can gain a better feedback and sharing timely information among decision makers, health workers and citizens. User-interface (UI) of system, including main home page with Map-API, reporting entrance and latest news, was user-friendly.\n\nUsing the 2009 pandemic influenza, results of evaluation are shown (Fig. 2) . Except the pattern of 'ILI' (Fig. 2C ), other curves, using our easily understood definitions, show similar increase trend in week 34 with the gold standard (NNRS) ( Fig. 2A) , the first outbreak signal NNRS had detected. With CUSUM, case numbers did increase in week 34\u00c135 and fell out thresholds in week 35\u00c138, except 'Fever'Cough'.\n\nIn conclusion, easily defined syndrome groups for public surveillance is feasible and can complement with traditional passive surveillance systems. More potential case can be detected earlier, particularly those who do not seek medical care. Certainly, this newly developed and user-friendly surveillance system can be applied to study transmission of infectious disease within socialnetwork and also to allow public's participating surveillance leading to public health efforts in disease prevention will be no longer limited to healthcare system and thus become more effective. \n\nMost outbreaks are small and localized in nature, although it is larger outbreaks that result in the most public attention. So, a solution to manage an outbreak has to be able to accommodate a response to small outbreaks in a single jurisdiction scalable up to outbreaks that involve thousands of cases across multiple jurisdictions and to handle different types of situations with different questions and response required. To make this happen, information and resources need to be shared more consistently and efficiently to help facilitate the communication that occurs at all levels and to support day-to-day operations in order to ensure consistent use.\n\nDuring the period from early 2008 through mid-2009, representatives from many of the operational public health groups across the state worked together to identify the requirements necessary to support the improvement of outbreak management in New York. These requirements were prioritized by the project team and the highest level requirements were approved to begin the design and development of the Outbreak Management System (OMS). The system included the following features: creating a central outbreak incident to record incident level information, generating a unique identifier that can be shared across integrated applications to facilitate aggregated query and reporting capabilities with a common data set shared across the jurisdictions and program areas involved in an outbreak investigation and providing forms that are customizable for an outbreak but use standard sets of questions and a common vocabulary where possible. The OMS user guide and training were provided to those who will be using it to manage outbreak incidents.\n\nA project charter including project mission, proposed solution, guiding principles, project scope, critical risk factors, communication plan and project team was approved in 2008. Regular project team meetings were conducted, and functional requirements and software specification documents were completed in 2009. A diagram of data flow is shown in Fig. 1. An incident screen with create, update and search utilities was designed and completed in May 2011. The incident screen collects incident, disease-and event/facility-specific data, case definition and coordinator/investigator information. Web services were applied to create basic reports (Fig. 2) , including case counts by case status, county, age group and a de-identified line list extracting from the Communicable Disease Electronic Surveillance System (CDESS). User acceptance testing was completed in July and webinar trainings to all users were completed in September 2011. The content and structure of food and waterborne outbreak investigation forms have been developed. The prototype of user interface for entering forms currently is under development.\n\nThe Outbreak Management Solution consists of a combination of systems development, training and technical communications enhancements. The OMS will increase ability to provide timely and consistent information to the public and healthcare practitioners, to improve ability to coordinate response activities. The system will be able to answer general inquiries and generate reports and to calculate performance measures. \n\nAlthough development of computerized medical record systems in the United States is a high priority, there are relatively few instances of such systems supporting disease surveillance systems. The Indian Health Service (IHS) has had an electronic record database for over 30 years; however, implementation of point of care electronic health records (EHR) and use of these data for public health surveillance have begun only over the past 4 years.\n\nThe IHS health database is distributed across the United States with most data maintained at 465 local care facilities. Among these 465 facilities, there are over 235 EHR deployments, using similar but separately maintained configurations of the IHS EHR. Data are entered into the EHR system as part of daily clinical care or transcribed from paper for results of clinical referrals or outside tests. We developed a surveillance system that identifies reportable cases, notifies providers and provides data to a dedicated national surveillance database. Cases are found using a locally deployed extension to the local data system that searches for a combination of ICD-9 codes, clinical data and laboratory data, based on Council of State and Territorial Epidemiologists (CSTE) case definitions, on a nightly basis. Reports for situational awareness and response are made locally, regionally and nationally using an a priori established priority ranking of the public health importance of a case or outbreak.\n\nPandemic influenza (pH1N1) was the first health condition targeted for surveillance in 2009. Through an iterative process, a combination of ICD-9 codes and measured fever at the time of visit yielded the highest sensitivity and specificity using the case definition for influenza-like illness (ILI) found in the Centers for Disease Control and Prevention's (CDC) ILInet surveillance system. Formal evaluation of ILI surveillance using review of local medical records (electronic and paper) in one region of the country found that the system had a sensitivity of 96.4% and specificity of 97.8%. IHS is expanding EHR surveillance to capture cases of chlamydia, syphilis, HIV, invasive pneumococcal disease, measles, Haemophilus influenza type b (Hib), meningococcal disease, hepatitis B, hepatitis C and tuberculosis.\n\nPyConTextKit is a web-based platform that extracts entities from clinical text and provides relevant metadata*for example, whether the entity is negated or hypothetical*using simple lexical clues occurring in the window of text surrounding the entity. The system provides a flexible framework for clinical text mining, which in turn expedites the development of new resources and simplifies the resulting analysis process. PyCon-TextKit is an extension of an existing Python implementation of the ConText algorithm (1), which has been used successfully to identify patients with an acute pulmonary embolism and to identify patients with findings consistent with seven syndromes (2) . Public health practitioners are beginning to have access to clinical symptoms, findings and diagnoses from the EMR. Making use of these data is difficult, because much of it is in the form of free text. Natural language processing techniques can be leveraged to make sense of this text, but such techniques often require technical expertise. PyConTextKit provides a web-based interface that makes it easier for the user to perform concept identification for surveillance.\n\nPyConTextKit's annotation lexicon can be derived from existing lexicons or ontologies and then used to extract concepts relevant to a particular domain or syndrome. In this case, the symptoms from the Syndromic Surveillance Ontology (3) and the Extended Syndromic Surveillance Ontology (ESSO) (4) have been imported into PyConTextKit. Users can create their own text classifier by porting concepts from ESSO and by adding new concepts. Concepts are ultimately mapped to standardized vocabularies like the Unified Medical Language System. PyConTextKit currently supports the following six features: view of documents to be annotated,management of a lexicon, document annotation using the lexicon,view of annotation results, document classification based on the annotations and summary statistics generation.\n\nPyConTextKit allows the user to manage a lexicon for extraction targets, such as symptoms. It also allows the user to manage a lexicon for modifiers, such as negation cues (e.g., 'no' and 'absence of') and temporality cues (e.g., 'history of'). The modifiers are applied to the targets by pyConTextKit during the annotation phase, and the user can determine the criteria for extraction of a target from a report based on the modifiers. For example, the user may only want to extract symptoms that occurred recently and not historically. The document classification feature identifies documents containing the targets and modifiers specified by the user. For instance, the user may want to identify documents with recent and nonnegated instances of respiratory symptoms and diagnoses.\n\nFinally, PyConTextKit also enables the user to view summary statistics such as the number of documents in the dataset meeting the specified criteria. If the application were run on a dataset involving patients from a particular population, for example, the user could view the number of patients meeting the criteria in that population.\n\nPyConTextKit is aimed at a clinical audience attempting to apply NLP to clinical reports. The strength of PyConText-Kit lies in its flexibility in incorporating new knowledge, its hopefully intuitive interface and the sophistication of its document-level analysis. \n\nInfluenza is a serious disease that seasonality causes substantial but varying morbidity and mortality. In Taiwan, estimates of the influenza mortality burden were based on post-hocanalyses of national mortality statistics and not available until at least six months after the corresponding epidemic. Timely monitoring and early detection of influenza-associated excess mortality can guide antiviral or vaccine interventions and help healthcare capacity planning. Beginning April 2009, Taiwan Centers for Disease Control (TCDC) has been collaborating with the Department of Health (DOH) Office of Statistics to develop an automated system for real-time P&I mortality surveillance (1).\n\nTaiwan's Mortality Information Regulations require medical institutions to report any mortality to DOH through the National Death Certificate System (NDCS) within 7 days after a death certification is issued. Automated data from the NDCS were daily submitted to TCDC by secure electronic transmission and processed and analyzed using SAS Enterprise Guide 4.3 (SAS Institute Inc, Cary, NC). For each report, the underlying cause of death was determined by applying the World Health Organization classification principles (2) and searched for freetext traditional Chinese 'pneumonia', 'influenza', or 'flu' to identify P&I deaths. Reporting timeliness and completeness of this surveillance system was assessed by comparing reporting data with post-hoc mortality statistics for the year of 2008. We used an R-package 'surveillance' to detect aberrations in the P&I mortality weekly data (3) .\n\nIn 2008, the number of deaths for which P&I was listed as the underlying cause in the national mortality statistics was 8,665; of these, 6,795 (78%) were reported through the NDCS. The weekly surveillance-based P&I mortality estimates had a consistently strong correlation with those obtained from mortality statistics data (correlation coefficient 0.85, p B0.0001). Eighty seven percent of the reports were received within 7 days after death (median 2 days). During the 2010\u00c111 influenza season, an increase in mortality was observed in January 2011, with the highest weekly number of P&I deaths to be 421 (week 5 of 2011) (Fig. 1) . From 2010 through 2011, consecutive alarms were generated for week 26\u00c127, 31\u00c132 and 36\u00c139 of 2010, and week 2\u00c115 of 2011 ( Fig. 1) .\n\nTaiwan has established an early warning system for P&I mortality to assist with characterization of influenza severity. \n\nPrevious studies in developed countries showed school absenteeism data can serve as a proxy for monitoring infectious disease activities and facilitate early community outbreak detection. However, absenteeism patterns may differ in developing settings and affect the utility of the surveillance system. Despite the nonspecific nature of absenteeism data, other practical challenges will need to overcome for system set up and maintenance in remote area.\n\nWeekly electronic school attendance reports were received from the participating schools by short message service (SMS) or direct communication by phone to the central office of The Cambodian Children's Advocacy Foundation, Cambodia, a local nongovernmental organization for initial data processing. Absenteeism data were anonymized. Overall absenteeism data were weekly aggregated and sent to Hong Kong, via email for further analysis.\n\nImplementation of the electronic surveillance system was feasible after initial staff training, purchasing necessary equipments for communication and standardizing data formats. The protocol for data sending, receiving and analyzing were stable. Data transfer procedures were simple and acceptable according to the school and CCAF staff's feedback. Data quality was monitored by occasional onsite school visits by the investigators.\n\nA total of 430 students (47.4% female) from 17 preschools have absenteeism data recorded since November 27, 2010. From March 1, 2011 onward, a total of 1437 students (47.6% female) from 47 preschools (including 30 public preschools) have absenteeism data recorded. The mean weekly overall absenteeism rate from November 27, 2010, to July 12, 2011, was 23.2% (maximum 32.4%, minimum 13.6%, standard deviation 4.5%), whereas the mean weekly absenteeism rate due to sickness was 2.3% (maximum 4.0%, minimum 0.7%, standard deviation 1.0%). We are currently seeking reference disease surveillance data to evaluate the accuracy of this system and negotiating with the village chiefs to set up disease surveillance data dissemination points for risk communication with the villagers.\n\nWhile school absenteeism data are preexisting, easily accessible and require minimum time and resource for data collection and database maintenance after initial development, it can potentially serve as a convenient syndromic data source for disease surveillance targeting school age children in the population. The system will be particularly useful in resource limited settings where health care and laboratory capacity are insufficient for disease surveillance purposes.\n\nSchool absenteeism; rural area; disease surveillance; electronic data; short message service \n\nA devastating cholera outbreak began in Haiti in 2010. Sequencing of Vibrio cholerae isolates showed that the epidemic was likely the result of the introduction of cholera from a distant geographic source. The same strain of cholera was detected in other countries within 100 days. The unique instigation and geographic spread of this epidemic highlight the need for improvements in timely global outbreak surveillance. Novel information sources have been shown to provide early information about public health events and disease epidemiology. Particularly, volume of Internet metrics such as web searches or microblogs have been shown to be a good corollary for public health events (1) . In this study, we evaluate geographic trends in online social media following an infectious disease outbreak to determine whether this may enable prediction of secondary outbreak locations.\n\nWe examined Twitter postings from the first 100 days of the Haitian cholera outbreak. Twitter is a microblogging service in which users can give information in 140 character length posts, 'Tweets'. We selected Tweets containing the word 'cholera' including those with the Twitter hashtag identifier ('#cholera'). Our search captured English, French and Spanish mentions of the word cholera. We define an outbreak as cholera incidence beyond an isolated case. Six countries in which cholera did or was suspected to have spread, and without endemic cholera, were examined: Canada, Dominican Republic, Mexico, Spain, USA and Venezuela. We first collected 'Twitter Updates' for each country, Tweets that came from users in a particular country, normalized by the number of Twitter users in the country. Second, we filtered Tweets in which the keyword cholera as well as a country's name was mentioned, 'Twitter Mentions'. Logistic models were constructed to analyze the relationship between volume of updates and mentions and the occurrence of a secondary cholera outbreak in the chosen countries. We evaluated our models through the Hosmer-Lemeshow (HL) test and also by cross-validation with data from Puerto Rico, in which there was concern of a potential outbreak.\n\nGlobal Tweets regarding a disease outbreak include concern from family or friends, local happenings and reiteration of news reports. Fig. 1 illustrates example Tweets and distribution of Twitter Updates in this study. The HL test yielded p-values of \u00c2 1 and 0.185 (updates and mentions models). Large p-values indicate that the null hypothesis cannot be rejected and the model fits the expected distribution of values well, in this case, better for the updates model. Both models output a low probability (mentions: 0.04, updates: 6e-11) of an outbreak in Puerto Rico within 100 days, and there was no actual outbreak.\n\nGlobal discussion of disease outbreaks may indicate where an outbreak will spread. This is the first study to examine how these discussions, via social media, can be used to understand and predict geographic spread of disease. Both the models demonstrated good fit to expected distributions through the HL test and correctly predicted no outbreak in Puerto Rico. We are working on incorporating data from more countries into the model, as well as other covariates such as environmental factors that would contribute to a country's tendency toward an outbreak. Although the global microblogging community is currently limited in demographics, penetrat\\ion of consumer technology is increasing worldwide and could be a useful complementary tool for timely and cost-effective disease outbreak surveillance. \n\nFor the 2010\u00c12011 influenza season, Spokane Regional Health District required hospitals to report any admissions with laboratory-confirmed influenza using traditional NC surveillance methods. Simultaneously, HIE records from four Spokane facilities were monitored for flu diagnoses (i.e., records with ICD9 487\u00c1488 listed in the working or final diagnoses) and positive flu laboratory test results (including rapid antigen, DFA, culture or PCR). Records from the NC system and the HIE were matched using facility name, age, gender, county and admission date. The medical records of cases detected by the HIE but not reported through the NC system were evaluated to determine true case status. Sensitivity and PPV were calculated for each surveillance system. Timeliness, completeness and representativeness of records received through the HIE were evaluated against NC reporting.\n\nOne hundred forty-six true laboratory-confirmed influenza cases were identified (Fig. 1 ). By including records with a flu diagnosis or a positive flu lab result (excluding records with a negative flu lab), the sensitivity of the HIE was 90% and the PPV was 94%. In comparison, the sensitivity of NC reporting was 91%. HIE cases were detected a median of 5 days after admission versus 2 days through the NC system. Data for influenza hospitalizations from the HIE did not differ signifi-cantly from data collected through the NC system with regard to sex, age, pregnancy status and mortality. The time series of influenza-related hospital admissions from the HIE and NC system were highly correlated (r 00.99).\n\nHIE data are a useful resource for influenza hospitalization surveillance. They are sensitive, specific and representative of the true population of laboratory-confirmed influenza patients admitted to the hospital. It also provided data that were adequately timely and complete. Microbiology laboratory data improved the sensitivity and PPV of the Public Health Surveillance HIE feed to levels near that of NC reporting when used in combination with discharge diagnoses. Thus, for influenza, this enhanced syndromic data feed is comparable to traditional clinical surveillance.\n\nHealth information exchange; influenza; surveillance (3), a resource developed by a working group of 18 researchers representing 10 syndromic surveillance systems in North America. ESSO encodes almost three times as many clinical concepts as the Syndromic Surveillance Ontology and incorporates eight syndrome categories, in contrast to the Syndromic Surveillance Ontology's four (influenza-like illness, constitutional, respiratory and gastrointestinal). The new clinical concepts and syndrome groupings in ESSO were developed by a board-certified infectious disease physician (author JD) in conjunction with an informaticist (author MC). In order to evaluate and audit these new syndrome definitions, we initiated a survey of syndromic surveillance practitioners.\n\nWe designed an online survey that presented respondents with all the clinical concepts associated with each syndrome definition, and the question 'To what extent do you agree that the following concepts are potentially indicative of SYNDROME?' For each clinical concept, the respondent then indicated their agreement from 'Strongly disagree' to 'Strongly agree'. We publicized our survey through the ISDS Newsletter.\n\nAs September 5, 2011, 24 people have participated in the survey, with 14 completing all the questions. Although providing personal information was optional, half the respondents supplied biographical details. Most of the respondents were based in North America, typically from state or county public health departments, although three were based outside North America (one from Taiwan and two from the UK NHS). Apart from one assistant professor, all the respondents had either 'public health', 'epidemiologist' or 'syndromic surveillance' in their job titles. Strong disagreement was expressed by a minority of respondents on 7 of the 279 ESSO concepts (see Table 1 ). Only 2 concepts*'hoarseness' (respiratory syndrome) and 'concussion' (neurological syndrome)*elicited disagreement (or strong disagreement) with ESSO syndrome definitions among a majority of respondents. We are currently developing a strategy to 'flag' concepts with high levels of disagreement in order to better inform ESSO users.\n\nOntology; terminology; informatics \n\nThe ability to rapidly detect any substantial change in disease incidence is of critical importance to facilitate timely public health response and, consequently, to reduce undue morbidity and mortality. Unlike testing methods (1, 2), modeling for spatiotemporal disease surveillance is relatively recent, and this is a very active area of statistical research (3) . Models describing the behavior of diseases in space and time allow covariate effects to be estimated and provide better insight into etiology, spread, prediction and control. Most spatiotemporal models have been developed for retrospective analyses of complete data sets (4). However, data in public health registries accumulate over time and sequential analyses of all the data collected so far is a key concept to early detection of disease outbreaks. When the analysis of spatially aggregated data on multiple diseases is of interest, the use of multivariate models accounting for correlations across both diseases and locations may provide a better description of the data and enhance the comprehension of disease dynamics.\n\nWhen small area disease data in the form of counts are available, Bayesian hierarchical Poisson models are commonly used to describe the behavior of disease (5) . In this study, we use the convolution model (6) to describe the behavior of disease under endemic conditions. Each time new observations become available, we show how the conditional predictive ordinate (CPO, 7), which is a Bayesian diagnostic tool that detects unusual observations, can be adapted in a surveillance context to detect small areas of unusual disease aggregation (8) .\n\nFor the joint analysis of two or more diseases, we introduce a generalization of the shared component model (9) where the underlying risk surface for each disease is separated into shared and disease-specific components. We then propose a multivariate extension of the surveillance CPO that incorporates information from the different diseases and, consequently, facilitates the outbreak detection work. The multivariate surveillance technique has the ability to detect outbreaks of disease in either one or in a combination of diseases.\n\nWe analyze weekly emergency room discharges for acute upper respiratory infections, influenza, acute bronchitis, asthma and pneumonia in 2009. The data are available by county for the 46 counties of South Carolina. The use of a shared component model accounting for correlation across diseases provides a better overall fit. In addition, the use of the multivariate SCPO increases the statistical power for detection of outbreaks.\n\nPublic health surveillance; spatial data; Bayesian hierarchical models; joint disease mapping; conditional predictive ordinate\n\nAn expanded ambulatory health record, the Comprehensive Ambulatory Patient Encounter Record (CAPER) will provide multiple types of data for use in DoD ESSENCE. A new type of data not previously available is the reason for visit (ROV), a freetext field analogous to the CC. Intake personnel ask patients why they have come to the clinic and record their responses. Traditionally, the text should reflect the patient's actual statement. In reality, the staff often 'translates' the statement and adds jargon. Text parsing maps keywords or phrases to specific syndromes. Challenges exist given the vagaries of the English language and local idiomatic usage. Still, CC analysis by text parsing has been successful in civilian settings (1). However, it was necessary to modify the parsing to reflect the characteristics of CAPER data and of the covered population. For example, consider the shock/coma syndrome. Loss of consciousness is relatively common in military settings due to prolonged standing, exertion in hot weather with dehydration, etc., whereas the main concern is shock/coma due to infectious causes. To reduce false positive mappings, the parser now excludes terms such as syncope, fainting, electric shock, road march, parade formation, immunization, blood draw, diabetes, hypoglycemic, etc.\n\nFirst, a set of syndromes in an existing JHU-APL CC parser used in civilian versions of ESSENCE were selected for evaluation. The CC parser was then used to categorize the ROV from 3 months of records from all DoD facilities (about 12 million records total). From the records matched to each syndrome, 2000 were selected; the 1000 most common strings and an additional 1000 strings at random. Two analysts evaluated the sample strings independently and identified key decisions they each used to decide whether the match between the text string and the syndrome was accurate. They then attempted to reconcile those cases where they disagreed. Unresolved differences were reviewed by a DoD consultant who offered revised rules based on clinical experience and known practice patterns among DoD providers. The modified rules were incorporated into the CC parser and tested on miniature data samples for accuracy, and then the CC parser was rerun on the full record set. The cycle of independent analysis and review was repeated with additional modifications to correct any remaining errors followed by a final full run. Before and after contingency tables were used to compare CCbased versus diagnosis-based classifications. The final product was a modified CC parser input file tailored for use with DoD ambulatory healthcare records.\n\nThe following before/after contingency Table 1 illustrates the results for two syndromes: one common, influenza-like illness (ILI), and one rarer syndrome, neurological (Neuro). Additional results will show effects of the CC noise removal on alerting using datasets with documented outbreaks.\n\nThis iterative method produced a CC parser with substantially improved performance, eliminating many obvious incorrect classifications and resulting in a smaller number of more meaningful alerts for public health investigation. The process could be used to tune parsers to meet the unique medical terminology used in different communities. Moreover, daily CC and diagnostic counts should not be crudely pooled, but do provide complementary views of the population health status. \n\nTo review observations and conclusions from a recent global biosurveillance conference, provide an assessment of the scientific and technical capabilities and gaps to achieve an effective and sustainable integrated global biosurveillance (InGBSV) system, and recommend research and development priorities enabling InGBSV.\n\nLife science and biotechnology advances have provided transforming capabilities that could be leveraged for InGBSV. Global infectious disease surveillance holds great promise as a tool to mitigate the endemic and pandemic infectious disease impacts and remains an area of broad international interest. All nations have significant needs for addressing infectious diseases that impact human health and agriculture, and concerns for bioenergy research and environmental protection. In January 2011, Los Alamos National Laboratory, Department of State and the Defense Threat Reduction Agency co-hosted the 'Global Biosurveillance Enabling Science and Technology' conference. Guided by the National Strategy for Countering Biological Threats and joined by major government stakeholders, the primary objective was to bring together the international technical community to discuss the scientific basis and technical approaches to an effective and sustainable InGBSV system and develop a research agenda enabling a long-term, sustainable capability. The overall objective of the conference was to develop a technology road map for InGBSV, with three underlying components: (1) identify opportunities for integrating existing biosurveillance systems, the near-term technological advancements that can support such integration and the priority of future research and development areas; (2) identify the required technical infrastructure to support InGBSV, such as methodologies and standards for technology evaluation, validation and transition; and (3) identify opportunities, and the challenges that must be overcome, for partnerships and collaborations.\n\nTo achieve the objectives, the conference was structured to review the current state of biosurveillance, identify core components for a comprehensive capability and scientific and technical bases to support this capability and explore the critical improvements needed to enhance the existing regional and global disease outbreak prediction capabilities. Open discussion time was planned in order to engage broad participation during the conference to recommend approaches to establishing an effective international network, propose implementation strategies and the measures of effectiveness and identify the challenges that must be overcome in the next 3\u00c15 years in order to establish an initial biosurveillance capability that will have significant positive impact on biothreat nonproliferation, economy and public health.\n\nWe will report the principle observations from the conference. All participants were keenly aware of the complexity of developing an InGBSV, passionate about and committed to pursuing biosurveillance and supportive of the initial focus on application of existing information technology tools. It was largely agreed that:\n\n\u00c1 Scientific understanding of pathogen and pathogen-humanenvironment interaction is the foundation for integrated InGBSV; \u00c1 Emerging technology being developed by the R&D community for basic and applied life science advancement provides tremendous support for InGBSV; \u00c1 InGBSV can be 'jump started' with initial focus on information science and technology applications and integration; \u00c1 Challenges were recognized as multidimensional, but opportunities for developing a GBSV exist and are invigorated by international health security policies; \u00c1 Formulating unconventional partnerships and establishing an advanced concept demonstration is an effective near-term path forward.\n\nAn effective integration of existing technologies can provide great potentials to pursuing the opportunities afforded by establishing and operating an integrated global biosurveillance system (Fig. 1) . A common appreciation is also evident for the challenges associated with planning, obtaining necessary resources and establishing the desired functional biosurveillance capability. \n\nIt is admitted that real time surveillance system permits to reduce delay of outbreak detection and preventive measures implementation (1) . It is usually based on prediagnostic numeric data collection and transmission (2) . ASTER (Alerte et surveillance en temps r\u00e9el) is a real time surveillance system for French Armed Forces deployed in French Guiana and Djibouti ( Fig. 1) , constituted by 2 kinds of networks: several declaration networks and one analysis network (3). On June 2011, an outbreak occurred among a French Army Regiment in Djibouti, which has permitted to evaluate ASTER in real conditions.\n\nDeclaration network: at the end of medical consultation, each medical staff member declares clinic signs of his patient using a numeric standardized form on computers (specific declaration software). They transmit this anonymous form to a data base located in a Military Surveillance Disease Centre in France. Analysis network: observed data are automatically compared with historical data every 10 minutes, using current past graph method (specific analysis software), to produce alarm signals. These signals have to be analysed by epidemiologists to confirm or not the real alert about outbreak occurrence.\n\nData base already contained administrative data about all the soldiers present in Djibouti; and in case of illness symptoms in cause with date of onset and rapid antigenic tests results. Fiftyone cases of tonsillitis were declared during 4 days on 646 soldiers (attack rate 08%), with 18 positive streptotests on 25 performed (72%) (Fig. 2) . Epidemic curve had only one peak as if it was one source of contamination. A retrospective cohort study found one meal at risk (RR 012.8, IC95% 0[7.9\u00c120.6]), prepared by a local food provider.\n\nASTER produced an early warning signal, 7 days before the classic surveillance system, and only 1 day after the beginning of symptoms. It is based on clinic signs surveillance, which is more sensitive than disease surveillance. It permitted to perform immediately the description of the outbreak, using the realtime database without disturbing physicians and, therefore, to change the local food provider. The quality of data was good although physicians were busy because of the number of patients.\n\nReal time surveillance; outbreak; early warning; sensitivity \n\nData obtained through public health surveillance systems are used to detect and locate clusters of cases of diseases in spacetime, which may indicate the occurrence of an outbreak or an epidemic (1\u00c15). We present a methodology based on ALRs to compare the null hypothesis (no outbreaks) against the alternative hypothesis (presence of an emerging disease cluster).\n\nThe ALR preserves the martingale structure of the regular likelihood ratio, which allows the determination of an upper limit for the false alarm rate, depending only on the quantity of evaluated cluster candidates.\n\nA fast computational algorithm incorporates this important property, determining the cutting point to control the false alarm rate, thus making a viable tool for the detection of emerging clusters in geographical maps, where the baseline of the number of cases has nonconstant average. The greater flexibility of the candidate clusters' shape produces a better estimation of the most likely cluster.\n\nHowever, the large cardinality of the set of candidate clusters is an obstacle for the application of the ALR procedures, generating function values so small that the alarm may not ring, even if an emerging cluster exists. To solve this problem, we propose the use of an adaptive approach also for the clusters' configuration space.\n\nPerformance is evaluated by the following criteria: average detection delay and probability of correct detection in space,\n\ngiven that an outbreak really exists. We present simulations with artificial data and applications for thyroid cancer in New Mexico and hanseniasis in children in the Brazilian Amazon.\n\nAn empirical analysis based on simulations was obtained, with very satisfactory results. Those performance results suggest that the ALR strategies, working in both adaptivity levels of parametric space and clusters' configuration space, are very effective in the surveillance of space-time disease clusters. Objective To assess the effectiveness of a public health automated phone campaign to increase vaccination uptake in targeted neighborhoods. To identify alternative predictors of variation in vaccination uptake, specifically to assess the association between vaccination uptake and weather conditions and day-of-week.\n\nWork on vaccination timing and promotion largely precedes the 2009 pandemic. Postpandemic studies examining the wide range of local vaccination efforts mostly have been limited to surveys assessing the role of administrative strategies, logistical challenges and perceived deterrents of vaccination (1).\n\nWe used a quasi-Poisson logistic regression model to analyze daily vaccination counts at Montr\u00e9al's mass vaccination centers (MVC; n 018) before and after an automated phone campaign promoting pandemic vaccination in 13 of the city's 29 health districts. We then used a similar model to test a more mundane explanation for the considerable variation in daily use of MVC: that inclement weather and weekends deterred vaccination.\n\nWe found a nonsignificant increase in vaccinations following the phone campaign, with fewer than 1000 estimated additional vaccinations (results not shown). The association between weather conditions and vaccination was strong and significant when controlling for variation between MVC (Table 1) . We found no evidence of day-of-week effect.\n\nOnly 50% of Montr\u00e9al Island was vaccinated, which was well short of the public health goal for 'herd immunity'. Uptake was below 30% in some census tracts. Vaccination capacity was not the limiting factor.\n\nDespite targeting neighborhoods with the lowest uptake, the Health Department's campaign did not appear to increase vaccination, reflecting ineffectual communication or a more troubling lack of trust in health authorities (2) . Launching the campaign earlier might have been more effective.\n\nThe strong association between vaccination and weather ( Fig. 1) , suggests that many individuals either were easily deterred from vaccination or delayed their trip to MVC. For wait-and-see individuals, even a short postponement may well have become nonvaccination (3) .\n\nThese findings suggest that vaccination uptake could be improved by allocating more resources at the start of the vaccination campaign.\n\nVaccination campaign; pandemic; influenza; weather \n\nIn 2004, the Marion County Public Health Department (MCPHD), which serves a county population over 890,000, began using a real-time syndromic surveillance system, ES-SENCE (Electronic Surveillance System for the Early Notification of Community-based Epidemics) to assist in detecting possible disease outbreaks. Today, about 1600 emergency department visits occur daily in Marion County's 14 emergency departments. Epidemiologists from MCPHD have contributed to the city's extreme temperature plans for the last few years. While most of the previous increases in heat-related illnesses in Marion County have been attributed to prolonged heat exposure in connection with local auto races, the county had not activated the county wide emergency response plan in several years. From Tuesday, July 19 through Friday, July 22, 2011, the Marion County Extreme Temperature Plan was put into action in response to several days of a high heat index.\n\nAs the written plan indicated, a MCPHD epidemiologist checked ESSENCE every 3 hours and sent updated numbers to the Emergency Operations Center three times a day via e-mail. The query used the following terms: '\u02c6heat\u02c6, or,\u02c6dehyd\u02c6,or,\u02c6hot\u02c6,andnot,\u02c6gunshot\u02c6'. This is one of several pieces of information used to guide decision making when considering opening additional cooling centers and creating press releases for the public.\n\nThe MCPHD sister's agency is the area hospital that accepts medically underserved patients. With this access to the patient system, the electronic medical records of 21 people meeting the search criteria and seeking care at this emergency department between June 1, 2011, and July 29, 2011 were reviewed. An extended time period was reviewed to see if there were obvious differences in the counts of patients or terminology used in the chief complaint once the heat wave was upon the city. Five (24%) sought care in June 2011, 16 (76%) in July. Fifty percent of those seeking care for heat-related issues were seen in a 2-day period in July. Six people (29%) developed symptoms while at work. Work-related tasks included roofing, painting, working in metal tanks and driving trucks without air conditioning. Two homeless persons (10%) sought care during the 2-day time frame when half of the cases were identified as well as four of the six who developed symptoms while at work. Alcohol and drugs may have been a contributing factor for three (14%) of those seeking care. Nine individuals (43%) were treated for medical conditions, such as chronic obstructive pulmonary disease, diabetes, urinary tract infections, gastrointestinal infections or pneumonia.\n\nAlthough the current query did produce a few 'false positives', the MCPHD staff has decided to continue the use of the same terminology since a significant amount of the cases detected were indeed heat related. The counts from the days of the heat wave were significantly higher than in previous summer months. The use of syndromic surveillance during a heat event can provide meaningful information for decision makers in emergency preparedness. Heat-Related Chief Complaints \n\nThe CDC's BioSense Program receives near real-time health care utilization data from a number of sources, including Department of Defense (DoD) healthcare facilities from around the globe and nonfederal hospital emergency departments (EDs) in the United States, to support all-hazards surveillance and situation awareness. Following the tsunami in Japan on March 11, 2011 , the BioSense Program modified its surveillance protocols to monitor: (1) injuries and possible radiationassociated health effects in Japan-based DoD facilities and (2) potential adverse health effects associated with the consumption of potassium iodide (KI), a salt used to prevent injury to the thyroid gland in the event of radiation exposure, among persons attending participating EDs in the US. We present the findings from that enhanced surveillance.\n\nThe BioSense Program monitored healthcare activity in 20 DoD facilities located in Japan from March 17 through April 11, 2011. In Japan-based outpatient DoD facilities, we monitored 10 health conditions, which are associated with injuries, and possible syndromic presentations of radiation exposure, which included nausea/vomiting, diarrhea, headache, hypotension, rash, convulsion, dyspnea, dizziness and anemia. We also searched for radiation exposure-specific International Classification of Diseases, Ninth Revision, Clinical Modification (ICD-9-CM) 990, 508.0, 558.1, E926 and E926.9. There was a 2-to 5-day lag time between the time of patient visit and time when ICD-9-CM-coded final diagnoses were available. To monitor healthcare utilization for potential adverse effects associated with KI exposure in the United States, we searched ED chief complaint (CC) data from all 635 nonfederal BioSense hospitals for the following keywords indicating a KI-related visit: (1) potas*, pottas*; (2) iodine, iodide; (3) KI; (4) radiation, radeation; (5) nuclea*; (6) Japan. A given ED visit was considered a match if the content of the CC met the following keyword inclusion criteria: 1 and 2, 3, 4 and 5 or 6. Perl Regular Expressions were used to take into account upper-and lowercase letters and word boundaries. CC data were updated within 0\u00c12 days following the visit date.\n\nTo identify clusters of patient visits of interest, we used a modified version of the early aberration reporting system (EARS) C2 statistic (1) . For both surveillance efforts, this signal detection method was run upon the data for individual facilities.\n\nAdditionally, visit data from all 20 DoD facilities were analyzed as a group.\n\nFrom March 17 through April 11, 2011, the BioSense Team created daily reports for the CDC's Emergency Operation Center and DoD counterparts. Reports included time series graphs for each of the 10 health conditions. Fig. 1 shows an example of a time series for diarrhea and total visits in the 20 DoD facilities. During this surveillance period, no clusters or radiation exposure coded visits were detected in Japan-based DoD facilities. In the United States, no ED-visit clusters associated with KI intoxication were found in nonfederal US EDs.\n\nBioSense is an adaptable electronic all-hazards public health surveillance system that can provide near real-time health situational awareness during large-scale natural disasters. \n\nThis study examines healthcare records, for the time period January 1, 2010\u00c1June 30, 2011, from a North Carolina-based hospital system composed of three different hospitals for clusters of visits related to exposures. Visits were identified based upon the inclusion of terms in chief complaint data related to chemical, carbon monoxide, meningitis, food poisoning and other types of exposures. For each hospital, time series of visit counts from 1 hour cells, based on patient time-of-visit, were monitored using the past 60 days' cell counts as a baseline. Either a Poisson or a negative binomial distribution was assumed, depending on the baseline mean and variance for each hospital/hour cell. A p-value was calculated for the probability of at least as many visits as observed, and an alert was issued if this value was below 0.01, a threshold chosen to minimize the burden on the PHEs to investigate the alert.\n\nFor comparison with traditional NC DETECT methods, we also applied Biosense's modified C2 algorithm (2) to the daily exposure-related visit counts for this study. Table 1 shows how C2 and TOA alerting are complementary at the 3 study hospitals. Line lists provide relevant information for each patient cluster. Table 2 gives an example of a TOA alert from a late morning cluster at a single hospital.\n\nTOA monitoring of exposure-related ED visits efficiently complements daily syndromic surveillance, finding additional clusters of potential interest. This method can be adapted to distributed as well as centralized alerting systems. \n\nTo examine the completeness of data submitted from clinical information systems to public health agencies as notifiable disease reports.\n\nElectronic laboratory reporting (ELR) was demonstrated just over a decade ago to be an effective method to improve the timeliness of reporting as well as the number of reports submitted to public health agencies (1) . The quality of data (including completeness) in information systems across all industries and organizations is often poor (2) , and anecdotal reports in the surveillance literature suggest that ELR may not improve the completeness of the data in the submitted reports (3).\n\nThe scope of our research included the following aims: (1) the development of a method for evaluating the completeness of laboratory data in the context of public health reporting; (2) measuring the completeness of laboratory data received from clinical information systems and an HIE using the method; and (3) comparing the completeness of the 'raw' data from clinical information systems (e.g., unaltered and unedited ELR messages) with the completeness of 'enhanced' data from the HIE (e.g., ELR messages having syntax corrected and concepts mapped to standard vocabularies).\n\nA comparison of 7,592,039 raw messages and 16,365 enhanced messages revealed a number of differences with respect to data completeness. Data field completeness within the ELR messages varied from 0.01% to 84.6% across the two samples. Completeness was generally higher in the enhanced message sample as shown in Table 1 .\n\nTo effectively perform surveillance, public health agencies require access to 'timely, accurate, and complete data' (4) . Unfortunately, data quality is an issue for many clinical information systems that capture data utilized in public health surveillance processes. This study assessed the completeness of real-world ELR data from multiple provider organizations using a variety of laboratory information systems, documenting evidence that ELR data are heterogeneous in their completeness across and within information systems. In many cases, data important to public health surveillance processes are missing, indicating suboptimal ELR data quality. The study further documented evidence that a statewide or regional HIE can employ methods to mitigate ELR data deficiencies, leading to improvements in the completeness of ELR data prior to transmission to public health agencies.\n\nElectronic laboratory reporting; health information exchange; data quality; completeness \n\nNo off the shelf software was available that met local health department system requirements and budget constraints. Thus, a collaborative team of public health professionals and database programmers convened to establish a project charter that outlined the system requirements, personnel responsible, timeline and budget. A qualitative analysis of current county level systems and data helped to establish the requirements of the FITS system, as well as direct the reporting capabilities and features. The fixed budget expenditure and early deadline led to an expedited timeframe; the system was completed within 4 months.\n\nA FITS was created in accordance with the project charter, timeline, user specifications and budget and included but was not limited to the following technologies: CentOS, Ruby and Excel. An innovative feature of the FITS system is the live lookup of national drug codes (NDC) hosted on the FDA's website, which autopopulates the FITS vaccination database with up-to-date information (2) . FITS allows flu immunization records to be accurately captured at the county level, resolving the dilemma created by the PREP amendment. County health professionals were invited to a system users training to orient them with the system, record management and downloading/ uploading of data. After an initial rollout of FITS at the county level, it is expected to be promoted statewide to increase accurate reporting of immunization administration.\n\nThe field of public health informatics calls for the conceptualization, design, development, deployment, refinement, maintenance and evaluation of surveillance systems (3) . This project exemplifies the positive outcomes that can result from collaborative efforts within the informatics framework. It is anticipated that this system will serve as a model for other counties across the state and will lead to improved reporting of flu vaccination records across the State of Ohio and perhaps beyond. Introduction Spatial cluster analysis is considered an important technique for the elucidation of disease causes and epidemiological surveillance. Kulldorff's spatial scan statistic, defined as a likelihood ratio, is the usual measure of the strength of geographic clusters (1). The circular scan (2), a particular case of the spatial scan statistic, is currently the most used tool for the detection and inference of spatial clusters of disease. Kulldorff's spatial scan statistic for aggregated area maps searches for clusters of cases without specifying their size (number of areas) or geographic location in advance. Their statistical significance is tested while adjusting for the multiple testing inherent in such a procedure. However, as is shown in this work, this adjustment is not done in an even manner for all possible cluster sizes (3).\n\nWe pose a modified inference question: what is the probability that the null hypothesis is rejected for the original observed cases map with a most likely cluster of size k, taking into account only those most likely clusters of size k found under null hypothesis for comparison? This question is especially important when the p-value computed by the usual inference process is near the alpha significance level, regarding the correctness of the decision based in this inference.\n\nNumerical experiments are made showing that the proportions of rejections of the null hypothesis differ noticeably, by employing the usual critical value, compared with using the data-driven critical values. It is also shown that the computational cost of estimating the data-driven critical value may be reduced through the use of a simple interpolation.\n\nA practical procedure is provided to make more accurate inferences about the most likely cluster found by the spatial scan statistic. The proposed method is more useful when the computed p-value using the classical inference is close to the significance level; otherwise, there will be no change in the decision process. In this situation, it is recommended that the data-driven inference should be performed, especially when the observed most likely cluster has relatively large size.\n\nSpatial scan statistic; inference; data-driven Significant multiple high-and low-risk regions in event data maps Emerson Bodevan 1 , Luiz Duczmal 2 *, Gladston Prates Moreira 3 , Anderson Duarte 3 and Fl\u00e1 via Oliveira Magalh\u00e3 es 4\n\nThe Voronoi Based Scan (VBScan) (1) is a fast method for the detection and inference of point data set space-time disease clusters. A Voronoi diagram is built for points representing population individuals (cases and controls). The number of Voronoi cells boundaries intercepted by the line segment joining two cases' points defines the Voronoi distance between those points. That distance is used to approximate the density of the heterogeneous population and build the Voronoi distance Minimum Spanning Tree (MST) linking the cases. The successive removal of its edges generates subtrees, which are the potential space-time clusters, which are evaluated through the scan statistic. Monte Carlo replications of the original data are used to evaluate cluster significance. In the present work, we modify VBScan to find the best partition dividing the map into multiple low-and high-risk regions.\n\nIn our novel approach, we use the previous VBScan recursively on the map with case-control point event data. At each recursive step, we compute two functions: (i) the likelihood ratio of the multiple components and (ii) the likelihood ratio increase since the previous step. As the first function always increases monotonically with every added component to the partition, the last function is used as a measure of the cost-benefit of adding a further region to the partition. This is done employing a multicriteria decision process, determining the nondominated partition solutions. Through Monte Carlo replications under null hypothesis, we compute the significance of the nondominated solutions and choose the best partition.\n\nOur method was tested on several different simulated maps partitioned into different numbers of components (ranging from 2 to 4). The relative risks for each component were chosen as 3 sigma, (3 sigma and 0 sigma, corresponding respectively to high-, low-and neutral-risk spots. We evaluate the power of detection and matching (a measure of overlap between the real and detected partitions) for each set of 1000 Monte Carlo replications. The average power varies from 0.686 to 0.803, and matching varies from 0.566 to 0.850 for the several sets of simulations.\n\nWe also applied the method on a case study of dengue fever in a small Brazilian town in 2010 (1). Fig. 1 shows the MST linking the 57 cases (small circles) distributed among 3929 controls. The optimal partition consists of three components: two high-risk regions (red and blue) and a low-risk region (white).\n\nThe proposed method is fast, with good partitions' accuracy determination. The dengue fever application's result shows that our method is in very good agreement with the previous analysis with VBScan, which indicates two significant high-risk clusters (the red region is the primary cluster with p-value 0.004, and the blue region is the secondary cluster with p-value 0.016).\n\nCase-control; disease cluster; spatial scan statistic; space partition; dengue fever 1 \n\nThe spatial scan statistic (1) is the most used measure for cluster strenght. The evaluation of all possible subsets of regions in a large dataset is computationally infeasible. Many heuristics have appeared recently to compute approximate values that maximizes the logarithm of the likelihood ratio. The Fast Subset Scan (2) finds exactly the optimal irregularly spatial cluster; however, the solution may not be connected.\n\nThe spatial cluster detection problem was formulated as the classic knapsack problem (3) and modeled as a biobjective unconstrained combinatorial optimization problem.\n\nDynamic programming relies on the principle that, in an optimal sequence of decisions or choices, each subsequence must also be optimal. During the search for a solution, it avoids full enumeration by pruning early partial decision solutions that cannot possibly lead to optimal solutions.\n\nWe propose a novel method, the Geographical Dynamic Scan (GDScan) to find optimal connected clusters. It employs an adaptation of the Nemhauser\u00c1Ullman algorithm for the 0\u00c11 knapsack problem (4). We minimize a biobjective vector function F(z)0((C(z),N(z)), where C(z) and N(z) are the number of cases and the population of the candidate cluster z, respectively. Then, we show that the solution which maximizes the spatial scan statistic is included in the set of nondominated solutions of F (the Pareto set), showing that the dynamic programming algorithm allows to solve the unconstrained maximization of the scan statistic for any given spatial dataset. However, this is typically not sufficient to solve practical spatial detection problems.\n\nThe dynamic programming algorithm is thus modified to consider (i) a geographical proximity constraint and (ii) a connectivity constraint, for each region j. Assuming that the geographical proximity of a region j contains k regions, the geographical dynamic scan guarantees the optimal solution within the collection of 2\u02c6k subsets, searching for only a small number of subsets, which depends almost linearly on k, on average.\n\nWe conducted numerical simulations showing that GDScan has good power of detection, sensitivity and positive predicted value.\n\nAn application is shown for the dataset of Chagas' disease cases in the population at risk of puerperal women in Minas Gerais state, Brazil, in 2006 (5). Fig. 1 shows the nondominated sets of solutions obtained by GDScan for neighborhood sizes of 5, 20, 40 and 90.\n\nGDScan is a fast and an efficient method to detect connected arbitrarily shaped disease clusters in aggregated area maps.\n\nDisease cluster; dynamic programming; spatial scan statistic \n\nOrdering-based approaches (1,2) and quadtrees (3) have been introduced recently to detect multiple spatial clusters in point event datasets. The ALG (4) is an efficient graph-based data structure to handle the communication of cells in discrete domains. This adaptive data structure was favorably compared to common tree-based data structures (quadtrees). An additional feature of the ALG data structure is the total ordering of the component cells through a modified adaptive Hilbert curve, which links sequentially the cells (the orange curve in the example of Fig. 1 ).\n\nWe combine ordering-based approaches with the ALG structure to identify multiple clusters in case-control datasets, in a fivestep procedure. In the first step, we subdivide adaptively the domain into square cells (blue squares in Fig. 1 ), with controls (pink points) and cases (little dotted black squares). In the second step, the cell's ordering given by the Hilbert curve is used to sequentially join cells with the highest proportion of cases over controls. This produces loose groups of higher than average rates of disease. The adjacent groups thus formed are themselves united, according to certain criteria, into larger groups in the third step, forming the cluster candidates. In the fourth step, Kulldorff's spatial scan statistic is computed for each group, and the clusters are ranked. Finally the cases are randomized, and steps 1\u00c14 are repeated. That is done hundreds of times to compute the significance of each cluster. Only significant clusters are reported.\n\nAs an application, we find clusters of dengue fever for Lassance City, in southeast Brazil, 2010 (5). Fig. 1 shows the three significant clusters found, displayed as the three green patches.\n\nThe previous adaptive subdivision of the domain is essential to define more homogeneous regions within the study area.\n\nAlso, instead of just applying some ordering-based approach, our method introduces an intermediate step (step 3) to combine the separated regions of high incidence. Those two features produce more reliable clusters, compared with the usual ordering-based methods.\n\nSpatial cluster; autonomous leaves graph; ordering-based; spatial scan statistic; quadtree \n\nIn April 2009, a novel strain of influenza A was detected in Mexico, which quickly spread to the United States and the rest of the world. In response to the pandemic, the New Hampshire Department of Health and Human Services (NH DHHS) developed a web-based school absenteeism reporting system to track and record overall absenteeism and influenza-like illness (ILI)-related absenteeism in New Hampshire schools.\n\nAn absenteeism reporting form was developed and placed on a NH DHHS website. Access to the reporting form website was through a secure NH Department of Education (DOE) web portal, and school nurses were asked to voluntarily report data into the system. The questionnaire asked for the number of students absent, the number of students absent for ILI, the number of staff absent and the number of staff absent for ILI in addition to the name of the reporting school ( Fig. 1 ). Data were exported and analyzed daily by NH DHHS staff using Microsoft Excel. School enrollment data for each school were provided by DOE so that rates of absenteeism could be calculated. Rates for overall absenteeism and absenteeism due to ILI were aggregated by school administrative unit (SAU) and posted on the NH DHHS website twice weekly in the form of a map. Schools reporting absenteeism greater than 10% for any given day were contacted to determine whether an ILI outbreak was occurring and to recommend control measures.\n\nBetween September 7 and December 23, 2009, statewide overall school absenteeism ranged from 0.0% to 29.3% and statewide ILI-related absenteeism ranged from 0.0% to 14.2%, both of which peaked the week of November 1\u00c17, 2009. The observed peak of school absenteeism was consistent with data observed in other ILI surveillance systems such as over-the-counter sales of cough and cold medications and visits to emergency departments ( Fig. 2) . At the peek of absenteeism, 346 of 479 (72%) of all elementary, middle and high schools in New Hampshire were reporting into the system. NH DHHS identified 103 outbreaks using the school absenteeism reporting system; a state public health nurse investigated each outbreak. Timeliness of outbreak detections were within 24 hours due to daily reporting.\n\nThe newly developed school absenteeism reporting system provided important public health surveillance data to evaluate potential outbreaks or clusters of disease in communities and resulted in the detection of and response to 103 outbreaks of ILI that would not have been detected otherwise. Enhanced interaction with school nurses through the development of the surveillance system resulted in increased awareness in school populations about the influenza A/H1N1 (2009) virus. Furthermore, the rapid detection and response to potential outbreaks identified using the system may have minimized the effect of ILI in the school system and the community, through heightened awareness and implementation of control measures.\n\nAlthough the reporting system started as a way to monitor the impact of the 2009 influenza A/H1N1 pandemic, NH DHHS has continued to routinely monitor student absence ever since. School absenteeism surveillance has the potential to aid in early detection, and mitigation, of other communicable diseases in the school system, an important indicator of illness in the communit. \n\nEDs supply critical infrastructure to provide medical care in the event of a disaster or disease outbreak, including seasonal and pandemic influenza (1). Already overcrowded and stretched to near-capacity, influenza activity augments patient volumes and increases ED crowding (2, 3); high ED patient volumes expected during a true influenza pandemic represents a significant threat to the nation's healthcare infrastructure (4) . EDs ability to manage both seasonal and pandemic influenza surges is dependent on coupling early detection with graded rapid response. While practical use of traditional surveillance systems has been limited due to the several week lag associated with reporting, new internet-based surveillance tools, such as GFT, report surveillance data in nearreal time, thus allowing rapid integration into healthcare response planning (5) .\n\nOctober 2010) at an urban academic hospital with physically and administratively separate adult and pediatric EDs. We collected weekly data from GFT for the city of Baltimore, ED CDC reported standardized influenza-like illness (ILI) data, laboratory-confirmed influenza data and ED crowding indices (including patient volume, number of elopements, waiting room time and length of stay for admitted and discharged patients). Pediatric and adult data were analyzed separately using crosscorrelation with GFT.\n\nGFT correlated with both number of positive influenza tests as seen in Figure 1 (adult ED r 00.876, pediatric ED r 00.718) and number of ED patients presenting with ILI (adult ED r00.885, pediatric ED r 00.652). Pediatric but not adult crowding measures such as total ED volume (r 00.649) and left without being seen (r 00.641) also had good correlation with GFT. Adult crowding measures for low acuity patients such as waiting room time (r00.421) and length of stay in discharged patients (r00.548) had moderate correlation with GFT.\n\nCity-level GFT shows strong correlation with local influenza cases and ED ILI visits, providing first time evidence of its utility for local ED surveillance and, potentially, response planning. Importantly, GFT correlated with several pediatric ED crowding measures as well as those for low acuity adult patients.\n\nInfluenza, Google flu trends, emergency department, crowding \n\nTo describe a real-time reportable disease and surveillance solution focused on local public health department needs and compatible with state health departments, regardless of meaningful use certification status of health care providers.\n\nMultiple options (1, 2) are available for health care provider organizations to receive assistance in demonstrating compliance with meaningful use requirements for public health reporting (3) . A certified EHR solution is a requirement for participation in these programs; vast majority of health care providers do not yet have such a solution. No funding programs are currently available to assist public health agencies, especially local public health departments (4) . As a result, most providers and local public health agencies are seemingly left without viable options except spending significantly in a tight budget environment.\n\nPrior to ARRA 2009/Meaningful Use, KHA, KY CHFS and ETI created an electronic disease-reporting solution for hospitals and associated local public health. The Community Surveillance project operates in 3 population centers within Kentucky and provides real-time surveillance and disease reporting for up to 18 prevalent disease conditions across more than 20 provider locations and 6 provider organizations within the Northern Kentucky, Lexington/Fayette County and Louisville Metro communities. The software solution, ETI's HealthSIS, is able to accept meaningful use certified messaging, uncertified messaging formats and custom data streams for both reportable disease and syndromic surveillance information from a single stream within each provider location. The messaging stream used for identifying reportable or syndromic conditions is a copy of the content generated by normal hospital operations; specialized or additional data input is not required from health care provider staff. HealthSIS is configured to submit only data relevant to surveillance goals of the community from source systems; this configurable filtering capability allows for reduced resource requirements, reduced data management resources, and a manageable data set for analysis.\n\nSince mid-2008, NKIDHD receives electronic disease reports and surveillance support for what is now the 18 most prevalent disease conditions in the community. SEMC (6 facilities) has realized 75%\u00c190% reduction in public health reporting effort as a result of the capabilities provided by HealthSIS. Since mid-2009, LFCHD receives syndromic surveillance data from ambulance runs, initially to support preparations for the 2010 Alltech-FEI World Equestrian Games; LFCHD began receiving electronic disease reports for 9 prevalent disease conditions in mid-2010 from CBH and UKMC. Since late 2009, LMPHW receives electronic disease reports for 5 prevalent disease conditions from BHE and notifications of same from JHSMH; in 2011, NHC began participating in the disease-reporting process.\n\nInstalling and maintaining electronic disease and syndromic surveillance to support public health agencies is possible without large budgets and without massive systems upgrades within health care provider organizations; benefits are clearly measurable \u00c1 independent study in Washington state in 2010 confirms benefit of the concept (5). Emergint's HealthSIS software and the Community Surveillance solution implemented in Kentucky presents a systems approach that can be replicated across the country, whether fed by providers or HIEs and regardless of meaningful use certification status. \n\nThe electronic surveillance system for the early notification of community-based epidemics (ESSENCE) is the web-based syndromic surveillance system utilized by DHMH. ESSENCE utilizes a secure, automated process for the transfer of data to the ESSENCE system. Data sources in the Maryland ESSENCE system include emergency department (ED) chief complaints, poison control center calls, over-the-counter (OTC) medication sales and pharmaceutical transaction data (for certain classes of antibacterial and antiviral medication). All data sources have statewide coverage and are captured daily in near real-time fashion. OIT developed a web-based application in conjunction with OP&R to allow the epidemiologists involved in the ESSENCE program to monitor and audit the transfer of this data. The application allows the user to indicate whether or not each data file has been consumed into ESSENCE for any date of the year. The user can edit these daily entries at any time to update the status of the data that have been received. The user may also query the database by data source, date and date range to generate a report. The database also contains contact information for technical and infection control staff at the hospitals that participate in the ESSENCE program. Finally, the application can also generate reports that detail which users have logged into ESSENCE, when the log-in occurred, and which pages within ESSENCE were visited.\n\nForty-six EDs, two major pharmacy chains, two poison control centers and the Centers for Disease Control and Prevention (CDC; through a pilot partnership), all contribute data to ESSENCE on a daily basis. Thirty-six separate SSH File Transfer Protocol (sFTP) data feeds are required to transfer and incorporate these data into ESSENCE. Beginning January 1, 2011, the web-based application developed by OIT was utilized on a daily basis to ensure that the transfer of data was monitored and recorded regularly. Each morning, an epidemiologist from OP&R logs into ESSENCE and verifies which data points have been consumed into the system. The presence or absence of each data point is then recorded in the data tracking application. An automated e-mail is generated that details which data sources are absent. This e-mail is sent to the OIT employees involved in the ESSENCE program, who then check the server to see if the data were transferred or if there was an error during the transfer and consumption process. The epidemiologists then contact each data source that failed to send the data on that particular day.\n\nData are presented for January 1, 2011, through July 31, 2011 (212 total days). Between the ED chief complaint data, the poison control data, the OTC medication sales data and the pharmaceutical transaction data, there are a total of 50 data points on any given day in the Maryland ESSENCE system. This amounts to a total of 10,600 possible data points that can be in the ESSENCE system during this time frame. Using the data tracking application, OP&R has managed to acquire and consume 10,527 data points or 99.31% of all possible data points for this time period. The poison control data are complete for this time frame, as is the pharmaceutical transaction data, and one of the major pharmacy chain's data. The other major pharmacy chain whose data are not complete is only missing 2 data points (99.10% complete). Twenty-five of the 46 EDs have transferred 100% of the possible data points to the ESSENCE system. All other EDs contributing data to the ESSENCE system are at least 95.75% complete.\n\nThe data tracking application developed by OIT and utilized by OP&R to monitor and audit the transfer of syndromic surveillance data has thus far been successful in ensuring data completeness. Those involved with the program have been able to monitor and document that over 99% of all possible data are incorporated into the surveillance system. The data source with the lowest completion percentage has over 95% of its data incorporated into the system. DHMH will continue to use this system moving forward to ensure that the syndromic surveillance data transfers continue to be successful.\n\nData; transfer; audit; ESSENCE *Zachary Faigen E-mail: zfaigen@dhmh.state.md.us Introduction ILI data are collected via an Influenza Sentinel Provider Surveillance Network at the state level. Because participation is voluntary, locations of the sentinel providers may not reflect optimal geographic placement. This study analyzes two different geographic placement schemes*a maximal coverage model (MCM) and a K-median model, two location-allocation models commonly used in geographic information systems (GIS) (1). The MCM chooses sites in areas with the densest population. The K-median model chooses sites, which minimize the average distance traveled by individuals to their nearest site. We have previously shown how a placement model can be used to improve population coverage for ILI surveillance in Iowa when considering the sites recruited by the Iowa Department of Public Health (IDPH) (2) . We extend this work by evaluating different surveillance placement algorithms with respect to outbreak intensity and timing (i.e., being able to capture the start, peak and end of the influenza season).\n\nWe developed a web-based site placement calculator to aid public health officials in designing their surveillance system. We then compare the two algorithmic site placement schemes against each other by simulating the spread of influenza across the state of Iowa. Our simulations are based on an Iowa Medicaid dataset comprised two million cases classified with 30 different ILI ICD-9 codes and their corresponding geocodes from 2000 to 2008. We use the Huff Model (3) to determine whether or not a case might have been detected by a particular network of sites. Using this scheme, we compare surveillance networks based on outbreak intensity (i.e., which networks detect the highest percentage of cases) and outbreak timing (i.e., which networks detect cases temporally in sync with the true start, peak and end of the disease season). To compare network outbreak timing, we generate the noise parameters of a state space time series model using the expectationmaximization (EM) algorithm implementation provided by Shumway and Stoffer (4). We then perform an analysis on which ICD-9 codes a network might consider.\n\nConsidering outbreak intensity, we show that sites chosen by our approach outperform the sites used by the IDPH. In other words, we can provide a more accurate representation of disease burden during an influenza season. However, our approach does not provide a substantial difference in the detection of the start, peak and end of the influenza season. In addition, when using the noise values generated by the EM algorithm to analyze the minimal number of sites needed to estimate the timing of the influenza season, our results were highly influenced by both the number of different ICD-9 codes considered and the number of cases considered.\n\nWe built a web-based tool to assist public health officials in designing their sentinel surveillance site network. Through simulation, we show that the sites our tool selects allow for better representation of disease burden. We also show that selecting the correct ICD-9 codes that the surveillance network should consider may be as important as selecting the locations of the sites themselves. Using our methods, we can help public health officials design surveillance systems, which are smaller and more easily managed but still detect cases that reflect reliable estimates of both disease burden and timing. \n\nNoroviruses are the single most common cause of epidemic, nonbacterial gastroenteritis worldwide. NoVs cause an estimated 68\u00c180% of gastroenteritis outbreaks in industrialized countries and possibly more in developing countries.\n\nData were analyzed from 900 RT-PCR-confirmed NoVoutbreaks extracted from a systematic review of articles published from 1993 to 2011, indexed under the terms 'norovirus' and 'outbreak'. Seventy\u00c1four variables were included in the database.\n\nOf the 894 outbreaks documenting year of occurrence, 72% occurred between 2000 and 2010. More than 90% of outbreaks occurred in the northern hemisphere and 45% took place during the winter. In general, we found the number of primary cases and persons at risk was significantly lower in outbreaks related to food and waterborne transmission as well as foodservice and healthcare settings. The attack rates were significantly higher in outbreaks related to food, water and those that occurred in the winter. Attack rates were also lower in healthcare-related outbreaks, perhaps on account of proper infection control practices and active surveillance by healthcare facilities to limit the spread of disease.\n\nMultivariate regression analyses demonstrated that higher attack rates were significantly associated with foodservice (b 0 14.70, p00.02) and winter outbreaks (b09.81, p0B0.01). A combination of strains was most common among food and waterborne outbreaks. Waterborne outbreaks were also significantly associated with GI strains (odds ratio [OR] 00.10, 95% confidence interval [CI] 00.03\u00c10.41 where the odds of an outbreak being caused by a GII strain are less than the odds of the outbreak being caused by a GI strain), while healthcarerelated (OR 040.42, 95% CI 02.09\u00c1783.15 where the odds of the outbreak being caused by a GII strain are greater than the odds of the outbreak being caused by a GI strain) and winter outbreaks (OR 05.56, 95% CI 01.97\u00c115.69) were associated with GII strains (Table 1) .\n\nFood and waterborne outbreaks may have greater attack rates due to: (1) efficient viral transmission, especially within smaller confines, via drinking water or food items, and (2) more accurate identification of persons at risk.\n\nDecreased mobility of infected persons in healthcare settings may also limit transmission of NoV to healthy individuals. As mentioned previously, the clustering of people indoors during seasonal cold weather may facilitate person-to-person NoV transmission. These results identify important trends for epidemic NoV detection, prevention and control. \n\nThe intrinsic variability that exists in the cases counting data for aggregated-area maps amounts to a corresponding uncertainty in the delineation of the most likely cluster found by methods based on the spatial scan statistics (3) . If this cluster turns out to be statistically significant, it allows the characterization of a possible localized anomaly, dividing the areas in the map in two classes: those inside and outside the cluster. But, what about the areas that are outside the cluster but adjacent to it, sometimes sharing a physical border with an area inside the cluster? Should we simply discard them in a disease prevention program? Do all the areas inside the detected cluster have the same priority concerning public health actions? The intensity function (2), a recently introduced visualization method, answers those questions assigning a plausibility to each area of the study map to belong to the most likely cluster detected by the scan statistics. We use the intensity function to study cases of diabetes in Minas Gerais state, Brazil.\n\nWe use the intensity function to visualize the plausibility of each area of some study map to belong to a possible cluster in the map. Fig. 1 presents the most likely cluster found by circular scan. Fig. 2 shows the intensity function. The intensity function map (Fig. 2) shows clearly that areas with the highest quantiles correspond ( Fig. 1 ) to areas belonging to the primary cluster detected by circular scan. But, the intensity function map also shows a significative number of areas (red color) with a high plausibility to belong to a possible real cluster and some areas (orange color) with intermediate to high intensity function values.\n\nGiven a study map with an observed number of cases distributed among its areas, the intensity function value for each area represents the importance of that particular area in delineating a possible cluster of anomalies in the map. This is shown clearly in the results obtained for diabetes cases in Minas Gerais.\n\nIntensity function; spatial scan statistics; diabetes; delineation of spatial clusters \n\nCardiovascular event prediction has long been of interest in the practice of intensive care. It has been approached using signalprocessing of vital signs (1\u00c14), including the use of graphical models (3, 4) .\n\nOur approach is novel in making data segmentation as well as hidden state segmentation an unsupervised process and in simultaneously tracking evolution of multiple vital signs. The proposed models are adaptable to the individual patient's vitals online and in real time, without requiring patient-specific training data if the patient-specific feedback signal is available. Additionally, they can incorporate expert interventions, produce explanations for alarm predictions and consider effects of medication on state changes to reduce false alert probability.\n\nThe proposed model represents distributions of patient data (vitals, state and treatment) as a dynamic Bayesian network. The state of the patient is observed only when an alarm is triggered. The arity of the state variable is estimated from data via E-M optimization. The state and another discrete observable, treatment (a vector of administered medications), influence the continuous output variables that represent the vital signs. The vitals are segmented adaptively using a Kalman filter to reflect a potentially nonstationary periodicity of signals. The segmented vitals are then represented with a continuous Semihidden Markov Model. The trained system is capable of predicting the patient's state on-the-fly from currently observed vitals. It can also learn on-the-fly whenever user feedback is available in the form of correct labels of the predicted states.\n\nWe conducted evaluations using the MIMIC II data (5). We used ECG and respiratory rate as input vitals in an attempt to predict heart failure alarms. The results shown in Table 1 were obtained per-patient, by subsampling, using data from the patients held out of the training set. The proposed approach brings the AUC metric (area under the receiver operating characteristic diagram) to 0.66 on average, the patient-specific model offers an improvement, and the inclusion of treatment information provides further benefits.\n\nWe have outlined a probabilistic modeling system that is capable of predicting heart failure alarms using time series of vital signs. It is able to learn the key parameters from data (state and temporal resolution) and allows fast adaptation to personalized features of a specific patient. Tests involving a limited set of vital signs indicate improved predictability of heart failure events when compared to a model relying only on prior probabilities. The next steps involve adding more vital signs to the input space to realize improvements of predictive accuracy. \n\nInfluenza is a major cause of mortality. In developed countries, mortality is at its highest during winter months, not only as a result of deaths from influenza and pneumonia but also as a result of deaths attributed to other diseases (e.g., cardiovascular disease). Understandably, much of the surveillance of influenza follows predefined geographic regions (e.g., census regions or state boundaries). However, the spread of influenza and its resulting mortality does not respect such boundaries.\n\nData on influenza and pneumonia mortality were collected from 97 cities over 11 years (1996 through 2007), as reported in the MMWR (1). We used a novel method of computing the pairwise distance between two time series based on the Mahalanobis Distance derived from the time-series state-space-modeling framework. Mahalanobis Distance is a scale invariant form of Euclidean Distance that also takes correlations of the data set into account. This is an extension of a previously devised Kullback-Leibler Information-based time-series-clustering discrepancy measure (2) . All pairwise distances between cities were then used in a clustering procedure known as QT_Clust (3). This procedure was initially developed for the clustering of high dimensional genomic data. However, QT_Clust may be applied to many time-series-data sets where the trajectory rather than the process of a time series is of interest. A measure of cluster size and within-cluster distance is used to compare how geographically based influenza surveillance performs as opposed to nongeographically based surveillance.\n\nThe average within-cluster distance for the nine census regions is 5205 units. Ignoring geography, we found that our nine largest clusters held 85 of the cities (87.6% of the total cities observed) and maintained an average within-cluster distance of 4918 units. This amounted to a 5.5% reduction in the within-cluster distance. The largest of these clusters held 33 cities from all but one census region and had a within-cluster distance of 4295 units, meaning that its within-cluster distance was 17.5% smaller than that of the mean within-cluster distance of the nine census regions, the largest of which only held 17 cities.\n\nIt is natural to think of geographic proximity as an indicator of how likely a city or region's pattern of influenza mortality mirrors that of another region. However, we hypothesize that the relatively high level of travel within the country will affect the pattern of mortality such that cities across the nation may resemble one another more closely than cities within a predefined geographic region. Our approach involved the creation of a discrepancy measure specifically designed for time series data and the application of a clustering routine that seeks to create high quality clusters (rather than high-inclusion clusters). The largest cluster held roughly a third of the observed cities and yet still had a low within-cluster distance when compared to the geographic census regions. This result suggests that many cities observe similar influenza and pneumonia mortality patterns despite varying geographical locations. There are several limitations to this study. First, while our discrepancy works well in the presence of missing data, a preponderance of consecutive missing time points can negatively affect performance. We determined that 25 cities out of the original 122 cities reported too sporadically for analysis. Furthermore, our clustering technique depends upon the arbitrary selection of a 'quality criterion' that is very data driven. High quality clusters can be obtained, but this often leads to a large number of clusters. Conversely, a small number of clusters can be obtained by lowering the quality criterion. Future work will determine if we can use this time-seriesclustering approach to find repeatable clusters that may or may not suggest changes to current geographic boundaries in an effort to coordinate future influenza surveillance activities. \n\nBased on the definition of the U.S. Centers for Disease Control and Prevention (2), an updated definition of syndromic surveillance was developed, taking into account the evolution of syndromic surveillance in the past decade. Further, an inventory of syndromic surveillance systems in Europe has been started. To identify human syndromic surveillance systems, a literature review was first performed using Pubmed and Google, identifying 40 relevant publications. A brief questionnaire was sent to Triple-S partners, the European Center for Disease Prevention and Control (ECDC) and other contact persons to identify existing, past, pilot and planned systems in the different countries and the reference person for each system. The reference persons were then asked to complete a long online questionnaire for collecting detailed information (e.g., objectives, data sources, timeliness, statistical methods for outbreak detection, reporting tools and response measures).\n\nFor the inventory of veterinary syndromic surveillance systems, a similar method was used. The brief questionnaire was sent to the European Food and Safety Agency (EFSA) focal points and chief veterinary officers of each Member State and to the members of the European College of Veterinary Public Health. Differently from the inventory of human systems, the veterinary inventory included mortality surveillance systems.\n\nEight site-visits to existing systems are scheduled between June 2011 and May 2012, e.g., United Kingdom, France and Denmark/Sweden. Open to 6\u00c110 project partners and participants from all European countries, the visits offer an in-depth understanding of a variety of systems and facilitate knowledge transfer, through discussions on practical experiences with national and regional stakeholders (e.g., strengths and weaknesses of the systems, lessons learned from the operators and users and expectations of decision makers).\n\nThe first output of the project was the adoption of the definition of human and animal syndromic surveillance.\n\nThe initial results from the inventory of syndromic surveillance systems and the geographical distribution of identified systems will be presented. As a result of the literature review and the responses to the brief questionnaire for human systems, 19 active systems, 11 pilot or planned systems and 4 systems for past mass gathering events since 2000 (e.g., Olympic games) have been identified to date. For veterinary systems, only 5 systems were identified by the literature review, whereas 16 active, 7 pilot and 2 expired systems have been identified by the brief questionnaires.\n\nThe first 4-day site-visit took place in the United Kingdom (Birmingham and Glasgow) in June 2011, where there are several systems based on different data sources: emergency departments, general practitioners (Q-surveillance, Piper and SISRS), phone calls to help lines (NHS Direct, NHS24), out-ofhours primary care and pharmacy prescription data.\n\nBy December 2011, four site visits have been conducted. The synthesis of the first visited systems, including their main characteristics and the experiences and lessons learned through those visits, will be presented.\n\nResults from the inventory and the site visits will constitute the foundation for the development of guidelines for improving syndromic surveillance in Europe. Objective To present the Triple-S project, which aims to increase the European capacity for real-time surveillance and monitoring of the health burden of expected and unexpected health-related events.\n\nA European project to develop guidelines to strengthen public health surveillance and rapid response was launched in September 2010 for 3 years, under the name Triple-S (Syndromic Surveillance Survey, Assessment toward Guidelines for Europe). The project, co-financed by the European commission through the Executive Agency for Health and Consumers, involves 24 organizations from 13 countries (Fig. 1) . The DG Sanco, ECDC, WHO/Europe and ISDS are members of the advisory board of the project, to ensure an exchange of practices and expertise at both the European and the global level ( Fig. 1 ).\n\nThe Triple-S project coordinated by the French Institute for Public Health Surveillance (InVS) is divided into six work packages (WP). Three are horizontal managerial WP for coordination, dissemination and evaluation. The other three concern an inventory of existing systems (WP4), country visits (WP5) for knowledge exchange and a deeper understanding of a selected number of systems. WP4 and 5 will lead to the development of guidelines for implementing syndromic surveillance in Europe (WP6).\n\nThe inventory will identify competent organizations and reference persons for animal and human syndromic systems in the European Union. A questionnaire will allow the collection of detailed characteristics of established, pilot and planned systems.\n\nThe Triple-S consortium has adopted a proactive approach to stimulate knowledge exchange through eight country visits.\n\nThe projects's final guidelines will provide scientific and technical guidance and tools for the development and implementation of syndromic surveillance systems for both human and animal health, according to the needs and expectations of the different EU member states taking into consideration the different data sources available and the different aims of syndromic surveillance systems. An additional outcome of the project is to build a sustainable network of organizations, which can provide support and advice on tasks related to syndromic surveillance: management, partnership with data providers and users, statistical methods, definitions of syndromes and dissemination.\n\nFor this, the triple S project will develop links with different projects in the USA and Canada. For organizations planning to start or reestablish a syndromic surveillance system in their own country, this network could help raise awareness of opportunities and of pros and cons of the anticipated syndromic surveillance system.\n\nThe objective of the project is not to create one single European syndromic surveillance system but to review and analyze syndromic surveillance activities across Europe to produce guidelines, while respecting the diversity of health systems and potential data sources for syndromic surveillance across Europe. \n\nBased on the descriptive analysis, a linear yearly trend, the days of the week, the period of school holidays, a seasonal effect and the unusual days (day-off) have a marked effect on the daily fluctuations of ED visits. The pattern of the daily visits during the summer periods has been modeled using a quadratic function. The day-of-week effect has been differentiated by seasonal period of the year. The final model based on the combination of variables explains 78% of the daily variations of the ED attendances and shows a good predictive performance on 2010.\n\nThis study is a first approach to improve the knowledge of the factors that influence the ED visits. In previous work, we proposed a process by which only posts that are based on specific 'important' topics are read, thus drastically reducing the amount of posts that need to be read. The process works by finding a set of 'bellwether' users that act as indicators for 'important' topics and only posts relating to these topics are then read. This approach does not consider the text of messages, only the patterns of user participation.\n\nOur text analysis approach follows that of Cataldi et al. (1), using the idea of semantic 'energy' to identify emerging topics within Twitter posts. Authority is calculated via PageRank and used to weight each author's contribution to the semantic energy of all terms occurring in within some interval ti. A decay parameter d defines the impact of prior time steps on the current interval.\n\nWe considered 3 models of authority: (1) (emerging topic detection) ETD uniform (i.e., equal weight); (2) ETD PageRank; and (3) bellwether. For 1 and 2, we built a directed graph of user activity, using thread coparticipation to define edges. Each EIN post was text tokenized, POS-tagged, and had stop words removed. We use a time window t 0 5 days to aggregate messages terms and a decay parameter d0 60 days. We identified emerging terms using an energy threshold approach, where emerging is defined as any term where energy! k*m energy over the interval t, where k is some constant; we used k 0 1.3. Any term identified as emerging that occurs in the postsubject line is flagged as important. For the bellwether model, we algorithmically selected 80 and 90 authors from the year prior to the one under analysis and flagged threads as important when one of those bellwethers participated in it. We also conducted 1000 random trials of selecting subsets of 80 users to follow.\n\nFor evaluation, we used an annotated set of EIN threads identified as clinically important. We measured the total number of threads each authority model flagged for reading versus the number of actual important messages.\n\nThe performance of each authority method, measured as threads recommended by each model and evaluated over all messages from January 2003 to March 2009 (Table 1) .\n\nThe bellwether model performs best overall, requiring the least messages read while detecting more important threads at less cost of reading unimportant threads. The differences between 80 and 90 bellwethers reflect how parameters influence the tradeoff between these 3 measures. There was no significant benefit gained from viewing the EIN network in terms of a PageRank over equal authority, which aligns with previous work identifying PageRank's limitations in identifying experts (2) . Moreover, compared to randomly selecting 80 authors to follow, the performance is worse with our chosen parameters. Future work will examine incorporating bellwether authority into a textual analysis framework. \n\nWe chose the following aspects of patient care to be included in the database form: presurgery patient condition and medications, anesthesia information, perfusion information, surgery information, recovery information, status of the patient at discharge and30 days and 365 days postsurgery follow-up information. Information was collected through structured questionnaire by trained data abstractor and entered into Microsoft Access software. On the basis of research hypotheses, specific data chunk was extracted and analyzed in SPSS (Statistical Package of Social Sciences) software. Impact in clinical practice Before this database, there was no way to monitor mortality and morbidity. Fortunately, with the development of database, postsurgery mortality and morbidity rates could easily be generated. It helped in development of strict enforcement of protocol to reduce the mortality and morbidity rates. It also helped in controlling preventable postsurgery complications. It also helps in identification of a gap inpatient knowledge regarding the use of warfarin after heart valve surgery and deficiencies in laboratory capabilities, both causing catastrophic complications. As a result, we modified our practice in an effort to address these issues and reduce the complication rates after heart valve surgery. Furthermore, identification of the need to quantify the midterm functional status of in-person and telephonic interview, resulting in the development of a questionnaire that has been added to our protocol 1-year postsurgery.\n\nMore meticulous record keeping, including long-term follow-up for 5 years will be collected. In addition to this, the development of a separate congenital/pediatrics cardiac surgery database will also be developed.\n\nUpdated and stringently maintained database helps to identify deficiencies in practice and provides a direction for future improvement.\n\nDatabase; coronary artery bypass grafting; warfarin; mortality; quality of care; evaluation\n\nThe Ohio Department of Health (ODH) has created a biosurveillance network, which was originally based on the Real-time Outbreak and Disease Surveillance (RODS TM created by the University of Pittsburgh and is now developed as EpiCenter TM and managed by Health Monitoring Systems, Inc. (HMS) (1\u00c13). The web-based system uses advanced statistical algorithms to generate alerts from thresholds that are tuned at the state scale of geography for surveillance of chief complaints during emergency department admissions. Interpretation of output and the use of the system is geared toward trained epidemiologists and infection control practitioners.\n\nThe need to evaluate biosurveillance data within a local, realworld context is necessary to maximize situational awareness at the community level given that: emergencies begin and end as local events, hospital emergency department demographic catchments may vary significantly within a county and some emergency department capabilities may be unique to particular hospitals. With the addition of data analysis methods, which produce intuitive summary visualizations of large data sets, it is hoped that individuals whose training is not as specialized as the EpiCenter TM users will gain a greater understanding of the biosurveillance data and its relevance to the local population.\n\nReusable procedures were created for MySQL TM (4) to load and transform standard EpiCenter TM data exports. Structured Query Language (SQL) statements process export file data elements to create: more granular temporal elements, category groupings to mirror daily activities and generalized lifestyles, categories based on spatial calculations and scores derived from the frequency of symptom and syndrome categories.\n\nAdditional blocks of code were created in R TM (5) for automated analysis, visualization and reporting. The information graphics produced by R with enhanced biosurveillance data includes pivot tables, thematic maps, heatmaps, pictograms and charts. Edits of the code may be done with a text editor, and the local geographic coordinates of zip codes and hospital facilities can be obtained on the Internet.\n\nThe information graphics are to be assembled and annotated as an annual reference resource, Cuyahoga County Hospital Emergency Department Service Utilization Profile (HEDSUP). This output of localized biosurveillance data analysis summarizes the facility admissions, catchment demographics and symptoms using various visualizations, which aim to be understandable by an audience of nonstatistical experts.\n\nFacility specific sections will be made available to hospital infection control practitioners and emergency department managers to evaluate patterns of service utilization and to improve data quality. Local health departments are considered to be the primary users through daily epidemiology and surveillance requiring decision support during disease outbreak investigation and response activities across all hospital emergency departments within a health jurisdiction.\n\nThe high availability of open source components cited above, the ease of integration and minimal development cost may provide low-resource environments, such as local health departments, increased functionality through a sustainable and customizable framework of modular components. The utilization of more intuitive data visualizations will shift the burden of advanced data analysis to a less technical interpretation of information by a broader user base for a greater understanding of local public health dynamics.\n\nVisualization; open source; localized; situational awareness; biosurveillance Introduction An increase in tuberculosis (TB) among homeless men residing in Marion County, Indiana, was noticed in the summer of 2008. The Marion County Public Health Department (MCPHD) hosted screening events at homeless shelters in hopes of finding unidentified cases. To locate men who had a presumptive positive screen, the MCPHD partnered with researchers at Regenstrief Institute (RI) to create an alert for healthcare providers who use the Gopher patient management system in one of the city's busiest emergency departments. A similar process was used at this facility to impact prescription behavior (1). A similar method was also used at the New York City Department of Health and Mental Hygiene (2).\n\nMCPHD and RI created a legal memorandum of understanding so that MCPHD could share the names and date of births of suspect cases to the programmers at RI. The alert went into effect in July of 2010. When a healthcare provider's search is also one of the suspected names, an alert appears on the screen informing the provider that this person should have a chest x-ray as part of a follow-up to a TB outbreak investigation. A phone number of a MCPHD nurse on call is provided. The suspect list is periodically updated to remove names of patients who have been located in other medical settings. The novel aspect of this system is that normal methods of locating these individual such as phone or address was not available. Additionally, other traditional public health methods to contact these patients had not proved successful.\n\nFifty-three different patients have been on the alert list since activation. Only one notification has occurred in the 13 months of activation. On December 1, 2010, the TB program reported that a provider had seen one of the suspect cases and the alert prompted the provider to order a chest x-ray and notify the MCPHD staff.\n\nA review of a hospital patient management system revealed that 12 other patients were seen in the emergency departments while on active alert lists. Some patients were seen more than once while on the list. Some cases showed that the chest x-rays were performed as requested but the patient records did not indicate if the procedure was prompted due to the alert or because the patient presented with symptoms of TB. A review of the process is underway to better understand why these encounters did not provide a notification to the MCPHD.\n\nSeveral MCPHD staff work in local homeless shelters daily looking for the suspect patients. If a staff member prompts an individual to go to the ED, that encounter is not recorded in the MCPHD Patient Management System. Therefore, the provider may ignore the TB alert on these patients since the patient was already suspected for TB.\n\nIn some instances, the patients were seen at the MCPHD TB clinic within a couple of days of being seen at the hospital ED. Again, the records do not indicate if the patient was prompted to go to the TB clinic. Interestingly, no new TB cases among this population were reported for the month of August.\n\nFuture attempts at locating patients: Since many of the identified cases have known psychiatric issues, outreach workers in the TB program are hoping to partner with the mental health community to reach some of the suspect cases. MCPHD is working with a local mental health clinic to create a similar alert in their patient management system. Also, RI may help develop another alert that includes contacts of cases, rather than suspect patients in hopes of completing the first initial screening for that segment of the population.\n\nThe most important outcome is getting the patients tested and treated if infected. Assessing the effectiveness of the alert is difficult due to a lack of encounter data. Only one-fourth of the patients (13 of the 53) visited the emergency department during the year of the alert. This is another reminder that multiple strategies must be used to reach this population for care. Health informatics can be an aid to public health in such endeavors. \n\nThe VHA is the VA organization responsible for providing healthcare to over 5 million patients annually at 153 medical centers and over 900 outpatient clinics across the United States and U.S. territories. The VA Subject Matter Expertise Center for Biological Events (SMEC-bio) aims to leverage data in the extensive VHA electronic health records system and other sources to provide decision support to leadership for emerging infectious disease threats. Initial SMEC-bio work to examine this capability suggested that the increased incidence of dengue disease in the VHA patient population in PR in 2010 may be related to increased rainfall (1). This present work analyzes dengue incidence in the PR VHA patient population over time to understand disease trends and contribute to a framework for predictive analysis.\n\nVHA administrative inpatient and outpatient datasets were queried separately for monthly occurrence of dengue and dengue-like diagnosis codes (ICD-9-CM 061, 065.4, 066.3 and V73.5) in PR for Federal Fiscal Year (FY) 1997 to FY 2011 (up to August). Patients are unique within each FY and are counted at the first occurrence of the noted code(s). Wavelet time series analysis using the Morlet wavelet was performed to identify the presence and scale of periodic components in the inpatient and outpatient time series. Wavelet coherence analysis was subsequently carried out to determine the statistical association R(a,t) between the two time series at multiple periodic scales 'a' and time scales 't' (see equation).\n\nFinally, the phase lag between the two time series was determined by computing their phase difference as the ratio of the imaginary and real parts of the cross-spectrum of the two time series.\n\nWavelet power spectral analysis of the inpatient and outpatient time series identified statistically significant oscillatory modes across different years and at all periodic scales examined* indication of the endemic nature of dengue in PR. Crossspectral analysis of the two time series revealed three distinct areas of significant coherence as seen in Fig. 1 . At the 1-year period, the two time series have strong association during 2004\u00c1present, with waves of outpatient cases lagging behind those of inpatient cases by an average lag time of 7 days (not shown). At the 1.5-year period, the two time series cohere during 1999\u00c12003, indicating that dengue outbreaks did not occur yearly in the VHA population prior to 2004. At the 3.5\u00c14-year period, they cohere across all years in the data, an indication of a multiyear interepidemic period.\n\nEndemic and epidemic signatures of dengue were shown to be present in the PR VHA patient population. Furthermore, an average lag time of 7 days between the epidemic waves of inpatient and outpatient dengue cases was observed at the annual scale, not reported previously. In light of these observations, future studies will examine whether the dengue dynamics in the VHA patient population in PR, coupled with other data such as weather parameters, can be used to forecast dengue epidemics in VHA patients and perhaps inform dengue dynamics in the general population in the region. \n\nIncreasingly, epidemiologists have been tasked with interpreting multiple streams of heterogeneous data arising from varied surveillance systems. However, public health personnel have experienced an overload of plots and charts, as information visualization techniques have not kept pace.\n\nElucidating design objectives based on analysis of current system functionality and gaps in currently available systems; 2.\n\nDeveloping a conceptual model that captures and represents the mental model of the prototypic public health epidemiologist; 3.\n\nDeveloping novel visualization paradigms for the public health domain; 4.\n\nDeveloping sample data set to support development and testing of the prototype.\n\nThe prototype was populated with real world data and used to visualize a gastrointestinal disease outbreak caused by cryptosporidium and respiratory virus outbreaks including influenza and RSV. The prototype was well received by regional epidemiologist practicing in the state and local health departments of Utah.\n\nThe EpiCanvas display provides a novel visualization that facilitates situational awareness. Based on heuristic mental models of end users, this display encourages visual correlation, data interrogation, exploration and discovery (Fig. 1) . The prototype also provides the first iteration of an integrated infectious disease weather map for use by public health professionals.\n\nVisualization; analytics; surveillance \n\nIn this project, we present a robust methodology for evaluating the fitness of the Semi-Na\u00efve Bayesian Network (SNBN) disease model structure used by Geographic Utilization of Artificial Intelligence in Real-Time for Disease Identification and Alert Notification (GUARDIAN)*a real-time, scalable, extensible, automated, knowledge-based infectious disease detection and diagnosis system*for determining the appropriate thresholds, which separate between different 'goodness of fit' categories, and for tuning the model parameters to optimize its applicability within a particular healthcare facility.\n\nEach of the infectious diseases that GUARDIAN monitors is modeled in GUARDIAN's knowledge base as a SNBN (1) of diagnostic features. Each model is developed through extensive literature review by infectious disease experts and encoded as a standardized probabilistic SNBN (2) . GUARDIAN uses these networks to rapidly assess each patient whose data are presented to the system. General model fitness is evaluated using 10-fold cross-validation. The overall, threshold-independent, model quality is determined through analysis of the receiver operating characteristic (ROC) curve (3) of each model using de-identified emergency department patients for the true negatives. To find the thresholds for each relative risk category, we use Gaussian decomposition (4) over the probability distribution of known negatives; known positives of other diseases; and known positives of confirmed, suspected and probable cases of the disease of interest.\n\nTo tune the SNBN model parameters for a particular healthcare facility, we use a hill-climbing algorithm (5) over known positives from literature and a sample of patients (negative and, if available, positive) from that healthcare facility. The hillclimbing algorithm uses the 10-fold cross-validation area under the ROC curve as the metric to optimize.\n\nWe performed the process outlined above for severe acute respiratory syndrome (SARS), because its similarity to influenza presents the largest challenge of all of the diseases in GUAR-DIAN's current knowledge base. Even with this challenge, the area under the ROC curve was 0.929 and was optimized to 0.962 through hill-climbing. Gaussian decomposition showed good fidelity using 5 risk categories (Fig. 1) .\n\nAs we have demonstrated for SARS, GUARDIAN's infectiousdisease knowledge base uses robust models, which accurately discriminate among related diseases with a high level of accuracy, confidently place each diagnosis within its appropriate relative risk category and optimize its performance for a particular healthcare facility. These results illustrate the improvement that disease-specific expert systems, such as GUARDIAN, represent over traditional trend-based anomaly detection systems. The robust process presented here is currently being used to validate GUARDIAN's existing and ever-growing knowledge base containing a number of diseases of interest for public health surveillance. \n\nThe Centers for Disease Control and Prevention (CDC) case definition of influenza-like illness (ILI) as fever with cough and/ or sore throat (1) casts a wide net resulting in lower sensitivity, which can have major implications on public health surveillance and response.\n\nThis is a retrospective cross-sectional study conducted August 1, 2009, to July 31, 2011, in the emergency department of an academic medical center. The sample consisted of 2661 patients who received a nasopharyngeal swab followed by polymerase chain reaction (PCR) testing for respiratory viruses. Geographic Utilization of Artificial Intelligence in Real-Time for Disease Identification and Alert Notification (GUARDIAN)*a syndrome surveillance program*was utilized to review patients' records and detect the presence or absence of 37 influenza-associated symptoms (e.g., rhinorrhea, myalgias, headache and nausea among others) including reported and measured fever, cough and sore throat. Demographic factors such as age groups and gender were included in the analysis. Descriptive and x 2 test were used to determine a subset of significant signs and symptoms. A binary logistic regression with backward selection option was employed to further narrow down significant symptoms.\n\nFemales represented 53.4% of the sample. The percent of positive influenza cases based on PCR results was 9.2% (i.e., 245 cases). The majority of positive influenza cases (55.9%) occurred below 50 years of age. Positive influenza patients with fever, cough or sore throat were 207 (84.5%), 218 (89%) and 56 (22.9%), respectively. Based on x 2 test, fever, sore throat, cough, myalgias or body aches, chills or rigors, rhinorrhea or nasal congestion or sinusitis or nasal symptoms, dyspnea, upper respiratory infection symptoms or viral illness, rash and age groups were statistically significant. Apart from fever and cough, myalgias and rhinorrhea were significant associated symptoms of influenza based on multivariate analysis (Table 1) .\n\nBased on these results, some of the recommended ILI case definitions could be (1) fever with cough and/or myalgias and/or rhinorrhea (i.e., based on only positive odds ratios among symptoms); (2) fever with cough (i.e., based on highest positive odds ratios among symptoms \n\nDetection of BTAs is critical to the rapid initiation of treatment, infection control measures and public health emergency response plans. Due to the rarity of BTAs, standard methodology for developing syndrome definitions and measuring their validity is lacking.\n\nBTA profile development consisted of the following steps.\n\nStep 1: Literature scans for BTAs: articles found in a literature review on BTAs that met predefined criteria were reviewed by multiple researchers to independently extract BTA-related data including physical and clinical symptoms, epidemiology, incubation period, laboratory findings, radiological findings and diagnosis (confirmed, probable or suspected).\n\nStep 2: Data analysis and transformation: articles were randomly divided, taking into account reported diagnosis and sample size, to generate detection (75% of articles), and testing (25% of articles) profiles. Statistical approaches such as combining frequencies, weighted mean, pooled variance, min of min and max of max were utilized for combining the data from articles to generate the profiles.\n\nStep 3: Missing data analysis: based on generated statistical and clinical judgment, specific reasonable assumptions about the missing values for each element (i.e., always reported, never reported, representative and conditionally independent) were applied to the profile. Imputed case analysis (ICA) strategies (1) used these data assumptions to fill in missing data in each metaanalysis of the summary data.\n\nStep 4: Translation: the generated profiles and synthetic positive BTA cases were reviewed (via clinical filters and physician reviews) and programmed into GUARDIAN.\n\nStep 5: Prior probability determination: using archived, historical patient data, the probabilities associated with each element of the profile were determined for the general (non-BTA) patient population.\n\nStep 6: Validation and testing: multiple mutually exclusive samples of ED cases along with synthetic/real positive BTA cases were utilized to perform 10-fold cross-validation as well as testing to generate statistical measures such as positive predicted value, negative predicted value, sensitivity, specificity, accuracy and receiver operating characteristic curve (ROC) for each BTA.\n\nTo demonstrate the applicability and usability of BTA methodology, severe acute respiratory syndrome (SARS) was chosen since differentiating SARS symptoms from regular influenza is difficult and presents challenges for even robust surveillance systems.\n\nLiterature scan yielded 34 articles with 4265 cases and 90 unique signs, symptoms and confirmatory features (frequency data068 and continuous data022) for SARS. After combining the data and assigning the assumptions, there were 18 representative, 63 conditionally independent and 9 confirmatory features. Applying the BTA methodology for SARS, the positive predicted value, negative predicted value, sensitivity, specificity and accuracy based on 10-fold cross-validation were 55.7%, 94.6%, 74.8%, 88.1% and 85.8%, respectively. An ROC curve analysis revealed an area under the curve of 0.929. The main features contributing toward identifying the positive SARS cases were fever, chills/rigors, nonproductive cough, fatigue/ malaise/lethargy and myalgias. The identified features were in agreement with clinicians' judgment.\n\nThe GUARDIAN BTA profile development methodology provides a sound approach for creating disease profiles and a robust validation process even in a BTA (e.g., SARS) that may closely resemble regularly occurring diseases (e.g., influenza). The BTA profile development methodology has been successfully applied to other BTAs such as botulism, brucellosis and West Nile virus, with high sensitivity and specificity.\n\nBiological threat agents; real-time surveillance; surveillance methodology \n\nIn the summer of 2001, New Jersey (NJ) was in the process of developing surveillance activities for bioterrorism. On September 11, 2001, the United States suffered a major terrorist attack. Approximately a month later, anthrax-laced letters were processed through a NJ Postal Distribution Center (PDC). As a result of these events, the state instituted simplistic surveillance activities in emergency departments (EDs). Over time, this initial system has developed into a broader, more streamlined approach to surveillance that now includes syndromic data, e.g., Influenza-like illness (ILI), as well as the use of technology (automated surveys, real-time data connections and alert analysis), to achieve surveillance goals and provide daily information to public health partners in local health departments and DHSS response colleagues.\n\nDaily response rates over time were analyzed to determine whether enhancements to surveillance produced any improvement in participation by EDs. During the timeframe used for the study, the total number of EDs varied due to facility closures and reorganizations and, therefore, daily response was measured by using the percentage of facilities responding each day versus the actual number. \n\nWith each implementation of a new form of data collection and more advanced analysis, the response rate increased (see Fig. 1 ). In addition, the time involved for surveillance activities decreased for DHSS staff since increased automation led to fewer errors and a reduced need for follow up.\n\nAs automation in surveillance activities has increased, participation rates of facilities improved as well. Hospital staff became more engaged when there was a more defined purpose to reporting ED visits and admissions (e.g., The Republican National Convention and the H1N1 Novel Influenza A outbreak). Based on the improvements observed, the state is undertaking a project to move all NJ EDs into a real-time, syndromic surveillance system. This implementation is expected to further enhance data reporting and increase response rates beyond the current 86.4%. \n\nWe used Amazon's EC2 (Elastic Compute Cloud) services to experiment with cloud computing for syndromic surveillance. We applied two cloud service models: Infrastructure as a Service (IaaS) and Software as a Service (SaaS). Our first goal was to apply cloud computing technologies in order to reduce computational time needed for syndromic analyses. Scan statistics, due to their reliance on Monte Carlo simulation to find confidence levels, are particularly well suited to being improved by parallel computation. We used the R package DCluster to calculate scan statistics and combined that with the SNOW (Simple Network of Workstations) package. We also experimented with using cloud computing to parallelize the AMOEBA approach to cluster detection.\n\nOur second goal was to determine the practicality of easing the barrier of software complexity. To that end, we created software packages that include data import, analysis and visual presentation of results and released them as freely available virtual machines, or images, for the public to use. The GeoViz Toolkit was one of the software packages delivered in this manner (Fig. 1) .\n\nWe found that both Infrastructure as a Service and Software as a Service cloud computing service models can help reduce barriers to effective use of sydromic surveillance methods. Easy provision of many computers allowed us to speed up the computational times by an order of magnitude. The creation of integrated software services to perform disease surveillance is the easiest way to deliver complex functionality.\n\nWe conclude that, in the future, cloud computing can and should play a more prominent role in disease surveillance.\n\nCloud computing; scan statistics; informatics Introduction Emergency management during a disaster entails innumerable challenges. Each disaster uniquely shapes the types and timing of information needed both to manage the disaster and to measure the impact on available resources, the environment and community systems. Traditional public health surveillance methods typically preclude providing a real-time, comprehensive estimate of public health impacts related to the disaster while the disaster is unfolding. Traditional methods can also be resource intensive and costly, require active cooperation of medical systems involved in a disaster response and are often conducted postdisaster.\n\nSyndromic surveillance of emergency department (ED) chief complaints and over-the-counter (OTC) medication sales was reinstituted in the Austin area in the fall of 2010. In 2011, the Austin area was hit with three natural disasters: a winter ice storm; a summer of extreme heat/extended drought; and a week of significant wildfires. Each disaster varied greatly in type, size, intensity and duration. The Austin/Travis County Health and Human Services Department (A/TCHHSD), in partnership with Austin/Travis County EMS (ATCEMS), was able for the first time to provide near-real time data to emergency managers on the potential health impact during each of the 2011 disasters using the syndromic and EMS electronic data systems. The data were used to provide situational awareness and guide selected response actions during the course of the disaster, as well as document potential areas for future mitigation efforts.\n\nA/TCHHSD uses two syndromic surveillance systems: (1) Realtime Outbreak and Disease Surveillance (RODS) system* utilizes chief complaint data from emergency department visits in 14 Austin Metro area hospitals; and (2) National Retail Data Monitor (NRDM)* utilizes OTC medications sales data. ATCEMS has an automated system to track the types of calls to EMS and transport to area hospitals. All three systems also provide data on patient age, sex, home zip code and receiving hospital. Information on the use of syndromic surveillance and EMS systems for each natural disaster (ice, extreme heat and fire) will be presented. Each case study will provide information on: (1) salient features of the natural disaster; (2) rationale for the type(s) of surveillance resources employed; (3) data analysis; (4) results; (5) data dissemination; (6) advantages and limitations; (7) lessons learned; and (8) process improvements.\n\nIce storm: Piloted the use of 'keyword' surveillance in our jurisdiction. Local hospitals were asked to include the word 'weather' in the chief complaint of patients presenting to the ED. The major trauma hospital in the Austin area implemented keyword surveillance within 4 hours of the request. Keyword surveillance provided insight into the impact of injuries during the ice storm. This approach was essentially resource neutral, both for the health department and the hospitals. The RODS system was also used to track chief complaints of hyperthermia and exposure. Data were reported twice a day during the ice event.\n\nDrought/heat: This is an ongoing surveillance effort. We will present RODS data and EMS data from May through September 2011 which describe the pattern of heat-related illness over time. The pattern of heat-related illness diverged over time from the heat index. These data were reported to emergency management daily during the most extreme heat index days and weekly for the rest of the summer.\n\nWildfires/smoke incident: We were asked to provide an estimate of the impact of air quality from the wildfires. We examined ED chief complaint data, OTC medication sales and EMS data. These data are still being analyzed.\n\nSyndromic surveillance/EMS data systems are extremely valuable in providing situational awareness during an emergency incident. Use of electronic data systems are essentially resource neutral and can provide near real-time data. These systems do not replace the need for traditional disease/injury surveillance but can help fill a need during a crisis. Response partners must be educated as to the limitations of the systems. \n\nTo demonstrate how event-based biosurveillance, using direct and indirect indications and warning (I&W) of disease, provides early warning and situational awareness of the emergence of infectious diseases that have the potential to cause social disruption and negatively impact public health infrastructure, trade, and the economy (1). Specifically, tracking of I&W during the 2011 enterohemorrhagic Escherichia coli (EHEC) O104:H4 outbreak in Germany and Europe was selected to illustrate this methodology.\n\nArgus is an event-based, multilingual surveillance system, which captures and analyzes information from publicly available Internet media. Argus produces reports that summarize and contextualize I&W of emerging threats and makes these reports available to the system's users (1) . The significance of the EHEC outbreak analyzed here lies primarily in the fact that it raised epidemiological questions and public health infrastructure concerns that have yet to be resolved, and required the development of new resources for detecting and responding to newly emerging epidemics (2) .\n\nArgus reports meeting the following inclusion criteria were reviewed: (1) entities: E. coli and food/crop contamination, (2) location: Germany and the European Union (EU), (3) time period: May\u00c1July 2011. The reports were reviewed for relevant I&W with the primary goal of identifying factors that inhibited effective control of the outbreak and resulted in public health infrastructure strain. Geospatial visualizations of the Argus outbreak reports were created as the event unfolded.\n\nOn May 23, a surge in EHEC infections was reported at hospitals mainly in northern Germany; the outbreak was unusual in that it caused atypically severe symptoms in adult females. By May 26, state health authorities had identified over 600 EHEC cases, including 214 severe cases with hemolytic uremic syndrome (HUS), and confirmed the causative agent as a highly virulent HUS-associated EHEC 41 strain belonging to serotype O104:H4. Faced with a rapidly growing number of cases, health authorities notified the EU of a potential public health emergency of international concern and implemented new surveillance systems (2) . Media reports suggested that the public health infrastructure was strained to a breaking point, as hospitals in northern Germany issued appeals for blood donations and transferred cases to hospitals in neighboring states. These problems were compounded by the lack of an effective HUS treatment, causing health officials to resort to an emergency experimental treatment instead. As the outbreak continued to spread, up to 130 cases primarily associated with travel were detected in 13 other European countries (3). The EU responded by implementing a new case definition twice over the course of 1 month, to allow for effective surveillance and treatment of cases (3, 4) . By June 29, an investigation launched by the European Food Safety Agency (EFSA) had determined that contaminated fenugreek seeds imported from Egypt were the most probable source of the outbreak (3, 5) . Previous efforts to locate the source of infection had failed, resulting in strained trade relations and major economic losses among EU member states (3). On July 26, Germany's Robert Koch Institute (RKI) declared the outbreak over and reported a cumulative total of 4321 EHEC cases, including 852 HUS cases and 52 fatalities (6) .\n\nThis study highlights the challenges faced in providing a timely response to a rapidly spreading infectious disease outbreak and the role that event-based biosurveillance can play in quickly identifying areas for public health intervention. Argus reporting identified that the EHEC outbreak fundamentally challenged the public health system in Germany, by exposing deficiencies in infectious disease surveillance. More importantly, it evidenced that even a strong public health system must be able to adapt rapidly to challenges posed by the changing epidemiology of infectious diseases (2) . To that end, an interdisciplinary approach to event-based biosurveillance that allows for the timely detection of outbreaks and astute analysis of pertinent I&W is of paramount importance.\n\nEvent-based biosurveillance; infectious disease; social disruption; E. coli O104:H4; food contamination\n\nIn 2010, as rules for the Centers for Medicaid and Medicare Electronic Health Record (EHR) Incentive Programs (Meaningful Use) (1) were finalized, ISDS became aware of a trend toward new EHR systems capturing or sending emergency department (ED) chief complaint (CC) data as structured variables without including the free-text. This perceived shift in technology was occurring in the absence of consensus-based technical requirements for syndromic surveillance and survey data on the value of free-text CC to public health practice.\n\nOn January 31, 2011, ISDS, in collaboration with the CDC BioSense Program, recommended a core set of data for public health syndromic surveillance (PHSS) to support public health's participation in Meaningful Use. This study was conducted to better support a requirement for ED CC as free-text, by investigating the relationship between the unstructured, freetext form of CC data and its usefulness in public health practice.\n\nPHSS analysts from 40 public health agencies that contribute syndromic data to the ISDS Distribute project were asked to take an online survey.\n\nThe survey, developed in consultation with state-and locallevel syndromic surveillance experts and implemented using SurveyMonkey \u2020 , consisted of 15 questions, which were crafted to obtain data in four areas: (1) basic system design and coverage;\n\n(2) CC data formatting and classification practices; (3) CC data use; and (4) impact of codifying CC on PHSS capabilities.\n\nParticipants had 2 weeks to complete the survey. ISDS staff contacted nonrespondents to encourage participation 7 and 3 days before the end of the survey period. Qualitative survey data from open-ended questions were reviewed and grouped into themes or categories.\n\nPHSS epidemiologists or analysts from 87.5% (35 out of 40) of the Distribute-contributing health authorities completed the survey. Within the respondent group, 9 cover local jurisdictions, 25 state jurisdictions, and one was from CDC BioSense. Combined, the 35 agencies captured EHR data from 1344 ED.\n\nSurvey results revealed that 97% of participants receive ED patient CC data in free-text (Fig. 1) . ED triage staff presumably capture these data in an EHR, based on a patient's presenting condition as an open-ended, unstructured memo. Some survey participants also reported receiving ED CC in coded formats, either as ICD-9 codes (34%) or as text from a drop-down menu (20%).\n\nA majority of survey respondents (74%) reported having used free-text CC to monitor public health in over 17 different emergencies over the past 2-3 years. Most frequently, free-text CC was used to monitor the impact of H1N1, heat waves, infectious disease outbreaks, and winter storms.\n\nThrough a national survey of PHSS epidemiologists, ISDS identified that public health agencies benefit from free-text CC data, and this format needs to be maintained. ISDS also learned that as newly certified EHR systems are switching CC from freetext to a structured format, the advantages for making this transition are not fully known to public health practitioners.\n\nSyndromic surveillance; Meaningful Use; free-text; EHR Introduction NC DETECT provides near-real-time statewide surveillance capacity to local, regional and state-level users across NC with twice daily data feeds from 117 (99%) emergency departments (EDs), hourly updates from the statewide poison center and daily feeds from statewide EMS runs and select urgent care centers. The NC DETECT Web application provides access to aggregate and line listing analyses customized to users' respective jurisdictions. The most active users are state-level epidemiologists (DPH) and hospital-based public health epidemiologists (PHEs). The use of NC DETECT is included in PHE job descriptions, and functionality has been developed specifically to meet their surveillance needs, including data entry of aggregated laboratory results for flu and respiratory panels. Interviews of local health department (LHD) users completed as part of an evaluation project have suggested that functionality specifically tailored to LHDs may increase their use of the NC DETECT Web application (1). As of June 2011, there were 139 LHD users with active NC DETECT accounts (out of 384 total users with active accounts). Methods Initial information-gathering sessions were held with DPH stakeholders on April 7 and 12, 2011. Mock-ups based on these meetings were discussed with LHD focus groups on April 13 and 14 via Web conference. A later version of the prototype was shown in person at a health department epidemiology team meeting on May 13, and feedback from that meeting was incorporated into the initial release of the dashboards, which were made available to LHD users on June 14, 2011. On June 21, 2011, drill down functionality was added to the dashboards, and on June 30, 2011, the dashboards were made available to DPH users. The dashboards were developed in Java to integrate with our existing Web application using Java and jQuery.\n\nThe dashboards are organized by tabs; current tabs include Overview (Fig. 1) , Hot Topics, Heat, Animals/Vectors, Hurricane, Foodborne, PHE Weekly Report summary and users comments on signals and events investigations. The tabs will change in subject in the fall and winter months, e.g., including a Flu tab. The average number of LHD logins into the NC DETECT Web application has not increased significantly since the release of the dashboards (Fig. 2) .\n\nAverage LHD logins per week for June and July 2011 (n 015) are significantly lower than for PHEs (45 per week on average for 12 total PHE level users). Dashboard interfaces may be particularly beneficial and used more during large scale events of public health significance monitoring, e.g., the 2012 Democratic National Convention in Charlotte, NC. We will continue to work with LHD users to design easy-to-use reports to meet their surveillance needs.\n\nDashboards; all-hazards surveillance; user interface design \n\nTo explore the possibility of using statistical methods to detect Shigella outbreaks, assess the effectiveness of the methods to signal real outbreaks, provide manageable information for follow-up activities and avoid unnecessary surveillance work.\n\nShigella remains highly infectious in the United States, and rapid detection of Shigella outbreaks is crucial for disease control and timely public health actions. The New York State Department of Health (NYSDOH) implemented a Communicable Disease Electronic Surveillance System (CDESS) for local health departments (LHDs) to collect clinical and laboratory testing information and supplement epidemiologic information for the patients from New York State, excluding New York City, with infectious diseases. The CDESS includes reported cases that are involved in outbreaks and which constituted the base for identifying any outbreak. The selection of a fitted outbreak detection method would play a critical role in enhancing disease surveillance.\n\nWeekly case numbers were obtained from CDESS and counted patients with Shigella who had diagnosis or specimen collection dated between January 1, 2006, and December 31, 2010. Six statistical models were applied to the weekly case numbers in generating signals to identify outbreaks, and signals were compared to the actual outbreak to evaluate their detection powers. Outbreak-related cases from CDESS were removed for the modeling purpose except for the cumulative sum-related methods, which used all cases. The sensitivity (SE), specificity (SP), positive predictive value (PPV) and negative predictive value (NPV) were calculated to evaluate the performance of each method.\n\nGeneral Linear method (GL) Yt0a'abi ct; i; i01 . . . 52; where Yt is the expected number of cases in week t, ct,i is the dummy value which equals 1 if the week of the year for Yt is the same as i, else it equals 0.\n\nIt applies the same statistical procedure as GL except for the assumption that the case numbers follow Poisson distribution.\n\nYt0a'bt'c1sin(2pt=52)'c2sin(4pt=52)'c3sin(6pt=52)' d1cos(2pt=52)'d2cos(4pt=52)'d3cos(6pt=52)'at; where Yt is the expected number of cases in week t, and at is the random error.\n\nA signal was generated when the case number exceeded the 95% confidence limit for the prediction value from the above three methods.\n\nA signal was created when the case number exceeded the baseline mean, i.e., mean of previous two weeks, plus three standard deviations.\n\nHistorical Limit method (HL) Similar procedures applied as CuSum except that data for the prior 8 weeks of the last year were used as the baseline.\n\nNegative Binomial CuSum method (NBC) Prior 8 weeks of data excluding current week were used to calculate the baseline mean and variance, which derived the NBC parameter. A signal occurred when the parameter exceeded the threshold value.\n\nFor the purpose of evaluations, an outbreak week was defined as any week that had over two outbreak-related cases during the study period.\n\nFourteen outbreak weeks were identified to evaluate the detection ability of the six methods. The The SPs did not vary much across six methods while the SE of the PO method was higher than the rest. The PPV ranged from 11% to 63%, and the NPV did not vary greatly. The total numbers of signals generated from the PO and NBC methods were higher than the rest.\n\nAmong the above six methods, the PO method had the ability to detect a high percentage of true outbreaks. However, the high number of signals and the relatively low PPV indicated the limitations of the PO method. Other information such as geographical clusters should be considered in determining further public health investigations as needed.\n\nThere is national recognition of the need for cross-programmatic data as well as system coordination and integration for surveillance, prevention, response and control implementation. To accomplish this, public health must develop an informatics competency and create an achievable roadmap, supported by performance measures, for the future. Within the New York State Department of Health, Office of Public Health (OPH), a cross-organizational and cross-functional Public Health Information Management Workgroup (PHIM-WG) was formed to align public health information and technology goals, objectives, strategies and resources across OPH. In June 2011, the OPH Performance Management Initiative, funded by the Centers for Disease Control and Prevention's National Public Health Improvement Initiative, offered strategic planning workshops, funded by the Association for State and Territorial Health Officials (ASTHO), to PHIM-WG.\n\nSenior management of the major programmatic areas within OPH including, Communicable and Chronic Disease, Family Health, HIV/AIDS, Environmental Health and Wadsworth Center Laboratory, identified representatives to participate in PHIM-WG. Informatics, information technology (IT) and information management (IM) literature was reviewed to determine a framework upon which to build the strategy (1). Words and concepts with multiple interpretations were identified and agreed-upon definitions were used for planning discussion. An assessment of the as-is and desired state formed the basis of the strategic objectives and destinations. A community-balanced scorecard (CBSC) approach (2), grounded in the Public Health Accreditation Board Essential Services (PHAB-ES), is being used to guide the development of a strategic plan, to include performance metrics.\n\nPHIM-WG includes physician, epidemiology, program management, policy and planning, IT, quality improvement and project management representatives. IM, composed of the integration of program, processes, policy and technology, was the selected framework. An initial informatics lexicon was developed. Using CBSC, identified strategic destinations were aligned with PHAB-ES objectives, which were then adapted and aligned with the IM framework. An IM vision and strategy map, including strategic objectives and destinations, were produced. Public health IM desired state, objectives, and activities were linked to the PHAB-ES within four major community perspectives; health status, implementation, process and learning, and assets. PHIM-WG is working to produce a more-fully developed strategy and implementation plan, including engaging internal and external partners, defining associated performance metrics to measure progress to the desired state and aligning with NYSDOH strategic planning efforts.\n\nAs a cornerstone of public health, IT/IM should be and can be aligned with or directly linked to the public health essential services. The development and promotion of a common informatics lexicon and workforce engagement and training are critical to public health, especially for advancing data analysis, use, and dissemination capabilities. PHAB-ES-based IM strategic planning can be an essential first step for community collaborators to define the vision, objectives and measurable activities to advance the technology, research and practice of public health surveillance.\n\nInformatics; information management; strategic planning; public health; cross program\n\nBeginning on March 13, 2011, ACDC experienced an unusual increase in reported bacterial meningitis cases in Los Angeles (LA) County. Early in the investigation, there were few epidemiological links between the cases. Three cases were homeless; two resided at the same Skid Row shelter in downtown LA. ACDC assessed its syndromic surveillance databases to help gauge the scope of the outbreak and detect potentially overlooked cases.\n\nElectronic ED chief complaints (CC) from January 1, 2011, to April 10, 2011. were queried from eight EDs within an 11-mile radius of Skid Row. Only visitors with resident zip codes that corresponded to Skid Row or that were blank to account for homelessness were included. Visits were reviewed if CC included keywords based on common meningitis symptoms and also those of confirmed cases.\n\nCoroner deaths from the same time period were reviewed for location of death and homeless status. Real-time LA City emergency dispatch calls were also reviewed if they were made from the same homeless shelter in which the two confirmed cases resided.\n\nTwo hundred and thirty-eight ED visits met the meningitis syndrome definition; however, there was no substantial increase ( Fig. 1 ). Within the same zip code catchment area, there were no ED visitors with mention of homelessness or shelter residence in their CC.\n\nThere was no overall increase in the total number of homeless coroner deaths. Two of 45 deaths took place in shelters*one death in January from 'cardiomyopathy' that occurred at the homeless shelter of interest, and another nonspecific shelter death in March from 'strep pneumonia'.\n\nForty-one 911 ambulance calls were made from the homeless shelter associated with the confirmed meningitis cases. While there was no overall increase in call volume, one call matched a confirmed case fatality.\n\nOne limitation of ED data in this investigation is that they do not contain patient resident addresses, making restriction to the homeless or shelter residents impossible. While no additional cases were found, the absence of an increase provides validation that a large countywide outbreak had not occurred.\n\nBoth coroner and 911 call databases were more flexible than ED data, containing fields facilitating focused queries on the key epidemiological links of homelessness and shelter residence. Coroner data are limited, however, in that there is a 2-day reporting lag. While many homeless deaths were found, few had precisely reported death locations.\n\nMany 911 calls were reported from the shelter of interest. While medical information was vague, additional details enabled ACDC to match one call to a confirmed case. Follow-up for diagnosis information is possible when ED transportation information is present. Precise caller locations make 911 calls particularly useful for investigations with a strong emphasis on location such as point source outbreaks. Querying preestablished ED visit, coroner death, and 911 call feeds can provide a relatively quick supplement to traditional outbreak investigations.\n\nCoroner; 911 call; dispatch; emergency department; outbreak \n\nChronic diseases are the leading causes of mortality and morbidity for Americans but public health surveillance for these conditions is limited. Health departments currently use telephone interviews, medical surveys and death certificates to gather information on chronic diseases but these sources are limited by cost, timeliness, limited clinical detail and/or poor population coverage. Continual and automated extraction, analysis and summarization of EHR data could advance surveillance in each of these domains.\n\nWe leveraged the Electronic medical record Support for Public Health (ESP) surveillance platform to create a chronic disease surveillance module. ESP is an open source software (esphealth.org) that reads structured EHR data, analyzes them for events of public health interest and communicates findings to public health agencies. We created algorithms to identify diabetes types using a combination of diagnosis codes, laboratory tests and medication prescriptions. We then applied these algorithms to the ESP installation in Atrius Health, a multisite, ambulatory practice with over 700,000 patients. We programmed ESP to create patient level linelists each night that detail patients' demographics (age, sex, race/ethnicity and zip code), vitals (body mass index, blood pressure and pregnancy status), key laboratories (hemoglobin A1C and cholesterol levels), diabetes type and care (medications and medical nutrition counseling). De-identified linelists are transmitted nightly to a secure website called the 'RiskScape' that automatically maps selected health indicators and stratifies results by age group, race/ethnicity, year of diagnosis and body mass index. Users can customize indicators and stratifications displayed by RiskScape.\n\nThe RiskScape presents a timely, clinically rich picture of the health of large populations using EHR data that is refreshed nightly. Examples of RiskScape views and report options are shown in Fig. 1 and 2. Fig. 1 maps the rate of nutrition referrals by zip code amongst women with gestational diabetes. Fig. 2 stratifies these results by age and race/ethnicity within the greater Boston area and compares them to statewide averages.\n\nAutomated analysis and presentation of EHR data can provide a rich, timely picture of chronic disease prevalence, care and complications for large populations. This technology has a great potential to advance public health practice by highlighting specific populations with gaps in care that merit targeted interventions. \n\nMuch progress has been made on the development of novel systems for influenza surveillance (1, 2) or explored the choices of algorithms for detecting the start of a peak season. The use of multiple streams of surveillance data has been shown to improve performance (3) but few studies have explored its use in situational awareness to quantify level or trend of disease activity. In this study, we propose a multivariate statistical approach, which describes overall influenza activity and handles interrupted or drop-in surveillance systems.\n\nA multivariate dynamic linear time series model was fitted to data on influenza-like illness (ILI) rates among networks of public and private general practitioners and school absenteeism rates, plus drop-in fever count data from designated flu clinics (DFC) that were created during the pandemic. The data streams were assumed to follow an underlying latent process with local linear trend. The estimated level and trend of the latent process reflect the magnitude and direction of influenza activity, which are then combined to infer an overall influenza activity index. Correlations between the estimated influenza level from the model and laboratory isolation rate were calculated to assess its performance before and during the 2009 pandemic.\n\nILI rates from public outpatient clinics and the estimated influenza level from the multivariate model had the highest correlations with laboratory isolation data before the 2009 pandemic (r00.57 and 0.58, respectively) but the former was interrupted during the pandemic period due to activation of the DFC. The estimated influenza level from the multivariate model captured the influenza level well during the pandemic period (r00.76), significantly better than the best surveillance data in the same period (p-value 00.03). The inferred influenza activity index is able to reflect the influenza activity (Fig. 1) .\n\nThe use of a multivariate method to integrate information from multiple sources of influenza surveillance data can improve situational awareness of influenza activity, with the advantage of maintaining performance when data streams are interrupted or supplemented by additional systems during certain critical periods such as the 2009 influenza pandemic.\n\nKeywords Sentinel surveillance; influenza; multivariate analysis; pandemic Introduction NPDS is a national database of detailed information collected from each call, uploaded in near real-time, from the 57 participating regional poison centers (PCs) located across the United States. NPDS is owned and operated by the American Association of Poison Control Centers (AAPCC). Since 2001, scientists from the Centers for Disease Control and Prevention collaborated with AAPCC to use NPDS for surveillance of chemical, poison and radiological exposures. In March 2011, a 9.0 magnitude earthquake and tsunami damaged the reactors at the Fukushima Daiichi nuclear power plant in Japan, causing a radiological incident classified as a 'major accident' according to the International Nuclear Event Scale. The incident resulted in the release of radioactive iodine (I\u00c1131) into the global environment, which was detected in precipitation in parts of the United States. While no adverse health effects were expected, concerned citizens contacted public health officials at the local, state and federal levels. Many started to acquire and use potassium iodide (KI) and other iodide-containing products intended for thyroid protection from I\u00c1131, even though this was not a public health recommendation by state and federal public health agencies. Shortly after international media coverage began, regional PCs began receiving calls regarding the Japan radiological incident. State and federal health officials were interested in identifying health communication needs and targeting risk communication messages to address radiation concerns and KI usage recommendations as part of the public health response. This was done in part through NPDS-based surveillance.\n\nA new, unique event code was created for staff of all 57 regional PCs to use for coding calls related to this incident. This enabled CDC and AAPCC to track incident-related information requests and exposure calls using NPDS. Calls involving either information requests or reported exposures to radiation, potassium iodide and other iodide-containing products were identified, reviewed and tabulated daily. For each exposure call, individual PCs were then contacted by AAPCC officials to obtain additional data not uploaded to NPDS. CDC epidemiologists and toxicologists reviewed these data daily using set criteria to determine if a true exposure had occurred. Aggregate NPDS data were reported daily to CDC's Emergency Operations Center leadership to enhance situational awareness.\n\nDuring the time period that the CDC Emergency Operations Center (EOC) was activated for this response (March 11 to April 18), there were 404 calls nationally regarding the Japan radiological incident. Three hundred and forty (84%) were calls requesting information about KI, iodide/iodine containing products or radiation associated with the Japan radiological incident. The remaining 64 calls (16%) were potential incidentrelated exposure calls. Of these, KI (n020), other iodidecontaining products (n017) and radiation (n 015) were reported most frequently. The number of information calls peaked on March 16 (n054), and the number of exposure calls peaked on March 17 (n09). Thirty-four (53%) of exposure calls were confirmed KI and iodide/iodine containing product exposures, 23 (36%) were calls regarding incident-related exposures, which were unable to be confirmed, and 7 (11%) were determined to be nonexposures.\n\nCollaboration between CDC, AAPCC and PC staff were crucial to surveillance efforts during the Japan radiological incident response. National surveillance using NPDS demonstrated utility for conducting near real-time human health effects and exposure surveillance associated with a known public health emergency. Surveillance efforts identified confirmed exposures to KI and iodide-containing products. The CDC used this information, along with other media sources, to identify health communication needs and implement appropriate health messaging. \n\nWe assessed destination information from the EDN system for immigrants and refugees arriving during 2009 and 2010 with TB disease (Class A TB with waiver) or a radiographic TB without positive smear or culture for TB (Class B1), or LTBI (Class B2), or contact with a TB case. The destination information was mapped with ArcGIS software to the county level and aggregated at the national level. Data were categorized by region according to the 10 Agency for Toxic Substances and Disease Registry (ATSDR) regions (5) . Since the change of location after arrival can be entered into the EDN system by the health department, this information was assessed for the system's ability to provide secondary migration information.\n\nThe \n\nOver one third of immigrant and refugee arrivals with TB notifications were in the region comprising Arizona, California, Hawaii and Nevada. The increase in TB notifications in this region was attributed to those born in Vietnam. Secondary migration data were available, but the relatively early change in locations may indicate corrections to initial destination data rather than true secondary migration.\n\nTuberculosis; immigrants; refugees; electronic disease notification; EDN\n\nModern public health surveillance systems have great potential for improving public health. However, evaluating the performance of surveillance systems is challenging because examples of baseline disease distribution in the population are limited to a few years of data collection. Agent-based simulations of infectious disease transmission in highly detailed synthetic populations can provide unlimited realistic baseline data.\n\nDynamic social networks for the Boston area (4.1 million individuals) were constructed based on data for individuals, locations and activity patterns collected from the real world. We modeled a full season of endemic influenza-like illnesses (ILI), healthcare seeking behavior and a surveillance system for outpatient visits. The resulting in silico surveillance data contain the demographics and complete history of disease progression for all individuals in the population; those who are in a specified surveillance system create a data stream of ILI visits. Outbreaks of influenza are artificially inserted into this surveillance data. Outbreak detection using space-and-time scan statistics was used to analyze the background with and without the inserted outbreaks. The performance of the algorithm was assessed under different levels of coverage and catchment distributions. One hundred unique baseline data sets were generated. Twelve artificial outbreaks were inserted in each. Six different surveillance system designs were assessed.\n\nWe present a robust framework for using highly detailed simulations to provide the foundation for evaluating and designing a surveillance system's ability to detect outbreaks. A small demonstration study shows that detection rates varied from 17% to 80% across the different surveillance systems. Increased coverage did not linearly improve detection probability for all surveillance systems. Surveillance systems with uniform coverage of the population did not perform better than one based on a real-world system with nonuniform coverage. Higher coverage improved the timeliness of detection but, for most cases, by only 1 or 2 days on average. Additional results can be found online (http://ndssl.vbi.vt.edu/insilicoSurveillance/).\n\nHighly detailed simulations of infectious disease transmission can be configured to represent nearly infinite scenarios, making them a powerful tool for evaluating the performance of surveillance systems and the methods used for outbreak detection. \n\nThe 'wisdom of the crowd' or the 'crowd trial' is a process of taking into account the collective intelligence of a large population sharing experiences regarding health issues and treatments online via social media platforms [Health 2.0], generating novel data sets comprising massive unstructured user-generated content of health reports.\n\nUnlike regulated formal postmarketing reports, the crowd trial takes place spontaneously, continuously and on a very large scale. This crowd trial provides a snapshot of health trends and has become a proxy of postmarket clinical trials of medications and other therapies.\n\nThe purpose of this case report is to demonstrate how applying an additional data source originated from e-patient reports helps support drug surveillance and pharmacovigilance processes.\n\nSingulair (Montelukast Sodium) is a leukotriene receptor antagonist, indicated to prevent asthma attacks in adults and children. It is also used to relieve allergies in adults and children.\n\nSingulair was approved by the FDA in February 20, 1998. In March 2008, the FDA informed healthcare professionals of investigating the possible association between Singulair usage and behavior/mood changes, suicidality and suicide.\n\nFirst Life Research (FLR) identifies, analyzes, indexes and aggregates user-generated content by collecting billions of testimonials from social networks. It utilizes cutting edge technologies for massive data aggregation and applies advanced natural language processing (NLP) techniques for continuous analyses, in order to convert this unstructured data into refined information.\n\nWith the proliferation of social networks, the web has become a warehouse of patient discussions and reports, estimated at 10 billion records and growing at a rate of 40 percent per year. These reports are spread across more than 150,000 (and growing) English-language sites, forums and blogs. FLR has searched and mapped thousands of these sites and indexed hundreds of millions of posts (currently 800M) and is engaged in refining statistical methods of signal detection that enables investigation of health trends. FLR can look at large samples and discover small changes, such as drug side effects, which may not be discovered by other means for years.\n\nIn this case, FLR detected the mentioned FDA alerts and related clinical manifestations prior to the official alert by 'listening' to the 'crowd trial', in that case, the Singulair users. \n\nThis report shows that by 'listening' into the social web, unforeseen phenomena may be revealed. Specifically, it is evident that advanced technological solutions and signal detection algorithm were able to detect neuropsychiatric events (side effects) in the case of Singulair, more than 2 years prior to any official warning by the regulator or the manufacturer.\n\n'Crowd trial' provides a dashboard of health trends and grants feedback on medications, drug safety, side effects, interactions and drug comparisons.\n\nThe insights gained and demonstrated as aforementioned can be used to support and enable better informed decision making processes, both for patients and healthcare providers.\n\nDrug surveillance; user generated content; crowd trial; adverse drug reaction\n\nThe emerging 'wisdom of the crowd' analytics potentially represents a new phase and eventually new tools using data evaluations based on large scale population inputs, and it will benefit greatly all public health environment. \n\nThe American Recovery and Reinvestment Act (ARRA) initiated a broad range of national implementation activities. In order to support the critical activities of meaningful use (MU), ONC established the S&I Framework. In the beginning of 2011, the Laboratory Reporting Interface (LRI) Public Health (PH) Work Group (WG) was formed as a subworking group of the S&I Framework LRI activity. This LRI PH WG, besides providing PH required data elements to the LRI, assessed a need for documentation of the broad landscape of public health data exchange transactions. As a result, this WG recommended to participants and leadership of the ONC S&I that a new initiative, the ONC S&I PH-R activity should be established. In July 2011, a team of PH practitioners (co-authors of this presentation) started working on a charter and proposed deliverables for the group.\n\nFindings by ONC S&I LRI PH WG demonstrated that there are significant gaps in development of (a) functional requirements for PH-R and (b) interoperable standards-based specifications that support PH-R electronic data exchange from clinical care to public health and within public health. In order to strengthen PH-R, the S&I PH-R activity defined the following priorities: (1) Compile the full picture of all aspects of PH reporting; (2) Review and define public health and patient safety business processes and functional requirements and develop \u00c1 HIT interoperability specifications; (3) Align public health objectives in MU Stage 1 with the needs of other public health domains and programs that were not explicitly mentioned in MU Stages 1; (4) Develop a roadmap for aligning public health, patient safety and clinical objectives in MU with regards to HIT standards, development, harmonization, testing and certification; (5) Develop a roadmap for deploying standard-based certified HIT applications in PH agencies and for patient safety reporting.\n\nEven though practical tasks of the S&I PH-R initiative are at the initial stage, this activity will evolve into an important national forum that embraces stakeholders critical for improvement of population health tasks including system vendors, clinical care and public health professionals. Addressing gaps in interoperability of data exchange between clinical and population care should foster progress in situational awareness, PH emergency response and quality of population care.\n\nPublic health reporting; ONC S&I; informatics *Nikolay Lipskiy E-mail: dgz1@cdc.gov Introduction Using an EHR system, we tracked an outpatient population from a series of primary care providers to identify ILI as part of a multistate effort directed by the Centers for Disease Control and Prevention. From these patients, we also collected deidentified project-specific information and symptoms using an electronic template to evaluate possible differences among patient groupings as well as longitudinal population patterns.\n\nWe selected a series of providers using NYC DOHMH's EHR network, from which we could obtain practice characteristics (i.e., number of patient visits, type of practice and age distribution) and evaluation score developed to rate a practice's ability to use EHRs. We then set up an electronic template at each practice and scheduled the transmission of a report with de-identified patient characteristics and patient counts. Nasopharyngeal samples were collected from each patient presenting with ILI to test for influenza subtypes including influenza A (H1, H3 and H1N1) and influenza B by RT-PCR. Samples negative for influenza were tested for other respiratory viruses including rhinovirus, metapneumovirus (MPV), respiratory syncytial virus (RSV), parainfluenza virus (PIV) and adenovirus by RT-PCR by Luminex. We analyzed the data for completeness to evaluate the success of electronic surveillance. We also compared the data by gender, age group, symptoms as well as evaluated virus frequency over time.\n\nCompared to paper-based records, EHR-based tracking reduced time and manpower requirements by the automation of data acquisition from each practice and improved capabilities for determining ILI incidence by reporting a patient denominator along with the number of ILI cases. Proper training and selecting the right practice played a large role in that success. Some initial challenges included providers overlooking the symptomology associated with ILI in the CDC guidelines, which led to failing to identify ILI cases and unfamiliarity with the electronic template. This was especially an issue in a larger practice that had a large number of rotating staff.\n\nThe results of PCR testing for influenza subtypes evolved from almost exclusively H1N1 in 2009\u00c12010 to the cocirculation of H1N1, seasonal H3 and influenza B in 2010\u00c12011. Luminex testing was only performed in 2010\u00c12011, and we found that rhinovirus and MPV were most common and were present over most of the season. Other viruses showed peaks at certain times of the year.\n\nThis project demonstrates that EHRs can improve surveillance capabilities by streamlining and standardizing reporting. This can help to establish a more sophisticated reporting tool using gold standard methods on a larger scale, which will in turn improve public health by providing information on the most common circulating virus at the time of diagnosis, and especially in the event of outbreaks such as pandemic H1N1. In addition, longer term longitudinal use of EHRs for this type of surveillance can determine whether the pattern observed one season is repeated the next.\n\nKeywords Electronic health record system; influenza-like illness; surveillance; influenza\n\nThe status of each ICU patient is routinely monitored, and a number of vital signs are recorded at subsecond frequencies (1), which results in large amounts of data. We propose an approach to transform this stream of raw vital measurements into a sparse sequence of discrete events. Each such event represents significant departure of an observed vital sequence from the null distribution learned from reference data. Any substantial departure may be indicative of an upcoming adverse health episode. Our method searches the space of such events for correlations with near-future changes in health status. Automatically extracted events with significant correlations can be used to predict impending undesirable changes in the patient's health. The ultimate goal is to equip ICU physicians with a surveillance tool that will issue probabilistic alerts of upcoming patient status escalations in sufficient advance to take preventative actions before undesirable conditions actually set in.\n\nTo generate potentially informative events from vital signs, we first segment each data channel into sequences of k consecutive measurements. We then perform Fourier transformation to obtain spectral profiles of each segment of raw signal. Multiple spectral profiles, extracted from periods of observation that are considered medically benign, are then assembled to form a kdimensional flat table. We apply principal component analysis to this, and the top p components are considered further. These p components form a null space model of the expected normal behavior of the given vital sign. We build one null space model for each channel separately; this concludes the learning stage of the process.\n\nEach newly observed set of k consecutive measurements is then processed through Fourier transform and projected onto the p principal components of the corresponding null space models. Over time of observation, these projections produce p time series per measurement channel. We apply a cumulative sum (CuSum) control chart to each of these time series and mark the time stamps at which CuSum alerts are raised. These moments correspond to circumstances in which the observed spectral decomposition of a vital sign does not match what is expected. We consider each such event as potentially informative of near-future deteriorations in the patient's health status. We quantify the predictive utility of each type of these automatically extracted events using training data, which contain actual health alerts, in addition to the vital signs data. To accomplish the task, we perform an exhaustive search across all pairs of CuSum event types (inputs) and alert types (outputs) and identify pairs with high values of the lift statistic (2). Input-output pairs with lifts significantly greater than 1.0 can be expected to enable prediction of health status alerts. Fig. 1 depicts an example result obtained with the presented method. The CuSum Events (green spikes) obtained for the 9th principal component of Modified Chest Lead 1 (MCL1) signal, and the alerts (red spikes) are critical apnea conditions. We can see that, for this patient, the CuSum events most of the time precede apnea alerts, and they can potentially be used to predict an upcoming apneas.\n\nWe have outlined a method of processing vitals collected routinely at the bed side of ICU patients. It identifies signals that can be predictive of upcoming adverse health events.\n\nCritical care; event detection; data mining \n\nInfluenza is a recurrent viral disease that requires timely and accurate detection. The use of Twitter as a source for biosurveillance has been shown useful (1). However, these efforts target messages in English, omitting from surveillance the part of users that speaks other languages, such as Spanish.\n\nWe implemented a system that builds upon existing technologies and services. The open source platform Ushahidi (2) was used to automatically search for content. An initial query report was generated from Twitter, includes username, content and timestamp. The city of each user was extracted from their profile and a query to GoogleMaps gave us the coordinates. At the end, this new information was uploaded to Ushahidi. We used the keyword 'gripa' (Spanish for flu) and scheduled hourly updates of the search.\n\nThe prototype website operated for a pilot period of 1 month starting April 11h, 2011. A total of 473 unique occurrences worldwide were captured, of which 29% are located in Mexico (138/478) and 52% in Colombia (244/473).\n\nWe observed a higher number of incidences in Colombia relative to Mexico (Fig. 1a) . When comparing these findings with the data on the reported cases of influenza (Fig. 1b) from the World Health Organization Flunet Biosurveillance (3), the results were consistent.\n\nOur approach has promising potential for timely detection of ILI-related incidences in the areas previously underrepresented. Future work is to include different linguistic and contextual representations.\n\nBiosurveillance; influenza; twitter; open source; spanish A demonstration of meaningfully using the ISDSrecommended data elements Introduction National Health IT Initiatives are helping to advance the state of automated disease surveillance through incentives to healthcare facilities to implement electronic medical records and provide data to health departments and use collaborative systems to enhance quality of care and patient safety. While the emergence of a standard for the transfer of surveillance data is urgently needed, migrating from the current practice to a future standard can be a source of frustration.\n\nThis project will investigate tools that can be used to support ingestion and translation of public health meaningful use data in the HL7 formats. Open source tools, such as Mirth, have been identified as early candidates to support this function. After the necessary translations have been made, this project will investigate transfer methods to move the meaningful use data from a public health department to a cloud environment. With data available in the cloud, the project will then investigate methods for putting the ESSENCE system in a cloud environment as well. This will provide the collaborative team a platform to evaluate the utility of both the meaningful use data and potentially the value of having regional and national data sharing aspects available to the public health users. Finally, the team will determine the scalability and performance of a cloud environment for disseminating these tools to other jurisdictions across the country.\n\nEarly research for this project has already shown the need to redesign aspects of the ESSENCE system to support the additional meaningful use data fields. These changes involved modifications to the database design and the utilization of a more flexible configuration system. We fully expect additional modifications to be made to better support the cloud environment. These findings and the results of the public health evaluation of the system will be presented.\n\nPublic health departments will soon be flooded with mountains of new data. Having tools that can translate, transfer and utilize these new data sets effectively will be necessary. This collaborative team will research and put into practice solutions that can be used throughout the country.\n\nElectronic medical records for public health; meaningful use; interoperability; cloud Introduction Domains go through phases of existence, and the electronic disease surveillance domain is no different. This domain has gone from an experimental phase, where initial prototyping and research tried to define what was possible, to a utility phase where the focus was on determining what tools and data were solving problems for users, to an integration phase where disparate systems that solve individual problems are tied together to solve larger, more complex problems or solve existing problems more efficiently. With the integration phase comes the desire to standardize on many aspects of the problem across these tools, data sets and organizations. This desire to standardize is based on the assumption that if all parties are using similar language or technology, then it will be easier for users and developers to move them from one place to another.\n\nNormally the challenge to the domain is deciding on a vocabulary or technology that allows seamless transitions between all involved. The disease surveillance domain has accomplished this by trying to use some existing standards, such as Health Level 7 (HL7), and trying to develop some of their own, such as chief complaint-based syndrome definitions. However, the standards that are commonly discussed in this domain are easily misunderstood. These misunderstandings are predominantly a communication and/or educational issue, but they do cause problems in the disease surveillance domain. With the increased use of these standards due to meaningful use initiatives, these problems will continue to grow and be repeated without improved understanding and better communication about standards.\n\nAfter reviewing presentations and participating in many discussions at conferences and with public health officials, a number of topics were identified that many believe use or are standards. These topics included HL7, syndrome definitions, analytical algorithms definitions and the definition of what is or is not a disease surveillance system. Next, the common understandings of each were compiled and compared with actual definitions and real world experiences from users of the standards. From this, a list of misunderstandings or poorly communicated aspects of each topic was derived.\n\nThe results of this process have pointed out a number of inconsistencies with general assumed knowledge and actual truth related to many standards. The HL7 standard is just one example of a standard that is misunderstood in many aspects. Many believe that HL7 is a transport protocol, others believe that is a file format, others believe that it defines specific locations for data elements and still others believe that HL7 'set the language, structure and data types required for seamless integration from one system to another' (1). Each of these beliefs has nuggets of truth in them but do not explain the full story of HL7. Those that believe an HL7 message from one hospital can be fully read and understood in the exact same way as a second hospital may also be mistaken. Even though this is the hope of a standard, to have a standards-based tool that can be used over and over in different situations, real world experience tells us a different story about this so-called standard. Similarly, each topic has beliefs that are partially true, but by not understanding the whole truth, the standards can lead to complications.\n\nStandards are highly beneficial to a domain. They provide efficiency in tool development and promote interoperability between organizations. Sadly, fully understanding a standard can sometimes be difficult, and misunderstandings can allow decisions to be made on untrue assumptions about a standard. The word standard has a meaning attached to it that can easily confuse someone into believing a capability exists that actually does not. Through improved education and communication, we can benefit from these standards without getting caught in their traps.\n\nStandards; HL7; syndrome definition; detector interfaces; system definition\n\nIn development for over 14 years, ESSENCE is a disease surveillance system utilized by public health stakeholders at city, county, state, regional, national and global levels. The system was developed by a team from the Johns Hopkins University Applied Physics Laboratory (JHU/APL) with substantial collaborations with the U.S. Department of Defense Global Emerging Infections Surveillance and Response System (DoD GEIS), U.S. Department of Veterans Affairs (VA) and numerous public health departments. This team encompassed a broad range of individuals with backgrounds in epidemiology, mathematics, computer science, statistics, engineering and medicine with significant and constant influence from many public health collaborators.\n\nWe created a timeline of events, such as a particular partner's need (Florida Department of Health's desire to detect outbreaks based on patient time of arrival) or a public health outbreak (SARS) and correlated each one with design and architecture decisions that influenced ESSENCE. We used these events to describe the epidemiology, technology, analytical, administrative, political, legal and monetary factors that were considered at each point. Looking historically and critically at each decision point, we analyzed the benefits and costs of each decision. These benefits and costs were described from many different points of view, including those of the developer, user, administrator and others.\n\nAfter walking through the historical timeline, we described the current architecture and feature set of ESSENCE. We also were able to point out the unique features between different instances of ESSENCE.\n\nBased on user feedback, understanding outside influences and internal research, the ESSENCE team is always looking to improve the system. Part of this presentation will be to describe the future plans for the ESSENCE system from both architecture and feature stand points.\n\nPublic health user needs and preferences have strongly influenced and prioritized the growth of ESSENCE, sometimes in unforeseen directions. Conversely, the evolving domain of syndromic and disease surveillance has broadened the situational awareness, perspectives and sometimes the responsibilities of public health monitors. The ESSENCE system has provided those monitors with the tools to help detect and investigate public health situations in their communities.\n\nThe utility of the ESSENCE system can be traced back directly to the influence of public health users and to the design decisions of the ESSENCE team. Understanding the history of disease surveillance in this context can help clarify current situations faced by today's public health practitioners as well as prepare them for tomorrow.\n\nKeywords ESSENCE, disease surveillance, system architecture Introduction VA ESSENCE analyzes ICD-9 diagnosis codes and demographic data from outpatient and emergency department (ED) visits using complex aberrancy-detection algorithms (1). In 2010, a new instance was stood up (VA Inpatient ESSENCE), which receives weekly feeds of inpatient data from all VA acute care hospitals starting October 1, 2009. Data include demographics, admission/ discharge data (including ICD-9 diagnosis codes), diagnosisrelated group (DRG), bedsection, procedure and surgery data.\n\nFor this demonstration, we selected one disease for which we currently perform routine outpatient/ED ESSENCE surveillance (influenza) and one HAI of interest [C. difficile infection (CDI)]. First, we queried VA Inpatient ESSENCE for hospitalizations with an influenza diagnosis code (ICD-9: 487, 488). These data were compared to CDC's AHDRA hospitalizations, a voluntarily reporting system for laboratory-confirmed influenza-associated hospitalizations. Second, we queried VA Inpatient ESSENCE for hospitalizations with the CDI diagnosis code (ICD-9: 008.45) as well as total monthly discharges. Monthly rates for CDI were then calculated per 1000 total discharges. CDI rate per 100,000 population for FY 2010 was calculated using the total enrollees in VA Health Care in FY 2010 (8.343 million) as the denominator. Previous analysis from a non-VA hospital demonstrated good correlation between the CDI code and positive toxin assay (2) .\n\nAlerts for influenza were observed on multiple consecutive days during the fall wave of the H1N1 pandemic as well as during the peak of the 2010\u00c12011 influenza season. Peaks in weekly influenza hospitalizations appeared to correlate well temporally between the VA and CDC's AHDRA data (Fig. 1) . From October 1, 2009 to July 31, 2011 more than 12,500 CDI codes were identified among nearly 1.13 million hospitalizations with a calculated mean CDI rate of 11.1 per 1000 discharges (Fig. 2) . The CDI rate for FY10 was 78/100,000 population.\n\nInpatient data provide robust and valuable information for VA beyond what was previously available in outpatient ESSENCE data or through manual methods. Inpatient data can be monitored year-round, which provides more complete situational awareness for planning and response. Future plans include (1) developing inpatient-specific alerting algorithms, (2) establishing a single VA ESSENCE application that combines both outpatient and inpatient data and (3) imsproving timeliness of inpatient data receipt and adding additional data elements to improve system specificity. \n\nOf the 13 million people in Malawi (1) 85% are rural and the country has high burden of under-five morbidity and mortality due to preventable infectious diseases. Respiratory, febrile and diarrhea diseases are the top 3 morbidity and mortality illnesses in most developing countries (2) . Acute medical care has greatly improved these conditions, but widespread and uncontrolled use of antibiotics threatens to reverse gains achieved so far. Drug sensitivity tests are a prerequisite to guide prescription practices.\n\nAn evaluative study on all 28 district hospital laboratories in all regions of Malawi. The data are routine quarterly assessments covering from October 2009 to April 2011. The main focus was on performance of culture procedures, drug sensitivity testing practice, documentation and demand and use of drug sensitivity results by clinicians.\n\nMalawi has 29 district hospital laboratories of which only 12 (41%) are currently able to perform culture procedures. Only four (14%) of the laboratories performing culture procedures are able to perform drug sensitivity cultures, which should inform prescription practices. There is lack of demand and reliance on drug sensitivity tests by the prescribing clinician. Clinicians sited the lack of laboratory capacity and also the delays that go with culturing procedures.\n\nInadequate laboratory performance of drug sensitivity tests coupled with syndromic clinical diagnosis are the culprits of antimicrobial resistance and treatment access in Malawi.\n\nThere is no laboratory-based data forming sensitivity profiles of most antibiotics used to treat common infectious diseases.\n\nMalawi is one of the many low income countries that can claim no substantive laboratory-based data on antimicrobial susceptibility. Laboratory surveillance of antimicrobial resistance is a prerequisite to guide informed selection and purchase of drugs for local use based on scientific proof. This is more cost effective and may lead to modification of treatment procedures as necessary.\n\nDrug sensitivity tests; prescription practices; clinicians; laboratory -based data.\n\nSeasonality has a major effect on the spatial and temporal (i.e., spatiotemporal) dynamics of natural systems and their populations (1) . Although the seasonality of influenza in temperate countries is widely recognized, interregional spread of influenza in the United States has not been well characterized.\n\nCities Mortality Reporting System (1996\u00c12008) to construct weekly time series of P&I mortality for each year and Census Bureau Division. The timing of each seasonal wave was determined by identifying a significant increase and subsequent decrease in P&I mortality plus a lead-in and a lead-out week. Average time to death ([S[(t)(nt)]]/N; where N 0total P&I deaths for all weekly periods in the season, t0week of season (e.g., 1, 2, etc.), and nt 0total P&I deaths for week t) was used to determine the timing and velocity of each seasonal influenza wave. Ordinary least squares regression was used to develop trend lines and spread vectors for annual influenza epidemics in order to determine the directionality of annual influenza waves. Average time to national spread, average time to national peak P&I mortality and average P&I mortality were also determined and compared between influenza subtypes.\n\nFor the years 1972\u00c11988 and 1996\u00c12008, annual influenza epidemics needed an average of 7.9 weeks to spread across the country and lasted an average of 22 weeks. Seasons where H3N2 was the dominant influenza subtype (N013) were, on average, significantly shorter (20.3 vs. 26.7 weeks p00.0049) and spread quicker (time to death: 10.3 weeks vs. 13.8 weeks, p 00.0053) than seasons with H1N1 as the dominant subtype (N03). There was also a significant difference in the average time to national spread between H3N2-dominant seasons and H1N1-dominant seasons (6.1 vs. 13 weeks, p 00.0253) ( Table 1) . Moreover, an average seasonal traveling wave of influenza began in the East North Central region then took two routes: (1) eastward then southward along the Atlantic coast and (2) westward to the Pacific coast.\n\nPreliminary results of this analysis suggest that certain temporal patterns of influenza seasons vary by influenza subtype. Future analyses will focus on determining the temporal characteristics for influenza seasons between 1989 and 1996 (and for seasons between 1996 and 2007, using complete NVSS mortality sets) and assessing the intercounty spread of epidemic influenza. Accurately identifying spatiotemporal patterns could improve epidemic prediction and prevention as well as aid the creation of efficient containment policies for pandemic influenza (2) . This analysis will aid public health in developing more effective and efficient strategies to decrease morbidity and mortality associated with seasonal influenza in the United States.\n\nPandemic preparedness; spatial dynamics; geographic synchrony \n\nTo outline the mechanism of a pilot educational brucellosis prevention program among selected high-risk groups in an endemic region of Uzbekistan.\n\nOne goal of the Biological Threat Reduction Program (BTRP) of the US Defense Threat Reduction Agency (DTRA) is the enhancement of surveillance of especially dangerous pathogens of both humans and animals within countries of the former Soviet Union. One of the diseases of interest to the program is brucellosis, which is a life-threatening condition and constitutes a major health and economic challenge around the world. This is also true for Uzbekistan (UZ), where brucellosis is endemic in a number of regions. In the Samarqand region of UZ, for example, studies have reported a 9.3%, and 3.6% seroprevalence for humans and farm animals, respectively (1).\n\nThe lack of awareness about brucellosis in at-risk populations, shepherds, veterinarians and people who handle raw milk is believed to significantly contribute to the spread of disease from animals to humans. Here, we suggest mechanisms to evaluate awareness about the disease and the impact of an educational intervention in at-risk groups.\n\nThe intervention and two control groups will include subjects from the at-risk groups in the Samarqand region. In all three groups, the selection of study subjects will be done from nonbrucella-related visits to primary care centers by at-risk patients with no previous history of brucella. At-risk subjects within the intervention and first control group will be asked to complete a questionnaire to assess their awareness about brucellosis, specifically about its clinical presentation and risk for exposure in people. At-risk subjects in the second control group will not receive any questionnaire. The educational intervention procedures will consist of briefings to a group of healthcare professionals, delivered through BTRP regular training events, together with printed materials to be explained by the physicians to patients in the intervention group. The briefings and materials will show practical ways of preventing the spread of brucellosis targeted at common practices within the atrisk groups. The seasonality of the disease in endemic regions like Samarqand dictates that the best timing for the intervention program is in the fall (Sept\u00c1Dec), before lambing season (Feb\u00c1Jun). Our measurable outcome is the number of newly acquired human brucellosis cases among the three study groups registered after the intervention. Registration of brucellosis cases will follow existing protocols within the Uzbek healthcare system. Additionally, the questionnaire administered to the intervention and one control group will provide an insight of the baseline awareness about the disease. Adequate sample size and analysis of the data will allow comparisons between the three study groups and between strata within the groups, e.g., veterinarians and farmers. The control group not exposed to the questionnaire will allow an assessment of the impact of possible increased awareness as a result of our interventions.\n\nDisease awareness questionnaires, educational materials and further details of our study design will be presented at the conference. The anticipated increase in knowledge about risk practices associated with the transmission of brucellosis from animals in at-risk populations should lead to a reduction in human cases of brucellosis in the intervention group, compared to control groups.\n\nThe epidemiology of brucellosis among humans and animals is well-characterized. Preventive measures for the diseases are well known; yet, applying this knowledge in resource-poor countries remains a constant challenge. Having effective health education programs is a vital component in efforts to reduce the disease burden by reducing the animal-to-human transmission rate. (3) an isolated case, uninvolved in recent transmission (i.e., neither source nor recipient). Source and secondary cases require more intense intervention due to their involvement in a chain of transmission; thus, accurate and rapid classification of new patients should help public health personnel to effectively prioritize control activities. However, the currently accepted method for classification, DNA fingerprint analysis, takes many weeks to produce the results (1); therefore, public health personnel often solely rely on their intuition to identify the case who is most likely to be involved in transmission.\n\nVarious clinical and sociodemographic features are known to be associated with TB transmission (2). By using these readily available data at the time of diagnosis, it is possible to rapidly estimate the probabilities of the case being source, secondary and isolated. \n\nPerformance of the prediction model was promising as it was significantly better than random prediction (i.e., the AUCs were higher than 0.5). Small proportions of source and secondary cases in the available data may have limited performance. However, the model can be an effective decision support tool if its ability to identify a case likely to be involved in transmission is superior to the intuition of public health officials. Thus, further evaluation of the model in the context of TB control program should be conducted. If effective, the model would be particularly useful when incidence of TB increases in a resource limited setting, in which efficient prioritization of investigation is desired. Overall, the current study has important implications in promoting the approach of evidence-based practice in control of TB.\n\nTuberculosis; transmission; prediction model; public health; decision support \n\nInformation on established syndromic surveillance systems was collected from peer-reviewed articles (found in MEDLINE, Scopus and Google Scholar), proceedings from all ISDS Conferences and other conferences and searches through reference lists of papers. In addition, web pages of international health organizations, surveillance networks and Ministries of Health were explored. Identified syndromic surveillance systems were categorized by country, resource level and surveillance methodology, among other features. Eight systems were selected and examined in detail to extract transferable information.\n\nThe literature demonstrates the many diverse, yet successful, syndromic surveillance efforts being implemented at the national and regional levels. Existing systems utilize a variety of data sources, data transmission techniques and analysis methodologies, ranging from low-tech, highly manual systems to automated, electronic systems. Frequently, syndromic surveillance systems are a coordinated effort among several partners, supplement existing systems, incorporate both specific and nonspecific disease detection and are used in conjunction with laboratory-based surveillance.\n\nThough not without challenges, syndromic surveillance has the potential to serve as a valuable disease detection tool in resource-limited settings. Further examination and evaluation of these systems will benefit global disease surveillance capacity.\n\nBiosurveillance; syndrome; developing countries Introduction Alcohol abuse is one of the major leading causes of preventable mortality in the United States (1). Binge drinking or excessive alcohol consumption, categorized as a pattern of drinking that brings a person's blood alcohol concentration (BAC) to 0.08 (2), has become a major cause for concern, especially in the 18-to 20-year-old population. Iowa City is home to the University of Iowa, a large public university of 30,000 students. On June 1, 2010, the city council enacted a new ordinance prohibiting persons under 21 from entering or remaining in bars (establishments after 10:00 PM whose primary purpose is the sale of alcoholic beverages) after 10:00 PM (3). Prior to the ordinance, Iowa City was the only municipality in the region where underage patrons were allowed on premises. The new ordinance was enacted largely in response to public safety concerns, including perceptions of increased violence and sexual assaults, especially at bar closing time.\n\nOur hypothesis is that the under 21 ordinance also resulted in changes to travel behavior, where prior to the ordinance, the campus bar culture constituted an 'attractive nuisance', attracting a volatile mix of college students and nonlocals of all ages.\n\nArrest records were obtained from the University of Iowa Police Department containing all alcohol-related citations from January 1, 2004 to June 26, 2011. As the University of Iowa Police Department is one of the 4 local law enforcement agencies (Iowa City Police, Coralville Police and Johnson County Sheriff), these 7002 records represent a sample of alcoholrelated arrests, albeit one focused on the downtown bar area frequented by college students. Each record contains the date of the arrest as well as the age and home address of the offender, allowing us to compare 'in town' offenders (i.e., from within Iowa City, Coralville and transients) with 'out of town' offenders. Records corresponding to football Saturdays, where some 50,000 people come to Iowa City to tailgate and attend the Big10 football game, were excluded from the analysis as not representative of the usual bar culture. A total of 1490 alcoholrelated arrest records remained in the analysis.\n\nA Fisher's exact test was used to test the hypothesis of whether the proportion of arrests of out of town patrons versus in town patrons is independent of the under 21 ordinance.\n\nData analysis confirms that, following the ordinance, the proportion of arrests involving out of town patrons to in town patrons was significantly reduced (Fisher's exact test, p 5 0.0001). Similar results were obtained for only under 21 arrests (Fisher's exact test, p0 0.0095) and over 21 arrests (Fisher's exact test, p 0 0.0058), suggesting that the campus bars were equally attractive to all age groups prior to the ordinance.\n\nImmediately following the ordinance, the average weekly number of alcohol-related arrests increased from 9.3 to 16.3. Since over 21 arrests also increased, the change cannot be attributed solely to the new ordinance; indeed, additional police resources were deployed in a deliberate attempt to change the drinking culture. Of course, since the arresting officer cannot generally detect residency prior to arrest, arrest data still represent a geographically unbiased sample of bar patrons and can be used to explore changes in the mix of patrons.\n\nWe hypothesize that the changes detected in the proportion of arrests of in town and out of town patrons reflect a more homogeneous student clientele, where town-gown tensions are less likely to arise. Of course, any reduction in out of town patrons also corresponds to a reduction in the risk of DUIrelated fatalities, since students walk to the bars.\n\nThere are several shortcomings to this study. First, our data are incomplete as data from other enforcement agencies was not available. Second, we were unable to directly confirm the link with violence or sexual assault, as additional data would be required to do so: these are our next steps.\n\nAlcohol; binge drinking; college binge drinking\n\nThe Border Infectious Disease Surveillance (BIDS) program was established in 1999 by the Centers for Disease Control and Prevention and Mexico Secretariat of Health, following mandates from the Council of State and Territorial Epidemiologists (CSTE) and the United States\u00c1Mexico border health association to improve border surveillance. The BIDS program is a binational public health collaboration to create an active sentinel-site surveillance of infectious disease among the United States\u00c1Mexico border. It is a collaborative effort between local, state, federal and international public health agencies throughout both countries in the border region. This project is aimed at using the best aspects of both countries surveillance system.\n\nWe established a network of sentinel clinic and hospital sites along the geographical United States\u00c1Mexico border region. We utilized a shared syndromic case definition that is compatible between both countries. Standardized data collection instruments allows for exchange of surveillance data. We increased the laboratory capacity for to test for diseases of public health importance.\n\nThis effort has been successful at building a regional surveillance system. In the 2010, three pilot hospital sites were enrolled to conduct severe acute respiratory infection (SARI) surveillance. These patients were tested for viral, bacterial and important fungal infections that cause respiratory disease. Fig. 1 includes results of the 74 hospitalized SARI patients who were enrolled in the 2010\u00c12011 influenza season. The SARI patients were 54% (n040) male and had a median age of was 62.5 years (range, 0\u00c1 87 years). The expansion of this surveillance system requires additional sentinel hospital-sites and additional syndromes. A syndrome of acute diarrheal illness will be the focus of surveillance at one new pilot sentinel site, with potential to expand in the future.\n\nA surveillance system using syndromic and CSTE case definitions allows for comparison of morbidity in the United States/ Mexico border region, increased communication and bidirectional sharing of information across the border. Creating and expanding a regional surveillance system that crosses an international boundary requires coordination and collaboration from all agencies involved. These surveillance data allow for examination of the border region as one epidemiologic unit. Consistent communication with clinicians and hospital staff helps to build credibility and interest. Simplicity in surveillance procedures encourages compliance. These surveillance efforts can guide vaccine allocation planning and efficiency in evaluating illnesses that maybe vaccine preventable. Systems to share information between various states in the United States\u00c1Mexico border region are important to develop binational control strategies.\n\nSurveillance; syndromic; border; binational; Mexico Novel conceptual framework and toolset for countrywide assessments of opportunities and challenges for public health interventions Introduction Imbalances in wealth, education, infrastructure, sociopolitical leadership, healthcare and demographics create opportunities and challenges when implementing public health interventions. Understanding these, while embracing 'smart power', one can objectively assess a country's receptivity for support. Therefore, we developed a novel conceptual framework and toolset that objectively measured opportunities and challenges to inform decision-making, specifically about future implementation of the Electronic Integrated Disease Surveillance System (EIDSS)*a computer-based system for national reporting and monitoring of reportable human and veterinary infectious diseases*in East Africa and the Middle East.\n\nAfter conceptualizing and designing the toolset architecture, we gathered objective data to calculate indicators using a systematic approach from published reports; articles from peer-reviewed journals; and websites of international organizations and national Ministries in each country. We also interviewed stakeholders. Indicators were weighted to reflect the level of impact on elements and domains, and standardized baselines were established to uniformly measure outcomes. Outcomes for each element and domain were then calculated based on the weighted, indicator data.\n\nOne hundred twenty-four indicators were identified that measured 16 elements that defined 7 domains of country-specific opportunities and challenges: political will, stakeholder involvement, culture, public health functionality, healthcare, laboratory and communication infrastructure. Thirty (24%) of the 124 indicators were chosen from the reporting requirements of the 2005 International Health Regulations. In the pilot, we found various positive and negative implementation characteristics in Uganda, Kenya, Tanzania, Afghanistan, Iraq and Pakistan.\n\nWe conceived a new and useful approach to objectively analyze opportunities and challenges for public health interventions within a country. With respect to introducing EIDSS, we piloted the toolset and described a balanced view of the opportunities and challenges. Application of this novel framework should be useful for other public health interventions, and validation and further testing of the toolset should be performed.\n\nPublic health evaluation; assessment; SWOT; smart power \n\nTo present the prevailing global public health informatics landscape in developing countries highlighting current mobile system requirements and usage for disease surveillance and revealing gaps in the technology.\n\nMobile technology provides opportunities to monitor and improve health in areas of the world where resources are scarce. Poor infrastructure and the lack of access to medical services for millions have led to increased usage of mobile technology for health-related purposes in recent years. As adoption has increased, so has its acceptance as a viable technology for health data collection. The ability to provide timely, accurate and informed responses to emerging outbreaks of disease and other health threats makes mobile technology highly suitable for use in surveillance data collection activities and within the arena of global health informatics overall. The American Public Health Association (APHA) defines global health informatics as the application of information and communication technologies to improve health in low-resource settings, which include the following:\n\n. linking disparate sources of data together through natural language processing; . use of mobile health technologies for disease surveillance;\n\n. use of telemedicine to manage chronic disease;\n\n. use of digital libraries to increase knowledge and awareness of public health events.\n\nBased on donor-funded global health projects, systems requirements were gathered and existing mobile systems were evaluated for use in surveillance in low-resource settings. In advance of the tools evaluation, literature reviews were performed, and informatics experts at the Centers for Disease Control and Prevention (CDC), the World Health Organization (WHO) and various global nongovernmental organizations (NGOs) and associations were consulted and then recommendations were formulated. Systems were evaluated based on minimum requirements, which included maturity, usage, scalability, interoperability, functional features related to data collection and attributes that enable country ownership and generate high data quality.\n\nIn our evaluation, no single system was found to meet the needs of all the surveillance requirements. Mobile technology standards and guidelines were searched for, with none being found. An open-source, end-to-end software solution that is readily available and able to meet the needs of health surveillance was not identified, although several systems were deemed promising and have garnered significant use. Key features of an end-to-end mobile surveillance system would include the following:\n\n. easily adoptable;\n\n. open source or public domain;\n\n. able to support multiple mobile platforms;\n\n. form design environment;\n\n. enumeration, case selection and case management;\n\n. multilingual and Unicode functionality;\n\n. client-server deployment (local and cloud based);\n\n. SMS enabled; . rational database system data storage;\n\n. data extraction to statistical file formats;\n\n. embedded analysis and report capability;\n\n. GIS/GPS enabled, with global mapping capability;\n\n. geospatial analytic capability;\n\n. data visualization.\n\nMobile technology has emerged as a key component of global health informatics. With the expansion of this technology, a plethora of tools and systems have materialized. With so many systems, it is difficult to know which tools to apply. To add to the confusion, no standards or guidelines currently exist. Additionally, there is a clear need for an end-to-end, opensource, scalable mobile system that incorporates functionality for questionnaire design, data management, analysis and reporting. These gaps must be addressed in order for mobile surveillance technologies adoption to advance adequately.\n\nIntroduction Disease screening facilitates the reduction of disease prevalence in two ways: (1) by preventing transmission and (2) allowing for treatment of infected individuals. Hospitals choosing an optimal screening level must weigh the benefits of decreased prevalence against the costs of screening and subsequent treatment. If screening decisions are made by multiple decision units (DU; e.g., hospital wards), then they must consider the disease prevalence among admissions to their unit. Thus, the screening decisions made by one DU directly affect the disease prevalence of the other units when patients are shared.\n\nBecause of this interdependent relationship, one DU may have an incentive to ''free-ride'' off the screening decisions of others as the disease prevalence declines. On the other hand, DUs may find it futile to invest in screening if they admit a large number of infected patients from neighbors who fail to screen properly. This problem is important in determining the optimal level of unit autonomy, since increasing a unit's level of autonomy in screening effectively increases the total number of DUs.\n\nWe develop a theoretical model that incorporates the two channels through which screening may reduce prevalence. The model is based on a hospital composed of N treatment units (e.g., ICU and ER) divided into n DUs, that transfer patients between one another and an outside population. Disease prevalence in each DU is determined by an SIS model based on the multi-institutional framework of Smith, et al. (1, 2) . A DU's prevalence is a function of its own screening level (s) and that of their neighbors (\u0161).\n\nWe develop a cost structure similar to Armbruster and Brandeau that incorporates the various costs to screen for and treat a disease. (3) Given these costs, a single DU chooses the screening level that minimizes its net present value of discounted future costs. We solve for the symmetric, pure-strategy Nash equilibrium.\n\nAs the rate of recovery following treatment (t) increases relative to screening and treatment costs, the DU's best response curve transitions from an inverted-U pattern to one that is monotonically decreasing (Fig. 1) . Additionally, the equilibrium screening value is monotonically decreasing in the number of DUs (Fig. 2) . Here the best response curves intersect the line of equal screening values.\n\nWhen treatment is less effective, free-riding is less severe and a DU's optimal screening may actually increase with its opponents level. However, as treatment becomes more effective, optimal screening levels are strictly decreasing in the other DU's allocation: free-riding takes full effect. As the number of DUs increases, so does the opportunity to free-ride. This means optimal screening will decrease and disease prevalence will increase as the number of DUs increases. Therefore, in a purely symmetric environment increasing unit autonomy may adversely affect disease prevalence: authority for screening should be centralized. \n\nThe time series of syphilis cases has been studied at the country and state level at the yearly basis (1, 2) , and it has been found that syphilis has a periodicity of approximately 10 years (2). However, to inform prevention efforts, it is important to understand the short-term dynamics of disease activity.\n\nWe used data from the MMWR. It contains weekly syphilis counts per state. We consider the time period from 1995 to 2009. We removed week 53 when present, due to inconsistencies in reporting. We considered 53 locations: the 50 states plus Puerto Rico, and the cities of New York City and Washington DC. To predict disease activity in each state, we constructed a series of linear lagged regression models that used several states as covariates. To benchmark our models, we constructed a basic ARIMA model with one autocorrelation term. All the models were constructed to forecast 4 weeks in advance. Prediction at week t was performed by fitting the models using all past data prior to week t\u00c14. To identify bellwether states, we proceeded as follows. First, we repeatedly fitted 2-covariate models to forecast each state and obtained the top 5 most frequent bellwether states for each state. Then, we obtained the most frequent bellwether states from the above lists.\n\nWe found that forecasting states using less than 10 states as covariates is better than using more or the state itself as covariate (ARIMA), as shown in Fig. 1 . An example of out of sample prediction is shown in Fig. 2 , for New York City.\n\nWe also found that the 10 most frequent states in models with two covariates are California, Virginia, Florida, New York City (treated as state), Alabama, Ohio, Tennessee, North Carolina, New Hampshire and New Mexico. The first 5 are covariates of 40 states, and the amount increases to 50 when adding the later.\n\nUsing several states as covariates in models seem to improve their forecasting power. This suggests that these models 'learn' the dynamics of syphilis between different states. In addition, we have identified the existence of specific bellwether states. By using these bellwether states, it is possible to forecast syphilis cases in almost all the states in the country.\n\nSeveral limitations undermine the quality of the predictions. First, cases are counted at reporting time instead of acquisition time (3) . Second, the MMWR file supposedly contains cumulative numbers within a year, but this is not always true. Third, some states exhibit strong yearly periodicity, which seems to be due to patterns in disease reporting.\n\nSyphilis time series; forecasting; disease surveillance \n\nArgus is an event-based surveillance system, which captures information from publicly available Internet media in multiple languages. The information is contextualized, and indications and warning (I&W) of disease are identified. Reports are generated by regional experts and are made available to the system's users (1) . In this study a small-scale disease event, plague emergence, was tracked in a rural setting, despite media suppression and a low availability of epidemiological information.\n\nArgus reports meeting the following inclusion criteria were selected retrospectively: (1) disease: plague, (2) location: Peru, (3) time period: April\u00c1October 2010. The reports were reviewed for relevant I&W of plague infection, with the goal of identifying factors that contributed to disease spread and ineffective public health response.\n\nFrom the time period specified, media reported on a human plague outbreak in northern Peru where all 3 clinical forms of plague were identified (septicemic, pneumonic and bubonic); in one area, bubonic plague was registered for the first time in over a decade while pneumonic plague was reported for the first time ever in the country, according to an official (2) .\n\nThe first human case of bubonic plague was reported in April, followed by a 2-month reporting lull from May to July. Subsequently, new media information revealed ongoing human plague cases, including nosocomial pneumonic infections which had spread from one patient to medical staff and one relative, as well as a severe lack of biosafety personal protective and laboratory equipment (3) .\n\nRetrospective review of Argus reports later identified 3 key factors that limited the effectiveness of disease management in the region: (1) a lack of government leadership and accountability, (2) poor sanitation leading to an inability to decrease the vector population and (3) an inadequate regional healthcare infrastructure (4) . Media sources recognized discrepancies in medical information provided by health officials and the medical community, and as the outbreak continued, protests erupted over poor sanitary conditions and insufficient medical resources as observed by healthcare workers. In August, the Minister of Health (MOH) declared that the outbreak had been 'controlled'; however, the media continued to report human plague cases and noted concern regarding the potential danger of plague spreading to urban markets. Travel restrictions were applied and reports later speculated that the World Health Organization (WHO) would close ports and issue a national quarantine if plague extended into coastal export areas (5, 6) . Further, officials declared a latent risk of disease transmission to bordering countries. At the end of the study reporting timeframe, media continued to identify the confirmation of new human bubonic plague cases, the implementation of vector control efforts, and the ongoing risk to residents despite attempted disease management efforts.\n\nThe use of an event-based methodology provided detailed insight into a localized, small-scale disease situation where limited medical and epidemiological information was available. Argus documentation of this event allowed for a retrospective review, which identified deficiencies in the current disease management system in Peru and drew attention to the potential negative impact of social and political context on public health efforts.\n\nSurveillance; plague; emergence; intervention; isolated\n\nHeat waves have serious health impacts such as heat exhaustion, heat stroke, dehydration and death. Heat illness morbidity and mortality can be reduced with the identification of vulnerable populations and targeted public health interventions. In June and July of 2011, a heat wave occurred in Nebraska in which 28 days reached 90 F or higher. Syndromic surveillance data were used to describe heat-related illness emergency department (ED) visits during this time.\n\nEight hospitals currently submit syndromic surveillance ED data to Nebraska Department of Health and Human Services (NeDHHS), representing approximately 18% of all ED visits for the state. Five hospitals reported complete data for the selected study period, June 1, 2010\u00c1August 10, 2011. The three hospitals not reporting complete data for the study period were excluded. These records represent approximately 15% of all ED visits in the state for June\u00c1August. Cases of heat-related illness were identifiedusing ICD9CM diagnostic and external cause of injury codes: 992, 705.1, 708.2 and E900. Additional cases were identified from the chief complaint field using the SAS INDEX function to locate the following words within the text field: 'HEAT', 'HEATED', 'DEHYDRATED' and 'HYPERTHERMIA'. Each record returned from these searches was examined to confirm the presence of heat illness. Chief complaint fields containing keywords but not involving heat-related illness, i.e., 'applied heat to swollen ankle', were eliminated. with heat-related ED vists were 55% male (n 0273) with a median age of 34 years. Further analyses will assess correlation between heat index and heat illness in Nebraska.\n\nThe rate of heat-related illness ED visits was slightly higher in the summer of 2011 than in 2010. This system provides an effective method to identify and track heat illness. Timely identification of patients with heat illness using this system can facilitate rapid and focused public health response and reduce heat*related morbidity and mortality.\n\nSyndromic surveillance; heat illness; heat wave Introduction Commonly used syndromic surveillance methods based on the spatial scan statistic (1) first classify disease cases into broad, preexisting symptom categories (prodromes) such as respiratory or fever, then detect spatial clusters where the recent case count of some prodrome is unexpectedly high. Novel emerging infections may have very specific and anomalous symptoms, which should be easy to detect even if the number of cases is small. However, typical spatial scan approaches may fail to detect a novel outbreak if the resulting cases are not classified to any known prodrome. Alternatively, detection may be delayed because cases are lumped into an overly broad prodrome, diluting the outbreak signal.\n\nWe propose a new approach to detect emerging patterns of keywords in the chief complaint data. Our semantic scan statistic has three steps: automatically inferring a set of topics (probability distributions over words) from the data using Latent Dirichlet Allocation (2), classifying each chief complaint to the most likely topic, and then performing a spatial scan using the case counts for each topic. We compare three variants of the semantic scan: static (topics are learned from historical data and do not change from day to day), dynamic (topics are recalculated each day using the most recent two weeks of data) and incremental (not only using the static topics but also learning additional 'emerging' topics that differ substantially from the static topics).\n\nWe compared the three semantic scan methods to the standard, prodrome-based spatial scan using synthetic disease outbreaks injected into real-world emergency department data from Allegheny County, PA. We first considered 55 different outbreak types, corresponding to all distinct ICD-9 codes with at least 10 cases, which were mapped to one of the existing prodromes. For each outbreak type, we generated spatially localized injects with chief complaints sampled from the cases with that ICD-9 code (Fig. 1) . The static, dynamic and incremental methods required an average of 7.7, 7.1 and 6.9 days, respectively, to detect and were able to precisely characterize the outbreak based on the detected topic (e.g., top keywords for ICD-9 code 569.3 were 'rectal', 'bleed', and 'bleeding'). The prodrome method achieved more timely detection (5.0 days to detect) but with much less precise characterization (e.g., 'hemorrhagic' for ICD-9 code 569.3). Next, we considered both randomly selected, unmapped ICD-9 codes and synthetically generated unprecedented events, such as an outbreak that makes the patient's nose turn green. The prodrome method required 10.9 days to detect these outbreaks, while the semantic scan was able to achieve much faster detection. For example, for the green nose outbreak, the static, dynamic and incremental methods detected in 6.4, 5.3 and 5.6 days, respectively. The dynamic and incremental methods correctly identified the emerging topic (keywords 'green', 'nose', 'nasal', etc.), while the static method did not, since the outbreak did not correspond to any of the topics learned from historical data.\n\nThe semantic scan statistic can successfully capture emerging spatial patterns in free-text chief complaint data, enabling more timely detection of novel emerging outbreaks with previously unseen patterns of symptoms. Other advantages include more accurate characterization of outbreaks (identifying a set of keywords that precisely describe the disease symptoms) and the ability to detect outbreaks without preexisting syndrome definitions. Additionally, our methods have the potential to achieve more timely detection by incorporating free-text data sources, such as Twitter and other social media tools, into the surveillance process.\n\nText mining; event detection; semantic scan\n\nOptimal sequential management of disease outbreaks has been shown to dramatically improve the realized outbreak costs when the number of newly infected and recovered individuals is assumed to be known (1, 2) . This assumption has been relaxed so that infected and recovered individuals are sampled, and therefore the rate of information gain about the infectiousness and morbidity of a particular outbreak is proportional to the sampling rate (3). We study the effect of no recovered sampling and signal delay, features common to surveillance systems, on the costs associated with an outbreak.\n\nWe develop a stochastic compartment model for disease populations consisting of susceptible (S), infected (I), recovered (R) and deceased (D) individuals. This model contains four parameters determining the rates of these transitions: S 0I, I0R, I0D and S 0R (vaccination). While all vaccination and death transitions are observed completely, the infected and recovered transitions are observed through sampling possibly with a delay between the transition and when the information can be used in a decision.\n\nSequential inference of parameters is performed using Bayesian updating, which is available in closed form when independent gamma priors are assumed, and the current system state is known. For the two sampled transitions, the associated parameters are updated in a manner that is consistent with how information is gained during sampling so that the rate of information gain is proportional to the sampling rate.\n\nA cost structure is developed to weigh the outbreak morbidity and mortality versus the cost of active outbreak control (isolation, vaccination and increased sampling). The morbidity cost is quadratic to account for increased costs that occur when many individuals are sick simultaneously. Control costs include fixed and running costs, which are a function of the current number of infected individuals (3) .\n\nThe effect of recovered sampling and delay is primarily assessed by running separate scenarios that have combinations of sampling and delay and calculating the average outbreak cost under these scenarios. In addition, allowing recovered sampling in a control allowed analysis of how often and when the optimal outbreak management utilized this sampling.\n\nAs a case study, we use a recent measles outbreak in Harare, Zimbabwe, as our basis. At outbreak onset, we assume 20,000 susceptible individuals ( \u00c21% of total population in accordance with vaccination coverage rates) and 20 infected individuals. Priors for outbreak parameters are vague but informative, e.g., a 95% interval for infectiousness is 4 to 11 days.\n\nRelative to the base-case scenario where immediate sampling is performed on both newly infected and recovered individuals, the following results are observed. Eliminating recovered sampling increases average costs by 5%, a one-period delay between transitions and control action increases costs 6%, a two-period delay increases costs 14% and eliminating all sampling increases costs by 34%.\n\nWhen allowing increased sampling as a possible outbreak control measure, the optimal decision was to utilize sampling of infected and recovered individuals about 20% of the time.\n\nTypical syndromic surveillance systems have taken the first step, which is to provide a measure of the number of newly infected individuals. Costs being equal, this research suggests this was the best investment for surveillance. We hope future research with different diseases and surveillance possibilities will elucidate where money should be spent in improving surveillance practices. \n\nData were extracted from the weekly Zimbabwe cholera epidemiological bulletins available in the World Health Organization's Zimbabwe cholera epidemiological bulletin archive (2) . The focus of the data collection was on the tables titled 'Distribution of Measles IgM Positive by Age group and District of residence', which typically contained both cumulative and new cases of IgM-confirmed measles cases by district and age categories. Although not entirely consistent, the age categories were younger than 9 months, 9\u00c111 months, 1\u00c14 years, 5\u00c114 years, and 14 years and older.\n\nThe statistical software R (3) was used for data cleaning (an extensive process) and exploratory analysis. The maptools package (4) was used to generate maps of the geographical disease progression. Fig. 1A provides an example time series for the cumulativeconfirmed measles cases in Harare, the capital of Zimbabwe, where all age categories have been combined. Indicated in green is the mass vaccination campaign that took place between May 24 and June 2. Fig. 1B provides an example map displaying the geographical distribution of confirmed measles cases upon extinction of the outbreak. The darker color indicates a higher attack rate (number of confirmed cases divided by total population); the darkest red area is Harare.\n\nThis exploratory analysis questions the utility of the mass vaccination campaign since the campaign came after the peak of the outbreak in the hardest hit district in Zimbabwe. But since Harare was one of the earliest districts affected, perhaps the campaign prevented further spread to other districts. In addition, it is possible that suspected cases in Harare were more likely to become confirmed cases due to geographical proximity of testing laboratories, thereby inflating the relative attack rate.\n\nMeasles; Zimbabwe; exploratory analysis; geographical; R \n\nIn March 11, 2011, the big earthquake attacked eastern Japan followed by huge tsunami and nuclear plant accident. Consequently, a lot of people could not help living in evacuation sites. Since those evaluation sites have high density of population and were not necessarily good in sanitary condition, outbreaks of influenza, norovirus or other infectious diseases were concerned.\n\nWe developed a web-based evacuation site surveillance system with 8 syndromes including acute gastroenteric symptoms; influenza or influenza-like-illness; acute respiratory symptoms other than influenza; rash and fever; neurologic symptoms including tetanus, meningitis and encephalitis; cutaneous symptoms; wound-related infectious diseases; icterus and death. Age of the patients was classified into three categories: younger than 5 years, 5 to 64 years and 65 years old or older. Analysis by evacuation site was performed automatically, and if some aberrations were found, the system showed an alert sign on the screen of a computer. The information on patients was shared with the public health center and the local government office simultaneously.\n\nEvacuation site surveillance started in Fukushima prefecture on March 25, 2011, and in Miyagi prefecture on May 8, 2011.\n\nAbout 400 sites in Miyagi prefecture were covered until the end of May. When the surveillance found an aberration, the public health center investigated the site and started taking an action for control.\n\nThis system raised awareness of infectious diseases and provided good information for risk assessment. Before the earthquake, the pharmacy surveillance and the school surveillance (only in Miyagi prefecture), which are nationwide syndromic surveillance in Japan, were operating, and these played a complementary role for evacuation site surveillance and the official surveillance. Our experience showed that it would be too late to start to develop the system from the scratch after a disaster occurred. Thus, it is essential to make a plan on activation of the system in advance in case a severe disaster occurs and to prepare and stockpile the hardware that is necessary for an early activation of evacuation site surveillance. The necessary hardware, for example, includes battery and communication tool even if electronic power, internet and (mobile) phone network are shut down. This is the next challenge. \n\nSyndromic surveillance systems were designed for early outbreak and bioterrorism event detection. As practical experience shaped development and implementation, these systems became more broadly used for general surveillance and situational awareness, notably ILI monitoring. Beginning in 2006, ISDS engaged partners from state and local health departments to build Distribute, a distributed surveillance network for sharing de-identified aggregate emergency department (ED) syndromic surveillance data through existing state and local public health systems (1). To provide more meaningful cross-jurisdictional comparisons and to allow valid aggregation of syndromic data at the national level, a pilot study was conducted to assess implementation of a common ILI syndrome definition across Distribute.\n\nSix jurisdictions provided 4 years of baseline ED data using a common ILI definition comprising 3 subsyndrome components defined by a formal code-set (Fig. 1) . Distribute sites were invited to participate in the assessment based on geography, jurisdiction size and ED coverage. Invited sites were asked to provide historical data consisting of total and ILI-related daily visit counts by age group ( B2, 2\u00c14, 5\u00c117, 18\u00c144, 45\u00c164 and 65' years). The common ILI syndrome and subsyndrome case definitions for the pilot were defined from coded or free text ED patient electronic chief complaint data as 'fever and cough', 'fever and sore throat', and 'flu'. Evaluation included comparison of syndrome time-series, subsyndrome and age-specific distribution of visits and signal-to-noise measures.\n\nWe found less variation between jurisdictions in weekly ratios using the common ILI definition (mean 2%; range 1.5\u00c13.1%) than locally preferred syndromes (mean 4.9%; range 1.8-8.4%), and influenza epidemic signal-to-noise ratios were comparable for most jurisdictions during the study period. The findings suggest that the common syndrome improves comparability without an overall cost in terms of epidemic signal discrimination.\n\nThe results of this common ILI assessment suggest that disparate local systems can adopt a harmonized syndrome definition allowing for meaningful comparisons and national aggregation while maintaining the ability to use local systems and definitions. The common ILI syndrome provided more directly comparable time-series, both during baseline periods and epidemics. Use of the common syndrome did not have an overall or systematic cost in terms of epidemic signal discrimination. Where the signal-to-noise ratio was not improved, differences were usually minimal. Also, the use of the common syndrome did not restrict the use of the locally defined syndromes for local detection. This collaborative pilot was useful in synthesizing local experience in the creation of a nationally harmonized ILI syndrome definition.\n\nInfluenza; surveillance; epidemiology; syndrome standard; emergency department \n\nWe describe the initial phase of the ISDS Distribute pilot for monitoring acute gastroenteritis (AGE) syndromic emergency department (ED) visits and present preliminary analysis of agespecific trends documenting a dramatic shift in AGE consistent with US rotavirus vaccine policy and use.\n\nEpidemic AGE is a major contributor to the global burden of morbidity and mortality. Rotavirus and norovirus epidemics present a significant burden annually, with their predominant impact in temperate climates occurring during winter periods. Annually, epidemic rotavirus causes an estimated 600,000 deaths worldwide and 70,000 hospitalizations in the United States, primarily among children younger than 5 years (1). The U.S. burden from norovirus is estimated at 71,000 hospitalizations annually, with the impact more generally across age groups (2) . Changes in rotavirus vaccine use have significantly reduced the impact of epidemic rotavirus (3).\n\nThe Distribute project began in 2006 as a distributed, syndromic surveillance effort networking state and local health departments to share aggregate ED based influenza-like illness (ILI) syndrome data (4) . The AGE pilot was conducted to assess the feasibility of generalizing the Distribute model from ILI trends to monitoring other syndromes. Distribute participating jurisdictions were asked to submit diarrheal and vomiting AGE syndrome ED data, following a commonly used syndrome definition. Of the 10 Distribute participating jurisdictions that submitted AGE data, 6 provided historical baseline data going back to January 2006 or earlier. Of these, 3 were state, 3 large city or county jurisdictions, located in Northeastern, Mid-Atlantic, Midwestern and Western U.S. surveillance regions. Syndrome time-series ratios [(weekly AGE syndrome count)/ (total ED visit count)] were assessed by jurisdiction and age group. To aid comparison of seasonal trends across jurisdictions, time-series were normalized around their baseline as a measure of relative increase [(weekly AGE ratio)/(weekly lowerquartile)]. Rotavirus vaccine 2006 pre-and postlicensure periods were compared.\n\nAll jurisdictions submitting AGE data to Distribute presented seasonal trends with predominant winter peaks. Across the pilot jurisdictions, seasonal peaks from 2003/04 to 2005/06 occurred during Mar\u00c1Apr, while 2006/07 to 2009/10 seasonal trends peaked predominantly in Dec\u00c1Feb. Overall, epidemic timing was similar across age groups; however, the shifting pattern in impact after the 2006/07 season presented a greater drop among young children. (Fig. 1) .\n\nThe results of the pilot suggest the Distribute model can be successfully generalized to monitoring AGE trends, specifically the age-specific timing and impact of winter-seasonal epidemic rotavirus and norovirus. The case study of 2006 rotavirus vaccine implementation and subsequent shift in timing and impact of AGE trends suggest that syndromic ED data can potentially provide a useful surveillance indicator of populationlevel vaccine effect.\n\nGastroenteritis; norovirus; rotavirus; epidemiology; emergency department \n\nCost-effective, flexible and innovative tools that integrate disparate data sets and allow sharing of information between geographically dispersed collaborators are needed to improve public health surveillance practice. Gossamer Health (Good Open Standards System for Aggregating, Monitoring and Electronic Reporting of Health), http://gossamerhealth.org, is an open source system, suitable for server or 'cloud' deployment, which is designed for the collection, analysis, interpretation and visualization of syndromic surveillance data and other indicators to monitor population health. The Gossamer Health system combines applied public health informatics research conducted at the University of Washington (UW) Center for Public Health Informatics and Washington State Department of Health, in collaboration with other state and local health jurisdictions, the International Society for Disease Surveillance and the Centers for Disease Control and Prevention.\n\nGossamer combines work on (1) methods for automated surveillance based on summarized clinical data, such as the influenza and visit counts used in the Distribute project (1), (2) methods developed for the modularization of surveillance processes developed for the Shoki project (2), (3) methods developed for the automated processing of Health Information Exchange data (HIE) as part of the CDC HIE initiative (3) and (4) standard industry server virtualization and deployment techniques (4).\n\nGossamer uses code developed at UW and additional open source components. Most components are distributed under the '3-clause BSD license', permitting free use, modification and redistribution. Automated modules include (1) HL7 message receipt, processing and storage, (2) compilation of line listing data from HL7 Minimum Biosurveillance Data Set (MBDS) and Meaningful use (under development) messages, (3) classification of cases into syndromes and compilation of syndrome data into indicators, (4) receipt, storage, aggregation and management of indicator data, and (5) analysis, visualization and reporting (AVR) of indicator data. Modules may be deployed locally or in the EC2 cloud and communicated using standard protocols to let deployment strategies be mixed across the system to support both sharing and shared use of components, as well as load balancing and optimization. This presentation will talk about the goals of the open source system and give underlying details of the technical implementation using virtual machines. As an example, we will discuss an application of the Gossamer system instance developed to let a state public health agency disseminate summarized laboratory test results for multiple (14) respiratory viruses (see Fig. 1 ).\n\nTo support existing and emergent surveillance needs, the UW has worked with local and state health jurisdictions to identify features that allow for user-defined indicators of chronic and infectious disease surveillance. An important aspect of the Gossamer Health vision is its support for public health agencies to collaborate in cross-jurisdictional surveillance efforts through both on-demand and automated sharing of standards-based data feeds.\n\nGossamer is a work in progress, but it is a community work. All are welcome to participate in its development. \n\nCross-jurisdictional sharing of public health syndrome data is useful for many reasons, among them to provide a larger regional or national view of activity and to determine if unusual activity observed in one jurisdiction is atypical. Considerable barriers to sharing of public health data exist, including maintaining control of potentially sensitive data and having informatics systems available to take and view data.\n\nThe Distribute project (1,2) has successfully enabled crossjurisdictional sharing of ILI syndrome data through a community of practice approach to facilitate control and trust and a distributed informatics solution.\n\nThe Gossamer system (3) incorporates methods used in several UW projects including Distribute. Gossamer has been designed in a modular fashion to be hosted using virtual or physical machines, including inside cloud environments. Two modules of the Gossamer system are designed for aggregate data sharing and provide a subset of the Distribute functionality.\n\nThe Distribute and Gossamer systems have been used for ad hoc sharing in three different contexts: sharing of common ILI data for research into syndrome standardization, sharing syndromic data for specific events (2010 Olympics) and for pilot regional sharing of respiratory laboratory results. Two additional projects are underway to share specific syndromes of recent interest: alcohol-related and heat-related ED visits.\n\nThe Distribute system was initially designed to share 4 syndromes (broad and narrow ILI, and GI syndromes). To reduce barriers to entry, the Distribute project does not impose strict syndrome definitions. This lack of standardization introduces variability between jurisdictions and a pilot has been undertaken to compare sites with preferred definitions and to develop a common ILI definition. To enable the addition of a common syndrome considerable modifications to the structure of the Distribute system were required. The approach taken allowed for the use of arbitrary indicators and stratification ranges.\n\nThe Gossamer system uses a similar data storage architecture to that of the current version of Distribute, though Gossamer is more modular and better able to use external services. These features make it useful for moving beyond specific political structures or disease content areas.\n\nThe expanded data model has now been used to support the ILI standardization effort through comparison of newly contributed 'ILI-S' syndrome data. Distribute was also used to develop a site to allow Washington State DoH to share specific syndromic data with British Columbia during the 2010 Olympics. An instance of Gossamer demonstrated sharing laboratory results for 14 viral isolates between two states. In addition to community-driven comparisons of ILI and GI syndromes, the data model has been applied at the design level to two additional syndrome types for ad hoc data sharing: alcohol intoxicationrelated visits and heat exposure-related ED visits.\n\nWhile built around similar data models, each system has strengths and weaknesses for ad hoc sharing of data. Advantages of the Distribute system for sharing additional data include making use of the existing trust and community that is based around the system, which reduces many barriers to sharing data and facilitates adding more community members. In addition, data feeds and administrative details are already in place.\n\nDisadvantages of using Distribute include limitations in the common data transmission format, limitations in stratifiers and limitations in compartmentalization.\n\nThe implementation of the very similar data model in Gossamer is able to address some of these issues by various strategies including virtualization and modular architecture, while extending the flexibility which supports new applications of the data collection, quality and analysis methods developed for use with influenza syndromes in Disribute.\n\nThe 5 examples illustrate the strengths of the community of practice approach to sharing data. The Distribute and Gossamer systems illustrate how lightweight systems can be designed to easily facilitate ad hoc sharing between jurisdictions.\n\nInformatics; surviellance; architecture; data sharing; public health practice\n\nDistribute is a national emergency department syndromic surveillance project developed by the International Society for Disease Surveillance (ISDS) for influenza-like illness (ILI) that integrates data from existing state and local public health department surveillance systems. The Distribute project provides graphic comparisons of both ILI-related clinical visits across jurisdictions and a national picture of ILI.\n\nUnlike other surveillance systems, Distribute is designed to work solely with summarized (aggregated) data, which cannot be traced back to the unaggregated 'raw' data. This and the distributed, voluntary nature of the project create some unique data quality issues, with considerable site to site variability. Together with the ISDS, the University of Washington has developed processes and tools to address these challenges, mirroring work done by others in the Distribute community.\n\nUniversity of Washington together with the ISDS has undertaken a comprehensive analysis of the quality of the data being received by Distribute, primarily using visual methods, examining data quality characteristics within and between sites. This process included basic exploratory analysis of data quality problems and analytical analysis of specific aspects of data quality, including the relationship between timeliness, completion and accuracy.\n\nConsiderable variability was seen between sites in terms of timeliness and completion, and completion rates did not necessarily correlate with accuracy. In our talk, we will present results comparing the quality of data between sites (sites will be unidentified), in particular comparisons between timeliness, completion and accuracy. We will also examine the types of observed relationships between timeliness, completeness and accuracy exhibited across the sites.\n\nThe purpose of this talk is to facilitate discussion between Distribute participants around data quality and the role that the ISDS can play in ensuring data quality. We will show prototypes of two features that could be hosted on the Distribute restricted site. The first feature would allow each site to compare the quality of their data (identified only to them, with site linked to the id of the user) with the remaining sites (each unidentified). The second feature would allow each site to see time series of their data together with prediction intervals for the accuracy of the ILI ratio for recent dates where the data are incomplete (see Fig. 1 ).\n\nOur goal is to spark discussion on data quality with respect to syndromic surveillance data and, in particular, how the Distribute project can be leveraged to improve the quality of aggregate data produced by participating sites.\n\nKeywords Data quality; surveillance; public health practice; data quality *Ian Painter E-mail: ipainter@uw.edu (page number not for citation purpose) \n\nDistribute is a national emergency department syndromic surveillance project developed by the International Society for Disease Surveillance for influenza-like illness (ILI) that integrates data from existing state and local public health department surveillance systems. The Distribute project provides graphic comparisons of both ILI-related clinical visits across jurisdictions and a national picture of ILI.\n\nUnlike other surveillance systems, Distribute is designed to work solely with summarized (aggregated) data, which cannot be traced back to the unaggregated 'raw' data. This and the distributed, voluntary nature of the project creates some unique data quality issues, with considerable site to site variability. Together with the ISDS, the University of Washington has developed processes and tools to address these challenges, mirroring work done by others in the Distribute community.\n\nThe University of Washington together with the ISDS has undertaken a comprehensive analysis of the quality of the data being received by Distribute, primarily using visual methods, examining data quality characteristics within and between sites. Several visualization tools were developed to assist in analyzing and characterizing data quality patterns for each site: upload pattern graphs (Fig. 1) , stacked lag histograms and arrays of lagged time series graphs. Upload pattern graphs are heat maps comparing upload dates with encounter dates (an example figure is given below for three sites). Stacked lag histograms provide a succinct view of the complete distribution of data timeliness for a particular site. Arrays of lagged time series graphs provide an in-depth look at how timeliness patterns manifest in time series graphs. Implementation of the latter two visualizations required implementing a specific database architecture to enable reconstruction of the data at any prior upload date.\n\nIn our talk, we will present these visualizations and demonstrate how they can be used to discover several common and some unusual data quality patterns and issues. We will also discuss the underlying architecture that allows us to reconstruct prior views and discuss the importance of examining data quality in terms of prior data views.\n\nVisualizations; data quality; surveillance \n\nDuring responses, an electronic medical record (EMR) allows federal emergency response staff to view and evaluate near realtime clinical encounter data. Analysis of EMR patient data can enhance situational awareness and provide decision advantage for headquarters' staff during both domestic and international events. The EMR was utilized by field medical personnel during the response to the Haiti earthquake.\n\nDuring the U.S. response to the Haiti Earthquake in January 2010, patient demographic and clinical treatment data were collected by ESF-8 responders through the EMR. Data were collected throughout the patient experience during registration, triage, treatment and discharge. Inclusion criteria for encounter records in the main analysis were entered into the EMR between January 18, 2010, and February 22, 2010, encounter occurred at one of the HHS sites in Haiti and data downloaded no later than February 23, 2010. Data were then analyzed in order to identify potential emerging conditions and operational medical needs during the entire response.\n\nWe analyzed 8925 patient encounter records entered into the EMR between January 18 and February 22, 2010. Of those records, 4612 (51.8%) were coded as female, 3995 (44.8%) as male and 303 (3.4%) were not specified. Additionally, 1444 (16.2%) of the encounters were coded as less than 6 years old, 1638 (18.3%) were coded as 6\u00c118 years old, 4352 (48.8%) were coded as 19\u00c149 years old, 1004 (11.2%) were coded as 50\u00c165 years old, 283 (3.2%) were coded as more than 65 years old and 204 (2.3%) were not specified. Mean age was 27.1 (SD 019.1) years with a minimum of 1 day and a maximum of 100 years. Additionally, 6575 (75.1%) records were coded as nonurgent, 1889 (21.6%) as urgent and 295 (3.3%) as emergent. Daily surveillance of the records resulted in the identification many of suspected or confirmed symptom and disease occurrences. They included 8 cases of chicken pox/herpes zoster, 46 cases of conjunctivitis, 1 case of hemorrhagic fever, 23 guns shots wounds, 15 cases of malaria, 1 case of measles, 3 cases of meningitis, 2 cases of mumps, 53 cases of acariasis (including scabies), 1 case of typhus, 3 cases of tetanus, 3 cases of tuberculosis and 7 cases of pneumonia. We also detected 714 instances of fever and 550 instances of diarrhea.\n\nDuring the 2010 earthquake response in Haiti, knowledge of the medical encounters through EMR data in the field provided indications of need for patient care. The surveillance of suspected and confirmed condition and diseases of concern allowed for timely decisions on adjustments to the response. Event burden could be quickly assessed through electronic reporting. EMR data can enhance and inform emergency response decision-making during domestic and international events and may be a useful tool for field public health and medical surveillance and situational awareness during future disaster responses. \n\nEpidemiological data suggests that there have been disproportionate numbers of non-White persons hospitalized due to 2009 pandemic influenza (H1N1) in MA. Population-based statewide descriptions of H1N1-related hospitalizations according to race/ ethnic group and SES have not been described.\n\nWe identified those discharged from any MA hospital during the H1N1 pandemic in the Hospital Discharge Database (HDD) with ICD-9 diagnosis codes correlating highly with positive viral specimens (1). Using five-digit zip codes as an identifier, we linked census data to the HDD population to provide a measure of SES indicator through aggregate levels of affluence. We used random-effects multivariate logistic regression models to explore the above objectives.\n\nResults 9737 individuals met inclusion criteria, and 1529 individuals (16%) were admitted to the ICU. Hispanics had the lowest rates of ICU stay (11% Hispanics in the ICU had the highest length of stay (8.1 days), the youngest mean age (26 years), nearly a third (32%) were B18 years, 52% were from the lowest SES group, and 58% were female (Table 1) . Differences between race/ethnic groups and SES exist (Table 1) . Results from multivariate regressions indicate that Hispanics are at 27% lower risk for ICU stay compared to Whites (OR 00.73, p B0.001*data not shown).\n\nHispanics were particularly vulnerable to exposure and susceptibility to H1N1 (2). However, Hispanics had the lowest rates of H1N1-related ICU admission and significantly lower risk of having H1N1-related ICU visits. Logistic regression models indicate that these differences are not explained by the large differences in SES. This is contrary to other reports and could be related to the low mean age of this group. Future work should address how lower age among Hispanics influences H1N1-related ICU stay \u00c1 especially in young Hispanic women.\n\nPandemic H1N1 influenza; epidemiology; disparity research; race/ethnicity Objective\n\nTo investigate the utility of spatial analysis in the tracking of the stages of the HIV epidemic at an administrative territory level, using the Odessa region, Ukraine, as an example.\n\nDetection of the signs of HIV epidemic transition from concentrated to generalized stage is an important issue for many countries including Ukraine. Objective and timely detection of the generalization of HIV epidemic is a significant factor for the development and implementation of appropriate preventive programs. As an additional method for estimating HIV epidemic stage, the spatial analysis of the reported new HIV cases among injection drug users (IDU) and other populations (due to sexual way of transmission) has been recommended. For studying new HIV cases in small societies, relative risk (RR) rates are preferred over incidence indicators. Spatial clustering based on the calculation of RR rates allows us to locate the high-risk areas of HIV infection with greater accuracy.\n\nIn our opinion, in the process of epidemic generalization, the spatial divergence of epidemic will be observed as well. In particular, clusters with high RR of sexual HIV transmission independent from the clusters with high RR of injection HIV transmission may appear.\n\nWe used spatial clustering based on reported HIV cases acquired through IDU and sexual transmission from 1994 to 2009 in the smallest administrative units (called Radas) in the rural territory of the Odessa region, Ukraine. For the formal spatial clustering, we used Kulldolf Spatial Statistics, realized in the SatScan program. Clustering was conducted by the Poisson model. We used the circle window and set the cluster size limit empirically at 15% of the at-risk population. The study was done in clusters with high RR.\n\nVisualization was carried out on QuantumGIS.\n\nWith clustering, the HIV incidence due to IDU and sexual intercourse were mostly identical in the 1994\u00c11999 and 2000\u00c1 2004 periods. However, three spatial clusters of sexually acquired HIV emerged in the 2005\u00c12009 period (RR 0 3.44, p 0 0.0005; RR 0 10.60, p0 0.011; RR 0 2.18, p 0 0.0265), which did not correspond to an increased RR of IDU-acquired HIV (see Fig. 1 ). Proportion of Radas, simultaneously included in the clusters of both types of HIV transmission, decreased from 64.58% in 2000\u00c12004 to 48.33% in 2005\u00c12009.\n\nTo test the effectiveness of the method, we compared the number of Radas where HIV cases were registered due to sexual transmission only and were not detected due to IDU. In the 2005\u00c12009 period, we observed an increase in the number of Radas reporting sexually acquired HIV cases but not IDUacquired HIV cases.\n\nThe spatial clustering of the HIV epidemic in the rural areas of the Odessa region showed a divergence in the spatial distribution between IDU and sexually transmitted HIV. We believe this finding may indicate the generalization tendencies of HIV epidemic. Our hypothesis has been supported by other epidemiological characteristics, such as: increase in number of sexual HIV cases and their proportion in the total number of HIV cases; increase in proportion of Radas reporting sexually acquired HIV cases but not IDU-acquired HIV cases; increase in the proportion of sexual HIV cases reported in these Radas; HIV seroprevalence among pregnant women in the region accounted in average to 0.9\u00c11.1%.\n\nTo estimate HIV epidemic stage, additional methods of epidemiological analysis like spatial analysis of morbidity can be used. \n\nOHA, in collaboration with the Johns Hopkins University Applied Physics Laboratory, implemented a syndromic surveillance system, Oregon ESSENCE. A critical component to developing and growing this statewide system is obtaining buy-in and voluntary participation from hospital EDs. This process involves approval at multiple levels within a hospital facility from administration to information technology (IT) staff responsible for sending electronic ED data to the Oregon ESSENCE system. Therefore, developing marketing materials that appeal to a wide range of recruitment audiences is a key step in obtaining stakeholder buy-in. OHA adopted the ISDS and CDC syndromic surveillance standards for the public health objective of the Center for Medicaid and Medicare Services (CMS) Meaningful Use Programs. However, Oregon hospitals will not receive financial incentive to participate in Oregon ESSENCE from CMS until 2014 during stage two of Meaningful Use. Consequently, this project's early years will focus on obtaining voluntary participation from hospitals.\n\nOHA developed a recruitment packet to provide information to hospital Chief Executive Officers, Chief Information Officers, Infection Preventionists, Meaningful Use coordinators and IT staff. The packets will be distributed in a number of ways: primarily, during face-to-face meetings with hospital and public health stakeholders, and also during other forums such as meetings of the Oregon Association of Hospitals and Health Systems as well as broader Meaningful Use seminars. Recruitment folders include a brief overview of syndromic surveillance and the ESSENCE system (Welcome to Oregon ESSENCE); a description of utility (Oregon ESSENCE: Real-time Data for Public Health Action); a list of the requested variables (Oregon ESSENCE Data Fact Sheet); examples of effective uses of ESSENCE (ESSENCE success stories); a visual diagram of the data flow process (Oregon ESSENCE data flow); and a list of action steps to begin participation (Let's Roll).\n\nWe developed an informative packet of materials for a variety of audiences that is both appealing and concise. Oregon's hospitals come in all shapes and sizes, each with unique approval processes for engaging in data sharing, prioritization of voluntary public health projects, coordination of Meaningful Use efforts and IT support. Therefore, we expect that the breadth and depth of the marketing materials will be a critical component to successful recruitment of hospitals.\n\nWe developed appealing and concise information packets for a variety of audiences. While each individual may not need the full breadth of the information we are providing, depending on their role at the hospital, we anticipate that the recruitment packet provides a useful overview of Oregon ESSENCE and syndromic surveillance to a variety of hospital and public health stakeholders.\n\nEmergency departments; data exchange; marketing *Melissa Powell E-mail: melissa.e.powell@state.or.us\n\nOregon Health Authority (OHA), in collaboration with the Johns Hopkins University Applied Physics Laboratory, recently implemented Oregon ESSENCE, an automated, electronic syndromic surveillance system. One way to strengthen syndromic surveillance is to include data from multiple sources. We are integrating data from emergency departments, state notifiable conditions and vital statistics and the Oregon Poison Center (OPC). Implementing ESSENCE in Oregon provided the opportunity to automate poison center surveillance, which was previously done manually. In order to achieve this, OHA needed a daily data feed of OPC data to upload into Oregon ESSENCE servers. For OPC to do this directly, they would have incurred significant costs to develop the necessary electronic infrastructure to query and send the data; furthermore, OPC does not employ IT staff. OHA does not currently have funding available to support IT system interoperability with Oregon ESSENCE; so, we sought a low-cost solution that would build upon existing systems that utilized the National Poison Data System (NPDS) web service.\n\nOPC facilitated OHA access to the NPDS web service, which OHA could use free of charge. Access to the web service consisted of requesting approval from the local poison center and adhering to an NPDS web service data use agreement between OPC and OHA. We use FileMaker, a commercial off the shelf database application, to automatically query the NPDS web service on a daily basis. The queried data are then automatically sent from a local database temporarily storing the information to the ESSENCE servers. OHA already uses FileMaker for managing notifiable conditions data (i.e., communicable disease reporting); so, there were no new licensing costs associated with this method.\n\nOPC data are available within the ESSENCE application to OHA syndromic surveillance staff. Sending OPC data into ESSENCE allows OHA staff to monitor timely OPC data in an automated, routine manner. When alerts are generated within the ESSENCE system, they are first assessed by syndromic surveillance staff. Those that require follow-up trigger a call between OHA and OPC. Oregon is the first state to use the NPDS web service to upload poison center data into ESSENCE.\n\nOHA previously monitored OPC data using two methods: (1) through the NPDS system using a web-based interface; and (2) through ToxiTrack, poison center database software. ToxiTrack software is a companion software to Toxicall \u2020 , the data collection software system utilized by OPC. Data from Toxicall were transferred via VPN to OHA, where ToxiTrack software was used to view data. Although both of these systems provide unique capabilities for viewing summarized case data, there are limitations in their functionality for situational awareness. ESSENCE offers OHA the ability to easily analyze and report on these data and geospatial graphing capabilities without having to use additional statistical and GIS software.\n\nIntegration of poison center data into Oregon ESSENCE supports the initiative to develop a statewide syndromic surveillance system that includes a variety of data sources. It also addresses the need for improved, timely communication between OPC and OHA that was identified following Oregon's response to the 2011 Japanese Earthquake and Radiation event. Because OPC data are integrated into ESSENCE, OHA staff members are able to develop an understanding of expected call volumes and types during day-to-day operations. This is an important component of ongoing situational awareness as we learn what to expect and also how to interpret data from OPC. This resource-effective solution can be applied to jurisdictions that use a variety of applications to monitor their poison center data.\n\nPoison center; web service; integration across data sources; resource-limited settings *Melissa Powell E-mail: melissa.e.powell@state.or.us Introduction Syndromic surveillance of health care data such as the International Classification of Diseases, Ninth Revision (ICD-9), codes related to ILI, was used to track the progression of the 2009 Fall Novel H1N1 outbreak in the Madison area (1) . Early studies focused on prediction of an outbreak; however, further investigation of patient resource utilization would be helpful in developing an action plan for addressing community and patient needs during future outbreaks. There is a paucity of research comparing ED and urgent care utilization rates during the 2009 Novel H1N1 pandemic, though there are regional data suggesting that urgent care centers bore a larger portion of the burden of H1N1 influenza than EDs (2) . Furthermore, one group found that ILI-related phone calls to urgent care centers predicted influenza outbreak at least 1 week ahead of peaks in the ILI hospital care consultation rates (3) . ED data on its own have proven useful for public health disease surveillance (4, 5) , and many studies group urgent care and ED care together. The literature is lacking subgroup analysis of these two very different care environments. Understanding the correlation between urgent care and ED utilization rates will provide a more in depth understanding of the stress that the 2009 Fall Novel H1N1 placed on community resources in our geographic region.\n\nThis study is a cross-sectional retrospective analysis of ED vs. urgent care utilization rates for ILI in the greater Madison area from October 2009 to December 2009. The proportion of ILI encounters was calculated for two university-based urgent care centers (grouped) and compared with the ED data from the same university-based system. Proportions were calculated from ICD-9 and total daily encounter volume data.\n\nThe average proportion of encounters for ILI at urgent care centers was 0.298 in comparison with 0.125 for ED visits during the 2009 Fall Novel H1N1 influenza outbreak. Graphical trends in illness were comparable.\n\nPatients in our geographic region were 2.4 times more likely to seek care at urgent care centers for ILI during the Fall wave of the H1N1 influenza pandemic. Neither care site predicted the outbreak more effectively than the other. \n\nThe critical need for population-level interventions to support the health needs of the growing population of older adults is widely recognized (1). In addition, there is a need for novel indicators to monitor wellness as a resource for living and a means for prediction and prevention of changes in community health status (2) . Smart homes, defined as residential infrastructure equipped with technology features that enable passive monitoring of residents to proactively support wellness, have the potential to support older adults for independence at the residence of their choice. However, a characterization of the current state of smart homes research as a population health intervention is lacking. In addition, there is a knowledge translation gap between the smart homes research and public health practice communities.\n\nThe EBPH movement identifies three types of evidence along a continuum to inform population health interventions: Type 1 (something should be done), Type 2 (this should be done) and Type 3 (how it should be done) (3). Type 2 evidence consists of a classification scheme for interventions (emerging, promising, effective and evidence based) (3). To illustrate typology use with an example: the need for population health interventions for aging populations is well known (Type 1 evidence), many studies show that smart home technologies can support aging in place (Type 2 evidence), but there are few, if any, examples of smart homes as population health interventions to support aging in place (Type 3 evidence).\n\nOur research questions for this systematic review are as follows:\n\n1) What categories of Type 2 evidence from the scientific literature uphold smart homes as an EBPH intervention? 2)\n\nWhat are the novel health indicators identified from smart home studies to inform design of a community health registry that supports prediction and prevention of negative changes in health status? 3)\n\nWhat stakeholders are reported in studies that contribute Type 2 evidence for smart homes as an EBPH intervention? 4)\n\nWhat gaps exist between Type 2 and Type 3 evidence for smart homes as an EBPH intervention?\n\nOur search methodology includes searches of MEDLINE, CINAHL and IEEE conference proceedings databases to provide coverage across a literature that is found in many disciplines and is not well-indexed. As the term 'smart home' is not well-defined, our search terms also include 'telemedicine', 'telehealth', 'e-health', 'health monitoring', 'gerontechnology' and 'gerotechnology' in combination with 'older adult', 'elderly', 'aging', 'ageing', 'community-dwelling' and 'senior'. Our inclusion criteria include any study that describes a technology designed for an older adult audience to support wellness management through social, spiritual, physical or cognitive means (4). Our exclusion criteria include smart homes designed for efficiency and nonhealth-related surveillance technologies.\n\nInitial search results indicate many studies that can be classified as Type 2 evidence along the continuum of emerging, promising, effective and evidence-based smart home interventions. Initial findings are that Type 3 evidence is lacking and public health policy makers are underrepresented.\n\nEarly analysis of complete search results will be presented for (1) categorizations of evidence according to the evidence-based public health typology, (2) enumeration of stakeholders reported in included studies and (3) identification of novel indicators of health to inform design of a standards-based community health registry for older adults.\n\nSmart homes; population health; aging in place; older adults; informatics\n\nIn May 2001, Boston released a strategic transportation plan to improve bicycle access and safety (1) . According to the Boston Transportation Department, ridership has increased 122% between 2007 and 2009 (2). A collaborative public health and public safety task force was initiated in 2010 to foster a safe and healthy bicycling environment.\n\nThe Boston Public Health Commission (BPHC) syndromic surveillance system receives information from ED visits from all 10 acute care hospitals in Boston every 24 hours. Data received include visit date, demographics, ZIP code of residence, chief complaints and ICD-9 CM-coded final diagnosis. Disposition information was reported from 9 of these hospitals in 2010. BPHC collaborated with CDC's BioSense Program to specify a BRI syndromic case definition that combined chief complaint and ICD-9 CM-coded information and excluded motor cycle only related events. Subsyndromes were used to assess the type of injury and severity based upon 47 standard BioSense subsyndromes and 21 subsyndromes developed for this study. The data sample used for this study included over 2 million visits between 2007 and 2010. Injury visits were categorized at the neighborhood level using a standard ZIP code of residenceto-neighborhood mapping. Results were stratified by age, patient neighborhood of residence, race/ethnicity, gender and disposition (2010 data only).\n\nOver the study period, a total of 4510 ED visits were classified as BRIs (0.22%). The percentage of BRI visits increased from 0.18% in 2007 to 0.27% in 2010. The majority of injuries (69%) occurred between May and September (Fig. 1) and likely corresponds to increased bicycling activity during those months.\n\nSeventy-five percent of persons presenting with BRIs were male and 60% reported race/ethnicity as white. Persons aged 18\u00c1 25 years represented 28% of visits and those aged 6\u00c117 years accounted for 17%. Boston residents accounted for 52% of BRI visits; 15% were from bordering communities. One Boston neighborhood with the highest BRI rate by patient residence also has a large college student population.\n\nThroughout the entire study period (2007\u00c12010), nearly one quarter (1082) of BRI visits were associated with fractures and dislocations; whereas less than 10% of visits were for sprains or strain injuries. Head injuries were associated with 84 (1.9%) of BRI visits.\n\nIn 2010, 149 (11%) of the 1411 BRI visits resulted in admission, most commonly for fractures and dislocations. Twenty-two percent were among individuals aged between 50 and 59 years; 21% were among persons aged 18\u00c124 years. Fiftyfour percent of all BRI admissions were associated with fractures and dislocations. Thirty-one (2.2%) BRI visits in 2010 were associated with head injuries; of which 11 (35%) were admitted for care. For BRI visits involving falls, 8% were admitted versus 17% for BRI visits associated with a motor vehicle.\n\nSyndromic surveillance can be used to monitor and track BRI and to inform targeted prevention activities such as education and outreach to select at-risk populations (e.g., college students). Presently, information on the environmental context of injuries, such as the precise location of the accident, is limited. As bicycle use increases, improved methods to combine syndromic surveillance, emergency medical services and public safety information are needed to identify accident 'hot spots' to guide implementation of preventive measures.\n\nInjury; prevention; emergency; bicycle; syndromic surveillance \n\nAnimal bites may have potentially devastating consequences, including physical and emotional trauma, infection, rabies exposure, hospitalization and, rarely, death (1). NC law requires animal bites be reported to local health directors (2) . However, methods for recording and storing bite data vary among municipalities. NC does not have a statewide system for reporting and surveillance of animal bites. Additionally, many animal bites are likely not reported to the appropriate agencies (3) .\n\nNC DETECT provides near-real-time statewide surveillance capacity to local, regional and state-level users with twice daily data feeds from NC EDs. Between 2008 and 2010, 110 to 113 EDs were submitting visit data to NC DETECT. Several animal bite-related online reports are available and provide aggregate and visit-level analyses customized to users' respective jurisdictions. The NC DETECT ED visit database currently provides the most comprehensive and cost-effective source of animal bite data in NC.\n\nSeveral NC DETECT animal bite-related reports were developed based on chief complaint and triage note keyword searches and ICD-9-CM codes. Using the Animal Bite Keyword Report, statewide ED visit data were extracted for 2008\u00c12010. ED visit records in NC DETECT were examined manually to assess the performance of case definition keywords. Using the Animal Bite ICD-9-CM Code Report, statewide ED visit data were extracted for 2008\u00c12010. The following ICD-9-CM injury codes are included in this report: E906.0 (dog bite), E906.1 (rat bite), E906.3 (bite of other animal except arthropod) and E906.5 (bite by unspecified animal). The burden of ICD-9-CM\u00c1coded animal bite visits to total ED visits was examined by age group and gender.\n\nReview of Animal Bite Keyword Report data revealed several additional case definition inclusion and exclusion keywords. This knowledge has led to continued development of keyword reports. The Animal Bite ICD-9-CM Code Report indicated a total of 33,294 ED visits for animal bite from 2008 to 2010. For each year, the highest proportion of ICD-9-CM\u00c1coded animal bite ED visits to total ED visits were for 5\u00c19 year olds (Fig. 1) . Across all 3 years, males had a slightly higher proportion of animal bite-coded ED visits to total ED visits (0.28%) compared to females (0.23%).\n\nCase definition development for the Animal Bite Keyword Report is an iterative process. Sensitivity and specificity of keyword reports must be considered, and case definitions should depend on the report's intended use. Evaluation of the Animal Bite ICD-9-CM Code Report showed 5\u00c19 year olds and males have the highest proportion of animal bite-coded ED visits in NC. A snake bite report and animal bite incidence rate reports are under development. NC DETECT is a valuable source for animal bite surveillance in NC.\n\nAnimal bite; surveillance; emergency department \n\nIn March\u00c1April 2011, Salt Lake Valley Health Department (SLVHD) investigated an outbreak of measles (N 09) resulting from a single imported case from Europe. Syndromic surveillance was used to identify measles-like illness (MLI) and enhance early case detection, which is crucial for proper public health intervention (1).\n\nDaily text-based chief complaint data, March 23\u00c1May 5, 2011, from 15 syndromic sites were obtained from EpiCenter (2) (funds provided by Utah Department of Health), mapped to 5 MLI syndromes (Table 1 ) and summarized using the Early Aberration Reporting System (EARS) (3) . Events of interest included all 'rash' events that contributed to an alert or had a concerning chief complaint (e.g., eye pain), all 'febrile rash' events that had a concerning chief complaint, all 'prodrome' events that had a concerning chief complaint, all 'case definition' events April 7, 2011 onward (date after which public health intervention was still possible) and all 'measles/testing' events. Visit notes, laboratory tests and results were obtained daily for each event of interest and reviewed for MLI. Summary findings, including diagnoses, laboratory results, rash descriptions and suspect exposures, were documented and non-MLI events were ruled out. Events of high suspicion for measles were further investigated via patient interview by phone and/or home visit.\n\nNinety-seven events of interest (of 2365 events captured in MLI syndromes) were identified: 32 rash, 58 febrile rash, 1 prodrome, 12 case definition and 8 measles/testing (14 were categorized in ! 1 syndrome). Eighty-four events of interest were ruled out based on chart findings. Thirteen events of high suspicion for measles required further investigation. Twelve events were ruled out based on negative measles IgM results, evidence indicating other diseases (fifth disease and Kawasaki syndrome), vaccine reaction or inaccurate documentation of clinical symptoms. One event was found to be confirmed by positive measles IgM (Fig. 1) .\n\nEarly identification of a measles case using syndromic surveillance during an outbreak was crucial in reducing contact exposures, preventing additional cases and reducing the cost associated with proper public health intervention. We estimate that early detection of the remaining 8 confirmed cases by syndromic surveillance could have reduced the direct cost of the outbreak by 82%. Syndromic surveillance played a significant role in curtailing the outbreak as a valuable tool to supplement active surveillance.\n\nMeasles; syndromic surveillance; early detection; outbreak; cost Introduction Syndromic surveillance systems use electronic health-related data to support near-real time disease surveillance. Over the last 10 years, the use of ILI syndromes defined from emergency department (ED) data has become an increasingly accepted strategy for public health influenza surveillance at the local and national levels. However, various ILI definitions exist and few studies have used patient-level data to describe validity for influenza specifically.\n\nA retrospective design was used to evaluate clinical records for a predictive model of lab-confirmed influenza. Children who presented to the ED at Seattle Children's Hospital between January 1, 2001 and May 31, 2005 were eligible for inclusion in the study. The accuracy of four syndrome definitions were compared for identifying lab-confirmed influenza: (1) ILI from chief complaint (CC) or diagnoses codes (''ILI''); (2) ILI from CC alone; (3) febrile illness from CC or diagnoses (''Febrile''); and (4) febrile illness from CC alone. We evaluated syndrome validity over two distinct time periods: (1) the ''discrete'' 2003\u00c104 influenza season, which had relatively less co-circulation of influenza and respiratory syncytial virus (RSV) compared to most years, and (2) the ''concomitant'' 2000\u00c105 influenza seasons (excluding 2003\u00c104), when influenza and RSV co-circulation was high. Analyses during the concomitant years were further stratified by age B5 years and ]5 years. Multiple imputation was used to address missing viral lab results. The imputation model was based on testing guidelines in place at the hospital during the time of study.\n\nWe studied approximately 14,000 visits during the discrete year and 32,000 visits during concomitant years. Viral results were unavailable for approximately 75% of respiratory visits and multiple imputation was used to impute values. During the discrete year, sensitivity and specificity were 0.49 (95% Confidence Interval [CI]: 0.30, 0.68) and 0.72 (CI: 0.70, 0.74) respectively, for the ''Febrile'' definition and 0.29 (CI: 0.13, 0.54) and 0.89 (CI: 0.87, 0.90) for the ''ILI'' definition. ILI sensitivity was 2.05 (CI: 1.08, 3.91) times greater and its false positive fraction 44% (CI: 37%, 49%) lower in concomitant years compared to the discrete year. Greater sensitivity and false positive fractions (1-specificity) tended to be produced by the febrile definitions than by the ILI definitions; and by definitions derived from CC or diagnoses as compared to those from CC alone. The false positive fraction of all syndrome definitions was higher in younger children compared to older children.\n\nAlthough the sensitivity of syndromic ILI definitions was not high by clinical standards, our interest was to understand the proportion of influenza cases in the community being captured by the system. ED ILI may provide a more robust estimate of the burden of disease than laboratory surveillance, which captures only a subset of patients seen by a healthcare provider and who were tested. The higher specificity of the ILI definitions suggests it is best used for situational awareness during influenza outbreaks and for distinguishing influenza from other viral agents. The use of several definitions throughout the season may be most appropriate in some settings. Public health practitioners should bear in mind that syndrome performance may vary by season and year. Higher syndrome specificity among older children suggests specificity in adults should be higher than that observed for younger populations. However, the generalizability of these results to adult populations and other hospitals is uncertain and should be further studied.\n\nThe electronic surveillance system for the early notification of community-based epidemics (ESSENCE) is the web-based syndromic surveillance system utilized by the Maryland Department of Health and Mental Hygiene (DHMH). ESSENCE utilizes a secure, automated process for the transfer of data to the ESSENCE system that is consistent with federal standards for electronic disease surveillance. Data sources in the Maryland ESSENCE system include ED chief complaints, poison control center calls, over-the-counter (OTC) medication sales and pharmaceutical transaction data (specifically for antibacterial and antiviral medications). All data sources have statewide coverage and are captured daily in near real-time fashion.\n\nForty-six EDs, two major pharmacy chains, two poison control centers and the Centers for Disease Control and Prevention (through a pilot partnership), all contribute data to ESSENCE on a daily basis. Data reported from June 1, 2009, through January 1, 2011, were used to examine the relationships between ED visits for ILI and antiviral (M2 inhibitors and neuraminidase inhibitors) prescription medication transactions in the state of Maryland. ArcGIS 9.2 was used to spatially evaluate these relationships. Data for the total population of Maryland by jurisdiction were obtained from the U.S. Census Bureau, Census 2010 PL94-171 release and prepared by the Maryland Department of Planning, Projections and Data Analysis/State Data Center, April 2011.\n\nGenerally, jurisdictions with the highest populations also had the highest number of ILI ED visits and the highest numbers of antiviral prescription medication transactions. These results did not vary based on type of antiviral medication. There was one exception to the general trend: County 14 had the lowest percent of ILI ED visits (0.45%) but the highest percentage of antiviral prescription medication transactions (1.26%). Spatial analysis showed that the highest number of ILI ED visits were in the National Capital Region (NCR) and Central Maryland while the highest numbers of antiviral prescription medications were in the NCR Region.\n\nThe trends seen in this analysis follow what is to be expected; the counties with the larger populations had higher numbers of ILI ED visits and higher antiviral prescriptions. These larger counties have more hospitals, which allows for greater access to EDs. County 14 has only one hospital that contributes data to the ESSENCE system; thus, residents may have traveled to an ED in another county but filled a prescription in their home county. This could account for why County 14 had the lowest number of ILI visits and the highest number of antiviral prescriptions. This county also has a very high median income; thus, it is possible that ED visits were lower because more individuals sought medical attention from primary care physicians. Other counties may follow these same trends.\n\nThe ESSENCE system has been a useful tool in the tracking and monitoring of diseases such as influenza. It is also used as an indicator to local health departments to begin preparation for flu season. DHMH will continue to use syndromic surveillance on a daily basis for early detection of seasonal and pandemic influenza. \n\nEvaluation was conducted through electronic telecommunication with the disease control staff of the D/M HOs and checking of websites and S-R electronic bulletins.\n\nTogether with the staff of the Sardjito Hospital (teaching hospital of the GMU SM), local D/MHOs and the GMU MS Department of Public Health, the CHSM developed Standard Operating Procedures for S-R core and support functions of MNCH priority diseases (e.g., postpartum bleeding, preeclampsia/eclampsia, LBW and pneumonia) as well as of other major diseases (e.g., malaria, TB, DM and hypertension). The training sessions and consultations were effectively executed in the target districts and municipalities. Based on the performance of the electronic bulletins, however, only one DHO has a functioning S-R support unit. Efficacy of the S-R Systems strengthening approach used by the CHSM could not be evaluated by way of on-the-spot interviews, observation and review of S-R records/ reports due to financial constraints.\n\nA more intensive strengthening method is required to ensure sustainable operation of core and support functions of S-R Systems. The MoH is considering to post at least one Field Epidemiology Training Program (FETP) graduate at the D/M HOs. These FETP graduates, and students, could be used to build and enhance S-R systems for priority diseases and to conduct valid monitoring-evaluation.\n\nSurveillance-response; MNCH; strengthening; Indonesia\n\nThe Government of Indonesia (GoI) aims to eliminate malaria by 2030 in 4 stages (1). To reach the elimination phase, High Case Incidence (HCI) areas go through a preelimination phase. The aim of the proposed project is to support one of the Stage 3 provinces in reaching the preelimination phase by 2015 and to assist its HCI districts and municipalities in reorienting their programs to malaria elimination. The preelimination phase can be attained by following these evidence-based technical strategies: (1) prompt and accurate diagnosis of cases; (2) prompt treatment with effective medicines, including intermittent preventive treatment in pregnancy (IPTp); (3) selective, targeted and integrated vector control; and (4) emergency and epidemic preparedness (2) .\n\nThese strategies can only be properly carried out if the District/Municipal Health Offices (D/M HOs) have a timely, useful and reliable malaria surveillance-response (S-R) system. The use of computers and electronic telecommunication networks has sped up the flow of institution-based case surveillance data to the D/M HO.\n\nTo increase its usefulness, however, the S-R system must include data of cases detected in the community along with data of the disease agent and environment. The proposed project will include the collection of all these surveillance data in order to be useful for the implementation of malaria control strategies. Furthermore, to increase timeliness and reliability, the project will support the malaria S-R systems of the Bangka Belitung Province, Sumatera, by means of cell phone (CP) applications through the following activities:\n\nTo develop a CP software for a malaria S-R system and to set up a malaria S-R central data bank (CDB) that will be placed at a commercial hosting server.\n\nTo set up a village CP network in each HCI village for demographic data and home malaria management (HMM) data reporting by households.\n\nTo train village midwifes or village malaria workers (VM/ MW) to provide HMM, to administer IPTp to pregnant members, to send diagnosis, treatment and IPTp data to the CDB and to obtain blood films for microscopic examination by the HC parasitology microscopist.\n\nTo train HC parasitology microscopists to perform microscopic examinations, to use a microscopy-enabled CP for sending microscopy images to the Provincial Lab for reliability testing and to send data to the CDB.\n\nTo train HC coassistant entomologist, D/M HO assistant entomologist and Provincial HO entomologist to collect vector and environment data, to use a CP for sending vector control targets data to the CDB and to use a microscopy-enabled CP for sending microscopy images to the Provincial Lab for reliability testing.\n\nTo provide consultations, training and resources for the D/ MHOs to facilitate the utilization of CP applications for reporting demographic and HMM data and drug and insecticide resistance/efficacy sentinel surveillance and to facilitate sector and intersector surveillance-based rapid and planned response decision making.\n\nTo ensure the attainment of project objectives, the GMU CHSM and collaborating institutions will (1) obtain endorsements from the heads of the District/Municipal and Provincial Governments; (2) engage MoH Directorate of Malaria and GMU Medical School staff in workshops and technical guidance; (3) engage malaria program managers of the District/Municipal and Provincial HOs as project field coordinators; and, (4) recruit experienced technicians as on-the-job trainers in parasitological microscopy, entomology and information technology and experienced experts as trainers and consultants in public health surveillance and management.\n\nPoster presentation at the ISDS 10th Annual Conference 2011.\n\nDescription: CDC works to save lives and protect people during major public health events. In an effort to support these processes, CDC established CTS, which is maintained within the Division of Informatics Solutions and Operations (DISO), in the Public Health Informatics and Technical Program Office (PHITPO). CTS consists of four system components, which interoperate to improve communications and event response efficiency while still functioning independently, recognizing the unique requirements and use cases for each system. Collectively, the data consolidated from these systems can show population coverage, numbers of untreated individuals, drug and equipment shortages, need for resupply and more. The web-based applications are deployed centrally at CDC and use the CDC's secure data access method for security.\n\nThe first of these components is the Inventory Management and Tracking System (IMATS), currently under development. IMATS provides state and local public health providers with a tool to track medical and nonmedical countermeasure inventory and supplies during daily operations or an event. The solution tracks quantities of inventory, monitors reorder thresholds and facilitates warehouse operations including receiving, staging and storing of inventory.\n\nThe Communications Portal is a web-based content management system in development, which consolidates important event response details into one place and will provide timely and adequate information to states and other jurisdictions. This system is complementary to the IMATS as it manages communications related to, but not limited to, Emergency Use Authorization (EUA), Investigational New Drug (IND) and recall notices.\n\nPreparing for the future of public health surveillance also requires innovative and appropriate informatics systems that provide timely and accurate response to all-hazards events. CTS and its components are developed to assist in all types of surveillance needs.\n\nCountermeasure; all hazards; public health; inventory; tracking\n\nFor public health surveillance to achieve its desired purpose of reducing morbidity and mortality, surveillance data must be linked to public health response. While there is evidence of the growing popularity of syndromic surveillance (1, 2) , the impact or value added with its application to public health responses is not well described (3) .\n\nOntario's 36 public health units, the provincial ministry of health and federal public health agency completed a web survey in 2010 to identify surveillance systems used routinely and during the pandemic and to describe the perceived utility of systems for monitoring pandemic activity and informing decision making. Follow-up semi-structured interviews were conducted with key informants to elucidate drivers for specific public health actions taken during the pandemic and, specifically, to understand the role syndromic data played in influencing decisions among those who had access.\n\nThe web survey identified 20/38 (53%) organizations which use at least one syndromic surveillance system; key informant interviews identified another 2 organizations, for a total of 22/38 (58%) syndromic surveillance 'users'. Mirroring routine surveillance, traditional surveillance systems, specifically laboratory and reportable disease data (iPHIS) and school absenteeism data were the most frequently used sources during the pandemic (Fig. 1) . Laboratory data were considered the most useful data source for monitoring the epidemiology (71% of organizations perceived it as 'essential') and informing decision making (76%), while emergency department screening data were considered the most useful syndromic surveillance source (52% and 70%). Syndromic data were found to support two specific public health actions taken during the pandemic: influenza assessment centers and communications, including recommendations to the public. Informants felt that syndromic data provided confidence to decide whether and when to open/close influenza assessment centers and when/what to communicate to the public. Nonsyndromic users utilized stakeholder consultations and traditional surveillance data to support these decisions. Syndromic surveillance did not appear to have a role in supporting decisions around immunization clinics, school closures or recommendations to health care professionals; rather vaccine availability and ministerial guidance acted as drivers for these decisions.\n\nWhile traditional surveillance systems were considered most essential for monitoring the pandemic locally and informing decisions, syndromic surveillance was found to support several public health actions taken during the pandemic. Understanding how syndromic surveillance systems are valued, utilized and linked to public health action is necessary to inform investments to build surveillance capacity.\n\nPublic health surveillance; syndromic surveillance; pandemic influenza; evaluation \n\nInformal surveillance systems like HealthMap (HM) are effective at the early detection of outbreaks (1, 2) . However, reliance on informal sources such as news media makes the efficiency of these systems vulnerable to newsroom constraints, namely highprofile disease events drawing reporting resources at the expense of other potential outbreaks and diminished staff over weekends and holidays. To our knowledge, this effect on informal or syndromic surveillance systems has yet to be studied.\n\nUsing HM's English-language global infectious disease database events (3), we identified expected periods of decreased reporting of infectious disease due to newsroom constraints between July 1, 2008, and August 31, 2011. Crowdout events were defined as averaging greater than five events per day for at least 2 weeks, plus making up at least 50% of daily events. Meeting these criteria were H1N1/swine flu (two instances), Haiti's cholera epidemic, 2010, and the E.coli outbreak in Germany, 2011. The December holiday period, when most of the newsroom is off duty, was also tested. We examined whether the average number of noncrowdout events differed significantly from the average daily HM events at baseline, defined as similarly structured periods without holidays or high-profile epidemic events. Baselines were measured before and after the crowdout period, plus during the same time period in other applicable years. Means were compared using paired t tests with unequal variances.\n\nThe two instances where H1N1 met inclusion criteria both resulted in average numbers of daily events significantly lower than similar periods before, after and parallel to the time period in question (Fig. 1) . See Table 1 for more results. On average, the greatest number of daily events occurs on Thursdays, least on Sundays. The outbreaks of cholera in Haiti and E. coli in Germany showed no significant crowdout effect at both global and regional levels. A reduction in the average events per day during the December holiday period was not significant.\n\nInformal surveillance has limitations that are exacerbated by newsroom constraints. During the global H1N1 pandemic, significantly fewer infectious disease events were recorded by HM's informal surveillance system. Crowdout poses a risk for epidemiological surveillance since decreased relative surveillance may postpone reporting of outbreaks. Moreover, crowdout during H1N1 showed that this phenomenon can endure for long time periods. However, regional outbreaks like cholera in Haiti or E. coli in Germany do not appear to affect informal surveillance on a global or regional scale.\n\nInformal surveillance; syndromic surveillance; infectious disease; epidemics; media \n\nEpi-X is an internet-based secure website for the exchange of information regarding developing public health events. Reports are exchanged with state epidemiologists, state health officers and other key public health officials. Provisional and secure information is regularly posted on Epi-X. The Epi-X user base is restricted to public health officials at the local, state, federal and international levels. Private healthcare practitioners who do not otherwise hold a government position are not given access to Epi-X. As of August 2011, Epi-X has approximately 6000 users, of which approximately 1600 are authorized to directly contribute reports regarding developing public health events. Epi-X is frequently used to seek reports of cases of illness related to an outbreak, cluster or increased occurrence of a specific infectious disease. The usability and usefulness of Epi-X in this capacity have not previously been assessed.\n\nA total of 52 case-seeking reports were posted on Epi-X during calendar year 2010, all of which were used to seek cases of infectious disease. Epi-X staff were successful in eliciting contributor feedback in regards to 30 of these reports. Four questions were asked that assessed the motivation behind posting a case-seeking report on Epi-X, the practicality of posting a case-seeking report on Epi-X, the successfulness of finding related cases by posting a case-seeking report on Epi-X and if the contributor intends to use Epi-X for this purpose in the future.\n\nOf the 52 case-seeking reports posted on Epi-X during calendar year 2010, all were posted with the intent of seeking cases of illness caused by infectious disease. One report was broad based and also sought cases of illness caused by injury. These reports were categorized by type of infectious agent, depending upon commonality of symptoms and routes of transmission. Epi-X contributors posted case-seeking reports for 19 individual confirmed or suspected infectious agents in 2010. The top four infectious agents for which case-seeking reports were posted on Epi-X in 2010 were Salmonella (10 reports), Legionella (9), hepatitis A virus (4) and measles virus (4) . Other infectious agents included Influenza, Bordetella, Cryptosporidium, Escherichia coli and Listeria. Three reports were posted for which the infectious agent was unknown.\n\nThe 52 reports were contributed by 44 contributors. Epi-X staff were able to elicit feedback from contributors for 30 reports. In regards to usability, the system was considered practical for 28 of the 30 reports for which feedback was elicited. In regards to case-seeking usefulness, 2 of the 30 case-seeking reports for which feedback was elicited were considered not successful; eight were considered moderately successful, and 15 were considered fully successful. For five reports, the contributor was unable to rank the success. Of the 30 respondents, 28 stated their intent to use Epi-X for this purpose in the future.\n\nEpi-X case-seeking reports were considered at least moderately successful in 23 of 30 reports for which feedback was elicited. In some instances, investigators expected to find no other related cases but posted their reports to make sure they had been thorough. Some investigators regarded their report(s) as successful, despite not finding any additional cases. Investigators may become more confident that all related cases have already been identified if they do not find additional cases as a result of posting on Epi-X.\n\nEpi-X has become a standard method of identifying related cases. For investigators seeking additional cases in other statelevel jurisdictions, posting case-seeking reports on Epi-X is a practical method. Increased use would likely strengthen the public health response to emerging infectious-disease events.\n\nThe Epidemic Information Exchange; Epi-X; surveillance; secure; case finding *James Schwendinger E-mail: bnz2@cdc.gov \n\nHepatitis Avirus (HAV) infection is usually mild in childhood but more severe in adolescents and adults. An estimated 1.4 million cases of HAV infection occur annually in the world. The casefatality rate among patients of all ages is approximately 0.3% but tends to be higher among older persons (approximately 2% for 40 years or older). HAV is a notifiable disease on weekly basis where health centers and hospitals report cases to the health directorates, which in turn report electronically to the Communicable Diseases Directorate, with subsequent paper reporting of detailed epidemiological description. The due time is Tuesday next week. Diagnosis is clinically based and depends on case definition. A previous study in Jordan revealed that reporting rate increased from 6.4 in 2004 to 7.9 in 2008/100,000, the highest reporting rate was in the North region, mainly Mafraq.\n\nTen health centers and one hospital were randomly selected; 13 weeks were also selected randomly from the year 2009. The reporting process was reviewed in the three levels for the number of reported cases of HAV in the selected weeks: the peripheral level by reviewing the reporting forms, notifiable logbooks of the reporting sites; the intermediate level in the health directorate by reviewing the specific notification forms(SNF) from each reporting site, and the comprehensive forms from all reporting sites; and the central level by reviewing the electronic and paper reporting to the communicable diseases directorate.\n\nThe SNF were found for only 15% of reported HAV from Health Directorate in 2009. All the selected reporting sites had commitment in reporting. The sensitivity of reporting from reporting sites to health directorate was 96%; nevertheless, 38% of the reporting sites reported zero cases. HAV surveillance in Mafraq was evaluated upon application of CDC criteria for evaluation of surveillance system (as demonstrated in Table 1 ).\n\nThe increased number of HAV-reported cases in Mafraq is not related to a public health hazard; it is probably a result of relatively reasonable surveillance system. The reporting protocol is not well implemented, it is mostly phone based, and this will weaken the sensitivity of surveillance system; therefore, paper-based reporting should be enhanced.\n\nHepatitis A; surveillance; evaluation; Mafraq, Jordan The diagnosis is clinically based and does not depend on laboratory test. Surveillance does not require complex training, equipments or fulltime working personnel. Reporting procedure is telephone based and 'regular mail' based, which is affordable to all reporting centers\n\nThe sureveillance system for HAV is clinically based, it includes also suspect and probable cases, and the reporting is according to available facilities. Case definition could be easily modified to cope with any addition Acceptability Timeliness Almost 38% of the reporting sites did not report any case in 2009; also, 23% of the reporting sites reported three cases or less, this could reflect that the surveillance for hepatitis A is not well accepted Almost all reporting centers reported to the health directorate in exact time by telephone, this is followed by paper reporting. Only 42% of the reports from Mafraq health directorate to the Communicable Diseases Directorate were done electronically; about 90% of the electronic reporting was done on time, 'Tuesday' the next week\n\nData quality HAV surveillance is considered representative as monthly reports give detailed epidemiological information\n\nThe SNFs were found for only 15% of reported HAV cases from Health Directorate; none of HAV cases were investigated. Discrepancies were observed in the reported numbers, as 7% in excess was found in the reporting centers registry in comparison with the original reporting center SNFs; while 6% less was observed between the numbers of reported HAV cases in health directorate registry in comparison with reporting center registry \n\nThe spread of infectious diseases is facilitated by human travel. Disease is often introduced by travelers and then spread among susceptible individuals. Likewise, uninfected susceptible travelers can move into populations sustaining the spread of an infectious disease.\n\nSeveral disease-modeling efforts have incorporated travel and census data in an effort to better understand the spread of disease. Unfortunately, most travel data are not fine grained enough to capture individual movements over long periods and large spaces. Alternative methods (e.g., tracking currency movements or cell phone signals) have been suggested to measure how people move with higher resolution but these are often sparse, expensive and not readily available to researchers.\n\nFourSquare is a social media application that permits users to 'check-in' (i.e., record their currentlocation at stores, restaurants, etc.) via their mobile telephones in exchange for incentives (e.g., location-specific coupons). FourSquare and similar applications (Gowalla, Yelp, etc.) generally broadcast each check-in via Twitter or Facebook; in addition, some GPS-enabled mobile Twitter clients add explicit geocodes to individual tweets.\n\nHere, we propose the use of geocoded social media data as a real-time fine-grained proxy for human travel.\n\nSixty-eight million geocoded entries (tweets and check-ins) from 3.2 million users were collected from the Twitter streaming API for the period from September 11, 2010 through January 28, 2011. The Twitter API provides a random sample of tweets; nongeocoded tweets or tweets originating from outside the United States were discarded. In addition, users with fewer than 6 records, or those who check in too frequently (more than once in 5 seconds) or travel too quickly (faster than 1800 km/hr) were removed to exclude automated bots or other location spam.\n\nWe analyzed a 5-week subset of the data (September 11, 2010 through October 26, 2010) consisting of 3 million record intervals from 165,000 users.\n\nWe display intrastate travel by aggregating each user's consecutive records within each state and plotting only transitions between states (Fig. 1) . The denser edges represent more frequent transitions, illustrating the pattern of travel on a national scale. We also constructed a heat map representation of Manhattan (Fig. 2) by aggregating users' check-ins with 500 m resolution. A larger bubble represents a denser set of records in that geographic area.\n\nBy linking each individual users' consecutive location records together, we computed the statistical distribution of time interval and distance traveled between records. About half of the checkins are less than 6 hr and no more than 1km apart from each other.\n\nWe show that social media location data can be used as multiscale proxy for travel at the national, state and urban level. These data are inexpensive and easily obtained. Furthermore, they can be used not only to understand historical travel but also to monitor in realtime changes in travel behavior to help inform disease surveillance.\n\nFuture work, currently underway, will validate this source of information against other sources of travel data and will investigate its value to better understand the spread of infectious diseases for disease monitoring and surveillance purposes. \n\nAdverse drug events (ADEs) are a major cause of morbidity and mortality (1, 2) . However, postmarketing surveillance systems are passive, and reporting is generally not mandated (2) . Thus, many ADEs go unreported, and it is difficult to estimate and/or anticipate side effects that are unknown at the time of approval. ADEs that are reported to the FDA tend to be severe, and potentially common, but less serious side effects are more difficult to characterize and document. Drugs with a high risk of harm outweighing the therapeutic value have recently been subjected to a greater level of interest with the Food and Drug Administration's Risk Evaluation and Mitigation Strategies (REMS) (3). However, no rapid method to detect if the REMS produce the desired effect and assessment of the impact is conducted by the drug manufacturer.\n\nIncreasingly, Americans have been turning to the internet for health-related information, largely by the use of search engines such as Google. The volume of searches for drugs and ADEs provides a unique insight about the interest in various medications and side effects as well as longitudinal changes.\n\nWe generated a list of the 179 most commonly used drugs in the United States in 2008 based on the Agency for Healthcare Research and Quality's Medical Expenditure Panel Survey (MEPS). Using this list of drugs, we consulted MicroMedex, a drug database, for information regarding possible ADEs for each drug. Next, we then obtained search volume data from Google Insight for all possible pairs of drugs and ADEs.\n\nUsing a set of searches restricted to only the known ADEs for a given drug, we coded each ADE as either common or other as listed by MicroMedex. Based on this categorization, we conducted a Wilcoxon two-sample signed rank test. Finally, we constructed a negative binomial model to explain the number of ADEs found by Google Insights. The total number of detected ADEs was modeled using the number of common ADEs in MicroMedex, the number of other ADEs in Micro-Medex and the number of prescriptions for the drug based on 2008 data from MEPS as covariates.\n\nA second list of 149 drugs with REMS was obtained from the FDA and search volume as collected for each of the drugs. We fit a generalized linear model to the data starting 1 year before and ending 1 year after the initial REMS approval date. The model included a dummy variable indicating if the month occurred before or after the initial approval of the REMS. The interaction between this variable and the time covariate was used to determine if the REMS had any impact on interest as measured by search volume.\n\nBoth the Wilcoxon signed rank test and the negative binomial model indicate that Google Insight more readily detected common ADEs compared to the other ADEs. The Wilcoxon rank sum test indicated a shift toward more complete detection for the common ADEs compared to other ADEs (pB 0.001).\n\nThe negative binomial had similar results. The marginal increase in the number of ADEs detected by Google at the median for both the common and other ADEs was similar at 1.27 and 1.29, respectively. However, the median values were 7 and 39, respectively.\n\nOnly 40% (59/149) of drugs with a REMS approval demonstrated a change in slope with 90% confidence. The remaining 60% (90/149) indicated no significant change in interest over the time frame.\n\nOur data help validate the use of Google Insights and search volume as a means to estimate the relative incidence of ADEs. In addition, internet search volume can be used as a rapid means for detecting new or changing ADEs after approval. Finally, the severity and frequency of ADEs may vary within a particular drug class, and search volume may provide additional information for guiding clinicians to select a given drug within a class.\n\nThe release of the REMS failed to create a change in search volume for the majority of the drugs. This may be due to prior elevated interest as the result of previous safety alerts or may be an indication that the REMS fails to create increased awareness of the risks of the drug. Further analysis of FDA safety alerts or change point analysis may provide a greater understanding of the effect of various risk management methods.\n\nKeywords adverse drug events, Google Insights, post-marketing surveillance\n\nTo assess the impact of use of mobile phones use on the efficiency and effectiveness of the Integrated Disease Surveillance Project (IDSP) in the state of Andhra Pradesh (AP).\n\nPublic health surveillance systems are constantly facing challenges of epidemics and shortage in the healthcare workforce. These challenges are more pronounced in developing countries, which bear the greatest burden of disease and where new pathogens are more likely to emerge, old ones to reemerge and drug-resistant strains to propagate. In August 2008, a mobile phone-based surveillance system was piloted in 6 of the 23 districts in the state of AP in India. Health workers in 3832 hospitals and health centers used mobile phones to send reports to and receive information from the nationwide Integrated Disease Surveillance Project (IDSP). Like in many other states, the IDSP in AP is facing many operational constraints like lack of human resource, irregular supply of logistics, hard to reach health facilities, poor coordination with various health programs and poor linkages with nonstate stakeholders. The mobile phone-based surveillance system was an attempt to tackle some of the barriers to improving the IDSP by capitalizing on the exponential growth in numbers as well as reach of mobile phones in the state. Promising results from the pilot of the system led AP state to extend it to about 16,000 reporting units in all 23 districts. This study evaluates how the system has affected the efficiency and effectiveness of IDSP in the state.\n\nKey informant interviews, focus group discussions, record reviews and surveillance data analysis were conducted at the District Surveillance Units (DSUs), Primary Health Centers(PHCs)and Health Subcenters (HSCs). Five out of the 23 districts were selected for the evaluation using a probability proportion to size sampling strategy. Six PHCs were selected randomly from each of these 5 districts and 1 HSC was selected randomly from each of the PHCs. A total of 30 PHCs and HSCs were visited for evaluation.\n\nThe mobile phone-based system was being used only by 20 to 60% of the reporting units. Since the start of the system, there was an increase of 10 to 25% in completeness of IDSP reports. There were significant gains (12\u00c130%) in timeliness of reports. The system was saving time and money on logistics when compared to paper-based reporting. Public health workers in the field were enthusiastic about the system but were not using it as widely or extensively as was possible, because of lack of clear directives for implementation; lack of guidelines for usage and lack of systematic training of workforce for using the system.\n\nUse of mobile phone technology has the potential to enhance the overall efficiency and effectiveness of the IDSP but will require clear policy directives and guidelines for deployment and usage, systematic training plans and adequate resources for the technology to be accepted and used universally in the state. Our evaluation findigs suggest that to maximize the potential benefits of mobile technology in health systems, its use should be based on evidence from operational, technical and technological feasibility studies. This study will prove useful for scaling up such strategies toward disease surveillance systems in countries with similar operational challenges and ready access to mobile phones.\n\nIntegrated disease surveillance; mobile technology; surveillance quality; feasibility; policy\n\nThe use of syndromic surveillance systems by state and local health departments for the detection of bioterrorist events and emerging infections has greatly increased since 2001. While these systems have proven useful for tracking influenza and identifying large outbreaks, the value of these systems in the early detection of bioterrorism events has been under constant evaluation (3, 4) .\n\nSeveral U.S. anthrax infections have been identified since the 2001 Amerithrax attacks. These cases were investigated by a number of local, state and federal agencies, and most were subsequently associated with exposure to imported animal hides contaminated with anthrax spores of natural origin (5\u00c17). Each incident presented a unique diagnostic challenge since all three forms of the disease (inhalation, cutaneous and gastrointestinal) were identified. All of the cases were reviewed to determine which laboratory and surveillance systems were used to first identify possible cases and the number of days required to confirm the diagnosis of anthrax. The role of syndromic surveillance and other advanced surveillance systems in identifying these cases and searching for additional cases was evaluated. Efforts to coordinate surveillance and communication efforts among the various jurisdictions involved in the investigation of these cases were also noted.\n\nA review of these post-Amerithrax incidents revealed that all the cases were identified by astute clinicians using improved laboratory techniques. The time required to suspect and confirm the diagnosis of anthrax decreased with each subsequent incident, with increased awareness of animal sources of anthrax combined with improved compliance with laboratory reporting protocols. While syndromic surveillance systems did not identify the initial patients, these systems were used to search for additional cases. These efforts were enhanced when they were well coordinated among all jurisdictions.\n\nThe single local sources of exposure in most of these cases limited the value of these incidents to test the ability of syndromic surveillance systems to detect potential bioterrorist attacks. However, each incident provided valuable experience in the use of advanced laboratory and syndromic surveillance systems in the identification of anthrax cases. Although 10 years of surveillance system development has enhanced our nation's preparedness, use of outbreak modeling exercises in conjunction with regional and national multijurisdictional public health working groups, such as the Distribute Community of Practice, can further test and develop our ability to respond to bioterrorist attacks and emerging disease.\n\nAnthrax; syndromic surveillance systems; disease detection; modeling\n\nParallel surveillance, separate monitoring of each continuous series, has been widely used for multivariate surveillance; however, it has severe limitations. First, it faces the problem of multiplicity from multiple testing. Also, the ignorance of CBS reduces the performance of outbreak detection if data are truly correlated. Finally, since health data are normally dependent over time, CWS is another issue that should be taken into account. Sufficient reduction methods are used to reduce the dimensionality of a simple multivariate series to a univariate series, which has been proved to be sufficient for monitoring a mean shift in multivariate surveillance (1, 2) . Having considered the sufficiency property and the nature of health data, we propose a sufficient reduction method for detecting a mean shift in multivariate series where CWS and CBS are taken into account. (2) proposed a sufficient reduction method used for monitoring a mean shift in multivariate series where observations are assumed independent. Also, the former allows for CBS while the latter does not. In this study, we further develop sufficient reduction methods by taking CWS and CBS into account. At each time point, data from p-dimensional multivariate series are used to calculate sufficient statistics derived from the likelihood ratio between out of control and in control states. The evaluation of this method is by simulation study, where bivariate series are generated daily from different sets of parameters (whether or not CWS and/or CBS are present) (3). Detection of a mean shift, which is 2, 3 or 4 times standard deviation of background data, is investigated. A EWMA chart is used to monitor the resultant series of sufficient statistics, and the conditional expected delays (CED) and false alarm rates (FAR) (4) from four methods are compared.\n\nThree examples from our simulation study are shown in Table 1 . Data are generated from three different sets of parameters (CWS (8) and CBS (r)), and the aim is to detect a shift in mean of 2s.d. Dataset 1 has no CWS and CBS (800 and r 00). Dataset 2 includes CWS (8 00.4), while dataset 3 presents both CWS and CBS (8 00.4 and r00.3). For all datasets, the parallel method gives longer delays compared with other methods. In the case of dataset 1 (no CWS and CBS), the last three methods perform similarly. When CWS is present (dataset 2), the proposed method performs better than the others with slightly lower delay and much lower FAR. This pattern is repeated when CBS is incorporated (dataset 3).\n\nWhen CWS is present, CWS should be taken into account to the sufficient reduction method as ignoring CWS delays detection and gives more false alarms. Sufficient reduction methods derived for independent observations (1, 2) do not take CWS into account; therefore, the effect of CWS is still present in their derived series of sufficient statistics. This effect violates the assumptions of EWMA chart, for which data are assumed to be independent and then produces a high FAR. Although the sufficient reduction method proposed by Wessman (1) allows for CBS, it does not allow CWS. Incorporating both CWS and CBS in our proposed sufficient reduction method substantially improves the performance in detecting a mean shift in multivariate surveillance data.\n\nIntroduction Disease surveillance data often have an underlying network structure (e.g., for outbreaks that spread by person-to-person contact). If the underlying graph structure is known, detection methods such as GraphScan (1) can be used to identify an anomalous subgraph, indicative of an emerging event. Typically, however, the network structure is unknown and must be learned from unlabeled data, given only the time series of observed counts (e.g., daily hospital visits for each zip code).\n\nOur solution builds on the GraphScan (1) and Linear Time Subset Scan (LTSS) (2) approaches, comparing the most anomalous subsets detected with and without the graph constraints. We consider a large set of potential graph structures and efficiently compute the highest-scoring connected subgraph for each graph structure and each training example using GraphScan. We normalize each score by dividing by the maximum unconstrained subset score for that training example (computed efficiently using LTSS). We then compute the mean normalized score averaged over all training examples. If a given graph is close to the true underlying structure, then its maximum constrained score will be close to the maximum unconstrained score for many training examples, while if the graph is missing essential connections, then the maximum constrained score given that structure will be much lower than the maximum unconstrained score. Any graph with a large number of edges will also score close to the maximum unconstrained score. Thus, we compare the mean normalized score of a given graph structure to the distribution of mean normalized scores for random graphs with the same number of edges and choose the graph structure with the most significant score given this distribution.\n\nWe generated simulated disease outbreaks that spread based on the zip code adjacency graph with additional edges added to simulate travel patterns and injected these outbreaks into real-world hospital data. We evaluated detection time and spatial accuracy using the learned graphs for these simulated injects (Fig. 1 ). This figure also shows the detection performance given the true (adjacency plus travel) graph, the adjacency graph without travel patterns and the average performance given randomly generated graphs. We observe that the learned graph achieves comparable spatial accuracy to the true graph, while the adjacency graph has lower accuracy. Additionally, the learned graph is able to detect outbreaks over a day earlier than the true graph and 1.5 days earlier than the adjacency graph. Thus, our method can successfully learn the additional edges due to travel patterns, substantially improving detection performance.\n\nWe proposed a novel framework to learn graph structure from unlabeled data. This approach can accurately learn a graph structure, which can then be used by graph-based event detection methods such as GraphScan, enabling more timely and accurate detection of outbreaks, which spread based on that latent structure. Our results show that the learned graph structure is similar to the true underlying graph structure. The resulting graph often has better detection power than the true graph, enabling more timely detection of outbreaks, while achieving similar spatial accuracy to the true graph.\n\nKeywords Event detection; biosurveillance; graph learning \n\nThe illegal wildlife trade is a multifaceted, clandestine industry that has led to the disruption of fragile ecosystems, facilitated the spread of pathogens and led to the emergence of novel infectious diseases in humans, domestic animals and native wildlife (1, 2) . The trade is as diverse as it is large, with live and dead wildlife, representing multiple species sold to satisfy human demands for food, medicine, pets and trophies. Wildlife are harvested at astonishing numbers and used for such things as exotic pets, ornamental jewelry and clothing and traditional Chinese medicine (3) . An estimated 75% of recently emerging infectious diseases originated from animals (4), which can include both live animals and animal products.\n\nFreely available RSS feeds from official sources, such as organizations dedicated to ending the illegal wildlife trade to include TRAFFIC, WildAid and the Coalition Against Wildlife Trafficking (CAWT), were used to obtain information on illegal wildlife and wildlife product confiscations. In addition, information was obtained from freely available, disparate Internet sources (including discussion forums, mailing lists, news media outlets and blogs) by utilizing specific keyword search strings. For a 1-year period beginning August 1, 2010, English-language reports were collected on the illegal wildlife trade and interception points were analyzed (Fig. 1 ). When available, the origin and intended destinations of illegal wildlife products were also collected to aid in the development of proposed wildlife trade routes and hot-spot regions. Lastly, a comprehensive list of commonly traded species was compiled along with the potential zoonotic diseases that could be spread from traded animals to humans.\n\nFrom 858 reports collected, elephants (n0107, 12.5%), rhinoceros (n0103, 12.0%), tigers (n068, 7.9%), leopards (n054, 6.3%), and pangolins (n045, 5.2%) were among the most commonly intercepted species (to include live animals and wildlife products). Zoonotic diseases associated with these species include rabies, cowpox, echinococcosis, anthrax, and tuberculosis. Countries with the most illegal wildlife product interceptions included India (n 0146, 15.6%), the United States (n0143, 15.3%), South Africa (n075, 8.0%), China (n041, 4.4%), and Vietnam (n037, 4.0%).\n\nAvailable at http://www.healthmap.org/wildlifetrade, the digital wildlife surveillance tool is freely available to both wildlife conservation officials as well as members of the general public and shows real-time reports of illegal wildlife trade activity worldwide as an interactive visualization. The system combines official and unofficial reports with an overall goal of providing a greater understanding of the global wildlife trade network in addition to providing a jumping-off point for the identification of hot spot regions where enhanced surveillance should be implemented for emerging zoonoses. \n\nThe HEDSS system was implemented in 2004 to monitor disease activity (1). Twenty of 32 emergency departments (ED) and 1 urgent care clinic provide data. Chief complaints are routinely categorized into 8 syndromes.\n\nAlthough previous studies have shown that ED syndomic surveillance is not useful for early detection of GI outbreaks (2) , it has demonstrated utility in monitoring trends in seasonal norovirus activity (3) . An evaluation to assess the utility of HEDSS to characterize endemic and outbreak levels of GI illness has not been previously conducted in Connecticut.\n\nIn Connecticut, Campylobacter, Cryptosporidium, Cyclospora, shiga toxin-producing Escherichia coli (STEC), Giardia, Listeria, Salmonella, Shigella, Vibrio and Yersinia are laboratory reportable findings. Aggregate hospital admissions data are reported daily by all hospitals. Facility and community GI outbreaks are also reportable events. Weekly percentage of HEDSS GI syndrome visits (combined GI, vomiting, diarrhea and bloody diarrhea) were compared to the number of GI hospital admissions, number of facility and community GI outbreaks and reportable enteric diseases using correlation coefficients. GI syndrome ED visits were also examined by geographical region and age.\n\nVomiting and diarrhea were each highly correlated with the combined GI syndrome (r 00.99, p B0.0001; r 00.93, p B0.001, respectively), although vomiting has a greater magnitude than diarrhea. ED GI visits were correlated with GI hospital admissions (r 00.73, p B0.0001). Similar results were also seen when comparing HEDSS GI data to the number of total reported outbreaks (r00.76, pB0.0001) and facility outbreaks (r00.71, p B0.0001) but not community outbreaks alone (r 0 0.09, p00.23). The combined GI syndrome was inversely correlated with laboratory confirmed cases of Giardia (r0( 0.18, p 00.02), Campylobacter (r 0(0.45, p B0.0001), STEC (r0(0.32, p B0.0001), Listeria (r0(0.23, p 00.004), Salmonella (r0(0.41, p B0.0001), Shigella (r0(0.19, p 00.01), Vibrio (r 0(0.36, p B0.0001). No significant positive correlations were detected when controlling for seasonality or using a narrower syndrome definition. There was no significant geographic variation in GI illness by region. Children younger than 5 years had a proportion of ED visits for GI illness that was consistently higher than all other age groups.\n\nThere is a strong and consistent association between ED visits for GI illness and facility outbreaks, the majority of which are suspected to be caused by norovirus (4, 5) . The strength of observed associations was similar when using a vomiting, diarrhea or combined GI syndromes; no significant correlations were observed when using the narrow bloody diarrhea syndrome. HEDSS GI syndromes were inversely correlated with illness caused by bacterial enteric pathogens, even when using the bloody diarrhea syndrome to identify more severe illness or controlling for seasonality. The HEDSS system is a critical tool for situational awareness of community gastrointestinal illness, particularly that which is caused by norovirus. Since norovirus is not a reportable condition in Connecticut, this system is used as the primary source of monitoring community GI illness.\n\nKeywords Syndromic surveillance; gastrointestinal; public health practice; evaluation\n\nAsthma is a chronic condition of public health concern associated with morbidity, mortality and healthcare utilisation. It disproportionately affects certain ethnic and demographic groups.\n\nAsthma admission records in London (2001\u00c12006) were used. Negative binomial regression was used to model the effect of demographic (sex, age & ethnic group), diagnostic (primary & secondary diagnosis, method of admission) and temporal (day of the week, meteorological season & year of admission) factors on the LOS, accounting for the random effects of each patient's attendance, as model 'I' and again for area of residence, model 'A'. Akaike information criterion (AIC) was used to compare the two models.\n\nThe median and mean asthma LOS over the period of study were 2 and 3 days, respectively. Admissions increased over the years from 8308 (2001) to 10,554 (2006) , but LOS declined within the same period. Fewer males (48%) than females (52%) were admitted and, the latter had longer LOS compared to males. Only 5% were primarily diagnosed as predominantly allergic, whilst >94% were classified as 'asthma, unspecified'. Younger people were more likely to be admitted than elderly, but the latter had higher LOS (p B0.001). The secondary diagnosis and method of admission were important diagnostic determinants of length of stay, with very marginal differences between the two statistical models ('I' & 'A'). Again, all the temporal factors were significant determinants of LOS. Overall the patient cluster model (AIC=239394.8) outperformed the area model (AIC=247899.9).\n\nAsthma LOS is best predicted by demographic, diagnostic and temporal factors with individual patients as a random effect.\n\nAsthma; length of stay; spell duration; risk factors; hospital admission *I. Soyiri E-mail: soyiriin@yahoo.com \n\nThe spatial scan statistic (1) detects significant spatial clusters of disease by maximizing a likelihood ratio statistic F(S) over a large set of spatial regions, typically constrained by shape. The fast localized scan (2) enables scalable detection of irregular clusters by searching over proximity-constrained subsets of locations, using the linear-time subset scanning (LTSS) property to efficiently search over all subsets of each location and its k(1 nearest neighbors. However, for a fixed neighborhood size k, each of the 2 k subsets are considered equally likely, and thus the fast localized scan does not take into account the spatial attributes of a subset. Hence, we wish to extend the fast localized scan by incorporating soft constraints, which give preference to spatially compact clusters while still considering all subsets within a given neighborhood.\n\nFor a given local neighborhood with center location s c and size k, we place a bonus or penalty^i0h(1 \u00c1 2d i /r) on each location s i , where d i is that location's distance from the center, r is the neighborhood radius and h is a constant representing the strength of the compactness constraint. Each^i can be interpreted as the prior log-odds that s i will be affected, and thus the center location (d i 00,^i 0h) is e h times as likely as its (k ( 1)th nearest neighbor (d i 0r,^i0(h). We demonstrate that the penalized score function F'(S) 0F(S)'Ss i # S^i can be efficiently maximized over all subsets S for each neighborhood.\n\nTo do so, we show that F(S) can be written as an additive function (sum over locations) conditioned on the relative risk in region S, and therefore F'(S) is additive given the risk as well. We then jointly maximize F?(S) over all subsets S and all values of the risk.\n\nThe penalized subset scan was evaluated using emergency department (ED) data from 97 Allegheny County zip codes. We compared detection power and spatial accuracy, with and without compactness constraints, on synthetic, spatially localized outbreaks injected into the ED data. Our results show that including compactness constraints allows the penalized subset scan methods to detect outbreaks earlier and improve spatial accuracy, as compared to the unpenalized fast localized scan and circular scan, over a wide range of neighborhood sizes (Fig.  1) . Without compactness constraints, the method averaged 7.6 days to detect and an overlap coefficient of 54.9% for neighborhood size of k 010, but detection performance degraded rapidly for smaller or larger values of k. Performance of the compactness-constrained methods was less dependent on neighborhood size, requiring 7.4 days to detect and achieving an overlap coefficient of 59.3% for well-chosen parameter values.\n\nOur results demonstrate that the incorporation of soft compactness constraints substantially improves the timeliness and accuracy of outbreak detection. Our new approach based on additive linear-time subset scanning enables efficient maximization of penalized scan statistics over subsets of the data, thus improving detection of irregular clusters.\n\nOutbreak detection; spatial scan; penalized subset scan \n\nAlthough the advent of the ONCs 'meaningful use' criteria has added significant new incentives for healthcare organizations to provide the necessary data for implementing syndromic surveillance, incentives alone are not sufficient to sustain a robust community of practice that engages public health and healthcare practitioners working together to fully achieve meaningful use objectives. The process for building a successful community of practice around syndromic surveillance is primarily applicationagnostic. The business process has many of the same characteristics regardless of application features and can be incrementally customized for each community based on the unique needs and opportunities and the functional characteristics of the application. This presentation will explore lessons-learned in the north central Texas region with BioSense 1 and ESSENCE over the past 6 years and will describe the multiphase process currently underway for BioSense 2.0. Key program process steps and success criteria for public health and healthcare practitioners will be described. This road map will enable other local health department jurisdictions to replicate proven methodologies in their own communities. The presentation will also highlight what it takes for an existing community of practice with a home-grown system to move processes and protocols to the cloud.\n\nThe NACCHO Advanced Practice Centers (APC) Program is a network of local health departments whose mission is to promote innovative and practical solutions that enhance the capabilities of all local health departments and the public health system to prepare for, respond to, and recover from public health emergencies. Real world practice situations are supported and evaluated, resulting in the creation of tools designed to export and scale roll outs of lessons learned to other jurisdictions.\n\nSeveral products or tools specific to biosurveillance, disease detection and investigation were created through the APC Program methodology. Highlighted in this talk will be the Building a Public Health Community of Practice*A Biosurveillance Resource Compendium is a CD toolkit intended to help public health agencies implement an effective, comprehensive biosurveillance program. Providing approximately 40 resources, the CD includes a series of articles on implementing biosurveillance initiatives, materials defining and discussing the development of a public health community of practice, specific examples of real-world tools and resources that have proven beneficial in North Texas (including system response protocols) and a research report on biosurveillance system efficacy. The CD can help public health agencies strengthen partnerships with stakeholders at the federal, state and local levels and with the medical community, law enforcement, first responders and schools; it details how Tarrant County Public Health accomplished those goals and shares tools that were instrumental to the agency's success.\n\nLessons learned from a systematic approach to building and sustaining a regional and local biosurveillance community of practice have been documented in a meaningful way. These lessons can and should be leveraged as more of the country engages in syndromic surveillance through meaningful use incentives and the BioSense 2.0 infrastructure. The NACCHO sponsored north central Texas APC and tools derived from their work is a proven method to provide such assistance to local health departments across the country.\n\nInformatics; advanced practice centers; sustained relationships *Michael Coletta E-mail: mcoletta@naccho.org\n\nThe ability to estimate and characterize the burden of disease on a population is important for all public health events, including extreme heat events. Preparing for such events is critical to minimize the associated morbidity and mortality (1, 2) . Since there are delays in obtaining hospital discharge or death records, monitoring of ED visits is the timeliest and an inexpensive method for surveillance of HRI (1). Aside from air temperature, other environmental variables are used to issue heat advisories based on the heat index, including humidity and wind (3) . The purpose of this study was to evaluate the relationship between HRI ED visits and weather variables as predictors, in Ohio.\n\nSyndromic surveillance data from ED visits were collected and analyzed from Ohio's syndromic surveillance application, Epi-Center, for July 2011. Since the physical effects of HRI can vary greatly and affect multiple body systems, a specific classifier was created to query ED visits that were likely related to HRI and was defined as chief complaints referencing heat 'exhaustion or exposure', dehydration or hyperthermia. Measurements for weather variables included temperature, dew point, humidity, pressure and wind speed. The average daily values of these variables were calculated from seven geographically representative cities in Ohio and used as a surrogate for statewide data. These data were obtained from Weather Underground, which collects data from Automated Surface Observations System (ASOS) stations located at airports throughout the United States. These data were analyzed via time-series analyses and stratified by age group and gender. Correlation and linear regression analyses were performed, using SAS v 9.2 to determine which weather variables were the best predictors of HRI, as defined by ED chief complaint data.\n\nDuring the third week of July 2011, Ohio experienced a heat wave with multiple heat advisories throughout its various cities. The total ED visits related to HRI peaked on July 21 (n0170, 107 males, 63 females), which was also the day with the highest maximum temperature (97.4 F). A time-series chart of these ED visits by age group is shown below. The data show that the most sensitive populations (ages 0-5 and 65 and older) were the least affected and likely were adhering to the heat advisories. The 18\u00c1 39-and 40\u00c164-year-old age groups were most affected by the heat. Pearson correlation showed a strong relationship between HRI visits and mean temperature and dew point (r00.76 and r00.66), p B0.0001. Multiple linear regression analyses were completed to determine which weather variables were the best predictors with HRI. The best model showed that for every 1 unit increase in ED visits, there was a 3.88 unit increase in mean temperature, independent of mean humidity and wind speed, p B0.0001. The addition of mean dew point caused the model to have a high colinearity and was removed from the model.\n\nThese results suggest the advisories provided to the public during the heat wave in Ohio were most adhered to by the sensitive populations (very young and elderly). Middle-aged males were most susceptible to HRI during the peak of the heat wave. Temperature and dew point showed a strong relationship with HRI and were modeled as significant predictors of HRI. Additional analyses should be completed to further evaluate this relationship. Finally, obtaining patient diagnosis records from the hospital EDs would provide strength in validating the observed results.\n\nHeat-related illness; weather; predictor; classifier; correlation This not only represents a huge opportunity for public health to collect more data to enhance disease detection and control, improve safety, and reduce health disparities, but also presents an integration challenge.\n\nIn 2011, NH DPHS initiated a project with Orion Health to build a Rhapsody integration engine (1) portal to receive the three types of Public Health data. A Syndromic surveillance pilot was chosen since 25 of 26 hospitals were already sending real-time data in HL7 format to the statewide syndromic surveillance system. NH DPHS collaborated with the NH Regional Extension Center (REC) to host MU guidance and brokered with Orion Health, the Office of the National Coordinator (ONC), and CMS to offer hospitals the option to use a modular certification for MU public health measures by selecting the Orion Health module (2) . Selecting this module allows hospitals to send data to the NH DPHS Rhapsody portal in whatever format they choose; then, the NH DPHS Rhapsody system converts these messages to the approved ONC standards for public health reporting. Orion Health contractors set up the Rhapsody server, configured data routes and built validation, filtering, and mapping logic. Mapping to HL7 2.5.1 was performed, but additional mapping to 2.3.1 was done before sending data to the syndromic surveillance application. Hospitals were directed to reroute data transmissions to the new Rhapsody VPN IP address and port, and Rhapsody was configured to pass traffic to the original surveillance application address and port. Additionally, data was sent through the normal VPN connection to compare the accuracy and performance of the new path.\n\nThis MU project generated more hospital participation than was realized prior to initiating the Rhapsody integration.\n\nNegligible syndromic surveillance processing time degradation was realized with the added Rhapsody processing. This processing allowed NH DPHS to implement its last acute care hospital into the existing syndromic surveillance application (using Rhapsody mapping), filter existing hospital syndromic surveillance transmissions on specific patient types (preventing unwanted types), receive MU ELR and immunization data prior to expected timelines, increase hospital MU certification reimbursement without additional MU expenditure and decrease the hospital laboratory staff reporting burden, which previously was manual.\n\nConclusions NH DPHS was able to take advantage of opportunities and resources beyond the State of NH. The brokered Orion Health Rhapsody MU certification solution provided a lower cost certification solution to hospitals (as compared to purchasing Rhapsody or certifying their EHR). NH DPHS was able to build an expandable public health MU infrastructure easily integrated with the NH HIE. The MU REC website provided guidance, FAQs, state rules and allowed NH DPHS to communicate effectively with hospital partners and the NH REC, to take advantage of REC expertise, and keep all partners informed.\n\nIn response to the terrorist attack of September 11, 2001 , the NH Department of Health and Human Services (NH DHHS) engaged state and external partners in the design of an early warning surveillance system to support bioterrorism and emergency preparedness. Initially, NH DHHS began collecting four syndrome counts from 13 hospital emergency departments (EDs) by fax. Automation began in 2002, when an over-thecounter (OTC) syndromic surveillance pilot system was implemented by Scientific Technologies Corporation (STC). In 2003\u00c12004 this system, the Syndromic Tracking and Encounter Management System (STEMS), was expanded to include school absentee and occupational health reports. Over time, an internal death data application was automated to query vital record deaths, and in 2005, a real-time ED surveillance pilot, the Automated Hospital ED Data System (AHEDD), was developed by STC to replace manual ED surveillance. Over the past decade, NH continued to expand the original concept with innovative approaches to identify undetected or underreported disease outbreaks.\n\nNH's surveillance consists of assessing individual but compatible surveillance systems for (1) rapid detection of a covert bioterrorism attack and (2) early detection of naturally occurring outbreaks (i.e., influenza). The OTC pharmaceutical system was implemented with automated data processing and alerting within an enterprise architecture. Modified Shewhart charting was developed with dynamic system modeling using a knowledge base technique. Community health status was charted with a set of state syndrome variables and dynamic processes, where baselines, thresholds, trend analysis and alerts from historic data were automatically charted (1). This technical framework was implemented in STEMS with OTC data, school absentee data and occupational health data, then later in AHEDD. The AHEDD system also used the Real-Time Outbreak and Disease Surveillance CoCo chief complaint classifier with electronic data feeds from four hospitals. AHEDD was later expanded to include drill down custom querying for all 26 acute care hospitals (allowing NH to realize statewide ED surveillance).\n\nOver time, custom querying included data mining techniques adapted from the death data application, (2) to detect narrowly defined chief complaint health conditions and cluster activity.\n\nThis together with a 'Google'-like query tool allow NH surveillance staff to quickly assess any situation. Recently, a single portal infrastructure, based on AHEDD, was created to receive all external syndromic surveillance, Electronic Lab Reporting and immunization transmissions, helping hospital partners meet Meaningful Use (MU), which paves the way for integration with a statewide Health Information Exchange.\n\nOver the past 10 years, the usefulness of NH's surveillance systems has been demonstrated repeatedly. STEMS detected influenza and school norovirus outbreaks (3), and AHEDD tracked H1N1 and acute respiratory illness during the flu season, detected anthrax exposures during a gastrointestinal anthrax investigation and identified reportable disease occurrences (i.e., Lyme disease) and nonreportable clusters (i.e., carbon monoxide). These narrowly defined chief complaint queries have been found to be more useful than broad-based queries in detecting daily illness and heath risks. Results of individual surveillance systems assessed together validate individual system detections (i.e., increased sales of OTC antiviral medication and increased school ILI absenteeism validate ED flu spikes).\n\nTen years of NH syndromic surveillance tool development has established a critical biosurveillance infrastructure with emergency preparedness response capability during disease outbreaks and natural disasters. These syndromic surveillance tools are now integral to the daily efforts of epidemiologists and public health professionals.\n\nThe association of influenza vaccination with influenzalike illness among adults aged 65 years and older in the United States Mayuko Takayama 1,2 *, Catherine Wetmore 1 and Ali Mokdad 1 Objective To explore the association of influenza vaccination with influenza-like illness (ILI) among adults aged 65 years and older\n\nAfter the 2009 H1N1 influenza pandemic, CDC initiated community-based surveillance of self-reported influenza-like illness (ILI) (1), defined as the presence of fever with cough or sore throat. Although ILI is frequently attributed to other pathogens, including rhinovirus, routine surveillance of ILI at the population level does aid in the detection of nascent influenza outbreaks. In the United States, approximately 90% of influenza-related deaths occur among adults aged 65 years and older (2) . We explored the association of influenza vaccination with ILI, among this vulnerable age group.\n\nSelf-reported survey data from the 2010 Behavioral Risk Factor Surveillance System (BRFSS) was analyzed. Because the relationship between ILI and influenza infection is strongest during the influenza season, we limited the study sample to adults aged 65 years and older who participated between January and March 2010 (N035,628). We adjusted for three categories of individual-level factors: sociodemographics, health behaviors, and history of chronic disease diagnoses. We used stratified, weighted multivariable logistic regression to estimate the association between receipt of the influenza vaccine in the past year and report of ILI in the past month via adjusted odds ratios (aOR) and 95% confidence intervals (95% CI).\n\nRecent ILI was reported by 3.37% (95% CI: 3.02\u00c13.73%) of responders. 67.7% (95% CI: 66.8\u00c168.6%) reported receiving the influenza vaccine in the past year. After adjusting for sociodemographics, health behaviors, and chronic disease diagnoses, receipt of influenza vaccination was significantly associated with recent ILI, with vaccine recipients being more likely to report ILI (aOR 01.50, 95% CI: 1.01\u00c12.24). Persons who are underweight (BMIB18.5, compared with normal weight) (aOR 03.21, 95% CI: 1.19\u00c18.65), and those diagnosed with asthma (aOR 02.45, 95% CI: 1.65\u00c13.62), coronary heart disease (aOR 01.77, 95% CI: 1.17\u00c12.65), and stroke (aOR 0 1.75, 95% CI: 1.07\u00c12.87) were also more likely to report ILI.\n\nOur study showed an association between influenza vaccination and influenza-like illness among persons aged 65 years and older. This is a counterintuitive finding as vaccines are known to reduce the burden of influenza. Although our study is crosssectional and we cannot determine a causal pathway, it is possible that individuals with greater susceptibility to influenza infection (e.g., persons with chronic diseases) were more likely to get vaccinated. Indeed, these findings suggest the success of targeted public health messaging regarding the importance of vaccination among high risk individuals.\n\nInfluenza; vaccination; influenza-like illness; surveillance\n\nPublic health officials and epidemiologists have been attempting to eradicate syphilis for decades, but national incidence rates are again on the rise. It has been suggested that the syphilis epidemic in the United States is a 'rare example of unforced, endogenous oscillations in disease incidence, with an 8\u00c111-year period that is predicted by the natural dynamics of syphilis infection, to which there is partially protective immunity' (1). While the time series of aggregate case counts seems to support this claim, between 1990 and 2010, there seems to have been a significant change in the spatial distribution of the syphilis epidemic. It is unclear if this change can also be attributed to 'endogenous' factors or whether it is due to exogenous factors such as behavioral changes (e.g., the widespread use of the internet for anonymous sexual encounters). For example, it is pointed out that levels of syphilis in 1989 were abnormally high in counties in North Carolina (NC) immediately adjacent to highways (2) . The hypothesis was that this may be due to truck drivers and prostitution and/or the emerging cocaine market (1). Our results indicate that syphilis distribution in NC has changed since 1989, diffusing away from highway counties (see Fig. 1 ).\n\nUsing CDC data for syphilis, we construct county-level syphilis distribution maps for NC and Florida and time series (1990-2010) of spatial distributions of syphilis for Florida. Additionally, for comparison, we construct county-level (from 2004 to 2010) and state-level (from 1995 to 2010) syphilis distribution time series.\n\nMaps of cases (per 100,000) in NC show that the disease has spread into rural counties and is no longer concentrated along the highway (see Fig. 1 ). In Florida, along with the overall decrease in syphilis incidence, the distribution of cases becomes more concentrated from 1990 to 1998. When, in 1999, syphilis incidence rates begin to increase again, the distribution again widens and spreads to more rural communities (see Fig. 2 ).\n\nThe time series of national state-level syphilis distribution indicates an increase in the number of states at the extremes of the distribution (i.e., with very high or very low case counts). However, at the same time, the national county-level distribution remains stationary. This indicates that counties with high case counts are clustering in states with high case counts and similarly counties with low case counts are clustering in states with low case counts.\n\nThe county-level spatial distribution of syphilis has changed significantly since 1990 and in ways that may depend on exogenous factors. Higher prevalence of syphilis in states seems more due to an increase in syphilis in counties that earlier had a low incidence of the disease. County-level syphilis data present a rather nuanced picture of how syphilis incidence has changed over the years and may form the basis for effective interventions.\n\nKeywords Spatial distributions; time-series analysis; syphilis \n\nEvent-based biosurveillance monitors diverse information sources for the detection of events pertaining to human, plant and animal health using online documents, such as news articles, newsletters and blogs (1) . Machine learning techniques have been successfully used for automated document classification, an important step in filtering source information (2\u00c115).\n\nWe review studies on document classification using machine learning for event-based biosurveillance and comparatively summarize them for close examination. Table 1 lists relevant studies we identified. These studies differ in target regions, languages, event types and surveillance criteria, as well as classification methods. This diversity illustrates the complementarity of all the approaches.\n\nCommon challenges shared by these methods include detection of rare events and practical evaluation of the employed methods. The comparative advantages of each method remain unclear because of the lack of benchmark data. A community effort is necessary to develop an event ontology and benchmark corpora.\n\nKeywords biosurveillance; text classification; machine learning \n\nTracking ED asthma visits is an important part of asthma surveillance, as ED visits can be preventable and may represent asthma control failure (1). When using limited clinical ED datasets for secondary purposes such as public health surveillance, it is important to employ a standard approach to operationally defining ED visits attributable to asthma. The prevailing approach uses only the primary ICD\u00c19\u00c1CM diagnosis (Dx) for the ED visit (2); however, doing so may underestimate the public health impact of asthma. We conducted this pilot study to determine the value of including ED visits with asthma-related Dx in secondary or tertiary positions. For example, for an ED visit with a primary Dx of upper respiratory infection and secondary Dx of asthma, it is possible that the infection triggered the asthma exacerbation and the visit could be attributed to both infection and asthma.\n\nWe utilized all ED visit data for 2008\u00c12009 from the state public health surveillance system (3), accounting for 99.5% of the visits to North Carolina EDs. Included were visits with an ICD-9-CM diagnosis code for asthma (493.xx) in any Dx position (1\u00c111). We then grouped asthma visits into 11 strata based on the Dx position containing the asthma code. We identified the most frequent chief complaint and primary Dx categories for each of the 11 asthma Dx positions. We also grouped procedure codes (ICD\u00c19\u00c1CM and CPT) for potential asthma (e.g., nebulized medications) and cardiac (e.g., electrocardiogram) conditions for each Dx position.\n\nResults 350,341 (4.0%) of the 8.7 million ED visits had a diagnosis of asthma in 1 of the 11 Dx positions. The most common chief complaints for visits with asthma were: Dx positions 1 and 2-dyspnea and asthma, and Dx positions 3\u00c15-injury. 69,877 (19.9%) of the asthma visits had at least 1 procedure code assigned, those with asthma or cardiac procedure code are shown in Fig. 1 .\n\nRestricting the definition of an asthma-related ED visit to the first diagnosis position may miss a substantial proportion of the asthma-related public health burden. Further analysis is in progress to evaluate the validity of these preliminary findings.\n\nPublic health surveillance; ED data; asthma Data elements include disposition, initial vital signs, up to 11 ICD-9-CM final diagnosis codes, up to five external causes of injury codes (E-codes), as well as the arrival date and time, patient sex and age, patient zip and county and chief complaint. As of January 2008, NC DETECT emergency department data covered 99% of the NC population and captures approximately 4.5 million ED visits each year. As a result, requests for data from researchers continue to increase. Use of the data for public health purposes is covered by the mandate requiring hospitals to submit their emergency department data to NC DPH.\n\nData requesters must use the ED data in NC DETECT for public health-focused studies. Data requests from commercial entities are not approved. The data request process occurs primarily via paper and e-mail, although we have implemented a centralized tracking system to store all documentation for data requests and track changes to them over time. To initiate the process, requesters view a presentation on https://www.ncdetect. org/ReportsPortal/public/dataRequest.do and then enter information on the study purpose, the researchers involved, any grants covering the research and the specific data requested* specifically the data elements, time frame and file format. Researchers must get approval from their home institution's Institutional Review Board and sign a Data Use Agreement (DUA) with NC DPH. The DUA outlines data use requirements such as securing the data during the study, presenting data in aggregate form only (in a manner in which an individual cannot be identified), sharing materials with NC DPH prior to presentation or publication and destroying data upon completion of the study. Data requests within NC DPH typically do not require a DUA and are exempt from this process. In addition, researchers who need to determine the feasibility of a study before submitting a full data request can go through an exploratory process that requires a DUA but no IRB. While data requests are ongoing, a small Data Oversight Committee (DOC) meets once monthly to review these requests and to discuss status and outstanding issues. The NC DETECT DOC includes representatives from the NCDPH, CCHI, NC Hospital Association (NCHA) and DPH legal personnel (as needed).\n\nWe currently have 31 data requests in our online tracking system. Each data request represents multiple e-mails and phone calls, iterative revisions to the data request and multiple data pulls from the NC DETECT database. Requests can be delayed when researchers request data elements that are not collected by NC DETECT, submit unclear requirements, change requirements, do not understand the challenges of processing free text data and/or add/change researchers who will be accessing the data. Requesters have used NC DETECT data to publish manuscripts on topics including the health effects of wildfires, ED visits for cancer patients, tick-borne illness and asthma, and comparison of NC ED visit data to national data, among others. Because the ED visit data are collected under a state mandate and in collaboration with the NCHA, their release and use for research is thoroughly evaluated by the DOC. The complexity of the data requests over time has resulted in changing of data use restrictions, as well as revisions of the DUA wording. We do not have enough resources to closely monitor the use of the data once they are provided to researchers. However, researchers are expected to abide by all provisions detailed in their DUA and by signing acknowledge the potential penalties for violation of the terms the agreement.\n\nData requests can take a considerable amount of time and iterative discussions with the requester, even with a welldefined process and clear documentation. Understanding the administrative and technical time commitments involved is important when considering making syndromic surveillance data available to external users for research.\n\nData sharing; data use agreements; data requests\n\nRecent events have focused on the role of emerging and reemerging diseases not only as a significant public health threat but also as a serious threat to the economy and security of nations. The lead time to detect and contain a novel emerging disease or events with public health importance has become much shorter, making developing countries particularly vulnerable to both natural and manmade threats. There is a need to develop disease surveillance systems flexible enough to adapt to the local existing infrastructure of developing countries but which will still be able to provide valid alerts and early detection of significant public health threats.\n\nIn collaboration with the Philippine National Epidemiology Center (NEC) and the Philippines-AFRIMS Virology Research Unit, Armed Forces Research Institute of Medical Sciences, the EDE program, which was developed by Johns Hopkins University\u00c1Applied Physics Lab, was introduced in the Philippines to augment the data analysis capability of the Philippine Integrated Disease Surveillance and Response (PIDSR) System. Reported significant increases in the number of suspect dengue cases/outbreaks at the municipality, provincial and regional level, which were reported to and investigated by NEC from July 1, 2011, to August 31, 2011, were used as a reference point. A defined period, 30 days prior to the date when the event was officially reported, was retrospectively analyzed. The day when an EDE alert was first triggered and the number of EDE alerts detected during this period were described. Since NEC analyzes data by morbidity week, municipalities that were detected to be above the NEC alert or epidemic threshold during a randomly selected morbidity week (week 31; reporting date of August 6, 2011) were compared with the number of EDE alerts triggered during the past 7 days before the report date of morbidity week 31.\n\nRetrospective analysis done during the past 30 days before the event was officially reported showed that EDE Alerts were already triggered as early as 30 days (median of 27.5 and range 14\u00c130 days) prior to the date of the NEC report. The number of days associated with EDE 'alerts' out of the 30 days prior to the NEC official report date had a median of 9.5 days (range of 3\u00c114 days). A total of 17 municipalities had reported dengue cases above the alert or epidemic threshold with 8/17 of these municipalities having at least 1 day in the previous week with a case count of more than 5 while 9/17 had case counts of 5 or less for all 7 days in the past week. For municipalities with at least 1 day with a case count of 5 or more for the previous 7 days, the median of the number of days with associated EDE alerts was 5 (range 0\u00c17 days). For municipalities with case counts of 5 or less for all 7 prior days, no alerts were usually generated (median 0 and range 0\u00c12 days).\n\nA surveillance system's usefulness for outbreak detection should be correlated with its ability to increase the lead time in detecting outbreaks of public health significance, which should subsequently lead to a more timely intervention. Analysis of currently available data seem to show promising applications of EDE in early warning alert capability of impending increases in dengue cases in the Philippines though when case counts are 5 or less, alert results may not be very reliable. Validity of alerts generated by EDE for early detection of outbreaks should be further investigated using other diseases, prediagnostic/ nonclinical/nontraditional data and syndromes, taking into consideration effect of seasonality, weekly trends or holidays.\n\nSurveillance, outbreak, dengue, predictive, validity\n\nIn R\u00e9union Island, the nonspecific surveillance was mainly developed during A(H1N1) influenza pandemic in 2009 (1, 2). In March 2010, a new surveillance system was implemented from National Health Insurance data. This monitoring was based on the weekly consultation number and home visits by general practitioners.\n\nThe data based on the activity of general practitioners were transmitted on week W and covered the consultations and home visits carried out by the general practitioners in the week W (1.\n\nThese data were updated week by week according to the flow of repayments. The data received were aggregated, and no personal information was communicated.\n\nThe thresholds corresponding to the statistical alarms for the weekly numbers of all consultations were based on a calculation using adapted versions of two historical methods (log-linear regression model of Farrington and historical limit method) and CUSUM methods.\n\nThe surveillance period was spread over 134 weeks from week 1 of 2009 to week 29 of 2011. For the two historical methods, expected numbers of all consultations were calculated during these 134 weeks, using a training period of at least 3 years. A 95% confidence interval was calculated for each weekly expected number. A weekly count observed was considered significantly greater than the expected value if it was above the 95% upper confidence limit.\n\nFor the CUSUM methods, only few weeks were necessary to calculate a one-sided positive cumulative sum. An alarm was obtained if this cumulative sum was greater than a fixed decision value.\n\nThe data covered 72% of the population of R\u00e9union Island. Over the surveillance period, 11,048,739 consultations were recorded with an average of 82,453 consultations per week (min: 56,682; max: 120,432). An illustration of the results obtained with the historical limit method is presented in Fig. 1 . The first alarms that occurred on week 34 to week 36 of 2009 corresponded to the influenza A(H1N1) epidemic with a peak in week 35. Statistical alarms observed on week 8 of 2010, and week 7 to 9 of 2011 were related to the season circulation of respiratory syncytial virus. These results were confirmed by the laboratory data. During the austral winter of 2010, one alarm was obtained in week 39 corresponding to the influenza epidemic.\n\nThis surveillance system based on the data of the National Health Insurance is a complementary tool to nonspecific monitoring in Reunion Island. Not only does it ensure the detection of unusual health events but it also allows to quantify a public health impact for major events. It brings information about the recourse to the so-called 'non emergency' cares that will allow public health authorities to implement adapted control measures. The major advantage of this system is its exhaustive data use that ensures a global view on all consultations carried out in the island and to have a denominator to calculate other indicators. \n\nMining text for real-time syndromic surveillance usually requires a comprehensive knowledge base (KB), which contains detailed information about concepts relevant to the domain, such as disease names, symptoms, drugs and radiology findings. Two such resources are the Biocaster Ontology (1) and the Extended Syndromic Surveillance Ontology (ESSO) (2) . However, both these resources are difficult to manipulate, customize, reuse and extend without knowledge of ontology development environments (like Prot\u00e9g\u00e9) and Semantic Web standards (like RDF and OWL). The cKASS software tool provides an easy-touse, adaptable environment for extending and modifying existing syndrome definitions via a web-based Graphical User Interface, which does not require knowledge of complex, ontology-editing environments or semantic web standards. Further, cKASS allows for*indeed encourages*the sharing of user-defined syndrome definitions, with collaborative features that will enhance the ability of the surveillance community to quickly generate new definitions in response to emerging threats.\n\nWe have developed a web-based prototype of the cKASS system that allows individual users or collaborative communities to access the service anytime and anywhere, without a complex technical configuration process (Fig. 1) . Two types of databases are used to support cKASS. First, a relational database is used to store user information and KB descriptors(e.g., KB domain and status). Second, KBs are stored as RDF triples using triple store and queried using SPARQL, an RDF query language, with the Jena SDB (SPARQL database,) providing robust and scalable storage. Existing resources stored in standard RDF and OWL formats can be easily loaded into the triple store and used as a basis for constructing new syndrome definitions.\n\nThe web interface is designed to support both individual and collaborative KB development. cKASS consists of two zones:\n\nUser workspace, where registered users can create, browse, modify and publish customized syndrome definitions constructed from either publicly available or user-created resources.\n\nCommunity space, where anyone can browse and search shared KBs. Users who choose to share their KBs can make them available to the general community in this space.\n\ncKASS also provides search/query capabilities at different levels.\n\nFor example, the user can search within a specified domain or within a named KB for terms or concepts. Queries can either be simple strings or can consist of arbitrarily complex SPARQL and SQL queries. Further, users can import queried results into their syndrome definitions (for example, concept only, concept and its attributes or concept and all its subclasses). Finally, once created, KBs can be exported in standard formats, such as XML, CSV or RDF, for use with other tools.\n\nCurrently, two existing syndromic surveillance oriented ontologies* Biocaster and ESSO*have been loaded into the cKASS triple store and can be used as a basis to construct new syndrome definitions. Both KBs can be queried using SPARQL and SQL. Conclusions cKASS offers public health professionals and clinicians an environment to support the extension and modification of existing KBs, without the need to use complex ontology editing environments and formalisms, allowing the user to rapidly develop or augment existing syndrome definitions and react quickly to the changing surveillance landscape. Keywords Syndrome surveillance; knowledge authoring; ontology (1). Producers were informed of the problem by their swine processing facility. Tissue samples from affected producers were culture-positive for Mycobacterium avium. In the spring of 2010, USDA Veterinary Services (VS) began monitoring weekly ADRS STB carcass condemn data after a VS Staff Officer was made aware of unusual increases in STB condemns in another region. By June 2010, STB condemn rates in both of the affected areas decreased to typical seasonal levels; however, beginning January 2011, rates again rose beyond baseline seasonal highs, exceeding those seen in the 2010 outbreak.\n\nThe ADRS provides weekly condemn data to VS along with information on species and total number of animals slaughtered. June 2007\u00c1May 2011 ADRS market swine data were grouped by three major swine production areas (basins) to (1) identify preoutbreak condemn baselines, (2) quantify differences in the 2010 and 2011 STB outbreaks and (3) ascertain the geographical extent of the outbreaks. In addition, a fourth basin was created representing the remainder of U.S. market swine slaughter plants.\n\nTo identify critical weeks of anomalous condemns, a modification of the 'C3' version of the Early Aberration Reporting System was applied to the STB condemn series (2) . In addition to examining alerts by basin, the alerting algorithm was applied to individual plant data. Data processing was performed using SAS version 9.1 and an Excel-based 'Alerting Algorithms Tool' developed and published by Dr. Howard Burkom (3) .\n\nMean weekly swine TB condemn rates, which seasonally ranged from 5.7 to 21.4 per 100,000 between 2007 and 2009 (mean 010.7, SD03.0), increased above typical levels beginning January 2010 and rose even higher beginning January 2011 (Fig. 1) . Most of the increase was due to condemns in Basin 3, which experienced 670/ 100,000 weekly STB condemns at the height of the 2011 outbreak. Summary data for Basins 1, 2 and 4 indicate that condemn profiles remained at nonoutbreak levels over the 4-year data series. Retrospective analysis by individual facility suggests that while condemns in Basin 1 appeared to coincide with typical seasonal STB rates, the pattern of alerts for one facility may have signaled STB outbreaks in both outbreak periods.\n\nBy combining 'on-the-ground' practitioner-based information with geographically broader analysis of ADRS data, we identified an emerging disease situation involving TB lesions in swine. A preliminary epidemiological investigation suggests that likely principal risk sources are related to feed and ground water (1). Analysis of ADRS condemn data suggests that several lower Midwest slaughter facilities in addition to the affected plant used by producers involved in the investigation may have been affected by STB.\n\nAbattoir; surveillance; syndromic\n\nHypoglycemia is a serious sequel of diabetes treatment that is not tracked by current health surveillance efforts despite substantial related morbidity and mortality (1). We take a novel approach to hypoglycemia surveillance, engaging members of an international online diabetes social network (SN) in reporting about this issue as members of a consented, distributed public health research cohort.\n\nWe collected structured self-reported data about hypoglycemia and related harms using a software application called TuAnalyze that supports SN-mediated health research (2) . Odds for harms were estimated controlling for demographics, diabetes type and health insurance.\n\nOf 2538 TuAnalyze users, 608 (24% response rate) completed two complementary surveys on hypoglycemia and diabetes care. Of these, 169 (27.8%) reported ]1 severe low in the past 12 months.\n\nHarms were high; one in seven reported an accident or serious injury; over 40% reported high daily worry, and the frequency of reported withdrawal behaviors ranged from 20 to 50%. Experience of ]1 past 12-month severe low was associated with added risk for each of the six harms, and for experiencing multiple harms. (Tables 1 and 2) .\n\nHypoglycemia prevalence is high and exerts a considerable toll in terms of physical and social harms in this sample of predominantly type 1 or insulin-treated patients. Hypoglycemia surveillance is feasible using a novel approach that affords opportunity for bidirectional communication and tracking* capabilities important to ameliorating this problem.\n\nDiabetes; hypoglycemia; surveillance; social networking \n\nThe Veterans Health Administration (VHA) uses the Electronic Surveillance System for the Early Notification of Communitybased Epidemics (ESSENCE) to detect disease outbreaks and other health-related events earlier than other forms of surveillance (1). Although Veterans may use any VHA facility in the world, the strongest predictor of which healthcare facility is accessed is geographic proximity to the patient's residence. A number of outbreaks have occurred in the Veteran population when geographically separate groups convened in a single location for professional or social events. One classic example was the initial Legionnaire's disease outbreak, identified among participants at the Legionnaire's convention in Philadelphia in the late 1970s (2) . Numerous events involving travel by large Veteran (and employee) populations are scheduled each year.\n\nAn H1N1 influenza outbreak was identified at a Veteran Benefits Administration (VBA)-sponsored conference in Baltimore, MD, in July 2009 in which affected VBA employees (both local and from out-of-town) sought healthcare at the VA Maryland Health Care System*Baltimore Medical Center. Using ESSENCE, daily counts of ICD-9 codes related to influenza diagnoses (as defined by VA ESSENCE influenzalike illness [ILI] syndrome group) were collected from the VHA Baltimore Medical Center from March 01, 2009, to September 12, 2009 . Data included case status (as defined by ICD-9 code and chart review), date and location of visit and patients' zip code of residence. We also accessed data from the VA Planning System and Support Group to determine whether the patients' residential ZIP code fell within the Baltimore VA Medical Center's catchment area. Using SAS, a p-chart (where the denominator was the daily number of patient ILI encounters) was run to determine days during which an aberrant proportion of patients from out-of-catchment zip codes were encountered.\n\nAn aberrant proportion of out-of-catchment zip code ILI encounters signaled an out-of-control process (or alert) on July 23, 2009, 2 days later than the beginning of the influenza outbreak at the facility (Fig. 1 ) on the date when the majority of affected participants were evaluated for flu symptoms. (The alert on July 26, 2009, was a part of this same outbreak.) Using this algorithm, there were two other days in the 7-month period during which the chart signaled that the process was out-of-control: March 21, 2009, and September 6, 2009 . Investigations are being conducted to determine the nature of these other signals.\n\nUsing p-charts to detect unusual clusters of patients' residential zip codes that fall outside of facilities catchment area is likely a method of detecting disease outbreaks previously not utilized. Future work includes running this algorithm in all VA Medical Centers to prospectively identify disease outbreaks involving increased proportions of patients residing outside of the medical center's catchment area.\n\nSurveillance; p-chart; algorithm; signal detection; outbreak Objective To present the development and implementation of the SIPS project, a statewide, hospital-based surveillance system for severe community-acquired pneumonia (sCAP) in Kentucky.\n\nThe threat of epidemics due to nonhuman strains of influenza A viruses is ever present (1). Surveillance is a critical aspect of pandemic preparedness for early case detection (2) . Identification of the index cases of a pandemic virus can trigger public health mitigation efforts (3) . To develop an appropriate surveillance process, it is important to understand the two possibilities of pandemic evolution. A new pandemic may begin with mild cases, during which surveillance should be concentrated on work/school absenteeism and in physician offices. The other possibility begins with severe cases, characterized by sCAP, respiratory failure and ICU admission. As the syndrome of pneumonia is not reportable to health agencies for public health surveillance, a year-round, hospital-based surveillance mechanism may be an important tool for early case detection in the event of an epidemic of sCAP. To fill these gaps, we developed a statewide, hospital-based surveillance network for sCAP surveillance in Kentucky.\n\nAll acute care hospitals in Kentucky were invited to participate in the project. A case of sCAP was defined as a patient admitted to an ICU with the physician diagnosis of CAP. Upon patient identification, demographic and clinical characteristics were entered into an Internet-based data collection form. All patients had a nasopharyngeal swab sent to the University of Louisville Infectious Diseases Reference Laboratory for identification of viral pathogens. The Luminex xTAG respiratory viral panel multiplex PCR was used for viral identification. Clinical cultures were utilized to identify bacterial and fungal causes of sCAP. Statistical Process Control (SPC) charts were used to identify outbreaks. Chloropleth maps were used for spatial analysis. Each analytical mechanism was provided in real-time via the study website.\n\nSurveillance for sCAP began in December 2008, prior to the 2009 H1N1 influenza A pandemic. Six facilities representing all areas of the state, both rural and metropolitan were included. The website, www.kyflu.net was developed for study coordination. From December 1, 2008, through August 2011, 458 cases of sCAP were identified. There were multiple areas of specialcause variance on the SPC charts, though there were no unusual clusters upon spatial evaluation of the maps. The most common virus identified in patients with sCAP was rhinovirus (n039, 20%), followed by 2009 H1N1 influenza A virus (n034, 18%). These viruses were cultured in chicken eggs, genetically analyzed and further studied in mouse and ferret models to determine viral evolution and virulence mechanisms. One influenza virus was found to be hypervirulent compared to other strains.\n\nThe SIPS project is an ongoing effort that has thus far successfully identified patients with sCAP of viral etiology. Surveillance for sCAP is important not only for the early detection of cases in the event of a pandemic of influenza but for other etiologies as well. Furthermore, through translational research activities, we were able to identify novel strains of influenza and are working to further characterize the evolution of these viruses in our state.\n\nInfluenza; respiratory virus; outbreak; pandemic; epidemic\n\nAdverse drug events (ADEs) are a significant source of morbidity and mortality. The majority of postmarketing surveillance for ADEs is passive. Information regarding ADEs is reported to the medical community in peer-reviewed journals. However, in most cases, there is significant lag in the publication of peer-reviewed articles concerning ADEs. Within medical journals, our intuition is that letters to the editor may provide the earliest reports of ADEs. They often report single case reports or a collection of cases and usually precede more formal investigations and reports. Although these letters may contain useful and timely information, the challenge is that letters to the editor may be 'buried' inside print journals. Furthermore, they may be more difficult to find and access even when using electronic searches because unlike other published reports, there is no corresponding abstract to view. Due to the lack of an abstract, detection depends almost exclusively upon words in a title or manually applied Medical Subject Headings (MeSH). We propose that searching the full text of letters to the editor can provide a faster and perhaps more complete detection of ADEs compared to searches based on MeSH terms or titles alone.\n\nWe first identified a list of the most commonly used 179 drugs in 2008 based on the Agency for Healthcare Research and Quality compiled Medical Expenditures Survey. We then used Micro-Medex, a commercial drug information service, to find a list of key publications describing ADEs for these drugs. Next, we obtained the text for the majority of letters to the editor published in The Lancet (6558 from 1967 to date; 82% of total) and The New England Journal of Medicine (3524 from 1966 to date; 75% of total). We restricted the letters to those that had the MeSH term 'adverse effect' in the indexing data. We also eliminated the letters with label 'Comment' to avoid searching letters specifically referencing a previously published paper in each journal, respectively. The resulting dataset contained 2166 letters for The Lancet and 1449 for The New England Journal of Medicine.\n\nWe then compared the results from two different search strategies. In the first, an emulation of a PubMed search, we only examined the MeSH terms and the title for the letter. Our second approach included a search of the full text of the letters in addition to the title. Using these two strategies, we were able to determine the 'earliest' letter in these two journals for a given drug/ADE pair. We compared this date against the date of the citation referenced by MicroMedex to determine which search method provided the earliest detection.\n\nBoth search strategies, with and without full text, were able to find the particular drug/ADE pair mentioned in letters before the corresponding Micromedex reference. However, using fulltext search outperformed title/MeSH-based search, not only based on the number of drug/ADE pairs found but also on the time of detection. The percentage of letters in the dataset that are not related to specific articles is 0.6% using title/MeSH, 2.1% using title/full-text. Furthermore, we found that MeSH terms are not always reliable. For example, some of the letters had MeSH terms like ''Adverse Effect'' but no mention of adverse effects in the letter. Not surprisingly, since MeSH is a controlled vocabulary, some of these terms do not appear in the full text of the letters. These findings are shown in Table 1 .\n\nOur results suggest that the full texts of the letters to the editor provide a potential stream of information regarding early warnings for ADEs. Future work will need to expand the number of journals considered and, furthermore, consider the potential for 'false positive' warnings.\n\nAdverse drug events; letters to the editor; signal detection Objective To examine the incidence and characteristics of heat illness during sports and recreation.\n\nAlthough heat illness is preventable, it is a leading cause of death among U.S. high school and college athletes (1) . Despite this, the total burden of heat illness during sports and recreation is unknown. With over 250 million U.S. residents reporting occasional participation in sports or recreational activities (2), there is a large population at risk.\n\nWe used two national injury surveillance systems to examine heat illnesses in two different U.S. population subsets. We used the National Electronic Injury Surveillance System-All Injury Program (NEISS-AIP) to examine heat illness incidence and characteristics among sports and recreation participants of all ages from 2001 to 2009, and we used the National High School Sports-Related Injury Surveillance Study (High School RIO TM ) to examine heat illness incidence and characteristics among high school-aged athletes from 2005 to 2009 (Table 1) . NEISS-AIP, operated by the U.S. Consumer Product Safety Commission, monitors consumer product-related injuries treated in a nationally representative sample of 66 U.S. hospital emergency departments (EDs) (3). Trained coders enter demographics, a brief narrative and consumer product information for each injury presenting to their ED. High School RIO TM , operated by the Center for Injury Research and Policy at Nationwide Children's Hospital (Columbus, OH), monitors sports injuries in a nationally representative sample of 100 high schools (4). Certified athletic trainers at participating schools report exposure and injury data electronically.\n\nUsing NEISS-AIP, we calculated an estimated 5946 (95% confidence interval [CI]04194\u00c17698) ED visits for sports-and recreation-related heat illnesses occurred annually from 2001 to 2009. Incidence was highest among males (72.5%) and among persons aged 15\u00c119 years (35.6%) and occurred most commonly during football (24.7%) and exercise (20.4%). Using RIO TM , we calculated an estimated 9237 (95% CI 08357\u00c110,116) heat illnesses resulting in time lost from participation occurred during high school sports annually from 2005 to 2009, most commonly during football (70.7%).\n\nNational injury surveillance systems provide a unique opportunity to examine heat illness in sports and recreational settings. NEISS-AIP and High School RIO TM demonstrate different approaches to studying this problem. Results from both analyses indicate that heat illness causes substantial morbidity among sports and recreation participants. We need to find new ways to target effective heat illness prevention messages to those at greatest risk to reduce morbidity and prevent mortality. Continued surveillance is also warranted to monitor trends and evaluate interventional activities.\n\nInjury; surveillance; heat illness; NEISS; RIO TM Introduction Syndromic surveillance uses syndrome (a specific collection of clinical symptoms) data that are monitored as indicators of a potential disease outbreak. Advanced surveillance systems have been implemented globally for early detection of infectious disease outbreaks and bioterrorist attacks. However, such systems are often confronted with the challenges such as (i) incorporate situation specific characteristics such as covariate information for certain diseases; (ii) accommodate the spatial and temporal dynamics of the disease; and (iii) provide analysis and visualization tools to help detect unexpected patterns. New methods that improve the overall detection capabilities of these systems while also minimizing the number of false positives can have a broad social impact.\n\nIn this paper, we propose an inference model for determining the location of outbreaks of epidemics in a network of nodes. In our setting, the network is the NC counties where the basic model incorporates spatial geographical relationships between the counties. The model is epidemiological, by choice, to process daily flu counts from the counties in order to infer when an outbreak of flu is present in a county that is distinguishable from background counts. The methodology incorporates Gaussian Markov random field (GMRF) and spatio-temporal conditional autoregressive (CAR) modeling.\n\nThe methodology has some nice features including timely detection of outbreaks, robust inference to model misspecification, reasonable prediction performance as well as attractive analytical and visualization tool to assist public health authorities in risk assessment. Based on extensive simulation studies and synthetic data generated from a dynamic SIR model, we demonstrated that the model is capable of capturing outbreaks rapidly, while still limiting false positives.\n\nIn this paper, we have presented a new methodology that adapts the existing GMRF class of models to deal with spatio-temporal surveillance data. When the data are mainly spatial and coarsely discretized in time, simple models such as the CAR model will continue to be valuable for descriptive analysis. However, when data have a fine resolution in both the spatial and temporal dimensions, our model, which explicitly incorporates the directional nature of time by conditioning future events on past outcomes, is likely to be more insightful.\n\nSyndromic surveillance; spatio-temporal; Markov random field; conditional autoregressive Introduction Livestock owners normally pay the full cost of disease testing. As a result the number of laboratory submissions is dependent on the owner's perception that testing is beneficial. This decreases the likelihood of an accurate diagnosis and biases the number and type of samples received by a laboratory. Despite these limitations, laboratory data are commonly used for passive disease surveillance.\n\nThe Ontario Farm-call Surveillance Project (OFSP) analyzed disease-related farm call data supplied by livestock veterinarians. Project goals were to provide a new data source for livestock disease monitoring and to improve the quality of laboratory data. As an incentive for participation, veterinarians were not charged when diagnostic samples were sent to the Animal Health Laboratory (AHL), University of Guelph.\n\nThe OFSP veterinary clinics were a convenience sample of foodproduction and equine clinics in Ontario. Clinics participating in OFSP were offered two incentives: (1) free diagnostic testing at the AHL and (2) $175.00 per farm call if postmortems (PMs) were performed and farm call data were received within 10 days of the call. The first incentive was offered for the duration of the project; the second was available from October 2010 to June 15, 2011.\n\nThe average number of days from farm call completion to data submission was compared pre-and post-PM incentive.\n\nThe rate at which a veterinarian submitted samples for diagnostic testing to the AHL was calculated (total number of submissions/total number of farm calls). Only 20/28 OFSP clinics were enrolled in the study pre-PM incentive. A comparison of the number of submissions to the AHL for those clinics pre-and post-PM incentive was performed. Submissions of animals for necropsy or tissue for histology were classified as 'pathology' submissions. The proportion of livestock pathology submissions that were from the OFSP were compared to the total livestock pathology submissions pre-and postcommencement of the PM incentive. AHL reporting rates of livestock zoonotic diseases were compared pre-and post-commencement of the OFSP (total number of positive livestock zoonotic disease laboratory submissions/total number of livestock laboratory submissions).\n\nOne hundred and eight veterinarians from 28 livestock clinics contributed data to the surveillance project between April 2009 and June 2011. No clinics withdrew from the study. Fig. 1 illustrates the timeliness of reporting before and after the PM incentive.\n\nVeterinarians participating in OFSP submitted a sample to the AHL 11% of the time they completed a disease-related farm call. A comparison of 20 OFSP clinics revealed that 458 more cases were submitted to the AHL while those clinics were participating in the OFSP than the year prior to participation. OFSP clinics represented 19% (28/147) of the clinics submitting pathology samples during the time period the PM incentive was offered. OFSP pathology submissions represented 36% (712/ 1984) of the total pathology livestock submissions for the same time period. For the same period, the previous year (pre-PM incentive) OFSP pathology submissions accounted for 7.7% (141/1822) of the total pathology submissions.\n\nThe proportion of laboratory submissions from OFSP clinics positive for a zoonotic disease increased from 4.3% prior to participation in the project to 7.7% while part of the OFSP.\n\nIncentives are needed to ensure adequate compliance with a surveillance program. The OFSP incentives were considered a key factor in the number of veterinarians participating in the study as well as the 0% drop out rate.\n\nReceiving data quickly is critical when monitoring for new or emerging diseases. Animals found dead or moribund are an important group to monitor for livestock disease surveillance but producers often do not want to pay the cost of a PM. The ability to provide better client service made the incentives offered by OFSP appealing to veterinarians.\n\nThe OFSP incentives increased submissions to the laboratory, improved the laboratory data for passive surveillance and, specifically, increased zoonotic disease reporting.\n\nThanks to the OFSP veterinarians and clinic staff for their effort and support with this project. "}