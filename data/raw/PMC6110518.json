{"title": "Accounting for non-stationarity in epidemiology by embedding time-varying parameters in stochastic models", "body": "Our approach is based on three main components: an epidemiological model embedded in a state-space framework, a diffusion process for each time-varying parameter and an up-to-date Bayesian inference technique based on adaptive PMCMC.\n\nThe main advantage of the state-space framework is the use of two sets of equations, the first set describes the propagation of the disease in the population and the second is for the observation process. This allows for consideration of unknowns and uncertainty both in the epidemiological mechanisms and in the partial observation of the disease:\n{x\u02d9(t)=g(t,x(t),\u03b8'(t),u(t))y(t)|x(t)\u223cf(h(x(t)),\u03b8'(t))(1)\n\nThe first equation is for the epidemiological model, with x(t) representing the state variables (for instance, S(t) the susceptibles, I(t) the infectious and R(t) the removed for the classical SIR model) and \u03b8'(t) the epidemiological parameters. The second is the observational process defined by probabilistic law f and a reporting rate on transformation of some state variable h(x(t)) because we may not be able to directly measure all state variables but just some or a function of them. In these equations, y(t) are partial observations of x(t), u(t) is the process noise describing different form of stochasticity and the observational noise is included in f. In our applications, h(x(t)) will be the cumulative sum of new cases over the observation time step, that is generally the quantity observed by Public Health systems.\n\nConsidering the time-varying parameters \u03b8(t) as a subset of \u03b8'(t), we make the assumption that they evolve more or less randomly and do not follow a defined mathematical function. In the absence of prior information the use of diffusion motion allows us to impose few restrictions on the evolution of \u03b8(t). We consider that they follow a continuous diffusion process (a discrete diffusion process was used in [35]):\nd\u03b8(t)=\u03c3dB(t)ordlog(\u03b8(t))=\u03c3dB(t)(2)\nwhere \u03c3 is the volatility of the Brownian process (dB(t)) and will be estimated during the fitting process. The use of a Brownian process can be viewed as a weak hypothesis for the imposed motion of \u03b8(t) and the volatility \u03c3 being a regularized factor. Intuitively, the higher the values of \u03c3 the larger the changes in \u03b8(t). The logarithm transformation avoids negative values which have no biological meaning. When prior knowledge on \u03b8(t) is available this Brownian process can be modified to account for a drift in (2) (see [36]).\n\nFor the time-varying parameter, we focus on the parameter of the force of infection classically defined as:\n\u03bb(t)=\u03b2(t).S(t).I(t)N(3)\nwith \u03b2(t) the transmission rate usually defined by a sinusoidal function. The control or the behavior modification can also be taken into account:\n\u03bb(t)=\u03b2(t).(S(t)\u03b5S(t)).(I(t)\u03b5I(t))N(4)\n\n\u03b5i(t) describe the clustering of the population [39,40] but can also describe a reduction in the population due to voluntary avoidance behavior or social distancing. However due to the absence of structural identifiability properties [41, 42] it should be very difficult to estimate simultaneously both \u03b2(t) and \u03b5i(t).\n\nFor model estimation we use Bayesian methods, coupling particle filter and MCMC for partially observed stochastic non-linear systems [36,43] (see Methods). The implementation provided in SSM software [36] is used.\n\nWe start our demonstration by showing that it is possible to reconstruct both the trajectory of a SIRS model (SIRS stands for Susceptibles, Infectious, Removed and Susceptibles again) and that of the sinusoidal transmission rate. In this example, the trajectory of each variable has been simulated with a model for which all the parameters were known. Moreover we also knew the observation process that has generated the data, a Poisson law for the incidence with an observation rate equal to 1. Fig 1 displays the reconstructed trajectories of both the incidence and the transmission rate highlighting the potential of the method. The parameter estimations are in perfect agreement with the values used to generate the observations and the estimation process has correctly converged (S1 and S2 Figs). This clearly demonstrates the feasibility of accurately ascertaining the time evolution of the transmission rate and correctly estimating the Reff (see Fig 2). It is worth emphasizing that the SIRS model is a complicated example for different reasons. First, even with a constant transmission rate the SIRS model can generate oscillations (damped oscillations, see [17,44]). Secondly, the model trajectories are not very sensitive, a modification of \u00b1 10% can induce minor modifications of the trajectories that are inside or near the 95% CI of our inferences (Fig 2). Moreover in this example we have used initial conditions outside the attractor of the dynamics to generate transients that appear more realistic for real applications, but are more complex to reconstruct. The robustness of our approach has also been tested: (i) using long time series and initial conditions near the attractor (Fig 3A and S3A Fig); (ii) modifying the number of inferring parameters (S4\u2013S6 Figs), for instance estimating just the volatility parameter (S7 and S8 Figs); (iii) considering the possibility of not using the transformation log in the diffusion process (S9 and S10 Figs) and (iv) using a true \u03b2(t) with 2 or 3 periodic components (Fig 3B and 3C and S3B and S3C Fig).\n\nWe have also explored the performance of our approach by comparing their inferences to those of the true model. The re-estimation of the true model on its own data is displayed in S11\u2013S13 Figs. Table 1 presents indices of the goodness-of-fit of the true model and models with time-varying \u03b2(t) with different number of parameters inferred. As expected, the error on \u03b2(t) is smaller when the true equation is used (Table 1). However, regarding the estimated incidence, the true model and our approach give similar results both in terms of mean and variance (Table 1). It could be argued that the price of the flexibility of our approach is a greater variability in some of the trajectory estimations (Table 1). Nevertheless the average dynamics are always estimated correctly.\n\nAs misspecification is an important problem (e.g. [45]) we have also compared the performance of our approach to those of a misspecified seasonal SIRS model. We have thus used the example of a sinusoidal \u03b2(t) with two periodic components (see Fig 3B) and computed the indices of the goodness-of-fit of the true model with the SIRS model with 1 year sinusoidal \u03b2(t) and with our time-varying periodic \u03b2(t). The results clearly show that our approach performed better than the misspecified model for the three trajectories analyzed, Incidence, \u03b2 and Reff (Table 2). Once again the price of the flexibility of our approach is a greater variability in some of the trajectory estimations. However this is preferable to a large error in the median trajectories as occurred in those observed with the misspecified model (Table 2).\n\nOur methodology is also applicable to other more complex or simpler tasks. For instance, it can follow the time evolution of a parameter describing the availability of susceptibles, \u03b5S(t) (Fig 4 and S14 and S15 Figs). Fig 4 shows the accurate reconstruction of the trajectory of the incidence and also of the trajectory of \u03b5S(t) that shifted at a given time point and decreased slightly thereafter. This highlights once again the potential of our approach as it is never easy to estimate a discontinuous dynamic with a continuous process (2).\n\nIn previous works, the dynamics of influenza in Israel have been analyzed using a discrete deterministic SIRS model and weekly data from Israel\u2019s Maccabi health maintenance organization [20,46]. To describe the seasonality of this recurrent epidemic, the authors used a linear model between the transmission rate and local climatic variables, daily temperature and relative humidity [20,46]. We have re-analyzed their dataset (but limited to 1998\u20132003 due to a modification in the reporting) to reconstruct the time evolution of \u03b2(t). Our results (Fig 5 and S16 Fig) clearly show the potential of our method, highlighting that the \u03b2(t) fluctuations are more irregular and complex than a simple sinusoidal function.\n\nOur last example is on dengue in Cambodia. Again the idea is to relax the assumption of a sinusoidal \u03b2(t) in a SEIR model. Monthly data from the capital Phnom Penh [47], for which the meteorological data is available from the international airport, was used. We can accurately describe the 12 year time series and reconstruct the time evolution of \u03b2(t) (Fig 6 and S17 Fig). Our results stress that the \u03b2(t) oscillations are more complex than a simple sinusoidal function. Sometimes bi-modality occurs over one season. In general one observes a fast growth of \u03b2(t) and a slow decrease. Moreover the amplitude of the \u03b2(t) varies from year to year, perhaps depending on the fluctuations in the mosquito population and in the environment. Interestingly the peak in \u03b2(t) appears 1 to 2 months before the incidence peak. This delay can be explained by the extrinsic incubation period and might be used in a warning system.\n\nTo explain the \u03b2(t) oscillations we have explored the potential effects of local and global climatic variables using wavelet decomposition [48] as one of our main underlying hypotheses is non-stationarity. We observed very significant coherency between \u03b2(t) and climate for the local climate for the seasonal mode (Fig 7 and S18\u2013S20 Figs) and also for the 2\u20133 year components with global climatic variable (S21 Fig). Thus, the rhythm of \u03b2(t) can be explained perfectly by climatic factors. Nevertheless, again mainly due to large non-stationarity, by using solely one or two climatic variables we are able to correctly describe dengue evolution in the short-term (Fig 7C, red area) but not over a large time period (Fig 7C, blue area). This reflects the complexity of such a disease where the ecology of the vectors, the environment, the climate, the immune status of the human population and its behavior are all involved. This large non-stationarity association between dengue and climatic factors has recently been demonstrated using statistical models (dynamic generalized linear models) and data from a medium-sized city in Colombia [49]. The authors showed that dengue cases correlate with climatic variables (temperature, rainfall, solar radiation and relative humidity) but these correlations change over time, some intervals showing a positive association, while in others the association is negative [49]. The non-stationarity association between dengue and climate may be explained by the fact that a climatic variable has different effects depending on the biological cycle of the pathogen or of the vector. Moreover the effects of one climatic variable can also depend on other climatic variables potentially enhancing the non-stationarity association.\n\nAs there remain numerous uncertainties during the course of each epidemic, we are increasingly aware of the importance of developing adequate statistical and mathematical tools. Such tools need to take account of the time-varying nature of the underlying ecological and biological mechanisms as well as social and behavioral influences involved in an epidemic. Because of this, time-varying parameters modeled with a diffusion process, that track epidemiological patterns and update the key parameters according to data appear to be a worthwhile approach. Indeed developing a more complex model would be difficult considering the relative paucity of available data.\n\nWe propose a flexible modeling framework that encompasses time-varying aspects of the epidemic. It does this via diffusion process equations for time-varying parameters and also considers uncertainty associated with key parameters and data. This data-driven framework for time-varying parameters has been coupled with simple stochastic models and a robust Bayesian procedure for inference. To test its efficiency, our proposed methodology was first applied to a toy model and then to real epidemiological examples.\n\nOur results clearly demonstrate the potential of our framework. Firstly, our methodology was able to accurately reconstruct both the incidence and the sinusoidal transmission rate of a simple SIRS model just based on noisy observations (Figs 1\u20134 and S4,S5,S7,S9 and S14 Figs). Based on these reconstructions one can also closely estimate Reff which is one of the key relevant epidemiological parameters. Our results also highlight the flexibility of our developed methodology. It can reconstruct the time evolution of a shifting parameter (\u03b5S(t), see Fig 4 and S14 Fig) as well as an oscillating parameter that influences the nonlinear part of the model (\u03b2(t), see Figs 1\u20133 and S4,S5,S7 and S9 Figs). The comparison using goodness-of-fit indices with the inferred true model allows us to highlight the fact that our methodology performs as well for the observed incidence. Its flexibility results in greater variability in some other trajectories mainly \u03b2(t) and Reff (Table 1). Moreover, in the absence of knowledge of the true evolution of the transmission rate, our approach appears to capture the dynamic observed more accurately than a misspecified model (Table 2). Secondly, applied to real datasets, our framework is able, based solely on simple stochastic models, to reconstruct complex epidemics such as flu or dengue over long time periods (Figs 5 and 6). In such cases, the reconstruction of the time evolution of the transmission rate clearly stresses that, on real datasets, it is difficult to assimilate the dynamic of this parameter as a simple sinusoidal function. It is more irregular in amplitude and sometimes multi-modal over one season.\n\nConsidering the paucity of information available regarding the complexity of the mechanisms involved during an epidemic, describing and fitting a full model for a given transmissible disease is always challenging. Our data-driven methodology can be used as a first step towards a better understanding of a complex epidemic, where data is limited or lacks certainty. Indeed most of the unknowns and uncertainties can be put into time-varying parameters. The potential effects of all these uncertainties can then be explored by analyzing the reconstructed time evolution of the time-varying parameters. See Fig 7 for such preliminary analysis of dengue in Phnom Penh. This allows a more thorough analysis of the influences and the interactions between both the human behavior and complex environmental drivers. In a recent paper [50], the authors reviewed evidence of interactions between seasonal influenza virus and other pathogens (bacteria or virus). They concluded that it is important to incorporate these different coinfecting pathogens in models of seasonal flu in order to get a better estimate of the burden of influenza. Our framework could be an alternative to the development of complex models with all the potential interactions between pathogens and to estimate the strength of the interactions. After reconstructing the time evolution of the transmission rate the statistical association between the coinfecting pathogens and the transmission rate could be tested. This screening may facilitate the construction of more complex models that could incorporate only the most significant coinfecting pathogens in the seasonal flu model.\n\nOur methodology also has other advantages. Taking account of the simplicity of the model used, and the fact that weak hypotheses on the dynamics of the time-varying parameters have been included, our proposed methodology can retrospectively test the impact of interventions. This has previously been done in the case of HIV epidemics [34\u201335], where it was hypothesized that the reduction in the transmissibility was due to a modification of the sexual behavior in the population and the increase in the seropositive period duration due to the introduction of the first antiviral treatments. Evaluation of interventions has also been done recently in the case of the Ebola epidemic in West Africa [51]. The relative simplicity of our methodology is also suitable for short-term predictions and it can then easily be used to predict an epidemic in real time. Starting with a given estimated state defining the system, the fitting process can be run again each time new data is available and the new posteriors are used for new predictions [36]. This can inform public health decisions and indeed has been done recently to great effect in the case of the Ebola epidemics in West Africa [52].\n\nA major challenge in model fitting is the reliability of data collected and also the non-identifiability of the mechanistic models that always have very rich dynamical behavior. The question of identifiability is too often avoided in epidemiological models applied to a topical Public Health issues. There is, however, considerable literature on this subject (e.g. [41,42,53\u201355]). Identifiability is not evident even for a simple seasonal SIR model [56]. To solve this problem one can fit a combination of parameters or fix some of them (the population size for instance) [57]. In our applications there is a clear limitation due to practical non-identifiability of reporting rate and initial conditions. To fix these problems we have used informative priors (see Method). Using informative priors or fixing some parameters gives very similar results (compare Fig 1 and S4\u2013S7 Figs). Related to this is the misspecification of models [45]. In our cases, as with other semi-mechanistic models the time-varying parameter methodology captures some of the information in the data but not in the mechanistic part of the model. If the model is misspecified due to lack of precision, it compensates for it and the dynamics of \u03b2(t) will drive improvements in the model to make it more complex and realistic (Table 2). If the model is misspecified to the extent that it creates mechanisms that do not exist, the reconstructed \u03b2(t) would compensate for these effects but it will be harder to interpret.\n\nIn this work we have used simple mechanistic models. The proposed methodology is not limited to simple models. For instance, a two-strain dengue model has also been tested. In this case the main problem was linked to the unavailability of both seroprevalence and incidence for each strain. Indeed, one of the major difficulties with these multi-strain models is the identification of the initial conditions (e.g. [58]). Nevertheless it is worth emphasizing that the Bayesian inference method used in our framework, PMCMC, the approximation of the likelihood is limited for a large number of parameters and/or equations [59]. In such cases testing other methodologies like ABC [60,61] is advisable.\n\nIt is always difficult to fit complex models with rich behaviors based on very limited information. In this regard we agree with Metcalf et al. [62] who stressed that nowadays we need seroprevalence studies to quantify the immunological status of the population, because in most cases the magnitude of the outbreak is difficult to evaluate without precise seroprevalence data.\n\nTo tackle the uncertainty and the non-stationarity of epidemics, our methodology, although it appears non-standard, makes important progress towards a better understanding of the mechanisms responsible for disease propagation. We believe that, should it form part of the development of the next predictive tools for Public Health, it will make a significant contribution to improving the understanding and control of infectious diseases in our increasingly uncertain world.\n\nOur first model is a classical SIRS model with an observation rate \u03c1 = 1 and Poisson law as the observational process:\nS\u02d9=\u03bc.(N\u2212S)\u2212\u03b2(t).S.I/N+\u03b1.RI\u02d9=\u03b2(t).S.I/N\u2212(\u03b3+\u03bc).IC\u02d9=\u03b2(t).S.I/NR\u02d9=\u03b3.I\u2212(\u03b1+\u03bc).R(5)\nwhere S, I and R are the susceptibles, the infectious and the removed respectively, the transmission rate \u03b2(t) = \u03b20.(1 + \u03b21 sin(2\u03c0t/365+2\u03c0\u03d5), 1/\u03b1 is the average duration of immunity, \u03b3 is the recovery rate and \u03bc is the recruitment or mortality rate. In (5), C is the number of new cases, then h(x(t)) is the cumulative sum of C(t) over the observation time step, 7 days. With this model Reff(t) = \u03b2(t).S(t)/(N.\u03b3). The parameter values are in the caption of Fig 1. For the fit of our simulated data, Gaussian priors are used for epidemiological parameters (\u03b1 and \u03b3). Initially non-informative priors were used for the volatility \u03c3, the reporting rate \u03c1 and the initial conditions \u03b3(0) by \u03b2(0) but to reduce problems linked to practical non-identifiability materialized by correlation between some estimates, informative priors were used for \u03c1 (see S1 Fig). Some other simulations have been done fixing \u03b2(0) and \u03c1 or just inferring \u03c3 (see S4\u2013S8 Figs).\n\nFor analyzing Israel flu data we have used a continuous SIRS model identical to (5), we simply added imported infectious people i in the force of infection:\n\u03bb(t)=\u03b2(t).S(t).(I(t)+i)N(6)\n\nThe initial guess values for the parameters are from [46]. In this example the observational process is a Negative-Binomial law with an over-dispersion parameter equal to 0.05 and the reporting rate \u03c1 = 0.15 [46]. For the fit, Gaussian priors are used for epidemiological parameters (i, \u03b1, \u03b3) and non-informative priors for the volatility \u03c3 and the initial conditions (S(0), I(0)). S16 Fig displays the priors and the posteriors.\n\nTo describe the dengue epidemics, taking account of the available data for Phnom Penh, we have fitted a one strain model using a SEIR model:\nS\u02d9=\u03bc.(N\u2212S)\u2212\u03b2(t).S.(I+i)/NE\u02d9=\u03b2(t).S.(I+i)/N\u2212(\u03b4+\u03bc).EI\u02d9=\u03b4.E\u2212(\u03b3+\u03bc).IR\u02d9=\u03b3.I\u2212\u03bc.R(7)\nwhere E is for infected but not yet infectious, \u03b2(t) is the transmission rate, 1/\u03b4 is the average duration of the latent period, \u03b3 is the recovery rate and \u03bc is the recruitment or mortality rate. The initial guess for parameter values comes from the literature [63]. In this example the observational process is a Negative-Binomial law with an over-dispersion parameter equal to 0.05 and the reporting rate \u03c1 has been estimated using a narrow Gaussian prior. Non-informative priors are used for the volatility \u03c3, initial condition for infected E(0) and imported infectious people i. Gaussian priors are used for other parameters and initial conditions. When E(0) is fitted, I(0) is estimated as a steady-state value I(0) = \u03b4.E(0)/(\u03b3+\u03bc). S17 Fig. displays the priors and the posteriors.\n\nDue to the use of a diffusion Eq (2) for the dynamic of the time-varying parameters, the stochastic versions of the previous models have been fitted. Thus the models are considered in a stochastic framework in which the compartments are discrete and the number of reactions occurring in a time interval dt is approximated by a multinomial distribution. It is fully described in [64,65].\n\nIn a model with n observations and J particles. L is the model likelihood p(y1:n|\u03b8). Wk(j) is the weight and xk(j) is the state associated to particle j at iteration k.\n\n1. Set L=1,W0(j)=1/J.\n\n2. Sample (x0(j))j=1:J from p(x0|\u03b8)\n\n3. for (k = 0:n\u22121) do\n\n4.     for (j = 1:J) do\n\n5.         Sample xk+1(j) from p(xk+1|xk(j),\u03b8)\n\n6.         Set \u03b1(j)=p(yk+1|xk+1(j),\u03b8)\n\n7.     end for\n\n8.     Set Wk+1(j)=\u03b1(j)\u2211l=1J\u03b1(l) and L=L1J\u2211l=1J\u03b1(l)\n\n9.     Resample (x0:k+1(j))j=1:J from Wk+1(j).\n\n10. end for\n\nSince the epidemiological propagation models are considered in a stochastic framework, their likelihood is intractable and it is estimated with particle filtering methods (Sequential Monte Carlo, SMC). With a given set of parameters, the SMC algorithm reconstructs sequentially the trajectory of the state variables and the time-varying parameters, and computes the associated likelihood. Firstly, the distribution of the initial conditions of the system is approximated with a sample of particles. Then, at each iteration, the particles are projected according to the propagation model up to the next observation point, they receive a weight reflecting the quality of their prediction compared to the observation and the total likelihood is updated. A resampling step using the weights is performed before the next iteration, in order to discard the trajectories associated with low weight particles.\n\nIn order to estimate the parameters of the system, the particle filter is embedded in a Markov Chain Monte Carlo framework, leading to the PMCMC algorithm [43]. More precisely, the likelihood estimated by SMC is used in a Metropolis Hasting scheme (particle marginal Metropolis Hastings) [43]. The proposal distribution is a Gaussian whose co-variance matrix is adapted following the framework described in [65].\n\nThe starting point of the MCMC chain is initialized using optimal values obtained from the KSimplex algorithm on a large number of parameter sets. Then, a pre-adaptation of the proposal co-variance matrix is performed with Kalman MCMC (KMCMC). Each time the idea relies on less computationally intense algorithms in order to facilitate the exploration of parameter space. But as we use stochastic models we approximate the likelihood using the extended Kalman filter both in the simplex algorithm (KSimplex) [65] and in the MCMC (KMCMC) [36]. Then the adaptive PMCMC is executed on the output of the KMCMC with 100000 iterations and 10000 particles for the final figures. For instance, the results such as those of Fig 1 take less than 24 hours, on a blade server from PowerEdge M-Series with 40 processor cores.\n\nIn a model with n observations and J particles.\n\nq(.|\u03b8(i)) is the transition kernel\n\n1. Initialize \u03b8(0)\n\n2. Using SMC algorithm, compute p^(y1:n|\u03b8(0)) and sample x0:n(0) from p^(x0:n|y1:n,\u03b8(0))\n\n3. for (i = 0:N\u22121) do\n\n4.     Sample \u03b8* from q(.|\u03b8(i))\n\n5.     Using SMC algorithm, compute L(\u03b8*)=p^(y1:n|\u03b8*) and sample x0:n* from p^(x0:n|y1:n,\u03b8*)\n\n6.     Accept \u03b8* (and x0:n*) with probability 1\u2227L(\u03b8*)p(\u03b8*)q(\u03b8(i)|\u03b8*)L(\u03b8(i))p(\u03b8(i))q(\u03b8*|\u03b8(i))\n\n7.     If accepted, \u03b8(i+1)= \u03b8* and x0:n(i+1)=x0:n*. Otherwise, \u03b8(i+1)= \u03b8(i) and x0:n(i+1)=x0:n(i).\n\n8. end for\n\nIn order to assess convergence of the chain, the visual inspection of the chains (e.g.\nS2 Fig or S8 Fig) was complemented by diagnosis provided in the Coda package in R [66]. Due to the large computational cost of the algorithm, we did not run multiple independent chains, rather we relied on diagnosis using one MCMC chain and testing its stationarity: Geweke diagnosis [67] and Heidelberger and Welch\u2019s diagnosis [68]. The results are presented in S1 and S2 Tables.\n\nAmong the various approaches developed to study nonstationary data, wavelet analysis is probably the most efficient. In particular, this method gives us the possibility of investigating and quantifying the evolution in time of the periodic components of a time series (see [69]). Wavelets constitute a family of functions derived from a single function, the \u2018\u2018mother wavelet\u201d, \u03a8a,\u03c4(t), that can be expressed as the function of two parameters, one for the time position \u03c4, and the other for the scale of the wavelets a, related to the frequency. More explicitly, wavelets are defined as:\n\u03a8a,\u03c4(t)=1a\u03c8(t\u2212\u03c4a)\n\nThe wavelet transform of a time series x(t) with respect to a chosen mother wavelet is performed as follows:\nWx(a,\u03c4)=1a.\u222b\u2212\u221e+\u221ex(t).\u03a8*(t\u2212\u03c4a).dt=\u222b\u2212\u221e+\u221ex(t).\u03a8a,\u03c4*.dt\nwhere * denotes the complex conjugate form. The wavelet transform Wx(a,\u03c4) represents the contribution of the scale a to the signal at different time positions \u03c4. The computation of the wavelet transform is done along the signal x(t) simply by increasing the parameter \u03c4 over a range of scales a until all coherent structures within the signal can be identified. Here, as mother wavelet, we have used the Morlet wavelet [69].\n\nWith the wavelet approach, we can estimate the repartition of variance at different scale a and different time location \u03c4. This is known as the wavelet power spectrum: Sx(a,\u03c4) = | Wx(a,\u03c4) |2. An important point with the continuous wavelet is that the relationship between the wavelet frequency f0 and the wavelet scale a can be derived analytically. For the Morlet wavelet this relationship is given by:\n1f=4\u03c0af0+2+f02\n\nThen when f0\n= 2\u03c0, the wavelet scale a is inversely related to the frequency, f \u2248 1/a. This greatly simplifies the interpretation of the wavelet analysis and one can replace, on all equations, the scale a by the frequency f or the period 1/f.\n\nTo determine the statistical relationship between two time series, wavelet coherence can be computed (e.g. [48,70]):\nRx,y(f,\u03c4)=(|\u2329Wx,y(f,\u03c4)\u232a|2|\u2329Wx(f,\u03c4)\u232a|2.|\u2329Wy(f,\u03c4)\u232a|2)1/2\nwhere the angle brackets around terms indicate smoothing in both time and frequency, Wx(f,\u03c4) is the wavelet transform of series x(t), Wy(f,\u03c4) is the wavelet transform of series y(t), and Wx,y(f,\u03c4) is the cross-wavelet spectrum. The values of wavelet coherence are between 0 < Rx,y(f,\u03c4) < 1. The wavelet coherency is equal to 1 when there is a perfect linear relation at particular time and scale between the two signals, and equal to 0 if x(t) and y(t) are independent.\n\nTo complement this, phase analysis can be used to characterise the association between signals (e.g. [48,70]). The phase difference provides information on the sign of the relationship (i.e., in phase or out of phase) and can be computed, for complex mother wavelet, with the wavelet transform Wx(f,\u03c4) as:\n\u03d5x(f,\u03c4)=tan\u22121Im(Wx(f,\u03c4))Re(Wx(f,\u03c4))\n\nSimilarly with the cross-wavelet transform Wx,y(f,\u03c4) the phase difference between the two time series can be computed:\n\u03d5x,y(f,\u03c4)=tan\u22121Im(Wx,y(f,\u03c4))Re(Wx,y(f,\u03c4))"}