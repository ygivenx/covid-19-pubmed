{"title": "Protein Analysis by Shotgun/Bottom-up Proteomics", "body": "inference is accomplished by assigning peptide sequences to proteins. Because peptides can be either uniquely assigned to a single protein or shared by more than one protein, the identified proteins may be further scored and grouped based on their peptides. In contrast, another strategy, termed 'top-down' proteomics, is used to characterize intact proteins ( Figure 1 ). The top-down approach has some potential advantages for PTM and protein isoform determination and has achieved notable success. Intact proteins have been measured up to 200 kDa, 12 and a large scale study has identified more than 1,000 proteins by multidimensional separations from complex samples. 13 However, the top-down method has significant limitations compared with shotgun proteomics due to difficulties with protein fractionation, protein ionization and fragmentation in the gas phase. By relying on the analysis of peptides, which are more easily fractionated, ionized and fragmented, shotgun proteomics can be more universally adopted for protein analysis. In fact, a hybrid of bottomup and top-down methodologies and instrumentation has been introduced as middle-down proteomics. 14 Essentially, middle-down proteomics analyzes larger peptide fragments than bottom-up proteomics, minimizing peptide redundancy between proteins. Additionally the large peptide fragments yield similar advantages as top-down proteomics, such as gaining further insight into post-translational modifications, without the analytical challenges of analyzing intact proteins. Shotgun proteomics has become a workhorse for the analysis of proteins and their modifications and will be increasingly combined with top-down methods in the future.\n\nIn the past decade shotgun proteomics has been widely used by biologists for many different research experiments, advancing biological discoveries. Some applications include, but are not limited to, proteome profiling, protein quantification, protein modification, and proteinprotein interaction. There have been several reviews nicely summarizing mass spectrometry history, 15 protein quantification with mass spectrometry, 16 its biological applications, 5, [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] and many recent advances in methodology. [27] [28] [29] [30] [31] [32] In this review, we try to provide a full and updated survey of shotgun proteomics, including the fundamental techniques and applications that laid the foundation along with those developed and greatly improved in the past several years.\n\nProteins are part of a complex network of interacting biomolecules that regulate their function and localization within the cell. Extraction and isolation of proteins from chemical and physical interactions with other biomolecules from specific cellular sub-compartments has become a critical step for their global analysis in a biological context. In some cases, physical and chemical interactions may otherwise inhibit the isolation or analysis of proteins of interest by LC-MS. The global analysis of membrane-embedded proteins is a prominent example. Isolation, solubilization, and proteolytic digestion of lipid-bound proteins have all proven to be essential steps in their shotgun proteomic analysis. The integration of multiple methodological advancements for analysis of membrane-bound proteins is described in the \"Proteolytic Digestion and Chromatographic Separations\" sections. Another noteworthy example of protein isolation from interactions with other non-protein biomolecules that improved proteomic analysis was recently demonstrated with transcription factors (TF). Under specific biological conditions, TFs form complexes with high affinity for DNA. Until recently their proteomic analysis was thought to be limited by their low abundance, but was instead due to inadequate disruption of TF-DNA interactions. The degradation of DNA using a combination of deoxyribonucleases improved the recovery of transcription factors from standard hypotonic-lysed cells, facilitating their targeted proteomic analysis. 33 Proteins have also been isolated from more rigid structures, such as bone tissue using hydrochloric acid, allowing for the identification of ~2,500 proteins with shotgun proteomics. 34 Application of traditional subcellular isolation techniques, primarily sucrose gradient sedimentation and similar methodologies, from different cell types and tissues have allowed for global analysis of proteins within subcellular compartments. Studies of the differential expression and trafficking of proteins between subcellular compartments are important to understanding proper cellular function. Characterization of the principal subcellular proteomes, nuclear and cytosolic, has been performed on yeast, [35] [36] leukemia cells, 37 a bronchitis virus cellular model, 38 and an autoimmunity cell model. 39 A study of mouse liver used protein correlation profiling to map ~1,400 proteins to 10 subcellular localizations with validation by enzymatic assays, marker protein profiles, and confocal microscopy. 40 Further studies have teased apart finer subcellular compartments, such as the nucleolus. Significant changes to the nucleolar proteome were found upon infection with the Influenza A virus. 41 Many studies have begun to interrogate the energy-producing organelle within the cell, the mitochondrion. Mitochondrial proteins have been identified from C. elegans, 42 rat liver, 43 and leukemia cell lines 44 by coupling biochemical sedimentation purification with shotgun proteomic analysis. Similarly, the protein post-translational modifications phosphorylation and carbonylation have been identified from mitochondrial preparations of murine heart and skeletal muscle, respectively. [45] [46] A quantitative comparison of mitochondrial proteins among rat heart, liver, and muscle tissues found essentially the same proteins with tissuespecific abundances. 47 Combining many of these methodologies, approximately 22 protein abundance changes were found among subcellular fractions due to myocardial ischemia. 48 Another highly studied subcellular fraction using proteomic methods is the synaptosome. Studies on the synaptosome have implications in many aspects of neuroscience research. The synapse is the biochemical communication junction unique to neuronal cells and can be isolated within a synaptosomal preparation from multiple differential centrifugation steps. As with all subcellular proteomic studies discussed thus far, the quality of the data is heavily dependent on the purity of the subcellular preparation. In the case of the synaptosome, correlation-profiling has been employed to validate post-synaptic density proteins. 49 Similar quantitative proteomic methodologies have facilitated the characterization of post-synaptic density proteins between rat forebrain and cerebellum, 50 hippocampal synaptosome protein changes in CAM kinase II mutant mice, 51 and synaptosomal protein dynamics and spatiotemporal dynamics of synaptosomal and non-synaptosomal mitochondrial proteins during brain development. [52] [53] Quantitative phosphoproteomic analysis of KCl-activated synaptosomes found a uniquely regulated phosphorylation site on the glutamate receptor subunit GluR1. 54 Further advances in subcellular fractionation and proteomic methodologies will aid in understanding the complex dynamics of proteins among cellular subcompartments.\n\nProtein dynamic range is the largest challenge that faces proteomics technology development. Currently, all steps within an LC-MS proteomics pipeline are protein abundance-dependent. Thus, adjustment of protein concentration dynamic range has become an option for improving comprehensiveness through improved analysis of low abundance proteins. Two main approaches are used for protein dynamic range adjustment: (1) selective depletion of known high abundance proteins and (2) selective equalization of protein dynamic range using combinatorial ligand libraries. In particular, both of these strategies have proven most useful for the analysis of plasma and other clinical samples. Specific applications of this will be described in the \"Clinical Applications\" section. Clinical samples for proteomic analysis are often more complex than model systems and present higher protein dynamic ranges, up to nine orders of magnitude. 55 Fortunately, only a few proteins are extremely abundant, such as serum albumin in the case of plasma, and thus can be specifically removed or depleted prior to LC-MS analysis. Chemical-based approaches can selectively precipitate abundant proteins, usually albumin, from plasma to improve proteomic depth and have been demonstrated with sodium chloride and ethanol, 56 acetonitrile, 57 the disulfide reducing agents DTT and TCEP, 58 and ammonium sulfate. 59 Antibody arrays against the highest abundance proteins have also improved proteomic coverage of clinical samples, 60 yet there remain significant short comings for the analysis of low abundance proteins. 61 Although relatively effective, another drawback to antibody depletion methodologies is the high cost of reagents (Sigma 20 protein single depletion kit - $1,200) . Additionally, since the depletion efficiency relies on the binding capacity of the antibodies only small sample amounts (8 \u03bcL plasma) can be depleted. Ultimately this depletion capacity can limit the starting mass of low abundance proteins within the sample. Nonetheless, antibody depletion is a critical step for most clinical applications.\n\nProtein abundance dynamic range adjustment using combinatorial ligand libraries is an alternative, cheaper, and more holistic approach. Bead-bound combinatorial peptide ligand libraries simultaneously deplete abundant proteins while enriching low abundance proteins 62 and can be performed for $50 per experiment. The equalization strategy is the converse of depletion strategies in that proteins which bind to a bead-conjugated hexapeptide ligand are collected and used for analysis. The combinatorial hexapeptide library serves as a large collection of ligand epitopes for proteins to bind. Additionally, hexapeptide ligands are assumed to be at approximately equimolar amounts, allowing for equalization of protein concentration. An obvious drawback to this methodology is that for a protein to be retained for analysis it must have affinity for one of the millions of possible hexapeptide ligands that are represented on the bead library used. 63 High abundance proteins that saturate their equimolar hexapeptide ligands can be washed away, while low abundance proteins can be concentrated and enriched on the solid-phase beads, especially if they have high affinity for their associated ligand or ligands. The benefits of protein equalization with hexapeptide beads in conjunction with shotgun proteomics was demonstrated on a model human cell line. 64 More recently, classic Michaelis-Menten enzyme kinetics were exploited to equalize proteomes in an unbiased fashion. 65 The methodology cleverly uses a protease, already used in shotgun proteomic pipelines, to selectively digest abundant proteins into peptides for removal with a molecular weight cutoff spin-filter. The remaining less abundant, undigested proteins are then also digested to completion, as routinely performed and described in the following section. With the abundant proteins depleted and the proteome equalized, dramatic improvements were observed in the total number of protein identifications and the sequence coverage and quantitation metrics of low abundance proteins. This strategy directly addresses one of the most daunting challenges of globally analyzing proteomes, protein abundance dynamic range, and presents a simple and versatile strategy to significantly improving shotgun proteomic analysis.\n\nAnalysis of proteins from their proteolytic peptides circumvents some of the challenges associated with intact protein separation, ionization, and MS characterization. A protein lysate is a highly heterogeneous mixture of proteins with diverse physicochemical properties. Purposefully increasing the complexity of a sample prior to analysis is somewhat counter-intuitive. However, selective protease digestion acts to normalize and compartmentalize the biochemical heterogeneity of proteins within a sample as peptides and may, in fact, create a less heterogeneous mixture when protein splice isoforms and posttranslational modifications are considered. Additionally, with multiple representations of a protein as peptides the probability of sampling and identifying a peptide associated with a particular low abundance protein and/or post-translational modification increases.\n\nIn general, proteolytic enzymes differ by their specificity for cleaving the amide bonds between individual residues in a protein. Commonly used proteases with their biochemical specificity and applications are listed in Table 1 . The cleavage is carried out through hydrolysis of the amide bond before or after a specific residue, residues, or combination of residues. Trypsin has become the gold standard for protein digestion to peptides for shotgun proteomics. Trypsin is a serine protease which cleaves at the carboxyl side of arginine and lysine. This sequence-specific information has been used to filter identified peptides. However, high accuracy mass spectrometers have reduced the importance of this filtering criterion and allowed for identification of non-tryptic protein sequences and posttranslational modifications where trypsin cleavage is inhibited. [66] [67] [68] For low complexity samples, such as protein complexes, the combination of both highly selective and nonselective proteases improves protein and post-translational modification coverage. [69] [70] For complex proteomic samples, the utilization of a combination of highly selective proteases improves protein and proteome coverage and sensitivity by creating complementary peptides. [71] [72] These multi-protease analyses are performed in parallel, as a systematic study showed that purposefully creating more peptides with two proteolytic enzymes reduced the number of proteins identified. 73 Similarly, parallel analysis of a tryptic digestion and subsequent proteolytic digestion with Glu-C after size-based isolation of long tryptic peptides improved protein, proteome, and phosphorylation identification coverage. 74 Related studies also illustrated the effects of protease biases on global phosphorylation identification studies based on identified phosphorylation motifs. [75] [76] [77] Digestion efficiency has been optimized based on a number of reaction conditions. In particular, adequate solubilization and unfolding of all proteins in a complex mixture is important to provide a protease access to cleavage sites. The use of organic solvents during trypsin digestion has been shown to improve digestion efficiency based on peptide identifications, protein sequence coverage, and trypsin specificity on protein complex purifications [78] [79] and complex proteomic mixtures. 80 SDS remains one of the best protein solubilizers, but is detrimental to LC-MS peptide sensitivity, as are most traditional surfactants, so strategies for removal are continually developed. SDS works well with protease digestions because it is a strong chaotropic agent, or chaotrope -a substance which denatures and disrupts the structure of macromolecules. A chaotrope swapping strategy was previously demonstrated 81 for removal of SDS while maintaining protein denaturation and was recently reintroduced as beneficial with higher sensitivity mass spectrometers. 82 As an alternative to pre-digestion removal of SDS, a KCl precipitation strategy was demonstrated post-digestion to provide the benefits of SDS-assisted proteolytic digestion without the detrimental effects during LC-MS analysis. 83 A number of LC-and MS-compatible surfactants have also been developed and evaluated to improve protein identification comprehensiveness. 80, 84 Generally, the commercially-available MS-compatible surfactants (e.g. ProteaseMAX, Invitrosol, Rapigest, PPS Silent Surfactant) have an acid labile moiety within the surfactant structure so it can be degraded during or after digestion and prior to LC-MS. The degradation creates components which do not co-elute with peptides during LC-MS, making them compatible with common shotgun proteomics methods. Two lesscommon, volatile surfactants which can be evaporated prior to LC-MS have also proven useful for solubilization and digestion of membrane-bound proteins: perfluorooctanoic acid 85 and 1-butyl-3-methyl imidazolium tetrafluoroborate. 86 As an alternative to surfactants, trifluoroethanol has proven useful for concurrent protein extraction and denaturation for mass-limited samples where sample clean-up is usually detrimental to sensitivity. 87 Avoidance of chaotropes for protein solubilization through the use of ammonium bicarbonate alone was proposed to improve detection limits in an analysis of a few hundred to thousand cancer cells. 88 Modification of protein digestions using physical methods has also contributed to improved digestion efficiency and proteomic coverage. Digital microfluidics allowed for automation of sample clean-up and protein digestion steps for MALDI to improve sensitivity. [89] [90] [91] [92] [93] Covalent and dynamic immobilization of trypsin within microreactors, [94] [95] on microparticles 96 and nanoparticles 97 and the use of focused highly-intensity ultrasound [98] [99] and microwave [100] [101] [102] [103] heating have improved the kinetics of tryptic digestion, reducing digestion time. The immobilization of proteases on microwave-absorbing microspheres and nanoparticles further improved speed and efficiency. [104] [105] Microwave heating of proteins under acidic conditions selectively cleaves proteins at aspartic acid residues, creating complementary peptides of similar length to trypsin digestion. [106] [107] Sequential microwaveassisted acid hydrolysis and overnight protease digestion proved useful for the digestion of extremely thermal-and biochemically-stable proteins from the hyperthermophile Pyrococcus furiosus. 108 Raising the pressure of proteolytic digestion has also improved the efficiency of proteolytic digestion, 109 presumably by improved unfolding of proteins and greater mixing, and allowed for online digestion within an LC-MS pipeline. 110 \n\nTwo dimensional polyacrylamide gel electrophoresis (2D-PAGE) is a powerful method for the separation of complex mixtures of proteins for proteomic analysis. 111, 112 This method is based on molecular mass and charge and is capable of separating several thousands of intact proteins on a single gel. Following separation on 2D-PAGE, proteins can be identified as intact proteins or peptides using MALDI-MS or with LC-MS after an in-gel digestion. 113 A combination of detergents (such as SDS and CHAPS) and chaotropes (such as urea and thiourea) have generally been used for solubilization and denaturation of protein samples prior to separation on the 2D gel. 114, 115 Solubilized proteins are separated by isoelectric focusing (IEF), where a gradient of pH is applied to a gel, followed by application of an electric potential. Development of immobilized pH gradient (IPG) strips, which are far simpler to use than carrier-ampholyte-driven pH gradients, has led to greater popularity of the 2D method in the proteomics field. Enhanced reproducibility and generation of various pH gradient types, such as basic gradients, 116 non-linear pH gradients, 117 or narrow pH gradients 118 using plastic-supported IPG strips have been reported.\n\nAfter 2D-PAGE separation, proteins can be detected by Commassie Brilliant Blue or silver staining. Despite greater sensitivity, silver staining does not show linearity of signal and is less compatible with MS, therefore Commassie Brilliant Blue is most commonly used. 119 A formaldehyde-free silver staining method that is compatible with MS has been developed. 120 The Pro-Q Diamond and Pro-Q Emerald staining methods have been developed for phosphoproteins and glycoproteins, respectively. 121, 122 Use of 2D-PAGE is labor-intensive and time-consuming, with a low dynamic range and significant gel-to-gel variation. 123 Introduction of 2D difference gel electrophoresis (DIGE) has overcome some of the drawbacks associated with use of 2D gel electrophoresis, and provides more accurate and sensitive results. This method utilizes the fluorescent property of Cy3 and Cy5 N-hydroxysuccinimidyl ester cyanines, which show different excitation fluorescent spectra at different wavelengths. Typically, two samples are labeled with fluorescent dyes Cy3 and Cy5, respectively, and an internal standard is labeled with Cy2. The three samples are mixed and analyzed on one gel, 124 which permits measurement of protein amount in each sample relative to the internal standard in which the amount of each protein is known. Software such as DeCyder can be used for the detection of spots, and for normalization and analysis of data, which can increase quantitative accuracy and speed. Gel spots can also be digested by trypsin, and analyzed by MALDI-ToF, which generates a peptide mass fingerprint, or LC-MS/MS, which can provide peptide sequence information.\n\nHigh resolution separation of intact proteins based on protein size is a unique characteristic of 2D-PAGE. This feature can also be used to identify proteins which are degraded under specific conditions such as apoptosis. In one such study, cell extracts were treated with and without the proteases granzyme B 125 and caspase 3 126 , then run on 2D PAGE to find differences. By taking advantage of the change of pI induced by various modifications such as phosphorylation, 2D-PAGE can also be applicable to study of PTMs. Phosphorylation primarily changes the pI of proteins which results in a shift in the mobility pattern in a horizontal direction on the gel. The modified form shows an extra spot, which does not migrate together with the principal spot, and modified peptides can be identified using MS. 2D gel-based proteomics is a mature technology that has been employed in proteomics for over 3 decades and is still useful to study bacterial proteomics with low complexity, 127 intact protein with post-translational modifications 128 and as a micropreparative tool, 129 among other things.\n\nThe development of LC-MS/MS technologies has led to a reduction in 2D gel-based separations, but 1D-SDS-PAGE remains a standard separation method for complex protein mixtures based on their molecular weight. 130 Separated complex protein mixtures are cut into 10-20 gel slices and each gel band is digested by in-gel trypsin method. 131 The methodology has been standardized as GeLCMS (gel-enhanced LC-MS) to represent the hybrid gel and LC-MS analysis. 132 Compared to gel-free methods, this method has some important advantages, including differentiating splice isoforms and degraded proteins and removal of low molecular weight impurities such as detergents and buffer components, which are detrimental for MS analysis. However, both sample loss to the gel and residual SDS, can limit sensitivity and comprehensiveness. The other, orthogonal separation from 2D gel electrophoresis, isoelectric focusing, has also been exploited for protein separation prior to LC-MS. An immobilized pH gradient strip in the Off-Gel\u2122 electrophoresis (OGE) system focuses proteins based on their pI, allowing for their recovery in the liquid-phase. 133 Improvements from protein fractionation by OGE and bottom-up proteomic analysis were demonstrated with a human plasma sample. 134 A comparative GeLCMS analysis with a solution-phase IEF separation identified 25% more proteins and improved reproducibility to 96%. 135 Free-flow electrophoresis followed by RPLC was used to fractionate proteins from a model cell line and human serum prior to MS/MS identification as peptides. [136] [137] Chromatofocusing 138 and size-exlusion chromatography (SEC) 139 have also been used prior to shotgun proteomic workflows to improve comprehensiveness. Combining solution IEF, RPLC, and 2DIGE, as an intact protein analysis system (IPAS), was used to quantitatively profile the human plasma proteome. 140 A similar methodology which followed solution IEF and RPLC, using the Proteome Lab\u2122 PF 2D platform, by LC-MS analysis fractionated and identified proteins from human plasma gel-free. 141 \n\nShotgun proteomics has become a widely used method for multiple reasons. One notable reason is the amenability of common analytical chromatography methods for separation of peptides prior to ESI-or MALDI-MS/MS. Since the initial demonstrations of online solidphase extraction, strong cation exchange fractionation, and nanoflow liquid chromatography for direct ESI with homemade columns, 8 numerous academic and commercial configurations have been reported which further automate and improve the process. As a sign of the wide-spread need and benefits, commercial supplies and comparable configurations are available from Agilent Technologies Inc., New Objective Inc., and Shotgun Proteomics Inc.\n\nThe two main ionization methods used for charging and transferring peptide into the gasphase in shotgun proteomics are nanoelectrospray (nESI) 142 and MALDI. 143 nESI has been generally coupled with RPLC separations and MALDI with gel-based separations. MALDI is most often performed by transferring proteins or peptides from a gel to a support or substrate, 144 but methodologies were developed to perform MALDI directly from 2D gels to simplify the process and improve reproducibility. [145] [146] There has also been significant cross-over of separation and ionization methods in both application and development of new ionization strategies. These include coupling HPLC 147 and CE 148 to MALDI in online 149 and offline [150] [151] peptide fractionation modes. Collection of peptides from HPLC onto MALDI plates allowed for exclusion of redundant peptides from replicate analyses. 152 Due to the higher tolerance to surfactants than ESI, LC-MALDI was more comprehensive and complementary to gel and standard LC-ESI methods. 153 Desorption ESI (DESI), where ESI can be used to vaporize deposited peptides from a substrate, has been described for bottomup proteomic analysis. [154] [155] Other similar methods which combine DESI and MALDI have also been demonstrated, [156] [157] including the capability to perform chemical reactions. 158 Laserspray ionization (LSI) has also produced ESI-like peptide spectra from a standard MALDI plate. 159 Capacitive charging of a number of substrates has been used to ionize peptides through electrostatic-spray ionization (ESTASI). 160 Peptides have even been vaporized and ionized from a solid-state small molecule matrix solely by introduction to vacuum, yielding ESI-like peptide charge states. 161 Similarly, new ESI-like ionization methods have either completed removed the electrical potential or changed the way it is applied to improve sensitivity and selectivity. Simple placement of the outlet of a HPLC column into the heated mass spectrometer inlet under vacuum, deemed solvent-assisted inlet ionization (SAII), vaporizes peptides with similar charge states to ESI and greater sensitivity. 162 SAII has shown to maintain chromatographic peak shape and is compatible with \u03bcL/min and nL/min flow rates. [163] [164] Through application of an AC voltage, inductive ESI can control the charge state of peptides. 165 Introduction of an inverted post-column makeup flow during gradient elution HPLC improved ESI signal stability throughout the separation. 166 Continued improvements to peptide ionization methods will surely aid in shotgun proteomics, likely through improved sensitivity and expansion of MS-compatible liquid-phase separations.\n\nPeptide chromatography and mass spectrometry are dramatically simpler both theoretically and experimentally than at the protein level, making methods to analyze proteins at the peptide level more straightforward. However, rigorous LC separation of peptides is critical for detection of peptides from a complex proteomic mixture for a number of reasons. Generally, in order for a peptide to be sampled for fragmentation its precursor intensity must be both above background noise and more abundant than other peptide ions measured simultaneously. Resolution of peptides of similar masses is essential in order to acquire distinct, non-mixed fragmentation spectra. This criterion is best met by separation in the liquid phase through chromatography since differences in charge and hydrophobicity can be exploited. Adequate chromatographic separation is also crucial for effective electrospray ionization (ESI). Although ESI is a powerful, relatively unbiased method for introducing peptides into the gas phase, it can easily be crippled by ionization suppression. Attempting to electrospray many analytes simultaneously, whether peptides or contaminants, results in ionization of only the most hydrophobic molecules. 167 This concept has resonated in the shotgun proteomics community over the years and has been reconfirmed recently in both untargeted and targeted peptide analyses. [168] [169] In fact, exploiting this concept by increasing the hydrophobicity of peptides through alkylation of primary amines has increased ionization efficiency and signal intensity. 170 Thus resolution of peptides prior to ESI-MS/MS is of utmost importance. The challenge of adequate separation of peptides from a complex mixture becomes particularly evident from an examination of a yeast proteome, which, with ~7000 gene products, is far less complex than a comparable human sample. A theoretical in silico digestion generated ca. 300,000 peptides. 171 This number of peptides is already nearly 10 times greater than the number that is commonly identified in a single comprehensive proteomic analysis. The most complex human samples, such as plasma, can have a concentration dynamic range as high as 12 orders of magnitude with potentially 25,000 gene products 55 and even model organisms like C. elegans and D. melanogaster are predicted to have nearly as many genes as humans. [172] [173] The first comprehensive proteomic analyses of model organisms using state-of-the-art proteomics technology, which exploited multidimensional separations of peptides, identified 2,388 (S. cerevisiae), [174] [175] 10,631 (C. elegans), 176 and 9,124 (D. melanogaster) 177 proteins. More recent analyses with both improved peptide separations and more sensitive mass spectrometers have boosted protein identification numbers for yeast above 4000 proteins. [178] [179] Early and more recent applications of mass spectrometry for proteomics used either gelbased or offline LC fractionation of peptides. Although many of these methodologies are still useful for targeted and global proteomic studies, the largest gains in sensitivity from peptide separations were initially demonstrated and still used today by coupling nanoelectrospray 142 to reverse-phase nanoflow liquid chromatography (nLC). A representative base peak chromatogram is shown in Figure 10a . Peptides were loaded directly onto a homemade nLC capillary column, separated based on hydrophobicity, and were directly electrosprayed from the capillary tip into the mass spectrometer. [180] [181] The sensitivity of this methodology, which avoids the use of auto samplers, was dramatically redemonstrated in the phosphoproteomic analysis of ~10,000 cells. 182 Employing proven chromatographic technological improvements has also benefited in shotgun proteomic analysis. Reducing the column inner diameter and eluent flow to low nanoliter per minute rates while increasing the column length has produced similar results to longer multidimensional separations through both increased peak capacity and ionization efficiency. 183 High temperature RPLC has proven essential for the separation and identification of hydrophobic peptides from membrane-embedded proteins. 184 Sub-zero RPLC reduced back-exchange and improved dynamic range in amide hydrogen/deuterium exchange experiments. 185 Cutting-edge separation technology has begun to further impact the capabilities of shotgun proteomics, including the use of ultrahigh pressure liquid chromatography (UPLC) developed by Jorgenson. 186 Reductions in chromatographic resin particle size, and thus peptide peak width, have increased peptide identification efficiency, sensitivity, and reproducibility. 187 A capillary column frit commonly used in proteomics was designed specifically for UPLC analysis. 188 A detailed study of synthetic peptides illustrated the capabilities of UPLC to separate peptide isomers and conformers. 189 Coupled with improvements to mass spectrometer speed, UPLC separation efficiency has facilitated identification of 78% of the validated yeast proteome with a single 4 hr separation dimension and six replicate runs 179 and over 1400 human proteins in less than a half hour. 190 Superficially porous HPLC particles have also been shown to improve separation efficiency, but have yet to be tested on complex peptide mixtures with MS/MS. [191] [192] [193] [194] [195] Monolithic columns have provided separation benefits without the backpressure restrictions from smaller particles. As a result, extremely long columns (2-4 m) running an ~8 hr separation facilitated the identification of 22,196/2,602 peptides/proteins from E. coli, 41,319/5,970 from HeLa cells, and an astounding 98,977/9,510 from human induced pluripotent stem cells. [196] [197] [198] The aforementioned peptide separations have relied almost exclusively on RPLC prior to ESI, but two alterative analytical separations provide different peptide retention mechanisms with ESI-compatible buffers. HILIC separates peptides based on their hydrophilic interactions with an ionic resin and has found most application in peptide fractionation and PTM analysis. 199 An organic to aqueous gradient, inverse to RPLC, generally inverts peptide retention order. HILIC-ESI-MS of peptides has been performed with packed 200 and monolithic 201 columns, but has yet to be exploited for shotgun proteomic analysis. ERLIC is a specific form of HILIC, using a weak anion exchange (WAX) resin. Unlike RPLC, peptides are retained under two separation modes. Early in the organic to aqueous gradient hydrophilic interactions dominate, as in HILIC and inversely to RPLC. However, as the aqueous content of the elution buffer is increased, basic peptides electrostatically repel the WAX resin while acidic peptides are retained until their hydrophilic interaction with the WAX resin is disrupted late in the gradient. These superimposed separation mechanisms with ERLIC distribute peptides over the gradient better than RPLC and outperform it based on peptide and protein identifications by higher confidence spectral matching of larger peptides. 202 Capillary electrophoresis has also reemerged as a complementary, more sensitive, and viable option in shotgun proteomics, largely due to improvements in electrospray interfaces. [203] [204] [205] [206] [207] [208] [209] Fractionation of peptides prior to nLC-ESI to improve comprehensiveness was initially performed online with SCX resin, 8, 10, 175, 210 minimizing sample losses from transfers intrinsic to offline fractionation and auto samplers. Addition of WAX resin with the SCX resin in a mixed-bed format exploited the Donnan effect and increased peptide recovery, reduced carryover between salt elutions, improved separation orthogonally, and led to identification of twice as many peptides and phosphopeptides in separate analyses. 211 The use of WAX alone with a pH-based elution also improved reproducibility and reduced carryover between fractions. 212 Other online systems have performed a RPLC separation at high pH prior to the low pH nLC-MS dimension to improve peak capacity in the first fractionation dimension. [213] [214] Offline fractionation has allowed for further optimizations, the use of MS-incompatible buffers, and the combination of separations that can't be directly interfaced. Offline fractionation of peptides by SCX with UV detection allowed for optimization of sample loading for each subsequent nLC-MS run. 215 Preparative electrophoretic methods that were first applied at the protein level, have also been used for fractionating peptides such as free-flow electrophoresis 216 and IPG strips in a traditional 217 and OGE setup. 134, 218 Many new fractionation methodologies have the benefit of identifying PTMs in a less biased manner than specific enrichment methods and may facilitate global co-identification and co-analysis of multiple relevant biological PTMs. In combination with Lys-N protease digestion, SCX fractionation has become possible to identify multiple PTMs simultaneously from complex mixtures including acetylated Nterminal peptides; singly phosphorylated peptides containing a single basic (Lys) residue; peptides containing a single basic (Lys) residue; and peptides containing more than one basic residue. 219 The use of zwitterionic (ZIC)-HILIC for prefractionation of peptides at median pH was found as a complementary alternative to SCX and at low pH, also a method to fractionate peptides into classes of PTMs with the more common proteases trypsin and Lys-C. 220 Continued work with ZIC-HILIC resins is improving sensitivity while maintaining comprehensiveness of analysis, identifying 20,000 peptides and 3,500 proteins from 1.5 \u03bcg of HeLa cell lysate. 221 ERLIC fractionation of peptides identified more proteins and peptides, particularly of basic and hydrophobic character, than SCX [222] [223] and this strategy facilitated simultaneous analysis of phosphorylation and glycosylation from rat kidney. 224 Inverting RPLC and ERLIC separation order has allowed for assessment of the extent of asparagine deamidation on peptides. 225 A similar separation mode, hydrophilic SAX, was also found to be highly orthogonal to RPLC. 226 Further combination of fractionation separations in three dimensional configurations has continued to improve comprehensiveness and sensitivity. [227] [228] [229] [230] The use of an online three-dimensional separation of peptides has allowed the identification of proteins present at approximately 50 copies per cell from analysis of the entire yeast proteome. 231 This sensitivity gain from an added dimension of fractionation correlated to an estimated detection limit of 65 amol. Further improvements to prefractionation and enrichment of post-translationally modified peptides will undoubtedly improve identification comprehensiveness and lead to new biological discoveries.\n\nIn recent years, peptide analysis has driven the technological advances of new mass spectrometers and techniques. In particular, multiple hybrid instruments have been developed with different mass analyzers, ion optics, and fragmentation sources. These combinations have improved the accuracy of peptide precursor and fragment ion mass measurements and created more informative and complementary peptide fragment ions through various fragmentation methods. Common mass analyzers that have proven useful for peptide analysis from complex mixtures are the LIT, Orbitrap, FT-ICR, quadrupole (Q), and ToF. Table 2 describes their commonly-achieved analytical metrics for proteomics. Since each analyzer isolates and measures peptides masses using different mechanisms, each mass spectrometer represents a balance between sensitivity, speed, and accuracy. Most current mass spectrometers used for proteomics employ a LIT, which allows for both isolation and fragmentation of peptide ions. Data-dependent acquisition allows for primarily unbiased sampling and identification of peptides within a sample, and is performed as follows. Peptide ions are trapped within the LIT and subsequently scanned by increasing the radiofrequency voltage applied to the trap. An initial precursor scan is performed to identify abundant peptide precursor ion m/z's. Sequential trapping and isolation of each individual abundant precursor ion is done by filling the trap and ejecting all but a population of ions within a mass window (~3 m/z) containing the peptide precursor m/z. The isolated ions are translationally excited prior to collisions. The collisions lead to conversion of translational energy to internal (vibrational) energy and then fragmentation. Fragment ions are scanned out to the mass analyzer and the process is repeated until abundant peptide precursor ions have been sampled. Often, a signal-to-noise threshold or maximum number of fragmentation scans is used to define how frequently the precursor ion and fragmentation scans are performed. 232 Benefits in sensitivity have been achieved through sampling lower abundance ions through data-independent acquisition of consecutive small (10-25 m/z) windows. [233] [234] [235] [236] The modification of the initial 3-D QIT to a 2-D LIT improved sampling speed 2-fold, [237] [238] and a dual-pressure 2-D LIT configuration further improved sampling speed and sensitivity. 239 Interfacing the 2-D LIT to FT-ICR 240 and, more recently, to the Orbitrap 241 improved the accuracy of peptide precursor measurements and the confidence in both identification and quantification of proteins and post-translational modifications. FT-ICR instruments still have the highest mass accuracy, but the Orbitrap is faster, more sensitive, and improving in resolution, particularly with its recent reduction in size. 242 The use of identified peptides, 243-247 external lock mass standards, 248 background ions, [249] [250] [251] and fragment ions 252 for online 253 and offline 254 mass calibration has further improved mass accuracy over the course of proteomic runs where drift can otherwise occur. Other routine and emerging options for performing data-dependent acquisition of peptides using hybrid instruments are the Q-ToF 255-257 and Q-Orbitrap. [258] [259] Schematic diagrams of the common mass spectrometers used for shotgun proteomics are illustrated in Figure 2 and Figure 3 . Representative MS data is shown in Figure 10a . Application of ion mobility configurations at the inlet of mass spectrometers has reduced background noise and improved sensitivity, [260] [261] increased dynamic range, [262] [263] improved proteome coverage, 264 and allowed for differential identification of isomeric peptides, [265] [266] phosphopeptides, [267] [268] and glycopeptides. 269 The use of ion mobility is beneficial since it provides a gas-phase separation of peptides and chemical noise. Separation is achieved through the differential mobility of ions based on charge, size, and conformation as they are passed through a carrier buffer gas.\n\nPeptide fragmentation methods with different fundamental mechanisms have been implemented on mass spectrometers used for shotgun proteomics which provide complementary peptide fragment ions, proteome coverage, and quantification accuracy. The instrumental configurations for fragmentation are also indicated in Figure 2 and Figure 3 .\n\nThe common fragmentation mechanisms employed are illustrated in Figure 4 . The most common and robust fragmentation method used for peptide analysis is CID/CAD (collisioninduced/activated dissociation). A representative CID MS/MS spectrum is show in Figure  10b . LIT instruments use resonant-excitation, creating only single fragmentation events as the ions fall out of the excitation frequency upon fragmentation. The most prevalent ions formed are b-and y-type which result from fragmentation at the peptide bond, leaving the positive charge on either the N-terminal or C-terminal fragment, respectively. Beam-type collisional activation entails passing ions through a quadruple, fragmenting ions until they reach their minimum potential energy, creating mostly y-type ions. Resonant-excitation has been primarily used on LITs and beam-type collisional activation on triple quadrupole (QQQ) instruments. Recently beam-type fragmentation, deemed higher energy C-trap dissociation or higher energy CID (HCD), 270 has also been demonstrated on LIT instruments with 271 and without 272 instrumental modifications and on hybrid instruments with dedicated collision cells. 273 Beam-type collision yields sequence-informative low mass peptide fragment ions and it's implementation on hybrid mass spectrometers has most dramatically improved peptide quantification using low mass isobaric tag reporter ions, [274] [275] further described in the \"Quantification\" section. Briefly, reporter ions are unique mass fragments ions from an amine-reactive, isotope-labeled chemical tag that can be used for relative quantification between protein samples. Prior to HCD, these low mass reporter ions were unreliably observed with CID and a pulsed Q dissociation (PQD) activation strategy improved reporter detection, but hampered protein identifications. [276] [277] CID of phosphopeptides often results in preferential loss of the phosphate moiety due to the low critical energy for this fragmentation process. 278 Further collisional activation of peptide fragment ions 279 after phosphate neutral loss in the same or a subsequent fragmentation scan creates more sequence-informative fragmentation ions. [280] [281] [282] HCD fragmentation is an efficient alternative for phosphoproteomic studies, 283 yet a comparative study illustrated that the greater acquisition speed of CID provided larger data sets. 284 Like CID, electron capture dissociation (ECD) 285 and electron transfer dissociation (ETD) 286 induce random fragmentation along the peptide backbone, albeit from gas-phase reactions with either thermal electrons or fluoranthene, respectively, creating mostly c-and z-type ions as shown in Figure 4 . The benefit of ECD was initially demonstrated for localization of labile \u03b3-CO 2 and SO 3 modifications that were otherwise ejected prior to peptide backbone fragmentation by CID. 287 Early bottom-up proteomics studies with ECD-FTICR-MS automated acquisition of fragmentation 288 and found that larger peptides 289 of higher charge state 290 were more efficiently fragmented and identified than with CID. Sequential CID and ECD in a large-scale phosphoproteomics experiment illustrated CID is better for phosphopeptide identification, ECD is better for phosphorylation localization, and together they provide complementary information and high confidence for infrequently identified phosphopeptides. 291 ECD with FTICR-MS presented great potential for bottom-up proteomics, but was not easily compatible with the commonly used LIT since the thermal electrons quickly lose their energy and cannot be trapped. The use of a focused electron beam has been proposed as a solution, 292 but this problem otherwise spawned ETD, where a LIT-trappable anion is used as a one-electron donor to induce fragmentation by the same non-ergodic pathway as ECD. 286 An optimization study using four reagents illustrated ETD fragmentation can be as fast or faster than CID depending on peptide charge state; azulene was the best reagent due to its higher reactivity, fewer inefficient proton-transfer reactions, and low fowling of ion optic elements from a higher vapor pressure. 293 One of the notable advantages of ETD is the retention of phosphorylation moieties on fragment ions, a shortcoming of CID methods. 294 Exploiting this characteristic of ETD, a comparison of phosphoproteomic results using CID and ETD 295 indicated phosphate rearrangement during CID fragmentation was much less prevalent than anticipated from a targeted study of a small number of synthesized phosphopeptides. 296 On the downside, the efficiency of ETD is charge-state dependent, thus diminishing its success for peptides in low charge states. When coupled with Lys-N for proteolytic digestion, ETD fragmentation has been used to generate straightforward peptide sequence ladders, 297 which is useful in de novo sequencing as discussed in the \"Bioinformatics\" section. Integration of ETD with Orbitrap mass spectrometers [298] [299] and application to large scale proteomics studies has demonstrated complementary identifications of peptides, proteins, and proteomes to CID fragmentation. ETD with supplementary CID fragmentation (ETcaD) of doubly protonated peptide precursor radicals, [M+2H] 2+\u2022 , was developed to minimize non-dissociative electron transfer (ETnoD) processes. 300 This concept was also reported concurrently along with the chargereduction of larger peptides with ETD prior to CID (CRCID) for identification of posttranslational modifications. 301 From these characterizations, a decision tree-driven approach was demonstrated to select the appropriate fragmentation method based on peptide charge state and m/z and improve proteome coverage 302 , and has since been implemented with other fragmentation methods with further improvements. [303] [304] [305] Exploiting the anion fragmentation capabilities of ETD facilitated identification of the previously under-sampled acidic proteome. 306 The combination of ETD with infrared (IR)-activated ions outperformed both ETD and CID for higher peptide charge states. 307 The key improvements were reduction of the ETnoD process with preactivation and the creation of primarily odd electron z \u2022 -type and even electron c-type product ions. Implementation of IR fragmentation alone 308 has also shown improved reporter-based relative quantification of peptides. 309 Ultimately, these improvements to fragmentation and identification of larger peptides may make a dramatic contribution to middle-down proteomics methodologies.\n\nThe eukaryotic proteome is much more diverse than the corresponding genome due to two stages of regulations: post-transcription and post-translation. Post-transcriptional regulation generates multiple mRNA splicing patterns, which are subsequently translated into different proteins. The proteins can be further post-translationally modified by covalently adding some chemical units or changing the structures of the amino acids themself. Therefore, the mapping of PTMs is an important dimension to help describe the whole proteome.\n\nPTMs play key roles in almost all biological processes. Hundreds of PTMs have been found to occur on different amino acids. The typical approach of detecting PTMs using mass spectrometry requires enrichment techniques, due to relatively low PTM levels. PTMs are measured by mass shifts caused by the modification ( Table 3 ). The modified residue site can be further interpreted by its site-specific fragments. In this review, we will focus on the most biologically relevant PTMs, including phosphorylation, ubiquitination and glycosylation.\n\nAddition of a phosphate group to a protein can influence many properties of the protein, including protein folding, activity, interaction with other proteins, and localization or degradation; thus, phosphorylation plays essential roles in regulation of nearly all biological phenomena, including proliferation, differentiation, apoptosis, and cellular communication. 310, 311 Defects in regulation of reversible phosphorylation controlled by protein kinases/phosphatases can be the cause of various diseases, including cancer, diabetes, chronic inflammatory diseases, and neurodegenerative diseases.\n\nIn order to understand signaling networks in normal and pathogenic mechanisms in various diseases, development of an analytical method for identification of phosphorylated proteins and phosphorylation sites is essential. Phosphorylation is often a sub-stoichiometric process; at a given time point, not all copies of a given protein are present in a phosphorylated state. Therefore, highly sensitive methods for isolation, detection, and quantification of low abundant phosphorylation sites are required. In the past, phosphorylation analysis for identification and localization of the modified amino acid was conducted primarily by radiolabeling 312 with 32 P combined with capillary electrophoresis, amino acid analysis, or Edman radiosequencing. 313 Recently, with vast and ongoing improvements in sample preparation, separation, enrichment, instrumentation, and data analysis, the field of phosphoproteomics has shown substantial expansion, which has resulted in more extensive and confident identification and quantification of phosphorylation sites. In fact, use of proteomic approaches that employ MS can lead to identification and quantification of thousands of phosphorylation sites from a single sample in the femtomole or even attomole range. 314, 315, 316 Current methods for study of phosphorylation using LC-MS/MS are reviewed below and illustrated in Figure 5 .\n\nChromatography (IMAC) with metal ions including Fe(III), Ga(III), Al(III), and Zr(III), has been widely used for enrichment of phosphopeptides. 317,318-319 A number of factors, including binding, washing, and elution affect the efficiency of the IMAC procedure. 320 In order to eliminate the binding of non-phosphopeptides in IMAC, acidic conditions for loading and washing have been used; phosphopeptides can be then eluted using alkaline conditions. 321 Esterification of peptide carboxyl groups resulted in improved specificity of phosphopeptide enrichment 322 using IMAC and a method using Zr or Ti, which prevents binding of acidic peptides, has been developed. 323 An alternative to IMAC enrichment of phosphopeptides uses TiO 2 , which has shown a higher capacity and better selectivity for phosphorylated peptides. 324 TiO 2 precolumns, TiO 2 -based HPLC chips, TiO 2 tips, 324, 325 and other metal oxide enrichment methods using ZrO 2 326 or Ga 2 O 3 , 327 have been used for purification of phosphopeptides. To improve binding selectivity of phosphopeptides on TiO 2 , competitive binders, such as 2,5dihydroxybenzoic acid (DHB) and phthalic acid, 325, 328 were used in the buffers during enrichment. To increase recovery of phosphopeptides, multiple rounds of consecutive incubation using fewer TiO 2 beads than the optimum ratio have been suggested. 329 In addition, various methods for elution of trapped phosphopeptides, such as ammonium bicarbonate with 50mM ammonium phosphate (pH 10.5), ammonia solution (pH 10.5-11), or step gradients from pH 8.5 (100mM triethylammonium bicarbonate) to pH 11.5 (3% ammonium hydroxide) have been used. 330, 331 A method combining IMAC and TiO 2 (called SIMAC) 332 for simultaneous detection of mono-phosphorylated and multi-phosphorylated peptides has been introduced. Mono-phosphorylated peptides are eluted by acidic buffers from IMAC and multi-phosphorylated peptides by basic elution, resulting in increased sensitivity of detection and reduced sample complexity. Recently, polymer-based metal ion affinity capture (PolyMAC) using polyamidoamine dendrimers multifunctionalized with titanium ions and aldehyde groups has been introduced, showing high selectivity, fast chelation times, and high phosphopeptide recovery compared with current strategies based on solid phase nanoparticles. 333 Fractionation of protein samples is still required even if methods employing IMAC and TiO 2 are used for enrichment of phosphopeptides. Several chromatographic methods, including SCX, 315 SAX, 334 HILIC, 335 and ERLIC 336 have been used in an effort to increase the efficient identification of phosphorylation sites by prefractionation. The combination of SCX fractionation and TiO 2 enrichment is a popular method. Tryptic peptides at pH 2.7 usually carry a net charge of +2 (N-terminal amino group and C-terminal arginine or lysine side chain); however, the presence of a phosphate group decreases the net charge state by one. Using SCX fractionation at pH 2.7, phosphopeptides can be separated from nonphosphorylated peptides 337 and analysis of these fractions using LC-MS/MS resulted in identification of more than 2,000 phosphopeptides from the nuclear fraction of HeLa cell. 315 An acidic, then highly acidic double SCX fractionation strategy separated and selected for basic phosphopeptides. 338 pI-difference also allows separation of methylated phosphopeptides from the methylated nonphosphopeptides by in-solution isoelectric focusing 339 and this concept was also applied for IPG strips pH 3-10 as used in the first dimension of 2-DE. 340 When HILIC, is used, non-phosphorylated peptides are eluted in the early fractions followed by elution of peptides with single and multiple phosphorylated sites. The presence of the phosphate group increases the peptide's hydrophilicity, and thus retention time. 341 Exploiting a different separation mechanism with SAX, acidic phosphorylated phosphopeptides can be depleted for increased identification of basophilic kinase substrates. 342 An excess of Ca 2+ can be used for precipitation of phosphopeptides. [343] [344] Calcium phosphorylation precipitation method for identification of phosphoproteome was combined with a subsequent IMAC method in rice embryonic cells, resulting in identification of 242 phosphopeptides representing 125 phosphoproteins. 345 Ba 2+ was also used for precipitation of phosphopeptides and this method combined with MudPIT identified 1,037 phosphopeptides from 250 ug of HeLa cells nuclear extract. 344 Furthermore, coverage of the phosphoproteome was extended with three Ba 2+ ions concentrations. Immunoprecipitation based on anti-phosphotyrosine antibodies can be also used for enrichment of phosphotyrosine proteins/peptides. 346, 347 In general, antibodies for phosphoserine and phosphothreonine are less specific than anti-phosphotyrosine antibodies and are not frequently used for enrichment. In addition, the recently repurposed hydroxyapatite (HAP) chromatography resin efficiently enriched phosphopeptides based on the higher affinity of multi-phosphorylated peptides towards HAP surfaces. 348 HAP has allowed for efficient analysis of mass-limited complex samples with single-step microcolumn enrichment coupled to MudPIT. 349\n\nto the electronegativity of the phosphoryl group, as well as the labile nature of the phosphoester bond, phosphopeptides are less efficiently ionized and fragmented in comparison to unmodified peptides. Therefore, MS analysis of phosphopeptides is more difficult than it is for non-phosphorylated peptides. Results of MS/MS obtained from phosphopeptide analysis under general CID conditions demonstrated loss of labile metaphosphoric acid or phosphoric acid. 350 To improve phosphopeptide identification, selection and analysis of ions with neutral loss can be performed with additional CID for generation of an MS3 spectrum. 351 In addition, treatment with phosphatase can increase confidence in phosphopeptide identification and localization of phosphorylation sites through parallel MS/MS analyses of two samples before and after treatment with phosphatase. [352] [353] Alternatively, use of electron capture dissociation (ECD) 354 and electron transfer dissociation (ETD) 286 can induce backbone fragmentation for generation of c-and z-type ions which retain an intact form of PTM such as a phosphorylation group. ETD is compatible with LTQ-Orbitrap, ion trap, and LTQ-FT-ICR mass spectrometers, and is suitable for LC-MS/MS analysis of complex phosphopeptide mixtures. 355 Because the two fragmentation modes are complementary, combination of CID and ETD/ECD for enhancement of the number of identified phosphopeptides has been suggested. 356 \n\nsites in phosphopeptides, the identification of the amino acid sequence and mapping of phosphorylation sites must be determined accurately by hand or analysis software. In particular, if a phosphopeptide contains consecutive amino acids of serine, threonine, or tyrosine, precise MS/MS spectra generated by cleavage both N-terminal and C-terminal of the identified phosphorylation site are required. Various algorithms, such as SEQUEST and Mascot, can be used for identification of phosphorylation sites; however, validation of the assigned phosphorylation sites should be performed manually. Ambiguity in site assignment can occur because fragment ions don't adequately define the site or a peptide that is phosphorylated at different sites within the same sequence could co-elute and co-fragment providing evidence for both sites within the spectrum. Various software programs, such as Debunker 357 and Ascore, 337 have been developed to assist in evaluation and validation of phosphopeptides and phosphorylation site assignments, respectively. In addition, more specialized database resources, such as Phospho.ELM, 358 PHOSIDA, 359 Scansite, 360 KinasePhos, 361 and PPSP 362 can also provide tools for prediction and annotation which aid in identification of potential kinases associated with phosphorylation sites.\n\nUbiquitin is a highly conserved 76 amino acid small protein, which exists in all eukaryotic cells. Ubiquitination is reversible, ATP-dependent, and catalyzed by a ubiquitin E1 (activating) -E2 (conjugating) -E3 (ligating) cascade, [363] [364] [365] resulting in a covalent isopeptide bonds between a glycine residue at the carboxy-terminal of ubiquitin and the \u03b5side chain of a lysine residue within a substrate protein. Ubiquitination can produce either monoubiquitinated or polyubiquitinated proteins. The latter is formed when one of the seven lysine residues of ubiquitin is linked to the C-terminal glycine of another ubiquitin. The way the ubiquitin molecules are linked plays an important role in the function of the resulting modified protein. [366] [367] The most well documented function of ubquitination is its role in mediating protein degradation. Moreover, ubiquitin and many other ubiquitin-like proteins (UBLs) are involved in various biological processes, including but not limited to cell meiosis, autophagy, DNA repair, immune response and apoptosis. [368] [369] [370] The traditional ubiquintination assay, which is normally based on affinity interaction, is incapable of detecting individual ubiquitinated proteins and sites in a high throughput mode. Current mass spectrometry-based proteomic technologies have greatly improved detection and characterization of ubiquitination due to their high sensitivity and mass accuracy. Like many other PTMs detected by MS, ubiquitination is characterized by a signature mass shift. The carboxy-terminal of a ubiquitin has an amino-acid sequence of -R 72 L 73 R 74 G 75 G 76 , which is normally cleaved after the R 74 residue during typsin digestion. The carboxy end (G 76 ) of ubiquitin is covalently attached to a lysine on the substrate and leads to a missed cleavage on the substrate during typsin digest. As a result, the signature ubiquitinated peptide contains additional G 75 -G 76 residues from ubiquitin, which results in a mass shift of 114.043 Da (G-G) as well as a missed K cleavage at the ubiquitination site.\n\nDetection of ubiquitination by mass spectrometry may generate false positives, which should be carefully examined. Although the mass shift of 114.043 Da can be measured precisely and accurately in mass spec analysis, there are other events which cause a mass increase of 114 Da, (some with exactly the same chemical elemental composition as diglycine), making them indistinguishable from ubiquitination. For instance, the residue asparagine (Asn) has a monoisotopic mass of 114.043. When a peptide contains a K-N motif, a missed cleavage between these two residues will result in a ubiquitination-like spectrum, and the database search engine may not be able to distinguish between di-glycine and asparagine. Another potential issue comes from the iodoacetamide (IAM) used in cysteine (Cys) alkylation prior to protein digestion. Carbamidomethylation leads to a mass increase of 57.021 Da on Cys and sometimes lysine. 371 Further, it has also been reported that IAM can introduce a di-acetamidoacetamide covalent adduct to lysine, resulting in the identical chemical composition as diglycine. The identical masses introduce artifacts into the database search algorithms, resulting in false positive ubiquitination site. 372 To avoid artifacts, an alternative alkylating reagent 372 or adjusted incubation temperature 373 can be used to reduce over-alkylation. False ubiquitination identification can also be caused by the isotopologue peaks of several amino acids with mass close to 114 Da. For instance, leucine and isoleucine both have a monoisotopic mass of 113.084 Da and their m+1 heavy isotopic mass is 114 Da. If the 114 isotope containing peak is considered as the peptide precursor, it may result in a false ubiquitination identification. In this case, a high mass accuracy threshold and either manual or software validation of the monoisotopic mass can be employed to ensure correct assignment.\n\nAn enrichment or purification step is normally required prior to mass spectrometry analysis in order to get deeper ubiquitination coverage, since its overall abundance is low in biological samples. Several affinity approaches are widely used to enrich for ubiquitinated proteins. Ubiquitin-substrate conjugates can be purified by either anti-ubiquitin antibodies 374 or His-tagged ubiquitin. 375 High sensitivity and specificity of antibodies are critical for the success of an antibody approach. The His-tagged ubiquitin method is thought to be of higher specificity, because the procedure can be done under protein denaturing conditions. However, a His-tagged approach becomes challenging for some biological samples, such as animal tissues and clinical samples. Because ubiquitination occurs at different sites and at different levels among individual molecules, using an antibody to pull down whole proteins may generate a significant number of unmodified peptides after protein digestion. Recently, a new antibody has been designed to address this issue targeting the diglycine motif after protein digestion by trypsin. 376 Polyubiquitinated proteins can also be enriched by Ub binding domains (UBDs), which have high affinity for poly Ub chains. 377 There are many other UBLs which covalently conjugate to protein substrates and generate diverse modifications. These modifications can be determined by detection of a UBL remnant-containing peptides after trypsin digestion, but there are some challenges. First of all, the mature form of some ubiquitin-like modifiers (e.g. RUB1, NEDD8 and ISG15) have the same C-terminal amino acid sequence as ubiquitin (-RGG), which results in an indistinguishable di-glycine signature adduct. To determine the different modifiers, a prefractionation step such as immunoaffinity purification or epitope tagged Ub or UBLs can be used. [378] [379] However, many other UBLs (SUMO, URM, and HUB1) result in a relatively long amino acid sequence remnant after trypsin cleavage. Such branched peptides generate much more complicated MS/MS spectra after CID fragmentation, and interpretation is difficult. To address this limitation, C-terminal SUMO mutants with different protease digestion specificities have been employed, enabling a rapid and efficient identification of SUMO sites. 380 The potential of this mutation approach is that it can be easily adapted to determining the sites of conjugation for other UBL proteins (not only SUMO) from a diverse range of organisms.\n\nMass spectrometry can also be used to determine the linkage sites in polyubiquitin chains. Ubiquitin has seven lysine residues, each of which can be linked to the C-terminal glycine of another ubiquitin, forming polyubiquitin. The biological consequence of polyubiquitin can be highly dependent on which lysine is modified by another ubiquitin molecule. For instance, K48-linkage primarily targets proteins for proteasomal degradation, whereas K63linkage appears to play a role in DNA repair, subcellular localization, and protein-protein interactions. Antibodies against these linkage structures have been developed. 367 Alternatively, the tryptic ubiquitin peptides derived from different linkage types have unique structures and masses, and therefore can be determined by mass spectrometry. 381-382\n\nGlycosylation is thought to be one of the most common protein PTMs. A protein is glycosylated by a covalent link of the glycan to either an amide or alcohol in the protein. An N-linked glycan is attached to the amide group of asparagine residue in an amino acid sequence motif of Asn-X-Ser/Thr, where X represents any amino acid other than proline. 383 An O-linked glycosylation links the glycan to the hydroxyl group of serine or threonine.\n\nMany studies have revealed that glycosylation, especially on membrane, secreted, and body fluid proteins, greatly influences many biological functions, including protein folding, protein turnover, and immunity.\n\nGlycan analysis, or glycomics, has traditionally aimed to define only the glycan modification in a glycoprotein. In contrast, glycoproteomics refers to the full characterization of glyco-proteins and glyco-peptides. Glycomics studies screen for glycan structures, but lose the information on localization sites and from what proteins they are derived. This information is lost because analysis of glycans normally requires the release of glycan moieties from the glycosylated proteins. N-linked glycosylation is generally cleaved by an amidase, such as peptide N-glycosidase F (PNGase F), which releases broad spectrum sugars. However, such a universal enzyme is not available for O-linked glycans because they are very heterogeneous, and have many forms of linkage core structures. Therefore Oglycosylation is typically cleaved by chemical methods, such as hydrazinolysis 384 and alkaline \u03b2-elimination. 385 The released glycan can be subsequently analyzed by different methods. Typically, the glycan, either derivatized or underivatized, is determined by mass spectrometry or nuclear magnetic resonance (NMR).\n\nGlycosylated peptides and proteins are typically present in low abundance in complex biological samples, and an enrichment step is normally performed in order to improve sensitivity of glycosylation detection. For this purpose, a number of enrichment approaches have been developed, including lectin affinity, [386] [387] hydrazide coupling, 388 HILIC, [389] [390] and boronic acid affinity. [391] [392] Among these strategies, lectin-affinity is the most widely used due to its high specificity. Lectins are carbohydrate binding proteins, which can specifically attach to sugar moieties. There are a number of well characterized lectins that may be used for enrichment. For instance, Concanavalin A (ConA) binds to mannose glycan whereas wheat germ agglutinin (WGA) preferentially recognizes N-acetylglucosamine. Ulex europaeus agglutinin (UEA) and aleuria aurantia lectin (AAL) are specific fucose binding lectins. N-acetylneuraminic acid can be enriched by maackia amurensis leukoagglutinin (MAL) and hemoagglutinin (MAH). Combinations of multiple lectin forms have been used to achieve higher glycosylation coverage. Another frequently used enrichment method uses hydrazide chemistry, in which the carbohydrate is oxidized to a di-aldehyde, which is then covalently coupled to hydrazide bead.\n\nThe obvious drawback of glycan analysis is the loss of the information about which protein and residue site glycosylation occurs. Mass spectrometry-based glycoproteomic strategies are able to address this issue, and tend to be high throughput and accurate methods in this application. There are two different ways to analyze glycosylated peptides using mass spectrometry. The first, like most other PTM detection methods using MS, is to measure the intact glyco-peptides with glycan; the amino acid sequence and glycosylation site can be determined by the spectrum interpretation. Obviously, this method is ideal, since both the glycan and peptides are measured simultaneously. However, in practice this method has had limited success on large scale analysis, due to the fact that glycan heterogeneity makes spectral interpretation difficult for glycosylated peptides, and the sugar group makes peptide fragmentation challenging. In addition to conventional CID method for peptide fragmentation, some new ion dissociation methods, such as infrared multiphoton dissociation (IRMPD), 393 electon-capture dissociation (ECD) 394 and electron-transfer disassociation (ETD), 395 have been introduced to generate more fragment ions derived from peptide backbone with no loss of the glycan moiety. A full characterization of both glycopeptide and glycan can be accomplished by using two complementary dissociation strategies. First, CID fragmentation usually cleaves the glycopeptide at glycosidic bonds, providing information predominantly on the glycan structures. Next, ETD fragmentation can be applied, which generates more peptide backbone fragments for peptide sequence identification. The other strategy is to remove the glycan first by reacting with amidase. Deglycosylated peptides are then subjected to a typical shotgun proteomics analysis. In contrast, this method only identifies which peptides were glycosylated. For this strategy, PNGase F cleaves N-linked glycans from glycoproteins, deaminating asparagine to aspartic acid, resulting in a 1 Da mass increase. If this deamination happens in an 18 O water environment, the heavy oxygen leads to an additional mass shift of 2 Da. As a result, a 3 Da mass increase on asparagine can be used for glycosylation site determination. 396 As the Nlinked glycosylation contains the motif sequence of Asn-X-Ser/Thr, a targeted database which only comprises motif containing sequences can increase the sensitivity of glycopeptide identification and reduce the false discovery rate. 397 \n\n3.4.1 Acetylation-Acetylation is a modification that mainly occurs on protein N-terminal or lysine residue. The N-terminal acetylation is a co-translational modification, and the later one is a post-translational modification. The N-terminal residue of a nascent protein, resulting from genetic initiation codon of 'AUG', is often methionine, which can be acetylated. Frequently, the N-terminal methionine is also be removed by methionine amino peptidases, thereafter the remaining N-terminal residue is revealed and acetylated by N-aacetyl transferases (NATs). N-terminal acetylation is a very common modification in eukaryotes, and up to 80% of human proteins have been reported to be acetylated. [398] [399] The second type of acetylation is introduced as an acetyl group to the 3-amino group of lysine residues. The lysine acetylation is a reversible process which is catalyzed by acetyltransferases and deacetylases, respectively.\n\nAcetylation tightly regulates diverse protein functions. The earliest and most well-known study of acetylation was focused on histones, which demonstrated a significant correlation between histone acetylation and gene expression. 400 Thereafter many other biological significances have been discovered to be related to acetylation, which include apoptosis, 401 cellular metabolism, 402 protein stability, 398 and neurodegenerative disorders, 403 among others. Moreover, it has been implied greatly that acetylation is cooperative with many other important PTMs, such as phosphorylation, methylation, ubiquitination, sumoylation. 404 The traditional detection of acetylation involves radioactive labeling and acetyl-lysine antibody. Both techniques are able to measure the presence of acetylation, but incapable of localizing the acetylation site. With MS, the acetylation sites can be captured by its signature mass shift (42 Da) , and the modified site can be interpreted from MS/MS as well. MS-based proteomics has largely extended acetylation from histone to non-histone targets. Choudhary et al. 405 has identified 3,600 lysine acetylation sites on 1,750 protein, implying a global occurrence of lysine acetylation. Lundby et al. 406 further enlarged the acetylation scale to 15,474 modification sites on 4,541 proteins from 16 rat tissues, and discovered that the sequence motifs for lysine acetylation varied between different cellular components.\n\nSimilarly to ubiquitination, the acetylation on lysine residues normally results in a missed cleavage site after trypsin digestion, which should be considered carefully in protein database search. Acetylation should be also distinguished from trimethylation cautiously, as both modification lead to quite closed mass shifts (42.0106 vs. 42.0469 Da). High mass accuracy data enables us to address this issue. Compared to lysine acetylation, N-terminal acetylation has not been investigated globally, mainly due to its high diversity, and the lack of specific enrichment method. Furthermore, the mature proteins are usually N-terminally processed, and the initial methionine residue can be removed. Therefore consideration of non-tryptic peptides would be essential to finding N-terminal peptides in a database search.\n\nmethylation is another common modification, in which a methyltransferases catalyze the addition of methyl groups to carbon, nitrogen, sulfur, and oxygen atoms of several amino acids, of which the arginine and lysine methylations are most widely studied. Similarly to histone acetylation, histone methylation is another most important PTM which plays a crucial role in regulation of chromatin structure and transcription. 407 Methylation occurs to varied extents, which result in mono-, di-, and trimethylations. Therefore, the proteomic database search should take all the possibilities into consideration.\n\nWith mass spectrometry, Ong et al. employed a modified SILAC method, in which the 13 CD 4 -methionine was metabolically converted to 13 CD 4 -S-adenosyl methionine, and the later one was then served as the solo methyl donor. The obvious advantage of this method is its increased confidence of methylation identification because the heavy methylated peptide and its light counterpart peptide have a signature mass difference. 408 In Saccharomyces cerevisiae, 83 lysine and arginine methylation sites and their specific motifs were identified. 409 In another study, Vermeulen et al. identified the specific protein binders to trimethyl-lysine modifications on histones. 410 A less frequently studied methylation on isoaspartyl residues was recently found on p53 using mass spectrometry and was correlated to p53 degradation. 411\n\nThe proteins can be modified through redox reactions, and proteomic studies focusing on these modifications are termed as redox proteomics. Redox proteomics has been recently comprehensively reviewed, [412] [413] therefore this review will only briefly cover this field. Among all amino acids, the most oxidation susceptible residue is cysteine as it contains active thiol. The thiol of cysteine can be oxidized to a variety of forms, including disulfide bond between two cysteine molecules from either different proteins or within the same protein, protein sulphenic acid (PSOH), sulphinic acid (PSO 2 H), sulphonic acid (PSO 3 H), S-glutathionylation, and S-nitrosylation.\n\nLike many other PTM analyses, the low abundance of cysteine modifications makes the detection challenging for complex samples. In addition, some of the redox modifications are quite labile, therefore are not directly compatible with sample preparation and MS analysis. Some cysteine modifications caused by small thiol molecules, such as glutathione and cysteine, are more readily to be detected, which have mass shifts of 305 Da and 119 Da compared to their unmodified counterparts, respectively. These mass signatures can be measured and the modification site can be localized as well in MS analysis. However, for disulfide bond linked peptides, the detection can be more complicated. The first method is to measure disulfide bond linked peptides by successive usages of two different alkylating reagents with different molecular mass. For instant, iodoacetamide can be used to initially block the free thiols, which lead to a mass shift of 57 Da. Subsequently the disulfide bonds are reduced, and the newly opened thiols are further alkylated with N-ethylmaleimide, which results in a mass increase of 125 Da. The different mass shifts can be used to determine which cysteine residues were previously free or blocked. The limits of this method are that it is not able to distinguish between different disulfide types, and there is no ways to know which two cysteine residues are linked. Alternatively, the disulfide bond linked peptides can be analyzed directly by MS. In this case, more effort is required for data interpretation as the fragment ions are derived from multiple peptides, which can be either inter-protein or intra-protein.\n\nProtein S-nitrosylation is a labile reversible modification, in which the thiols of cysteine react with nitric oxide, forming the S-nitrosothiol. The S-nitrosylation has been reported to regulate several diseases, including neurodegenerative diseases, 414 diabetes, 415 cancer, 416 and cardiovascular diseases. 417 Because of the labile nature of the S-nitrosylation, the direct analysis of it with MS is normally less successful. Alternatively, a biotin switch strategy 418 was introduced to measure the nitrosothiols indirectly. In a biotin switch experiment, the free thiols of cysteine residues are first specifically blocked by methyl methanethiosulfonate (MMTS). Next the S-nitrosothiols are reduced by ascorbate, forming thiol, which reacts with a sulfhydryl-specific biotinylating reagent, N-[6-(biotinamido)hexyl]-3\u2032-(2\u2032-pyridyldithio) propionamide (biotin-HPDP). The S-biotinylated proteins or peptide can be further enriched, and subjected to shotgun proteomic analysis. Similarly to biotin method, enrichment of Snitrosothiols (SNOs), using resin-assisted capture (SNO-RAC) was introduced, 419 providing a more efficient solution.\n\nWith advances in sample preparation, protein/peptide fractionation, sensitivity and accuracy in modern mass spectrometry, the proteome map of a certain organisms can now be routinely obtained in reasonable depth using shotgun methods. [176] [177] [178] 420 Two recent studies have been able to characterize more than 10,000 proteins in samples from cultured cell lines. [421] [422] Although proteomics was largely aimed at qualitative analysis early on (i.e. generating a protein list from a given organism), it has become apparent that the protein list itself is insufficient for addressing many biological questions. Abundance changes of proteins are principally a reflection of biological processes or disease states. Altered protein levels can be clues for possible drug targets and also potential clinical biomarkers for disease diagnosis, even at an early clinical phase. As a result, new methods for quantitative measurements on both protein expression and PTMs have been developed and have become an integral part of current proteomic studies.\n\nThe classic proteomic platform, 2-DE, was the first tool used for proteome quantification. Quantification is performed by comparing the staining densities of proteins on two or more gels, providing a measure of relative quantification. However, 2-DE has its limitations. First of all, the 2-DE gel has a limited resolution for large number of proteins which comprise the whole proteome. The co-appearance of protein spots makes accurate quantification impossible. The incompatibility of 2-DE with hydrophobic proteins means it cannot be easily used for membrane proteins. Additionally, 2-DE is incapable of analyzing low abundant proteins in a high dynamic range sample such as plasma, whose dynamic range of protein expression can vary by up to 12 orders of magnitude. 423 2-DE-based quantification detects only extreme differences and inaccurately estimates quantity changes. Furthermore, 2-DE is a labor and time consuming strategy that allows only individual gel spots to be identified one at a time.\n\nGiven the limitations of 2-DE-based methods for quantification, several strategies have emerged to quantify the proteome based on the mass spectrometry data. The current MSbased quantitative approaches are shown in Figure 6 . Since 2-DE quantification has largely been replaced by MS-based methods, the following discussion will cover only the LC-MSbased quantitative strategies. MS-based quantitative data are obtained by either stable isotope labeling or label-free approaches. The label-free strategy measures samples individually, comparing the MS ion intensity of peptides [424] [425] [426] [427] [428] or using the number of acquired spectra 175,429-430 matching a peptide/protein as an indicator for their respective amounts in a given sample. The isotope labeling approach allows the mixing of multiple samples at different experimental stages. The absolute or relative protein abundance can be obtained by measuring the intensities of different isotope coded peaks which are distinguished by mass spectrometry (Table 4 ). Multiplexing quantification not only makes comparison more straightforward, but also reduces valuable instrument time. There are two methods that are used to derive quantitative information from mass spectrometry data: one is to calculate peptide precursor ion abundance in the MS1 scan; alternatively, the isotope coded reporter ions (which reflect peptide quantity) can be detached from the peptide by fragmentation and measured in the MS2 scan.\n\nInitial MS-based quantification methods relied on chemical labeling to add isotope-coded reagents to reactive groups on the side chains of amino acids or to the peptide termini. The first chemical labeling methods used for mass spectrometry-based quantification made use of the reaction between the thiol side chain of cysteine and isotope-coded tags in a method called ICAT (isotope-coded affinity tag). [431] [432] The ICAT reagent consists of three different elements: a biotin affinity tag, a thiol specific reactive group, and a linker which contains either light or heavy isotopes. In an ICAT experiment, cysteine residues are selectively derivatized with an ICAT reagent containing either eight 1 H or eight 2 H atoms, and the protein mixture is then subjected to avidin affinity chromatography to purify ICAT coded proteins. Thereafter, proteins are digested with trypsin and the peptide mixture is analyzed by LC-MS. Because cysteine is not found in every peptide, the ICAT technique can significantly reduce the complexity of the peptide mixture, thus simplifying analysis of complex samples. On the other hand, ICAT obviously eliminates all non-cysteine-containing peptides and therefore is not suitable for comprehensive large-scale quantification. Furthermore, the deuterium tag results in a retention time shift between light and heavy peptides in reversed-phase chromatography, which complicates subsequent data analysis. 433 The second generation of ICAT has been modified to include a 13 C-labeled linker instead of deuterium. [434] [435] [436] A similar isotopecoded protein label (ICPL) 437 method uses either six light 12 C or heavy 13 C in isotope tags attached to free amino groups in proteins.\n\nAnother chemical labeling strategy using formaldehyde to introduce dimethyl labels, has been used to label the N-terminus and amino group of Lys residues (Figure 7a ). [438] [439] In this method, the light form of formaldehyde is reacted with cyanoborohydride to introduce double chemical groups of CH 3 to each primary amine in a peptide (Figure 7a ). The medium and heavy labeled reagents generate two sets of CHD 2 and 13 CD 3 , respectively. As a result, 4 Da of mass difference can be detected between three groups by mass spectrometry (Figure  8a -c). Although dimethyl labeling has been shown as an easy, efficient and inexpensive approach, there are still some restrictions. Like in the original ICAT method, there is a chromatographic retention time shift caused by deuterium labeling. Additionally, in the case where the mass difference is only 4 Da, observed in 3-plex labeling (Figure 7a ), the small mass difference may lead to isotopic peak overlapping between two peptides (Figure 8b ), especially for larger peptides. 18 O-labeling is an MS1-based stable isotope labeling method in which the isotope is introduced during enzymatic reaction. [440] [441] [442] In this method, the C-terminal carboxyl group of proteolytic peptide is labeled with two atoms of 18 O by amide bond cleavage and oxygen exchange in the presence of 18 O water. The labeled and unlabeled peptides are distinguished by a 4 Da mass difference in mass spectrometry. 18 O-labeling is an easy and inexpensive isotope labeling method. However, 18 O-labeling is less widely used than other quantitative methods for a number of reasons. The variable incorporation of 18 O atoms into peptides [443] [444] [445] is the primary limitation of the method. As oxygen exchange is not always complete, one labeled peptide may contain both singly labeled and doubly labeled subgroups. Together with unlabeled peptides, there will be a total of three groups of peptides with only a 2 Da mass shift separating them, leading to complicated data analysis. A modified 18 O-labeling approach decoupled from protein digestion has been developed which increases the efficiency of producing doubly labeled peptides. 446 However, even with all peptides doubly labeled, a mass difference of 4 Da is still relatively small, especially for large peptides with broad isotope peak distributions. Quantitative algorithms for 18 O-labeled data must be mindful of isotopic peak overlapping and variable labeling efficiencies in these samples. 445, 447 \n\nMetabolic labeling of proteins for quantification employs a stable isotope-enriched medium or diet to culture or feed living systems. The isotopic atoms are incorporated into the whole proteome through protein synthesis during protein turnover and cell multiplication. The labeled peptides have a mass increase that can be detected by a mass spectrometer. When labeled and unlabeled samples are combined prior to introduction into the mass spectrometer, the ratio of peak intensities in the mass spectrum reflects the relative abundances of the peptides. Metabolic labeling is considered to have higher quantitative accuracy than other labeling methods, since it allows samples to be mixed at the protein level prior to any sample preparation, avoiding the introduction of sample handling errors and systematic variance. However, unlike chemical or enzymatic isotope labeling, metabolic labeling cannot be applied universally to all samples. Stable isotope metabolic labeling first was introduced by Langen et al. in 1998, who used an 15 N-and 13 C-labeling approach to compare protein quantities with 2-DE. 448 Other research groups soon reported the successful use of 15 N metabolic labeling in both yeast 449 and a mammalian cell line. 450 Nitrogen, rather than carbon, is typically chosen as the isotopic marker because the isotopic nitrogen reagent is easier to obtain. Moreover, there are on average four times as many carbon atoms in a protein as nitrogen atoms. As a result, a 13 C-labeled peptide usually results in a broad distribution of the peptide isotopic peak, making data analysis more challenging. 15 N-labeling technology has been applied successfully to cells in culture, [450] [451] plants, [452] [453] [454] [455] Drosophila melanogaster, 456 Caenorhabditis elegans, [456] [457] and mammals. 458-460 15 N labeling of mammal is referred to as \"stable isotope labeling of amino acids in mammals\" (SILAM). 52, 461 Another metabolic labeling method, known as \"stable isotope labeling with amino acids in cell culture\" (SILAC), was introduced in 2002. 462 The major difference between SILAM and SILAC is that SILAM results in the labeling of one atom in all amino acids, whereas SILAC labeling is limited to select amino acids (usually Lys and/or Arg). In a typical SILAC experiment, cells are differentially labeled by growing them in light medium with normal Arg or Lys (e.g. Arg-0 or Lys-0) or labeled medium with heavy Arg or Lys (e.g. Arg-6 or Lys-6). The subsequent trypsin digest cleaves the proteins at arginine and lysine residues. Therefore, every tryptic peptide except for the C-terminal contains one labeled amino acid, which makes the mass increase of the labeled peptide predictable. Originally, SILAC was used only for cell culture. However, the SILAC approach also has been recently applied to mouse labeling 463 by feeding the mice a 13 C 6 -lysine-labeled diet for four generations, and Drosophila melanogaster 464 by feeding with labeled yeast.\n\nThe two main forms of metabolic labeling, SILAM and SILAC, each have strengths and shortcomings. SILAC and SILAM display different isotope patterns for labeled peptides in mass spectra (Figure 9 ). Since only one (or limited) labeled amino acid can be incorporated in any given tryptic SILAC peptide, the mass difference between the unlabeled and labeled peptide can be predicted, which facilitates data analysis. By contrast, the mass increase of a 15 N labeled peptide depends on its chemical composition as well as on the labeling incorporation rate. This variable mass gain usually makes subsequent data analysis more challenging. However, the variable mass shift caused by the 15 N atom number can also be a potential benefit for larger peptides. Thus the fixed mass difference derived from SILAC, e.g. 6 Da, may not be large enough for complete separation of the isotope patterns of each peptide (Figure 9 ).\n\nThe requirement for labeling efficiency varies between 15 N-SILAM and SILAC. Generally, complete or nearly complete labeling is necessary for a straightforward data processing and reliable quantification. However, the relative isotope abundance (RIA) ordinarily does not reach absolute 100% in either 15 N or SILAC, especially in mammal labeling, because of residual unlabeled atoms in the nutritional source and metabolic amino acid recycling. SILAC peptides appear only in two forms in the MS: labeled and unlabeled. If a protein is only partially labeled, the MS of unlabeled peptide is a mixture composed of two parts, the original unlabeled peptide and the partially labeled peptide (Figure 9d ). To avoid this, the labeling incorporation rate of SILAC should be close to 100%. By contrast, as the incorporation rate increases in the SILAM method, the labeled MS peaks of 15 N peptide gradually moves towards higher mass. A relatively low labeling incorporation rate is sufficient to separate the labeled and unlabeled MS peak envelopes of 15 N peptides ( Figure  9c ). Consequently, a high labeling efficiency for the 15 N quantitative strategy is not as stringently required as for SILAC (Figure 9c and d) , which reduces the cost and time required for labeling. Complete labeling is easily achieved for actively dividing cells in cellbased experiments because the medium that contains the labeled amino acids can serve as the whole nutritional source for protein synthesis. Moreover, the metabolic rate of cultured cells is normally very high. Mammals such as mouse and rat are not easily fully labeled because of the relatively slow turnover of both proteins and its precursor in the amino acid pool. A labeling approach starting in utero has been used to achieve successful labeling. 52, 461 Although there is no clear biological bias caused by incorporation of heavy isotopes, a label swapping strategy is recommended to avoid such a risk, and other systematic technical bias. In a label swapping experiment, the isotope types for two samples are switched in two replicates. 465 Thus any potential effects caused by incomplete SILAC labeling efficiency, protein contaminations, or isotope itself can be removed. An ideal correlation between two swapping replicates should result in two ratios (e.g. Light/Heavy) which are reciprocal to each other.\n\nAlthough metabolic labeling may provide the best quantification precision and accuracy, it is still used infrequently in proteomic studies, especially those involving animals. One reason for its limited use is the high cost due to the difficulties in manufacturing isotope enriched reagents and the requirement of large quantities of reagents to label animals. Also, not every organism is amendable to metabolic labeling, particularly human samples, although heavy leucine infusion has been used to track human surfactant protein in newborn infants. 466 An indirect 'spike-in' strategy was introduced to address these issues. 459 Briefly, labeled proteins are used as an internal standard, which is simultaneously mixed with every sample to be compared. The final quantification between samples can be derived from the individual ratios between each sample and the uniform standard. The benefits of using 'spike-in' are obvious. First, although the heavy stable isotopes or isotope enriched protein sources are thought to be a safe replacement for light ones, there may be some unknown biological effects caused by changed isotopes or diets. A labeled internal standard is able to eliminate such potential effects. Secondly, once an organism is labeled, it can be used for many diverse experiments. A labeled mouse can provide researchers with organs (brain, heart, liver etc.) with adequate protein content for many studies and so the cost per experiment for metabolic labeling is not as high as it might appear. For organisms not suitable for metabolic labeling, a labeled internal standard which shares the same genome background and has a considerable proteome overlap with the target sample, can be used for quantification. [467] [468] 15 N labeled rat brain as 'spike-in' to quantify the proteome and phosphoproteome in cultured primary neurons. 467 The 'spike-in' method allows comparison of unlimited number of samples in parallel but has some inherent restrictions. The overlapping proteins, especially in 'tissue/cell' experiments, represent a reduced portion of the whole proteome since the samples originate from different cell types. Because a ratio of ratios (ratio/ratio) is used for quantification, only the proteins found in every experiment can be used to draw the final quantitative map. Furthermore, the statistical deviations in a 'spike-in' experiment are typically higher than those in a direct comparison.\n\ntags for relative and absolute quantification (iTRAQ \u00ae ) 469 and tandem mass tags (TMT \u00ae ), 470 consist of several functional elements: a unique mass reporter, a cleavable linker as a mass balancer, and an amine-reactive group (Figure 7b ). All labeling subdivisions in a set of multiplex tags have the same total mass weight (Figure 7b) . Importantly, these labeling elements facilitate coelution of peptides during LC and co-isolation for fragmentation during MS/MS. Peptide mixtures representing different biological samples are labeled with different forms of the tag by reacting the amine-reactive group of the tag with the peptide N-termini and lysine residues of the peptide. During peptide fragmentation in the mass spectrometer the linker is fragmented, releasing the mass reporter, where the intensity represents the relative abundance of the original peptide (Figure 8d-g) . There are several features of isobaric labeling which have led to its widespread use in proteomics. For instance, an isobaric labeling strategy is capable of analyzing multiple labeled pools of peptides, up to 6-plex for TMT 471 and 8-plex 472 for iTRAQ, in a single analysis, reducing analytical time significantly. In contrast, all other isotope labeling approaches are limited to 2 or 3 isotope comparisons. Another benefit of using an isobaric label is that it does not increase the complexity of the MS1 scan ( Figure 8e ) and does not decrease the precursor signal sensitivity (as in SILAC and SILAM), since all the tags lead to the same mass increase for each labeled peptide. However, isobaric reagents are undetectable in conventional CID in ion trap instruments because these low-mass reporters are ejected from the ion trap during activation. 473 To circumvent this issue, a modified activation method, pulsed q dissociation (PQD) 474 can be used which enables MS/MS reporter ions to be detected in an ion trap mass analyzer. Higher-energy collisional dissociation (HCD) 273 has also been routinely used in iTRAQ and TMT analysis. 275, 475 HCD provides better MS2 data quality, because all the MS2 data are acquired with high mass accuracy, but it requires more ions and time to generate a MS2 spectrum compared with that from normal CID. As a result, the HCD-based quantification normally leads to lower proteome coverage. Although isobaric labeling has been shown to be a powerful tool for quantitative proteomics, it suffers from a lack of quantification accuracy, [476] [477] which is largely influenced by co-fragmentation of coeluting peptides with similar m/z. When the MS selects a peptide precursor for subsequent fragmentation, it isolates the precursor in a wide m/z window, which may cover both target peptide and the co-eluting peptides. In this case, the reporter ions do not originate from a pure peptide population, but a mixture. Thus if the co-fragmented peptides do not have the same quantitative ratios, it will result in inaccurate quantifications. Recently, two independent studies have sought to overcome this limitation. [478] [479] Ting et al. 478 employed an additional stage of mass spectrometry to improve the ion selection specificity. In this case, the most intense MS2 fragment ion was selected for a further fragmentation, and the reporter ions released during the second fragmentation were used for quantification. To avoid selection of non-labeled fragments in MS2, the researchers used protease Lys-C, not trypsin, to digest the proteins. The resulting peptides all contained Lys and were labeled with isobaric tags at both termini. Thus all the fragment ions in MS2 were tagged and able to release reporter ions in the MS3 analysis. Wenger et al. 479 reduced the charge of peptides by using proton-transfer ion-ion reactions, generating more purified precursors for further fragmentation. For instance, if a doubly charged peptide and a triply charged peptide have the same m/z, using the Wenger method both charges can be reduced by one, generating singly charged and doubly charged peptides respectively. These two newly charged peptides will now have different m/z, avoiding precursor interference. Both strategies show promise as good solutions for isobaric labeling, but an increase in the number of steps in the procedures may lead to fewer peptide measurements and identifications over the same period of analysis time.\n\nSimilarly, another potential weakness of the isobaric strategy, which has not been widely recognized, is the bias caused by using a single intensity measurement. In a shotgun proteomic experiment, a peptide is usually triggered for fragmentation only once (or limited times) due to the 'dynamic exclusion' function. Therefore the reporter ions used for quantification only reflect the peptide abundances at that given time. In contrast, MS1-based quantification normally measures the whole peptide elution profile, which reduces relative variability, especially for low abundance peptides.\n\nLabel free quantification-As has been described, use of a labeling method that employs stable isotopes allows for accurate quantification of protein expression. However, certain limitations, including additional sample processing steps, cost of labeling reagents, inefficient labeling, difficulty in analysis of low abundance peptides, and limitation of sample number, are associated with use of these labeling techniques. As an alternative, label-free methods can be used to avoid the drawbacks of labeling methods. Quantification of protein expression using a label-free methods can be achieved by two methods: 1) spectral counting uses the frequency of peptide identification of a particular protein as a measure of relative abundance and 2) ion intensity uses the mass spectrometric chromatographic signal intensity of peptide peaks belonging to a particular protein. 480 In spectral counting 175, 429, 430 the frequency of peptide spectral matches of a specific protein can be correlated with the amount of a protein. Use of the spectral counting method can be applied to low to moderate mass resolution (0.1-1 Da) LC-MS data. Spectral counting has shown a linear correlation and good reproducibility over a large dynamic range for determination of relative protein abundance. 481, 482 In addition, the spectral count approach makes use of simpler normalization and statistical analysis than does the ion intensity method. A protein abundance index (PAI), defined as the number of identified peptides divided by the number of theoretically observable peptides for each protein, is used in label-free quantification to calculate the abundance of a protein. 483 This has been further converted to exponentially modified PAI (emPAI), which has greater proportionality to the protein abundance in a sample. 484 The emPAI calculation can be used for database search platforms such as SEQUEST and Mascot. One of the drawbacks of spectral counting is the inherency of peptides with different physicochemical properties to produce bias in MS result. To improve this disadvantage, a modified spectral counting method, called the absolute protein expression (APEX) was introduced for measurement of protein concentration per cell, based on the number of observed peptides for a protein and the probability of detection of peptides by MS. 485 APEX is a useful tool for large-scale analysis of proteomic data, as shown by estimation of cellular protein concentrations of human pathogen Leptospira interrogans. 486 The intensity based approach for quantitative label free MS involves integration of all chromatographic peak areas of a given protein; the area under the curve (AUC) directly correlates with the concentration of peptides in the range of 10 fmol -100 pmol. 424, 425 Thus, the process for quantification of proteins based on AUC by measurement of ion abundance at specific retention times for given ionized peptides, called the ion count, is useful for quantification within the given detection limits of the instrument. 487 Although the basic idea behind this method is rather straightforward, various factors to ensure reproducibility and accuracy must be taken into account. Factors that need be taken into consideration include co-eluting peptides, particularly when peptide signals are spread over a large retention time, multiple signals for the same peptide due to technical or biological variation in retention time, mass spectrometer speed and sensitivity, and background noise due to chemical interference. Computational methods that consider mass accuracy and alignment of retention times of peptides across various sets, background noise, and peak abundance normalization have been used to address these issues. 488 Finding the balance between MS and MS/MS frequency for quantification of proteins using AUC methods, while at the same time maximizing protein identifications, is imperative. With the advent of high mass accuracy mass spectrometers, this can be accomplished by performing multiple analyses of the sample separately in MS and MS/MS modes, 427 matching accurate mass and retention times for identification of peptides, and integrating the ion intensities of corresponding peptides to calculate the protein concentration. 489 A combination of both spectral counting-and ion intensity-based label-free quantification further improved accuracy. 490 As described in the \"Mass spectrometers and peptide MS analysis\" section, data-dependent analysis (DDA), where the mass spectrometer scans parent ions and selects the most abundant ions for fragmentation, is used for processing of most MS analysis. Using this method, low abundance peptides are often omitted, resulting in a low dynamic range of detection. Data-independent analysis (DIA) acquires data based on the sequential isolation and fragmentation of specific precursor windows. Using this method, signal to noise ratio showed 3-5 fold improvement, and peptides unidentified by DDA methods were detected. 233 Use of an advanced method, called XDIA, with increased spectra and peptide identification using ETD and CID, was reported to improve confidence in quantification statistics and protein coverage. 491 Recently, a DIA method called SWATH was developed for quantitative and qualitative detection of all proteins and peptides in a single analysis using fast, high resolution Q-ToF. 236 Despite the fact that there are always new developments in software programs and technical aspects of analytical instruments, high quality results that are both sensitive and specific can be generated only if the software is compatible with the specified instrument. Therefore, one of the obvious challenges for quantitative proteomics is choosing the most appropriate analysis software, considering file compatibility, user friendliness, computational requirements, data visualization, and automation. Some software tools for label-free quantification have been described below. SIEVE, developed by ThermoFisher Scientific, makes use of the base peak chromatogram to extract data and align peptide signals across LC-MS runs with statistical validation for determination of changes in peptide abundance. Other software including QuanLynx (Waters), Elucidator (Rosetta Biosoftware), and Expressionist (Genedata) are also commercially available. 492 ProteinQuant detects the first occurrence of a peptide MS/MS scan and notes its corresponding retention time in the master file. 493 Within the retention time window associated with the precursor MS/MS scan time, it generates a base peak chromatogram for precursor m/z and selects the maximum intensity ions. IDEAL-Q is another automated tool for use in label free quantification. 494 This tool accepts raw data in mzXML format and peptide and protein identifications from search engines such as SEQUEST, 495 Mascot, 496 or X!Tandem. 497 IDEAL-Q uses a fragmental regression algorithm to find unidentified peptides in a specific LC-MS/MS run through a predicted retention time from the same identified peptide in other runs. The predicted elution time is used to detect the precursor ion isotope cluster of the assigned peptide for quantification after noise filtering. SuperHirn 498 and PEPPeR 499 software make use of MS/MS scan in addition to retention time and m/z, which significantly improves alignment accuracy, but is still limited to high resolution data. SuperHirn uses an alternative alignment strategy and intensity correlation to detect outliers with significantly lower similarity values between LC-MS runs; therefore, low quality runs for the alignment process are excluded. 492, 498 Census, which is compatible with label and label-free analyses, reads the spectral file and constructs the chromatogram for each peptide generating a XML file, which is further loaded into a Census graphic user interface application. Results are exported after consideration of various peptide parameters, including regression ratio, regression score, determinant factor, data points, and outlier peptides. 500 A new developed software called IdentiQuantXL was compared with various software packages, including SIEVE, Msight, PEPPeR, ProteinQuant, and IDEAL-Q, based on key features, such as elution patterns, global or individual alignment, pattern-or identity-based, and multiple filters using various different samples, i.e., standard peptides, kidney tissue lysates, HT29-MTX cell lysates, and serum. 501 Recently, Skyline, open source software tool for quantitative data processing from targeted proteomics experiments performed using SRM, 502 expanded its capabilities to process label-free quantification of proteomics data using Skyline MS1 filtering. 503 This software provides key features including visual inspection of peak picking and both automated and manual integration, and can be used with mass spectrometers from major companies.\n\nMethods for label-free quantification in high throughput shotgun proteomics have come a long way in recent years. Each method has advantages and disadvantages and it is difficult to say that one method is more accurate than the others. With the advent of a large number of fast, accurate, and sensitive instruments and software program for validation, label-free quantification is becoming a popular alternative to the use of labeling methods.\n\nThe relative quantification methods described above are currently the standard methods used in the quantitative proteomics field, providing valuable information about altered protein expression. However, absolute quantification is still a much sought after goal in proteomics, as it allows us to have a more precise and comparable definition of the proteins and their PTMs within a biological system, which could include detailed information on cellular organization, protein quantities and dynamics, and protein stoichiometries within complexes, among other biological phenomena.\n\nThe basic principle of current absolute quantification methods is to introduce stable isotope labeled standards whose abundances are predefined. This method is equivalent to 'isotope dilution analysis', which was initially used in small molecule determination. 504 As discussed previously, metabolically labeled proteins can also be 'spiked-in' to serve as internal standards in proteomics experiments. For relative quantification, metabolically labeled standards usually contain the whole proteome, but protein abundance for individual proteins is unknown. The 'spike-in' methods used for absolute quantification employ standards with limited number of peptides and known concentration. Labeled standards can be generated in three ways: chemically synthesized stable isotope labeled peptides (AQUA), 505 biologically synthesized artificial quantification concatemer (QconCAT) peptides 506 and intact isotope labeled protein standard absolute quantification (PSAQ) or absolute SILAC. [507] [508] [509] The AQUA method relies on the relative comparison between an internal isotope-labeled standard peptide and unlabeled sample digest, in which a chemically identical peptide is expected. The labeled peptide can be mixed with the sample during protein digestion or right before the LC-MS analysis. Analysis of paired peptides in selective mode (SRM or MRM) 510 enables the MS to monitor both the intact peptide mass and one or more specific fragment/transition ions of that peptide. In combination with the retention time, the AQUA platform can eliminate ambiguities in peptide assignments and extend the quantification dynamic range. The preferred instrument for SRM/MRM analysis is the triple quadrupole mass spectrometer, since the three space tandem quadrupole analyzers can provide the best performance in precursor selection, fragmentation, and transition ion scan. In addition, the AQUA method is suitable for PTM determination. 505,511-512 A synthesized peptide with modified residue and heavy isotope label is used as the internal standard. An unmodified heavy peptide standard can also be added to extract quantitative information on both the total protein and modified protein levels. A disadvantage of AQUA is that this method is not fully compatible with protein fractionation. A target protein subjected to sample fractionation normally has incomplete recovery, leading to an increased error in the quantification. 513 The selection of the optimal peptide standard and the amount of the standard to be added to the sample are very important criteria for the AQUA method. A survey run is always recommended to determine which peptides are well ionized and fragmented and if there are any interfering ions. The selected peptides are typically fully tryptic, without missed cleavage, and not excessively long. Moreover, peptides with reactive amino acids and peptides shared by more than one protein are avoided. Unlike the other relatively global quantitative approaches, AQUA does not measure protein quantity in a high throughput manner but determines one or a few target peptides of interest.\n\nQconCAT is an AQUA-like strategy which enables absolute quantification on a larger scale. Briefly, an artificial protein formed from concatenation of tryptic peptides can be produced by either in vivo or in vitro methods from a single artificial gene, and then purified by its His6x-tag. The QconCAT polypeptide is mixed with the biological samples prior to proteolysis. After trypsin digestion, all released peptides can act as internal standards for multiple proteins. QconCAT can now include roughly 50 peptide standards, 514 which may correspond to 20-30 proteins. Similar to AQUA, a well-designed QconCAT construct is necessary for the final success of quantification. The design of QconCAT involves many aspects, which have been reviewed by Brownridge el al. 514 The major advantage of QconCAT is its ability to monitor several proteins simultaneously, which is very useful in protein complex and pathway studies. However, like AQUA, QconCAT is not compatible with protein fractionation, because the spiked-in standard is an artificial protein different than any of the target proteins.\n\nThe PSAQ method possesses some features of both AQUA and QconCAT. 507 Like AQUA, a PSAQ standard targets one protein. However, PSAQ employs an intact stable isotope labeled protein (which can be expressed in vivo or in vitro) rather than one peptide for use as the internal standard, therefore it provides multiple peptide standards for a given protein, with higher sequence coverage and better statistical reliability. Another strength of PSAQ is that the standard and sample can be mixed at the beginning stage of the sample preparation, making it compatible with prefractionation and resulting in enhanced sensitivity and the release of peptides during proteolysis will mimic the rate of release for the target protein.\n\nBoth QconCAT and PSAQ can provide higher quantitative efficiency than AQUA, as the former two allow quantifying multiple peptides by spiking in one standard. For QconCAT and PSAQ strategies, an accurate measurement of the standard quantity is important for subsequent quantification of peptides. Cysteine or amino acid analysis have been used for this purpose, [506] [507] where the protein is first hydrolyzed and then quantified by comparison with amino acid standards. A drawback of QconCAT and PSAQ is they are not easily used to measure modified peptides, whereas AQUA is more adaptable to synthesis of peptides with specific modifications.\n\nBesides the isotope labeled standard methods discussed above, there is another type of absolute quantification which is less used, but potentially useful. This strategy employs synthetic unlabeled peptides which may be labeled with isotope reagent, such as iTRAQ 54 or 18 O water. 515 The synthesized peptide and the endogenous peptide sample, including its counterpart, are labeled with different isotopes by chemical or enzymatic reactions. The advantage of this method is the use of unlabeled synthetized peptides and readily available isotopic labeling reagents.\n\nAbsolute quantification has shown promise in targeted proteomics. However, currently it can only be carried out on a limited number of target proteins and peptides, mainly due to the need for a synthetic internal peptide standard. Moreover, the degree to which the measured quantity accurately reflects the real sample quantity, especially after the timeconsuming sample preparation procedures and physical/chemical treatment of the sample, is still under debate. The reliability of the quantification can be greatly affected by protein degradation and the completeness of protein digestion. Therefore it is possible that the absolute protein concentration derived from these strategies does not accurately reflect the real protein level in the biological samples. Measurement of larger peptides with middledown proteomics or of intact proteins with top-down may help to alleviate these challenges.\n\nFrom ground-breaking development and automation of instrumentation, analytical methodologies, and bioinformatics pipelines, the most common proteomics experiment has quickly shifted from methodological to biological. Global quantitative biological comparisons are now possible, particularly with increasingly parallelized isotopic peptide labeling strategies, 516 which has increased the need for appropriate statistical consideration of protein expression changes with multiple testing correction. 517 The comparisons made with proteomics are similar to genomics and transcriptomics studies, 518 so many of the same principles are beginning to be used in data analysis. These include the ANOVA t-test [519] [520] and multiple test corrections of Bonferroni, 521 Benjamini-Hochberg, 522 Storey-Tibshirani. 523 , and Bayes. 524 Application and description of these tests in a proteomic context have been demonstrated on label-free spectral counting data [525] [526] [527] and metaboliclabeling data. 270, 524 These comparison allow for extraction of statistically-significant changed proteins for biological validation. Further development and application of these methodologies to shotgun proteomic data sets will be essential to finding interesting biological changes.\n\nBioinformatics is an essential aspect of shotgun proteomics, especially with the production of increasingly complex data sets from increasingly comprehensive MS-based proteomic analyses. A schematic of a common shotgun proteomics bioinformatics pipeline is illustrated in Figure 10b . The integration of bioinformatic tools into proteomics pipelines and bundled software packages has begun to help standardize and simplify proteomic analysis for transfer of complicated, powerful methodologies from the experts to the users. Examples of these are the Integrated Proteomics Pipeline (IP2, http:// integratedproteomics.com/), pFind Studio (http://pfind.ict.ac.cn/), 528 ProteoIQ (http:// www.bioinquire.com/), ProteomeDiscoverer (www.thermoscientific.com), Scaffold (http:// www.proteomesoftware.com/), MaxQuant (http://maxquant.org/), 529 and Transproteomics Pipeline (http://tools.proteomecenter.org). 530 Shotgun proteomics has developed into an automated pipeline of powerful analytical techniques. The automation has the advantage of wide-spread use -and unfortunately also misuse. A systematic study by the Human Proteome Organization (HUPO) of multiple proteomics labs revealed dramatic variability in results for a 20 protein test sample. 531 This highlighted the need for standardization of proteomic methodologies, which has followed, 532 and appropriate operator training, understanding, and usage of database search methods. As complex proteomes are commonly analyzed with shotgun proteomics, more complex standards are being developed and characterized for evaluation of system performance. [533] [534] [535] [536] Other recent efforts for addressing this issue include development of quality control software to monitor key proteomic metrics both during and after LC-MS runs and bioinformatics analysis. [537] [538] [539] Proper use 540 and comparison of proteomic algorithms and their performance 541 has also been highlighted.\n\nAfter analytical methodologies were worked out for the identification of peptides with tandem mass spectrometry, 542 one of the main limitations was manual interpretation of fragmentation spectra. Interpretation generally required an expert hand and, even then, was time consuming. For a LC-MS/MS run of a complex protein/peptide mixture, manual interpretation of all spectra was unrealistic. Thus, the crux of and one of the most influential contributions to the field of mass spectrometry-based proteomics was automation of identification of candidate peptide sequences from MS/MS spectra with software. An excellent conceptual review on this topic provides an overview of the different methodologies for matching peptide spectra to peptide sequences. 543 The first software developed for this purpose, SEQUEST, leveraged two timely technological developments, sequencing of genomes and computer software algorithms to match MS/MS peptide spectra to peptide sequences, and is still routinely used today. 495 Manually interpreting peptide MS/ MS spectra is done by finding mechanistically-expected amino acid-specific fragment ions or mass intervals to build confidence in a sequence. The SEQUEST algorithm uses a similar strategy by simultaneously comparing all experimental fragment ions to theoretically generated fragment ions at the spectrum level. The SEQUEST software makes two key calculations which define whether a peptide sequence is a confident match for a fragmentation spectrum: XCorr and \u0394CN. XCorr is a statistical calculation of the correlation of the theoretical and experimental spectra. \u0394CN, the difference between the top peptide spectrum match (PSM) and the second best PSM, is then calculated. Initially, \u0394CN was used as the best measure of whether a PSM was correct, 543 but subsequent filtering methods and software have been introduced to statistically assess the confidence of a large set of identified PSMs. The theoretical peptide spectra are generated using a database of proteins, from as complex as the entire translated genome to as simple as a list of high confidence, validated translated protein candidates. For a tryptic digestion, only theoretical tryptic peptides of the appropriate length (typically 6 -50 amino acids long) are considered as potential PSMs. Mascot is another commonly used search engine which instead relies on the probabilistic matching of fragment ions. 496 The Mascot search methodology originated from MALDI-and ESI-MS experiments on individually digested proteins where peptide mass fingerprints are used as the unique identifier of proteins. A probability score is calculated to determine how likely a calculated peptide mass fingerprint spectra matches an experimental one by chance. A similar probability scoring strategy of phosphorylation site informative fragment ions has proven useful for the confident localization of phosphorylation sites in global phosphoproteomics data. 337 Mascot has since been modified and expanded to calculate probability scores for peptide MS/MS data for complex mixtures and to include decoy matches within database searches. 544-545 X!Tandem followed SEQUEST and Mascot, combining three important attributes from each through the calculation of an expectation value. [546] [547] The expectation value is a probabilistic assessment (similar to the Mascot probability score) of the correlation of an experimental and theoretical spectrum (similar to XCorr in SEQUEST) and how much better a peptide match is than a stochastic match (similar to \u0394CN in SEQUEST). The combination of database search engine results using various methods has improved overall identification numbers and confidence. [548] [549] New software for identifying peptides from mass spectrometry data are continually being developed to improve upon widely-used methodologies, newly-implemented fragmentation methods, and for niche applications. A number of software tools have been developed to improve upon the SEQUEST-like search methodology to improve speed, sensitivity, and accuracy through consideration of fragment ion intensity, 550-552 algorithm architecture, [553] [554] [555] [556] and higher quality data. [557] [558] [559] Similar to trends with SEQUEST, an improved Mascot-like search engine (Andromeda), 560 mass accuracy-calibrated filtering, 561 and advanced machine learning filtering with Percolator 562 capitalize on higher quality data from newer mass spectrometers. On-the-fly database searching has allowed for intelligent, directed data acquisition. [563] [564] Fragmentation spectra of metabolically labeled peptides were used to validate peptide spectrum matches from unlabeled peptides. 565 Probabilistic matching of fragment ions has also proven useful for identifying sequence tags -abundant peptide fragment ion patterns. [566] [567] [568] [569] In particular, sequence tags facilitate the identification of protein site mutations and unexpected PTMs that would otherwise be missed by a traditional SEQUEST-or Mascot-like database search. [570] [571] [572] Database search engines have been either modified or newly developed to handle spectra from new fragmentation methods, such as ECD [573] [574] and ETD, [575] [576] [577] and variant peptides, such as non-ribosomal peptides. [578] [579] Other metrics have been introduced to improve PSM confidence and database search speed such as peptide precursor mass accuracy 249, [558] [559] [580] [581] [582] [583] [584] and charge state predication, 585-586 empirical statistical models, 482, 587 and amino acid composition. 588 Statistical analysis of large data sets from CID, 589-590 ETD, [591] [592] and HCD 593 have contributed to a better understanding of peptide fragmentation mechanisms for spectral prediction and peptide identification algorithms. In an effort to combine both the computational power that has proven useful with database searches and the versatility of manual spectra interpretation, de novo sequencing methods are becoming a popular area of development. Although database searching is extremely powerful and versatile, de novo sequencing has provided a complementary and alternative unbiased means for identifying peptide sequences, particularly for unknown peptides and proteins, in an automated fashion. [594] [595] [596] Combining de novo sequencing with database search methods 597 have improved the speed 598 and sensitivity 599 of database searches and the confidence of de novo sequenced peptides. 600 Application of de novo sequencing to HCD fragmented 601 and Lys-N digested, ETD fragmented 602 peptides have exploited less common ion types for sequence determination.\n\nPeptide search results are a mix of correct and false PSMs. The use of a decoy protein database was cleverly introduced as a way to filter for confident PSMs and is still most commonly used, 603 although some argue that a peptide probability is adequate and more resistant to false discoveries. 604 A decoy protein database is created by reversing or scrambling protein sequences from a normal database which is then appended to the normal protein database. These decoy peptides and proteins are then identified, with lower frequency, during the database search and used as a measure of random, incorrect PSMs. The random and incorrect decoy PSMs can then be used to establish a cutoff for the high confidence PSMs and to estimate the false discovery rate (FDR) of PSMs, peptides, and proteins. Generally, two peptides have been required for identification of a protein, but there is also evidence that a single high confidence peptide identification can be a better indicator than two lower confidence peptides. 603, 605 Semi-supervised machine learning of peptide filtering improved peptide identifications 17% from tryptic digests and 77% from nontryptic digests. [606] [607] Application of statistical methods in combination with the target decoy approach provided greater significance analysis of peptide matches. 608 An algorithm to optimize the protein filtering improved protein identifications by ~25% over common methods. 609 Considering both PSM and protein false discovery simultaneously in a twodimensional target decoy strategy yielded a more versatile and accurate representation of peptides and proteins within a sample. 610 A strategy has been presented to infer the proteins present within a complex sample from hundreds of LC-MS runs where protein false discovery rates are difficult to control using conventional PSM false discovery rates. 611 Similarly, protein database size and quality directly influence the size and quality of the identified protein and peptide candidates. Essentially, with a larger, less curated database the chances of matching decoy PSMs increases, subsequently decreasing the sensitivity of correct PSMs. Thus, database curation is an essential and continuing aspect of proteomics research, recently illustrated with a customized protein database derived from RNA-Seq data. 612 For newly sequenced organisms yet to be annotated, a proteogenomic approach can be used to search against the 6-frame translated genome. [613] [614] [615] [616] [617] For organisms which have yet to be sequenced or are extinct, 618-622 a combination of known databases can be used to identify peptides and proteins. These methodologies have even been used to find protein sequences and correct gene annotations for highly studied and characterized organisms such as S. cerevisiae 623 C. elegans, 624 and Mus musculus, 625 and Arabidopsis. 626 Leveraging known protein interaction networks, discarded PSMs were matched to proteins expected to be expressed and present as part of functional protein complexes. 627 Although software has eased the burden of manual interpretation of tens of thousands of tandem mass spectra, manually validating peptide spectra for proteins and post-translational modifications is still an essential principle of proteomic analysis.\n\nPeptides identified with tandem mass spectrometry are used as surrogate representations of intact proteins and their post-translational modifications. We have already described many of the experimental advantages of analyzing proteins as peptides. However, an ongoing challenge of shotgun proteomics is correctly mapping identified peptide sequences to protein sequences, particularly for redundant proteins and isoforms. Further, as proteomics methods continue to become more sensitive and comprehensive and protein databases increase in size, the ability to properly assign peptides to proteins has become even more challenging. At the same time, shotgun proteomics experiments have become more complicated and biology-driven, so the importance of correctly identifying and quantifying proteins from peptides has continued to increase. These challenges include the stochastic sampling and identification of unique peptides from protein isoforms (homologous proteins) or unrelated proteins which share non-unique tryptic peptide sequences (redundant proteins). When peptide sequences are shared among proteins, they are by definition more prevalent and abundant than their unique peptide counterparts, and thus also more easily identified. Conversely, unique peptides are less abundant and harder to identify. Unfortunately, the hard to identify unique peptides carry the most experimental evidence for unambiguous, confident identification of both homologous and redundant proteins. Thus, many bioinformatics strategies have been proposed and implemented to directly address this inherent challenge. Due to the complexity of this issue, a number of guidelines have been established by journal editors and conference organizers which aid in simplifying publication of proteomics data. [628] [629] [630] [631] [632] Initially, when MS data sets and protein databases were small, peptide database search engines 482, 587 and filtering software 633 assembled and listed all proteins for which there was peptide evidence. In particular, DTASelect and Contrast software packages grouped redundant proteins and isoforms within a single proteomic analysis and allowed for comparison between experiments based on spectral counts and sequence coverage. Generation of a minimal protein list which best described the identified peptide spectrum matches with the Isoform Resolver algorithm yielded a more conservative representation of proteins present in a sample. 634 A similar strategy using bipartite graphical analysis in a software package called IDPicker further improved the accuracy and transparency of protein identifications within a single proteomic analysis. [635] [636] Further classifying peptides as either ambiguous or unambiguous for not only protein sequences and protein isoforms, but also genes using the ProteinClassifier software added further confidence and clarity to protein inferences. 637 The majority of these strategies rely solely on the prevalence of peptide identifications, but a few methods have incorporated protein probabilities. The software tool PANORAMICS facilitated calculation of peptide-to-protein assignment probabilities by combining Mascot PSM probabilities and the probabilities of peptides and proteins generating spectra. 638 Other distinctive strategies seek to bypass assembling protein identifications from peptide identifications and directly perform protein sequencing from tandem mass spectra of peptides. An \"overlap \u2192 layout \u2192 consensus\" strategy for assembling proteins was borrowed from DNA fragment sequencing for \"sequencing\" proteins from non-specific protein digestions. 639 Essentially, repeat peptide identifications were clustered and signal averaged to generate a consensus spectra. Then the consensus spectra were all aligned until the overlaps created a full protein sequence for \u03b1-synuclein. A similar strategy with peptide alignment using spectral network analysis has facilitated the unbiased identification of post-translational modifications on proteins. [640] [641] Although these sequencing strategies have yet to be applied to highly complex mixtures, it has aided in clustering millions of tandem mass spectra from large scale experiments for faster and more sensitive database searches. 642 An excellent tutorial on the protein inference problem and implementation of many of these methodologies has been described elsewhere. 643 The identification of a single high confidence unique peptide spectrum match can provide high confidence in the presence of a protein, particularly when other high confidence nonunique peptides are also present to support that protein inference. However, quantification by both label-free and isotopic labeling methods can be more complicated. Generally, strategies that remedy the protein inference problem also improve protein quantification. 637 In the case of label-free detection using spectral counting, non-unique peptides must be appropriately assigned to redundant proteins to estimate their relative abundances. Similar strategies to address protein identification inference are regularly applied to spectral counting-based quantification, such as with Abacus, 644 but caveats exist. A systematic study using six homologous albumins spiked into a complex mixture illustrated that distributing shared spectral counts based on the number of unique spectral counts led to the most accurate and reproducible quantification results. 645 For relative ratio measurements using either label-free peptide ion currents or isotopically-labeled peptide ratios, the most accurate method for protein quantification is the use of only unique peptides sequences. [646] [647] [648] This method is the most stringent as it completely ignores the problem of shared peptides, and unfortunately a wealth of quantitative measurements, making it the least sensitive and comprehensive. Additionally, this method is highly dependent on multiple proteomics parameters; high complexity samples, poor LC-MS sensitivity, and large database size can all limit the number of unique peptides identified and thus quantified from a sample. Further, a small number of quantitative measurements from unique peptides can limit statistical analysis. An advantage of label-free ion current and metabolically-labeled peptide quantification is that multiple sequential measurements are made on peptide chromatographic peaks from MS1 precursor scans, accounting for measurement variability and noise within MS1 scans over the chromatographic peak timescale. Isobaric peptide labeling is used to perform quantification in the MS2 scan and is thus only measured when a peptide precursor ion is sampled for fragmentation. The estimation of measurement variability and noise for a peptide can only be done on peptides that are resampled and thus are highly dependent on the abundance of a protein and its corresponding peptides. Therefore, the ability to use all peptide quantification information, unique or not, would benefit isobaric labeling methods for protein quantification the most. One proposed solution for the use of shared peptides in protein quantification using ratio measurements was demonstrated with peptide ion current measurements. 649 The methodology combines the concepts described above used for protein identification inference and for distributing spectral counts of shared peptides among proteins with unique peptide counts. With peptide ratio measurements, peptides shared among proteins can be grouped and assigned to proteins with unique peptide ratio measurements which are statistically similar. The study showed that peptide measurements for protein groups from transferrin and histone 1 isoforms could be appropriately grouped to quantitate individual isoforms of each. Similarly, the differentiation of peptide measurements among the shared peptides from the redundant proteins desmin, vimentin, and keratin was possible. A similar strategy for inclusion of shared peptides in protein quantification was recently demonstrated using a combinatorial optimization to reduce relative abundance measurement error. 650 The effect of shared peptides on protein identification and quantification accuracy remains a common challenge in shotgun proteomics. Further software development in the bioinformatics field should continue to address these challenges. 651 The continued development of middle-down proteomics, which identifies larger peptide fragments with higher probability of being unique, should also help to address this wide-spread challenge. 14,297,652-654\n\nTypically, biological processes are carried out by interactions between many biomolecules. There are diverse types of interactions, such as protein-DNA or RNA, DNA-DNA, DNA-RNA and protein-protein interactions. Of these biomolecule interactions, protein-protein interaction are challenging to study due to their high diversity.\n\nThe classic approach to studying protein-protein interactions is yeast two-hybrid (Y2H) system ( Figure 11a ) which was introduced more than 20 years ago. 655 In a Y2H experiment, a transcript factor is split into two subunits, one is the binding domain (BD) and the other one is the activating domain (AD). The engineered bait protein is fused to the BD and the second protein (prey) is fused to the AD. If the bait and prey proteins interact with each other, the transcript factor can be activated, starting the transcription of reporter gene. Otherwise, there will be no transcription of the reporter gene (Figure 11a ). Y2H was designed to investigate direct binary interactions. The initial Y2H experiments focused on the interactions between a limited number of proteins. However, after genome scaled resources of open reading frames (ORFeomes) became available, comprehensive network maps have been drawn for various model organisms by large scale Y2H, including Saccharomyces cerevisiae, [656] [657] [658] [659] Drosophila melanogaster, 660 Caenorhabditis elegans, 661 and more recently even human. [662] [663] [664] [665] While Y2H has been widely used in high throughput protein interactome studies, there are limitations. The primary limitation is that the protein interactions do not occur in their physiological cellular conditions, and it is only possible to detect direct interaction between two proteins; any information on indirect interactions will be ignored.\n\nAn approach complementary to Y2H based on affinity purification and mass spectrometry (AP-MS) was developed to explore the protein-protein interaction for both targeted and large scale research. In an AP-MS experiment the target protein of interest, together with its interacting partners, is purified from a protein mixture. The purified protein complex is then subjected to shotgun proteomic identification and quantification (Figure 11b) . 10,614 PTM information can also be collected if desired. Because it is carried out under endogenous conditions, the AP-MS strategy enables identification of both direct and indirect interactors. Generally, the topology of the protein interactome is not found from the AP-MS strategy because it is incapable of distinguishing direct and indirect interactors (Figure 11b) . However, chemical cross-linking of protein complexes and the analysis of their cross-linked peptides can provide this information. 666 Alternatively, the reverse purification of protein complex components can be used to infer topology, as in global AP-MS studies. Methods which analyze intact protein complexes are also being developed to address these issues. [667] [668] Ideally, interactome experiments based on AP-MS should employ high quality monoclonal antibodies against the bait proteins. However, this is sometimes difficult due to a lack of good antibodies. Commonly, an engineered protein with an affinity has been used in AP-MS based protein interactome studies. Instead of using a specific antibody against target protein, the affinity tag system employs a uniform tag specific purification which can be used for many bait proteins. A widely used tag system is tandem affinity purification (TAP), 669 which consists of calmodulin-binding peptide (CBP) and protein A of Staphylococcus aureus (ProtA), linked by a tobacco etch virus (TEV) cleavage site ( Figure   12 ). The TAP fused protein and its interactors are first pulled down by the distal ProtA affinity tag, and then released by cutting at the TEV cleavage site. The bait protein complex is subsequently subjected to the second purification step, which binds the CBP (Figure 12 ). The advantage of TAP compared with the normal single-step procedure is reduced background protein levels. Ideally, all the proteins non-specifically binding to the affinity beads are excluded after the second purification. Many other variations of TAP have been developed with other features. 670 Large scale studies on protein interactomes have also been achieved using AP-MS approach. The pioneering large scale work by AP-MS focused on the yeast system, 671-674 but other organisms have also been investigated, including Escherichia.coli, 562,675-676 and human. 677 Although AP-MS has potential for drawing the whole interactome map, results can contain both false positive and false negative interactors. False positives are mainly caused by nonspecific interactions, such as proteins binding to affinity matrices while false negatives are generally from weak interactions. If experimental conditions do not mimic the physiological conditions, weakened binding between interactors can be observed. Because removal of non-specific binding protein typically requires intensive wash steps, weak interacting proteins can be lost.\n\nUsing AP-MS, either in target or large scale studies, researchers have obtained valuable evidence on how proteins interact. This information can help us gain understanding of disease and biological process mechanisms, and the influenced pathways can provide promising targets for pharmaceutical discovery. Furthermore, the multiple interactors in a network may work together as diagnostic or prognostic biomarkers.\n\nMany comparative global proteomic studies seek to find the most relevant proteins in a biological process through expression changes upon perturbation. With enough relative protein change measurements, comparative analysis of entire biological systems can be performed. Proteomic systems analysis has been primarily driven by improvements in the comprehensiveness of quantitative analysis and the bioinformatics tools which facilitate these categorizations and comparisons. Quantification of protein expression and posttranslational modification changes on thousands of proteins consecutively allows for analysis of the entire system under either normal or perturbed conditions. In particular, pathway analysis tools such as Ingenuity have simplified these comparisons. A PubMed search with key words \"comparative\", \"proteomics\", and \"mass spectrometry\" yields almost 2,500 citations. This large number of publications is a representation of how prevalent and important these types of studies have become. Since this number of publications is surely outside the scope of this review we have attempted to list and briefly describe notable studies in a chronological fashion below. Phosphoproteomic-based systems based studies are described in the 'Investigation of signaling networks through phosphoproteomics\" section. These references should provide examples of the capabilities of shotgun proteomics in systems biology.\n\nIntegration of quantitative proteomics data with DNA microarray and protein interaction data from yeast initially demonstrated the ability to perform quantitative pathway analysis. 678 Nutrient limitation of yeast and comparison of transcript and protein expression data revealed alternative carbon source pathways are transcriptionally upregulated with reduced glucose, while nitrogen scavenging pathways are upregulated post-transcriptionally through more efficient translation and/or reduced protein degradation with reduced ammonia. 679 Application of absolute protein quantification measurements revealed protein abundance within prokaryotes (E. coli) is equally regulated between transcriptional and translational mechanisms while in eukaryotes (S. cerevisiae) > 70% is controlled by posttranscriptional, mRNA-directed mechanisms. 680 Subtractive proteomics on nuclear envelopes discovered new integral membrane proteins linked to dystrophies. 681 Comparative proteomic analysis of long-lived C. elegans mutants identified insulin signaling targets that modulate lifespan. 457 Comprehensive quantitative proteomics of haploid versus diploid yeast suggested efficient control of the pheromone pathway and mating response. 178 Proteomic analyses revealed evolutionary conservation and divergence of N-terminal acetyltransferases from yeast and humans. 682 Lysine acetylation was found to target protein complexes and co-regulate major cellular functions. 405 New roles for protein glycosylation were discovered in eukaryotes, namely mitochondrial protein function and localization, from global analysis of the yeast glycoproteome. 683 Three functionally different human cell lines were compared; large abundance differences from various functional protein classes were observed along with low abundance cell-type specific proteins and highly enriched cellsurface proteins. 684 Comparison of transcript and protein levels in yeast upon osmotic stress revealed transcript increases correlated to protein increases, but transcript decreases didn't affect protein abundance. 685 A quantitative comparison between human induced-pluripotent and embryonic stem cell lines found the majority of proteins (97.8%) unchanged, indicating differences are from experimental conditions and not molecular signatures; the 58 changed proteins were involved in metabolism, antigen processing, and cell adhesion. 686 Through systematic deletion of the two kinases, one phosphatase, and two N-acetyltransferases within Mycoplasma pneumonia, followed by proteomic analysis, the cross-talk between phosphorylation and lysine acetylation modifications and their roles in regulating protein abundance were demonstrated. 687 From these system-wide discoveries, there is no doubt that shotgun proteomics has become an essential tool in biological studies.\n\nSignal networks induced by various extracellular and intracellular signals are essential for regulation of cells and organisms; many diseases can occur due to malfunctions in signal pathways. In order to understand biology and pathology in cell systems, study of the mechanisms of signal networks is necessary. Regulation of post-translational modifications (PTMs), including phosphorylation, glycosylation, acetylation, ubiquitination, and methylation, is one of the major mechanisms in signal networks. For example, once binding of endogenous or exogenous ligands to membrane receptors has occurred, a signal can usually be amplified through a phosphorylation cascade, affecting the level of expression of various genes. In addition, a signaling network may be involved in crosstalk with other signaling networks.\n\nWestern blotting using specific antibodies has traditionally been performed for detection of these PTMs, with signal intensities from Western blotting as an estimation of changes to PTMs in a specific state. However, limitations to use of antibodies include nonspecificity of antibodies, variance in quantification, and absence of specific antibodies to specific proteins or PTM motifs. The advantages of methods recently introduced for mapping PTM with MS have been demonstrated, even though there are challenges to identification of modified peptides of low abundance and analysis of MS/MS spectra from complex data sets have been reported. 688,689 Below, we have described how various applications of MS-based shotgun proteomics are utilized for characterization of signal networks through PTMs. 6.3.1 Investigation of signal networks through phosphoproteomics-The first study of the global signaling network of epidermal growth factor (EGF) based on MS was reported in 2004. 690 In this study, the time course of EGF signals through their activation upon stimulation of epidermal growth factor was determined by identifying 81 signaling proteins and 31 novel effectors. In addition, 6,600 phosphorylation sites from 2,244 proteins showing dynamic regulation by EGF stimulation were found. 690 Several studies focusing on Tyr phosphorylation signaling have been reported for insulin stimulation, which plays an important role in control of glucose, and many new insulin-regulated substrates have been identified. 691 Similarly, Tyr phosphorylated proteins have been quantified in order to reveal signal networks of platelet-derived growth factor (PDGF) for proliferation of mesenchymal stem cells. 692 In addition, a SILAC-based study of the differentiation of human embryonic stem cells identified 3,067 phosphorylation sites. 693 A label-free quantification study of the effect of multiple tyrosine receptor kinases in growth of undifferentiated embryonic stem cells identified 2,546 phosphorylation sites. 694 Phosphoproteomic analysis of toll-like receptor (TLR)-activated macrophages confirmed canonical targets within the TLR pathway and identified the cytoskeleton and new signaling molecules as targets of phosphorylation. 695 Based on two different fragmentation methods, CID and ETD, more than 10,000 phosphorylation sites have been detected in embryonic stem cells. 696 In yeast, quantitative phosphoproteomics has been applied to the study of the pheromone signaling pathway and 139 of the more than 700 identified phosphopeptides were found to be differentially regulated. 697 In addition, findings from a study of MAPK pathways required for mating versus filamentous growth determined that Fus3 (mating-specific MAPK) can prevent crosstalk between the two pathways. 698 Recent work on the phosphoproteome of the yeast centrosome identified 297 phosphorylation sites from different cell cycle stages, and mutation studies of phosphorylated residues, identified by MS in Spc42 and \u03b3-tubulin, demonstrated the important roles of phosphorylation in the biology and function of centrosomes. 699 Through phosphorylation, protein kinases can affect the activity, cellular location, protein binding, and stability of proteins. The catalytic domains of most kinases are highly conserved and are involved in ATP binding and phosphorylation of target proteins; allosteric modulation of this catalytic domain is exerted through a regulatory domain. Based on substrate recognition sites, kinases can be categorized into two classes: Ser/Thr kinases and tyrosine kinases. Many global approaches to phosphorylation have been reported. However, due to low abundance of protein kinases, compared with their substrate proteins, phosphorylation studies of protein kinases have been underrepresented. 314, 315, 350, 700 Antibody-mediated purification of tyrosine phosphorylated proteins 692 and immobilized kinase inhibitors has been performed for concurrent enrichment of protein kinases. 701, 702 Use of kinase-selective affinity purification for the kinome approach across the cell cycle resulted in quantification of 219 protein kinases from S and M phase-arrested human cancer cells and also identified more than 1,000 phosphorylation sites on protein kinases. 703 Development of an integrated method termed KAYAK (Kinase ActivitY Assay for Kinome profiling) for large-scale kinase activity profiling using stable-isotope dilution and high resolution MS has been reported. 704 In this study, 90 site-specific peptide phosphorylations were measured, and the source of activity for a peptide derived from a PI3K regulatory subunit was identified, which was confirmed to be a novel Src family kinase site in vivo. 704 Throughput and multiplicity in this method was improved by assessing rates of phosphorylation for all 90 of the same peptides used previously in a single reaction. 705 The modified KAYAK strategy reports activation of cellular signaling pathways, including mitogen stimulation of HEK-293 and HeLa cells. In addition, combining single-reaction KAYAK with kinase inhibition enables resolution of pathway specificity. 705\n\nGlcNAc (\u03b2-O-linked 2-acetamino-2-deoxy-\u03b2-D-glucopyranose) modification plays an important role in signaling networks, including nuclear transport of cytosolic proteins, protein degradation, and tolerance of cellular stress. This modification is reversible and is controlled by two enzymes, O-GlcNAc transferase (OGT) and O-GlcNAcase (OGA). 706 O-GlcNAcylation competes with phosphorylation at the same serine/threonine sites or at proximal sites on some proteins. O-GlcNAc modification is a low abundance and labile modification, therefore, detection of the structure of glycans and of modification sites on proteins using traditional mass spectrometric methods is difficult. For identification of O-GlcNAcylated proteins or modification sites, a number of enrichment strategies have been employed including: O-GlcNAc specific lectin succinyl wheat germ agglutinin (sWGA), 707 immunoprecipitation using O-GlcNAc specific antibody, 708 peptide tagging with BEMED (\u03b2-eliminated followed by Michael addition with dithiothreitol), 709 chemoenzymatic tagging-enrichment strategy, 710 and a photocleavable biotin-alkyne reagent (PCbiotinalkyne) tag. 711 In studies to determine a dynamic relationship between O-GlcNAcylation and GSK-3 dependent phosphorylation, at least 10 proteins showed increased O-GlcNAcylation upon GSK-3 inhibition by lithium, whereas 19 other proteins showed decreased O-GlcNAcylation. 712 To examine the effect of site-specific phosphorylation dynamics on globally elevated O-GlcNAcylation, sequential phosphopeptide enrichment was combined with iTRAQ labeling which resulted in the quantification of 711 phosphopeptides in NIH3T3 cells. 713 According to finding from these studies, cross-talk between two major PTMs is extensive; this result may be due to both steric competition of occupancy at the same or proximal sites and regulation of the other's enzymatic activity. In addition, regulation of activities of Calcium/calmodulin-dependent kinase IV (CaMKIV) and IKappaB kinase (IKK) by O-GlcNAc modification has been reported. 714, 715 Pharmacologically or genetically induced increases in O-GlcNAc resulted in severe defects in mitotic progression and cytokinesis. 716, 717 These data clearly exemplify the importance of the interplay between O-GlcNAcylation and phosphorylation in cellular signaling pathways.\n\nUbiquitination (Ub), conjugation of Ub to the 3-amino group of a lysine in a substrate protein, is involved in regulation of various cellular pathways, including signal network, protein degradation, and cell division. While mono-Ub is related to ligand-mediated endocytosis, poly-Ub is related to the proteasome pathway for protein degradation. Using quantitative MS, identification and quantification of various forms of Ub bound to EGFR have been achieved using the Ub-AQUA method. This result demonstrated that more than 50% of all EGFR bound Ub was a poly-Ub form, which was targeted to the lysosome. 718 Cyclin B1 is also modified by Ub chains of complex topology, rather than by homogeneous Lys 48-linked chains, and is degraded by the 26S proteasome. 719 Methylation and acetylation of histones is known to be part of an epigenetic marking system using different combinations of histone modification for control of gene expression. 720, 721 Findings from SILAC-based proteomic analysis in breast cancer cells treated with a histone deacetylase (HDAC) inhibitor showed induction of lysine acetylation in chromatinassociated proteins as well as non-histone proteins, including transcriptional factors, chaperones, and cell structure proteins. 722 Regulation of EGFR trafficking by lysine deacetylase HDAC6 through control of acetylation of alpha-tubulin has been reported. 723 S-nitrosylation, modification of cysteine thiol by a nitric oxide (NO), is emerging as an important PTM involved in regulation of cell signaling. 724 Due to the labile nature of the S-NO bond, detection of S-nitrosylated proteins is difficult, because it is frequently lost during sample preparation. Several methods, including the biotin switch assay and the chemical reduction/chemiluminescence assay, have been developed. 725, 726 The biotin switch method converts S-nitrosylated Cys to biotinylated Cys. This method has been used for identification and characterization of S-nitrosylated proteins in Arabidopsis plants, resulting in identification of 63 proteins from cell cultures and 52 proteins from leaves as candidates for S-nitrosylation, including signaling, redox-related, and stress-related proteins. 727 Classical biochemical studies using antibody-based approaches to conduct unbiased largescale studies of various extracellular and intracellular signals are limited. Because regulation of many proteins occurs after transcription of genes, global MS-based PTM proteomics enables system-wide characterization of signaling networks and complements gene expression analysis.\n\nWith modern mass spectrometers and quantitative methods, large scale and targeted protein information is obtainable, including measurement of quantitative protein abundance levels and protein modifications. However, current methods only provide a 'snapshot picture' of a cellular state at the time that sampling occurs. Protein abundance and modification are both highly dynamic and tightly regulated. Measurement of the dynamics of a proteome may provide critical answers for many biological questions. It has been shown that there is a poor correlation between mRNA and protein levels, 678, [728] [729] which may be partly explained by the protein synthesis/degradation rate. Moreover, protein turnover information can also be valuable as a biomarker. Since protein quantity is determined by synthesis and degradation rates, a change in protein turnover rates may precede a change in protein expression level. Several studies have observed significant changes in protein turnover but smaller changes on protein expression. [730] [731] Protein turnover analysis is not a new idea, and can be dated back to 1930's. 732 A typical turnover study involves administering either radioactive or stable isotope labeled tracers, which are incorporated into the protein synthesis. The resulting labeled proteins can be captured and determined by either scintillation counting or mass spectrometry. The classic 'pulse-chase' strategy uses radioactive isotopes to partially label proteins in a 'pulse' period, and measures their decay during the 'chase' period, when the non-radioactive isotope is applied. The advantages of this platform are that it only requires labeling part of a protein, and only the labeled fraction is measured along the time course. However, this method is more suitable for assessment of the average decay rate for all proteins in a biological system. Individual protein turnover information can only be obtained by protein purification, which limits the throughput of this method.\n\nBesides isotope tracers, there are other methods developed for protein turnover or stability studies. One strategy is to inhibit the protein biosynthesis using cycloheximide. 733 The protein degradation rates can be assessed by protein band intensities during the time course of cycloheximide treatment because there is no newly synthesized protein during this period. This method is usually used for the measurement of one or a limited number of proteins, since western blot is a low-efficiency detection assay. Recently, this strategy was scaled up to nearly 4,000 proteins by using a collection of yeast strains expressing tandem affinity purification (TAP) tag 733 (Figure 12) , which was universally used for target in immunodetection. One drawback of this method is that the inhibition of protein synthesis may greatly influence the biological nature of cells, and further change protein stability. Other newly developed methods rely on the libraries of clones expressing different proteins tagged by fluorescence. [734] [735] These methods indeed make protein turnover analysis possible on a large scale. However, the establishment and utilization of such engineered libraries are time and labor intensive processes and it is still quite challenging to apply this method to all organisms, especially mammals.\n\nAs discussed above, radioactive labeling, protein synthesis inhibition, and fusion protein libraries all have benefits and shortcomings for protein dynamics studies. Alternatively, several MS and stable isotope based approaches have emerged to explore protein turnover on a large scale for both single cell systems and animals. Compared with the radioactive isotope 'pulse-chase' method, a stable isotope labeling turnover experiment typically only includes a 'pulse' phase. This means that upon switching the medium/diet, the organism is only grown in an isotope-enriched environment until the sampling time points. The ratios between unlabeled and labeled peptides are used to interpret the protein turnover rates.\n\nThe most common type of protein turnover study is carried out on a single cell system, such as a cultured cell line. In this case, the design of the experiment is relatively straightforward: the protein synthesis precursor pool is principally composed of the amino acids from the medium. A switch of medium from an unlabeled to a labeled state or vice versa results in a rapid incorporation of isotopes in the newly synthesized proteins. In other words, almost all the newly synthesized proteins generated after the medium change will be labeled with the same relative isotope abundance (RIA) as is present in the medium. Data analysis is straightforward because the two groups of proteins, pre-existing and newly synthesized, both have defined RIA and predictable mass spectrometry distribution. 736 An example of this method used the pulsed SILAC (pSILAC) approach to show the influence of microRNAs on protein synthesis. 737 miRNA transfected and control Hela cells were subjected to either medium-heavy or heavy SILAC medium in the pulse. The mass spectrometry peak abundances of medium-heavy or heavy groups, representing the newly synthesized proteins, were used to compare the protein synthesis. More than 3000 proteins were quantified on their synthesis level, and hundreds of genes were observed to be directly repressed by microRNA. Another study employed a triple-SILAC method to measure protein synthesis and degradation on 8,041 Hela cell proteins. 738 However, this strategy cannot be easily adapted to whole animal studies because the change of dietary isotope does not lead to a sudden and complete labeling of the precursor pool. Incomplete labeling results from the breakdown and re-use of unlabeled amino acids in protein recycling. For animals, such a rapid precursor pool change can only occur via intravenous injection of the isotope tracer by either continuous infusion [739] [740] or a flooding dose. 741 Alternatively, oral administration of stable isotope labeled water, 2 H 2 O or H 2 18 O, 742 also achieves fast equilibration between body water and free amino acid. The limitation of these methods is that measuring protein turnover of individual proteins in a high throughput manner is not always possible due to its low overall RIA. Two recent studies have used this water strategy, measuring the protein turnover on a global scale. [743] [744] Next, the sudden intake of the isotope tracer by intravenous injection may alter protein synthesis and lead to artificial protein turnover results, 745 and the hydrogen/ deuterium exchange is reversible and can result in a back-exchange from deuterium to hydrogen during sample preparation in aqueous solvents. [746] [747] Furthermore, the water method relies on the analysis of a minor isotopic peak pattern change, which could be easily influenced by error in the ion intensity measurement. To avoid these complications the isotope tracer can be administered more naturally via the diet [748] [749] with fewer side effects. The major challenge here is that the protein synthesized during pulse phase will be labeled to varied isotope extents since the precursor pool will saturate gradually. In one study, chicken was chosen because of its continuous diet intake which leads to a quick increase and plateauing of precursor RIA that subsequently remains constant. 748 However, this method is not applicable to other mammals, including mice.\n\nTwo recent independent studies have employed similar 15 N labeled diets to determine the protein turnover in mice at the proteome scale. [749] [750] Both groups switched the normal diets of the mice to a 15 N labeled diet at a given time point and analyzed the protein samples after different feeding times, ranging from a half day to several weeks. They then measured the ratio between unlabeled and labeled peptides derived from the brain and plasma proteins. The ratio of the unlabeled/labeled peptides reflects the abundances of pre-existing and newly synthesized proteins ( Figure 13 ). Both studies revealed the mouse protein turnover information on a large scale. For quantification purposes, special algorithms were developed for data interpretation, as the partial 15 N labeled peptides generated complicated isotopic peak distribution. Price et al tried to define the 15 N incorporation rates of all newly synthesized peptides. 750 The observed 15 N peptides were a heterogeneous group synthesized from a time window with varied incorporation rates. Furthermore, the 14 N and 15 N peptides are most likely to overlap with each other when the precursor RIA is low (Figure 13b-c) . Zhang et al. avoided the requirement for the knowledge of labeling incorporation rates and complete separation of the tryptic peptides, providing a straightforward data processing platform. 749 In both studies, an 15 N diet was used instead of a SILAC diet to determine protein turnover in mammals because if a SILAC diet was used, part of the newly synthesized SILAC peptide would appear in the unlabeled isotope pattern unless the precursor is fully labeled, making it impossible to distinguish between the two with MS. Although the newly synthesized SILAM peptides may also appear at a low incorporation rate shortly after the labeling, it is still possible to separate it from the pre-existing unlabeled peptide. The 15 N-labeled tracer, present in all amino acids, significantly amplifies protein labeling efficiency ( Figure 13 ). For instance, if a protein is synthesized in a 20% labeled precursor pool, SILAC will have 80% of total newly synthesized peptides appearing in unlabeled form, whereas SILAM will have little chance of generating totally unlabeled peptides, because all the 20 amino acids are labeled.\n\nThe order of isotopic treatment is not critical, since newly synthesized peptides can be detected as either heavy or light. Both will lead to equivalent results. However, since fully labeling an organism consumes a great deal of time and money, it is generally preferable to start with peptides in an initial condition of natural isotope, followed by partial heavy isotope labeling. Recently, a reverse strategy was conducted in rat to study extremely longlived proteins which may provide insight into cell aging and neurodegenerative diseases. 751 The rats were fed a 15 N diet starting in utero. After the labeling efficiency reached 100%, the food supply was switched to standard 14 N. After 12 months, almost all the proteins had been resynthesized with natural isotope composition and any remaining 15 N peptides represented the initially synthesized proteins. These long-lived proteins were found to be related to the nuclear pore complex, the central transport channels that mediate all molecular trafficking in and out of the nucleus. Clearly, the reverse-labeling method was more suitable for this study, since it did not require long term (12 months) isotope feeding and avoided any confusion caused by 14 N peptide contamination which comes from other sources, such as keratin. In another study, researchers used multi-isotope imaging mass spectrometry, together with 15 N-labeling, to reveal that the stereocilia were generally remarkably slowly turned over, but a rapid turnover was found only at the tips of stereocilia. 752 With current MS-based strategies, decoupled protein synthesis and degradation rates cannot be easily measured simultaneously, because the quantitative measurements only represent the relative abundance, not the absolute abundance. The ratio between unlabeled and labeled isotope peaks can be affected by any change in pre-existing and newly synthesized proteins and the turnover rate measured describes the relative change between protein synthesis and degradation. Currently, the fractional turnover rate calculation is based on the assumption that the protein is in steady-state (i.e. the protein has equal rates for synthesis and degradation), is not always true.\n\nRecent advances in MS-based proteomics have made it an indispensable tool for use in the clinic. The goal of clinical proteomics is the identification of disease-specific biomarkers using clinical samples, such as plasma and tissues from patients. Identification of useful biomarkers of disease should provide a better chance for early diagnosis, optimization of treatment, and means for monitoring progress during treatment. To increase the chance for identification of biomarkers, MS-based proteomics technologies that enable identification of a large number of proteins with high throughput using small amounts of materials have been developed. Clinical proteomics using the latest proteomic technologies in conjunction with advanced bioinformatics is currently being used for identification of molecular signatures of diseases based on protein pathways and signaling cascades, and holds great promise for the future of medicine.\n\nbiomarker is a substance used as an indicator of normal biological processes, pathogenic processes, or pharmacological responses to a therapeutic invention. 753, 754 A biomarker can be a traceable substance used for examination of change in expression of a protein that reflects the risk or progression of a disease, or the susceptibility of the disease to a treatment. Serum markers, such as prostate-specific antigen (PSA) for prostate cancer, C-reactive protein (CRP) for heart disease, CA-125 for ovarian cancer, and CA 19-9 for colorectal and pancreatic cancer, are currently being used; however, they do not show sufficient sensitivity or specificity for early detection. Ideally, a unique biomarker for each disease should have the capacity for diagnosis of patients who do not have specific symptoms. Development of biomarker panels comprised of several proteins could result in improved detection and clinical management of various patients and provide higher sensitivities and specificities than a single protein biomarker.\n\nBlood is in contact with virtually all cells of the organism; therefore, it is considered the optimal source for discovery of biomarkers. As a source of biomarkers, blood is easily accessible, and its collection is low risk and relatively noninvasive. Release of tissue-related proteins into the blood stream occurs through a specific secretory mechanisms, either shedding from the cell surface or nonspecific leakage. 755 As an alternative to blood, other biofluids, including urine, cerebrospinal fluid, pancreatic juice, nipple aspirate fluid, and bile can be used. Urine is a common source for discovery of biomarkers (for urogenital disease as well as non-urogenital) due to its simple and noninvasive collection. 756 Urinary exosomes, endogenous microparticles identified in urine, have been shown to be a source for urine biomarker discovery using LC-based proteomics. 757, 758 Cerebrospinal fluid can be used for discovery of biomarkers for disease of the central nervous system. 759 Pancreatic juice is used for non-invasive diagnosis of pancreatic cancer. Nipple aspirate fluid, found within the ductal and lobular system in nonpregnant and non-lactating women 760 has been used in proteomic analysis of breast cancer. 761 Proximity of bile to the biliary tract makes it important for study of cholangiocarcinoma, a primary cancer that arises from biliary epithelial cells; secreted or shed proteins in bile can be relevant for its study. 762 Use of tumor tissues as a source of biomarkers is crucial for cancer biology. While the use of tumor tissue is limited by the small size of sample collected, the advantage of using clinical samples for biomarker discovery is that normal tissue from the surrounding area of the tumor can be used for paired analysis. Laser Capture Microdissection (LCM) has been employed to reduce the heterogeneity in human tumor tissues used in oncoproteomics studies. 763 Recent work to extract intact proteins from formalin fixed and paraffin-embedded (FFPE) tissues has provided a huge potential for conduct of biomarker studies using millions of stored specimens. 764\n\nThe complexity of the serum proteome presents a broad range of technical limitations for its use in clinical proteome analysis. Plasma proteins show a dynamic range of 10 orders of magnitude in concentration from albumin to the least abundant proteins. 55 Fortunately, clinical proteomics research has benefitted from development of various fractionation techniques and sensing approaches for management of the complexity of proteins and dynamic range in serum samples, 765, 766 further described in the \"Protein depletion and equalization methods\" section. One strategy designed to overcome the issue of dynamic range coupled protein prefractionation with depletion methods for removal of abundant proteins in plasma proteomes. Several approaches can be used for removal of abundant proteins from plasma. One approach involves the use of immunoaffinity columns such as top-12 and top-14 IgY depletion columns. 767 Most protein biomarkers used clinically, such as PSA, CA125, and CEA, are glycosylated. 768, 769, 770, 771 Alteration of cellular glycosylation is known to occur in association with different disease states. 772 There has been a great deal of work in discovering new potential markers using the shotgun method based on glycopeptides/ glycoproteins or glycans structures, especially in the cancer area. In the study of glycoproteins using proteomic approaches, various types of lectin chromatography are known to be capable of enriching glycosylated proteins from complex matrices 387 and a covalent method for capture using hydrazide is used for capture of glycoproteins/ glycopeptides. 773 In addition, a combination of titanium dioxide chromatography with HILIC showed selective enrichment of sialic acid-containing glycopeptides. 774 Recently, MS-based analysis of glycopeptides generated from immobilized-Pronase digestion has been enhanced by sensitive and reproducible chip-based porous graphitized carbon (PGC) nano-LC. 775 Simultaneously, the shotgun method based on glycans structures has been developed to discover new potential markers, especially in the cancer area. Two methods, compositional mass profiling and structure-specific chromatographic profiling, are currently used for comprehensive analysis of glycans. For compositional mass profiling method, Lebrilla's group has reported extensively on the application of a MALDI-MS based glycomics platform to discover glycans biomarkers of various cancers. [776] [777] [778] To differentiate or distinguish between glycans isomers, a method for structure-specific chromatographic profiling of glycans has been introduced [779] [780] These studies utilize structure-sensitive chromatography, such as PGC and HILIC, to separate glycans online prior to MS analysis. Recently, a microfluidic chip packed with graphitized carbon was used to chromatographically separate the glycans and 300 N-glycan species were identified from serum samples of prostate cancer patients. 781 Meanwhile, O-glycan structures of MUC1, a cell-surface glycoprotein, in breast, prostate, and gastric cancer samples have been determined by LC-MS/MS. 782 Software to analyze tandem spectra of oligosaccharides has been developed. For N-linked glycans analysis, GlycosidIQ 783 including only known glycans in its library, and GlycoFragment/GlycoSearchMS 784 including hypothetical glycans structures have been developed. Recently, GlycoWorkbench 785 was designed specifically to assist those with greater knowledge of glycans MS with annotation of glycans fragment spectra. Moreover, Cartoonist Two 786 was developed for interpreting tandem spectra of O-linked glycans.\n\nDifferent sample processing techniques, such as size fractionation, protein A/G depletion, and magnetic bead separation (C3, C8 and WCX), are known to be effective for reduction of the dynamic range and complexity of serum samples. 787, 788 Evolution of a combination of separation, detection and labeling strategies has enhanced possibility for sensitive, multiplexed detection of low-abundance disease-specific protein biomarkers in serum samples.\n\nProteomics has been used widely for identification of biomarkers of various diseases, including cancer, autoimmune disease, and infectious disease. In a gel-based proteomic study, increased expression of epidermal fatty acid binding protein 5, methylcrotonoyl-CoA carboxylase 2, palmitated protein A2, ezrin, and stomatin-like protein 2, and decreased expression of smooth muscle 22 were identified as diagnostic markers associated with lymph node metastasis in prostate cancer. 789 2-D DIGE and MALDI-ToF MS were used for detection of potential serological biomarkers, S100A8 and S100A9 (Calgranulin A and B), in colorectal cancer. 790 In an experiment for discovery of biomarkers for head-and-neck squamous cell carcinoma, 4-plex iTRAQ was used for comparison of paired and non-paired non-cancerous samples with cancerous tissues. 791 iTRAQ has also been used to study of cancer angiogenesis, metastasis, epithelial mesenchymal transition, cancer therapy resistance, and cancer secretome. In another study, sera of patients with colorectal cancer were investigated using LC-MS/MS; growth/differentiation factor 15, divergent member of the transforming growth factor-beta superfamily, and trefoil factor 3, which is secreted from goblet cells of the gastrointestinal tract with mitogenic and antiapoptotic activity, were identified as potential biomarkers for early diagnosis of colorectal cancer. 792 Performance of serum profiling using proteomics has resulted in identification of biomarkers for many autoimmune diseases, including systemic lupus erythematosus (SLE), 793 rheumatoid arthritis (RA), 794 multiple sclerosis, 795 and Crohn's disease (CD). 796 In addition, use of serum profiling has also resulted in identification of biomarkers for many other human diseases, including stroke, 797 nonalcoholic fatty liver disease (NAFLD), 798 diabetic nephropathy, 799 Down syndrome (DS), 800 sarcoidosis, 801 and graft-versus-host disease. 802 The Van Eyk group has performed extensive work in the area of proteomics for predicting heart attacks. [803] [804] In addition to cancers and autoimmune disorders, serum proteome analysis has also provided biomarkers for many infectious diseases, including tuberculosis, 805 severe acute respiratory syndrome (SARS), 806 and hepatitis. 807 Most of proteins listed in this section are putative biomarkers and have not been rigorously verified.\n\n6.5.3-MS based proteomics holds special promise for identification of biomarkers that can be used for blood tests. However, as shown in Figure 14 , only a small number of bloodbased biomarkers have been qualified or verified, 808 and even fewer have been validated (which requires larger groups of patients for testing of the proposed biomarker) 809 because current proteomics methods present several bottlenecks for analysis of large numbers of samples. Verification of biomarkers can require 100 -1,000 samples, whereas validation of biomarkers requires analysis of even larger numbers (thousands to tens of thousands). 808 The same assays are used for verification and clinical validation of biomarkers. 810 Due to high throughput and high sensitivity for quantification of proteins, ELISA is regarded as a general assay method. However, development of an ELISA method for one biomarker candidate is expensive and requires more than one year, and specific antibodies are sometimes unavailable. 811 Due to its multiplexibility, specificity, and sensitivity, MRM can also be used for validation, large-scale validation, or validation for subsequent analysis. 812 In addition, using MRM, reproducibility can be maintained across multiple laboratories. Monitoring initiated detection and sequencing-multiple reaction monitoring (MIDAS-MRM) allows for rapid and cost-effective absolute quantification and validation of biomarkers without the need for antibodies. 813 As examples of high-throughput MRM analysis using clinical samples, MRM-MS was applied to verify 12 target proteins for diabetic retinopathy using 3 groups of vitreous and plasma samples from 3 different stages of patients. 814 Kuzyk et al. demonstrated the rigorous MRM quantification of the 45 endogenous plasma proteins with 31 of these being putative biomarkers of cardiovascular disease. 815 This study was done without sample enrichment or fractionation in a single 45 min MRM analysis, in combination with stable-isotope labeled peptide standards. To improve the limit of quantification, MS3 fragment ions were monitored instead of MS2 fragment ions for SRM transitions, termed MRM 3 . 816 It was demonstrated that this method could show 3-to 5-fold improvements in limit of detection using 5 model proteins and detect protein biomarkers at the low ng/mL level in nondepleted human serum. 816 In addition, coupling a nanospray ionization multicapillary inlet/dual electrodynamic ion funnel interface to a commercial triple quadrupole mass spectrometer improved ion transmission efficiency that increased b\u1ef9 70-fold of average MRM peak intensities. 817 Various software related to MRMs has been developed to facilitate surrogate peptide determination and data processing. The commercial software include Pinpoint from Thermo Scientific and MultiQuant from AB Sciex for their TSQ and QTRAP mass spectrometers, and the open source software includes Skyline 502 and MRMer. 818 Methods such as SISCAPA (Stable Isotope Standards and Capture by Anti-Peptide Antibodies) and PRISM (high-pressure, high-resolution separations coupled with intelligent selection and multiplexing) have been introduced as alternative versions of MRMs. SISCAPA 819-820 uses a combination of bead-based affinity co-capture of native and SIS peptides, and their relative amounts are quantified by MRM-MS. SISCAPA has been shown to increase the sensitivity of MRM-MS by 1,800 and 18,000-fold for selected tryptic peptides of alpha(1)-antichymotrypsin and lipopolysaccharide-binding protein, respectively. 821 Recently, a group developed an antibody-free strategy that involves PRISM for sensitive SRM-based targeted protein quantification. This approach demonstrated accurate and reproducible quantification of proteins at concentrations in the 50-100 pg/mL range in human plasma/serum. 822 Prospects Despite the discovery of many new potential markers using proteomics, only a few biomarkers have been developed into clinical applications for disease screening and patient monitoring and approved by the FDA. 823 OVA1, the first biomarker identified through proteomics, has recently been approved by the US FDA. OVA1 uses the in vitro diagnostic multivariate index assay (IVDMIA), which includes five biomarkers for assessment of ovarian cancer risk in women diagnosed with ovarian tumors prior to a planned surgery. The experience with development of the first FDA-cleared biomarker has demonstrated that the path from discovery, validation, to clinical use of a biomarker is long and arduous and that proper study design and development of assays that employ robust analytical methods suitable for large-scale validation are needed. Recent advances in MS-based proteomics technology with sensitive and accurate MS technology, innovative bioinformatics, and MRM methods will support each step in biomarker development, from discovery to clinical application.\n\nMass spectrometry-based methods to analyze and identify proteins are clearly a powerful approach to study biology. Initial uses of the technology simply involved common experiments such as analyzing proteins separated by gel electrophoresis. These experiments quickly evolved into approaches to directly identify proteins in complexes and then new types of experiments were developed such as methods to identify the topology of proteins embedded in lipid bilayers. As a powerful 'hypothesis-generating engine', 19 shotgun proteomics has shed light on many different biological processes. Large-scale studies, including both protein expression and PTM characterizations enable us to have a systematic picture of all the expressed proteins in biological networks. Additionally, targeted studies are gaining use as a way to answer specific biological questions using MS-based technology. Mass spectrometry complements traditional biochemistry and molecular biology techniques for both biological discovery and validation and its role in biology has dramatically expanded.\n\nBeyond the initial biological experiment the shotgun proteomic process consists of 4 steps and it is at each step where improvements in technology or methodology can be realized to improve the overall process. As shotgun proteomics requires the digestion of complex mixtures of proteins, the proteolysis of proteins is a crucial first step of the process. The success of a shotgun analysis is thus dependent on efficient and complete digestion of proteins as this can lead to high sequence coverage. Not surprisingly there have been several studies to optimize the process and to improve the analysis of recalcitrant proteins such as membrane proteins. 824 Membrane proteins are a class of proteins that can be difficult to digest because most of the protein is embedded in a lipid bilayer. This attribute of membrane proteins has been exploited by Blackler et al to better identify membrane proteins. 825 Proteinase K is used to digest exposed protein regions in the lipid bilayer and peripheral membrane proteins. Once the digestion is complete the solution is centrifuged to remove peptides from the solution. The transmembrane regions of the membrane proteins precipitate with the lipid bilayer. These polypeptides are then digested with cyanogen bromide since many of these regions have methionine located in these segments. As these peptides are often hydrophobic, Blackler and Wu showed much improved separation and recovery of these peptides by using liquid chromatography at elevated temperature. 184 The interesting aspect of this method was the improved specificity for detection of membrane proteins, which can be difficult to achieve as proteins can stick to the lipid bilayer or get denatured during the cell lysis procedure. Methods have also appeared to improve the digestion of proteins or to preferentially digest and deplete proteins based on abundance. 65, 81 The state of sample preparation is good, but there can always be improvements especially on methods to improve digestion of low abundance proteins.\n\nA critical function of peptide separations is to reduce ion suppression, increase dynamic range, and minimize isobaric interferences. The digestion of whole cell lysates can potentially produce 100,000's of peptides over a wide range of abundances, isoelectric points, and hydrophobicities. These peptide mixtures need to be separated to avoid the simultaneous introduction of large numbers of peptides into the mass spectrometer, which would compromise dynamic range and recovery by suppressing the ionization of peptides. To this end, much emphasis has been placed on creating separation strategies to fractionate complex mixtures of peptides. Most strategies combine different separation techniques together to create multidimensional methods although reversed-phase HPLC is generally the method used to introduce peptides into the mass spectrometer. Offline strategies of gel electrophoresis, isoelectric focusing, chromatofocusing and HPLC have been used at the protein level to reduce the complexity of protein mixtures. Isoelectric focusing and ion exchange methods have been employed to prefractionate peptides in an offline manner. Ion exchange has been combined with reversed-phase HPLC to effect multidimensional separations both online and offline. While efforts to push single dimension separations to achieve sufficient resolution and peak capacity to resolve 100,000's of peptides are underway, they are unlikely to achieve the peak capacity of multidimensional separations.\n\nDespite the maturity of mass analyzers the last decade has seen significant innovation. Time-of-Flight mass analyzers have continued to evolve in terms of resolution and scan speed. MALDI-ToF methods have seen a drop in use in proteomics in favor of tandem MS methods in which the ToF is often combined with quadrupole mass filters. The last decade saw significant innovations in the development of the linear ion trap, which increased the ion capacity of ion traps and improved performance. The big innovation for proteomics was the optimization and development of the Orbitrap mass spectrometer. 241, 826 While this device has been around for many years, it took the invention of methods to inject ions into the device and the development of Fourier transform methods to record ion currents to create a powerful high resolution, high mass accuracy mass analyzer. The other older mass analyzer experiencing a renaissance was the ion mobility device. 827 Ion mobility separates by both m/z and molecular shape and thus can be useful to provide a separation method prior to mass analysis. It is potentially a good strategy to fractionate ion populations using a gas phase method prior to tandem mass spectrometry of individual ions. A clear advantage to doing this by ion mobility is the much faster time frames for ion separation versus chromatographic methods, but fractionation of the ion population has to occur with reasonable resolution to minimize ion dilution. Ultimately, tandem mass spectrometers should be able to completely sample the population of peptide ions in a reasonable amount of time.\n\nAn essential component of shotgun proteomics is software to interpret the data. The basic framework for large-scale analysis of tandem mass spectrometry data is completed. Software tools are available, efficient and reasonably accurate for the analysis of shotgun proteomic data. 543 There is concern that some tools over-fit data or use filtering criteria that don't meet community standards, but in general results are excellent when community standards are followed. 44, 828 Additional capabilities will derive from software tools that aid in the identification of mutations, de novo analysis, and the identification of heavily modified peptides. As dissociation methods are better able to fragment larger polypeptides, tools to dissect out the combinations and patterns of modifications will improve. Software tools for the analysis of quantitative data are improving and many tools are able to analyze most of the different quantitative strategies that have been developed. An area that will see more activity is data-independent acquisition (DIA). 233, 829 As detection limits improve in mass spectrometers it is increasingly difficult to cleanly isolate and fragment a unique peptide ion (isobaric interferences) and consequently methods have been developed to acquire multiple precursor ions simultaneously for fragmentation. Software tools to deconvolute and analyze the data have been developed, but more tools are needed especially as people innovate with new methods and experiments for DIA.\n\nAs mass spectrometers have improved for the analysis of intact proteins, increasingly shotgun proteomics will be combined with \"top down\" analysis to develop a more complete picture of the proteoforms for a protein. The dissociation methods such as ETD and ECD will allow the fragmentation of larger polypeptides, which can fill the middle space between bottom up and top down. In the past decade, the development of mass spectrometers designed for peptide/protein complex analysis has advanced rapidly, mostly in mass accuracy and sensitivity. However, there is still room for further improvement. Deep proteome discovery will require enhanced signal sensitivity for low abundant peptides in samples with large dynamic ranges. Direct detection of large or modified peptides/proteins will require innovations in fragmentation and ionization methods to improve spectra quality. In addition to improvements to the mass spectrometer, advances in the techniques involved in sample preparation, fractionation, or enrichment prior to MS and data processing after MS will also enhance the role of proteomics in biology. (2002) (2003) (2004) (2005) . During the periods, he has studied on traditional proteomics using various mass spectrometries and also developed a fusion technology bridging between cell biology and proteomics. He is currently an associate professor at School of Medicine of Kyungpook National University, Korea and has focused on the identification of biomarker candidates for kidney diseases, drug-induced liver injury, and cancer diseases by developing various proteomics technologies including glycoproteomics, membrane proteomics as well as enrichment technologies for clinic specimen (especially microvesicles) analysis.\n\nDr. Yates is a Professor in the Department of Chemical Physiology at The Scripps Research Institute. His research interests include development of integrated methods for tandem mass spectrometry analysis of protein mixtures, bioinformatics using mass spectrometry data, and biological studies involving proteomics. He is the lead inventor of the SEQUEST software for correlating tandem mass spectrometry data to sequences in the database and principle developer of the shotgun proteomics technique for the analysis of protein mixtures. His laboratory has developed the use of proteomic techniques to analyze protein complexes, posttranslational modifications, organelles and quantitative analysis of protein expression for the discovery of new biology. Many proteomic approaches developed by Yates have become a national and international resource to many investigators in the scientific community. Dr. Yates led an NIDCR funded Center to characterize the Saliva proteome and has been involved in an NCRR funded Research Resource Center for the last 15 years and was involved in an NSF funded Science and Technology Center for 10 years. He has received the American Society for Mass Spectrometry research award, the Pehr Edman Award in Protein Chemistry, the American Society for Mass Spectrometry Biemann Medal, the HUPO Distinguished Achievement Award in Proteomics, Herbert Sober Award from the ASBMB, and the Christian Anfinsen Award from The Protein Society. He has published 580 scientific articles. Proteomic strategies: bottom-up vs. top-down vs. middle-down. The bottom-up approach analyzes proteolytic peptides. The top-down method measures the intact proteins. The middle-down strategy analyzes larger peptides resulted from limited digestion or more selective proteases. One or more protein or peptide fractionation techniques can be applied prior to MS analysis and database searching. Diagrammatic summary of LIT-and Orbitrap-based mass spectrometers for proteomics. All but the IR fragmentation (orange box) is commercially available either as a single mass spectrometer or a combination of some essential components. Peptides are electrosprayed direclty from a LC separation into the heated inlet source where desolvated peptide ions are focused by a stacked ring ion guide (S-lens), then focused, filtered (typically 300-2000 m/ z), and transferred by the square quadrupole and octapole to the dual LIT. Peptide ions are collected, isolated, and fragmented by CID in the high pressure cell. Isolated precursor and fragment ions are passed to the low pressure trap for detection. This sequence of events is currently considered a state-of-the-art LIT experiment primarily for protein identification and label-free protein quantification. For higher resolution and mass accuracy detection, precursor or fragment ions can be passed to the Orbitrap mass analyzer via the second quadrupole and C-trap. Beam-type collision can be performed in the HCD collision cell instead of the ion trap for detection with Orbitrap. The Orbitrap detects ion currents of peptide ions that process around an orbital electrode. A Fourier transform is used to convert the frequency-based ion current to a m/z value. Either of these fragmentation schemes with Orbitrap detection are considered state-of-the-art for high mass accuracy peptide analysis and are most often used for protein and post-translational modification identification and quantification with isotopic labeling. Alternative fragmentation methods of ETD, IRMPD, or the combination IR-ETD can be used in conjunction with either the LIT or Orbitrap mass analyzers. The simplest configuration most recently demonstrated is a Q-Orbitrap with HCD detection which consists of only the S-lens, quadrupole mass filter, C-trap, Orbitrap, and HCD collision cell. This configuration and experiment design is quite similar to the QToF illustrated in Figure 3 . Schematic diagram of a QToF. The QToF allows for consecutive precursor mass filtering and fragmentation, an essential for shotgun proteomics which measures both intact and fragment ion masses of peptides. Essentially the instrument is a high mass accuracy QQQ frequently used in proteomics for targeted protein quantification experiments. Peptide ions from electrospray ionization are continuously focused by a Q jet ion guide, accelerated through quadrupole zero (Q0), Q1, and the collision cell for precursor peptide mass detection by time-of-flight and multichannel time-to-digital conversion (TDC) detector. Subsequently, abundant precursor ions can be selected by Q1 and fragmented in the collision cell prior to orthogonal acceleration for ToF detection. Common peptide fragmentation methods. Peptides are cleaved along the peptide backbone to sequence the peptide. CID/CAD entails acceleration of the kinetic energy of ions to promote energetic collisions with a target gas, thus causing conversion of the ion's kinetic energy to internal energy and ultimately resulting in ion fragmentation. Most fragmentation pathways rely on proton transfer. For trapping instruments that employ resonant excitation, the waveform used to accelerate a precursor ion is specific for a particular m/z value, thus only the selected precursor ion is activated. The resulting fragment ions are not excited and thus do not dissociate further, allowing detection of an array of predominantly both b and y ions (as well as others). In contrast to resonant excitation in trapping instruments, in beamtype CID both the selected precursor ions and any resulting fragment ions are passed through a collision region which enables further activation and dissociation of the fragment ions. This means that the less stable b ions will frequently decompose to very small ions. Thus, both peptide precursors and their fragment ions are activated and mostly y-type fragment ions persist. Unlike CID, ECD and ETD fragmentation relies on the gas phase reaction of the peptide ions with a thermal electron or an ETD reagent, respectively. The electron transfer-driven fragmentation mechanisms create mostly c-and z-type ions. Overview of phosphoproteomic methods Categorization of the main strategies for quantitative proteomics. Labeling reactions of triplex stable isotope dimethyl labels and duplex TMT labels. Both labeling methods target the N-terminus and Lys of peptides with a reactive isotopic group. a: Dimethyl labeling introduces different mass increases via different isotopic reagents. b: TMT labeling introduces equal mass increases via different reagents. The reporter ions with different masses are released during peptide fragmentation. Asterisk indicates a 13 C atom replacement. Two quantitative strategies based on chemical reaction. The representative peptide is doubly charged, and consisting of 15 molecules of averagine, a hypothetical amino acid. Averagine has a molecular formula of C 4.9384 H 7.7583 N 1.3577 O 1.4773 S 0.0417 , which is derived from statistical occurrence of amino acids in the protein identification resource protein database. a, b, c: Dimethyl labeling. The quantification is calculated based on the ion intensities in MS1. The MS2 is only used to identify the peptide sequence (c). This given peptide has slight isotopic peak overlap between the three groups (b), the overlapped areas will become more significant for longer peptides. d, e, f, g: 6-plex TMT labeling. The quantification is calculated based on the report ion intensities in MS2 (g). The MS2 is used for both peptide The mass spectra observed when the labeling efficiency is 80% for 15 N and SILAC quantifications. 15 N is still able to result in an accurate quantitative ratio, whereby the SILAC labeling leads to a false ratio. SILAC quantitative labeling is not compatible with partial labeling because the observed unlabeled peaks do not exclusively originate from unlabeled sample. Representative LC-MS/MS data and a generalized bioinformatic analysis pipeline for protein identification and quantification in shotgun proteomics. (a) As a total ion chromatogram is acquired by nESI-MS from the nLC separation of peptides, the mass spectrometer acquires both full scan MS (MS1) precursor spectra and data-dependent MS/ MS (MS2) fragmentation spectra. All ions, typically between 300 -2000 m/z, are detected during nLC in the full MS scans. The full scan defines the most abundant peptide precursor ions which are sampled by data-dependent for MS/MS. (b) The acquired data is then processed through a bioinformatics pipeline. A database search is used to match theoretically generated peptide fragmentation spectra to experimental MS2 fragmentation spectra, creating a list of peptide candidates for each experimental spectrum. The peptide candidates are ranked and filtered to create peptide spectrum matches (PSMs) and peptide identifications. PSMs can be filtered by XCorr using the \"incorrect\" reverse PSMs as an estimation of false discovery rate (FDR). In high mass accuracy experiments, prior to XCorr filtering a mass error window can be used to prefilter PSMs based on the precursor mass measurement from MS1 scans. If a systematic mass error is \"observed\", it can be \"corrected\" by adding or subtracting the average mass error. Identified peptides are assigned to proteins by inference to create a list of proteins present within the sample. The relative protein quantification is then performed by averaging the peptide ratio measurements for peptides assigned to the protein. These same strategies can be used for post-translational modification (PTM) identification and quantification, by using a peptide as a surrogate measurement of the PTM. The protein-protein interaction detected by Y2H and AP-MS. a: Y2H is used to detect binary interaction. The results here demonstrate the protein B can interact with protein A and C, but not D. b: AP-MS is used to identify the whole protein complex. All the interactors binding to protein B, including both direct and indirect binders, are identified by shotgun proteomics. Scheme of tandem affinity purification (TAP). Two steps of purification significantly remove the unspecific binding proteins. The protein turnover measured by 15 N partial labeling with the software ProTurnyzer. 749 The representative peptide has an amino acid sequence of LDKSQIHDIVLVGGSTR derived from mouse heat shock cognate 71 kDa protein. The yellow peaks represent the preexisting peptide with natural isotopic composition, whereby the purple peaks represent peptide synthesized during 15 N feeding. The gain of purple and removal of yellow reflect protein synthesis and protein degradation, respectively. The red bars indicate the intensity error between theoretical and measured peptide isotope distributions. The inset figures are the observed mass spectra for which the unlabeled and labeled peptide peaks were analyzed. Steps of biomarker development Table 2 Mass analyzers used in shotgun proteomics and their commonly-achieved analytical metrics for peptide analysis. "}