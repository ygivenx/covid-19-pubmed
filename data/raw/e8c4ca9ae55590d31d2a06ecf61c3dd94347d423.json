{"title": "Quality of drinking water", "body": "People who drink water that is contaminated with human faeces are at risk of diarrhoea, a condition that results in 1.8 million deaths in children each year. 1 In this week's BMJ, a systematic review and meta-analysis by Clasen and colleagues 2 finds that household interventions to improve the microbiological quality of drinking water reduce the occurrence of diarrhoea. Their results show that the quality of water has an impact on health. They also highlight the value to public health of achieving the targets outlined in the seventh millennium development goal-to reduce by half the proportion of people without sustainable access to safe drinking water.\n\nTwo articles published in 1985 and 1991 are the most cited reviews on the effectiveness of interventions to prevent diarrhoea. 3 4 These considered only improvements to the water source, however. They did not assess the microbiological quality of the water at the point of use, and they did not include any of the recent studies that evaluated microbiologically effective treatment of drinking water at the point of use. They concluded that improvements in the quality of drinking water at source reduced diarrhoea by 15-17%, in contrast to larger reductions as a result of increased water supply, promotion of hand washing, and improved sanitation.\n\nDuring the past two years, two reviews with metaanalyses have included many new studies on water treatment at point of use and re-evaluated the effect of improved water quality on diarrhoea. 5 6 The first concluded that in high quality studies, water treatment at point of use reduced diarrhoea by 39% compared with 11% (not statistically significant) for interventions that improved the quality of water at source. 5 The second reviewed interventions that used water treatment with sodium or calcium hypochlorite, it analysed only the youngest age group reported in each study, and it concluded that chlorine treatment at point of use reduced diarrhoea by 29%. 6 The meta-analysis by Clasen and colleagues of 42 controlled trials and 56 000 participants is the most rigorous review to date. 2 Studies that met their criteria included those assessing all water disinfection techniques at point of use and improvements to the water source, and published and unpublished studies. Clasen and colleagues conclude that interventions to improve the microbiological quality of drinking water are generally effective in reducing diarrhoea in adults and children under 5 years, and that household interventions are more effective than water source interventions.\n\nHowever, they caution that heterogeneity between trials means that effectiveness may vary according to the setting.\n\nThese promising results suggest that the measurement used to assess progress towards the millennium development goal should be changed to reflect the importance of microbiological water quality. Currently, the global standard for safe water is an assessment of the proportion of the population that has access to an \"improved water supply.\" 7 8 However, an improved water supply is an engineering definition. For example, piped water or a protected spring is an improved water supply compared with water from a tanker truck or an unprotected spring. 7 Importantly, improved water supplies are often contaminated with human faecal organisms-that is, they are not microbiologically safe water supplies [9] [10] [11] [12] Thus, the reduction in diarrhoea shown by Clasen and colleagues resulting from microbiological treatment of water at point of use does not necessarily apply to improved water supplies.\n\nFor these findings to translate to improved health, water quality needs to be measured by the microbiological quality of the water that people actually drink, rather than the types of water sources. In 2006 the United Nations projected, using the outdated metric, that the world is on track to meet the millennium development target for safe water. 8 The risk is that the United Nations will claim victory over unsafe water when, in fact, water supplies that are technically defined as \"improved\" will provide little health benefit to the population in need.\n\nPopulations with the lowest mortality rates from diarrhoeal disease have microbiologically safe water piped directly to point of use. Until such services can be provided in low income countries, point of use water treatment is a potential interim solution. However, experience of scaling up the implementation of treating household water to large populations is limited. Research is needed to evaluate whether the health gains demonstrated in the carefully controlled efficacy studies reviewed by Clasen and colleagues can be achieved in large populations at high risk for mortality from diarrhoeal disease when point of use water treatment is not provided free of cost, and when household visits to encourage use are limited.\n\nComposite end points may mislead-and regulators allow it to happen In this week's BMJ, Ferreira-Gonz\u00e1lez and colleagues report that clinical trials may mislead if they use composite end points. 1 For example, a statement that an intervention reduces a composite end point of cardiovascular mortality, myocardial infarction, and revascularisation procedures is misleading if revascularisation procedures were more common outcomes than death or infarction, or if the intervention had a large apparent treatment effect on revascularisation but not on death or infarction. 1 It is not enough for people who use the research-doctors and patients-to be aware of such potential to mislead: pharmaceutical regulators should also examine their role.\n\nPharmaceutical regulation has provided benefit to society by harnessing the innovation of industry towards improving health. Pharmaceutical regulation helps to ensure that drugs are safe and achieve clinically relevant benefits for patients. Regulation also governs the manner in which drugs may be marketed to prescribers and to patients. It allows only claims that can be supported by trial evidence to be used as a basis for promotional activities. Ensuring the evidence base of information to prescribers is a laudable aim, but as Alfred North Whitehead said, \"We think in generalities, but we live in detail.\" The implementation of regulation has led to innovation in trial design, specifically in the choice of primary outcome measures, such as composite outcome or surrogate measures, which can lead to major challenges for people trying to interpret and use results of research, who may not be adequately served by the process.\n\nA key aspect of drug regulation is embodied in the principles of \u03b1 spending-that is, the allocation of type 1 error (the error of rejecting a null hypothesis when it is actually true) in a manner designed to avoid spurious positive conclusions. 2 Because the likelihood of observing a statistically significant result by chance alone increases with the number of tests, it is important to restrict the number of tests undertaken and limit the type 1 error to preserve the overall error rate for the trial. To do this, the type 1 error is allocated to different outcomes, most simply through the specification of a single primary outcome measure (where a one sided P value of <0.025 is conventionally regarded as statistically significant). Alternatively, the available type 1 error may be split between different primary outcomes, or indeed outcomes may be placed in a predefined hierarchical list, with type 1 error \"spent\" down the list until the conventional one sided 2.5% \u03b1 level is reached (equivalent to a two sided 5% level-but no drug is ever licensed for being significantly worse than the comparator).\n\nIn terms of whether a trial has a positive or negative result, the choice of primary outcome may be of central importance. For example, the recent ADOPT trial 3 compared time to failure of monotherapy (defined as a confirmed concentration of fasting plasma glucose of >180 mg/dl) in 4360 newly diagnosed patients with type 2 diabetes treated with rosiglitazone, metformin, or glyburide who were followed for a median of four years. Although this surrogate primary outcome was highly significantly in favour of rosiglitazone, no difference was seen in death rate or rate of hospital admission between the groups, and no other indication of clinical benefit was seen for patients in the rosiglitazone group. The positive primary outcome reported by the study is expected to boost sales of the product. 4 However, after surveying the list of adverse events in the trial, it is hard to conclude that patients benefited from a longer time to failure of monotherapy.\n\nAn additional challenge in the market authorisation for pharmaceutical products is the use of composite outcomes, which potentially provide an opportunity for sponsors to \"game\" their trials. 1 Composite outcomes bring together two or more events that are considered as a single outcome. 5 \n\nTheoretical promise of benefit does not translate to improvements in morbidity and mortality\n\nIn this week's BMJ, Adhikari and colleagues report a systematic review of the impact of inhaled nitric oxide on physiological outcomes, morbidity, and mortality in people with acute respiratory distress syndrome. 1 They found that nitric oxide resulted in a limited improvement in oxygenation but did not reduce mortality (risk ratio 1.10; 95% confidence interval 0.94 to 1.30), the duration of ventilation, or the number of days free of ventilation.\n\nAcute respiratory distress syndrome is an important public health problem. It is a catastrophic form of acute respiratory failure that arises after pulmonary (for example, pneumonia or aspiration of gastric contents) or extrapulmonary (for example, sepsis or polytrauma) insults. Not only does it have an incidence as high as 64 cases per 100 000 people per year, 2 but it has a high mortality (30-60% in unselected populations) and risk of subsequent morbidity in survivors. 3 The many cellular and molecular actions of nitric oxide (the 1992 \"molecule of the year\" 4 ), also known as endothelial derived relaxing factor, are incompletely understood. 5 However, intensive care physicians were quick to use inhaled nitric oxide to treat acute respiratory distress syndrome because of its immediately observable beneficial effects on oxygenation and pulmonary vascular pressures in these patients, and because of the lack of other effective treatments.\n\nInhaled nitric oxide acts as a selective vasodilator. It is inactivated by haemoglobin and so acts only on the pulmonary circulation, lowering pulmonary vascular resistance and improving cardiac output. because in time to event analysis the statistical power of a study is driven by the number of events that accrue, rather than the number of patients randomised. Composite outcomes can help in avoiding arbitrary decisions between different candidate outcomes when prespecifying the primary outcome, and they have several advantages. However, a positive result for a composite outcome applies only to the cluster of events included in the composite and not to the individual components. Regulatory behaviour may have led to the addition of \"death\" to many composite primary end points used in trials, and it is our experience that the Food and Drug Administration has actively promoted the use of such composite outcome measures in heart failure trials. The DREAM trial, of rosiglitazone in the prevention of diabetes in patients with impaired fasting glucose or glucose tolerance (or both), had the composite primary outcome measure of diabetes or death. 7 The primary outcome was highly statistically significant, although there was no difference in the rate of death between the groups (30/2635 (1.1%) in the rosiglitazone group and 33/2634 (1.3%) in the placebo group). If the FDA followed standard practice, it would react to an application for extension of the marketing authorisation by granting authorisation for the composite outcome. To do so would wrongly endorse the idea that mortality was reduced.\n\nThe European licensing process seems to follow the FDA lead. Indeed, as the US represents about 60% of the world market for drugs, FDA policy drives the design of regulatory trials. Two areas of concern require attention. Firstly, the regulators should ensure that primary outcome variables in regulatory trials really do \"provide a valid and reliable measure of some clinically relevant and important treatment benefit in the patient population. . .,\" 8 as required in the regulators' own guidance on the design and analysis of clinical trials. Secondly, while it is our opinion that composite outcome measures do have a useful role in the evaluation of health technologies, the difficult problem of the appropriate interpretation of composite outcome measures in regulatory policy should be dealt with. This might be achieved by using a corollary (such as a health warning), which makes it clear that on their own the individual components of a composite have not been shown to be affected by the experimental treatment. preferentially increases blood flow to these units, improving ventilation-perfusion matching and oxygenation. Theoretically, these actions could improve oxygenation and oxygen delivery, allow for less injurious mechanical ventilation, and ultimately reduce the prevalence or severity of the multiorgan dysfunction that is the cause of death in most patients with acute respiratory distress syndrome. Unfortunately, randomised controlled trials of inhaled nitric oxide have not borne out this theory. Adhikari and colleagues' methodologically rigorous and clinically sound systematic review and meta-analysis of 12 randomised controlled trials provides evidence that nitric oxide can provide modest short term improvements in oxygenation. However, all but one of the nine relative risk point estimates for mortality favoured patients in control groups. This lack of concordance between physiological improvements and outcome for patients is a recurring theme in critical care, 6 7 and it probably plays a part in our collective reluctance to abandon these interventions.\n\nAs Adhikari and colleagues' study is a meta-analysis that includes several small underpowered randomised controlled trials, the results are best treated as hypothesis generating. 8 The review suggests that nitric oxide has no significant effect on mortality. Alternatively, and in keeping with the post hoc finding that people receiving nitric oxide had an increased risk of developing renal dysfunction (1.50, 1.11 to 2.02), we could speculate that patients with acute respiratory distress syndrome receiving nitric oxide have slightly higher mortality. What this meta-analysis does not provide is any suggestion of benefit with inhaled nitric oxide.\n\nGiven these findings, routine use of inhaled nitric oxide in such patients cannot be recommended. Indeed given the costs and potential for harm, its routine use in acute respiratory distress syndrome should be actively discouraged. I suggest that it should be used in this syndrome only for rare cases of refractory hypoxaemia, after considering modalities such as high frequency oscillation or prone positioning. 9 In the light of this new evidence should we persist with trying to show that nitric oxide improves outcomes in acute respiratory distress syndrome? Not finding a benefit is not proof of no benefit. However, the trend towards harm seen across these many trials makes it unlikely that we will eventually prove a benefit through persistence alone. This does not mean that nitric oxide is without merit; it is still useful in other diseases such as persistent pulmonary hypertension of the newborn. 10 Even in acute respiratory distress syndrome, nitric oxide may yet have a role outside salvage therapy for severe hypoxaemia, but this work by Adhikari and colleagues indicates that we need to change radically the designs of randomised controlled trials of nitric oxide in these patients. For example, future trials could explore alternative dosing schedules for nitric oxide (such as titrated decremental dosing 11 ), the application of nitric oxide to specific subgroups of patients, or combining nitric oxide with other treatments (such as mechanical ventilation strategies to reduce pressure, or early aggressive fluid resuscitation 12 ) .\n\nFuture trials should be grounded in sound observations from physiological animal and early phase human studies, along with observations from completed randomised trials. Making the successful leap from a solid mechanistic theory to a large randomised controlled trial is challenging, 13 and trying to do so without this grounding seems destined for failure, regardless of persistence.\n\nAn imperfect measure of a modest predictor of response to antidepressants may not be ready for clinical application Patients' responses to treatment with antidepressants vary greatly. The largest study on the effectiveness of antidepressants to date suggested that roughly one third of patients will recover fully given a long enough trial, one third will improve substantially, and one third will not respond. 1 A subset in all three groups will have adverse effects such as sexual dysfunction, insomnia, nausea, and weight gain. Side effects are rarely dangerous, but they cause many patients to discontinue treatment, often after a single prescription. 2 Similar concerns exist for many drugs, not just antidepressants. What makes antidepressants especially frustrating for clinicians and patients is the lack of factors to predict how individual patients will respond to a given treatment. We know that one third of patients will have minimal improvement, but we have few data to guide selection of alternative treatments. Indeed, while the psychiatric literature abounds with reports of clinical predictors, the findings are rarely replicated. 3 One of the only replicated predictors, that atypical depression responds better to monoamine oxidase inhibitors than to tricyclics, does not seem to apply to newer antidepressants. Worse, many of the widely touted and taught predictors turn out to be invalid on closer inspection. For example, conventional wisdom holds that antidepressants with \"activating\" properties, such as bupropion, are less likely to be effective in patients with anxiety or insomnia. In a clinical trial, however, this was not the case. 4 5 Any predictive test, especially one with the shiny lustre of genetics and the promise of rapid and highly accurate results, therefore causes excitement among psychiatric clinicians. The marketing of a test that can define a person's genetic profile in terms of two important P450 enzymes has generated just this sort of excitement. One journal devoted its cover to the headline, \"New tool: genotyping makes prescribing safer, more effective!\" However, a recent report by the US Agency for Healthcare Research and Quality 6 found little evidence to support a role for cytochrome P450 genotyping when prescribing antidepressants.\n\nThe argument for P450 genotyping is straightforward. Selective serotonin reuptake inhibitors and other newer antidepressants are metabolised by enzymes in the cytochrome P450 system, so variation in the encoding genes would be expected to influence concentrations of these inhibitors in the blood. In theory, people who metabolise these inhibitors poorly might develop supratherapeutic concentrations and be more likely to have adverse effects; conversely, those who metabolise them rapidly might develop subtherapeutic concentrations and be less likely to respond well to treatment.\n\nAs the agency report highlights, both aspects of this argument are suspect. The 11 studies that examined the relation between P450 genotype and antidepressant concentrations found only the suggestion of an association. A key point here is that P450 genotype is just one of many factors that influence drug concentrations. Other factors include variables that can change over time, such as diet, smoking, and cotreatment with other P450 substrates or inhibitors. 7 Furthermore, newer generations of antidepressants do not exhibit clear dose-response relations, and concentrations of antidepressants in the blood are rarely informative, except at the extremes. Measuring drug concentrations may be more useful in populations at higher risk; one study of depressed elderly patients did suggest that therapeutic drug monitoring led to changes in treatment about half the time. 8 So P450 genotype is not an accurate predictor of drug concentration in the blood, which in turn is not a strong predictor of outcome. Still, even modestly accurate predictors might have benefit. Unfortunately, no adequately powered studies have investigated this question directly. The suggestion that people who metabolise antidepressants rapidly may have a worse response and that those who metabolise them slowly may have more side effects is encouraging but not convincing. Notably, the largest study to look at this question failed to find an effect on adverse effects. 9 Therefore, before P450 genotyping can be recommended when prescribing antidepressants, we need to establish that this test can help improve outcomes, either in terms of tolerability or effectiveness. Studies that examine the effects of P450 in populations where the consequences of adverse effects might be greater (such as elderly patients) or suspicion of metabolic differences is high, or in patients who fail to respond to multiple antidepressant trials, would be particularly valuable. In the meantime, what should individual clinicians do? Where concern for drug interactions or toxicity is high, the simplest approach is to begin with antidepressants minimally metabolised by P450 isoforms CYP2D6, CYP3A, and CYP2C19. If this is not practical, the most direct and informative approach is to check concentrations of antidepressants in the blood.\n\nHow quickly we forget. In the mid-1980s, the dexamethasone suppression test was widely touted as a sensitive test for identifying major depressive disorder. Only later did it become clear that it is neither sensitive nor specific. 10 In a specialty where biomarkers of disease are rare, any biomarker is welcome-provided it is truly clinically useful. Unfortunately, at least as far as antidepressant prescribing is concerned, insufficient evidence is available to support the routine use of P450 genotyping. Ultimately, as with any other diagnostic tool, the value of pharmacogenetic tests needs to be determined by well designed and adequately powered trials before they are used in practice.\n\nOther viruses pose greater public health threats, so isn't it time to move on? Emotions still run high over the stocks of smallpox virus placed into the P4 freezers of Atlanta and Novosibirsk more than 30 years ago by the World Health Organization. In this week's BMJ, two articles present opposing views on whether the United States and Russia should destroy their stocks of smallpox virus (Variola). 1 2 One argument for maintaining smallpox stocks is that they are needed to develop safer vaccines. 1 Our current effective vaccine is safe when used judiciously-not for mass vaccination of populations, but for targeting those at risk after screening out people with a history of HIV, leukaemia, or eczema at higher risk of complications after vaccination. 3 Moreover, new vaccines are based on Vaccinia, not smallpox. 4 No new vaccine can be tested for efficacy until human cases of smallpox reappear.\n\nAnother argument is that smallpox stocks are needed to assess antiviral agents for the treatment of smallpox. Again, no agent can be properly tested until human cases reappear. Moreover, the production of an effective antiviral is unlikely to be profitable, given the likely number of cases, and the altruism of manufacturers will probably be limited. An antiviral agent might even be of limited use in practice. Many cases are identified late, after the appearance of irreversible sequelae. Others are identified at exposure, well before onset of symptoms, when vaccination provides substantial protection and reduces the mortality rate if not the occurrence. Immunoglobulin from vaccinated people and even from survivors of smallpox (the first available and the second theoretically available) could similarly modify outcomes.\n\nA third argument is that stocks are needed to develop better diagnostic tests. We already have rapid and sensitive tests for orthopoxvirus. 4 The need to distinguish between smallpox and zoonotic orthopoxviruses would not be an immediate priority in the context of potential terrorism, as the emergency test should emphasise sensitivity, not specificity. If the introduction of smallpox did produce multiple cases, the epidemiological pattern of severity would provide a fairly accurate diagnosis. In fact, the unique appearance of a patient with early severe smallpox would quickly be disseminated via the media, and subsequent cases would be recognised by lay people. Control would proceed whether or not every diagnosis had been confirmed. Even the classic differential diagnostic alternative of Varicella poses few problems in an unvaccinated population, as confusion in the past was created largely by smallpox modified by past vaccination.\n\nSo what then are the arguments for destroying smallpox stocks? The major benefit of destroying the stocks is a reduction in the probability that smallpox cases will reappear. 2 The virus originally stored in one of these facilities may be the only source available, because as time goes by with no indication to the contrary it becomes less likely that other clandestine stocks exist. The danger of escape is increased by dissemination to investigators and other laboratories.\n\nHowever, even if smallpox were to be introduced into the population, it would not attain the proportions that it did in medieval times. Under current Western social circumstances of small family size and highly efficient communication, the number of cases is unlikely to be large. 5 Most cases of smallpox are acquired at the bedside, whether in urban hospitals 6 or in rural villages, 4 and transmission between houses occurs through social relationships. If a large outbreak did occur, it would probably be the result of simultaneous exposures to the same (hospital) bedside rather than extended transmission. 6 If a chain of transmission does not die out on its own, it would quickly be contained by the standard control techniques of public health and hospital epidemiologists. 5 The unique appearance of an infectious case; the interval of roughly two weeks between exposure and symptoms; and the triad of surveillance, isolation, and effective vaccination would act together to ensure that control is established within a few case generations. Neither a widespread nor a long term epidemic is probable, whether judged from past history, 6 from extrapolation of the experience with severe acute respiratory syndrome, 7 or from any of the recent mathematical models. [8] [9] [10] [11] The net impact of an introduction would be comparable to a large common source outbreak of a severe disease caused by an agent such as hantavirus or encephalitis virus, although that impact might be substantially augmented by complications if mass vaccination were to be initiated. 5 Thus, a case can be made for destroying the stocks, given the absence of compelling contrary arguments, although the stocks do not pose a great threat. Destroying the stocks would have two added benefits-it would fulfil the commitment made by the US in 1990 to destroy stocks after the genome had been identified and it would circumvent any pressures to return stocks to their countries of origin. 2 Another real benefit would be the permanent elimination of this question as a distraction. More important problems need to be dealt with. Even more dangerous viruses may be found in P4 and lesser facilities. Release of the highly virulent recombinant 1918 influenza virus would be a real catastrophe, 12 yet retention and distribution of recombinant strains for study is enthusiastically justified on the basis of the need for effective prevention, diagnosis, and treatment."}