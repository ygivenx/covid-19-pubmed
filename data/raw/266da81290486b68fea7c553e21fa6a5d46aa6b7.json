{"title": "S1 Text Simulation Algorithm", "body": "1. Draw a waiting time t I in class I from a specified infectious period distribution, and set the time of recovery t R = t + t I .\n\n2. Let t next be the earliest time in the union of t I and t R (those greater than t) of all currently infectious individuals.\n\n3. The time of next infection t E is drawn as the first event in a non-homogeneous Poisson process with a time-varying rate \u03b2(t) (defined in the main text). There are a number of ways of simulating from a non-homogeneous Poisson process \u2212 for example, the thinning algorithm [1] which essentially samples the next event time t E from a homogeneous Poisson process with the baseline rate \u03b2 and accepts that with probability \u03b2(t E )/\u03b2. Note that when there are n > 1 currently infectious individuals, the acceptance probability would become\n\n5. If t E \u2265 t next , set t = t next , and resimulate t E as described in Step 3.\n\nAfter t E is sampled, select the source of this infection uniformly among currently infectious individuals. This new infection is then placed at distance r and angle \u2206\u03b8 from the selected source according to the density g(G = (r, \u2206\u03b8); \u03b7,\u015d) specified in details in the main text.\n\n7. Draw t I the time of becoming infectious and t R the recovery timefor this new infection using specified waiting time distributions.\n\n8. Repeat the above steps until a stopping criterion (e.g. t > t max ) is reached.\n\nIn the main text, for mathematical clarity, we have discussed a general case where the population density along the circumference \u03c3(l|r,\u015d) is assumed to be continuous. In practice, however, the data of population density over a study area is often provided in a discrete form, mostly on the grid level. This results in a piecewise constant density of the angle \u03b8, with the precise location of change-points in this density depending on how the 'grids' and the 'circle' intersect (see Fig. ? ?). To derive this density, it is necessary to compute the probability masses of the arcs (which is proportional to the density of the corresponding angles) that comprise the whole circumference, where population density is homogeneous/constant on each arc (and in the grid it belongs). Here we describe an algorithm for computing \u03c3(l|r,\u015d) given the grid-level population density. First of all, using basic plane and line geometry, we solve for the coordinates of the intersection points between the grid lines and the circle (Fig. ??) . Then, for each intersection point (x i , y i ) we solve for the angle \u03b8 i measured from the first quadrant by\n\nwhere (x s , y s ) is the coordinate of the source of infection (the center of the circle). Let (\u03b8 (1) , \u03b8 (2) ....) be the vector of ordered angles, and let \u2206\u03b8 i = \u03b8 (i+1) \u2212 \u03b8 (i) , for i = 1, 2, .... The probability mass of an arc segment with \u2206\u03b8 i is then proportional to\n\nwhere \u2206l i is the arc length corresponding to \u2206\u03b8 i , and \u03c3 \u2206l i is the constant population density of the grid-cell in which the arc lies. It is worth noting that infected individuals emerge in continuous space regardless the form of the population density data.\n\nWe describe how we simulate epidemics from the individually-based SEIR model described in the main text section Comparison with Individual-based SEIR Model. For the sake of computational efficiency, we consider an initially susceptible population with population size N = 10000. The geographical locations of these N individuals were randomly assigned accordingly to a normalized population density across the study area similar to the Ebola dataset. An epidemic was assumed to be initiated by an index case and progressed according to the conventional spatial-temporal SEIR epidemic model [2] . In contrast to our proposed framework, the conventional SEIR model requires an explicit specification of the infectious challenge presented to each susceptible individual. Specifically, a susceptible individual j becomes exposed during [t, t + dt) with probability\n\nwhere \u03b1 represents a primary infection rate and \u03b2 is the contact parameter. The term K(d ij , \u03ba ) characterises the dependence of the infectious challenge from infective i to j as a function of distance d ij and is known as the spatial kernel function. We assume that K(d ij , \u03ba ) = exp(\u2212\u03ba d ij ). It is noted that K(d ij , \u03ba ) does not have to be a proper density function. Similar to our proposed model, an infected individual is assumed to spend random times in class E and I, modelled by Gamma(\u03b3, \u03bb) and Exponential(1/\u03d5) distributions respectively. We focus on simulations that give rise to epidemics in which around 5% of a study population becomes infected (in 50 days). Specifically, we set \u03b1 = 2.5 \u00d7 10 \u22125 , \u03b2 = 1.8 \u00d7 10 \u22124 , \u03ba = 0.3, \u03b3 = 3, \u03bb = 1 and \u03d5 = 7. It is noted that, as the conventional SEIR model and our model have very distinct structures (and hence in general imply differing interpretations of their model parameters), they are therefore compared based on commonly agreed key 'model outcomes' (see main text).\n\nWe also fit the full individual-based SEIR model to one of the simulated datasets described in Simulating from Individual SEIR Model. It is noted that this will require an explicit consideration of each individual (among the population with N = 10000) in the model fitting and often require a large amount of recalculations of likelihood during the MCMC sampling \u2212 for example, at proposing a new value of \u03ba , the spatial infectivity between all infectious-susceptible pairs must be recalculated. As the purpose here is to compare the computational efficiency, we only record and compare the run-time for 1000 MCMC iterations both in performing the full individual-based SEIR model inference and performing inference of our model. A comparison, in which both model fittings were conducted using similar C++ codes and data structures, shows a significant speed gain in fitting our model (3 vs 2340 seconds).\n\nRipley's K function [3, 4] is similar to Moran's I function but is able to characterize clustering/dispersion of point patterns at multiple distances. Theoretically it is defined as K(r) = \u03bb \u22121 E[number of points within distance r of a randomly chosen point],\n\nwhere \u03bb is the density of points per unit area. We consider a common transformation of Ripley's K, Ripley's L function L(r) = K(r)/\u03c0. We compute the estimated L(r) using the function Linhom(\u00b7) provided in the R package spatstat [5] , on a range of distance [0, r max ]. This function also determines a sensible default of the maximum distance r max , by taking into account the increasing estimation uncertainty at larger distances. It is noted that the estimated L(r) are often compared to those computed from data generated from a null model (i.e. a Poisson point process), in which clustering/dispersion are characterized relative to the null model. In this paper, however, it is the comparison of values of L(r) computed from the model simulated data and the observed data is of interest."}