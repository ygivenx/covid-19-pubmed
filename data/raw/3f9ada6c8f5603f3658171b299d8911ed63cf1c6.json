{"title": "Network theory and SARS: predicting outbreak diversity", "body": "More than two years since the first case of severe acute respiratory syndrome (SARS), a respiratory illness caused by a novel coronavirus, occurred in Guangdong province of China (November, 2002) and more than 18 months since the syndrome was first recognized outside of Asia (in Canada on March 13, 2003) , its pattern of spread remains an enigma to public health officials and epidemiologists (Cyranoski and Abbott, 2003; Drosten et al., 2003; Ksiazek et al., 2003; Marra et al., 2003; Peiris et al., 2003; World Health Organization, 2003) . Mathematical epidemiologists originally estimated the average number of secondary cases emanating from one primary case in a susceptible population (R 0 ) to be in the range of 2.2 to 3.6 for this virus-an estimate well above one, approximating that of a new subtype of influenza (Hethcote, 2000; Lipsitch, 2003; Riley et al., 2003) .\n\nDespite this estimate and near-universal susceptibility, SARS has not emerged as a global pandemic. Instead, initial seeding was followed by intense but tightly circumscribed activity in some locales with only scant activity in others. In Canada, for instance, Toronto, Ontario and Vancouver, British Columbia were first affected nearly simultaneously in March 2003 . By June 3, 2003 , Toronto had experienced more than 209 probable cases and Vancouver had experienced only four probable cases. No other province of Canada reported any probable cases (Health Canada, 2003) . The United States with a population more than fifty-fold greater than Toronto reported 69 probable cases-67 imported and only two from secondary spread (Centers for Disease Control and Prevention, 2003) .\n\nThe discrepancy between the estimates of R 0 and the observed epidemiology might stem from early and effective intervention since R t ; the reproductive ratio of a disease at time t, will decrease with the implementation of successful infection control measures. Yet, even during the three and a half months of SARS spread in China between its initial appearance and the broad implementation of public health measures, case counts were much less than expected from such values of R 0 (Xu et al., 2004) . By definition, the total number of expected cases of a disease goes up by a factor of R 0 for every generation of infection, a generation being the mean time between an individual becoming infected and their infecting others. Based on recorded dates of the first symptoms for 124 pairs of infections in Singapore and Toronto (Leo et al., 2003; Poutanen et al., 2003) , we estimate the average generation time (g) for SARS to be 9.770.3 days. (This estimate clearly depends on the accuracy of the reported data.) Roughly, the cumulative number of SARS cases over D days should be P D=g i\u00bc0 \u00f0R 0 \u00de i \u00bc \u00f01 \u00c0 R D=g\u00fe1 0\n\n\u00de=\u00f01 \u00c0 R 0 \u00de (This is capped by total population size and does not consider the reduction in R t once a substantial proportion of the population is infected). Thus for R 0 ranging between 2.2 and 3.6, this equation predicts that in the first 120 days of transmission in China, there should have been between approximately 30,000 and 10 million cases. In fact only 782 cases were reported during the initial three months (World Health Organization, 2003) , which, using this simple calculation, suggests that R 0 should be much lower and closer to 1.6. A subsequent estimate based on data from the Hong Kong and Singapore outbreaks brings R 0 down to 1.2, which, by the above formula, predicts approximately 50 cases during the first 120 days of transmission (Chowell et al., 2003) . While this number agrees nicely with the case counts observed in Hong Kong and Singapore (Chowell et al., 2003a, b) it is an order of magnitude lower than that reported for China.\n\nWhy do epidemiologists derive such varied estimates of R 0 and why were the initial estimates so high in comparison to the observed epidemiology in China? The basic premise of fully mixed epidemiological modelsthat all individuals in a group are equally likely to become infected (or infect others)-often does not hold and therefore may lead to spurious estimates or estimates that cannot justifiably be extrapolated from the specific setting in which they were measured to the broader community context. Early SARS estimates were based largely on transmission data from closed settings like hospitals and crowded apartment buildings, where there are unusually high rates of contact between individuals (Lipsitch, 2003; Riley et al., 2003) . In fact, hospital transmission accounts for 50% of the value of R 0 described in Riley et al. (2003) . If the contact patterns in these settings were highly heterogeneous, then the estimates for R 0 may be inaccurate. Even if the estimates for R 0 were indeed appropriate for these specific settings, they probably should not be extrapolated to the population at large. Contact rates may be considerably lower outside hospitals and crowded apartment buildings and thus so may be the general value of R 0 for SARS (Yu et al., 2004) . Such disparity may account for the discrepancy between the estimates and the slower progress of the outbreak in China. In fact, further studies suggest that the unusually large cluster of infected cases in Amoy Gardens complex in Hong Kong was due to exposure to the virus-laden aerosol plume originating from one of the buildings in that area and not from direct person-to-person contact (Yu et al., 2004) . A recent analysis of the impact of SARS isolation interventions in Hong Kong, Singapore and Toronto emphasizes the importance of viewing R 0 as a distribution of possible values where the mean and median may vary depending on the setting in which the disease is spreading (Chowell et al., 2004) . SARS, like many other infectious diseases exhibits great heterogeneity in transmission efficiency with certain individuals appearing to be responsible for large proportion of transmission events (Booth et al., 2003; Donnelly et al., 2003; Leo et al., 2003) . These individuals may be ''superspreaders'' with unusually large numbers of contacts or ''supershedders'' who are unusually effective at excreting the virus into the environment they share with others. In contrast to the fully mixed assumption of standard compartmental models, the contact patterns in a community may be quite diverse. There is an enormous difference between a situation in which all individuals share typical contact patterns and one in which most infected individuals pass the disease on to only one or even zero others, but a small number pass it onto dozens or even hundreds-the mean value of R 0 can be the same in both cases, while the epidemiological outcomes are vastly different.\n\nPublic health control measures for communicable diseases, including contact tracing, isolation, quarantine, and ring vaccination (Greenhalgh, 1986; Mu\u00a8ller et al., 2000) have historically been predicated on sociological considerations. For example, the strategies for international SARS control were founded upon the largely intuitive idea of early interruption of critical social contacts (World Health Organization, 2003) . There are several mathematical approaches that likewise consider sociological factors. To name a few, compartmental models that break populations into many demographic groups capture greater behavioral heterogeneity (Hethcote and Yorke, 1984) ; stochastic approaches including stochastic compartmental models (Bailey, 1975) , branching process models (Becker, 1977; Farrington et al., 2003) , dyad models (Keeling et al., 1997; Ferguson and Garnett, 2000) , and Reed-Frost chain-binomial models (Lefevre and Picard, 1989 ) allow more exact predictions of the size and probability of epidemics; and ''individual-based modeling'', a primarily computational approach based on following the contact and infection histories of simulated individuals, yields detailed statistical predictions about disease outcomes. Most individual-based models assume predefined simple contact patterns such as regular lattices (Durrett, 1999; Kleczkowski and Grenfell, 1999; Ritton and O'neill, 2002; Sander et al., 2002) , although there have been recent efforts to consider more realistic contact patterns (Van der Ploeg et al., 1998; Chowell et al., 2003a, b; Eubank et al., 2004) .\n\nA recent addition to this toolkit is contact network epidemiology, an analytical framework that explicitly captures the diverse interactions that underlie the spread of diseases (Longini 1988; Sattenspiel and Simon, 1988; Morris, 1995; Ball et al., 1997; Diekmann et al., 1998; Lloyd and May, 2001; Newman, 2002; Keeling et al., 2003; Meyers et al., 2003) . The first step in contact network epidemiology is to construct networks based on information about real-life contacts between individuals. One can then analyse these networks to determine their crucial topological features and apply analytical methods to make epidemiological predictions and intervention recommendations. The two primary advantages of this approach are that (i) it makes no a priori assumptions about the global network structure and (ii) the mathematical analysis allows one to bypass extensive simulation.\n\nHere, we extend the mathematics of contact network epidemiology to make more detailed public health predictions, to demonstrate the importance of an accurate model of contact patterns in a community, and to provide new insight into the observed epidemiology of SARS.\n\nContact network models attempt to characterize every interpersonal contact that can potentially lead to disease transmission in a community. These contacts may take place within households, schools, workplaces, hospitals, etc. (Fig. 1A) . Each person in a community is represented as a vertex in the network and each contact between two people is represented as an edge (line) connecting their vertices. The number of edges emanating from a vertex, that is, the number of contacts a person has, is called the degree of the vertex. The distribution of the numbers of contacts-the degree distribution-is a fundamental quantity in network theory.\n\nIn the studies described here, we start by generating a plausible contact network for an urban setting using computer simulations. The simulations are based on data for the city of Vancouver, British Columbia. We choose N=1000 households at random from the Vancouver household size distribution (Statistics Canada, 2001), which yields approximately 2600 people. Household members are given ages according to the measured Vancouver age distribution (BC Stats, 2003) , and, based on age, are then assigned to schools according to school and class size distributions ( Vancouver School Board, 2002) , to occupations according to (un)employment data (BC Stats, 2002) , to hospitals as patients and caregivers according to hospital employment and bed data (Centre for Health Services and Policy Research, 2002) , and to other public places. Within each location we create random connections between individuals with probabilities of 1 for households, 0.3 for hospitals and schools, 0.03 for workplaces, and 0.003 for other public places. Admittedly, these within-location parameters are largely based on intuition, and future versions of this model will include estimates based on data. We found that the structure of these simulated networks is robust to small changes in these values. Each school or hospital is sub-divided into classrooms or wards. Pairs of students or patients within these sub-units were connected with higher probability than pairs associated with different sub-units. Teachers are assigned to classrooms and connected stochastically to appropriate students. Caregivers are assigned wards and then connected to appropriate patients. There are also low probability neighborhood contacts between individuals from different households 3 . This network offers a high degree of realism but is quite complex. We therefore use two simpler networks to provide additional insight. One is a random network with a Poisson degree distribution in which individuals connect to others independently and uniformly at random (Fig. 1B) . Neither the simulated nor the Poisson network, however, contains a significant fraction of superspreaders. Therefore we also study a network with a (truncated) power-law degree distribution (Fig. 1C) , a form much discussed in recent work on network epidemiology (Barabasi and Albert, 1999; Pastor-Satorras and Vespignani, 2001) . This network has a ''heavy tail'' of superspreaders ( Fig. 2 ) and, as we will see, these individuals can have a profound effect on outbreak patterns despite being few in number. Network theorists often refer to such networks as scale-free because of the absence of a typical degree in the network.\n\nWe define the transmissibility of a disease, T, to be the average probability that an infectious individual will transmit the disease to a susceptible individual with whom they have contact. T summarizes core aspects of disease transmission including the rate at which contacts take place between individuals, the likelihood that a contact will lead to transmission, the duration of the infectious period, and the susceptibility of individuals to SARS. The epidemic threshold, which, in an uncorrelated network, is given by\n\nwhere hki and hk 2 i are the mean degree and mean square degree of the network, respectively, is the minimum transmissibility (T) required for an outbreak to become a large-scale epidemic.\n\nWe choose the parameters of the Poisson and power law networks so that all three networks share the same epidemic threshold T c . Let p k denote the probability that a randomly selected individual in a network has degree k. Then, the Poisson network is given by p k \u00bc \u00f0m k =k!\u00de exp\u00f0\u00c0m\u00de with mean contact number m=19.6; and the power law network is given by\n\n( with distribution parameters k=94.2 and a=2. Here we fixed a and solved for k. The results described below are qualitatively similar for a large range of values of a. Truncation of the power law distribution raises the epidemic threshold of the network to values comparable to those found for urban networks.\n\nTo generate the two idealized networks, we begin with a specified number of vertices and choose degrees for these vertices at random from the desired degree distribution. Then we connect random pairs of vertices, until the chosen degrees are exhausted. This often yields imperfect graphs with loops connecting vertices to themselves or redundant edges that connect the same two vertices more than once. We remove these imperfections using an algorithm suggested by Maslov et al. (2001) in which we select at random two edges connecting, for example, vertex pairs AB and CD, and swap them so that they now connect AC and BD, unless this would create a new loop or double edge, in which case we do nothing. This process occasionally eliminates loops and repeated edges and by repeating it a sufficiently large number of times (depending on the network size) we can produce a network with none at all.\n\nGiven the degree distribution of a network, we can use tools based on percolation theory (Pastor-Satorras\n\nCumulative degree distributions for simulated urban, Poisson, and power law networks. As described in the text, these share the same epidemic threshold (T c ). Each line gives the probability that a randomly chosen individual (vertex) will have at least the number of contacts (degree) indicated on the x-axis. The degree distribution for the urban network is nearly exponential for degrees greater than ten. and Vespignani, 2001; Newman, 2002) to predict the fate of an outbreak of an infectious disease as a function of its transmissibility T (defined above). T is related to the traditional R 0 according to\n\nwhere hki and hk 2 i are the mean degree and mean square degree of the network, respectively. The critical transmissibility value T c (also defined above), corresponds to R 0 =1, above which a population is vulnerable to large scale epidemics (but is not guaranteed to experience an epidemic) and below which only small local outbreaks occur.\n\nNetwork theory makes a technical distinction between outbreaks and epidemics. An outbreak is a causally connected cluster of cases that, by chance or because the transmission probability is low, dies out before spreading to the population at large. In an epidemic, on the other hand, the infection escapes the initial group of cases into the community at large and results in population-wide incidence of the disease. The crucial difference is that the size of an outbreak is determined by the spontaneous dying out of the infection, whereas the size of an epidemic is limited only by the size of the population through which it spreads.\n\nTo predict the fate of an outbreak, we use probability generating functions (pgf), quantities that describe probability distributions, and here, summarize useful information about network topology. The pgf for a degree distribution is\n\nIf we choose a random edge and follow it to the nearest vertex, then the pgf for the ''excess degree''-the number of edges emanating from that vertex other than the one along which we arrived-is\n\nThe average degree and average excess degree equal the derivatives of these expressions at x=1, that is,\n\nrespectively. The value of the epidemic threshold T c , the predicted average size of an outbreak /sS and probability of an epidemic S were first derived in (Newman, 2002) . By nesting pgf's for the number of new infections emanating from an infected vertex one can construct a pgf for the size of a outbreak, and hence derive the average size of a outbreak:\n\nos4 \u00bc 1 \u00fe Thki 1\u00c0Thk e i : This expression diverges when an outbreak becomes a large-scale epidemic. The epidemic threshold T c (above) is the transmissibility value that marks this point.\n\nThe probability of a full-blown epidemic S is derived by first calculating the likelihood that a single infection will lead to only an outbreak instead of a full-blown epidemic, and then subtracting that value from one:\n\nwhere u is the probability that the person at the end of an edge does not have the disease and is the solution to the equation\n\nWe use numerical root finding methods to solve for u. S is also the expected proportion of the population that will be infected should an epidemic occur.\n\nHere we extend these results to predict the fate of an outbreak based on its initial conditions-how many and what kinds of individuals are already infected. We refer to the first individual in a community to come down with an infectious disease as patient zero. The probability that a patient zero with degree k will start an epidemic, e k , is equal to the probability that transmission of the disease along at least one of the edges emanating from the original vertex will lead to an epidemic. For any one of its k edges, 1 \u00c0 T is the probability that the disease does not get transmitted along the edge and Tu is the probability that even if disease is transmitted to the next vertex, it does not proceed into a full-blown epidemic. Thus\n\nThe probability that an outbreak of size N will ignite an epidemic is 1 \u00c0 Q N i\u00bc1 \u00f01 \u00c0 k i \u00de where k i is the degree of individual i. This is just one minus the probability that none of the N infected individuals sparks an epidemic. If we know the number of current cases but not their contact patterns, then our best estimate for the probability of an epidemic is calculated similarly, with each of the \u00f01 \u00c0 k i \u00de's replaced with the probability that a typical infected individual does not spark an epidemic. The number of edges through which a typical infected individual can start an epidemic is given by the excess degree pgf, and the probability that one of those edges will not give rise to an epidemic is 1 \u00c0 T \u00fe Tu: Thus the\n\nprobability that none of those edges will be a conduit to an epidemic is Finally, we derive an individual's risk of infection during an epidemic as a function of his or her degree. The probability n k that an individual with degree k will become infected during an epidemic is equal to one minus the probability that none of his or her k contacts will transmit the disease to him or her. The probability that a contact does not transmit the disease is equal to the probability that the contact was infected, but did not transmit the disease, (1\u00c0u)(1\u00c0T), plus the probability that the contact was not infected in the first place, u. Thus, a randomly chosen vertex of degree k will become infected with probability n k \u00bc k \u00bc 1 \u00c0 \u00f01 \u00c0 T \u00fe Tu\u00de k :\n\nWe have simulated disease spread to verify our analytical predictions. Beginning with a susceptible population and a single case or a small cluster of cases, we iteratively take each currently infected vertex, infect each of its susceptible neighbors with probability T and then change the status of the original vertex to recovered. This method of simulation does not capture the temporal progression of an epidemic, but just the overall number and distribution of infected individuals.\n\nWe predicted the probability S that an outbreak with R 0 41 will lead to an epidemic for the three networks described in Figs. 1 and 2. S is often significantly less than one, and can be different for two networks with the same R 0 (Fig. 3) . When S is well below one and R 0 is well above one, it is very likely that communities with similar contact patterns will have diverse experiences with the disease, some experiencing large epidemics and other experiencing only minor outbreaks. In particular, above the epidemic threshold, the probability of an epidemic in the power law network and the probability of an epidemic in either of the other networks diverge quickly. Outbreaks are consistently less likely to reach epidemic proportions in the power law network than in the others. The vertical lines in Fig. 3 correspond to Fig. 3 . Predicting outbreaks and epidemics. The left graph illustrates the average number of people infected in a small outbreak, /sS, when T is below the epidemic threshold. The right graph illustrates S, the probability that an epidemic occurs when T is above the epidemic threshold. S also equals the expected fraction of the population infected during an epidemic, should one occur. The vertical lines correspond to recent estimates of R 0 for SARS pre-intervention (right) and post-intervention (left) (Chowell et al., 2003; Lipsitch et al., 2003; Riley et al., 2003) . Note that we chose the parameters for the power law and Poisson networks so that for any value of T, all three networks share the same R 0 : Simulation values are based on 2571 simulated epidemics, each starting with a unique individual in the network. estimates of R 0 for SARS in these three networks (Chowell et al., 2003; Lipsitch, 2003; Riley et al., 2003) .\n\nThe different vulnerability of these networks arises from differences in the patterns of interpersonal contacts. For example, power law networks are made up primarily of vertices with very few contacts, and have a small minority of superspreaders of high degree. They will surpass the epidemic threshold when there is a nonnegligible probability that an outbreak will reach members of this minority. Because superspreaders are rare, however, any particular outbreak may fail to reach this minority and thus never generate an epidemic. In contrast, vertices in a Poisson network will be fairly homogeneous and any two small outbreaks will be essentially equivalent. Whereas a power law network reaches an epidemic threshold only when transmissibility is sufficiently high to reach superspreaders with reasonable frequency, a Poisson network reaches an epidemic threshold only when the 'typical' outbreak leads to an epidemic. Thus in the Poisson network, most outbreaks above the epidemic threshold give rise to epidemics.\n\nStochastic compartmental models predict that a population with R 0 41 will experience an epidemic with probability 1 \u00c0 1=R 0 (Bailey, 1975; Renshaw, 1991) . How do we reconcile this prediction with the observation that three different networks all sharing the same R 0 have different epidemic vulnerabilities? In general, compartmental models make simple assumptions about contact patterns. The standard SIR model, for example, assumes a Poisson degree distribution. Thus, such predictions may hold for a single class of degree distribution, but cannot be generalized to arbitrary networks.\n\nWe also predict the size of a small outbreak when ToT c , an estimate that is often not attainable with compartmental models (Fig. 3) . Below the threshold, a typical outbreak in a power law network will die out after only one or two cases, whereas such outbreaks in the simulated urban or Poisson networks will include, on average, eight or ten individuals. Predicting the average size of a non-epidemic outbreak, /sS, can aid in intervention against infectious diseases that rarely or never become self-sustaining epidemics but nevertheless have significant impact.\n\nThe similarity between the values of S and /sS predicted analytically and those measured through simulation (Fig. 3) suggest that the analytical tools provide a powerful shortcut around computationally expensive epidemic simulations. While it may not be surprising that the randomly assembled power law and Poisson networks should fit the analytical predictions well, the simulated urban network introduces additional correlations in the network structure that are not considered in our analytic calculations.\n\nGiven that, for most diseases and most communities, the introduction of a single case may or may not spark an epidemic, we can ask what factors favor one or the other outcome (epidemic or no epidemic). Using the formulas described above, we predict the likelihood of an epidemic as a function of the degree of patient zero. Both simulation and analysis of the simulated urban network illustrate that the likelihood of an outbreak is a monotonically increasing function of the degree of patient zero (Fig. 4A) . Near the epidemic threshold, the risk increases exponentially with degree, whereas well above the epidemic threshold (e.g., R 0 \u00bc 2:7), the risk increases steeply until an epidemic is almost guaranteed. Therefore, even without differences in public health intervention, two identical communities can experience significantly different SARS outbreaks if the contact patterns of the first cases in each community differ.\n\nIn Fig. 4B , we predict the probability of an epidemic based on the size of the initial outbreak. Intuitively, the more initial cases there are, the more precarious the outcome. For diseases far above the epidemic threshold, the threat of an epidemic is overwhelming for even very small outbreaks. Thus vigilant tracking of case-contacts of the first few cases is of paramount importance in the control of such a disease.\n\nAlong with the behavior of patient zero, individual and organized forms of disease intervention can dramatically affect an outbreak. Here we describe a simple application of our analytical toolkit to predict the efficacy of control measures. There are two basic categories of intervention. Transmission interventions, like wearing face masks and washing hands, reduce the likelihood that a contact with another person leads to transmission of the disease. Contact interventions, like avoiding public places and rearranging the patterns of interaction between caregivers and patients in a hospital, eliminate or reduce the opportunity for such contacts.\n\nIndividuals can protect themselves by adopting such measures. If followed equally rigorously, an individual will benefit equally from the two forms of intervention. That is, by reducing one's contacts by a fraction a, an individual of degree k reduces his or her risk of infection from 1 \u00c0 \u00f01 \u00c0 T \u00fe Tu\u00de k to 1 \u00c0 \u00f01 \u00c0 T \u00fe Tu\u00de ak ; and reducing the likelihood of transmission per encounter by the same fraction a, reduces the risk to 1 \u00c0 \u00f01 \u00c0 aT \u00fe aTu\u00de k : To leading order, these two probabilities are equal. The efficacy of these strategies increases with the magnitude of the intervention a, decreases with the degree of the individual, and depends on the nature of the underlying contact network (Fig. 5) . Near the epidemic threshold, individuals of different degree benefit equally from such strategies. Well above the epidemic threshold, the more limited one's contacts, the greater the impact of such interventions. For very highly connected individuals, partial interventions will have little or no effect.\n\nThere are situations where one form of intervention is more feasible than the other. In such cases, instead of comparing transmission and contact reductions of equal compliance (as in Fig. 5) , one should compare transmission and contact interventions of equal feasibility. For example, the surgical masks seen on the streets of Hong Kong may be poorly effective against the SARS agent, and may hardly lower transmissibility, whereas the N-95 or surgical masks worn by hospital workers may be quite effective (Seto et al., 2003) . Furthermore, individuals may easily reduce their social interactions by avoiding crowded shopping malls and movie theaters, whereas hospital caregivers may be unable to reduce the number of patients with whom they interact. Thus, taking into account intervention feasibility, members of the general public may be advised to avoid contact opportunities, whereas hospital employees should invest in high efficiency masks.\n\nPolicy makers take a more statistical approach to intervention than do individuals. Their goal is to reduce the likelihood and size of epidemics while minimizing cost. The most restrictive policies, such as closed borders and quarantining every member of society, are economically catastrophic. Network theory allows us to predict quantitatively the epidemiological impacts of diverse strategies, which can then be paired with economic and sociological assessments of such strategies. We provide a simple example of such analysis.\n\nWidespread adoption of transmission interventions will lower T and may successfully bring a population ARTICLE IN PRESS Fig. 4 . Predicting an epidemic from initial conditions. (A) The probability that patient zero will ignite a full-blown epidemic increases monotonically with his or her degree. The calculations are based on the simulated urban network. Simulation values are based on 2571 simulated epidemics, one for every unique patient zero in the network. Discrepancy between simulations and analysis is likely caused by the finite size of the network, which contains very few high degree vertices, and by the intrinsic community structure in which high degree vertices (like teachers and caregivers) are preferentially connected to each other. (B) The probability of a full-blown epidemic in the simulated urban network increases with the size of the initial outbreak. This calculation does not assume knowledge of the specific degrees of the individuals affected in the outbreak, information that would improve the prediction. For each circle in the graph, we ran 100 simulations starting with the appropriate number of randomly selected initial cases and calculated the fraction of those outbreaks that gave rise to an epidemic. under the epidemic threshold. For example, if a disease is spreading through our simulated urban network with T \u00bc 0:1550 (equivalently, R 0 \u00bc 2:7), then Fig. 3 indicates that average transmissibility must be lowered by 62.9% to bring the population under the epidemic threshold (i.e., under T \u00bc 0:0575). An intervention that lowers transmission by less than 62.9% (for example, poor quality face masks) will not in itself prevent the emergence of an epidemic.\n\nAs illustrated in Fig. 6 , policy makers can also consider the quantitative impact of contact reducing interventions. For a disease with R 0 \u00bc 2:7 (T=0.1662) spreading through the Vancouver-like network, 50% reductions in contacts will have variable impact depending on the targeted demographic. Health care workers are more at risk than school children, other working adults, and non-working adults. A typical nonworking adult cuts his risk of infection by approximately 33% when he or she eliminates half of previous contacts, whereas a health care worker cuts his or her risk by only 17%. These reductions also reduce the probability that the individual will spark a large-scale epidemic by similar amounts. Policy makers can consider the impact of not only individual compliance, but also of large-scale intervention. For example, closing all schools would reduce the probability of an epidemic from 84.9% to 73.8%. In a related article, we use these methods to compare a large range of control measures for a spectrum of respiratory-borne diseases (Pourbohloul et al., In review).\n\nContact network modeling of disease transmission allows us to make quantitative predictions about the scale of outbreaks from information about the first few cases (Fig. 4) . This provides insight into the very different SARS outbreaks in Toronto and Vancouver. The first cases in both cities were exposed to SARS at Hotel M in Hong Kong on February 21, 2003 . Patient zero in Toronto (onset February 25, 2003 was the matriarch of an extended, multi-generational family who died at home on March 5 as an unrecognized case of SARS (Poutanen et al., 2003) . In addition to the five of ten persons within her family cluster who were affected, subsequent spread to health care workers, patients and their families culminated in more than 200 probable cases in Toronto, most of them indigenously acquired (Health Canada, 2003; Poutanen et al., 2003) . In contrast, patient zero in Vancouver (onset February 26, 2003) returned from traveling with his wife to an otherwise empty abode on March 7, 2003 and was almost immediately hospitalized (Poutanen et al., 2003) . Two of the three other probable cases in Vancouver were imported from abroad and no secondary case of SARS from patient zero was detected (Health Canada, 2003) . Fig. 4A illustrates that, in our simulated urban network, the difference between a patient zero with one to five contacts (Vancouver) and a patient zero with ten or more contacts (Toronto) can mean a doubling or tripling in the likelihood of an epidemic.\n\nThis analysis further sheds light on the importance of contact patterns to the fate of an epidemic. Settings with different contact networks may share the same R 0 , yet may differ significantly in their vulnerability to an epidemic and the impact of an epidemic should one occur. Realistic contact networks also allow detailed quantitative assessments of intervention strategies. A caveat to this approach is the static nature of our models. While our calculations capture the temporal progression of a disease through a population, we assume that the underlying contact patterns are fixed throughout an outbreak, a reasonable assumption if public health control measures are implemented early and consistently. While one can easily consider temporally changing interventions through epidemiological simulation, we have not yet developed analytic methods to predict the impact of such dynamics.\n\nR 0 is a valuable epidemiological quantity. It is relatively straightforward to derive based on routinely collected epidemiologic data and can be predictive in homogeneous settings; it also has historically informed effective vaccination strategies (Anderson and May, 1991; Hethcote, 2000) . Yet R 0 has its limits. Since R 0 is a function of both the transmissibility of a disease and the contact patterns that underlie transmission, then measuring R 0 in a location where contact rates are unusually ARTICLE IN PRESS Fig. 6 . Demographics of intervention. The impact of contact-reducing interventions varies by demographic sector. Health care workers are most at risk followed by school children, working adults, and nonworking adults. Light bars reflect baseline risk before intervention and dark bars reflect reduced risk to an individual who limits his or her contacts to half of the previous amount. Error bars are 95% confidence intervals that reflect underlying diversity of contact patterns within each demographic sector.\n\nhigh will lead to an estimate that is not appropriate for the larger community. As in the case of SARS, however, data is often only available for a limited and unrepresentative sample of the larger population.\n\nEstimating the transmissibility T instead of R 0 gives us a way out of this difficulty. This means reporting not just the number of new infections per case, but also the total estimated number of contacts during the infectious period of that case. Given the primary role of contact tracing in infectious disease control, the relevant data is often collected. As an alternative to such direct estimates of T, if the underlying contact network is known, one can estimate T based on epidemiological case counts. We can predict the expected number of cases at each generation of transmission as a function T (not described here) and thus estimate T by curve fitting to the appropriate data (Meyers et al., 2003) . The sensitivity of our epidemiological predictions to the estimated value of T will vary by both contact network and disease . For example, for highly contagious diseases (T40.2), the probability of a large-scale epidemic is much more sensitive to minor variations in T in the power law network than in the Poisson and urban networks (Fig. 3) . The reverse is true for mildly contagious diseases just above the epidemic threshold.\n\nUnlike R 0 ; T can be justifiably extrapolated from one location to another even if the contact patterns are quite disparate. We offer a simple example to illustrate the benefits of measuring T. Suppose we measure R 0 \u00bc 2:7 in a hospital where the average individual comes in close contact with 100 other individuals. Then the probability that an individual will catch the disease from an infected contact is just 2.7% or, in network terms, T \u00bc 0:027: Now suppose the typical individual in the general population has 10 close contacts that could potentially lead to the spread of a disease. If we extrapolate R 0 \u00bc 2:7 to the general public, then we predict that, on average, 2.7 out of every 10 contacts or 27% of contacts become infected, whereas if we extrapolate T=0.027 to the general public we still have only 2.7% of contacts becoming infected, which gives us a much reduced expectation for the spread of the disease.\n\nWe have illustrated that percolation theory allows us to shortcut time-consuming simulations to produce robust predictions about the size and likelihood of an epidemic, the implications of patient zero's contact patterns and the initial size of an outbreak, and optimally reducing the risk of infection at a personal and population level. To truly reap these benefits of the network epidemiology, we must have not only good estimates of T but also realistic models of contact networks. We have presented a first step towards a realistic community network and have shown that it departs significantly from the idealized networks previously used in network epidemiology, and yet still is sufficiently random for the application of epidemiological network analysis. The task of making even more realistic contact network models of small communities, hospitals, cities, even the global the population is enormous, but promises a step change in our ability to predict and effectively control the spread of infectious disease. As we incorporate better data at these various scales, network theory will allow us to generalize our predictions and make better suggestions for epidemiological control."}