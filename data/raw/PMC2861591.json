{"title": "Syndromic Surveillance for Local Outbreaks of Lower-Respiratory Infections: Would It Work?", "body": "The SARS epidemic in 2003, the bioterrorism attacks in 2001, and the ongoing threat of new infectious disease outbreaks have prompted many countries to invest in their capacity to respond timely to emerging infectious disease outbreaks, as early outbreak-detection may well mitigate their impact. As a result, new surveillance systems for earlier detection have been implemented, often labeled \u201csyndromic surveillance\u201d [1]\u2013[6]. These systems use increased reporting of critical symptoms or clinical diagnoses as early indicators of infectious disease outbreaks. This not only allows monitoring of clinical syndromes before laboratory diagnoses have been made, but also allows detection of outbreaks of diseases for which no diagnostics were requested or available (including emerging pathogens). Geographic analysis methods \u2013 such as space-time scan statistics \u2013 may further increase the sensitivity of syndromic surveillance for detection of local outbreaks or of regional differences in regular seasonal epidemic diseases [2], [6]. In the SARS outbreak in Hongkong in 2003, it is believed that a near real-time space-time analysis would have detected the highly unusual clustering of severe acute respiratory syndrome cases much sooner [7]. However, concerns exist about the specificity of space-time syndromic surveillance, i.e. that it might generate many false signals [8], [9].\n\nThe objective of this study was to evaluate to what extent syndromic surveillance detects local outbreaks of lower-respiratory infections (LRIs) without swamping true signals by false alarms. Using retrospective hospitalization data, we simulated prospective space-time syndromic surveillance for LRI-elevations. The two largest outbreaks of Legionnaires' disease in the Netherlands in the last decade were used as \u201cpositive controls\u201d to test whether these known outbreaks would have been detected by space-time signals in LRI data. To assess other (likely) causes for detected LRI-elevations, we examined regional increases in the reported incidence of influenza-like-illness (ILI), hospital discharge diagnoses for respiratory illnesses and age group distributions for LRI cases. We also evaluated whether the number of generated space-time signals can be reduced by restricting the time and spatial windows for the analyses.\n\nSince we only used anonymous data from existing medical research and surveillance registries, neither formal ethics committee approval nor informed consent from the patients were required.\n\nHospitalization data were collected from the Dutch National Medical Register (discharge and secondary diagnoses by date of hospitalization for 1999\u20132006). In 1999\u20132004 this registry had a 99% coverage (16 million pop.) and in 2005/6 approximately 80%, after exclusion of hospitals with incomplete data for those years.\n\nWe included all records on hospitalizations with any kind of LRI as either discharge or secondary diagnosis, under the assumption that this reflects prospective classification of patients with a lower respiratory infection in a \u201cLRI-syndrome\u201d on the day of hospitalization. ICD-9-CM (International Classification of Diseases, 9th revision, Clinical Modification) codes for a LRI syndrome were selected from the CDC respiratory syndrome codes-list (Centers for Disease Control and Prevention, USA, http://www.bt.cdc.gov/surveillance/syndromedef/; and see Appendix S1). After excluding duplicate hospitalizations of the same patient within 6 weeks (5% excluded), 222638 records were included for 1999\u20132004, and 68124 for 2005\u20132006. Data were aggregated by hospitalization date, postal-code and age group (0\u20134, 5\u201319, 20\u201349, 50\u201364, \u226565 years). Since higher levels of spatial resolution can result in more sensitive detection of outbreaks [10], [11] we used 4-digit postal-codes (4023 areas in a 16 million population), which provide the highest level of spatial resolution available within privacy regulations.\n\nILI-data were collected from a sentinel network of general practitioners (GPs, Continuous Morbidity Registration Centres, CMR sentinel stations, 1% population coverage) [12]). The ILI-counts and underlying GP-practice populations were aggregated by region and week. The GP-practice populations were corrected for weeks that specific GP-practices did not supply data. Due to the small number of GP-practices in some parts of the country, the weekly ILI-data were aggregated in 4 major regional groups instead of postal codes.\n\nTwo large outbreaks of Legionnaires' disease were used as \u201cpositive controls\u201d for emerging LRI-outbreaks [13], [14]:\n\nFor the LRI-data, we used a space-time permutation scan statistic which compared the observed number of cases in circular areas with variable radii in flexible time periods vs the expected number of cases, based on the geographic distribution of cases in the whole dataset [15]. In this way, only the case data is needed to estimate the expected number of cases in each space-time window, and population density and time trends in the case data are automatically adjusted for.\n\nWe used SaTScan software [16] and the SaTScan Macro Accessory for Cartography (SMAC [17], applied in SAS version 9.1, SAS Institute Inc., Cary, NC, USA) to run the scan-statistic and visualize the results. We simulated a prospective surveillance by running the scan-statistic on data from the year preceding each time unit (day or week) in the analysis period. Thus, weekly or daily space-time signals were generated, each time that the observed number of cases in a certain space and time window exceeded the defined significance threshold. Since such analysis consumes a lot of computation time, we performed weekly analysis (instead of daily) over the whole study period. Daily analyses were also performed in the years that the test-case outbreaks occurred (1999 and 2006), to assess the earliest possible detection date. For all analyses, we chose to use a time-aggregation level of 7-days length. For the daily analyses, these 7-day aggregation windows shifted one day forward for each daily run. Thus we both reduced the computation time and adjusted for day-of-week effects (both purely temporal and spatial day-of-week effects).\n\nTo indicate the significance of detected space-time signals, we used recurrence intervals, which indicate how often a signal of the observed significance would be observed by chance under the hypothesis of no outbreak [18]. I.e. if the recurrence interval of a signal is say 1 year, 1 signal of the observed significance is expected in 1 year. Two thresholds levels were used: signals with recurrence interval \u22651 and \u22655 years. We assessed whether successive signals overlapped in space and time, which suggests the same cause. For the sake of readability, we indicated a group of such overlapping space-time signals as \u201ccluster\u201d and an individual space-time signal as \u201ccluster-signal\u201d.\n\nWe evaluated how many LRI-clusters and signals were detected over the whole study period (1999\u20132006) and looked for explanations guided by the two-step criteria in Figure 1. In step one, we assessed likely causes for the cluster-signals by looking for significantly higher proportions of specific hospital discharge diagnoses (e.g., Legionnaires' disease [19], [20]). In step two we assessed overlap with regional ILI clusters (Appendix S2), as (local) influenza activity might be reflected in local LRI-elevations. Since other pathogens than influenza might cause some ILI fluctuations, influenza activity was only considered to be a likely cause if space-time overlap between LRI and ILI-clusters coincided with the annual influenza season (Figure 1). If a specific cause was defined for one or more signals within one cluster, we considered that to be a likely cause for the whole cluster. We also evaluated the timeliness of detection for the clusters related to the known Legionnaires' disease outbreaks.\n\nA sensitivity analysis was used to evaluate the impact of time and spatial window settings on the number of clusters and signals detected. For the initial analyses, we put only minor constraints on the maximum temporal and spatial windows of the scan-statistic, to avoid wrongful assumptions about time, geographical location and size of an outbreak. We then repeated these weekly analyses with a temporal window of maximum 7 weeks and also with a spatial window of maximum 25 km radius, to assess the impact of these parameters on the number of signals generated.\n\nSee Appendix S2 for further details on use and settings of the scan-statistics.\n\nBetween Feb 1st 1999 and Sept 30th 2006, a total of 35 LRI-clusters with 221 cluster-signals were detected by weekly analysis (Table 1, non-restrictive parameter settings, recurrence interval \u22651 year). By raising the threshold (recurrence interval \u22655 years), we observed only 24 clusters with 146 cluster-signals (respectively 31% and 34% decrease). Figure 2a shows all LRI-clusters and signals on a timescale for the different recurrence interval levels \u2013 as detected with the initial non-restrictive parameter settings for space and time windows. The time between the first and the last signal within one cluster ranged from 0 to 26 weeks. By daily analysis, in 1999 and 2006 a total of 194 cluster-signals were detected (compared to 75 signals by weekly analysis with a \u22651 year recurrence level, both with non-restrictive parameter settings). However, the number of clusters was lower (10 clusters by daily analysis vs 12 by weekly analysis in 1999 and 2006).\n\n\nFigure 2a and Table 1 also show the likely causes for the detected LRI-clusters (according to the criteria in Figure 1, see methods section). The known Legionnaires' disease outbreaks in 1999 and 2006 were detected by LRI-clusters, since cluster-signals were generated with an increased proportion of patient discharge diagnoses for Legionnaires' disease in both outbreak areas and periods (Table 1, Figure 2a and 3a\u2013b) (proportions differed between successive signals: 44\u201365% in 1999, and 21\u201363% in 2006; p:<0.0001). The 1999 Legionnaires' disease related cluster-signals included a higher proportion of persons 50\u201364 years of age (37\u201348%; p:<0.0001). We compared the earliest detection dates for these outbreaks for daily and weekly analysis. Daily analysis signaled the outbreak 4 days earlier than weekly analysis, 2 days before the national alarm was given during the 1999 Legionnaires' disease outbreak. The 2006 Legionnaires' disease outbreak was detected by weekly analysis on 2006 July 15th, and could have been detected by daily analysis 5 days earlier, 3 days after the national alarm was given.\n\nMany of the other clusters and signals seemed to be related to local RSV and/or influenza activity (70% of cluster-signals and 60% of clusters, Table 1). Some of the influenza and RSV related clusters tended to persist over longer periods (Figure 2a). Young children (0\u20134 years old) were overrepresented in 82 of the 99 cluster-signals that we scored as RSV related (Table 1; p:<0.05).\n\nIn 2000, a cluster was detected with an unusually high number of patients diagnosed with aspergillosis, which was traced to a registration error (one patient was accidentally registered under 28 different anonymous identifiers).\n\nFor 46 cluster-signals we did not find a \u201clikely cause\u201d according to the criteria in Figure 1. Of these, 6 belonged to influenza and/or RSV related clusters (Figure 2a), and 11 coincided with local ILI-elevations outside the influenza season (1 at the end of spring 2000, 4 at the end of summer 2000 and 6 at the end of 2005).\n\nWhen repeating the weekly analyses with restricted time or spatial windows, both Legionnaires' disease outbreaks were still detected with the same timeliness. Table 1 and Figure 2b and 2c also show the clusters and signals that were still detected with a temporal window of maximum 7 weeks, and with a spatial window of maximum 25 km respectively (as compared to the signals detected with the initial non-restrictive settings).\n\nWith a time window of maximum 7 weeks, 129 of the 221 initial cluster-signals and 30 of the initial 35 clusters were still detected (respectively 42% and 14% decline, Table 1). Of the 5 clusters not detected \u2014 as compared to the initial analyses \u2014 2 had been scored as likely due to RSV, 1 to influenza and for the other 2 no likely cause had been scored (Table 1 and Figure 2a\u2013b).\n\nWith a maximum 25 km radius, 165 of the 221 initial cluster-signals and 33 of the 35 clusters were still detected (respectively 25% and 6% decline, Table 1). One of the 2 undetected clusters had been scored as likely due to RSV, for the other no likely cause had been scored (Table 1, Figure 2a and 2c).\n\nSome of the cluster-signals detected with restrictive time/spatial windows had not been detected with the initially detected signals (data not shown). With the restrictive time window 2 borderline significant cluster-signals were detected, that had been non-significant in the initial analysis. This was due to the fact that the restrictive settings limited the adjustments for taking into account the multiple testing (stemming from the many potential cluster locations and sizes evaluated) [15]. With the restrictive spatial window 3 extra cluster-signals were detected due to the same mechanism, and 2 other extra cluster-signals were detected due to the fact that initial cluster-signals that geographically overlapped with them had dropped out.\n\nThis retrospective study shows that space-time syndromic surveillance on hospitalizations can timely detect local LRI-outbreaks independent of detection of the causative pathogen. The frequency of cluster detection, when interpreted in the light of available epidemiological and microbiological data, does not give rise to excessive levels of further investigations.\n\nConsequently, we recommend real-time syndromic surveillance as an additional tool for detection of local LRI outbreaks, but only if syndromic data with sufficient quality and coverage can be collected, coupled with epidemiological and microbiological data. Public health responses can be based on a combination of syndromic surveillance data, reports by astute clinicians and early diagnostic test results, which all could generate the first alarm for different kinds of disease events. Future research on prospective syndromic surveillance should therefore focus on practical methods for integrating syndromic surveillance alarms with clinical reports and laboratory information for effective public-health responses."}