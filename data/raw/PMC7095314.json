{"title": "Planning for smallpox outbreaks", "body": "Events of recent years have heightened awareness of the potential threat of bioterrorism1, with smallpox considered to pose the greatest risk owing to the lethality (around 30%, depending on age and other factors2,3) and transmissibility of the virus. Although once endemic in many human populations, smallpox was eradicated in 1979 largely as a result of mass vaccination reinforced by other highly focused control measures3. Today, although viral samples are officially retained in only two locations, the existence of other sources cannot be ruled out4. In the face of such a difficult to quantify, unlikely, but potentially serious threat, contingency planning demands a rational assessment of the scale of casualties that a smallpox attack might cause, and identification of what controls might be optimal in minimizing its effects5,6,7,8. The latter task is complicated by the severe adverse effects of vaccination experienced by a significant minority of individuals9,10, such that a national mass vaccination campaign could cause more deaths than an isolated smallpox epidemic. A second key problem is the passage of time since the last smallpox outbreak: human populations, mobility and patterns of social interactions have changed in the last 30 years, complicating extrapolation from historical epidemics to the prediction of future outbreaks.\n\nMathematical models of the transmission of infectious agents are valuable tools in making such assessments, because they can integrate epidemiological and biological data to give quantitative insights into patterns of disease spread and the effect of interventions. Examples include the design and evaluation of childhood disease immunization programmes11,12, predicting the demographic impact of the HIV epidemic in different regions13, and analysing the spread and control of the 2001 foot-and-mouth epidemic in Britain14,15,16,17.\n\nFollowing this philosophy, four recently published analyses of the potential spread of smallpox virus in modern urban communities all rely heavily on mathematical modelling5,6,7,8. Given that a key aim of these studies was to inform public health planning, it is unfortunate that their conclusions differ as to which type of vaccination strategy might be optimal, and on the scale of casualties likely to result from a smallpox attack. As mathematical modelling is the only way that we can examine the possible impact of different release and control scenarios, it is important to understand the strengths and weaknesses of different modelling approaches and how model assumptions affect the conclusions drawn.\n\nA variety of methods exist for controlling the spread of smallpox, ranging from different vaccination strategies to movement/contact restrictions placed on infectious cases and their contacts (Table 1). Thus a key aspect of policy-orientated epidemic modelling is to assess both the adequacy of current policy and how it might further be optimized. Optimality is principally the minimization of mortality and morbidity, so it is critical that models accurately incorporate expected adverse event rates from vaccination. However, the SARS virus has shown that the economic costs of an epidemic can be out of all proportion to the numbers infected, indicating that minimizing the duration of a smallpox outbreak might also be a critical priority when formulating control strategy.\n\nIn all cases, it is critical that models explicitly capture the underlying mechanism of the control policy being investigated. The net effect of a control policy on disease transmission is well characterized by its impact on R: the effective reproduction number during the epidemic (Box 1). However, estimating this effect on R without explicit modelling of the details of a control policy is practically impossible for complex models that include population heterogeneity and a realistic description of disease biology. Models which just assume a priori the effect of a control measure on R (see for example refs 5, 8) have little inferential power because the predicted effectiveness is determined by the assumed value of R.\n\nIn addition to R, other factors determine the effectiveness and likely success of any given control measure. These include the likely scale and geographic extent of any bioterrorist attack, associated risks or fatalities due to the control, the disruption to civic society, the level of vaccine uptake, overall resource requirements, and the ability of health agencies to implement policies. Models should therefore incorporate realistic logistical constraints on policy implementation6, and, if needed, economic costs. There may also be a subtle interplay with epidemic dynamics here. For example, ring vaccination is constrained to the speed of the epidemic, whereas mass vaccination could in principle proceed as quickly as logistics allowed, thereby minimizing the duration of an outbreak.\n\nA key benefit of using models to examine disease control options is their ability to explain and\u2014with appropriate caveats\u2014predict trends at a population level from interactions and processes at the individual level. Often the emergent dynamics at the population scale may be anything but obvious, owing to the many nonlinearities, complexities and feedbacks arising from the basic mechanisms at the individual level.\n\nA corollary of the need to capture the mechanisms of transmission and control policies is that models have to be appropriately designed for the questions being addressed (Box 2). For instance, the feasibility of implementing different control policies is a key issue that will depend on the incidence of the disease. Models need to incorporate logistical constraints on policy implementation (for example, how many people can be vaccinated per day6) that are commensurate with that level of incidence. If the speed/risk of spread between communities is of interest, then models need to incorporate spatial structure. If contact tracing is to be assessed then some concept of social structure must be included.\n\nTable 2 compares model structures and assumptions of four recent studies5,6,7,8. The diversity of model structures chosen and assumptions made regarding infection seeding, spread and control complicates direct comparison of the results of these studies. One issue for all the studies is the numbers of parameter values that are assumed, rather than estimated from data21. The most important factors determining the conclusions drawn by two of the studies6,7 are the assumed infectiousness during prodrome relative to that during symptomatic disease, and the relatively low effectiveness of isolation of symptomatic cases assumed. New best estimates from a well-observed historical epidemic in Africa indicate prodromal transmission alone contributes 0.16 to R0 (ref. 21), 2.4% of the total R0 value of 6.9. Both of the studies assumed that prodromal R0 is 2.5\u20133 out of a total R0 of around 3 (refs 6, 7). Analyses using the new estimates show that isolation and ring vaccination\u2014if logistically feasible\u2014is nearly always optimal, and never markedly worse than mass vaccination at minimizing mortality24.\n\nThe remaining two studies make simplifying assumptions that limit their usefulness. Reference 5 assumes purely exponential epidemic growth, meaning that little can be inferred about outbreaks of large size or duration. References 5 and 8 assume (rather than model) the impact of different control measures on transmission, meaning that their conclusions regarding control policy effectiveness are largely predetermined.\n\nThe need to increase model sophistication and accuracy gives rise to an intrinsic tension: as model realism is increased the transparency associated with simple frameworks is often lost and the validation of model conclusions becomes harder. For models to be useful tools in policy planning, it is essential that they can be parameterized from available data, and tested against past and current epidemic outbreaks, with proper consideration of changes in human populations with respect to immunity, mobility and patterns of social interaction.\n\nSimple models have fewer parameters, which tends to make parameter estimation easier. Conversely, more complex models may have dozens of parameters describing the details of disease biology, host movement patterns and population structure. Unless all these parameters are robustly estimated or the effect of uncertainty in their values explored, there is a danger that incorrect assumptions will be made (and obscured by the complexity); this can make more detailed models no more reliable (and sometimes less so) than simpler frameworks. Achieving the correct balance between model complexity and validation is therefore key to informative modelling (Box 2 and Table 2). Validation in this context is how well the model matches observed epidemic behaviour at the level of detail relevant to the model's purposes. Ideally, such data should be independent of any epidemiological data used to estimate model parameters. When this ideal is not achievable (for example, when analysing an emerging epidemic of a novel disease25,26), the use of rigorous statistical methods for assessing model goodness of fit is imperative.\n\nThe most useful data for parameterization and validation of models are detailed (individual case) reports from historical outbreaks2,3. Such data provide the only reliable estimates of the reproduction number of smallpox (4\u201310, depending on the outbreak20,21), and information on how infectiousness varies at different disease stages2,21. However, extrapolating from historical data to contemporary developed-world populations is problematic. It is unclear how much residual immunity remains today as a result of past vaccination programmes; those vaccinated 25\u201330 years ago are unlikely to possess complete immunity and a significant proportion may develop less severe forms of the disease2,3, potentially changing the dynamics of transmission. Allowing for past immunity levels is therefore critical when estimating R0 from historical data20. Historically, most infections occurred in care-givers to symptomatic individuals, whether in households or hospitals3. It is unclear how 30 years of changes in household sizes, working patterns and mobility would affect transmission patterns today (see Box 2). Incorporating detailed data on demographics and human mobility into spatially explicit models offers one method by which such extrapolation can be made more reliable, but the scale of changes mean that much uncertainty will inevitably remain.\n\nWith such uncertainty, it is critical that risk assessment studies use modern statistical methods27 to obtain the best possible parameter estimates from historical data, while allowing for changes in the last 30 years. However, historical data are less relevant for some key parameters\u2014such as the likely scale of a bioterrorist attack, how rapidly the disease would be recognized, and the ability of public health authorities to respond. Furthermore, it is unclear how population behaviour would change in the face of an epidemic. Before recognition of the outbreak, would individuals in the latter stages of prodrome have more or fewer contacts, compared with their historical counterparts? Once smallpox is identified, will people voluntarily restrict their movements, or attempt to flee urban centres? These factors need to be explored with robust analysis28,29 of the sensitivity of model results and predicted optimal controls to parameter assumptions.\n\nParticularly important is the assessment of the potential for catastrophic outcomes. A policy option may be optimal for the great majority of possible parameter scenarios, but fail to control disease spread in a few worst-case scenarios, which are still feasible given current data. An alternative policy option that is slightly less optimal for most scenarios but controls spread in the worst case might then be preferred.\n\nFor models to have a meaningful role in influencing policy decisions, it is therefore critical that not just \u2018most likely\u2019 or \u2018worst case\u2019 scenario modelling results are communicated but that a more detailed understanding of the sensitivity of predictions of outbreak size and policy optimality to model assumptions is conveyed, together with open acknowledgement of model or data weaknesses. Once an outbreak has begun, such questions may also be answered more precisely through the use of real-time modelling to refine parameters and better inform policy.\n\nGiven the many uncertainties outlined above, we argue that no model can be truly predictive in the context of smallpox outbreak planning, and no one control method can be identified a priori as best. Instead, modelling should aim to identify effective interventions for a variety of release scenarios that span the ranges of uncertainty in key parameters. By attempting to identify a single \u2018optimal\u2019 strategy, recently published studies are arguably attempting the impossible; this is reflected in their differing conclusions, which can largely be attributed to underlying differences in model structures and parameter assignments. A more useful goal for modelling is to identify a small set of control options that might be used in a range of scenarios, together with a set of trigger thresholds, which might determine when responses need to be escalated. The key is to match model structure and aims to determine the \u2018necessary\u2019 level of detail.\n\nWhile recognizing the limitations of modelling for precise prediction, models represent a potentially powerful resource in the face of an actual outbreak. The 2001 foot-and-mouth disease epidemic in Britain14,15,16,17 highlighted the contribution that real-time statistical analysis and modelling could make in both predicting the future course of the outbreak and identifying the measures needed for its control. For smallpox, such a role might be even more critical\u2014to identify which of the many parameter and release scenarios explored in preparatory planning is actually being realized (for example, in relation to changes in population behaviour caused by the outbreak), and thus which set of controls is likely to be optimal in containing the outbreak while minimizing casualties. The foot-and-mouth story highlighted the potential advantages to be gained from having model and data structures in place as much as possible before any epidemic. In this sense recent studies5,6,7,8 and the ensuing debate are to be welcomed.\n\nKey to such a role is how much information would be available during the early stages of an epidemic to enable the analysis to be reliable; such data would also need to give enough early warning of a \u2018failing\u2019 intervention to allow intensification of controls sufficiently rapidly to prevent substantial excess deaths. Investigation of this issue now, using simulation and analytical studies, is critical. Real-time data capture and dissemination is essential, and infrastructure needs to be developed in advance to facilitate this critical mechanism for implementing and monitoring interventions. Currently, it is unclear what level of detail would be necessary for models used in such a context\u2014although some incorporation of the random effects that dominate epidemics in their early stages would clearly be desirable. If it were determined that the first few generations of cases in an outbreak would give insufficient information for real-time policy optimization, then a precautionary \u2018hit hard, hit early\u2019 policy might be warranted (coupled with a set of criteria for de-escalating the policy), despite the higher associated costs and adverse consequences of vaccinating more people than might strictly be necessary. Such considerations are of equal relevance to the emergence of new pathogens such as SARS25,26, as they are to deliberately released agents."}