{"title": "Integration of virtual and physical screening Virtual versus physical (high-throughput) screening Drug Discovery Today: Technologies", "body": "The random physical screening (PS) of compound collections, that is the in-house database of a pharmaceutical company, or the catalogs of various chemicals' vendors, represented a long-range strategy and was regarded as a substitute for serendipity [1] .\n\nAutomated compound handling and assaying facilities currently enable tasks such as compound retrieval from storage, dilution and plating of samples; therefore, PS is reaching its potential to identify hits on a timely basis. While random screening has enabled some successes, it has not fulfilled initial expectations. A gross increase in the number of assayed compounds does not guarantee better productivity per se [2] .\n\nAlso, PS results are not free from errors and different assay formats for the same target can give different results [3, 4] .\n\nThe in silico screening of (virtual) libraries of compounds is conceptually and economically attractive, as it makes possible the evaluation of an almost unlimited number of chemical structures, only a subset of which will be selected and subsequently assayed in a PS experiment. Typical virtual screening (VS) methods involve, for example, filtering of libraries for compounds containing toxic, reactive, or otherwise undesirable groups, or, by contrast, the search for molecules with preferred lead-or drug-like properties and desired activity [5] . In fact, VS is emerging as a key strategy to help filter out those compounds with poor potency, and biological or pharmacological properties [6] [7] [8] . Recent reviews suggest that while VS is often presented as an alternative to PS, both strategies are highly complementary [5, 9] .\n\nThe current trend in the pharmaceutical industry is to integrate computational and experimental technologies early in the drug discovery process [10] [11] [12] [13] . For instance, it is considered that a better and earlier utilization of information, that is (i) genomic, (ii) chemical, (iii) biological, (iv) structural, and (v) molecular property data, would lead to chemical libraries with more desirable chemical and biological properties [14, 15] . This can be done by integrating information from different areas that include: (i) analysis of the gene or protein family for target selection; (ii) absorption, distribution, metabolism, excretion and toxicity evaluation (ADME/ Tox); (iii) structural biology; (iv) VS; and (v) medicinal chemistry with parallel synthesis (Fig. 1) .\n\nLiterature reports from 2005 to 2006 show an increased dependence on the integration VS and PS for identifying leads in the drug discovery process. Twenty-three representative studies are summarized in Table 1 , which lists (i) the target studied, (ii) the strategy applied for both VS and PS methods, (iii) the size of the library evaluated, and (iv) the results achieved in each project. The last column indicates the original references. Table 1 reveals the VS workflow used in most of the studies: (i) preliminary filtering of a virtual library (tens to hundreds of thousands of compounds) using various criteria (e.g. Lipinski's rule of five); (ii) homology and pharmacophore modeling; combined with (iii) docking and scoring of the protein-ligand complexes. For PS methods, assays that are particular to each specific target were applied, most of them being based on fluorescence detection. The outcome of these studies indicates that preliminary VS not only drastically reduces the number of chemicals that are physically screened, but also increases the hit rates.\n\nVS is a knowledge-driven approach that depends on the amount and quality of information available about the system under investigation. Knowing the structure of the biological target macromolecule offers many advantages in comparison with the situation where only information about the geometry of a bioactive (reference) ligand is available. When structural information about the target is available from either fact or inference, we consider this target-based, or structure-based, virtual screening (TBVS). All other cases represent ligand-based virtual screening (LBVS), where the reference compound(s) are known substrates, inhibitors, agonists or antagonists, among others. An important issue in target selection is the druggability of the molecule under consideration, and whether the target is amenable to therapeutic intervention via small molecules. One approach is to assess whether members from the same gene family show similar binding affinity towards drug-like ligands with related physicochemical properties [16] ; the other approach is sometimes referred as 'target fishing' (see J. L. Jenkins, this issue).\n\nWith the advent of structural genomics and homology modeling initiatives [17] , the number of potential targets is expected to grow. For instance, over the last year (2005) (2006) , 26 new targets were screened at the NIH Molecular Libraries Initiative (formerly the Molecular Libraries Screening Center Network) (http://mli.nih.gov/); more are expected to be screened within next 2 years. Our Center (New Mexico Molecular Libraries Screening Center: http://screening.health.unm.edu/) has undertaken projects on several classes of receptors, which include two GPCRs listed in Table 1 and an integrin, LFA-1. For the formyl peptide receptor, we compared several strategies including screening of class-focused (GPCR) and target-focused (FPR) libraries (Table 2 ). In the latter case, we used a homology model with pharmacophore docking to select a compound library [18] . We recorded active molecules at the rate of 1/880 from the Prestwick Chemical Library (http://www.prestwickchemical.com/chem_lib.htm), 17/9993 in a diverse set from the NIH Small Molecule Repository (http://mlsmr.glpg.com/ MLSMR_HomePage/), 12/4959 in a GPCR class focused library from ChemDiv (http://www.chemdiv.com/en/products/screening/), and 30/4324 in a target focused library [18] .\n\nIn the case of GPR30, where no Target-specific ligand was known, we performed LBVS on the latter two libraries, using 17b-estradiol as the reference ligand. We ranked the top 100 structures for PS, finding one selective nM affinity agonist for GPR30 [19] and two ERa/ERb that do not bind to GPR30 (C.G. Bologa, unpublished).\n\nThe generic workflow shown in Fig. 2 is currently implemented at the New Mexico Molecular Libraries Screening Center, and follows the general template presented in Fig. 1 . The core of the system is represented by the 'screening database' where complete information related to the (i) chemical structure data of the compounds, that is existing in-house or purchased from different vendors, and (ii) bioactivity data, that is plate format information and biological screening outcome, is recorded. The workflow steps are well defined. The biological team provides the target and the corresponding assay to the screening team, which is responsible for the PS. Once compounds are registered into the database by the cheminformatics team, plates are created and recorded in the database. The medicinal chemistry team provides chemistry follow-up and property optimization.\n\nThere is a continuous information exchange between the screening, cheminformatics, and medicinal chemistry teams. Based on the outcome from the screening team, the cheminformatics team applies VS and post-high-throughput screening (HTS) analyses to further identify and prioritize compounds (or chemotypes) for further evaluation. The medicinal chemistry team verifies the chemical qualitative chemistry (QC) of the proposed hits and gives feedback to both the screening and cheminformatics teams. The final result is represented by the so-called 'chemical probe', which can be an inhibitor, activator or modulator of the studied target.\n\nVS methods have been comprehensively reviewed [20] (see I. Muegge, this issue). Therefore, only a brief description is given here. Our VS workflow is shown in Fig. 3 . There are two main types of VS: (i) target or structure-based virtual screening (TBVS, or SBVS); and (ii) LBVS.\n\nTBVS is applied when the target (protein, enzyme) structure is (i) known, based on the crystallographic or other structural methods, or (ii) built, using homology modeling. The procedure consists of docking a large number of molecules into the active site of the target, then scoring the binding affinity. The limiting step in this strategy is accurate scoring. There are four categories of scoring functions:\n\n(i) Knowledge-based methods [21] Because none of the above schemes has been shown to be general, it is preferable to use consensus-scoring methods [26] . LBVS methods start from known bioactives, which can be inhibitors or activators. Similarity search [27] and classification [28] methods can be used to select novel scaffolds (see K. V. Balakin, this issue). Filtering can be applied (i) forward or (ii) backward to the hits obtained in the VS campaign. In forward filtering [29] , the selection criteria are used to reduce the size of the initial library, that is from several millions to several hundreds or hundreds of test compounds further to be docked. The backward procedure uses filtering criteria to prioritize candidates for PS during post-HTS analysis [30] .\n\nTesting strategies for the selected compounds can include does-response characterization and cytotoxicity of the selected compounds. In our Center, many of the assays are being set up as high throughput multiplexes so that selectivity and specificity information against families of targets is available for individual compounds. The physical properties of the components to be tested contribute to the screening strategy because the presence of molecules which are insoluble, are aggregators, or are fluorescent, can interfere with the identification of their activities in the assays.\n\nWhen screening 100,000 to more than 1,000,000 compound libraries, it is paramount that the assay be optimized for complexity/simplicity (minimal additions, no wash steps, simple detection schemes), volume (typically no more than 10 mL, permitting use of 384 or 1536 well plates) and reproducibility (because the library is only screened once or twice). However, if VS technologies can reduce the library size to 10's or 100's of compounds, many of these constraints are lifted allowing the use of more physiologically relevant or complex assays, potentially including whole animal-based assays, which are recognized as a viable alternative in today's search for novel pharmaceuticals. Another issue related to assay implementation is the selection of in vitro vs. in vivo assays. Many of the initial hits in enzyme/protein-based in vitro assays may fail at the cellular or animal level due to stability or metabolism issues. However, with the development of VS and post-HTS analysis methods, this can be minimized. Finally, assay selection has a strong influence on the outcome of the physical screen. For example, the use of a simple binding assay screen can yield both agonists and antagonists of target activity. If only agonists are desired, a functional assay based on target activity might be preferentially selected.\n\nThe results of both VS and PS can yield a large number (often in the order of 100-1000) of interesting hits that warrant further attention. The issue of what molecules to select for dose-response confirmation is often left with the medicinal chemist or the biologist, and requires cheminformatics support. In our center, we apply the following post-HTS prioritization scheme [30] for chemotype as well as individual molecule evaluation (See Box 1).\n\nThus, post-HTS analysis is essentially a practical step designed to assist the decision-makers to evaluate compounds for further experiments. It should be applied only to confirmed hits, both at the structure and purity, as well as at the dose-response level. The final score captures information related not only to actives, but also inactives from the same chemical family, while the intellectual property and toxicity evaluation schemes are aimed at encoding information related to individual chemotypes. At the individual molecule level, the use of estimated physico-chemical properties can assist the final prioritization score.\n\nThe integration of VS and PS technologies is attractive for both scientific and economic reasons. Scientifically, one can reduce the search space to rapidly find a solution; economically, one is no longer required to screen millions of compounds physically, before identifying hits. Negative aspects of this integration effort are of theoretical and practical nature. Theoretically, the streamlining of PS may result in testing the wrong library subset. This relates to both the limitation of theoretical methods, and to the inappropriate use of VS technologies. Practically speaking, it is possible that the entire effort leads to naught; in this case, doubt is typically cast over in silico approaches, although experimental techniques are not without flaw either. Continuous information exchange and effective team communication, as illustrated in Fig. 2 , will avoid such negative situations.\n\nIntegration of these technologies is further supported by the increasing amount of valuable information being deposited in target and bioactivity databases (see T.I. Oprea, this issue). Conceivably, one can apply existing information to improve the success rate by using, for example, machine learning techniques to develop target-specific libraries; or to include target-specific or ligand-specific information in Vol. 3, No. 4 2006 Drug Discovery Today: Technologies | In silico techniques Box 1. Evaluation criteria to select molecules for chemistry follow-up (i) Chemotype evaluation: This criterion gives higher priority (a) to chemotypes that occur more in active compounds, compared to the overall number of tested chemotypes; (b) to chemotypes that are absent or less present in patents, disclosures and medicinal chemistry (for intellectual property reasons); and (c) to chemotypes that are generally regarded as safe, or are less frequent in toxicity databases. Chemotype evaluation is used to rank families of HTS hits, and is further applied to (ii) Individual molecule evaluation: Our scheme gives higher priority (a) to molecules that are in the desired physico-chemical property range (using methods to compute, e.g. solubility and permeability); (b) to molecules that have high(er) activity, compared to those that are less active. To the above, (c) we add the chemotype score computed earlier, for a final composite score that ranks all confirmed or presumed actives.\n\nwww.drugdiscoverytoday.com the post-HTS analysis process, to give higher priority to highquality probes; or perhaps to download the entire matrix of target/bioactivity data and use it to profile compounds."}