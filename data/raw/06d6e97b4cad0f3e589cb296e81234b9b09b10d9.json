{"title": "Segmentation with area constraints", "body": "Image segmentation is a fundamental task in image analysis. Consequentially, a large number of segmentation methods have been developed ranging from local thresholding to methods using statistical models of shape variation (Pham et al., 2000; Sonka et al., 2008) . The simplest available segmentation methods rely on local pixel-by-pixel segmentation decisions such as Otsu thresholding or methods based on clustering. These fully-local decisions are often not sufficient and because they neglect spatial dependencies, they are sensitive to noise and not directly applicable if an object is defined by its boundary surface only (e.g., if only the cell membrane or a cell membrane surrogate is imaged, but an image of the entire cell is desired). To overcome these limitations, nonlocal approaches have been proposed based on intelligent local merging decisions or by formulating optimization problems incorporating spatial dependencies. The former class of methods encompasses region growing approaches such as the popular watershed segmentation (Sonka et al., 2008) . The latter class of methods includes active-contours and -surfaces (Sapiro, 2001) as well as general parametric models which may use statistical information on shape and/or appearance (Cootes et al., 2001; Pizer et al., 2003) .\n\nWhen the object segmentation task is highly structured (i.e., expected shape variations are reasonably small and the approximate number and location of the objects are known) shape-or atlasbased segmentation methods are highly successful (Rohlfing et al., 2005) . However, for less structured cases these methods are not applicable. In microscopy, for example, images often contain hundreds or thousands of cells, cell nuclei, or organelles, with possibly large variations in shape and a priori unknown locations. While local thresholding or active-contour-type models may be applied in such cases, they are often too generic, too sensitive to noise, or require the judicial placement of seed points to assure an appropriate segmentation result to avoid over-or undersegmentations.\n\nIf shape-or atlas-based segmentation methods are too restrictive, and if general purpose segmentation methods such as active contours, region-growing or thresholding are not restrictive enough for a particular segmentation task, the question of how to incorporate additional domain information into a segmentation that lies between these two extremes arises. A possible option is to use information about simple geometric properties. In this paper we explore an approach for a segmentation with constraints on the segmentation area. Such a method can counteract potential leakage or shrinkage biases in a principled way. Such biases can be observed, for example, for active contour (Sapiro, 2001) or graph cut (Boykov and Funka-Lea, 2006) segmentations when boundary regularity is encouraged by penalizing a weighted length of the segmentation boundary. Area constraints may not be appropriate for all biomedical segmentation tasks; however there are a large number of problems in which reasonable area or volume intervals are known a priori. Our objective in this paper is not to perform an actual study for a particular biological problem, but rather to demonstrate the behavior of a segmentation method with areaconstraints on realistic image data. We use electron tomography datasets of synaptic vesicles and of double-membrane vesicles (DMVs) implicated in the SARS-coronavirus (severe acute respiratory syndrome coronavirus) replication (Knoops et al., 2008) .\n\nMany recent segmentation approaches are formulated such that the optimization problems become convex so that globally optimal solutions can be obtained (Appleton and Talbot, 2006; Bresson et al., 2007) or so that they can be solved with discrete solution methods, such as graph-cuts (Boykov and Funka-Lea, 2006) . While area-constraints can formally easily be added to the optimization problems for segmentation, solving the problems is hard. However, if finding a globally optimal solution is not of concern and a good initial guess for a solution is available, one can resort to standard methods from constrained optimization. For example, a curve evolution approach with an area penalty can be used (Ayed et al., 2008) . Proposed numerical solution approaches to obtain a global optimum or a good approximation.\n\nare limited to problems with small numbers of variables (Ji, 2004) , or require long computation times (Dahl and Flatberg, 2007) , use solution heuristics (Kernighan and Lin, 1970) , or use various forms of relaxations of the original problem to facilitate computations: e.g., spectral relaxations (Olsson et al., 2008) , semidefinite programming (Keuchel et al., 2003; Lisser and Rendl, 2003; Hager et al., 2009) , or variational inference approximations (Kropotov et al., 2010) .\n\nApproaches have generally focused on equality constraints (i.e., exact size) in formulation (Lim et al., 2010; Eriksson et al., 2011; Falkner et al., 1994; Ayed et al., 2008) or for testing (Hager et al., 2009 ). However, equality constraints have only limited applicability when the exact object size is not known beforehand or when it is a desired measurement (as is frequently the case in biomedical imaging), because it would bias the segmentation towards the chosen area. We therefore formulate the segmentation problem with inequality constraints on the segmentation area.\n\nSection 2 introduces the area-constrained segmentation problem. Section 3 outlines our solution approach. Sections 4-6 discuss its numerical solution. Segmentation results on real electron tomography images demonstrate the utility of the method in Section 7. The paper concludes with a summary and a discussion of future work.\n\nOur objective is a binary segmentation of an image into foreground and background. Without loss of generality, we consider two-dimensional images here. 1 Markov random field models with Gibbs energies using first and second order cliques have been particularly popular for image segmentation (Li, 2009) and can be exactly minimized under certain conditions (Kolmogorov and Zabin, 2004) for example by using graph cuts. Solutions are typically based on the minimal cut theorem (Ford and Fulkerson, 1956 ) relating the minimum cut in a graph to the maximum flow through the graph. Hence, by forming an appropriate graph and solving the maximum flow problem the segmentation solution can be obtained. The segmentation algorithm we analyze and extend is the partial differential equation formulation of the maximum flow problem (Appleton and Talbot, 2006) , which has equally broad application for image segmentation.\n\nAs is customary for image segmentation methods based on energies of Gibbs-type, we allow the optional specification of seed points or areas which explicitly enforce a particular labeling (foreground or background) for the seeds. Our segmentation formulation is an extension of the convex formulation of the active contour method and related segmentation methods such as the Chan-Vese segmentation model (Bresson et al., 2007; Chan and Vese, 2001) .\n\nTo avoid the segmentation of very small structures which likely represent noise and noisy boundaries, almost all energy-based methods penalize the (weighted) length of the boundary curve separating foreground from background. Most commonly, the length of the boundary curve is added to the segmentation energy. This introduces a well-known shrinking bias towards shorter boundary curves and therefore frequently leads to undersegmentations. Our goal is to add constraints on the segmentation area, to counteract the shrinking bias and to allow ''tuning'' of the segmentation algorithm to the expected size of the objects to be segmented.\n\nWhile our area-constrained extension is developed in the context of maximum-flow-based segmentation, the solution strategy itself is generic and expected to be applicable also to other segmentation models. For example, a similar solution strategy might be useful for segmentation methods which do not penalize boundary curve length directly, but instead a ratio between boundary length and enclosed areas (Grady and Schwartz, 2006; Shi and Malik, 2000) . Such methods do not exhibit the same shrinking bias, but also lack control over the obtained segmentation area.\n\nThe general optimization problem for area-constrained segmentation we consider is argmin u E\u00f0u\u00de; s:t: A\u00f0u\u00de 2 \u00bdA l ; A u ;\n\nwhere u \u00bc fu s js 2 Xg; u s 2 f0; 1g; and u s \u00bc 0; s 2 T;\n\nHere, u is an indicator function denoting foreground (u = 1) and background (u = 0) classes of the segmentation defined over the set of spatial locations X, where s denotes a spatial location, u s a value at location s and u is the union of these values for all s 2 X, i.e., u 2 f0; 1g jXj , where jXj denotes the number of considered spatial locations. E(u) is an energy function encoding the desired properties of a segmentation, A(u) indicates the area covered by a segmentation u, S and T denote the foreground and background seed sets respectively, 2 and A l and A u are lower and upper bounds for the segmentation area. This is an integer program (Nemhauser and Wolsey, 1988) since u s 2 {0, 1}. For image segmentation the number of variables, u s , corresponds to the number of pixels. A direct solution of problem (1) with integer-programming methods is typically computationally tractable only for very small images. For segmentations without area-constraints various relaxations of the original labeling problem have therefore been proposed. As an illustrative example, consider the continuous maximum flow approach (Appleton and Talbot, 2006) in which E mf \u00f0u\u00de \u00bc X s g s kr s uk \u00fe q s u s ; s:t: u s 2 \u00bd0; 1;\n\nThe overall algorithm and its analysis extends to higher dimensions. We use twodimensional terminology in the remainder of the paper only to simplify the presentation, e.g., boundary curve instead of boundary surface.\n\nsubject to the same seedpoint constraints as in (1) is minimized.\n\nHere, g > 0 denotes an edge-weighting term and q a regional bias which allows for the integration of local likelihoods of an element s to belong to the foreground or the background. 3 The key difference in structure is to allow u s 2 [0, 1] which renders the optimization problem convex, because it is now defined over a convex domain, u 2 [0, 1] jSj . A globally optimal solution can then efficiently be obtained. For the continuous maximum flow problem, the optimal solution will be essentially binary regardless the convex relaxation. This means that a minimizer, u \u2044 of (2) may not necessarily be binary, but any thresholded u h\u00c3 s \u00bc 1 \u00bdh;1 u \u00c3 s \u00c0 \u00c1 is binary and globally optimal with E(u \u2044 ) = E(u h\u2044 ) for h 2 (0, 1) (Appleton and Talbot, 2006) . Here, 1 S \u00f0x\u00de is the indicator function which returns 1 if x is in S and 0 otherwise.\n\nUnfortunately, this relaxed solution is no longer guaranteed to be essentially binary when adding the area-constraint by inequality constraints P s u s P A l , P s u s 6 A u . The ''area'' of a segmentation is defined as A\u00f0u\u00de :\u00bc P s u s . In addition, the segmentation method can become ''blind'' to the true optimal integer solution as illustrated in Section 2.1, which precludes the possibility of finding good approximate solutions for the integer program by thresholding the relaxed solution. A different solution strategy is therefore needed for area-constrained segmentation. We resort to branch and bound (see Section 6).\n\nAssume there are strong gradients along the boundary of concentric, non-intersecting shapes. For example, several circles with increasing radii or squares with increasing side lengths with small weights g. Assume that the weights are chosen such that all discontinuities of the resulting segmentation (for the original problem and its relaxation) occur only at these shape boundaries. This can always be achieved by assigning sufficiently large weights outside the desired boundaries. These concentric shapes are indexed by a scale parameter r, e.g. the radius of a circle or the diagonal of a square. The shape itself is not important, but only that the area of the shape is c A r 2 and its circumference is c L r for suitable constants c A and c L . We drop these constants without loss of generality in what follows. We would like the segmentation to snap into successively larger shapes when increasing the lower bound on the area. The following counter-example shows that this cannot be assured and therefore the convex relaxation (with u s 2 [0, 1]) is insufficient to obtain solutions to the area-constrained segmentation problem.\n\nConsider three concentric shapes with scales r 1 < r 2 < r 3 (see Fig. 1 ) and a sufficiently large seed region within the inner-most shape so that the unconstrained problem results in the segmentation of the smallest shape. The segmentation energy (2) is proportional to r i (for q s = 0) and the area is proportional to r 2 i . Without loss of generality, set r 1 = 1. To obtain the middle shape from the segmentation, we enforce A l 2 r 2 1 ; r 2 2 \u00c0 \u00c1 \u00bc 1; r 2 2 \u00c0 \u00c1 . The segmentation energy of the desired shape (for an integer-solution) is E int = r 2 . Under the relaxed segmentation model the optimal solution needs to occur at r 2 or r 3 . Since smaller values for u will lead to smaller overall energy values, the optimal relaxed solution will have A(u) = A l . Therefore, for a jump at r i the uniform fractional value for u which fulfills the area constraint exactly will be\n\nThe energy values (for a jump from 1 to u at r 1 = 1 and from u to 0 at\n\nBut then A l > 1 and r 3 > r 2 by assumption leads to b E 3 < b E 2 . This shows that the middle shape cannot be recovered by thresholding and the fractional solution has a lower energy than the solution for the integer program. Fig. 1 illustrates the difference between the relaxed and integer solutions for successively larger lower bounds on the area for concentric squares with foreground seeds at the center of the image and background seeds at the image boundary. As predicted, the relaxed solution is blind to the middle square and simply uniformly increases the fractional values of u with increasing A. In contrast, the integer solution is able to capture all three squares.\n\nWhile the relaxed solution is not suitable for area-constrained segmentation by itself it can be used to obtain lower bounds for the integer program. Instead of directly enforcing u 2 {0, 1} we formulate the optimization problem as a mixed integer nonlinear program (MINLP) (Hijazi et al., 2009) min u E minlp \u00f0u\u00de;\n\ns:t: A\u00f0u\u00de 2 \u00bdA l ; A u ; u s 2 \u00bd0; 1;\n\nwhich augments the maximal flow formulation (2) by selection variables b k and areas B k , which allow selection of additional image to be segmented, foreground seed set S, background seed set T and the cost g in the x and y direction (g x = 1/(1 + 50I x ) and g y = 1/(1 + 50I y )) respectively (from top left to top right). The cost is illustrated with directional dependence, because we use the 1-norm, g s kru s k 1 , to discretize the weighted total-variation term. Linear programming (LP) solution for different lower area bounds (middle); solution of integer program (bottom). The integer program is by construction binary and is able to capture all three concentric squares (with respect to the gradient magnitude). The LP solution is blind to the middle square and immediately ''bleeds out'' into the biggest square once the desired area is larger than the smallest square at the center.\n\n3 This is a very general energy form which can express many highly popular segmentation models, such as active contour and surface models, Chan-Vese segmentation, and segmentation models with general region-based likelihoods. For example, any energy of the form E\u00f0C\u00de \u00bc\n\ncan be written in the form of Eq.\n\n(2). Here, C is the boundary curve separating the foreground region, X 1 , from the background region, X 2 ; d(x) denotes available data at spatial location x, h i are given parameters, which typically parameterize the likelihoods p i , g(s) > 0 and s denotes arc-length. Hence, q s in Eq.\n\n(2) can be interpreted as the logarithm of the likelihood ratios in the foreground and the background regions at location s.\n\nforeground and background seeds. For practical segmentation problems full control over all pixels is in many cases not necessary. Instead, it is desirable to obtain a good approximation to the original optimization problem while controlling the computational complexity of the method. Hence, we replace the control of individual pixels by the control of coarse selection areas B k . Since we solve this problem by branch-and-bound the resulting reduction in the number of integer variables reduces the effort to compute the solution drastically (because it reduces the size of the branch and bound tree). The original integer program (1) with the non-relaxed maximum flow energy is recovered if the B k correspond to individual image pixels s R S [ T. If desired, maximal flow formulations with direction-dependent costs could be used (Zach et al., 2009b,a) . For formulations with only a lower area bound, the last condition is replaced by u s P b k (and similarly for only an upper bound).\n\nThe essentially binary property is a consequence of the underlying continuous max-flow solutions and means that given an optimal (not-necessarily binary) u an equally optimal solution can be found by thresholding u for any h 2 (0, 1). I.e., we only want to accept values for the selection variables b k which result in essentially binary solutions and therefore indicate that they were selected appropriately to avoid the problems discussed in Section 2.1.\n\nIntuitively, the maximal flow approach yields an essentially binary solution even when an area constraint is present if it is sufficiently constrained by seed points. For example, imposing a lower area constraint for a max-flow-based segmentation is trivial if the number of foreground seed points is larger or equal to the lower area bound. Then the constraint is essentially inactive and ''invisible'' to the segmentation algorithm. The difficulty lies in finding these seed points (without requiring a user to provide close to the final segmentation as input). Integer programming solves this problem by intelligent pixel-by-pixel searching. However, even though the existing search methods (Nemhauser and Wolsey, 1988) avoid the combinatorial explosion inherent to a brute-force approach, search trees will still get extremely large even for moderately small problems unless special problem structure can be exploited. We control the combinatorial explosion instead by an appropriate, coarse choice of selection areas.\n\nWe would like the solution to be robust to the choice of the selection areas B k . The solution boundaries are expected to be located close to where their cost is low, i.e., where g s is small. Hence, we try to avoid placing the boundaries of selection regions there and let the remaining pixels not covered by any selection region snap into the best boundary location. We use homogeneous image regions for the B k , which can be derived from super-pixels (Vedaldi and Soatto, 2008; Comaniciu and Meer, 2002) or from an image oversegmentation using a watershed method (Vincent and Soille, 1991) . Formulation (3) is more general than a direct super-pixel segmentation (e.g., one can use seed regions covering only a subset of the image to guide the segmentation while having complete representational freedom close to putative segmentation boundaries). To define the B k , we use quick-shift (Vedaldi and Soatto, 2008) to find super-pixels and erode them so that they do not touch the potential segmentation boundaries. Quick-shift is an efficient mode-seeking algorithm based on medoid shift (conceptually similar to the popular mean-shift segmentation algorithms Comaniciu and Meer, 2002) . It provides a tuning parameter to control under-and over-fragmentation of modes and can therefore be used to indirectly control the number of selection regions to be detected. Our method is not dependent on quickshift, and other clustering methods such as mean-shift or k-means (Jain et al., 1999) could be substituted. Fig. 2 shows an illustration of the selection regions. In addition to the max-flow method addressed in this paper we expect this approach of facilitating area-constraints through selection regions also to be generally useful for other segmentation methods.\n\nNote that when only an upper or a lower bound on the area are present, the segmentation can be robust even to selection areas crossing the integer-programming-optimal solution because we replace the equality constraint u s = b k by an inequality (u s P b k or u s 6 b k respectively) effectively resulting in ''don't-care'' selection areas. Segmentation boundaries can pass through such ''don't care'' selection areas if desired. Specifically, if only a lower-bound is imposed, then the selection regions drive the actual segmentation values u s through the inequality u s P b k . Therefore setting a selection region to 1 forces the segmentation value u s to be 1 for s 2 B k . However, setting a selection region to 0 amounts to leaving the segmentation values u s free. Hence, the solution will neither be forced to 0 or 1 in such an area and can be completely determined pixel-wise by the underlying image. The segmentation will be robust to selection regions that cross segmentation boundaries as long as there are a sufficient number of selection regions on the inside of an object that can be set to 1 so that the segmentation naturally ''snaps'' into the desired location. However, when we enforce a lower and an upper bound, we need to be able to increase and decrease the natural size of an unconstrained segmentation by setting regions to 1 or 0 respectively. In this case, selection regions crossing segmentation boundaries will matter because they have to be set to either 0 or 1. Consequentially, enforcing an upper and a lower bound may produce results which are worse than enforcing only a lower bound. This problem could easily be avoided by moving from binary to ternary selection variables (0: set to zero, 1: set to one, 2: do not care). This would leave the overall approach intact, but would result in a slightly different branch and bound implementation, which is not our focus here.\n\nSolving the MINLP (3) involves the computation of the optimal binary selection variables, b k . A brute-force approach enumerating all possible combinations {b k } 2 {0, 1} jbj (where jbj denotes the number of selection areas) is prohibitive for all but the most simple general integer programming problems. We therefore use branch and bound (Nemhauser and Wolsey, 1988) to solve (3), which determines the optimal values of the selection variables b k by building a search tree. Evaluation of the full search tree (feasible only for small problems) is avoided by guiding the search towards promising solution candidates and discarding branches which can provably not lead to an optimal solution.\n\nFor the MINLP energy (3) we introduce the relaxed MINLP energy as E relaxed \u00f0u\u00de \u00bc X s g s kru s k \u00fe q s u s ; s:t: A\u00f0u\u00de 2 \u00bdA l ; A u ; u s 2 \u00bd0; 1; \n\nwhere we dropped the essentially binary condition and removed some of the selection regions. Here, K is the set containing the indices of the selection regions which are used in the particular relaxed solution, with all other b k free. 4 We have E \u00c3 relaxed \u00f0p\u00de 6 E relaxed \u00f0u r \u00de 6 E minlp \u00f0u r \u00de where E \u00c3 relaxed denotes the dual energy to E relaxed , p is the dual variable to u, and u r is a feasible candidate solution to the relaxed optimization problem. The first inequality holds, because a dual energy is never larger than the corresponding primal energy. The second inequality holds, because E relaxed removes constraints from E minlp and therefore will either have a smaller energy value than E minlp (if u r violates some constraints of E minlp ) or will be equal to it. If u r is a feasible solution for E minlp the energy value will be finite, otherwise it will be infinite. Hence, if within the search tree we find a relaxed solution such that E \u00c3 relaxed \u00f0p\u00de > E u \u00c3 best \u00c0 \u00c1 where u \u00c3 best is the current best feasible solution known for E minlp we can prune the search tree for u r , i.e., we no longer need to look at any solutions for its free selection variables b k , because they could only cause higher energies. A search branch can further be terminated if it results in a feasible integer solution.\n\nWe use the alternating direction method of multipliers (ADMM) (Sections 4 and 5) to compute solution candidates, u r , to the relaxed problem and show how to compute a dual energy at every iteration step of the optimization algorithm. 5 Section 6 discusses how to use the relaxed dual and primal energies within the branch and bound solution framework and how to obtain finite-valued relaxed dual energies and integer-feasible solutions from the ADMM variables. See Fig. 3 for a graphical overview.\n\nA possible numerical scheme is to perform a standard primal/ dual gradient descent/ascent (Reinbacher et al., 2010) . While simple, these methods tend to oscillatory behavior and require costly projections at every iteration step to fulfill the area-constraint. 6 We instead use the alternating direction method of multipliers (ADMM) (Boyd et al., 2010) for the solution of the optimization problem. The basic idea of this method is to split a problem into smaller sub-problems while making use of the method of multipliers developed to solve constrained optimization problems (the augmented Lagrangian approach). This decomposition simplifies the solution process for the area-constrained segmentation problem by breaking it into simpler sub-pieces. It also allows for the computation of a finite-valued dual energy estimate, which serves as a lower bound for the branch and bound algorithm.\n\nWe only provide the basic setup for ADMM here for completeness, but refer to Boyd et al., 2010 for details. ADMM optimization problems are of the form min u;w f \u00f0w\u00de \u00fe g\u00f0u\u00de; s:t: Bw \u00fe Cu \u00bc c; lower or upper bounds. The energies change correspondingly. 5 The iterative solution can be terminated prior to convergence if the dual energy is larger than the best integer-feasible primal energy, E minlp u \u00c3 best \u00c0 \u00c1 . 6 In (Reinbacher et al., 2010 ) the projection step is solved iteratively. Our approach requires this projection step only for the evaluation of the energy, which is not required at every iteration. We also provide a non-iterative method to solve the problem in Section 6.1.\n\nwhere u 2 R n , w 2 R m , f and g are functions (f : R m # R, g : R n # R) that do not need to be differentiable, c 2 R q and B and C are appropriately sized matrices. 7 The ADMM update steps (with step size r > 0) are (Boyd et al., 2010) w k\u00fe1 argmin w f \u00f0w\u00de\u00fe\n\nThis amounts to first solving for w then for u and finally updating the normalized dual variables, z. The prox operator (Combettes and Pesquet, 2010) is defined as prox L f \u00f0y\u00de \u00bc argmin w f \u00f0w\u00de \u00fe 1 2 kLw \u00c0 yk 2 :\n\nNote that the update scheme for ADMM can readily be derived from an augmented Lagrangian formulation (Nocedal and Wright, 2006) . The augmented Lagrangian corresponding to (4) is\n\nwhere p is the Lagrangian multiplier. Making the identification p = rz, the ADMM Eq. (5) are simply the augmented Lagrangian update equations for (6) where the update for the primal variables is performed separately, and conveniently written using the prox operator. If f is an indicator function for a set C, i.e., f(x) = \u0131 C {x}, (which is 0 if x 2 C, 1 otherwise) the prox operator prox f (y) is simply the projection of y on C. For general functions f the prox operator prox L f \u00f0y\u00de minimizes f while not moving ''too far'' from y. See (Combettes and Pesquet, 2010) for a more detailed discussion.\n\nFor area-constrained segmentation, splitting the problem into more than two sub-problems subject to consistency constraints simplifies the solution because it will allow for decoupling of the spatial regularization of the total variation term, g s kr s uk, the unary potential term, q s u s , and the area constraint. The coupling is then re-introduced through a consistency constraint. Specifically, we will have an optimization problem of the form\n\nwhere the u i are all independent variable copies and the consensus variable u (our indicator function) is only present through the consistency constraints (i.e., g(u) = 0). At convergence, the constraints will be fulfilled and hence u i = u, \"i. The prox step for u then becomes an averaging step (here, B = I, C = \u00c0I, c = 0)\n\nThis global variable consensus (Boyd et al., 2010) formulation is well suited for parallel processing. Constraints on the consensus variable (u) can be encoded in g(u) and therefore allow the specification of seed points for area-constrained segmentation.\n\nInterestingly, this does not change the overall solution scheme much, since the optimization problem\n\ncan be rewritten in the two-step form\n\nwhich replaces the update step for u in Eq. (5). We solve the relaxed area-constraint segmentation problem with this form of ADMM by transforming it to look like (7) as described in Section 5. The consensus variable u then corresponds to our sought-for indicator function u.\n\nWe assume that the set of selection variables b = {b k } of (3) is split into a set of selection variables with known value (within a branch and bound tree) and a set of free selection variables. We then subsume the determined selection variables in the foreground, S, and background, T, seed sets respectively. Dropping the free selection variables from the formulation results in the relaxed area-constrained problem. For simplicity we use the 1-norm for the gradient term resulting in the energy\n\ns:t: A l 6 X s u s 6 A u ; u s 2 \u00bd0; 1 \u00f0 9\u00de\n\nwhere (s, t) denotes a pair of neighboring pixels (in our case using a four-connected neighborhood) and the weighted total variation term P s g s kru s k 1 \u00bc P s g s \u00f0j\u00f0u x \u00de s j \u00fe j\u00f0u y \u00de s j\u00de was discretized as P \u00f0s;t\u00de c st ju s \u00c0 u t j. This is a slightly more general formulation, but includes P s g s kru s k 1 if the spatial gradients in the x and y directions (u x and u y ) are discretized using finite differences, the sites s are given by the grid position of individual pixels and c st is set to g s for all t neighboring s. Note that this formulation is sufficiently general to support area-constrained segmentation for general graph structures. To simplify the solution of (10), we break the problem into the following four energies which need to be minimized:\n\nwhere \u0131 C {x} denotes the indicator function and we write for notational simplicity \u0131 C={x:f(x)=0} {x} = \u0131{f(x) = 0}. The energies encode the unary potential term, the area constraint, the pairwise-potential (edge) term, and the seeds, respectively. These problems are simple to solve independently. The consensus form of ADMM then allows us to couple the four easy sub-problems so that we obtain a solution of the original optimization problem (10) at convergence. Specifically, we use variable copies u A , u s , u s , u t and the consensus variable u. The energy for the consensus ADMM is then\n\nIn ADMM notation of Section 4.1: f \u00f0u A ; u s ; u s ;\n\n, and g holds the constraints for the consensus variable. The prox operators are easy to compute because they decouple spatially for u s , u A , and \u00f0 u s ; u t \u00de. The edge variables u s and u t encode the presence of an edge between a source (s) and target (t) node and locally have as many copies as there exist edges (i.e., for a regular grid two copies for s and two for t at each interior pixel to account for edges in the x and y directions). The overall algorithm is given in Algorithm 1. The prox operators are given in Section 5.1. Section 5.2 shows how we can compute the dual energy to (11) using the variables of the ADMM solution scheme. ; \u00f013\u00de \n\nHere, jVj denotes the number of pixels and E the edge set. See Section S.3 in the Supplementary material for the derivations.\n\nComputing the dual energy for ADMM using Fenchel duality (Rockafellar, 1997) yields (10) and not of the ADMM energy for the branch and bound solution. We also need a feasible energy of the original MINLP (3) and not of the relaxed ADMM energy. 8 Section 6 therefore describes how to compute the appropriate primal and dual energies from the ADMM primal and dual energies.\n\nAlgorithm 1. ADMM for the area-constrained segmentation. 8 The original primal and dual energies and their corresponding ADMM primal and dual energies will be equivalent at convergence. However, for an efficient branch and bound solution we want to be able to test branch and bound termination criteria with respect to the original primal and dual energies before convergence.\n\nBuilding the search tree for a branch and bound solution of (3) requires a method to create subproblems (we use a standard binary division strategy on the b k ), a strategy to select subproblems for evaluation, a strategy to select variables for division, and a way to generate integer-energy estimates. We use a custom implementation of branch and bound where sub-problems are selected based on the lowest current relaxed energies. Branching variables are determined using pseudo-costs (Achterberg et al., 2005) , and the lower bounds and integer-energy estimates are computed as described below. See Nemhauser and Wolsey (1988) for an indepth discussion of branch and bound.\n\nAt convergence, the equality of the consensus variables is fulfilled, the bounds are satisfied and the area constraint holds. Therefore primal and dual energies of the relaxed ADMM problem will be finite upon convergence. To terminate solution branches that cannot lead to an optimal solution early, finite-valued dual energy estimates are needed before convergence for the dual energy to obtain a lower bound. Further, a feasible integer-valued (or essentially binary) solution is needed to obtain an upper bound. A finite-valued ADMM energy estimate is needed to evaluate the convergence of a current relaxed ADMM solution candidate based on its duality gap (i.e., the difference between primal and dual energy). Section 6.1.1 discusses how to obtain a finite-valued relaxed energy from an ADMM relaxed solution before or at convergence. Section 6.1.2 discusses how to obtain a finite-valued dual energy for the relaxed problem from the variables of the relaxed ADMM solution method. Finally, Section 6.1.3 discusses how integer-feasible solutions can be obtained from relaxed solutions by thresholding. Fig. 3 illustrates the connection between the different primal and dual energies.\n\nA current finite-valued energy estimate, which is an upper bound of the relaxed energy at convergence, can be obtained by projecting the current consensus variable u back onto the constraint set (so that it fulfills the area and bound constraints, u s 2 [0, 1]). This requires solving the projection\n\nA l 6 X s q s 6 A u ; q s 2 \u00bd0; 1; which, in order to project to area A, requires finding a Lagrangian multiplier k e s.t.\n\nThe optimal k e can be found by computing successive relaxed solutions\n\nSince 0 6 k r e 6 k e the optimization problem can be broken into subpieces and solved efficiently by first sorting the values u (if the current area is smaller than A -a similar reasoning hold in the reverse case).\n\nIf there is no relaxed feasible solution, then no integer feasible solution can exist. A feasible relaxed solution can be computed if the area constraint projection steps are feasible, which will be the case if X s2T A s 6 \u00c0A l \u00fe X s A s ; X s2S A s 6 A u :\n\nHence, for a given set of foreground/background seedpoints in the branch and bound solver a solution of the relaxed problem only needs to be sought if these conditions hold, otherwise the dual energy is set to \u00c01 and the energy to 1.\n\n6.1.2. Estimate of the relaxed dual energy A finite lower bound for the relaxed energy can be obtained by adjusting the ADMM dual variables for the terms which would otherwise lead to a \u00c01 estimate before convergence. We therefore need to find a dual variable pair \u00f0p s ;p t \u00de that is as close as possible to the current estimate (p s , p t ) while fulfilling the edge variable constraint. Such a pair can by computed by the projection P\u00f0p s ; p t \u00de \u00bc \u00f0c; \u00c0c\u00de;\n\nfor p s \u00c0 p t > 2c st ;\n\n\u00f0\u00c0c; c\u00de; for p s \u00c0 p t < \u00c02c st ; p s \u00c0p t 2 ; p t \u00c0p s 2 \u00c0 \u00c1 ; otherwise:\n\nSee Section S.5 in the Supplementary material for the derivation.\n\nTo allow termination of suboptimal branches, a good estimate for an integer-feasible (or essentially binary) solution is desirable early during branch and bound. Assume a feasible relaxed solution is given. By thresholding the relaxed u at h 2 (0, 1), we can obtain in a finite number of thresholding steps (determined by bisection) an integer feasible solution, or show that such a thresholded solution does not exist (in which case the estimate is set to 1). In practice, we terminate the search for a solution candidate after a fixed number of thresholding steps. Terminating the search without finding an integer-feasible solution will not affect the overall branch and bound solution. We will only not be able to produce a good integer-valued energy estimate from this solution, which in turn may effect early termination of search branches and may consequentially result in larger branch and bound search trees.\n\nThe relaxed solution candidate may already be essentially binary and fulfill the area constraints given an appropriate selection of seed regions. In general, an optimal essentially binary u is guaranteed to exist if a sufficient number of selection areas B k exist, and only an upper or lower bound needs to be enforced. For simultaneous lower and upper bounds the branch and bound algorithm will either find the best integer (and therefore one of the essentially binary) solutions, or will prove that no such solution exists. Non-existence is a pathological case, which is unlikely in practice. We never observed such a case in our experiments, but it is possible to construct toy examples which exhibit this problem. When the area-constrained segmentation formulation requires the solution to be binary for the selection areas, only compliant thresholded solutions will be feasible and hence finite.\n\nWe tested the area-constrained segmentation method for the segmentation of synaptic vesicles and for double membrane vesicles in epithelial cells infected with SARS-coronavirus (Knoops et al., 2008) . All images are slices of electron tomography images. Images for the epithelial cells were obtained from the cell centered database (CCDB) of the National Center for Microscopy and Imaging Research (NCMIR -http://ccdb.ucsd.edu). The images for the synaptic vesicles were approximately at a resolution of (1.0 nm by 1.0 nm)/pixel and for the SARS-coronavirus at (1.2 nm by 1.2 nm)/pixel. These examples were chosen to demonstrate the properties of our developed area-constrained segmentation method, because segmentations for these electron tomography images are known to be challenging. For example, for the synaptic vesicle segmentation task the vesicle wall is not directly visible in the electron tomography image. Instead it needs to be inferred from the location of proteins (which appear dark) penetrating the vesicle wall which results in a ''noisy'' appearance of the vesicle wall. Further, a large number of vesicles can be found in one image. Vesicles are closely packed in some areas, which even experts can have difficulty outlining precisely. In our experiments a user was asked to place individual seed points at the center of the objects to be segmented. The selection areas were obtained by eroding a quick-shift segmentation of the complete image. The selection region closest to the user-placed seed point was set as a foreground seed, and the selection areas at the boundaries of a 100 \u00c2 100 pixel box centered at the seed point were set as background seeds. This box size was chosen to be sufficiently large to guarantee that the desired objects are contained within it. We used image intensities as edge terms (c st ) and set q = 0. We set c = 1 for all ADMM experiments.\n\nSetting the selection areas at the boundaries as background seeds is meaningful for our experiment because the object will be, by construction, at the center of the image. However, this is not essential. The boundaries could be included into the optimization, albeit at the price of higher computational cost.\n\nGiven the selected segmentation area and the selection regions we compared the following methods for the vesicle datasets:\n\n(1) UC: Area-constrained segmentation with a lower bound of 0.\n\nThis unconstrained case corresponds to a classical graph-cut segmentation with seed points.\n\n(2) LB/UB/LBUB: Area-constrained segmentation enforcing upper and lower bounds on the segmentation area separately and jointly. (3) BNC: Biased normalized cut (Maji et al., 2011) using foreground seeds. (4) NC: Normalized cut (Shi and Malik, 2000) . No seed regions are supported by this algorithm and hence none were used. (5) WS: Seeded watershed segmentation (Vincent and Soille, 1991) using foreground and background seeds. (6) RW: Random walker segmentation using foreground and background seeds.\n\nTo allow comparisons between the algorithms (i) we used the same seed regions for all algorithms, (ii) we used the same edge weights g for all algorithms except for the random walker algorithm, and (iii) determined the best possible thresholds for NC and BNC by searching which threshold results in the best value for the normalized cut. For the random walker segmentation algorithm, we used two sets of edge weights, g, because this is a segmentation model which will not exhibit discontinuities at the putative segmentation boundary and hence treats edge-weights differently than all the other tested models. We report randomwalker results using the same edge-weights as the other algorithms (RW) as well as using the more appropriate default settings for random walker segmentation (d-RW).\n\nWe used a lower area bound of 800 and an upper area bound of 2000 (areas in pixels) with a low number of large selection areas and a larger number of small selection areas. Synaptic vesicles observed in our specimen are estimated to be about 40 nm in diameter. Since we are dealing with slices of a three-dimensional structure, we expect the actual observed diameters to be smaller than this. An area between 800 and 2000 pixels corresponds approximately to diameters between 30 and 50 nm if a perfect circular shape is assumed.\n\nComparing to an expert segmentation of 38 vesicles many of the vesicles were segmented correctly by both the area-constrained segmentations and by the unconstrained segmentations. However, in the unconstrained case, a substantial number of vesicles was under-segmented (returning only the seed point). In contrast, the area-constrained segmentations successfully segmented these cases and were able to achieve a segmentation result very close to the gold standard regardless of the selection areas. Note that using only a lower bound gives the best results in this example because it retains maximal flexibility for the registration boundary. When upper and lower bounds are enforced, the segmentation needs to conform to the selection areas. Though the areaconstrained results are not statistically significantly different with respect to each other, they are statistically significantly better than Table 1 Dice similarity coefficients for vesicle segmentation with small (;) and larger (\") number of selection areas, B k . Unconstrained (UC), lower (LB), and lower and upper bound (LBUB) constrained segmentations. Biased normalized cut (BNC), normalized cut (NC), seeded watershed (WS), random walker (RW) and random walker with default settings (d-RW all the other tested segmentation methods. Biased normalized cut, watershed segmentation, and the unconstrained segmentation method showed reasonable overall results, but suffered from severe outliers. The standard normalized cut segmentation fails entirely on these datasets because it cannot identify the object of interest since the data is noisy and no seed regions can be used. Random walker segmentation overall performed well, did not show any strong outliers, but performed overall worse than the area-constrained segmentation method. Table 1 shows summary measures for the Dice similarity coefficients for the experiments. Fig. 4 shows the segmentation results for unconstrained and area-constrained segmentation for a subset of an image. Fig. 5 illustrates the different selection areas for a specific example. An overview of corresponding seed points, the gold standard manual segmentation as well as results for the area-constrained and the unconstrained segmentations is shown in the Supplementary material in Fig. S1 . Boxplots for all the segmentation methods and a comparison of their mean performance (as measured by Dice) are shown in Fig. S2 .\n\nAdjacent vesicles may overlap because they are treated independently. In practice, overlaps were not observed for vesicle segmentation results of the area-constrained segmentation approach. This is a property of the data combined with the segmentation approach (which encourages short boundaries). In general, overlapping segmentations are possible and present ambiguities in the segmentation. Such ambiguities could be avoided by moving to a multi-label segmentation formulation.\n\nIn cases where the unconstrained segmentations resulted in a correct segmentation, the branch and bound search terminated quickly for the area-constrained methods. Most of the computation time was spent to correct the more challenging cases. Between 28 and 90 selection regions were used. Run-times were moderate: on average less than a minute per vesicle with a large number, and four seconds with a small number of selection areas on a singlecore CPU implementation. The algorithm can easily be parallelized and implemented on a GPU (with an expected speed-up by at least an order of magnitude).\n\nWe used a lower area bound of 2000 (area in pixels) with a low number of large selection areas and repeated a subset of the experiments for the synaptic vesicle segmentation. For a perfect circle, this area would correspond to a diameter of about 60 nm at the Fig. 6 . Segmentation results for a slice of the SARS 6021 (top) and of the SARS 6022 (bottom) electron tomography image. Seed points were placed manually with a single mouse click. Without using an area constraint (red) only few of the vesicles are accurately segmented and in the majority of cases the segmentations are too small indicating that a short boundary length was favored over a segmentation at the desired location of the cell wall. Adding a lower bound on the area (blue) greatly improves the segmentation results. Though a bias for short segmentation boundaries is still present, most of the vesicles are segmented accurately. Since the SARS 6022 image appears less noisy many of the vesicles are also segmented correctly without using a segmentation area constraint. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) Fig. 5 . Example selection areas for a vesicle (a). Few selection areas (less b k ) (b) and many selection areas (more b k ) (c).\n\nDice similarity coefficients for the SARS 6021 and SARS 6022 images. Unconstrained (UC), lower (LB), and lower and upper bound (LBUB). Biased normalized cut (BNC), normalized cut (NC), seeded watershed (WS), random walker (RW) and random walker with default settings (d-RW). Bold: best results. Italicized results do not have significantly different mean in comparison to the best method. For these images with a clear vesicle boundary watershed segmentation, maxflow with a lower bound, and random walker segmentation work well. (Knoops et al., 2008) , this is a conservative lower bound on the area. Similar conclusions as for the synaptic vesicle experiment apply. However, since the images for the double membrane vesicles are significantly less noisy than the images for the synaptic vesicles watershed segmentation, random walker segmentation, as well as the area-constrained segmentation method, work well. The area-constrained segmentation method matches the performance of the best segmentation method (seeded watershed) for both SARS images. Generally, the segmentation using a lower bound on the segmentation area performed better than the unconstrained segmentation. Fig. 6 shows overviews of the resulting segmentations for SARS 6021 and 6022, respectively, for the unconstrained and the area-constrained segmentations. Table 2 gives an overview of the obtained Dice similarity coefficients. Fig. S3 in the Supplementary material shows boxplots for the segmentation results for all the tested methods and statistical significance levels between the methods with respect to mean Dice performance.\n\nWe developed a new method for image segmentation with area constraints. The method readily extends to higher dimensions using higher-dimensional generalizations of the selection regions. The proposed method relies on the solution of a mixed integer nonlinear program, which is solved using branch and bound. To reduce computational effort in solving the area-constrained segmentation, we proposed to use selection variables based on eroded super-pixels. This allows computation of the segmentations for practical problems. The behavior of the method was demonstrated for segmentations of vesicles from slices of electron tomography images. When area-constraints were available, statistically significant increases in segmentation quality were obtainable even in challenging cases. In particular, due to the global optimality properties of the algorithm, it performs well for noisy data.\n\nFuture directions include improvements on the optimization method: e.g., should computations be performed directly on super-pixels? Further, the sensitivity of the obtained results on the type and size of the superpixels should be explored. Another interesting direction would be to vary the area constraints to define an area-based scale space, which would allow us to automatically extract coherent sub-structures at different size levels from the images. Extensions to multiple objects or the inclusion of topological constraints (e.g., to enforce one connected component) are other possible research directions."}