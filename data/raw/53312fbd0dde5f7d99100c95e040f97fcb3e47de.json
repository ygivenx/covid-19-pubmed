{"title": "An investigation of dairy calf management practices, colostrum quality, failure of transfer of passive immunity, and occurrence of enteropathogens among Australian dairy farms", "body": "Calfhood diseases have a major effect on the economic viability of dairy operations, due to the costs associated with calf losses, treatments, and long-term effects on performance (Donovan et al., 1998) . Replacement rearing represents 15 to 20% of total dairy production costs (Heinrichs, 1993) . Therefore, health disorders among replacement stock significantly affect the sustainability of the dairy industry. Calf preweaning morbidity and mortality rates have been reported to be high (about 35% morbidity and 2.1 to 14% mortality) in several countries (Mee, 2013; NAHMS, 2014; Windeyer et al., 2014) . However, to the best of our knowledge, no data have been reported on calf morbidity and mortality rates in Australian dairy farms.\n\nCalf health and survival is affected by several farm management practices, such as calving intervention, colostrum administration, and feeding regimens . The majority of dairy farms in Australia are pasture-based (Dairy Australia, 2017b) . Hence, several management practices differ significantly from the confined dairy systems common in North America or Europe. The Australian dairy industry has published best-practice guidelines on calf management from birth to weaning in the Australian dairy system (Dairy Australia, 2017a) . Nevertheless, few data currently exist about on-farm management practices in dairy operations in Australia and their effects on calf health and survival.\n\nSome studies have investigated colostrum quality parameters (Phipps et al., 2016; Chuck et al., 2017) , 8353 the prevalence of failure of transfer of passive immunity (FTPI; Vogels et al., 2013) , the prevalence of common enteropathogens causing neonatal calf diarrhea (NCD; Izzo et al., 2011b) , and calf-rearing practices (Phipps et al., 2018) on Australian dairy farms. However, these studies were limited to a particular region and, to the authors' knowledge, no study has investigated these parameters together.\n\nThe current study had 2 aims: (1) to investigate current calf management practices on dairy farms in Australia and their association with herd-level morbidity and mortality; and (2) to estimate the prevalence of enteropathogens causing NCD, FTPI, and poor colostrum quality in a sample of Australian dairy farms using a pilot study.\n\nTo achieve the aims of this study, the required information was gathered in 2 phases. Phase 1 involved a cross-sectional study using a questionnaire distributed among Australian dairy farms, and phase 2 involved a pilot study collecting and analyzing samples (fecal and serum samples from calves and colostrum) from a cohort of dairy farms.\n\nThe procedures of this study were approved by the Animal Care and Ethics committee (protocol number A16062) and the Faculty of Science Human Research Ethics committee (protocol number 400/2016/14) of Charles Sturt University. Participation in the survey was voluntary. Animals were enrolled with the owner's written consent, and samples were collected by registered veterinarians.\n\nWe distributed a 92-question survey about health management practices, morbidity, and mortality to dairy producers across Australia between December 2016 and December 2017. The survey was developed in consultation with specialist veterinarians and herd advisors.\n\nSurvey questions focused on topics relevant for morbidity and mortality because of their evidenced effect on calf health and survival according to the literature. The questionnaire was structured in 7 blocks: farm details, disease history, treatment protocol for diarrheic calves, calving management, feeding of calves (including colostrum management), housing and rearing, and other interventions (e.g., dehorning, castration). A copy of the survey is available from the corresponding author upon request. We piloted the questionnaire with 2 veterinarians external to the research team, 4 veterinary students at Charles Sturt University, and 3 local dairy producers to assess the respondents' answers and identify problematic questions. We then revised the survey before wider distribution. Because the revisions were minimal, we included the pilot surveys of local producers in the study as participants.\n\nDistribution of the survey to all Australian dairy producers through a single organization (and as such, a sampling frame) was not possible, so we used a multi-pronged approach for distribution to maximize participation. We estimated the sample size required to obtain representation of dairy producers in Australia to be between 110 and 200, with the assumption that 20 to 25% of producers would conduct a specific practice (estimated prevalence), with 95% confidence level and 5 to 8% precision of the estimate. We distributed paper copies of the questionnaire to dairy producers attending various producers' meetings. A link to an online version of the survey (SurveyMonkey Inc., Palo Alto CA) was also circulated through producer-focused newsletters, magazines, and e-mail forums, as well as online via social media. As an incentive for participation, 4 gift cards worth AU$50 (1 AU$ = US$0.78 at the time of the study) from an Australian retailer were raffled among survey respondents.\n\nThe collaboration of veterinary practices was sought for the collection of samples on farms. A brief description of the project was distributed to the members of the Australian Cattle Veterinarians (a special-interest group of the Australian Veterinary Association) in their electronic newsletter and through their e-mail distribution list. In brief, veterinarians were invited to collect serum, fecal, and colostrum samples from farms where they regularly worked. Sampling materials and freight costs were covered by project funding. The veterinarians received a copy of the laboratory results at no cost and were encouraged to share and discuss them with their clients. Veterinarians interested in participating were asked to contact the research team and were provided with sampling kits, consent forms, prepaid courier labels, and instructions related to sample collection, handling, and shipment.\n\nSample Collection, Shipment, and Processing. Veterinarians were asked to collect per farm (1) 7 to 12 blood samples from calves aged 1 to 7 d using vacuumed 10 mL serum tubes (BD Vacutainer; Becton Dickinson and Company, Plymouth, UK); (2) 7 to 12 8354 ABUELO ET AL.\n\nJournal of Dairy Science Vol. 102 No. 9, 2019 fecal samples from scouring calves younger than 21 d of age with a sterilized plastic container (Tube 70 mL, 55 \u00d7 44 mm; Sarstedt AG & Co., Adelaide, Australia); and (3) 7 to 12 colostrum samples using an identical sterile container directly from calf-feeding equipment. We requested that serum and fecal samples be maintained under refrigeration at 4\u00b0C, and that colostrum be kept frozen at \u221220\u00b0C to minimize the multiplication of bacteria. Samples were shipped under refrigeration by express courier to the Veterinary Diagnostic Laboratory at Charles Sturt University and processed upon receipt. Blood tubes were centrifuged at 2,000 \u00d7 g for 10 min and the supernatant serum was harvested, aliquoted into 1.5-mL microcentrifuge tubes, and immediately assayed for IgG quantification. Fecal samples were kept at 4\u00b0C until analysis within 12 h. Colostrum samples were thawed at 4\u00b0C for 12 h before analysis. Colostrum samples from 2 farms (n = 19) were received defrosted and were excluded from the study. Overall, we analyzed a total of 202 fecal, 253 serum, and 221 colostrum samples from 23 different farms throughout Australia (Table 1) .\n\nQuantification of IgG. Serum and colostral IgG concentrations were determined using a commercial radial immunodiffusion assay (Bovine IgG test; Triple J Farms, Bellingham WA) following the manufacturer's instructions (http: / / 69 .195 .120 .15/ jjj/ wp -content/ uploads/ 2017/ 04/ Triple -J -Bovine -IgG -728411 .pdf). In brief, serial dilutions of 1:2 and 1:4, and 1:2, 1:4, 1:8, and 1:16 were made with saline for each serum and colostrum sample, respectively. Bovine IgG standards were included in each determination for reference and ranged from 1.96 to 27.5 g/L. The diffusion ring through the agarose gel containing mono-specific antibody after 24 h of incubation at room temperature was measured using a caliper with precision of 0.1 mm. The values of the sample's ring were read off the standard curve, giving a grams per liter value of IgG. Thresholds of >10 and >50 g/L for sera and colostrum, respectively, were used to classify satisfactory samples (Godden, 2008) . Calves with serum IgG lower than 10 g/L were classified as FTPI.\n\nIdentification of Enteropathogens. Fecal samples underwent rapid detection immunochromatography analysis using a commercially available assay (Rainbow Calf Scour 6; Bio-X Diagnostics, Jemelle, Belgium) to identify rotavirus, coronavirus, Cryptosporidium spp., and Escherichia coli following the manufacturer's instructions (Abuelo and Alves-Nores, 2016) . Briefly, samples were diluted in a provided sample tube and homogenized by manually inverting before being placed into the strip tube. Following closure of the strip tube to allow the sample to diffuse along the strips, the devices were left vertical on a laboratory bench for 10 min, and then read. Samples without a clear result for any of the pathogens (e.g., a weak positive reading or lack of negative control) were re-assayed, and if the same unclear result was obtained, were considered negative. A total of 7 (3.5%) samples were re-assayed for one or more pathogens, and only one resulted in an unclear result for Cryptosporidium spp. after reanalysis.\n\nWe also tested fecal samples for Salmonella spp. using the PCR screening test described by Mainar-Jaime et al. (2013) . Briefly, 10 g of feces were homogenized with 90 mL of sterile, buffered peptone water (Pail Buffered Peptone Water; Becton Dickinson and Company, Sparks, MD) and incubated for 18 \u00b1 2 h at 37 \u00b1 1\u00b0C for pre-enrichment. Then, DNA was extracted by the rapid boiling procedure from a 1 mL aliquot of diluted samples collected from the air-liquid interface (Oliveira et al., 2005) . The primers Fw (5\u2032-AGTGCTCGTT-TACGACCTGAA-3\u2032) and Rv (5\u2032-TGATCGATAAT-GCCAGACGA-3\u2032) were designed to amplify a 229-bp DNA fragment. The PCR mix was prepared with 5 \u00b5L of extracted DNA, 18 \u00b5L of 0.4 mM each primer, 0.2 mM each dNTP, 2.5 U of REDTaq DNA Polymerase (Sigma Aldrich, Castle Hill, NSW, Australia), and 5 \u00b5L of 10\u00d7 REDTaq PCR Reaction buffer (containing (Izzo et al., 2011b) .\n\nTo evaluate the level of contamination in colostrum samples, we measured total aerobic bacterial count (TBC) and total coliform count (TCC). We prepared 10-fold serial dilutions of each sample in 9 mL of sterilized PBS (Sigma Aldrich). For TBC, plates were prepared by placing 100 \u00b5L of each relevant dilution in sterile Petri dishes and adding sterilized plate count agar (Becton Dickinson), previously cooled to 50\u00b0C, into each plate before mixing and allowing to solidify. The TCC was prepared as described above, apart from the use of violet red bile agar (Becton Dickinson) instead of plate count agar. Plating was carried out in duplicate for each sample. The TCC and TBC plates were incubated at 30\u00b0C and 37\u00b0C for 72 h and 24 h, respectively. Duplicate plates containing colonies within the range of 30 to 300 were used to calculate mean colony forming units per milliliter in the original samples. Cut-off points of 100,000 and 10,000 cfu/mL for TBC and TCC, respectively, were used to classify samples as satisfactory or unsatisfactory (Godden, 2008) .\n\nPaper-based questionnaires were added into the online system, and answers were downloaded in spreadsheet format (Excel, Microsoft Corp., Redmond, WA) and exported into JMP Pro v.14 (SAS Institute Inc., Cary, NC) for statistical analysis. All responses were evaluated and screened for completeness independently by 2 of the authors. From the 121 responses received, 15 were incomplete and removed from the final pool of answers. A final number of 106 completed surveys were therefore analyzed.\n\nData from the questionnaire were initially examined using descriptive statistics, for data cleaning and to determine distributions. Categorical data are reported as the number of responses and percentages, whereas continuous data are reported as mean [\u00b1 standard deviation (SD)] and quartiles. To investigate associations between on-farm calf health management practices and herd-level morbidity and mortality, we conducted univariable linear regression analyses. The outcome variables considered were mortality risk, overall morbidity risk, and scour and pneumonia morbidity risks. Associations between explanatory variables and the outcome of the model with a P-value <0.05 were considered significant. We considered multivariate analysis, but did not use it because of the limited associations found at a univariate level.\n\nWe estimated the apparent prevalence (AP) of each studied enteropathogen as the proportion of positive fecal samples from the total fecal samples collected at farm and study levels. The methods employed for enteropathogen identification are not the considered the gold standard, so we also estimated the true prevalence (TP) of each pathogen based on reported test sensitivity and specificity values (Table 2) following the formula described by Rogan and Gladen (1978) :\n\nThe radial immunodiffusion test used is considered the gold standard for quantification of IgG in bovine colostrum and serum samples. Therefore, we assumed that the estimated prevalence of FTPI was the TP.\n\nAll the descriptive results from the questionnaire are available in Supplemental Table S1 (https: / / doi .org/ 10 .3168/ jds .2019 -16578). We identified limited significant associations between the studied calf management practices and the outcome variables in the univariate linear regression, and these failed to achieve significance at the multivariate level. Therefore, only the descriptive questionnaire results and the pilot study data are presented and discussed.\n\nHolstein-Friesian was the main breed for 64.2% of respondents, followed by Jersey (14.2%) and Holstein/ Jersey cross (12.3%). Other breeds, such as Brown Swiss, Ayrshire, Australian Red, or Illawarra represented less than 10% of the responses. The majority of responses originated from farms in the state of Victoria, followed by New South Wales (Table 1) . Among respondents, the mean (SD) and median (interquartile range) size of the milking herd were 440 (326.1) and 330 (345) animals, respectively. Farm operations with 251 to 500 milking cows were most common among respondents (36.8%), followed by farm sizes of 101-250 cows (30.2%), 501-1,000 cows (24.5%), >1,000 cows (4.7%), and <100 cows (3.8%). Overall, the distributions of breed, location, and herd size among respondents were similar to the values reported for the overall Australian dairy industry (Dairy Australia, 2017b).\n\nSurvey questions pertained to heifer calves only, because male calves are often removed from farms shortly after birth on many Australian dairies. The mean (SD) mortality risk in preweaned heifer calves reported by farmers was 5.6% (3.75). Of this, 66.7% of respondents reported mortality risks higher than the 3% industry target (Dairy Australia, 2017a), and 9.8% of respondents documented mortality risks higher than 10%. In addition, reported mean (SD) morbidity due to diarrhea and respiratory disease in preweaned heifers were 17.9% (15.44) and 6.0% (8.34), respectively. The Australian dairy industry does not have published independent benchmarks for these diseases. Instead, they recommend a preweaning illness risk of lower than 10% (Dairy Australia, 2017a) . When the number of reported cases of diarrhea and pneumonia were combined, the mean (SD) illness risk was 23.8% (19.90); only 24.5% of respondents met the preweaning illness rate target.\n\nMorbidity and mortality risk were not affected by herd size or geographic location (P > 0.05).\n\nCollectively, these data suggest that the calf morbidity and mortality risks reported by farmers are higher than industry-recommended targets in a great proportion of Australian dairy farms. However, we noted a great variation among survey respondents, with illness and mortality risks ranging from 0.0 to 87.5% and 1.0 to 26.7%, respectively. Our statistical analysis of the data did not identify a significant association between farm calf management practices and reported mortality, diarrhea/pneumonia morbidity, or overall illness risks. This could be attributed to the high variation in different calf management practices among the farms in our data set. Nevertheless, the fact that preweaning mortality and morbidity rates were met by a third and a quarter of respondents, respectively, indicates that industry targets are achievable, and this information can be used to motivate farmers with risks above the recommended levels.\n\nA total of 221 colostrum samples from 21 different farms were analyzed for IgG content, TBC, and TCC (Table 3) . Satisfactory IgG concentrations (>50 g/L) were obtained in 105 (47.5%) samples, and 129 (58.4%) and 160 (72.4%) of the samples met the recommended industry standards for TBC and TCC, respectively. However, when all the current recommendations were considered, only 43 samples (19.5%) met all criteria. These findings were consistent with a previous study conducted in 24 farms in northern Victoria (Australia), where only 23% of colostrum samples met the 3 standards (Phipps et al., 2016) . Similar to our results, this study also reported that more than 50% of studied samples contained a concentration of IgG lower than recommended and a high bacterial contamination in approximately 40% of samples. Nevertheless, the proportion of satisfactory samples was lower than in a study in the United States, in which 39.4% of samples met all the standards (Morrill et al., 2012) . A high proportion of colostrum samples above TBC and TCC thresholds has also been reported in Ireland (McAloon et al., 2016) . The present study demonstrates that a significant proportion of colostrum on Australian dairy farms may contain bacterial counts above industry recommendations. Elevated colostral TBC and TCC not only act as a vehicle for the transmission of organisms but also represent a significant risk for FTPI by decreasing the efficiency of absorption of immunoglobulins (Johnson et al., 2007; Gelsinger et al., 2015) . The harvesting stage has been suggested as the point at which the majority of contamination is most likely to occur (Stewart et al., 2005) . However, we observed a great variation among farms in the proportion of colostrum samples meeting all quality standards, with an average of 19.3% and a range of 0.0 to 83.3%, suggesting farm-specific factors influence the degree of colostrum contamination. Hence, veterinarians are required to conduct further investigations on each farm to identify where contamination is likely to occur. The prompt refrigeration of colostrum (within 1 h of collection) and thorough disinfection of the calf-feeding apparatus before use have been recommended to reduce bacterial contamination (Phipps et al., 2016) .\n\nIn addition to bacterial contamination, more than 50% of the studied colostrum samples had suboptimal IgG concentrations. This highlights the need to estimate colostrum IgG content before administering it to calves. This can be accurately done on farms using a colostrometer or a Brix refractometer (Bartier et al., 2015) . Indeed, the Australian dairy industry recommends the routine use of Brix refractometry because of its reliability for on-farm use (Dairy Australia, 2017a). However, only 51% of survey respondents routinely estimate colostrum IgG content with validated methods [i.e., a colostrometer (3.8%) or a Brix refractometer (47.2%)]. The remainder of the respondents reported either not routinely checking colostrum quality (21.7%) or performing only a visual assessment (24.5%), a very inaccurate method (Abuelo and Alves-Nores, 2016) .\n\nTaken together, the colostrum quality results suggest that a large number of calves are at risk of receiving colostrum with elevated bacterial counts and low immunoglobulin content, making them more susceptible to FTPI and negatively affecting calf health and the economy of the dairy enterprise. Additionally, the degree of colostrum contamination should be taken into consideration when assessing colostrum management on farms.\n\nWe also estimated the prevalence of FTPI in 23 farms. The concentration of serum IgG was measured in a total of 253 calves within their first week of age.\n\nThe overall and mean (range) within-herd prevalences of FTPI were 41.9 and 36.2% (0.0-83.3%), respectively. Vogels et al. (2013) estimated FTPI among 100 herds in southwest Victoria measuring serum total protein, also finding a high prevalence: 38% of calves experienced FTPI and more than two-thirds of the herds had more than 25% of calves with FTPI. Our survey found that 23.6% of respondents let calves suck colostrum from their dams and 71.6% separated calves from their dams >6 h after calving. In fact, 41.8% of respondents separate calves >12 h after birth. Relying on the calf sucking colostrum from their dam and late separation are known to increase the prevalence of FTPI (Besser et al., 1991; Vogels et al., 2013) . Therefore, collecting calves from the calving area more frequently and feeding them quality-tested colostrum immediately after removal will likely reduce the high prevalence of FTPI.\n\nCalves with FTPI have higher risks of mortality, respiratory disease, diarrhea, and overall morbidity, as well as an estimated decrease in ADG of 81 g/d (Raboisson et al., 2016) . Estimates of the cost of a case of FTPI under the Australian dairy systems are, to our knowledge, not available. However, the total cost per dairy calf with FTPI was estimated to be \u20ac60 (95% CI: \u20ac10 to \u20ac109) in European cattle systems (Raboisson et al., 2016) . The high prevalence of FTPI we observed not only affects calf health but is also likely to have a significant economic impact on the farm. However, only 13.2% of survey respondents reported undertaking some assessment of FTPI on their farms. This practice allows for monitoring of adequate immune transfer and can be easily performed at the farm using various methods (Abuelo and Alves-Nores, 2016) . Routine monitoring of FTPI should be incorporated into the herd health protocols of Australian dairy farms to improve colostrum management and reduce FTPI prevalence.\n\nFarmers were asked about how they diagnose and treat calves with NCD. All but 3 of the 106 survey respondents reported having at least 1 case of NCD in the previous year. In 83% of farms, calves are usually still housed when they start scouring. The onset of diarrhea is more common in calves aged 6 to 21 d (64.1% of respondents), followed by calves aged 0 to 5 d (32.1%). The majority of respondents (71.7%) diagnosed diarrhea themselves; only 17.9 and 7.6% of the farmers reported that the diagnosis was made by a veterinarian through either a visit or a conversation, respectively. Furthermore, 55.8% of farmers did not regularly require veterinary consultation for the treatment of NCD, and 33.0% of respondents always administered antimicro-8359 bials for cases of NCD. Although a larger proportion of farmers (49.1%) reported using antimicrobials only when the calves were systemically ill, following the current recommendation (Constable, 2004) , an important proportion of farmers still administered antimicrobials as a blank treatment for NCD. This results in the use of antimicrobials when they are not needed and generates reservoirs of resistance among both commensal and pathogenic bacteria (Catry et al., 2016) . Increasing awareness among farmers about the judicious use of antimicrobials for treating NCD is required.\n\nIn addition, 63.2% of respondents systematically withheld milk from calves with NCD: 29.7% did it for at least 24 h and 7.6% until the calves recovered from NCD. This was consistent with the finding that 55.7% of respondents fed oral rehydration solutions instead of milk or milk replacer to calves with NCD. Previous studies demonstrated weight loss in calves fed only oral rehydration solutions, compared to weight gain in those that received milk in addition to oral rehydration (Fettman et al., 1986; Garthwaite et al., 1994) . Indeed, even hypertonic oral solutions (with a high concentration of glucose) cannot provide sufficient energy for maintenance and growth (Constable et al., 2001) . However, the severity or duration of diarrhea is not different between calves that receive milk in addition to oral rehydration compared with oral rehydration alone (Garthwaite et al., 1994) . Thus, it is currently recommended to continue feeding milk to calves with NCD and only to withhold it for periods up to 12 h in severe cases (Smith, 2009; Lorenz et al., 2011; Smith and Berchtold, 2014) . The labels of most commercially available rehydration products in Australia were updated in 2014 to instruct farmers to continue the administration of milk-based products when using oral rehydration electrolytes (APVMA, 2018). Based on the results of this survey, however, many farmers still need this information. In Europe, legislation details the minimum requirements for commercial oral rehydration products for calves (European Commission, 2014), but this is not the case in other countries, including Australia and the United States. Significant variability in the quality of commercial oral electrolyte solutions available in the United States and Australia has been noted (Smith, 2009; Vogels, 2010) . Veterinarians need to be proactively involved in establishing guidelines for the use of specific oral rehydration products.\n\nOverall, these results might suggest that there is still significant room for veterinarians to become more involved in calf health programs in Australian dairy farms. However, previous research has highlighted the differences in perceptions of topics of discussion during farm visits between veterinarians and farmers (Hall and Wapenaar, 2012) . Therefore, improving effective communication between farmers and veterinarians should not be overlooked when transmitting and explaining evidence-based recommended practices.\n\nSamples for the laboratory diagnosis of diarrhea were reported to have been collected by 55.7% of the farmers completing the survey. Of these, Cryptosporidium parvum was isolated in 64.4% of farms, followed by Salmonella enterica (52.5%), rotavirus (49.1%), coronavirus (40.7%), and E. coli (35.6%).\n\nWe analyzed 202 fecal samples from diarrheic calves aged 11.3 \u00b1 5.29 d (mean \u00b1 SD) from 23 farms for the presence of common NCD enteropathogens. Overall, 70 samples (34.7%) were positive for a single pathogen, 76 (37.6%) for 2 pathogens, 33 (16.3%) for more than 2 pathogens, and 23 (11.4%) were negative for all pathogens investigated. Coinfection is frequent in NCD, with 5 to 71% of mixed infections being reported in the literature worldwide (de la Fuente et al., 1998; Izzo et al., 2011b) . The proportion of mixed infections detected in our study (53.9%) was lower than the 71% reported by the only previous Australian study (Izzo et al., 2011b) . However, the previous study focused only on samples collected from outbreaks of diarrhea, which might have increased the proportion of mixed infections, because these usually result in a more severe clinical presentation (Reynolds et al., 1986; Gulliksen et al., 2009) .\n\nOverall, the most prevalent enteropathogen identified in the diarrheic fecal samples was Cryptosporidium spp. (TP = 40.9%), followed by Salmonella spp. (TP = 25.2%), rotavirus (TP = 19.1%), E. coli F5 (TP = 13.9%), and coronavirus (TP = 7.4%). These results from on-farm collection were consistent with the results of the survey, which also found Cryptosporidium spp. and Salmonella spp. to be the most common enteropathogens. The within-herd prevalence of each pathogen varied considerably among farms in the pilot study (Table 4 ). For example, the TP of Cryptosporidium spp. and Salmonella spp. varied between 0.0 and 100.0% (mean: 44.1% and 27.5%, respectively) and the TP of coronavirus ranged from 0.0 to 57.2% (mean: 13.3%). The ELISA pathogen identification assay we used detects Cryptosporidium spp., but data worldwide show that Cryptosporidium parvum is the most common species found in calves of this age (Geurden et al., 2007; Langkjaer et al., 2007; Xiao et al., 2007) . Reports from Europe, the United States, and Australia indicate that Cryptosporidium spp. are among the most common enteropathogens isolated in cases of NCD, with a prevalence ranging from 15 to 59% (de la Fuente et al., 1999; Bj\u00f6rkman et al., 2003; Gulliksen et al., 2009; Izzo et al., 2011b) . Furthermore, several studies indicate that infection rates in young dairy calves with Cryptosporidium parvum are as high as 100% in some herds (de Graaf et al., 1999; O'Handley et al., 1999 , Olson et al., 2004 Abuelo, 2016) , which we also observed in the present study. Only one drug, halofuginone lactate, is currently licensed for the prevention and treatment of cryptosporidiosis in calves in Australia. However, some controversy exists regarding the effectiveness of this drug to treat established Cryptosporidium infections (Silverl\u00e5s et al., 2009; Trotz-Williams et al., 2011) . Therefore, enhancing calf immunity and reducing the exposure of the calves to the pathogen through appropriate management and hygiene practices are key to reducing the incidence of cryptosporidiosis in calves.\n\nSalmonella O-group D was isolated in 38 of the 56 samples (67.9%) positive on initial PCR screening in this study. This O-group includes Salmonella Dublin, which is the most common serovar identified in calves from this antigenic group, and an important serotype due to its ability to create a long-term carrier status with intermittent shedding (Nielsen et al., 2004) . Salmonella O-groups B and C were identified in 10 (17.9%) and 6 (10.7%) PCR-positive samples, respectively. These serogroups include the serovars Salmonella Typhimurium and Salmonella Bovismorbificans as the more common serovars identified in calves (Grimont and Weill, 2007) . Two PCR-positive samples from the same farm were negative to all the O-groups tested and subsequent serotypification was not undertaken. Similar data were presented in an earlier Australian report, which identified Salmonella Dublin as the most common serovar, followed by Salmonella Typhimurium and Salmonella Bovismorbificans (Izzo et al., 2011a) . Cryptosporidium parvum and Salmonella Typhimurium are known to cause disease in humans and they were identified in 40.9% and 5.4% of samples from diarrheic calves, respectively. These findings highlight the zoonotic potential of NCD with approximately half of the cases being caused by zoonotic agents. Therefore, the need for personal protection must be reinforced to people in contact with calves to prevent infections. Indeed, outbreaks of human cryptosporidiosis associated with an epizootic in calves have been reported (Reif et al., 1989) , and it is estimated that about 1 in every 6 human cryptosporidiosis cases comes from animals, calves (both beef and dairy) being the most common animal sources (Cacci\u00f2 and Putignani, 2014) .\n\nRotavirus has usually been identified in combination with another pathogen(s) as the most or second most prevalent (de la Fuente et al., 1999; Bj\u00f6rkman et al., 2003; Izzo et al., 2011b) . In our study, rotavirus was the third most commonly isolated pathogen, with a TP of 19.1%, lower than the 79.9% reported by Izzo et al. (2011b) . However, this difference might be explained by the source of the samples; compared with the previous study, our samples did not originate from outbreaks of NCD, in which mixed infections are common (de la Fuente et al., 1998; Smith, 2012) . Similarly, the TP of E. coli F5 (13.9%) was lower than in other studies, some of which reported prevalences up to 75.6% (El-Seedy et al., 2016) . However, NCD caused by E. coli is most prevalent within the first 4 to 7 d of life (Foster and Smith, 2009 ), so age differences among studies might explain the variation observed in the prevalence of E. coli NCD. Indeed, only 42 of the 202 fecal samples (20.8%) came from calves younger than 1 wk of age, and the TP of E. coli in this subgroup reached 69.0% (data not shown). Coronavirus was the least prevalent pathogen in the present study (TP = 7.4%). Several studies have also reported low prevalence of coronavirus in NCD, with documented prevalence ranging between 7.8 and 14% overseas and 21.6% in Australia (Reynolds et al., 1986 , de la Fuente et al., 1999 Gulliksen et al., 2009; Izzo et al., 2011b) . Neonatal calf diarrhea caused by rotavirus, coronavirus, and E. coli can be effectively prevented by vaccinating dams before calving to increase specific immunoglobulins in colostrum (Kohara et al., 1997) . Nevertheless, only 22.6% of survey respondents reported vaccinating dams for this purpose. Therefore, calf health could be further improved by vaccinating dams during the dry period and ensuring that calves receive adequate amounts of good-quality colostrum in a timely manner.\n\nA total of 23 samples (11.4%) were negative for all pathogens tested, including all 8 samples submitted from 1 farm. These negative results could be from cases of NCD caused by malnutrition or rapid change in diet, pathogens not included in this investigation, or by false negatives, especially for pathogens with low or intermittent shedding. Repeated sampling of negative animals was not attempted.\n\nThe majority of respondents (89.6%) fed fresh whole milk to their calves; a small proportion fed milk replacer alone (7.5%) or whole milk supplemented with milk replacer (2.8%). The supplementation of whole milk with milk replacer aims to provide high-energy, high-protein feed in a smaller volume than would otherwise be required to achieve a similar nutritional content if using whole milk or milk replacer alone, thus allowing optimal growth rates to be achieved without the need to feed high volumes of milk (Dairy Australia, 2017a) . Nevertheless, the mean (SD) volume of milk/ milk replacer fed to dairy calves up to 2 wk of age and from 3 wk onwards was 4.4 (1.47) L and 6.1 (2.11) L, respectively. The Australian recommendations for milk volume to be fed to calves is 10% BW (Dairy Australia, 2017a). Preweaning nutrition and thus preweaning ADG has lasting effects on subsequent lactation and reproductive performance (Kertz et al., 2017) . The volumes of milk fed by the majority of respondents were representative of conventional restricted milk feeding programs (Drackley, 2008) . Calves under these programs show lower ADG, greater risk of disease, and achieve first service later than calves fed under an intensive feeding program (Curtis et al., 2018) . On the other hand, restrictive milk feeding programs allow for weaning at an earlier age than intensive feeding programs (Drackley, 2008) . However, the mean (SD) age at weaning in our survey was 79.1 (28.45) d, similar to the mean (SD) weaning age of 10.2 (2.53) wk reported by Phipps et al. (2018) , but higher than the 8 wk recommended for intensive feeding (Eckert et al., 2015) . Nevertheless, several other factors, such as concentrate intake and weight, need to be considered when deciding when to wean calves, and this might explain the differences in weaning age compared with North American dairy systems. Indeed, it is important to consider that most of the previous studies of calf-feeding programs were performed in different dairy production systems; further research is needed to determine the benefits and cost-effectiveness of calf intensive feeding programs in the Australian pasture-based system. Routine feeding of waste milk to calves was performed by 71.7% of the respondents. Of these, 81.6% reported routinely feeding milk from cows with mastitis and 71.7% used milk from cows that had been treated with antimicrobials. These practices have also been reported to be common in other countries (Brunton et al., 2012; Duse et al., 2013) , in an attempt to reduce calf-rearing costs by using milk that would otherwise be discarded. Early evidence reported that these practices resulted in no differences in growth or morbidity compared with control milk (Kesler, 1981) . However, they have been associated with higher levels of antimicrobial-resistant bacteria in the gastrointestinal tracts of calves (Aust et al., 2013; Duse et al., 2015) . Also, feeding mastitis milk to calves is a risk factor for heifer mastitis (Parker et al., 2007; Ivemeyer et al., 2009) . These practices should be avoided not only to improve animal health but to prevent potential downstream implications for human health.\n\nMilk-based feedings were administered predominantly using plastic calf feeders (67.0%); bucket and automatic feeding was used by 12.3% and 6.6% of respondents, respectively. Feeding devices can serve as fomites for pathogen transmission. Indeed, 73.8% of the farms using calf feeders used the same feeder in multiple pens, without cleaning feeders (40.6%) or using only water (13.2%) between pens. Calves that share feeding devices have a higher odds of respiratory disease Lundborg et al., 2005) , which can be due to the transmission of pathogens via the use of the same nipple. The median (SD) number of teats per feeder was 6 (5.72) and 14 (17.29) up to 2 wk of age, and from 3 wk of age until weaning, respectively. Thus, the opportunities for disease transmission between animals via feeders are considerable if appropriate sanitation and disinfection practices are not in place.\n\nCalves were housed for an average (SD) of 36.8 (28.53) d after birth. We observed considerable variation in housing type for preweaned heifers. A closed barn (calves totally inside) with calves kept in groups was the most common housing method (51.9%), followed by an open barn (calves have free access to outside; 19.8%), a patio barn (calves kept inside with a restricted area open to outside; 17.9%), and individual hutches (11.3%). Calves being kept totally outside (4.7%) or kept individually inside a closed barn (2.8%) were the least common housing methods. For animals kept in groups, the size of the groups varied considerably. The median (SD) maximum number of calves per pen was 10 (10.71), with a range of 4 to 80 calves per pen. However, 86.4% of respondents did not keep calves of different ages together in the same pen, and although male calves were housed in the same shed as female calves by 54.7% of respondents, 44.8% kept them in separate pens in the same sheds. Also, 54.7% of respondents reported having at least 1 pen designated for sick animals on their farm, and 17.0% had a sick pen in each calf facility. Nevertheless, 76.4% of the farms did not have solid partitions between pens, which facilitates nose-to-nose contact and disease transmission among animals in the same shed (Lago et al., 2006) . Individual housing was used by only 14.1% of respondents, in contrast to with data from the United States, where approximately 70% of farms house preweaned heifer calves individually (NAHMS, 2014) . However, group housing improves solid feed intake and calf weight gain, as well as calf behavioral aspects, without adversely affecting calf health in well-managed herds (Costa et al., 2016) . Thus, although group-housed calves might be at a higher risk of disease transmission, the benefits associated with socialization likely outweigh this risk, provided calves are managed appropriately.\n\nWoodchips were the most common bedding material used (39.6%), followed by straw (31.1%), rice hulls (16.0%), and sawdust (14.1%). Straw is commonly recommended in areas of cold climate to allow nesting to counteract temperature loss (McGuirk, 2011) . However, this might be less relevant in Australia's more moderate climate. The hygiene of the environment and frequency of cleaning are likely of greater relevance for disease transmission. Pens were cleaned only before the calving season by 36.2% of respondents, but cleaned weekly, fortnightly, and monthly in 17.5%, 28.8%, and 17.5% of farms, respectively. A substantial proportion of respondents (24.5%) selected a cleaning frequency that was not one of the main options given on the survey: 16.0% cleaned pens as needed through visual assessment, and 8.5% cleaned after each group or calf (individual housing). Complete replacement of litter was the most common cleaning method (57.5%), followed by adding more litter to the pen (30.0%) and spraying disinfectant onto the litter (5.0%).\n\nWe were unable to calculate a survey response rate because we could not track the number of farmers who received the study information. Considering that Australia had 5,789 registered dairy farms in 2016 (Dairy Australia, 2017b), only 1.77% of Australian dairy farmers responded to the survey. However, the distribution of responses per Australian state in our survey was similar to the distribution of registered dairy farms (Dairy Australia, 2017b), so our results include the different dairy production systems present in the country. Nonetheless, self-selection bias is also inherent in these types of studies, so the results of the current study cannot be generalized to the entire target population. However, given the current lack of studies investigating dairy calf management practices at the Australian national level, this study provides useful information on what areas appear to need more attention by farmers, veterinarians, and extension agents.\n\nSimilarly, the collection of farm samples depended on the willingness of veterinarians and farmers to collaborate with the study. This recruitment method could have skewed results, because farms that knowingly have issues with NCD may have neglected to participate due to fear of scrutiny, although the study ensured confidentiality. Likewise, farms experiencing calf-related problems might have wanted to investigate them further at no cost. Selection bias could also have occurred in the fecal samples. We asked veterinarians to randomly collect samples from eligible calves. However, they could have consciously or unconsciously sampled the sickest-looking calves. This could have increased the percentage of samples positive for pathogens that cause more systemic clinical signs (e.g., Salmonella enterica). Linked information regarding management practices at the farms where samples were collected was deliberately not sought. This decision aimed to increase the willingness of farmers to participate in the study. This limited the capacity to investigate which factors were associated with poor colostrum quality, high rates of FTPI, or the prevalence of enteropathogens. However, these factors have been extensively investigated in the literature, and the objective of the study was to provide an estimation of the abovementioned parameters in the Australian dairy system.\n\nCollectively, these results indicate that there is still considerable room for improvement of calf management practices in the Australian dairy industry; a great proportion of farms did not meet industry benchmarks. Colostrum management seems to be one of the most important areas to improve, because the prevalence of FTPI, the proportion of colostrum samples not meeting quality standards, and the proportion of farmers not separating calves from dams promptly were considerably high. Strategies to increase awareness of industryrecommended practices for calf management and feeding are needed. Further studies should investigate the drivers of dairy producers to implement these industry standards.\n\nThis study was funded through a New Initiative Grant of the Graham Centre for Agricultural Innovation (Wagga Wagga NSW) and by the Darcy John O'Sullivan Bequest administered by Charles Sturt University. The enteropathogen rapid detection assays were kindly provided by MSD Animal Health Australia. The funders played no role in the design of the study, collection, analysis, or interpretation of data, or the preparation or approval of the manuscript. The authors express their gratitude to all the farmers who completed the survey and to the veterinarians that submitted samples. Similarly, the authors thank Claire Windeyer (University of Calgary, Canada) for assistance with the questionnaire design. The assistance of the Australian Cattle Veterinarians (a special-interest group of the Australian Veterinary Association) and Emily Malone (Graham Centre for Agricultural Innovation) in recruiting veterinarians and farmers, respectively, is also greatly appreciated. Likewise, the authors thank Lori Blechynden, Michelle Ayton, and the staff at the Veterinary Diagnostic Laboratory of Charles Sturt University for their help and support. Part of this study was included in the Bachelor of Veterinary Biology/ Bachelor of Veterinary Science (Honours) dissertation of N. Wood. The authors declare no competing interests."}