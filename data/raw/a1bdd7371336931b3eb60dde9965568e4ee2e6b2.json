{"title": "New technologies in computer-aided drug design: Toward target identification and new chemical entity discovery", "body": "Drug research and development (R & D) is comprehensive, expensive, time-consuming and full of risk. It is estimated that a drug from concept to market would take $12 years and cost more than US$800 million on an average [1] . Several new technologies have hence been developed and applied in drug R & D to shorten the research cycle and to reduce the expenses. Computer-aided drug design (CADD) is one of such evolutionary technologies [2] .\n\nHaving emerged as a quantitative structure-activity relationship (QSAR) analysis in the early 1960s, the concept of CADD has evolved very quickly, especially in the recent decade as an unprecedented development of structural biology and computer capabilities. CADD technologies including molecular modeling and simulation have become promising in drug discovery. Recently, CADD has even been used in designing highly selective ligands for a certain target that shares very similar structures with many proteins, which is difficult to be done by other methods. One such example is the rational design of selective inhibitors of p90 ribosomal protein S6 kinase [3] . In the postgenomic era, owing to the dramatic increase of small molecule and biomacromolecule information, CADD tools have been applied in almost every stage of drug R & D, greatly changing the strategy and pipeline for drug discovery [2] . As indicated in Fig. 1 , CADD, from its traditional application of lead discovery and optimization, has extended toward two directions: upstream for target identification and validation, and downstream for preclinical study (ADMET prediction) . In this review, we highlight some recent advances of CADD technologies; emphases are put on computational tools for target identification and new chemical entity discovery.\n\nTarget identification and validation is the first key stage in the drug discovery pipeline (Fig. 1) . However, identification and validation of druggable targets from among thousands of candidate macromolecules is still a challenging task [4] . Numerous technologies for addressing the targets have been developed recently. Genomic and proteomic approaches are the major tools for target identification. For example, a proteomic approach for identification of binding proteins for a given small molecule involves comparison of the protein expression profiles for a given cell or tissue in the presence or absence of the given molecule. This method has not been proved very successful in target discovery because it is laborious and time-consuming [5] . Therefore, complementary to the experimental methods, a series of computational (in silico) tools have also been developed for target identification. They can be cataloged into sequence-based approach and structure-based approaches.\n\nSequence-based approach contributes to the processes of target identification by providing functional information about target candidates and positioning information to biological networks. For those diseases caused by external pathogens such as bacteria and viruses, unique targets might be found in the pathogens by comparing functional genomics from humans with the corresponding genomics from pathogens [6] . For example, Dutta et al. used a subtractive genomic method to analyze the completed genome of Helicobacter pylori (H. pylori) and identified a set of genes that are likely to be essential to the pathogen but are absent in humans [7] . In theory, it is possible to recognize all the targets in the pathogen in this way; whereas for endogenous diseases, targets could be discovered by analyzing the differences of genomics between normal and abnormal tissues. A good example of this issue is that several novel steroid targets were identified by combinative use of bioinformatics and functional analysis of hormone response elements [8] .\n\nStructure-based approach that has shown promise in recent years is to use computational methods to find putative binding proteins for a given compound from either genomic or protein databases, and to subsequently use experimental procedures to validate the computational result [9] . One such computational approach, which is the reverse of docking a set of ligands into a given target, is to dock a compound with a known biological activity into the binding sites of all the three-dimensional (3D) structures in a given protein database. Protein 'hits' identified in this manner can then serve as potential candidates for experimental validation. Accordingly, this approach is referred to as reverse docking (or inverse docking) [10, 11] . The general procedure of target identification by using reverse docking integrating with biological technologies is shown in Fig. 2 . It includes four steps: reverse docking of a small molecule to select hit proteins; hit proteins postprocessing of through bioinformatic analysis to select candidates; experimentally validating by using biochemical and/or cellular assays; and finally, if it is possible and necessary, determining the X-ray crystal (or NMR) structures of the small molecule-protein complexes to verify the target at the atomic level. This approach requires a sufficient number of known protein structures covering a diverse range of drug targets (Fig. 2) . The protein structures are usually selected from the protein data bank (PDB) [12] or constructed with protein structure prediction method. Using a subset of PDB as an example, Paul et al. successfully recovered the corresponding targets of four unrelated ligands with the help of reverse docking method [13] .\n\nA reverse docking web server, Target Fishing Dock (TarFis-Dock), was also developed for identifying new drug targets [11] . For this server, a potential drug target database (PDTD) was constructed. The target proteins collected in PDTD were selected from the literatures and from several online Figure 1 . Drug discovery pipeline vs. computer-aided drug design (CADD) tools. CADD tools have been initially developed for lead optimization (such as QSAR) and then expanded for lead discovery (such as virtual screening). Now CADD tools have quickly extended toward both upstream and downstream directions along the drug discovery pipeline. In upstream direction, bioinformatics and reverse docking methods are usually used for target identification; once a target is identified, in silico methods are also developed to predict its 3D structures before experimental determination; computational methods can be used to predict target druggability and to design compounds before further experiments. In downstream direction, in silico ADMET prediction and physiologically based pharmacokinetic simulations can be conducted to model the preclinical test, which is usually integrated into in silico lead discovery stage to reduce the costs.\n\ndatabases, such as DrugBank. The structures of proteins were from PDB. Recently, TarFisDock has been proved as a tool of great potential value for identifying the target of anti-H. pylori natural product [14] . Colonization of the human stomach by the bacterium H. pylori is a major causative factor for gastrointestinal illnesses and gastric cancers. However, discovery of anti-H. pylori agents is a difficult task because of lack of mature protein targets. Therefore, identifying new molecular targets for developing new drugs against H. pylori is obviously necessary. The in-house potential drug target database was searched by using the reverse docking tool TarFisDock, taking the active natural product (Fig. 2a ) discovered by anti-H. pylori screening as a probe. Homology search revealed that among the 15 candidates discovered by reverse docking, only diaminopimelate decarboxylase and peptide deformylase (PDF) have homologous proteins in the genome of H. pylori. Enzymatic assay demonstrated the natural product and one of its derivatives are the potent inhibitors against the H. pylori PDF (HpPDF) with IC 50 values of 10.8 and 1.25 mM, respectively ( Fig. 2e ). X-ray crystal structures of HpPDF and the complexes of HpPDF with the natural product and its analog were also determined ( Fig. 2f ), demonstrating at the atomic level that HpPDF is a potential target for screening new anti-H. pylori agents.\n\nThe advantage of reverse docking is obvious: in addition to identifying target candidates for active compounds, it is also possible to identify potential targets responsible for toxicity and/or side effects of a drug supposing that the target database contains all the possible targets [15] . However, reverse docking still has certain limitations. The major one is that the protein entries in the protein structure databases, like the PDB, are not enough for covering all the protein information of disease-related genomes. The second one is that this approach has not considered the flexibility of proteins during docking simulation. These two aspects will produce negative false. Another limitation is that the scoring function for reverse docking is not accurate enough, which will produce positive false [11] . One tendency to overcome these shortages were expressed, and the binding affinities and/or inhibition or activation activities of the probes to the target hits were determined. In this way, the target candidates can be selected for further functional validation. (f) The crystal structure of natural product-target candidate (HpPDF) complex. This means that the binding between the natural product and target candidate was verified at the atomic level. The images of the proteins were generated using the PyMol program (http://pymol.sourceforge.net/).\n\nwww.drugdiscoverytoday.com is to develop new docking programs including protein flexibility and accurate scoring function. Another tendency is to integrate sequence-based and structure-based approaches [4] .\n\nDrug discovery and development in the past 100 years has been performed only against approximately 500 targets; and in the same period, about 20,000,000 organic compounds including natural products have been synthesized or isolated. However, the use of organic chemicals in drug discovery seems to be out of favor because the existing targets have not been screened by all the available compounds. In addition to this, the completion of the human genome suggests that there are 600-1500 druggable targets for drug intervention to control human diseases [16] . Therefore, it is believable that a large number of new drugs, at least many leads or hits, are hiding in the existing chemical mine. However, digging out this source is a hard task. Collecting all the existing compounds and screening them randomly are extremely unpractical, because it is intolerably expensive and timeconsuming although virtual screening shows a dawning to satisfy this requirement [17] . Indeed, recent promising advancement in virtual screening has demonstrated the efficiency of this approach in discovering lead (active) compounds. Virtual screening enriched the hit rate (defined as the number of compounds that bind at a particular concentration divided by the number of compounds experimentally tested) by about 100-1000-fold over random screening. Accordingly, virtual screening has been involved in the pipeline of drug discovery as a practical tool [18, 19] . Nevertheless, as mentioned above, all hits produced from virtual screening are existing compounds or old drugs, that is, virtual screening can only find the new medical usages for the existing compounds or drugs. What big pharmas and medicinal chemists are seeking is new chemical entities (NCEs), which can be strictly protected by the compound patents. There are at least two kinds of CADD methods for NCE discovery, de novo drug design [20] [21] [22] and combinatorial library design [23] .\n\nThe de novo drug design does not start from a database of complete molecules but aims at building a complete molecule from molecular bricks ('building blocks') to chemically fill the binding sites of target molecule [24] . The complete chemical entries could be constructed through linking the 'building blocks' together, or by growing from an 'embryo' molecule with the guidance of evaluation of binding affinity. The 'building blocks' could be either atoms or fragments (functional groups or small molecules). But using atoms as 'building blocks' is thought to be inefficient, therefore, it is seldom used nowadays. In the fragment linking approach, the binding site is mapped to identify the possible anchor points for functional groups. These groups are then linked together, and they form a complete molecule. In the sequential-growing approach, the molecule grows in the binding site controlled by an appropriate search algorithm, which evaluates each growing possibility with a scoring function. Different from docking-based virtual screening, fragment-based de novo design can perform sampling in the whole compound space, obtaining novel structures that are not limited in available databases. But the quality of a growing step strongly depends on the previous steps. Any step chemically going wrong would lead to an unacceptable result. For the fragment linking approach, choosing linkers to connect fragments together as complete structures is a problem. The most remarkable drawback of this approach might be the synthetic accessibility of the designed structures.\n\nThe advent of combinatorial chemistry is one of the most exciting developments in medicinal chemistry in the last decade. Coupled with automation technologies and highthroughput screening (HTS), it offers great potential for discovering new drug leads. This technology allows thousands or even millions of compounds to be synthesized at the same time. However, many products in the huge library are redundant. It also does not make sense to validate and assay millions of compounds. In addition to this, it was found that the large number of compounds synthesized did not result in the remarkable increase in drug candidates though the number of compounds synthesized and screened has increased by several orders of magnitude [25] . Initially, the focus of combinatorial library design was on selecting diverse sets of compounds on the assumption that maximizing diversity would result in a broad coverage of bioactivity space and hence would maximize the chances of finding drug leads. The creation of diversity through compound libraries has been a central claim and task of combinatorial chemistry since its inception. Suggestions and assumptions on how to assess diversity have been studied during the last decade. To synthesize a chemical library with reasonable size and considerable hit rate, 3D structural information and properties of a studied target should be taken into consideration to filter out redundant compounds [23] . Thus, the critical challenges are firstly to select sets of fragments that have the best potential to be parts of new drug leads for a given target; and secondly to set up proper criteria for product judgment (screening). To overcome the first challenge, three types of virtual libraries have been suggested. They are focused libraries, targeted libraries and primary screening libraries. A focused library is built on the basis of a lead molecule or pharmacophore and is geared toward one particular molecular target. A targeted library is designed for finding drug leads against specific targets. A primary screening library is a large combinatorial library used to randomly find new hits or to design novel scaffolds. To solve the second problem, druglikeness (ADMET) and structural diversity have been introduced into library design to reduce its size and increase its efficiency.\n\nAdopting the advantages of focused library and targeted library, as well as integrating technologies of docking-based virtual screening and druglike (ADMET) analysis, a targetfocused library design method was developed, based on which a software package, called LD1.0, was also developed [23] . The flowchart of LD1.0 is shown in Fig. 3 . Starting with the structures of hits and therapeutic target, the overall skeleton of potential ligands is schematically split into several fragments according to the interaction mechanism and the physicochemical properties of the binding site. Individual fragment library is constructed for each fragment, taking into account the binding features of the fragments to the binding site. Finally, target-focused libraries on the studied target are constructed with the judgments from structural diversity, druglikeness (ADMET) profiles and binding affinities [23] . During the target-focused library design, library-based genetic algorithm was applied to optimize the focused library, and the newly developed druglikeness filter was used to predict the druglike profile of the library [26] . Molecular docking approach was employed to predict the binding affinities of the library molecules with the target.\n\nThe quality of fragment libraries is critical to the final focused library. There are at least three ways to construct the fragment libraries [23] . Extracting fragments from known drugs or ligands (inhibitors or activators) of the studied target is an effective approach for collecting building blocks. Homology proteins usually share similar structural features and characteristics, especially at the binding site or active site. Therefore, the ligands for different targets belonging to the same family should share some common fragments. Thus, the fragments for constructing target-focused library could be designed by referring to the structures of the ligands of the homology proteins of the target. Also, fragments could be isolated from the active hits produced through primary screening (HTS and virtual screening) .\n\nThe efficiency of the strategy for target-focused library design and screening has been demonstrated by our recent example of discovering human cyclophilin A (CypA) inhibitors [27, 28] . By employing docking-based virtual screening in conjunction with chemical synthesis and bioassay, 14 binders of CypA were discovered, and four of them showed high CypA PPIase inhibition activities with IC 50 values of 2.5-6.2 mM [27] . To discover new chemical entities of CypA inhibitors with more potent activities, a target-focused library was designed based on the structures of the 14 hits and their binding modes to CypA by using the program LD1.0. The binding modes indicated that the small molecular CypA binders can be divided into three parts: part A interacts with the small pocket of CypA (pocket A), part B is located in the large pocket (pocket B) and part L is a linker between A and B, interacting with the 'saddle' pocket between sites A and B (Fig. 4) . LD1.0 selected 5 fragments for part A, 17 fragments Fragments for target-focused library design can be selected according to the interaction modes between primarily screened hits (binders) and target. Accordingly, these fragments are leadlike building blocks for constructing library. When the fragments are connected into whole molecules, they are optimized again for the interaction poses and binding affinities by using docking. This image was generated using the PyMol program. Remarkably, both the binding affinity and the inhibitory activity of the most potent compound increased $10 times than that of the most active compound discovered in the first cycle of discovery [28] .\n\nThe technological progress of CADD brought a paradigm change to both pharmas and research institutions: it was now possible to obtain appropriate hits within several weeks because of the contribution of CADD [29] . Traditionally, structure-based and pharmacophore techniques and QSAR are major tools for CADD. Parallel to the development of combinatorial chemistry and HTS since more than a decade ago, several new technologies, such as library design, virtual screening, druglike analysis and ADMET prediction, have become important tools in the computer-aided discovery of new drugs. In the coming future, in addition to improving individually existing CADD techniques, such as increasing the accuracy and effectiveness of virtual screening, one major tendency of CADD technology development will be to integrate computational chemistry and biology together with chemoinformatics and bioinformatics. This will leading to a new topic known as pharmacoinformatics, which will impact the pharmaceutical development process and increase the success rate of development candidates [30] . Another tendency is that CADD technologies have been entering into the functional genomic studies and target identification in particular. After the completion of the human genome and numerous pathogen genomes, efforts are underway to understand the role of gene products in biological pathways and human diseases and to exploit their functions for the sake of discovering new drug targets [31] . Small and cell-permeable chemical ligands are used increasingly in genomic approaches to understand the global functions of genomes and proteomes. This approach is referred to as chemical biology (or chemogenomics) [32] . As such, reverse docking can be referred to as computational chemical biology, which has been proven to be an effective way in finding clues of new targets [11] [12] [13] [14] [15] . On the contrary, the CADD techniques like virtual screening and library design can also be used to design small molecule probes for illuminating the molecular mechanisms underlying biological processes through altering or perturbing the functions of target proteins by inhibiting or activating their normal functions [17, 32] .\n\nIn postgenomic era, the concept of computer-aided drug design (CADD) has extended from lead discovery to target identification, from lead optimization to preclinical or clinical trials. Two approaches for in silico target identification: sequence-based and structure-based. In sequence-based approach, bioinformatic methods are applied to analyze and compare multiple sequences and identify potential targets from scratch; whereas in structure-based approach, reverse-docking methods might be helpful to identify target candidates for active compounds. At least two in silico strategies for the discovery of NCE: de novo drug design and combinatorial library design, especially target-focused library design, which has been demonstrated by our recent example of discovering human cyclophilin A inhibitors. Druglikeness or ADMET properties can be considered in library design."}