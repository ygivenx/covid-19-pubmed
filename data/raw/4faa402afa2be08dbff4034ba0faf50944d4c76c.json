{"title": "DEALING WITH BIO-AND ECOLOGICAL COMPLEXITY: CHALLENGES AND OPPORTUNITIES \"Status report prepared by the IFAC Coordinating committee on Bio-and Ecological Systems\" by", "body": "The complexities of the dynamic processes and their control that are associated with biological and ecological systems offer many challenges for the control engineer. Over the past decades the application of dynamic modelling and control has aided understanding of the complexities of their dynamics and control. At the same time using such complex systems as test-beds for new control methods has highlighted their limitations (e.g. in relation to system identification) and has thus acted as a catalyst for methodological advance. This paper continues the theme of exploring opportunities and achievements in applying modelling and control in the bio-and ecological domains, building on the earlier work reported in Hashimoto et al. (2004) .\n\nEach of the four thematic areas of agricultural, biomedical, environmental and biotechnological systems are considered in turn. In section 2, current key problems for each of these four areas will be considered. Section 3 focuses on recent major accomplishments. Finally, section 4 makes some forecasts for each of the areas as to where future development is likely to focus.\n\nAdapting to the Variability of Land and of Biological Systems: The variability of land and of biological systems and processes must be taken into account for improving the efficiency of agricultural production, post-harvest handling, storage and transportation of the products. This is still very much an area where there are problems to be tackled. At the same time there is pressure for consumer safety and ecological sustainability. This implies that technological developments need to be directed towards correct treatment at the right place and at the right time. Examples for this can be found in animal production where automatic identification of stress or illness of individual animals will lead to individual treatments rather than a group treatment (Moshou et al., 2001) .\n\nSimilarly one may see systems for automatic measurement and automatic composition of feed Copyright (c) 2005 IFAC. All rights reserved 16th Triennial World Congress, Prague, Czech Republic rations, climatic control etc., according to the performance characteristics of individual animals. The measurement of the animal's response to different treatments ('speaking animals') will lead to performance identification (Berckmans and Aerts, 2003) . In plant production, in protected cultivation or in open fields, there is also a tendency to look at the production characteristics either of individual plants or of small patches of plants (Griepentrog et al., 2003) . Combined variability of soil (spatial variability) and weather (temporal variability) plays an important role and must be taken into account together with the time-varying plant characteristics.\n\nThis will lead to automatic control of processes in the soil-substrate-plant-environment continuum or in phyto-factories whereby again plant responses to treatments serve as a basis for system identification (Baas, 2003; Morimoto and Hashimoto, 2000) . This is a further development of the 'speaking plant' concept. Process design and control in protected cultivation and in storage of crops will be required for a very sharp reduction in energy use (Sigrimis and King, 2000) .\n\nAutomatic detection of weeds, plant stress or imminent diseases will allow for appropriate local treatments, thereby minimising the impact on the environment. In this respect, it is most likely that sustainable as well as organic farming can only be possible or profitable if use is made of advanced and automated technologies.\n\nIn some regions (Europe, North America) there is a renewed interest in automation of harvesting and handling (quality sorting) of crops because of the difficulty of finding skilled labour at a reasonable cost and within the social and economic constraints. This is now especially so for high value crops in horticulture like fruit production or greenhouse production (De Baerdemaeker, 2001) . Furthermore, automatic control will enhance and exploit the full working capacity of machines, rather than designing larger machines to increase capacity. Human comfort and ergonomics are also areas attracting new interest in relation to technology and automation.\n\nAutomation for tracking and tracing of products and of the production conditions (stage of maturity, variability, treatments, etc.) is another important area where there are issues to be addressed, in which information technology developments will undoubtedly play an important role. These are areas where advanced sensor and communication methods are used. In the end, the quality as experienced by the customer is the important issue. Here, packagings with integrated thin film micro sensors allow the user to see the integrated temperature history of the product. More advanced would be the direct control of a microwave oven by information contained on the package about the current product.\n\nDisease Modelling and Public Health : The area of modelling disease transmission/propagation within a community or across biological/living systems constitutes a problem area where automation and automatic control methods and techniques could play an important role. The outbreak of a deadly new infectious disease, SARS (Severe Acute Respiratory Syndrome), which originated in the southern part of Mainland China and spread across Hong Kong, Vietnam, Singapore, Canada and some EU countries during the turn of 2003, has prompted public awareness about monitoring, preventing, and controlling the spread of disease as well as the need for access to the latest disease information (WHO, 2004) .\n\nThe world had witnessed the power of public health measures including surveillance, infection control, isolation, and quarantine. Although the SARS outbreak is over and there have only been a small number of suspected cases in P.R. China recently, it is not possible to predict if and when another round of SARS outbreak will occur (indeed further occurrences were seen in 2004). In order to control a possible SARS outbreak, there is the need to be prepared. The development of a rapid and decisive surveillance system is paramount, and the keys to the successful implementation of such a system are upto-date information on local, national, and global SARS activity and effective communication among local and international healthcare workers using web technologies (WHO, 2003a ).\n\nYet another important issue in relation to disease control is to study the transmission mechanism of the disease by means of modelling (Riley et al., 2003) . The results of modelling the transmission mechanisms are not only crucial to controlling and/or containing the disease outbreak, but also the hospital resource allocation and economic impact of the regions under threat by the disease (WHO, 2003a; 2003b) . Those data are very useful for referencing by neighbouring regions or distant regions for reallocating resource and planning for appropriate control policies in advance (WHO, 2003a) .\n\nAs well as disease modelling in such a public health context as described above, there is also the need for further development of modelling methods for predicting patient length of stay in a hospital. This is a problem of substantial importance in terms of ensuring that the best possible use is made of scarce healthcare resources.\n\nTherapy Delivery Systems : With a greater understanding of pharmacokinetics and pharmacodynamics at the molecular level, possibilities now exist for tailoring drug delivery systems designed to the needs of the individual patient. This raises a number of issues and opportunities in relation to modelling and control, seeking to develop smart drug delivery systems based on modelling the individual patient and the drug dynamics.\n\nImage-guided surgery is another emerging area, where the delivery of the surgical therapy, is conditioned by feedback provided during the time course of the surgical procedure. Such feedback utilises real-time modelling of the relevant physiological systems, reflecting the changing state of the patient during the course of surgery.\n\nIntegrated Water Resources Management: In many parts of the world, water demand is increasing while at the same time the availability and quality of water resources are decreasing, mainly due to human activities in connection with the growing world population, ongoing urbanisation, industrialisation and the intensification of agriculture. This development is often associated with general reductions in environmental quality and, as such, endangers sustainable development. Integrated approaches are required to identify and analyse such unfavourable and undesired developments and allow sustainable systems to be designed that integrate human society with its natural environment for the benefit of both.\n\nIt is generally agreed (Bonell and Askew, 2000) that integrated water resources management (IWRM GWP, 2000; plays a crucial role in this context and that a participatory approach would help to better control and accelerate the integration, make the decision process more transparent and comparable across various river basins and scales and increase confidence in an integrated model-based planning process. Though the popularity of IWRM as a concept has increased during the last decade, applications to real world cases of the paradigm mentioned in the literature are still remarkably few (see for instance Tortajada et al. (2004) ), thus leading to a growing scepticism (Biswas, 2004) as to the real potential of this attractive approach.\n\nThe development of proper legislation and policy is a key issue for the dissemination of integration and participation into water management practice (Wolf, 2002) . At a European level the IWRM paradigm has been adopted by the Water Framework Directive (EC-WFD 2000) that came into force in December 2000. The directive introduces a set of requirements to be fulfilled in order to reach an inland and coastal water \"good status\" by 2015 and sets out a detailed framework for the improved planning and management of water, including the development of River Basin Management Plans (RBMP) to be prepared within 2009 (WFD, Art. 13).\n\nThe Guidance Document for the Planning Process how the term integration should be intended in the implementation of such plans. Integration must concern many aspects, among which the following are particularly relevant: -Integration of environmental objectives; -Integration of all water uses, functions and values into a common policy framework; -Integration of all significant management and ecological aspects; and -Integration of stakeholders in decision making, by promoting transparency and information to the public and by involving stakeholders in the development of RBMP.\n\nAgain the GD11 recognises that planning is a process. This requires the provision of procedural guidance on the production and development of River Basin Management Plans supported by appropriate toolboxes, that should help to identify the possible trade-offs amongst quantifiable objectives so that further debates and analysis can be more informed.\n\nMoreover, the toolboxes must support planning as a systematic, integrative and iterative process.\n\nAccording to these requirements a general procedure (see Figure 1 ) for Participatory and Integrated Planning (PIP) has been developed (Castelletti and Soncini-Sessa, 2004) , where the decision making process is emerging as a process of social learning, which has to be supported by a Multi Objective Decision Support System (MODSS), based on system identification, control and decision theories.\n\nFurthermore, Water Reservoir Management systems are emerging as a fundamental component in the design of new dams as the best reply to flood and drought events that the 'greenhouse effect' is going to make more and more frequent.\n\nOther environmental sectors: Also, in other environmental sectors, such as air pollution, solid waste disposal and CO 2 emissions, the need emerges for behavioural models for complex decision analysis (Tamura, 2005) , conflict resolution and the design of policy: e.g. a policy for nations on CO 2 emission trading.\n\nThe goal of biotechnological processes is to optimise the performance of processes involving industrially important organisms (e.g. for the production of food products and additives), biomedically relevant species (e.g. for the production of antibiotics and other therapeutics) and the degradation of pollutants (e.g. wastewater treatment). This last area has been assuming ever-increasing importance during the past few years.\n\nMost bioprocesses are run batchwise or fed batchwise. They are inherently highly nonlinear systems, due to the bioreaction kinetics on the one hand and to the operation mode on the other hand. They are poorly taken care of by linear controllers, developed to maintain a process around its steadystate.\n\nBioprocesses involved in wastewater treatment (domestic, urban or industrial) are mostly operated continuously, at least for large-capacity facilities. In contrast to \"classical\" biopocesses which are based generally on a single species (bacteria, yeast, fungi, mammalian, plant or insect cells), they involve a complex ecosystem, where different microorganisms (bacteria, protozoa, metazoa or archea) should be kept in a good balance, in spite of highly variable influences. Whatever their size, wastewater treatment plants are complex nonlinear systems, subject to large perturbations (in flow, concentration and composition of the \"substrate\") and where different physical (such as settling) and biological phenomena take place. This makes them difficult to control in order to achieve the tight discharge limits which are specified nowadays.\n\nMuch is being achieved in wastewater treatment control applications. However, there are still a number of areas where there are significant problems yet to be addressed. These predominantly relate to the measurement processes where there is the need for further developments in both hard and soft sensors for biotechnological system control. This in many instances is the limiting factor in advancing effective control systems.\n\nOptimised Crop Cultivation: Much progress is being made in optimising cultivation of a wide variety of crops as a direct result of advances in measurement and control. These include advances in crop sensor technologies and developments in computing power which now makes model-based optimal control practicable (van Straten et al., 2000) .\n\nThere is a clear tendency towards individual plant monitoring. In particular, stem sap flow, leaf photosynthesis rate, leaf temperature, and stem or fruit perimeter can be measured on-line. The question remains, however, how this information can be used to control the crop as a whole. The solution to this question is related to natural variation between plants, and to spatial distributions. The latter problem is attacked now by advanced computational fluid dynamics (CFD) techniques (Reichrath and Davies, 2002) . In relation to water, individual ions can be measured with ion-selective electrodes, thus allowing accurate feedback control to satisfy the demand of the plant (Sigrimis et al., 2001; van Straten and Gieling, 2004) . As to the control itself, optimal control methodology now allows for economically optimal control, The bottle-neck here is the lack of sufficiently accurate crop quality models, although some progress has been made in a number of areas.\n\nA model for nitrate in lettuce has been used, for instance, to control the nitrate content of the head at harvest time (De Graaf et al., 2004) .\n\nApplication areas where advances are occurring include greenhouse operation . Here, for instance, multi-level digital control systems with generalised functions for process control have been developed to meet greenhouse control requirements. Hierarchical schemes are typically employed whereby intelligence is shared amongst low level control loops of the controller and the higher level decisions made by a central process computer . Such schemes provide a platform for an open system to implement all modern (including optimal) control techniques and plant management strategies. In The Netherlands the degree of penetration is large and the potential total area modest, whereas in China the degree of penetration is very low, but the growth potential is enormous. (Adapted and expanded from van Os (2000)).\n\nMore generally, a crude indicator for the penetration of high technology, including computerised control and robotics in the greenhouse industry is provided by the percentage of soil-less cultivation (Hydroponics). Figure 2 shows the percentage of hydroponic penetration across a range of countries.\n\nIntelligent Machinery: A further general area in which advances are occurring is that of intelligent machinery being used in the agricultural sector. This is a direct spin-off from developments in the electronics industry which sees both ever increasing specification coupled with price reductions that make widespread adoption both feasible and affordable. One example that that has been around for some time is the use of Geographical Positioning Systems (GPS) together with yield maps for precision farming Earl et al., 2000) .\n\nAnother challenge is the development of autonomous vehicles for agricultural operations (Bak and Jakobson, 2004) . This is stimulated by the needs from organic farming, where chemical weed control is not possible, thus necessitating time consuming, costly hand weeding. Intelligent autonomous vehicles with the right implements could have a role here, requiring the solution of a number of issues regarding autonomy, intelligence and safety. In the future, one may well see a development in the direction of individual plant treatment, even for field crops, using a fleet of co-ordinating smaller machines, that are working day and night.\n\nPost Harvesting: In storage technology, there is a similar tendency as in crop production, namely to strive for model-based quality control of the stored or transported product (Verdijck and van Straten, 2002) . The agri-food sector is an area, where modern modelling and control methodology is penetrating rapidly (e.g. Stigter et al. 2001; Bin Xia and Da-Wen Sun, 2002) .\n\nDevelopments in Model-Based Image Interpretation :\n\nOne of the important emerging areas where significant advance is occurring is improved imaging techniques, particularly molecular nuclear medicine imaging techniques (e.g., positron emission tomography (PET) and single-photon emission computed tomography (SPECT)), which allow in vivo study of physiological processes and provide local dynamic biochemical qualitative and quantitative information not available with conventional imaging modalities such as computer tomography (CT) and magnetic resonance imaging (MRI) (Phelps, 2000) . For quantitative studies, intensive modelling, system identification and control theories and techniques are required (Feng et al., 1997; Wong, 2004) .\n\nThe recent combination of PET/CT provides a new opportunity to better match the quantitative biomedical process to its anatomical structure in the living human body and facilitates the monitoring of therapeutic response and progress of the treatment (Ell and von Schulthess, 2002) . In this rapidly developing area, fast and reliable parameter estimation algorithms are extremely important, e.g. a fast algorithm for nonlinear system modelling is useful for neuroreceptor quantification and pharmocokinetic system identification.\n\nAnother developing area is bio-informatics involving modelling and control issues, which are also useful in healthcare delivery and its management. Healthcare is a highly heterogeneous, widely distributed but scattered sector. Yet, healthcare activities are composed of intensive information exchanges and complex interactions among a large number of healthcare professionals, academic researchers, patients, and service administrators.\n\nThe explosive growth of the Internet and World-Wide-Web (www) has had a significant impact on information exchange, and increasingly health information is stored in an electronic format (e.g. electronic medical/health records) that greatly facilitates sharing of health information in a much more convenient way than previously (Dick et al., 1997) .\n\nTypically when one talks about electronic healthcare, two distinct, yet closely related categories of applications come to mind: (1) medical or health informatics, and (2) clinical applications. There are many possible and potential research directions in these two applications where modelling and control of biomedical systems is involved.\n\nFor example, the idea of establishing a computerbased hospital automation system within a hospital has been a strong desire for many hospital administrators in the world. In particular, electronic health record systems which store information about an individual's lifetime health status, and decision support systems that plan for the effective usage of hospital resources for the individual patient based on their health status and needs, are valuable assets that can enhance dissemination of individual patient information among different departments/wards and physicians within/across hospitals, and have a positive impact on decision making (Dick et al., 1997) .\n\nComplementing developments in the hospital sector, there is under way a very significant shift towards home care, particular in the management of elderly persons and patients with chronic diseases such as diabetes, hypertension and asthma (Coyle et al., 1995; Van Dyk and Halverson, 2000) . This is being made possible as a result of advances in the application of information and communications technologies, leading to what is termed home telecare.\n\nThis embraces the provision of information to the patient in their home setting, the remote monitoring of the patient both as to their clinical status and their wider health status reflecting quality of life, and the provision of treatment and lifestyle advice to the patient, based on the interpretation of the homemonitored data.\n\nThis home telecare modality makes use of a wide range of measurement, modelling, decision making and control methodologies. It is particularly relevant to the needs of elderly patients suffering from chronic diseases and is set to assume increasing importance as a component of overall healthcare delivery over the coming decade (Coyle et al., 1995; Warner, 1997) . There is, however, still much evaluation work to be undertaken before such novel modalities of healthcare delivery are fully accepted as being cost effective, and in this regard modelling approaches have a clear role to play (Skiadas et al., 2002) .\n\nLarge scale systems: A number of advances are apparent in the way in which modelling methods are being applied to increase understanding of environmental systems. These include composite models being used to predict and estimate important environmental variables and to explore efficient environmental strategies and management schemes.\n\nThey are also being used in assessing influences and impacts for environmental change; how changes of input variables and/or environmental variables influence mutually the variables of the climate system, ecological systems, socio-economic activities, human lifestyle and others. More generally there is now evidence that policy decision making in this arena is increasingly being based on assessment models. Examples include the exploration of scenarios and the evaluation of policies designed to mitigate the effects of global warming. Identifiability of large simulation models: Large models are over-parameterised and so many different sets of parameter values will provide a similar explanation of the available data (equifinality). The alternatives are to use simpler, identifiable models; or constrain the parameters in some manner to a userspecified region of the parameter space (based on \"expert\" knowledge), either deterministically or stochastically (e.g. a numerical Bayesian approach) (Young, 1998 (Young, , 2003 Taylor et al., 2000; Young et al., 2002) .\n\nIn the last few years there has been a significant reemergence of the 'top-down' approach as an alternative to reductionist, 'bottom-up' approaches. This is supported by a growing number of scientists and modellers, including the Chairman of the UK Natural Environment Research Council (NERC). Moreover a growing interest in numerical Bayesian methodology, or in simpler alternatives as a tool in modelling and data assimilation, has to be noted.\n\nIt is unlikely that the problem of identifying large simulation models will be resolved (since the ambiguity cannot be removed). However, it will be realised that: (a) simple models are, in any case, best for time series forecasting (e.g. flow and flood forecasting) so the difficulties with the larger models are not too important; (b) simple models can also form a basis for the construction of large simulation models (required for the purposes of \"what-if\" planning and design studies) that at least have an identifiable \"core\" which explains the \"dominant modal dynamics\"; and (c) such large simulation models can then be handled using a numerical Bayesian approach or, preferably, a computationally simpler alternative.\n\nIndustrial Applications: Developing trends can also be observed at the level of different types of industry, where environmental control challenges are having to be met. For instance, over the past two decades the car industry has not only successfully cleared regulations for exhaust gas emissions, but has also reduced fuel consumption by means of computer controlled devices.\n\nIn the area of water quality control, design challenges for sewage plants include those of regulating the total quantities of nitrogen and phosphorus being transmitted from the waste plant to the river. In this context, precise and detailed mathematical models are needed and are being developed to estimate the water quality and quantity. These include models to describe changes in water quality and quantity from rainfall to the sewage plant, and models describing the decomposition of organic substances by bacteria and the removal of phosphorus.\n\nThe purpose of such mathematical models is to estimate and predict the changes over time in water quality and quantity, to design a sewage treatment plant control system, to realise an on-line control and tuning algorithm based on the model, and so on. However, whilst progress is being made, there are still methodological challenges to be overcome, relating to the proper treatment of bacterial reaction, with their nonlinear dynamics and spatially wide processes.\n\nMany control strategies have been proposed in the literature for wastewater treatment plants but their evaluation and comparison are difficult. This is partly due to the variability of the influent, to the complexity of the physical and biochemical phenomena and to the large range of time constants (from a few minutes to several days) inherent to the activated sludge process or to the anaerobic digestion.\n\nA benchmark for a continuous treatment process by activated sludge (BSM1), i.e. a simulation environment defining a plant layout, a simulation model, influent loads, test procedures and evaluation criteria has been proposed within the framework of COST Actions 682 and 624 Alex et al., 1999; Copp, 2001) in Europe.\n\nExtension of BSM1 toward plant-wide control is under development with the inclusion of anaerobic digestion of wasted sludge. This might have been an incentive for the new interest for these applications in the control community. Two sessions in the 15 th IFAC World Congress in Barcelona were devoted to wastewater treatment. Out of the thirty papers presented in the sessions related to biotechnological processes, 50% concerned water treatment.\n\nA special section of Control Engineering Practice contains a selection of these contributions (Volume 12, Issue 3, Pages 241-373, 2004 ).\n\nThe bioreactor is still most of the time the only piece of equipment which is really looked at. However the whole integrated process should be included. There is definitely a need for a systematic methodology to take into account the whole integrated process. The reason for such difficulties might be that the downstream treatment (separation, crystallisation etc.) is typically regarded as a chemical process rather than as a biochemical one.\n\nThe operations indeed are quite similar to the ones found in the fine chemicals industry but the specificity of biomolecules and the complexity of the fermentation broths should be strengthened out. As in chemical engineering, there is a strong desire for combining more design and control. This has been a topic of discussion for many years but the real advances in that field seem rare.\n\nThe concept of bioreactor is also applicable to the cells themselves. The \"Cell Factory\" implies that by looking to the bioreactor we are not at the basic level of control and that we should discover and learn the regulatory pathways inside the cells to be able to act on them. The door to system biology opens up.\n\nThere might be, however, some discussion about the absolute necessity of elaborate complex biomodels. The lack of reliable on-line or in situ measurements has always been a problem in biotechnology. They would allow a shortening in the response time of the control loops and may allow the use of simpler models. Indeed some smart sensors are able to indicate when they are defective, which is already very useful information.\n\nInstrumentation and monitoring are still major challenges. New sensors require years of development and testing before going on to the market, whose size is also an unfavourable factor. Basic sensors, mostly for physical and partly for chemical variables, are no longer a problem. What is more critical is the lack of sensors for biosubstances and for biomass.\n\nThe hopes which arose years ago from bioelectrodes have vanished in terms of their applications for bioprocess monitoring. They have found other fields of application. The bioindustry has probably not benefited enough from the development of microsensors. One of the reasons might be the harsh conditions they should withstand during sterilisation by steam, a prerequisite for most bioreactors, and during cleaning-in-place procedures.\n\nTo counterbalance the lack of in situ sensors, great effort has to be put into purification and final quality control. Spectrophotometric techniques in the infrared (near and medium), UV-visible (especially for wastewater treatment) and fluorescence combined with data mining techniques are promising (Lopes et al., 2004; Pons et al., 2004) . Biomass characterisation is a key issue.\n\nIt is not just to determine its concentration, but also its morphological and physiological state. In situ devices such as in-situ microscope, radio frequency impedance-meters and focused-beam reflectance meters have been successfully tested for some species, but the large variety of micro-organisms make the generalisation difficult.\n\nIn spite of the high non-linearities noted above, linear control theory and basic controllers (on/off PI(D)s etc.) are still applied on most industrial bioprocesses. More sophisticated control should rely on models able to represent correctly the behaviour of biosystems. It has been a constant matter of discussion between academia and industry.\n\nThe complexity of the biological systems is such that simplistic models, which are nice to manipulate and help to simplify the underlying mathematics, cannot reflect the real situations. Therefore industry remains sceptical about their use.\n\nOn the other hand, complex models will contain large sets of parameters that should be identified. That means that the models should be not only theoretically identifiable but also experimentally, i.e. that experiments should be carefully designed to provide valuable information. High throughput experimentation under well controlled conditions allows for rapid screening of various operational conditions, but is not yet largely used in bioengineering.\n\nDue to our lack of knowledge regarding the intrinsic phenomena taking place in living cells, uncertainty will be part of the picture for some time. The handling of uncertainty in the models is still hardly tackled (Ar\u00e1uzo-Bravo et al., 2004) . As a matter of fact, industry generally thinks that academia requires too much time to build models, when their time-tomarket for new products should be as short as possible in a highly competitive framework. The real advantage and benefit of a better process control should be more stressed in order to induce industry to use it.\n\nIndustry is not the only party that should be convinced that improvement in product quality can come from better control. The regulation authorities, such as the FDA in the US, also need to be convinced. Once the way to produce a new molecule has been defined, it is very difficult to change the recipe. As mentioned before, when the time-tomarket has to be as short as possible, robust and basic control is first applied, even if it is sub-optimal. The FDA and industry must be convinced of the use of models because they will in the end facilitate and improve the production pathways.\n\nSince living organisms are implied, reproducibility of cell cultivations and reduction of variability from run to run deserve special consideration. In that field many successful industrial stories about the use of data mining techniques, such as Principal Components Analysis, Self-Organising Maps, Projections on Latent Structures, Artificial Neural Networks, have been reported. The large historical databases stored in industry for traceability purposes can be organised to detect rapidly off-specification batches or defective sensors or actuators.\n\nIn recent years industry has focussed largely on media optimisation, especially in cell cultures. There was indeed an interest in decreasing the variability induced by the use of natural substances, but the effect of Bovine Spongiform Encephalopathy (BSE) has certainly played a role in such an effort towards fully defined media.\n\nThe true challenge of bioengineering lies in the understanding of how biological systems really work. Until recent years the focus has been on molecules such as nucleotide acids, proteins, etc. as the tools for investigation at a molecular level were just becoming available. It is necessary now to understand how the different elements interact between themselves in metabolic networks and cell-signaling pathways (Kitano, 2002a; .\n\nThe structure, the dynamics, and the control methods have to be studied. Identifiability (Zak et al., 2003) and robustness issues arise. High throughput data methods yield insights into the functions of cells, but limitations still exist in the information content they deliver. As the flux of information is increasing, new bioinformatics developments are needed for data validation and analysis of heterogenous data, as well as for the representation and exchange of network models (Hucka et al., 2003) . As the control loops exist and do not have to be designed from scratch, the next step will be to modify them to achieve properly designed drugs to cure illnesses (Kitano, 2004) and increase cell productivity (Kauffman et al., 2002) by proper disturbances.\n\n4. FORECASTS\n\nIn agriculture and horticulture it can be expected that the trend towards more technical options for acquiring information through dedicated (bio)sensors and vision techniques, together with increased intelligence in machinery and control equipment will materialise in a number of new products in the market.\n\nFor instance, in greenhouse cultivation, the manufacturers of greenhouse climate control computers are already building in more advanced control schemes, thus enabling the growers to economise on resources like energy -in the moderate temperature zones of the world -or water -in semi-arid regions. Also, this equipment will become more and more part of enterprise scale management systems, thus enabling the grower to respond to market demands in a more flexible and more profitable way.\n\nIn all agricultural sectors, automation will progress as well, first in regions of the world where labour costs are high, but eventually elsewhere as well.\n\nVarious handling activities, such as crafting, planting, fruit picking, harvesting, will become partly or fully automated. Although truly autonomous vehicles are still somewhat remote, automatic guidance is under reach. Also, advanced intelligent implements, such as weeders, will find their way, especially driven by the needs of organic farming first, and then gradually into conventional agriculture as well. Standardised bus systems will also help to promote more intelligent machinery.\n\nIn the longer run, sensors and sensor networks with cheap communication will enable the operation on the scale of individual plants or animals, and this will support the demand for better quality control -based on scientifically sound quality models still to be developed. Farmers and growers will become active players in the production chain, where tracing and tracking in combination with extensive information flows over the complete chain or web in conjunction with the internet will form a new environment in which controllers and control strategies developed by the control community have to operate.\n\nWithin the biomedical area, a number of areas are likely to experience rapid growth in the forthcoming years. It is expected, in particular, that bioinformatics, which covers a wide spectrum of scientific and applied research, will receive much attention. Areas affected will include healthcare delivery and its management, molecular and cell biology, molecular imaging, and drug development, to name just a few. Healthcare activities are characterised by intensive information exchanges and complex interaction among a large number of healthcare professionals.\n\nRapid increases in health information have raised the question of how information can be stored and exchanged efficiently across hospitals, wards and referring physicians over the internet. It is very important that this question should be answered 'correctly', because an 'incorrect' answer may lead to an inefficient storage/dissemination of health information and impact adversely on hospital resource allocation.\n\nRapid developments in communication technologies will also result in an expansion of what is termed home telecare, which greatly facilitates, for example, remote monitoring and management of patients, both as to their health status and the status of their home environment. This is particularly beneficial to elderly people and patients with long-term diseases such as diabetes and asthma.\n\nIn conjunction with rapid advances in biomedical instrumentation and related technologies, the elucidation of DNA structure in 1958 and completion of the sequencing of the human genome projects in 2003 have accelerated development of basic molecular and new biological assay techniques that can further our basic understanding of human disease, including cancer. In molecular and cell biology, much of the current research focuses on elucidating the functions of specific genes or gene products and understanding of the interactions between different gene products in specific pathways. This research is set to develop further.\n\nThese advances have also paved the way for the development of transgenic animal models of human disease, where the molecular basis of disease concerned can be studied in a living organism by exploring the patterns of gene expression that encode for the underlying biological (and pathological) processes and many other functions that cells perform.\n\nFurther advances are likely in relation to in vivo molecular imaging technologies such as positron emission tomography (PET). Different imaging probes (i.e. radiolabelled substrates and targeted contrast agents) are being developed to examine the integrative functions of molecules, cells, tissues, and whole organisms, and to validate the in vitro measurements in a repetitive and non-invasive manner.\n\nWith the use of animal models of disease and molecular imaging, it will become possible to perform certain kinds of studies that are rarely performed in humans because of practical or ethical issues. In conjunction with biopsy and tissue assays techniques, molecular imaging provides additional information that can be extracted from modelling the kinetic fate of the imaging probes within tissues.\n\nWith knowledge gained from kinetic modelling of the imaging probes and the tissue analysis, new imaging probes will be designed to study certain molecular pathways of interest that become altered in disease. The recent combined PET and computer tomography (CT) provides a new opportunity to better match the quantitative biomedical process to its anatomic structure in living human body and facilitates the monitoring of therapeutic response and progress of the treatment. Development of fast and reliable parameter estimation algorithms is extremely important for this task and much research effort is likely in addressing this issue.\n\nIntegrated Water Resources Management will expand from the first experimental case studies developed by universities and research institutes, with the first steps being taken towards systematic application in real world situations. In fact the new Water Frame Directive of the European Union requires the adoption of a River Basin Management Plan within the time frame up to 2009 for all the basins in the Union. This will afford great opportunities of work for consultants and engineering companies, together with new research challenges. Moreover the IWRM scheme will not only be adopted in the EU, but will also be distributed all over the world, due to the intensive dissemination action that the EU is planning. This will be facilitated by the emerging trend to create a large modelling support system on the web.\n\nIn the Water Quality Control Field it can be expected that the trend towards the adoption of automatic control of the whole treatment process will continue, resulting in the emergence of a number of new products in the market.\n\nThe availability of cheap computing power, especially through parallel computing facilities, will enable the diffusion of real time distributed controllers for the management of complex water reservoir networks. The automatic control of water reservoirs and regulated lakes will eventually move towards becoming standard practice.\n\nA better understanding of the control structure within organisms is expected to help to design new drugs that are needed to fight illnesses such as cancers or pathogens-related diseases, for which multi-drug resistance is raising alarms. The availability of increasing computing power will help to simulate the intricate expression networks.\n\nSuccessful process analytical technologies (PATs), which combine techniques for in-process monitoring, data-based modeling and process control, will drive the control quality in drugs production, to improve their safety and the efficiency.\n\nAt the fringe between bioengineering and environmental engineering, the development of PATs devoted to wastewater treatment will help to ensure a safe and sufficient production of drinking water, as the decreasing availability of fresh water around the world may be the cause of serious conflicts in the future."}