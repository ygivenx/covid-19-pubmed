{"title": "Diagnostic tools for tackling febrile illness and enhancing patient management", "body": "People in Low-and Middle-Income Countries (LMICs), primarily in sub-Saharan Africa, South-east Asia, and Latin America, suffer dramatically from infectious diseases, some of which are endemic, while others occur in the form of epidemics. A combination of factors leads to the perpetuation of this situation, including the tropical climate, the simultaneous presentation of multiple diseases, innate or acquired host factors (micronutrient deficiency, immunodeficiency, co-morbidities), lack of resources (low income) to procure medicines and vaccines or other preventive tools, lack/misuse (due to lack of training or information) of (suitable) diagnostic tools, increase of pathogen resistance to antimicrobial medicines, as well as social and community factors. As a result, in 2010, 64% of deaths worldwide were still due to infectious diseases; pneumonia, malaria, and sepsis were the leading causes of death, particularly in Africa [1] . Moreover, while the borders between tropical diseases -thought to be confined around the equator (such as Ebola) -and infectious diseases classically related to Northern countries (such as influenza) were discrete, climate change and the increase in population migration contributed to a blurring of these borders, thus making the spread of febrile illnesses a global reality and concern.\n\nMany people with acute infectious diseases develop fever, which is a frequent complaint, observed in approximately 80% of pediatric and adult patients presenting with an acute medical condition to health facilities. The estimated incidence of febrile episodes in malaria endemic countries varies according to studies but is generally between 2 and 7 episodes per person per year in children < 5 years [2] . Despite the fact that all these infectious diseases cause fever, they can result from very different types of pathogens -parasites, viruses, bacteriaeach of which requires a different type of treatment and management. Malaria, which was a major cause of fever a few decades ago, has now https://doi.org/10.1016/j.mee.2018. 10 .001\n\nGiven the still high (and often increasing) numbers of febrile (and related) illness cases and accompanied mortality globally, the (re-) emergence of global threats (e.g. Ebola in 2014) and the increasing resistance to antimicrobial medicines, there have been several conventions at the international level with the aim to define a roadmap to tackle these challenges. The most significant conclusions and decisions deriving from summit meetings are summarized below.\n\nThe World Health Organization (WHO) has changed its policy regarding the case management of malaria, to shift from presumptive treatment to laboratory-based confirmation of malaria before treatment [8] . Thus, wide access to malaria diagnosis is advocated to protect available antimalarial medicines against the development of resistance.\n\nAccording to the WHO 2014 Global Report on surveillance and antimicrobial resistance, the emergence of drug resistance due to misuse of antimicrobials is one of the major current public health threats worldwide. New tools that could mitigate this threat are urgently required [9] .\n\nIn a summary of the lessons learned from the 2014 Ebola epidemic, Bill Gates mentioned that: \"We need to invest in better disease-surveillance and laboratory-testing capacity, for normal situations and for epidemics. Routine surveillance systems should\u2026detect early signs of an outbreak beyond their sentinel sites and be quickly scaled up during epidemics. They should be linked with national public health laboratories to enable robust monitoring and response.\" [10] .\n\nIn an Ebola-focusing summit that was convened by the Paul Allen Foundation in April 2015, one of the conclusions stated that \"The greatest unmet need\u2026is a field-test for use in community or village settings\u2026 to help determine whether isolation and/or referral is indicated.\" [11] .\n\nDuring an expert meeting at WHO in June 2015 focusing on interoperability standards, it was concluded that there is a clear need for interface systems between diagnostic tools and e-Health technologies, aiming at both patient management and epidemics control [12] .\n\nThese conclusions and directives coming from multiple sites strongly demonstrate the need and the motivation that exists to support the development of new, innovative diagnostic tools that can efficiently resolve the aforementioned challenges related to febrile illnesses.\n\nThe first step to improve the management of patients with febrile illness is to estimate the distribution of the various syndromes and pathogens that cause fever. Even though the distribution of fevercausing diseases varies by geography, season, age and immunity of patients and the level of care, some findings were similar among studies [2] . These were related to cosmopolitan diseases found in most places worldwide, such as pneumonia or urinary tract infection. For other diseases, with various levels of endemicity, such as typhoid or rickettsiosis, or that occur rather in an epidemic way, such as arbovirus infections, the prevalence varied significantly according to the geographic location and, even more, according to the season or the calendar year. In studies that have recorded the clinical presentation of patients (and not only their laboratory results), the causes of fever in outpatients could be classified into four main syndromes: 1) acute respiratory infections (ARI, of any type); 2) diarrhea (gastroenteritis); 3) fever with another clear focus (e.g. meningitis or skin infection); and 4) non-specific fevers [13] (each diagnostic platform described in Section 5 focuses on at least one of the aforementioned cases). Even though important diagnostic challenges remain regarding the first three syndromes, clear clinical guidelines have been developed by WHO, such as the Integrated Management of Childhood Illness -IMCI [14] , to help clinicians to assess their patients and to decide on their treatment. Because they correspond to localized infections, these syndromes are generally diagnosed using the best available clinical predictors, while diagnostic tools are indeed not included. In contrast, regarding the 4th syndrome (non-specific fevers), very few guidelines are available.\n\nThe main challenge faced by clinicians is the management of patients with fever without specific symptoms or signs to guide them to the source of infection, combined, in endemic areas, with a negative malaria test result (the \"negative syndrome\" as labeled by health workers in Tanzania). These non-specific fevers, also called \"fever without focus\", are caused by a wide range of pathogens ( Fig. 1 and Table 1 ) that cannot be identified without accurate laboratory tests.\n\nRecent studies that aimed at determining the etiologies of fever [13, [15] [16] [17] [18] have identified the following important diseases as causes of non-specific fever:\n\n(i) Malaria continues to be a major global health problem. According to the 2016 World Malaria Report, 91 countries were still malaria endemic [19] . There were an estimated 212 million cases of malaria worldwide in 2016 and an estimated 429,000 deaths, while 90% of all malaria deaths occurred in Africa. Malaria prevalence varies widely, from 0 to 32% of all fevers. Indeed, the decrease in malaria transmission in many places in Africa [20, 21] has led to significant heterogeneity in transmission. The prevalence of malaria among patients with febrile illness has, therefore, become unpredictable and has triggered the switch of the WHO malaria case management policy from presumptive treatment, to treatment based on laboratory confirmation [8] . (ii) Urinary tract infection was an important cause of fever in young children (generally younger than two years old) that cannot be suspected on the basis of a history of urinary symptoms at that age (and therefore, it is included in the category of non-specific fevers). The prevalence among all children under five with febrile illness was 1-6%. (iii) Enteric fever was a significant cause of fever in children older than two years old and in adults, accounting for 2-10% of all fevers, with Salmonella typhi being the most frequent pathogen identified, followed by Salmonella non-typhi. (iv) Other bloodstream infections, mainly due to Streptococcus pneumoniae and Escherichia coli, accounted for about 2% of all fevers. Other systemic bacterial diseases, such as leptospirosis (0.2-13%), rickettsiosis (1-25%), Q fever (1-8%), and brucellosis (5%) were also important causes of fever, especially in adults who were more exposed to zoonoses and other environmental-related diseases than children. (v) Dengue was also an important cause and seemed to emerge in several African countries. Its prevalence is extremely variable, not so much geographically but temporally (seasonal and year to year variation). (vi) Cosmopolitan viruses, such as Human herpesvirus 6, parvovirus B19, Epstein-Barr virus, and Cytomegalovirus, which are transmitted mainly through close contact within family members, were mostly prevalent in children, accounting for 9% of all fevers and 22% of non-specific fevers in children [13] , while adults were more susceptible to vector-borne diseases such as chikungunya or West Nile virus. Acute HIV was found in a few patients. (vii) Co-infection with two or even more pathogens was frequent (in one study, 23% of pediatric patients had more than one disease simultaneously, Fig. 2 ), especially when an outbreak overlapped with an endemic situation, as it happened in a fever study in Tanzania in 2013. Suddenly, in January 2014, a significant outbreak of dengue started, and at the peak of the epidemic, almost 80% of patients presenting with fever were infected with dengue virus of serotype 2 [6] . Because of the absence of diagnostic tools outside the study sites, most of these patients were considered as malaria cases and treated with antimalarial medicines or, in case that malaria tests where available, they were considered as possibly infected by bacteria and treated with antibiotics. (viii) Regarding HIV, chronic HIV is an important co-morbidity, especially for adults (40% were positive in two Tanzanian studies, while HIV prevalence in the corresponding community was 5 to 10%), and should, thus, be systematically screened for, which is unfortunately not the case presently in Africa.\n\nWhatever the etiology, the first step in assessing febrile patients is to triage them as having a severe rather than a mild illness [22] . Objective point-of-care (POC) biosensors (such as oximeters), in addition to the subjective assessment of clinical danger signs (such as lethargy or severe dehydration), are helpful to correctly triage patients and should be integrated in the evaluation process [23] . When patients present with a mild disease, ambulatory management with appropriate home-based treatment is sufficient [24, 25] . The main challenge is then to identify the few patients who will benefit from antimicrobial treatment among all those with self-limited infection. Presumptive treatment with antimicrobials should be avoided as most of these infections are of viral origin (Fig. 2) , especially in children (except for malaria that can be ruled out by a rapid diagnostic test). Follow-up of patients to detect persistent or new symptoms and signs will then allow for the detection of rare clinical failures. At the primary care level, the decision to administer an antimicrobial should be based on an initial classification of the condition in the four categories mentioned in Section 2.2, combined with an accurate test specific for each syndrome that can distinguish between bacterial and viral etiology. As the existing host biomarkers lack accuracy (for example, C-reactive protein to identify the few bacterial pneumonia cases among the many viral respiratory infections), they should be combined with clinical predictors (e.g. fast breathing [26] ) to improve the overall specificity [23] .\n\nPatients with a rather severe febrile illness (most of them satisfy the criteria for sepsis) should be admitted and assessed for the different etiologies of fever, irrespective of the syndrome they present with. In sepsis, the symptoms and signs are indeed often unspecific to allow for initial classification into the four syndromes mentioned in Section 2.2 and all possibilities should be considered [15] . Under these conditions, accurate laboratory diagnosis is important, and the infections listed in Section 2.2 (taking into account specific exposures mentioned by the patients and the local epidemiology) should be tested for, whenever possible. The results of the laboratory tests should then still be interpreted in the clinical context, i.e. the pre-test probability of the disease and the likelihood ratios of clinical predictors. Indeed, for laboratory tests that have imperfect accuracy, these elements should be considered to calculate the post-test probability and be able to safely include or exclude certain diseases [27] . If this probability is above the \"treatment threshold\" (above which one treats the patients instead of continuing investigating them using tests), the appropriate antimicrobial should be administered [28] . If the probability is below the diagnostic threshold, no specific treatment is required, besides adjunctive treatment (e.g. i.e. acute respiratory infections, gastroenteritis, skin infections, meningitis and naso-pharyngeal infections (infections due to enterovirus, adenovirus or influenza, however presenting without any respiratory symptom). Source: figure provided by V. D'Acremont, adapted from [13] .\n\nClassification of fever-causing pathogens in Africa (parasitic, bacterial, viral, fungal systemic infections). \"NA\": Not Applicable; \"?\": unknown; \"NAATs\": Nucleic Acid Amplification Technologies; \"LFT\": Lateral Flow Test. Diseases not included because generally considered after more than one week of fever: Sinusitis, visceral leishmaniasis, amoebic liver abscess.\n\nDiseases not included because, although they are fairly prevalent, they rarely present with fever: Pertussis, Cryptosporidium.\n\nDiseases not included because clinical diagnosis is generally sensitive enough and specific enough: Measles. a Medium sensitivity in HIV patients with low CD4 cell count (urinary test).\n\nK. Mitsakakis et al. Microelectronic Engineering 201 (2018) intravenous rehydration in patients with severe diarrhea) and treatment for chronic conditions. If the probability falls between these two thresholds, further testing (when available) may be required and a second-line test should then be used. In practice, antimicrobials are often administered presumptively while waiting for the test results (except for malaria that can be excluded in < 15 min based on the results of a rapid test). In summary, evidence-based integrated management of fever is a complex process, both at hospital and primary care levels, that would clearly benefit from electronic clinical decision algorithms (eCDA) based on mobile technology [23, 29, 30] to guide clinicians through the necessary steps, reach an accurate evaluation of the disease probability, and decide on the most appropriate treatment and management. Electronic clinical decision algorithms are e-Health tools pertaining to the broader category of \"computerized decision support systems\" (CDSS). Contrary to differential diagnosis generators (DDx) that provide a long list of possible diagnoses and have shown poor accuracy [31] , eCDA provide structured decision pathways that align with the clinician's workflow and guide the clinician throughout the consultation, including on final treatments and advice (Section 6).\n\nThe diagnostic tools target in-and outpatients that visit urban and rural hospitals, peripheral health facilities and laboratories, and community level health posts. In particular, the following broad categories of target groups are identified:\n\n(i) Patients living in resource-limited countries are clearly in need of new diagnostic tests for infectious diseases. These patients are very diverse in their immune status, the chronic conditions they may suffer from, and their ability and willingness to pay for a diagnostic test. (ii) People traveling from endemic to non-endemic areas. Although it is difficult to determine the number of returning travelers and migrants to Northern countries that are infected with an endemic disease, because of variation in reporting methods for different pathogens, an estimated 20,000-30,000 cases of travelers with malaria are, for example, reported in Europe each year [32] . The number of people crossing borders between the Southern countries is much higher and represents also an important target group. They can be tested at airports, harbors, cross-border controls, immigration control checkpoints, where reliability and short time-to-result tests are required. (iii) Pre-and post-vaccination, elimination, and screening programs run by local governments, international organizations, and pharmaceutical industries. Disease prevention and elimination programs should be supported by comprehensive evidence to demonstrate the underlying prevalence of the pathogen in question and the efficacy of the strategy proposed. Using a multiplexingcapable diagnostic platform allows for effective modeling of the: (a) true prevalence and variation of multiple species, enabling the monitoring of impact of the intervention on disease dynamics; (b) local and regional differences in pathogen distribution. (iv) Epidemics surveillance, particularly of interest in: (a) sentinel sites, where the diagnostic tools can be installed at strategic geographic locations, in order to cover several regional, cultural, environmental, and epidemiological settings; (b) Ministries of Health and regional alarm centers that should regularly receive reports from the sentinel sites for assessment of the frequency of patients and the diversity of diseases.\n\nThe diagnostic systems should operate independently of patients' age, although there are some inherent difficulties to acquire proper quality sample matrix from an infant (e.g. sputum for alleged respiratory infection). Furthermore, for some tests, such as blood culture or Polymerase Chain Reaction (PCR) for bloodstream bacterial infections, the same diagnostic tool may have different performance in different age groups, due to different pathogen load [33] . Not all diagnostic tools are, thus, suitable for all cases. In addition, the training level of the users, the facilities available at each level of care, and the target patient population are parameters that developers of novel diagnostic tools must take into consideration.\n\nThere is an extensive debate regarding whether diagnostic tests with short time-to-result, but applicable only in laboratories, are true POC technologies or if the term \"POC\" should be used for tests that can be performed \"under the tree\". Considering that diagnosis should be closely associated with treatment and that, at the peripheral level, there is often shortage of health staff and medicines, the \"point-of-care\" becomes by default the \"point\" where \"proper care\" can be provided, and this may well be a clinic, a peripheral lab, or a hospital, depending on how well-equipped these settings are, especially in terms of human resources [34] .\n\nThe diversity of available diagnostic systems, but more importantly of target groups and local requirements, has posed the need to define generic requirements. To this scope, the \"ASSURED\" criteria were developed [35] to summarize the characteristics of the ideal diagnostic test for the developing world, which should be Affordable by the target groups; Sensitive and Specific; User-friendly by limited trained personnel; Rapid and Robust; Equipment-free; and Delivered to those in need. These criteria were initially developed for sexually transmitted infections but are generic for developing countries-targeted diagnostics. However, it has been evident that the users' requirements call for elaboration (or \"fine-tuning\") of these criteria. For example, the \"equipment-free\" criterion may be risky, because saving the test results in the device decreases the risk of mis-interpretation by inexperienced personnel. Therefore, there is an increasing trend to use mobile technology to read results provided by Lateral Flow Tests (LFTs). Moreover, there is need for guidance on how to select patients who should be tested, interpret test results in the clinical context, and triage patients who should be referred and admitted due to severe illness. In case of epidemics, where several patients arrive simultaneously at the checkpoint, the capacity of the tool to process several samples at the same time is an advantage. The ASSURED criteria, together with additional specific requirements, are summarized in Target Product Profiles (TPPs), which technology developers should meet during their development stages. Examples of TPPs exist for tuberculosis, Ebola, and differentiation between viral and bacterial infections, and are driven by the WHO, the M\u00e9decins Sans Fronti\u00e8res (MSF), the Foundation for Innovative New Diagnostics (FIND), and other organizations [36, 37] . \n\nMicroscopy for screening of malaria parasites by examining a drop of blood smeared on a slide after proper staining remains a widely used diagnostic tool. Giemsa-stained thick and thin blood films are used to detect the presence of Plasmodium parasites, to quantify the parasite density, and to identify the species [38] .\n\nConsidering the progress in light technology and the use of Light Emitting Diodes (LEDs), microscopy has become more easy to use. However, it still requires well-trained personnel and a degree of experience to prepare the samples and to interpret the results. Poor slide/ blood film preparation may lead to artifacts which are mistaken for parasites, while in reality they are bacteria, fungi, dirt, or cell debris. As a consequence, poor specificity leads to poor diagnostic quality [39] . Two studies in Tanzania have shown that the low quality of malaria microscopy and the lack of trust by clinicians in microscopy outcomes resulted in higher mortality among patients with non-malaria febrile illnesses than patients with malaria [40, 41] .\n\nAn additional major disadvantage of this method is the fact that microscopy cannot identify sources of fever other than malaria (except for borreliosis, which is a relatively rare cause of acute fever). Thus, in the case of malaria-negative diagnosis, or in the case of co-infection of malaria with some viral/bacterial agent, the microscopy-only diagnosis is not sufficient for clinicians to decide on the suitable treatment.\n\nFor bloodstream bacterial infections, including typhoid fever, the main test used in equipped laboratories is conventional bacterial culture. For pneumonia, culture is also based on respiratory secretions, including sputum (but it is then impossible to distinguish between chronic carriage and infection), bronchoalveolar lavage, or pleural fluid. Detection of pneumococcal bacteremia can orient the diagnosis; however, this test results in low yields, due to the relative fragility of these bacteria. Indeed, the main general drawback of blood culture is the inability, except for a few cases, to diagnose localized infections such as pneumonia or urinary tract infection. For typhoid, in addition to blood culture, stool culture and/or bone marrow culture are used but are rarely available. Other limitations are that cultures take several days to provide results and that collection of high quality samples from pediatric patients is rather difficult and often leads to false results [42, 43] . In adults, sensitivity of blood culture is limited by the low bacterial load. Specificity of blood culture is also hampered by contamination by cutaneous bacteria during blood withdrawal, because sample acquisition from two different sites to overcome this problem is rather challenging in practice, especially in children.\n\nLateral Flow Tests [44] consist of a plastic device containing a composite assay strip flanked by a reagent/sample pad at one end and an absorption pad at the other. The strip contains two or more lines striped into the nitrocellulose membrane: one or more test line(s) consist of a disease-specific antigen or antibody and one line is used as a control. Thus, both antigen-or antibody-specific tests can be performed. The reagent pad holds the dried conjugate consisting of colloidal goldlabeled antibodies or antigens specific for each test. The reaction is performed by adding the sample (typically finger-prick whole blood, or urine) to the sample pad, followed by the addition of a few drops of buffer. The sample is mixed with the conjugate, forming antibody-gold complexes that flow through the nitrocellulose membrane. When specific antibodies/antigens are present in the sample, they bind the respective conjugate at the test zone, indicating a positive result through the captured red-colored gold nanoparticles carrying the antibody/antigen of interest (Fig. 3) .\n\nMultiplexing is possible with the LFTs in two ways: either via multiple analytes on the same strip (one sample inlet for all), or via several strips on the same cassette (as many inlets as the number of strips). The former option is more challenging and less generic because it depends on the assays and the (compatibility of) reagents with all target proteins to be detected.\n\nThe results are read visually after 10-20 min, depending on the test. A valid test result is obtained if staining of the control line is observed. The equipment-free readout, however, is not sufficiently subjective, while it becomes even more complicated when (semi)quantitative readout is desired, e.g. to assess the intensity of the strip line. In addition to the mis-interpretation and ambiguity of the test results, there is also the risk of data loss, which is not the case when a readout equipment (with data storage and transmission capacity) is used. Especially in the case of multi-strip cassettes, the use of a readout unit may help to diminish the risk of confusion between results from different lines. Thus, a current trend in LFT diagnostics is towards an automated readout, such as the Deki-reader that has been well validated in the field for malaria testing [46] . Several technologies have been developed based on colorimetric (e.g. colloidal gold or colored latex) or fluorescence detection, by commercial suppliers: ESEQuant\u2122 LFT strip reader by Qiagen Lake Constance (Germany); an imaging system by Axxin Inc. (Australia); the handheld image capture LFT reader by Detekt Biomedical, LCC (USA); the cPOC\u2122 reader from LRE Medical (Germany); the handheld DCN Fluorescent Test Visualizer (USA) [47] .\n\nAlthough these systems are well suited for developed countries, they are often not affordable for LMICs. A more promising approach is the use of smartphones, which has several advantages over other systems to: (i) become increasingly accessible in Africa; (ii) be used as an image processing device with the built-in camera and suitable software; (iii) be able to support an application (APP) for processing the acquired data; and (iv) enable Global Positioning System (GPS) tracking of patients during an epidemic (following the appropriate ethics rules and after related permissions). Furthermore, data storage and transmission to external databases offers a high added value to LFTs. The camera can also typically scan 1-or 2-D barcodes on the LFT cassette in order to identify the type of test. To this direction, the non-profit global health organization \"Global Solutions for Infectious Diseases (GSID)\" [48] is developing a mobile tool to read, digitize, and transmit POC diagnostic results for important infectious diseases. In cooperation with the University of Washington (Seattle, USA) and Dimagi (Boston, USA), GSID developed an open-source software to capture the results of many different POC tests and report them immediately via wireless technology. A proof-of-concept study was conducted in Zimbabwe in 2014 [49] . Other examples of this approach are the mReader of mobile assay (USA), the AssayQuest\u2122 from Clearbridge BioLoc (Singapore), and the SkanSmart and SkanEasy products from Skannex (Norway). Extensive work on this field has been performed regarding software development, for example by Novarum DX\u2122 (UK), or the CommCare mobile platform by Dimagi (USA). Due to the relatively low complexity in manufacturing LFTs, there are > 100 manufacturers worldwide for clinical applications (which is why we are not able to provide a list of these manufacturers). The average price of an LFT is approximately US$1. Several studies assessed the performance of LFTs [50] [51] [52] [53] and in a non-exhaustive list of infections, LFTs currently exist for malaria, dengue, typhoid, HIV, hepatitis B virus (HBV), hepatitis C virus (HCV), and recently Ebola and Lassa [47] .\n\nHowever, the average quality of these tests is inversely proportional to the multitude of suppliers. It is often the case that their accuracy is inadequate [54] . The main drawback of LFTs that detect antibodies is that, at the acute phase, antibodies are often not yet present and the tests lack sensitivity. Also, the dynamics of IgM/IgG can be complex and hard to interpret, especially when re-infection is possible (e.g. dengue). Another problem is that antibodies -even IgM -persist for several weeks after acute infection, which decreases the specificity of the test (e.g. chikungunya). For this reason, the WHO has a standard operating procedure for pre-qualification, and publishes and regularly reviews recommendations for LFTs for particular diseases, especially malaria and HIV [54, 55] .\n\nNucleic acid amplification technologies (NAATs) are based on sequence-specific recognition and amplification of unique target regions in the genome of pathogens to be detected. Thus, NAATs are highly specific and sensitive, as single microorganisms can be detected. Compared to microscopy (the reference in malaria diagnosis), NAATs are much more sensitive, while in contrast to culture methods (the reference in bacterial disease diagnosis), NAAT process times can be reduced from days to hours. The following sections present the most frequently used NAATs.\n\nPolymerase chain reaction (PCR) represents the most commonly used NAAT-based diagnostic technology [56] . In this reaction, a thermostable polymerase (Taq, from Thermus aquaticus) is employed. Two primers are used that flank the target region of the template DNA to be amplified. A three-step process is then repeated~30-45 times: (i) a denaturation step at~95\u00b0C, where the double-stranded DNA (dsDNA) template is denatured resulting in two single-stranded DNA (ssDNA) molecules; (ii) a primer annealing step at~68\u00b0C, where the primers are hybridized to the ssDNA target region to be amplified; and (iii) an elongation step at~72\u00b0C, where the polymerase generates a copy (amplicon) of the target region starting from the primer in 3\u2032-to 5\u2032-end direction. In an ideal reaction, the targeted region of the template DNA is doubled after each cycle. The (endpoint) amplicons are detected via gel-electrophoresis (non-specific method) or by using different kinds of specific molecular probes that generate an amplicon-specific signal. Here, the signal also depends on the template concentration.\n\nThe need for cyclic heating and cooling to perform the previously described steps for PCR renders this method relatively time-consuming (several hours depending on the configuration and the thermocycler) and energy-consuming (a power supply is required). Recently advanced methods in DNA amplification use isothermal NAATs (iNAATs) [57, 58] , which overcome the need for thermal cycling. These methods are less energy consuming than PCR and can be potentially executed in battery or solar panel operated devices, which is an important advantage for their application at the point of care. Furthermore, as a consequence of continuous amplification rather than cycling, the reaction will often generate detectable products faster than PCR. A disadvantage of iNAATs is in general (not referring to specific methods) that quantitation is difficult as they do not follow a strictly controllable reaction scheme. In all methods mentioned above and in the next sections, RNA can also be amplified by the addition of a reverse transcriptase (RT), which transcribes RNA into complementary DNA (cDNA) for further amplification. In the following sections some of the main isothermal amplification technologies are briefly described.\n\nNucleic acid sequence based amplification (NASBA) [59] is used to detect RNA and is performed at 41\u00b0C. Due to the fact that it targets RNA, NASBA was first used for the rapid diagnosis and quantification of HIV-1 [60] . NASBA reaction is facilitated by three enzymes (avian myeloblastosis virus reverse transcriptase, RNase H, and T7 RNA polymerase) leading to the amplification product. In brief, during the amplification process, cDNA is initially produced from RNA templates through primer (primer 1) annealing to the template RNA and reverse transcription forming a cDNA from the latter. During cDNA production, RNase H hydrolyzes the RNA template. The resulting cDNA with the promoter sequence is annealed to a second primer (primer 2) and double-stranded DNA (dsDNA) is produced with reverse transcription. Following this step, T7 RNA polymerase transcribes an RNA molecule from the previously generated dsDNA. The above procedure is cyclic and in each round the number of produced RNA is increased. A unique advantage of this method is that it can selectively amplify RNA in the presence of high DNA background, while the process can also start with a DNA template. In this case, the RNase H step in the non-cyclic phase is not necessary. With NASBA, amplification of a nucleic acid sequence to > 10 9 copies can be accomplished in~90 min.\n\nLoop-mediated isothermal amplification (LAMP) was developed by Eiken Chemical [61] and is based on a bst polymerase with strand displacement activity. Thermal denaturation of dsDNA is not required, as the polymerase itself can denature dsDNA prior to elongation. Due to the reaction temperatures employed (60-65\u00b0C), dsDNA is in a metastable condition and the structure may hybridize/dehybridize spontaneously. This enables primers to bind to the template DNA in melted regions. Six primers are used resulting in high specificity. The forward (F3) and backward (B3) primers, together with the forward inner primer (FIP) and backward inner primer (BIP), generate an artificial starting structure with single-stranded loop regions in each end. Based on this \"dumb-bell\" structure, a cauliflower-like structure is generated with the FIP and BIP primers binding at the loop region. Loop primers (LF, LB) may help to decrease the reaction time [62] . This process results in very fast generation of dsDNA products that can be detected either with intercalating dyes or with specific probes [63] in potentially < 10 min. In short, LAMP is advantageous due to: (i) high specificity, through the use of a minimum of four primers that define six binding sites on the target; (ii) sensitivity equal to, or higher than PCR; (iii) robustness against inhibiting compounds.\n\nRecombinase polymerase amplification (RPA) [64] is typically performed at 37-42\u00b0C. Recombinase/primer filaments scan the template DNA for homologous sequences. If a match is found, recombinase mediates the hybridization of the primer to the complementary sequence. The denatured part of the template DNA is stabilized by singlestrand binding (SSB) proteins and the polymerase can extend the primer complementary to the template sequence. Due to the low reaction temperature, the reaction may start at will, with the addition of Mg 2+ . This may be necessary, especially in applications where ambient temperature is the same as the reaction temperature. A recent international quality assessment of molecular detection of Rift Valley fever virus via RPA performed equally well as the best RT-PCR tests [65] .\n\nHelicase-dependent amplification (HDA) is typically performed at 63\u00b0C. Two primers are used to initiate DNA replication by a polymerase. In a first step, the dsDNA unwinding activity of a helicase is exploited to achieve denaturation [66] . Subsequently, the primers anneal to the single-stranded DNA and then are extended by the DNA polymerase. Each DNA duplex is doubled in one cycle. The produced dsDNA molecules are separated by helicase and the chain reaction is repeated. Similar to RPA, single-strand binding proteins are used to stabilize the denatured ssDNA templates. The simplicity of the method, the uncomplicated cycle reaction, and its high speed (especially for circular HDA (cHDA), speed can reach 100 bp/s) are the major advantages of HDA [67] . HDA has been demonstrated to be efficient with several different types of sample matrices, including urine, stool, blood, and plasma [57] .\n\nFurther promising DNA isothermal amplification techniques, such as strand displacement amplification (SDA) [68] , Nicking Enzyme Amplification Reaction (NEAR) [69] , Strand Invasion Based Amplification (SIBA) [70] , or Rolling Circle Amplification (RCA) [71] are available and advantageous in various applications.\n\nDespite the advantages of NAATs regarding sensitivity, a drawback is the relatively high cost of the reagents, compared to the cost of LFTs. The main cost driver in NAATs is typically the amplification enzyme (the polymerase). Cost further increases when viral RNA should be amplified and a reverse transcriptase should be incorporated in the reaction mix. In the case of some iNAATs, the assay design can be very complicated; for example, primer design in LAMP or the simultaneous use of three enzymes, as required in NASBA. Costs increase further, when enzymes are not pre-stored in liquid, but in dry format (e.g. lyophilized). Such approaches may be required to help enzyme stability at the challenging environmental conditions of tropical regions. However, enzyme activity loss may be observed in lyophilized compared to liquid reagents. Further problems may arise as NAATs inherently measure both living and dead pathogens (as both can provide template DNA). This may lead to false positive diagnosis, for example during monitoring the progress of a patient over a treatment period. From the infrastructure point of view, specialized laboratory facilities are needed. In this case, well-trained personnel must also be employed to achieve proper assay set-up. In case of multiplexed assays, the risk of human error (e.g. pipetting error) increases, even with experienced personnel. To reach satisfying sensitivity, it is generally still necessary to purify nucleic acids from raw sample materials, such as blood, sputum, or urine. Such purification processes may represent > 50% of the manual workload. The labor costs for manual workflows add substantially to the overall costs.\n\nThis section summarizes POC and near-patient platforms for nucleic acid extraction and amplification, representing a big category of emerging and promising technologies that address the end-users' needs expressed in Sections 2.3 and 2.4, and overcome some challenges outlined in Section 4.2 related to lack of automation. In this context, NAATs mentioned in Section 4 should be integrated into automated systems in order to overcome the need for specialized personnel as well as laboratory infrastructure. This includes reagent pre-storage in the system for full hands-off operation. The automated platforms must withstand the challenging environmental conditions (temperature, humidity) of the tropical regions.\n\nThere are dozens of technologies for diagnostics, in various stages of development, used in various settings and detecting various targets. The list is long, and it would be impossible to include all in the present review, which does not aim to provide a list of all existing technologies, but to present those that apply in the context defined in the previous sections. Within this framework, we applied a specific methodology and followed certain (inclusion/exclusion) criteria to select which technologies to present. In particular, we included those that: (i) focus on febrile illness and other syndromic infectious diseases with the potential to be expanded to febrile illness (thus, we excluded technologies for blood chemistry/clinical chemistry analyzers); (ii) include at least nucleic acid amplification testing, which can also be combined with immunoassays (thus, we excluded technologies for CD4 cell counting); (iii) are at least at late stage development, pre-commercial, or commercial stage (thus, we excluded academic, research, or laboratorylevel solutions).\n\nThe description of each platform is divided in two sections: the performance as well as the technology and operating principle behind the platform. The former refers to issues such as portability, modularity, time-to-result, etc. The latter describes the core technical component(s) and main innovative features, e.g. the detection technology, the fluidics handling, and the manufacturing technology. In short: (i) In terms of detection technology, most platforms use optical methods (fluorescence in real-time signal monitoring or imaging mode; or light scattering as in Verigene\u00ae), thus, it appears that progress on the label-free technologies is still required to reach commercial level. Exceptions are the Q-POC\u2122 that uses silicon nanowires for detection and EasyNAT\u2122 that uses an integrated LFT. (ii) Regarding fluidics, it is noteworthy that not all described technologies implement microfluidics but also \"macro\"fluidics. In particular, Enigma\u00ae ML and cobas\u00ae Liat use cartridges that incorporate macrofluidic handling (e.g. syringes, plunges). Fluid handling is mostly pressure-driven, although centrifugal microfluidics are increasingly used (e.g. LabDisk, GenePOC\u2122, Liaison\u00ae MDX). (iii) Manufacturing-wise, the majority of the cartridges are plastic disposables, with some exceptions that are based on CMOS (Complementary Metal-Oxide-Semiconductor) technologies such as the VerePLEX\u2122 chip and the Q-POC\u2122 silicon nanowire array. (iv) In terms of amplification, all platforms allow for both DNA and RNA analysis. Most of them use RT-PCR although isothermal amplification is also increasingly used (e.g. in Alere\u2122 i, EasyNAT\u2122, LabDisk). Notably, the assembly \"assay-cartridge-instrument\" is common in all cases, constituting a platform-based approach.\n\nRegarding performance, some of the platforms aim at single or few pathogens (e.g. GeneXpert\u00ae, Alere\u2122 i, EasyNAT\u2122, cobas\u00ae Liat, Q-POC\u2122, GenePOC\u2122, Liaison\u00ae MDX), while others follow a syndromic approach, offering panels of several pathogens being simultaneously tested (e.g. FilmArray\u00ae, VerePLEX\u2122 Biosystem, Verigene\u00ae, DiagCORE\u00ae, LabDisk). Furthermore, it is important to emphasize that many of the technologies have a sample-to-answer time > 1 h (except Alere\u2122 i, cobas\u00ae Liat, and Q-POC\u2122), while the cost is in the range of tens of US$ for the cartridge and several thousands of US$ for the instrument. Therefore, NAATs seem to be outcompeted by LFTs. However, the added value that multiplex NAAT platforms offer in comparison to the LFTs should be taken into account. Moreover, the cost should be considered in a broad perspective, taking into account \"hidden\" materials and labor costs when comparing with the standards of care.\n\nA comprehensive overview of the technologies and some of their technical features are shown in Table 2 . Performance features (e.g. time-to-result, portability) are mentioned in the platform description but not in the table, as the latter intends to focus mostly on technical aspects. Furthermore, the information provided regarding the performance characteristics is based on the most up-to-date search on publicly available resources. The authors cannot exclude the possibility that these data may be updated in the future by the developers/manufacturers during the progress of the platform, or that manufacturers terminate or delay the development/manufacturing/market entry due to corporate or financial reasons. Furthermore, Table 3 summarizes some \"customer\" related information such as prices of instrument and test, pathogens/syndromes detected, and regulatory status. This information is provided for those platforms that public information is available, and it may vary between the European and US market. \n\nThe GeneXpert\u00ae system ( Fig. 4(a) ) from Cepheid [72] is a widely used system in developing countries implementing molecular diagnostics to identify tuberculosis (TB) [73] [74] [75] . Despite the complexity of its cartridge (assembly of more than five parts), the system was adopted by resource-limited countries due to the endorsement of the Xpert\u00ae MTB/RIF test for TB by the WHO in 2010 and the financial support by the Global Fund for AIDS, malaria, and tuberculosis. The system contains several additional versions to detect drug-resistant TB, HIV, MRSA, Chlamydia trachomatis, Neisseria gonorrhea [76] , while it included Ebola testing during the 2014 outbreak. The time-to-result is estimated to be 60 min. The system of the Xpert\u00ae series is developed in single-cartridge or multi-cartridge configurations for the end-users to decide which option is more suitable to their needs: low/medium throughput (1-, 2-, 4-, 16-cartridge system) for the point-of-care, or high throughput (80-cartridge station) for centralized laboratories. The most portable system of the Xpert\u00ae series aims to truly decentralize TB diagnosis. The GeneXpert\u00ae Omni* ( Fig. 4(b) ) is a single-cartridge version, battery operated and wirelessly connected to the cloud (operable also via smartphone), which allows highly decentralized utility and real-time data transmission. The price of a test is US$40-60 in the US market, however there are special arrangements with NGOs that subsidize this test for TB in developing countries, thus eventually costing slightly below US$10 (excluding shipping and distribution; this is the sales price ex works). The GeneXpert\u00ae IV device cost is approximately US$17,000, while the GeneXpert\u00ae Omni* costs less than US$3,000.\n\nThe GeneXpert\u00ae is a sample-to-answer system, where sample preparation and extraction of nucleic acids take place in the cartridge in an automated way as the necessary reagents are pre-stored. Only a few minutes of hands-on steps are required for liquefaction of crude samples such as sputum.\n\nRegarding fluidics, the cartridge contains a total of 11 chambers and reservoirs ( Fig. 5(a) ). At its core, there is a cylindrical rotary valve, which is handled by a plunger rod that moves vertically, as soon as the cartridge is inserted in the processing device. The interface between the valve and the plunger activates the liquids (sample and pre-stored liquid reagents) movement between chambers, by positive or negative pressure through small openings at the base of the reservoirs. An important component of the cartridge is an integrated filter, which is located at the base of the valve body and captures the microorganisms. Subsequently, a sonic horn approaches the filter area and mediates the mechanical lysis of the microorganisms and the release of nucleic acids. The latter are pumped through a chamber where beads with freezedried amplification reagents are stored. These are rehydrated upon sufficient filling of the corresponding chamber (the filling level acts also as internal fluidic quality control). The entire mixture is then directed to the PCR reaction tube, located at the back of the cartridge [79] .\n\nRegarding detection, the PCR tube is surrounded by heating/cooling plates that enable fast thermal response, and by optical blocks that enable amplification and real-time fluorescence-based PCR product detection. In contrast to traditional thermal cycling systems, in which all samples are subjected to the same time/temperature/optical protocol, each sample in a GeneXpert\u00ae system can be subjected to a different protocol. One more innovative feature of the processing module is the intelligent cooling/heating optical reaction (I-CORE) module [80] , a sophisticated, solid-state, miniaturized microelectronic and micro-optical system capable of performing PCR reactions with multichannel fluorescence detection in < 30 min. Each I-CORE includes a four-channel optics system capable of exciting and detecting multiple fluorescent dyes in the same reaction tube, thereby being able to accurately measure four DNA targets simultaneously.\n\nThe Filmarray\u00ae (Fig. 6 ) from bioM\u00e9rieux [83] is a benchtop diagnostic instrument that has three FDA-cleared panels: the Respiratory Panel [84] , the Blood Culture Identification Panel [85] , and the Gastrointestinal Panel [86, 87] . FilmArray\u00ae responded to the 2014 Ebola outbreak and received Emergency Use Authorization (EUA) from the US FDA, based on the FilmArray\u00ae BioThreat Panel that specifically detects Ebola Zaire. A field study was conducted in Sierra Leone in patients and healthcare workers [88] . Only a few minutes hands-on preparation time is required before the cartridge is inserted in the processing device, including the loading of the pouch into the loading block, the insertion of the hydration solution into the pouch, and the loading of the sample. The simplicity of use, the lack of refrigeration storage requirements, and the multiplexing capacity are positive features for use by limited- trained personnel. Up to 27 different targets can be analyzed per test, yet the throughput is still low, as only one patient can be screened per test run [89] . In addition, the manufacturer's list price for the reader (~US$40,000) and reagents (~US$130/cartridge) may not be affordable in resource-limited settings.\n\nThe FilmArray\u00ae is a sample-to-answer system, whose core technology is based on the freeze-dried vacuum reagent pouch, and on the nested multiplexed PCR that allows for the detection of multiple organisms.\n\nThe microfluidic pouch ( Fig. 6(b) ) consists of two areas, namely the fitment, where the reagents are pre-loaded and freeze-dried, and the main body. These two are bonded via heat welding. The fitment is fabricated with injection molding of polypropylene. The main body is fabricated with two sheets of a polyester/polypropylene film that contain a copolymer adhesive layer. These layers are welded together using heated plates. The fitment contains 12 reservoirs (A in Fig. 6(b) ) that contain the biochemical reagents. During the entire manufacturing process, vacuum is maintained in each well through a set of plunges (B). It is very important to maintain the vacuum in the fitment and the blisters because: (i) it helps to maintain the freeze-dried nature of the components and, thus, their long-term storage; (ii) it allows for the injection of the sample and the hydration solutions in the pouch in the correct volume; (iii) it minimizes the formation of bubbles in the microfluidic system.\n\nThe sample matrix is a naso-pharyngeal swab for the respiratory panel (different matrices are used for other panels). A total of 300 \u03bcL liquefied sample (100 \u03bcL sample and 200 \u03bcL lysis buffer) are used for the test. The user injects the hydration buffer (used for rehydrating the freeze-dried pre-stored reagents) and the sample in two differently designated inlets. The vacuum in the pouch automatically draws the correct volume, thus eliminating the need for precise measuring and pipetting by the user.\n\nLiquid handling is applied through pneumatic pressure and \"bladder\" assembly. This contains a bladder plate on which several inflatable bladders are located, each corresponding to one chamber of the pouch. The assembly is subjected to different gas pressures and as it (and the bladders) is externally in contact with the pouch chambers, any change in the volume of the bladders causes liquid to move between the chambers of the pouch. The bladders are pressed through pneumatically-driven pistons (Figs. 2, 3 in [90] ).\n\nThe sample moves to the lysis chamber where the FilmArray\u00ae performs mechanical lysis (bead beating) using ceramic (zirconium silicate) beads. The procedure follows the \"Boom chemistry\" [91] . The released nucleic acids are bound on silica-coated magnetic beads, which are transported from the lysis chamber into the purification chamber, using a magnet integrated in the device. In this chamber, any remaining cellular or viral debris are removed through washing. An elution step releases the nucleic acids from the magnetic beads.\n\nThe 1st stage PCR follows (15-20 cycles, including a reverse transcription step to convert RNA into cDNA), where dozens of primer pairs of all target molecules are mixed for multiplex PCR. A dilution step follows with the addition of a mixture of a fresh mastermix containing an intercalating fluorescent DNA dye. Subsequently, the mixture is aliquoted in a high-density array of 102 microfluidic wells where the 2nd stage (nested) PCR [92] takes place. The 2-step PCR is used to eliminate limitations associated with single-step multiplex PCR. At the end of the 2nd stage PCR, the temperature is slowly increased and the fluorescence in each well is measured to create a melting curve, the shape and position of which can be used for differentiation of amplification products with differences of < 2\u00b0C in melting temperature [93] . For the two stages of PCR, the instrument has two Peltier elements. A blue LED is used to illuminate the array at the 2nd stage PCR and the fluorescence emitted by the dyes is imaged by a CCD camera.\n\nAlere Inc. markets the molecular diagnostics point-of-care system Alere\u2122 i (Fig. 7(a), [94] ) for the detection of Influenza A and B [95] , human respiratory syncytial virus (RSV), as well as Group A Streptococcus (CLIA-waived, different cartridges for virus and bacterium detection). Recent studies have shown that the Alere\u2122 i system exhibited at least equal or superior sensitivity over conventional rapid tests [96, 97] . The rapid isothermal amplification technology implemented by Alere\u2122 i (NEAR, [69] ) enables the sample-to-answer analysis within 15 min. The instrument itself is portable and stand-alone (no need for a laptop), has a user-friendly interface, data storage capacity, and interface ability. The test price, as of 2014, is approximately US$70-85 while the device costs approximately US$8,500.\n\nThe sample matrix is a naso-pharyngeal swab eluted in transport medium. The analysis procedure is from sample to answer with prestored reagents. The single use disposable test cartridge consists of three parts (Fig. 7) . The test base is inserted into the first available device slot. The test base has two reaction tubes, each of which contains a lyophilized pellet with a pair of templates (similar to primers) for the specific amplification of the target nucleic acid, and a fluorescentlylabeled molecular beacon designed to specifically identify the amplified targets. The sample receiver is inserted in the second available device slot. This cartridge contains the elution buffer to elute the pathogens from the swab (10 s stirring of the swab in the cartridge). The transfer cartridge is pressed against the sample receiver to collect the necessary amount of material and then transferred and locked over the test base in order to initiate amplification. The amplified products are detected via dual-channel fluorescence, deriving from the fluorescent probes. Indepth technical design or information regarding the cartridge are not publicly available in detail for this system.\n\nAnother system from the same manufacturer is the Alere\u2122 q HIV-1/2 Detect (Fig. 8, [98] ). It is a fully automated platform for HIV-1 and HIV-2 detection within 50 min based on real-time PCR with multiplexing capability [99, 100] . It is suitable for point-of-care use due to its portable nature, battery operation, no laptop requirement, easy to use touch screen, while the cartridge can be stored at room temperature without need for cold chain. The Alere\u2122 q platform has been launched in multiple developing countries, initially for qualitative HIV, and allows for finger-prick detection of HIV virus in whole blood collected directly into the cartridge (25 \u03bcL are sufficient) that is then inserted into an instrument for automated processing, extraction, amplification, and detection.\n\nTechnology and operating principle of the Alere\u2122 q Alere\u2122 q HIV-1/2 Detect is a sample-to-answer system. Lysis is based on chaotropic salts acting upon the sample and releasing the nucleic acids. Biotinylated oligonucleotides that are specific to HIV-1 and HIV-2 genome hybridize with the post-lysis released viral RNA, and are subsequently bound on streptavidin-sepharose particles. After washing, reverse transcription and PCR follow.\n\nDetection of the PCR product is the core technological innovation of the system. It is based on Competitive Reporter Monitored Amplification (CMA) technology utilizing an array of immobilized oligonucleotide probes and complementary fluorescently labeled reporter oligonucleotides in solution [101] . These reporters compete with the amplicons for hybridization on the surface probes. As in the beginning there are only few amplicons, labeled reporters hybridize with the surface-probes, thus, the initial signal is high. As the PCR reaction progresses, the labeled reporters preferably bind to the amplicons, therefore, less reporters are bound on the microarray. Consequently, the progress of PCR is monitored via the decrease of fluorescence from the microarray spots until a plateau in the amplification reaction is reached. Fluorescence imaging follows the progress of the reaction, as one image is collected during each annealing cycle.\n\nRegarding fluidics (Fig. 8(b) ), the sample is inserted in a capillary (position 1), the inlet being specially designed to receive finger/heel prick. A control window (5) helps the user to assess the filling level. The cap (6) ensures hermetic sealing and minimizes the risk of sample spilling or aerosols exiting the cartridge, thereby avoiding any contamination risk. Dry reagents are pre-stored in internal compartments, along with a buffer reservoir (4) . A fluidic network of valves in the cartridge regulates the liquid/air movement. A septum, which is pricked by a needle connected to the pneumatic module of the cartridge, is used to apply air pressure and move the liquids into the different compartments. The compartment (3) is the reaction chamber where PCR takes place and the microarray is located.\n\nThe Enigma\u00ae ML (MiniLab\u2122) (Fig. 9) is a point-of-care platform commercialized by Enigma\u00ae Diagnostics, which, since mid-2017, is in the process of selling their intellectual property underlying its point-of-care molecular diagnostics platform [104] (nevertheless the platform is described here as one of the most representative ones). Although the main application of the system has been on respiratory tract infections [105] , its functional and performance characteristics would enable potential use in febrile illness diagnosis. Indicatively, the pipeline of infectious diseases includes influenza A and B, as well as RSV. The Enigma\u00ae ML requires no laptop due to its internal controller and user-friendly touch screen. The instrument is available in a modular configuration, i.e. in a single-module up to a six-module option (for one to six cartridges, respectively). Each module can operate independently via the central controller, therefore, different assays (requiring different protocols) from the same or different specimens can be performed at the same time. The overall analysis time for each module is 95 min. The analytical and diagnostic verification process of the FluAB-RSV assay on the Enigma\u00ae ML that led to the subsequent CE marking was completed in July 2013, at Guy's and St. Thomas' NHS Foundation Trust, London, UK [105] .\n\nThe molecular analysis is based on real-time PCR. All required reagents are pre-stored in the cartridge allowing for fully automated analysis with a very short hands-on time of 2 min, while there is no need for cold chain as the reagents can be stored at ambient temperature.\n\nThe biochemical analysis is initiated with a combination of thermal and chemical lysis to release nucleic acids, which are then captured by magnetic beads. Magnetic beads are robotically transferred in situ to two washing buffers for purification and removal of any inhibitory agents. The last step before amplification is the elution of the nucleic acids from the beads, followed by mixing with the amplification reagents (freeze-dried). Each test contains bacteriophage MS2 as an internal process control.\n\nThe cartridge consists of three main blocks (Fig. 10) : (i) the sample inlet block, where the swab is introduced in the collection tube that is then clamped onto the cartridge; (ii) the block with the pre-stored (liquid) reagents (indicated with yellow in Fig. 10) ; and (iii) the block with specific tools (movable components such as pipettors, magnetic wand, and foil cutter). The core of the cartridge operation is based on robotic actuation of fluids between the vessels in order to facilitate the biochemical reactions, handling of beads, etc. In particular, a robotic arm picks any movable items and inserts them in the corresponding liquid tubes [107] .\n\nA highly innovative feature of the system is the PCR reaction vessel [108] . It consists of an electrically conducting polymer (ECP), which acts as a resistive heating element. At the same time it is arranged in such a way that the electrically conducting profile differs in different areas of the vessel (along its axis), thereby controlling thermal gradients that are necessary for thermocycling. The different electrical conducting profile is regulated during the manufacturing of the vessel by varying its radial thickness (key parameter), thus varying unevenly its resistance profile. The vessel consists of a combination of a highly conductive material (aluminum) and an ECP, the two being separated by an insulating layer. The aforementioned induced temperature gradients also assist in convection-based liquid mixing in the reaction vessel. The ECP fabrication technology is typically injection molding.\n\nDetection is achieved via hybridization probes and Fluorescent Resonant Energy Transfer (FRET) [109] . Taking advantage of this effect, the Enigma\u00ae ML system uses two probes to hybridize with the amplified DNA/RNA product, acting as energy donors and acceptors. When amplification occurs, the two probes hybridize and are located in close proximity, thus, the energy of the donor (induced by the excitation source) is transferred to the acceptor, which, in turn, emits this energy as fluorescence. The latter is then monitored in real time during the amplification process, as the amount of the acceptor fluorescence is proportional to the amount of the generated PCR product.\n\nRoche Diagnostics offers the cobas\u00ae Liat (lab-in-a-tube) system [110] as a compact solution for point-of-care molecular diagnostics (Fig. 11) . The system is currently used for detecting: (i) influenza A and B and RSV viral RNA in naso-pharyngeal swab specimens from patients with signs and symptoms of respiratory infection in conjunction with clinical and epidemiological risk factors; (ii) Streptococcus pyogenes (Group A \u03b2-hemolytic Streptococcus, Strep A) in throat swab specimens from patients with signs and symptoms of pharyngitis. However, it is not a multiplexed system, as the aforementioned infections are detected in different cartridges. The instrument is compact and stand-alone (laptop-free) with small footprint operating in such way that minimizes possible interference by, and contamination of the user. With minimum training needed, the system can provide results in as fast as 20 min. The cost of the device and cartridge is approximately \u20ac25,000 and \u20ac55, respectively. Although the system has not yet been used for febrile illness diagnosis in developing countries, its performance features make it a good candidate.\n\nTechnology and operating principle cobas\u00ae Liat is a sample-to-answer platform thanks to the full integration of all necessary reagents in its cartridge. The in situ sample preparation starts with mixing the sample (200 \u03bcL) with chaotropic agents inducing pathogen lysis, followed by the \"bind-wash-elute\" protocol (Boom-chemistry [91] ), which involves binding of nucleic acids in silica-shelled magnetic beads, subsequent washes and a final elution step. Nucleic acids are then ready for real-time PCR with internal controls.\n\nThe core technology of the system is the cartridge, which consists of a rigid frame and a transparent flexible tubule. The latter consists of several pouch segments, which are separated via breakable seals and are flexible enough to be compressed. The system uses peristaltic fluidic actuation for liquid handling. After the cartridge is loaded, the analyzer, which contains clamps, plunges, and actuators, controls the selective release of reagents from tube segments, leading to mixing and propulsion of liquids by precisely applying pressure to the pouches. The pressure needed to compress the tubule to unload the pouch is approximately 1 atm. The analyzer also provides control of reaction conditions at different temperatures, and alternating movement of the reaction mix between two different temperature zones for rapid PCR (Fig. 12) . The outcome of the reaction appears as a real-time fluorescence signal, detected by the six-channel photometer module in the analyzer [112] .\n\nFrom the fabrication perspective, the tubule is based on polyolefins and is fabricated via injection molding or blow molding. In order to serve specific processing needs, some tubules are surface-processed via plasma treatment or introduction of additives. The wall material is multi-layered, with the inner layer being biocompatible, while the outer is resistant to gas permeability. The flexible tubule is supported by a rigid frame, which is made of polypropylene with lower melting temperature than the tubule to ensure uniform melting during sealing. According to the relevant patent [112] (although the patent does not ensure that these exact methods are used in the final production) sealing between these components is achieved via welding of the flexible tubule on the outer frame using thermal and/or ultrasonic sources. An alternative approach is to seal the two components with a hot-melt adhesive joint with ethylene vinyl acetate, or with UV cure epoxy. The dimensions of the frame, surrounding the tubule cartridge, are 150 mm (height) \u00d7 25 mm (width).\n\nThe Agency for Science, Technology and Research (A*STAR), Singapore, STMicroelectronics, Italy, and Veredus Laboratories, Singapore [114] have partnered to develop a lab-on-a-chip for diagnosis of infectious diseases (Fig. 13) . The system is already in the market and was used by the Brazilian authorities as the tool of choice during the 2014 world cup. A number of application-specific cartridges have been developed, some of which are: VereFlu\u2122 (for respiratory infections); VereMTB\u2122 (for tuberculosis); VereThreat\u2122 (for biothreat agents such as Anthrax, Small Pox, Plague and Tularemia); VereVet\u2122 (for multiple avian pathogens); VereMERS\u2122 (for the Middle East Respiratory Syndrome Coronavirus). In 2013 the partnership announced the launch of VereTrop\u2122 for multiple tropical diseases, providing the necessary multiplexity that febrile illness diagnosis requires. The cost per VereTrop\u2122 test is approximately US$100. Sample preparation is performed ex situ, either via spin columns or an automated extraction kit, and the overall time-to-result (including extraction, amplification, optical readout) adds up to approximately 3.5 h. VereFlu\u2122 [115] and VereTrop\u2122 [116] assay chips and multi drug resistant tuberculosis [117] have been clinically validated.\n\nThe core of the system is based on a lab-on-a-chip cartridge (the \"In-Check\" platform, Fig. 14) in the size of a standard microscope slide. It contains a silicon chip covered with a glass coverslip and bonded to a plastic support. An on-chip printed circuit board (PCB) provides the necessary electric contacts as an interface to the processing instrument (e.g. for temperature control). The silicon chip has distinct processing areas (Fig. 14) : (i) The sample inlet microfluidic ports with buried microchannels to facilitate easy chip filling and fluid displacement. (ii) The PCR area (12 \u00d7 8.5 mm 2 ), which contains four PCR chambers, with 1 \u03bcL liquid volume capacity, each. Four pairs of independently controlled aluminum resistors are used to heat the silicon substrates and fluidic reactors, thus providing the thermocycling environment. The temperature is regulated by the Temperature Control System (TCS) in the chip processing device. (iii) The outlet holes, which provide microfluidic contact to (iv) the post-PCR hybridization and detection area, which consists of a 3.5 \u00d7 9 mm 2 microarray with 126 spots, where oligonucleotide probes are spotted using a piezo-array system [119] .\n\nFabrication is performed with a semiconductor-based MEMS process technology, named SIMICH at 8\u2033 wafer diameter, which allows for the fabrication of micro-mechanical, sensor, and microfluidic components. More details on the process steps are available in [120] . Fig. 14 shows some key microfabricated components of the chip and a cross-sectional view of the entire lab-on-a-chip device. Post-fabrication processing includes surface chemical treatment in order to immobilize DNA probes in the microarray area, and to achieve biocompatibility of the PCR area for DNA amplification [121] . Post-amplification detection is performed in a separate, dedicated instrument, through fluorescent microarray detection of chip-hybridized amplification products using an image acquisition camera. \n\nQuantuMDx [123] is a UK-based nanomedtech company that develops and commercializes affordable handheld sample-to-result diagnostic and DNA sequencing technologies using nanowire biosensors and innovative microfluidic technologies. Their collaboration with the Institute of Microelectronics (IME) of the Agency for Science, Technology and Research (A*STAR), Singapore, is strategic for the fabrication of the key microelectronic components. The Q-POC\u2122 platform (Fig. 15 ) of QuantuMDx is a handheld, battery-powered molecular diagnostic device that promises a sample-to-answer DNA-based result in as few as 15 min. It contains integrated reagents with current stability targets of up to 40\u00b0C for up to 18 months. The system can test one patient per run and is a pioneering approach to the handheld sequencing market. In 2014, QuantuMDx partnered with FIND in order to develop a solution for the combined detection of TB and drug susceptibility determination for the causative agent of TB. The Q-POC\u2122 system seems to be especially promising for antimicrobial resistance profiling given that many different genes can be screened through a nanowire array. There are several other assays in the pipeline, for diagnosis of e.g. HIV, sexually transmitted infections, neglected diseases, as well as for tumor profiling [124] .\n\nThe core of Q-POC\u2122 lies in its biosensor chip, which is equipped with a silicon nanowire (SiNW) array based field-effect biosensor. SiNWs have large surface-to-volume ratio, tunable electric properties, and exhibit high potential as biosensors, thus enabling next-generation point-of-care diagnostics. The binding events are detected in a labelfree way through changes in the nanowires' resistance, effectively converting the genetic code into a binary code and providing the output in a digitized format. In particular, upon hybridization of the target DNA on the SiNW, the charge density (and subsequently the electric field) changes. This is reflected as a change in the resistance of the nanowire, which produces the biosensing signal (Fig. 16) . The more negative charges present during hybridization, the higher the resistance of the n-type SiNW sensor. This principle was shown by Zhang et al., by varying the hybridization sites (thus varying the distance of the charge layer) but keeping the total number of charges unchanged [126] .\n\nFunctionalization of SiNWs is performed with Peptide Nucleic Acid (PNA), instead of DNA oligonucleotides. The neutral nature of PNA minimizes the formation of dense charge layer near the nanowire surface, subsequently minimizing the signal to noise ratio. The n-type SiNWs feature typical dimensions of (W \u00d7 H \u00d7 L) 50 nm \u00d7 60 nm \u00d7 100 \u03bcm and are fabricated using standard CMOScompatible top-down approaches, through the oxidation of polysilicon beams patterning using conventional photolithography on p-type test wafers (more details available in Gao et al. [127] ). This method is compatible with mass-manufacturing, is reproducible and convenient, and allows for scaling the sensing area and multiplexing as required by the application. With a capacity of 1000 nanowires in each silicon biosensor chip, the multiplexing potential becomes huge [128] . The sample-to-answer operation is achieved by housing the biosensor chip in a microfluidic cartridge (Fig. 17) .\n\nUstar Biotechnologies (Hangzhou) Ltd.\n\n[130] commercializes its proprietary isothermal amplification technology into an equipment-free diagnostic system, the EasyNAT\u2122 (Fig. 18) . Therefore, the system is especially attractive for resource-limited settings and is intended for batch testing in microscopy centers. However, the system lacks multiplexity (1 target/cartridge) and requires hands-on extraction steps (centrifuge, vortex, syringe). The extraction is performed ex situ using an equipment-free extraction kit. After boiling lysis, a syringe is used to extract and elute the DNA using appropriate buffers. Initial tests with EasyNAT\u2122 kit have been performed in clinical studies in Tanzania [131] and China [132] for tuberculosis. The manufacturers note that the reagents require refrigeration (\"storage in \u221220\u00b0C\").\n\nThe system is based on an isothermal amplification method, called Cross Priming Amplification (CPA), which uses multiple (5-8) crosslinked primers to amplify DNA or RNA at a constant temperature of Reprinted with permission from [126] . Copyright \u00a9 2008 American Chemical Society.\n\n63\u00b0C [134] . Due to its isothermal nature, amplification does not require any complex temperature control system: a water bath or a heating block are used in order to maintain constant temperature and incubate the CPA assays. Following the 60 min amplification step, the reaction tube is transferred to the cartridge, where a lateral flow immunochromatographic strip provides the visual readout after 15-30 min.\n\nThe patented Cross-Contamination-Proof (XCP) nucleic acid detection device (Fig. 19 ) offers the advantage of minimizing the risk of amplicon cross-contamination [135] , through: (i) maintaining closed reaction tubes after amplification (thus avoiding release of amplicon aerosols); (ii) using an enclosed unit (the amplicon tube) to insert the reaction tube; (iii) placing the amplicon tube into an additional enclosed unit (the detection device). Running buffer and reaction tubes are inserted in the amplicon cartridge. The amplicon cartridge is subsequently inserted into the detection chamber. As the sealing of the detection chamber is closed, it activates a blade that punctures simultaneously the two tubes. The running buffer drives the amplicon to the adjacent lateral flow strip and amplification results are visually readable (Fig. 19(c) ).\n\nThe detection principle in the lateral flow nucleic acid testing strip is based on a combination of the nucleic acid hybridization and immunoassay principles. A probe is used, which carries a colored particle, and can hybridize with the amplicon. The complex is then captured by the antibody on the nitrocellulose membrane of the test strip. In the absence of an amplification product, there is no interaction/hybridization with the probe, which then flows uncaptured through the membrane to the absorbent pad ( Fig. 19(b) ). (i) Meander-shaped microfluidic channel filled with reagents that are released at will to area (g)/(h). In particular, reagents may include various nucleotide mixtures and wash solutions, all separated by air bubble(s), in order to flow sequentially and in a well-controlled way. When nucleotides flow sequentially over a nanowire-immobilized single stranded oligonucleotide, then according to the hybridization sequence, the local charge changes, causing a resistance change in the SiNW. Image source: used from [129] .\n\nLuminex Corp. commercializes the Verigene\u00ae RP Flex System, (Fig. 20) (developed and previously commercialized by Nanosphere), which received an FDA approval in 2015 [138] . The target application is respiratory tract infections and the system covers a broad panel including 13 viruses and 3 bacteria [139] . Analysis is performed from naso-pharyngeal swabs. Verigene\u00ae also offers other panels such as gastrointestinal, while it also identifies eight gram-negative organisms and resistance markers from blood culture [140] . The full-automation mode of the system (pre-stored reagents) requires minimum hands-on time (< 5 min), while the overall time-to-result is 2 h. The system is benchtop and consists of two components, the Reader (as a controller) and the Processor SP, performing the automated test processing steps. It is a modular system since one Reader, which acts as the user interface and central control unit, can handle several Processors SP.\n\nEach Verigene\u00ae test uses four single-use consumables: an extraction tray, a tip holder assembly, an amplification tray, and a test cartridge. These are all loaded in the Processor SP for all automated processing The glass support of the test cartridge, which carries the microarray, is inserted in the Reader of (a) for detection. Image sources: (a) used from [138] ; (b,c) reprinted from [141] , Copyright \u00a9 2009, with permission from Elsevier. steps, specimen extraction, target amplification, and hybridization. Fluidic handling is performed via an in-system servo actuator and positive displacement pump, e.g. syringe pump, in combination with pneumatic valves. A comprehensive sequence of steps is provided in one of the company's patents [142] and the system's technical bulletin [138] . After sample processing in the extraction and amplification trays, nucleic acids are transported to the test cartridge. At the end of the procedure, the substrate (which supports a glass slide with the microarray for capturing the target nucleic acids) must be removed from the cartridge and placed in the Reader (readout takes a few seconds). All necessary reagents are contained in the cartridge. The amplification technology is based on multiplex RT-PCR between heating and cooling zones followed by hybridization to target specific capture oligonucleotides in a microarray format.\n\nEnd-point detection is achieved with gold nanoparticles (AuNPs), which constitute the core technology of the system (proprietary NanoGrid Technology, Fig. 21 ). With dimensions of 13-15 nm, the advantage of AuNPs over conventional fluorophores is the increased sensitivity by several orders of magnitude (e.g. the light scattered from one nanoparticle is equivalent to the light emitted from 500,000 fluorophores [143] ). After amplification is completed, the workflow for detection is as follows: inside the test cartridge, the amplified targets are hybridized to capture oligonucleotides that are pre-immobilized on the glass slide microarray. After removal of the unbound DNA, the hybridization products are labelled with AuNPs. Subsequently, intermediate oligonucleotides are flushed into the chamber and bind specifically to the immobilized complex, leaving a poly-A tail sticking out and being available for subsequent attachment of poly-T-bound AuNPs, which act as probes. After removal of unbound AuNPs, captured AuNPs are covered by silver NPs (during the analysis procedure) to enhance the scattered light. Thus, the overall size of the NPs becomes larger and the subsequent optical signal is enhanced. Illumination begins with an LED (\u03bb max 630 nm) shining through the edge of the glass slide (acting as a waveguide to the LED illumination). The evanescent wave that is generated through the glass slide and towards the NP coated surface causes light scattering from the illuminated Au/silverNPs towards the camera, which captures images of the array multiple times and at various exposure times [144] . Notably, the AuNP-based detection technology may be adapted for protein analysis as well.\n\nThe Spanish molecular diagnostics company STAT-Dx [146], acquired by Qiagen in January 2018, has been developing the DiagCORE\u00ae (Fig. 22 ) platform operating as a near-patient testing solution for low test volumes or as a platform to cover mid-throughput requirements. The company announced in early 2018 the approval of CE-IVD clearance for the system and the respiratory panel. STAT-Dx expects full commercial launch of the DiagCORE\u00ae in the 2nd quarter of 2018. The \n\nThe cartridges of DiagCORE\u00ae are pre-filled with dry and liquid reagents with a shelf-life stability of 12 months at room temperature. The cartridges can be inoculated either using swab directly (with the appropriate cartridge housing for sample elution [147] ), or using liquid samples of volumes from 100 \u03bcL to 1.5 mL. Automated cell lysis is used for releasing nucleic acids from pathogens. Nucleic acid purification follows using high quality extraction columns. The sample is then subjected to rapid thermocycling for amplification; eight real-time PCR reaction chambers with six-plex capability allow for the simultaneous detection of a total of 48 targets.\n\nRegarding fluidics, the cartridge includes a transfer module that moves laterally along a guide that is located within the cartridge in order to align various fluid ports and to control the movement of fluids through the cartridge channels and chambers [148] . Fig. 23(a) shows a typical cartridge from the back side, where the areas designated with the numbers #110, #114, and #116 represent the testing unit, the dilution/dosing unit, and the fluid guiding unit between various chambers, respectively.\n\nThe testing unit is shown in more detail in Fig. 23(b) . The fluidic testing arrangement is aligned with the gravity field in order to avoid formation of bubbles in the various chambers. The inlet port of the structure is indicated as #204, while the top chamber (#216) is unvented and acts as an air reservoir for the air trapped within the microchannels. By avoiding venting, the elimination of aerosol leakage out of the cartridge is achieved. Channel openings (#206a, #206b) are used as fluidic controls, where optic sensing defines whether there is liquid or not. A mixing chamber is included (#208). Its large crosssection causes turbulent liquid flow, which enhances mixing (passive mixing). The chamber #210 is the actual reaction chamber (with a volume of up to 50 \u03bcL) serving also for detection. Chamber #212 contains dry stored reagents. By applying variable pressure in the inlet port #204, the liquid may be pushed to chamber #212, rehydrate the reagents, which are then pulled back to chamber #210 in order to participate in the reaction. The structure indicated in Fig. 23 (b) may be repeated several times, with a common inlet port and different stored reagents, in order to serve in geometrically multiplexed reactions.\n\nThe concept of centrifugal microfluidics (in contrast to pressuredriven microfluidics that all the aforementioned platforms use) has evolved to a mature and powerful technology for automation of diagnostic workflows in the fields of clinical chemistry, immunodiagnostics, nucleic acid analysis and others. This microfluidic approach benefits in particular from the straightforward mechanism for liquid actuation based on centrifugal forces that are a result of simple rotation of the cartridge with defined spinning frequencies [150] . No external pressure sources or complicated (micro)pumping systems are required, which reduces the risk of cross-contamination (due to openings in the cartridge) and allows for the building of simple, portable processing devices with small footprint and weight. These facts qualify centrifugal microfluidics as a technology for automation of diagnostics at the point of care. A main advantage of centrifugal microfluidics is the employment of microfluidic modules (\"unit operations\"), each one serving a particular fluidic functionality for: liquid handling (e.g. metering and aliquoting [151, 152] , valving and switching [153] [154] [155] , pumping [156, 157] or mixing [158, 159] ); assay integration (reagent pre-storage and supply [160, 161] ); separation [162, 163] ; detection [162, 164] ; blood plasma separation; nucleic acid purification and amplification, or washing and blocking. A comprehensive overview on unit operations and process chains is provided by Strohmeier et al. [165] . Combination of these unit operations and process chains allows for the integration of complex laboratory processes into one system for fully automated sample-to-answer analysis.\n\nChallenges are mainly in the field of cartridge-integrated sample preparation required for completely integrated sample-to-answer solutions [165] [166] [167] . Apart from the world-to-disk interface that defines how the sample can be added by the user to the cartridge, the preparation of complex samples such as sputum, a classical specimen in diagnostics e.g. for detection of tuberculosis [81] , is an unsolved issue yet, as samples can be diverse in their physical constitution, and harsh chemicals or strong forces are required for pretreatment. Further challenges are the handling of increased sample volumes (> 1 mL) of blood or urine that are required when the pathogen load is low or when the required clinical sensitivity for diagnosis is high. The maximum sample volume is typically limited by the available footprint of the disk and it has to be considered that e.g. for nucleic acid extraction by classical bind-wash-elute chemistries, equal volumes of lysis and binding buffer are required for sample treatment, hence posing further challenges to cartridge integrated reagent pre-storage. From the research perspective, increased application of disk-based systems has been recently observed in resource-limited settings, especially in the field of immunodiagnostics. A disk-based test for detection of a four-parameter liver assay panel for defining liver function has been demonstrated to be completed within 20 min by Nwankire et al. [168] using a portable, battery powered processing device and including field testing in a laboratory in Nigeria. Furthermore, Hosseini et al. [169] have implemented a novel mixing method using microspheres on disk in order to detect dengue virus antigen NS1. The following sections provide a short overview of some centrifugal microfluidic platforms that are at late development or market stage. The inclusion criteria in this review were that the technologies focus on infectious diseases and have at least a few publications in the field.\n\nOne representative platform of centrifugal microfluidics at late stage development is the LabDisk (Fig. 24) from Hahn-Schickard [170] and IMTEK, University of Freiburg, Germany. The technology has been applied in a variety of applications ranging from clinical chemistry [164, 171] , to immunoassay [172] and nucleic acid analysis, indicating universal use. In the latter field, two significant advances in fully automated sample-to-answer (nucleic acid extraction and amplification) analysis were announced, particularly for neonatal sepsis, detecting S. warneri, H. influenza, E. coli, and S. agalactiae [173] , as well as for H3N2 influenza virus [174] . The amplification was based on PCR and the time-to-result was 3-3.5 h. Yet, when the LabDisk was used to integrate RPA isothermal amplification for the detection of biological warfare pathogens (B. anthracis, F. tularensis, and Y. pestis) the total time-toresult was < 45 min [175] . In addition, the processing device for isothermal amplification operates with a power consumption of < 75 W, which facilitates its application in remote environments [176] and its potential use with battery or solar panels. The application of the LabDisk at the point of care in resourcelimited settings has been demonstrated with the detection of Yellow fever virus in laboratory and field settings in Senegal using RPA and 20 min amplification time [177] . Recently, a LabDisk was developed for the detection of malaria, dengue, chikungunya, pneumonia, and typhoid fever that used LAMP providing the necessary means for nucleic acid based multiplex amplification with a time-to-result between 70 and 120 min [178] . Currently, one disadvantage of LabDisk is that, while several parameters can be analyzed per disk, only one disk, corresponding to one patient, can be processed per test run.\n\nThe concept behind the LabDisk is to translate laboratory processes and steps into microfluidic unit operations and interface them towards fully functional sample-to-answer solutions. Sample volumes can range from (sub)\u03bcL to several hundreds \u00b5L. One of the LabDisk innovations is the pre-storage of liquid reagents in stick-packs [160] . These pouches tightly seal the buffers and release them on demand upon centrifugation.\n\nThe manufacturing technology is microthermoforming of polymer foils [179] , a technology that is routinely used in the macroscale for blister packages, but was adapted to the microscale for micro/nanostructures in the LabDisk (Fig. 25) . Typical foil thicknesses are between 150 and 300 \u03bcm. A mold and a thin polymer foil placed above the mold are heated at a temperature near the glass transition temperature of the polymer foil. When the conditions are favorable, air is blown from the top so that the foil takes the shape of the mold. Main process parameters are the applied air pressure and the temperatures of mold and foil. Various materials can be used, with most preferable candidates being the Cyclic Olefin Polymer/Copolymer (COP, COC) and Polycarbonate (PC), depending on the application requirements. Sealing is performed either via a pressure sensitive adhesive foil (containing nanocapsules, which break and release adhesive upon application of pressure) or via thermal sealing using one more foil material (e.g. COC on COC). The elastomeric molds are suitable for prototyping, where fast iterations are required. However, each elastomeric mold may be worn out after repeated use for some tens of cartridges. Thus, for large manufacturing series it is more efficient to use a metal mold. It may be more challenging to deform the foil (and methods such as coating on metal are used), however it is economically more sustainable and the durability of one metal mold can be sufficient for tens of thousands of disks.\n\nFrom the commercial point of view, the GenePOC\u2122 system (Fig. 26 ) from GenePOC Inc.\n\n[181] is a simple and integrated portable instrument for the prevention and early detection of infectious diseases. The system received in 2017 FDA clearance for its Clostridium difficile assay and a CE mark for its Group B Streptococcus assay. In the future, GenePOC Inc. plans to develop cartridges for detection of respiratory, gastrointestinal, neonatal, and hospital-acquired infections, as well as sexually transmitted diseases. The system operates in a sample-to-answer mode, with minimum hands-on steps (a few minutes). The manufacturers declare a time-to-result of up to 1 h. Importantly, the system operates in a stand-alone mode, without the need for laptop, which is replaced with a touch screen instead. Its universal sample-to-cartridge interface (accepts liquefied matrix) allows compatibility with several types of swabs, urine, etc. [182] .\n\nThe cartridge consists of only three pieces of plastic and has a wedge-shaped form (unlike an entire disk), which allows the device to process up to eight cartridges simultaneously, thus offering an increased throughput that is often necessary in cases of \"extreme\" POC testing [182] . The GenePOC\u2122 disposable is composed of three distinct operational sectors: (i) World-to-chip interface: 100 to 200 \u03bcL of clinical sample conditioned in GenePOC\u2122 sample buffer is inserted in the disposable with a transfer pipette. The developers mention that the use of blood is not feasible yet, as it would require off-chip microbial preconcentration. Subsequently, the inlet chamber is sealed with a lid that prevents aerosols from leakage. A series of siphons and passive valves prime the liquid to the next chambers. (ii) Universal sample preparation, starting with pathogen mechanical lysis: a metallic disk is magnetically actuated in the chamber where glass beads are present leading to efficient lysis and release of nucleic acids. The lysate is centrifugally driven to a dilution chamber, where PCR inhibitors are inactivated by heating up to 95\u00b0C and with proper ionic condition adjustment of the extracted material in order to optimize subsequent amplification. (iii) The amplification and detection sector, which is the only assay-specific area of the cartridge where RT-PCR is performed (reagents are drystored). This sector has three chambers available for amplification (thermocycling is achieved via air heating of the overall process chamber). The device includes four non-overlapping excitation and emission wavelengths for fluorescence detection of chemical dyes, therefore, up to 12 targets (4 in each chamber) can be detected simultaneously, and under rotation. Further details regarding cartridge material and fabrication methods are not available by the manufacturer.\n\nThe Liaison\u00ae MDX (Fig. 27 , formerly 3M Cycler with Simplexa\u2122 integrated assays) is a centrifugal-based automated platform commercialized by DiaSorin Inc. (formerly by Focus Diagnostics, which is currently owned by, and is part of DiaSorin Group [184]). The system has acquired FDA/CE-IVD approval and its target applications currently aim at respiratory tract infections for influenza A and B as well as RSV viruses, HSV 1 and 2, Group A Streptococcus, and C. difficile [185] . The system is classified as benchtop and is operated via a laptop. The cost per cartridge is approximately \u20ac30, while the instrument costs approximately \u20ac40,000. \n\nThe device is compatible with two types of disks, targeting different types of end-user specifications (both are made of polypropylene with a nucleic acid compatible adhesive): (i) the Direct Amplification Disk has eight individual slots/cartridges (all are connected into one disk, but one or more can be used simultaneously). The sample volume is 50 \u03bcL, which is mixed with buffer (50 \u03bcL) and the sample-to-answer time is 60 min based on high-speed thermocycling and rapid RT-PCR using high heating/cooling rates (> 5\u00b0C/s and > 4\u00b0C/s, respectively). Samples require no pre-processing (DNA/RNA extraction) and direct amplification is applicable. (ii) The Universal Disk is a 96-well singleuse cartridge able to perform multiple assays per disk. The reaction volume is 10 \u03bcL. The device has four excitation and emission wavelengths for optical multiplexing in addition to the geometric (multichamber) multiplexing. When the Universal Disk is used, extraction should be performed ex situ and the eluate is inserted into the disk.\n\nA rather different approach from the typical benchtop-based or fully-automated systems has been suggested by the \"Diagnostics-in-a-Suitcase (DiaS)\", initially developed for the emerging avian influenza A (H7N9) virus [186] . In contrast to the aforementioned systems, where the core was a (micro)fluidic cartridge handled in a fully automated way, the DiaS system does not proclaim miniaturization or fully-integrated components and requires a few hands-on steps. Yet, it smartly includes all the necessary biochemical components (extraction and amplification reagents), tools (gloves, pipettes, tube tracks, pipette boxes, waste container), and equipment (a tube scanner, vortex, microcentrifuge, even a mask in case of a highly infectious disease/epidemic), within a suitcase for a complete on-site analysis. It is an entire portable lab, which functions with solar panels or power packs (Fig. 28) .\n\nThe workflow includes a typical sample preparation starting from the lysis of the pathogens, extraction of nucleic acids by binding to magnetic beads, two washing steps, and elution. This process requires 30 min. The subsequent amplification step is conducted via RT-RPA and the time-to-positive is 15 min. In total, nine pipetting steps are required, which can be reduced by replacing some liquid components with lyophilized reagents. During the 2014 Ebola outbreak, the system was applied in field trial in Guinea in collaboration with the Institut Pasteur in Dakar, the Public Health Institute of Guinea, the University of Stirling, the Robert Koch Institute, and TwistDx Ltd. [187] . This innovative approach tackled several problems including lack of (constant) electricity; lack of cold chain for material storage; risk and time loss from transferring infectious material from the field to central laboratories for analysis; and the need for fast time-to-result for healthcare providers who screened patients for Ebola virus. A natural drawback of the DiaS system is the lack of connectivity with all the accompanied consequences (manual registration of data, risk of loss, ambiguous storage of data, etc.). Furthermore, it requires a certain degree of user training for the handling of manual steps.\n\nAlong a similar concept, MSF is developing a small-scale, autonomous diagnostic bacteriology laboratory based on appropriate and feasible, existing or adapted techniques, at affordable cost, with high accessibility and ease of use, which may respond to clinical needs in RT-PCR/Isothermal . The feasibility of using robust blood culture bottles with visual readout, with a new type of media that bypasses the need for blood and, thus making it easy to use by non-experts, is being currently evaluated. A simple pathogen identification system, restricted to genus, as well as an antibiotic sensitivity testing system, restricted to the six antibiotics used frequently at the peripheral level, have also been developed. The target patient populations are children presenting with severe illness, those with risk factors for bloodstream infections, such as neonates, malnourished or HIV positive children, those who fail to respond to first-line antibiotic treatment, hospitalized war patients, and patients with trauma or prior surgery by providing organism-directed antibiotic therapy. With the developed autonomous diagnostic laboratory, it will be possible to acquire information regarding more general questions such as proportions and antibiotic resistance profiles of key bacterial pathogens, thereby providing evidence-based information for antibiotic policy (appropriate prescribing) and allowing for the improvement of epidemiological investigations as well as supporting healthcare infection control in emergencies and in neglected populations in resource-limited settings.\n\nNovel diagnostic platforms, such as those mentioned in the previous sections, require validation in the target patient population, as well as in users. This should be a requirement for all new diagnostic tests, but it is even more important for point-of-care tests that are often used in nonselected patients (for example, any patient with fever attending any level of the health system) and by users with no technical background. Before large-scale implementation in resource-limited countries is decided, the test should also preferably be endorsed by WHO and by international donors and governments that provide funding. Unfortunately, many point-of-care tests have been launched in the market with only limited laboratory validation using convenient patient samples (for example that have a high pathogen load), or even cultured pathogens in relatively high concentration. Field evaluation of the performance of the test in real patients, who often harbor low pathogen loads, is indeed often undertaken only after registration of the product. This is due to the lack of national and international regulatory mechanisms applicable to diagnostic tests, which, in contrast, exist for medicines [189] . The net result is that health workers, especially those working in private clinics, and even patients going to pharmacies, have access to POC tests that have in fact very low sensitivity and/or specificity. For example, LFT for chikungunya is commercialized, although it has a sensitivity of maximum 50% in the field [190] [191] [192] .\n\nThe gap between the performance measured in the laboratory and that in the field is due to several factors, depending on the type of pathogen and technology used. The sensitivity of NAATs to detect bacteria in the blood compared to blood cultures is often disappointing [33] . Even though NAATs are able to detect additional cases compared to blood-culture, they are not positive in all blood culture-positive patients [193] because bacterial load can be very low, especially in adult patients with robust immunity. This explains the failure of numerous molecular-based multiplex platforms licensed in Northern countries, aiming at diagnosing rapidly the cause of sepsis in admitted patients. Fig. 29 . The whole diagnostic test development process, from innovation, to validation and application. This development process is in reality a reiterative process that is more circular than linear. Source: V. D'Acremont.\n\nThese tests work well for blood cultured for a few days but not for native blood, which implies that the potential gain of time, essential in these patients, is lost [194] . Tests based on the detection of antibodies, even of IgM type, often lack sensitivity during the very first days of an acute febrile episode, but also specificity because of antibody persistence for several weeks. These challenges show how important it is to undertake clinical trials in real conditions to assess first the real performance of the test in the field (accuracy against the best available standard), and then the impact of using such tests on the management of patients (efficacy, measured through the impact on the health outcome of patients, cure rate after a certain number of days, secondary hospitalizations, or deaths and sequelae), done by routine health staff in their real working environment (effectiveness, measured generally through the level of compliance to test results and guidelines, and the appropriateness of antimicrobial prescriptions) (Fig. 29 ). Outcomes measured in these trials should be related to the health outcome of patients and the public health benefits, and not only to the diagnosis based on laboratory reference standards (which for some diseases are anyway suboptimal or even non-existent).\n\n\"We have to treat the patient, not a test result\". To follow this adage, it is even more important nowadays that a continually increasing number of diagnostic tools is becoming available at the point of care. That should, however, not be interpreted as it has been for years with malaria microscopy, as an invitation to disregard test results and treat diseases presumptively based on clinical elements with low sensitivity and/or specificity [195] . This adage rather suggests that, because no diagnostic test is 100% perfect, their results do not provide a black-orwhite answer, but rather an indication on the disease probability. This probability depends on two factors: (i) the prevalence of the disease in the corresponding patient population (pre-test probability), and (ii) the performance (positive and negative likelihood ratios) of the test used. When a disease is rare in the population (low pre-test probability) even if the test has a reasonable accuracy, the post-test probability after a positive result remains low. For example, if a typhoid rapid test with 80% sensitivity and 80% specificity (and thus, a likelihood ratio (LR) of 0.8/(1-0.8) = 4) is used in an area of Asia where prevalence of typhoid fever among patients with febrile illness is 20%, the post-test probability will be 50% (it can be calculated using Fagan's nomogram [196] ), which suggests that it is reasonable to implement an antibiotic treatment to that patient. If the same test is used in an area of Africa where the prevalence is 2%, the post-test probability will only be 7.5%, which hardly justifies treating the patient for typhoid but rather to consider alternative diagnoses.\n\nBased on these principles, decision charts can be built to precisely guide clinicians on how to use diagnostic tests and prescribe medicines in the most rational way. Paper versions of such guidelines have been developed by WHO and UNICEF, and details on their strengths and weaknesses can be found in the literature [24, 25, 197] .\n\nThese guidelines, however, were deemed difficult to be adopted and properly implemented, due to several reasons including the long duration of the training required and the conflicting recommendations provided in different guidelines due to the time required for harmonization and then update of all paper material at large scale. Mobile electronic technologies are promising tools to overcome these challenges. An electronic algorithm is, indeed, able to guide clinicians through the specific branches that apply to their patients, to accelerate training by teaching health workers directly on the mobile support (and even integrating training modules into the device), and to help to disseminate quickly to all health workers updated versions of e-algorithms through 3G connection. Fig. 30 provides a schematic representation of an integrated tool that aims at managing children with febrile disease at primary care level in resource-limited countries (derived from the existing e-POCT tool [23] ). The tool integrates a few key clinical data, biosensors measuring respiratory rate, oxygen saturation, cardiac rate, glycemia, and hemoglobinemia, as well as rapid diagnostic tests detecting malaria antigen (other pathogens can be added according to local endemicities) and host biomarkers (to differentiate bacterial from viral infections). It then provides guidance to health workers on when to refer a sick child, and whether to prescribe or not an antimicrobial (and other type of medicines), while it also calculates drug dosage based on weight or age.\n\nIt is beyond the scope of this review to elaborate on the content and performance of existing e-algorithms and platforms for the integrated management of children with febrile disease, however, the reader can refer to a recent review published by Keitel et al. [30] . The consultation process data collected through the computerized decision-support tools used by clinicians and sent with 3G remote connection to a userfriendly data management system can be used for surveillance and outbreak detection.\n\nTo document the cause of patient's fever, and at the same time the cause of the potential epidemic, a decision-support system should integrate the results of a pathogen POC test, through a reader directly connected to the tablet supporting the clinical e-algorithm, and if possible also remotely to the central server. The source of information would be patients seen at routine health facilities tested by POC tools that have a direct impact on case management (e.g. malaria or typhoid), but also from a restricted number of sentinel sites where additional POC test, aimed at detecting pathogens of particular interest (that cause large epidemics, even if non-treatable such as dengue, or rare such as Ebola virus disease), would be used. The data accumulated on a daily or weekly basis (depending on the level of 3G connection availability) at the central level would allow health authorities to conduct real-time disease surveillance, through weekly/monthly reports, and would also enable immediate outbreak alarms when the preset incidence threshold for the surveyed disease has been reached. From the central server, automated feedback reports can also be created, sent to clinicians' tablets and discussed during supervision visits at the health facility. Training e-tools, aimed at improving management of patients in general or in the particular situation of an outbreak, could also be sent to the tablet to guide clinicians. Finally, a patient file supported by an electronic card owned by the patient, could be synchronized at each new consultation with the data collected by clinicians in the tablet (Fig. 31) . Such a fully integrated system seems to be overoptimistic; however, each of its components has already proven to be feasible and the challenge now is to find appropriate and sustainable diagnostic and Information and Communication Technology (ICT) platforms that can be deployed at large scale and in the long term.\n\nTo address the clinically complex differential diagnosis of an episode of fever, that is a frequent presenting syndrome, this review outlined some point-of-care and near-patient diagnostic technologies that can assist to this scope.\n\nIn the long, but non-exhaustive, list of described technologies, none seems to satisfy simultaneously all criteria of end-users' needs, target product profiles, and the ASSURED criteria. Regarding performance, some technologies may be fully automated and multiplexed, but they are prohibitively expensive; some are cost-effective, but compromise sensitivity or multiplexity. In contrast, some solutions offer multiplexity, yet they are benchtop, require laptop, electricity, and are barely portable (due to size and weight). Regarding technology, most of the described platforms implement nucleic acid amplification (PCR-or isothermal-based) and almost none of them includes a parallel immunoassay analysis to measure the host response to an infection. A few of the suggested approaches are equipment-free but therefore lack connectivity and interfacing ability. However, one can observe a common rationale in the structure of the described technologies. The vast majority are based on the combination of three components: the assay, the cartridge, and the readout device. Several variations may exist in the format of the assay, the cartridge, or the detection principle; however, this three-element model seems to be the backbone of all described diagnostic platforms. This modular nature should motivate the developers and manufacturers to consider more (semi)open and adaptable platforms to address end-users' needs in a dynamic way, being able to quickly modify their panels and adapt to endemic or epidemic needs.\n\nThe review concludes with the need of electronic decision trees to support diagnostic tools, as interactive assistance to clinicians. Such algorithms are derived from paper-based guidelines to computerized versions (which enforce the provision of output for any possible combination of clinical elements, which is not the case for traditional guidelines), operating on 3G mobile tools such as tablets. They receive, as input, data from several (POC and non-POC) diagnostic tests, which are processed via clinical algorithms, to provide clinicians with guidance regarding the handling of the patient (admission, treatment, etc.). Such interoperability between ICT components and interfaced physical systems (diagnostic tests) for decision-support can provide solutions of clinical and public health utility, therefore, this trend is expected to increase rapidly, offering high impact diagnosis in developing countries, and transforming the global healthcare landscape. This process, being rather complex and requiring know-how from a variety of disciplines and partners, requires multiple interactions between universities, industries, governmental and non-governmental organizations, as well as philanthropic institutions, that are not only based in wealthy countries but also in resource-limited countries. To increase the chances to make progress, most successful technologies should be supported and developers be motivated to partner with each other. It is only with such a spirit that the development pathway can be coherent and harmonized, and the new tools eventually may be implemented at large scale.\n\nLooking into future perspectives, it seems that a combination of technological and non-technological factors will be critical to decide whether the diagnostic POC technologies can be used in the management of patients with febrile illness.\n\nFrom the technological perspective, it would be interesting to observe the landscape in the next 5-8 years and whether label-free detection technologies can be transferred from the laboratory to the clinics, and then to the market. Magnetic field, electrochemical, gravimetric (e.g. surface acoustic waves), and micromechanical (e.g. cantilever based) detection technologies are some laboratory-mature Fig. 31 . Schematic representation of the potential integration of a mobile patient management system (eFever) and a centralized electronic disease surveillance system (eMergence). Source: Val\u00e9rie D'Acremont.\n\ncandidates that could potentially substitute fluorescence detection and offer the advantage of cheaper read-out devices. Regarding label-free technologies, it is important to consider how they can potentially be integrated into sample-to-answer systems, in view of the requirements outlined in Sections 2.3 and 2.4. In addition, it is important to keep track of the progress on the LFT-based nucleic acid analysis and detection, a concept that is rapidly catching up and combines the easiness of LFTs with the molecular analysis.\n\nThe transition from the laboratory to the market is crucial and depends on multiple parameters. A fundamental one is the sustainable and scalable manufacturability of the disposable cartridges (in terms of materials and processes). Ideally, developers should have access to fabrication facilities that could perform the scale-up manufacturing in two phases: first, from prototyping to medium scale manufacturing (a few thousands or tens of thousands cartridges/chips/components per year) in order to serve clinical validation studies; and in a next level to aim for large scale manufacturing (tens of thousands to hundreds of thousands, that are fairly realistic quantities for infectious diseases of global impact). Special attention should be given to the heterogeneous integration of components, i.e. when a system consists of not only plastic/silicon/glass core components, but integrates biological and biochemical agents, which are necessary for the sample-to-answer analysis. Issues of stability and compatibility of (bio)chemical reagents with cartridge materials and manufacturing processes, adsorption (and loss) of reagents may prove critical for reaching the desired limit of detection.\n\nA future perspective is also that the diagnostic tools are no longer operating in a stand-alone mode, but in a broader \"ecosystem\". To this direction, integration of ICT is of primary importance, as it is the means to connect a variety of different tools and generate networks (existing \"traditional\" approaches, reference methods, and new innovative tools), create databases, and process data (since we are in the era of Big Data). Along these lines, the combination of nucleic acid with protein biomarker testing seems to be a path for more reliable diagnosis, especially in case of syndromes caused by several different pathogens of bacterial, viral, parasitic, or fungal nature. Further elaborating on the ecosystem approach, and especially for diagnostics for resource-limited countries, special business model developments are required that would render marketization in the target areas attractive. Large industries or Small and Medium Enterprises (SMEs) may choose their own way to market, but a new path may be to try marketing in partnership with the pharmaceutical industry. It is obvious that diagnostics and therapeutics are the two sides of the same coin, and only through their combination and interplay can healthcare truly progress. Especially in an era that antimicrobial resistance rises dramatically, this exact issue could and should become the bridge to unite the worlds of diagnostics and therapeutics.\n\nOne parameter that should also be considered during the transition of the POC technologies from the laboratory to the market is the healthimpact modeling, including health economics and cost-impact analysis. One technology may be (comparatively) cheap but may not offer added clinical value; another may be (seemingly) expensive but it may prove overall cheaper than the existing test because the clinical impact is higher. The developers/manufacturers should compare the manufacturing cost of their technology to the real cost of the same test within their healthcare systems. A substitution of an existing standard of care by an innovative technology would be welcome if: it can lead to the same clinical impact at an overall lower price; or it can offer higher clinical impact at the same price. When assessing novel technologies, one should consider what they actually aim to substitute (material savings, time and labor savings, etc.) in order to have a complete view of the cost savings.\n\nLast but not least is the perspective of adaptability and usability by the potential end-users. Whether in resource-limited countries or in the more wealthy part of the world, a technology may be blocked from being used, even if it performs in the best way, due to reasons related to constraints and reluctances that end-users have. A behavioral change of the end-users (through several means, e.g. electronic decision algorithms, e-learning material, supervision tools) is the key factor to increase acceptability and trust towards new technologies. In addition, end-users should be reassured that these emerging tools do not aim to substitute them but to assist them in decision making, for their benefit, and for the benefit of the patients and the whole community."}