{"title": "Infectious Triggers of Chronic Lung Allograft Dysfunction", "body": "Lung transplantation, first performed in 1963, is the only therapeutic option for patients with end-stage lung diseases. Lung transplantation survival is, however, limited by a high incidence of chronic lung allograft rejection (CLAD), which ultimately results in chronic respiratory failure and death. To prevent the immediate rejection of the transplanted organ, patients must receive immunosuppressive medications for life. CLAD has two forms, the more common bronchiolitis obliterans syndrome (BOS) and the recently described restrictive allograft syndrome. CLAD is defined by a decrease in lung function, notably a decrease in forced expiratory volume in 1-s (FEV1). Until recently, most published studies had used BOS as the measure of CLAD. Outcomes herein will be described as they were in the individual studies: BOS or CLAD. Infections are a frequent complication after lung transplantation, the majority of which are pulmonary. Many studies have documented an increase in CLAD among those with specific pulmonary infections.\n\nA study from Switzerland is the most comprehensive study of outpatient lung transplant recipients (LTR) community-acquired respiratory viruses (CARV) epidemiology to date [1\u2022]. The study involved asymptomatic screening, as well as routine follow-up and emergency encounters, in 112 outpatient LTR. Community viruses were found in 174 of 903 encounters, 15 % identified in routine and 34 % in emergency visits. Asymptomatic viral carriage was identified in 10 % of the screening visits. Overall, 61 % of the LTR had a viral infection. Picornaviruses were the most frequently seen and most were human rhinovirus (HRV).\n\nCertain conditions may predispose LTR to CARV infections. In one study, elevated blood levels of tacrolimus were identified as a risk factor for CARV infection [1\u2022]. In studies of chronic HRV in LTR, it appeared that inadequate host immune responses against the virus were responsible for the lack of HRV clearance, not virus-specific factors [2, 3]. Additionally, the treatment of acute cellular rejection (ACR) with immune suppressing steroids may augment the likelihood of dual or sequential viral infections [4]. Moreover, CARV are largely acquired in the community setting to which LTR have increasing exposure as the time from transplantation increases. Several studies have found that the median time to CARV in LTR is greater than 1 year, particularly with bronchoalveolar lavage fluid (BALF) samples positive for virus [1\u2022, 5]. There may be more than one explanation for this finding, as BOS itself could be a risk for CARV [6] and BOS typically develops more than 1 year after transplantation. Thus, it appears that the immunocompetence of the host, increasing community exposures, and perhaps the presence of BOS are important risks for the acquisition of CARV.\n\nEarly studies of the impact of CARV upon lung allograft function tended to be case series of patients requiring admission to the hospital that relied upon culture methods of viral identification, limited to the detection of paramyxoviruses and influenza [5, 7\u20139]. However, while such studies did tend to identify LTR with more severe disease, it was apparent that temporary decreases in FEV1 are frequent [7, 10] and may persist [9, 10], often preceding the development of BOS [5, 11\u201313]. Indeed, in the prospective Swiss study, which encompassed both outpatients and inpatients, the mean FEV1 decrease was 106 mL [1\u2022]. Some earlier studies found a high co-occurrence of ACR during CARV (64\u201382 %) [5, 14, 15], but a more recent retrospective study [16] as well as a critical review of this literature failed to confirm such an association [17].\n\nOf greatest importance is the impact of CARV upon the development of CLAD. One of the earliest reports found a 50 % rate of BOS (as CLAD is identified in the earlier studies) among LTR surviving paramyxovirus or adenovirus infections [8], while another [5] showed that within 18 months of parainfluenza infections, 32 % of LTR had developed BOS at a median time of 6 months after infection. Other centers [6] have noted that lower respiratory tract CARV infection was a risk factor for the development of BOS in the 6 months following infection. Paramyxoviruses, including both respiratory syncytial virus and parainfluenza virus, appear to more often cause lower tract disease and perhaps more severe disease [1\u2022], with up to 38 % of LTR with respiratory syncytial virus developing BOS [12]. Indeed, research [18] has suggested that paramyxovirus survivors were more likely to progress to BOS, but that overall having any symptomatic CARV episode was strongly associated with BOS within the year (25 % of LTR with CARV versus 9 % without CARV). A single center study with 259 LTR found that any CARV and or lower respiratory tract disease from CARV increased the hazards for BOS, but that lower respiratory tract CARV had a greater impact and statistical significance [19]. Most recently, another single center study of similar size also found that CARV, of which 85 % was lower tract disease, increased the risk of subsequent CLAD and that this risk was most pronounced within 3 months of the CARV episode [20\u2022\u2022].\n\nWe recently reviewed over 550 LTR at our center and categorized each CARV infection as either asymptomatic, symptomatic without positive chest X-ray, or viral pneumonia (symptomatic plus positive chest X-ray). Categorizing each CARV episode in this manner allowed us to answer the question, does CARV severity impact the risk of subsequent CLAD? Prior studies have suggested this, but not directly addressed it. At our center, viral pneumonia was significantly associated with CLAD (HR 3.94 [1.97\u20137.90], p < 0.01), while asymptomatic and symptomatic CARV were not (p = 0.98, 0.94 respectively) (Allyn, in press). Interestingly, we found no difference in our outcomes whether culture or newer PCR-based viral detection methods were used, perhaps because parainfluenza and adenoviruses were more likely to cause CLAD and were readily identified prior to PCR.\n\nThe lungs are a reservoir for cytomegalovirus (CMV) [32, 33], and reactivation within the lung allograft after transplantation is common, though less so in the current valganciclovir era [34\u201337]. Several studies have found an association between CMV pneumonitis and CLAD, while others have not. For example, Snyder et al. [38] found that treated CMV pneumonitis in the first 6 months was a risk factor for BOS. Tamm and colleagues [39], however, noted that treated CMV was not associated with BOS, nor were they able to find differences in survival based upon donor/recipient serostatus. CMV pneumonitis is associated with an inflammatory lung allograft environment, with elevated IL-6 [40] and CCL2/CCL5 [41, 42], with CCL2 levels being predictive of BOS. The effect of CMV reactivation or infection on the development of CLAD in the present era of prophylaxis remains to be fully defined.\n\nEpstein-Barr virus (EBV) is a herpesvirus that once contracted remains permanently resident within the host, reactivating from time to time, particularly when there is a diminution of the cellular immune system required for viral control. Reactivation of EBV and shedding of EBV both within the lung allograft and blood occurs in approximately 40\u201350 % of LTR [43, 44], but its reactivation has thus far not been definitively associated with a subsequent increased risk of CLAD [36, 45]. A survey of 385 LTR found that having one or more blood samples positive for EBV by PCR increased the risk of subsequent BOS, but the role of immunosuppression on the reactivation of the EBV was not examined [43]. In a related study, this same group was not able to demonstrate that EBV reactivation in the blood was associated with BOS development, but the median follow-up time was only 17 months, limiting their power to detect BOS [44]. Neurohr et al. [34] looked at EBV reactivation within the lung allograft, along with HHV6 and CMV, and noted that recent treatment for ACR was associated with EBV BALF positivity, but interestingly found HHV6 reactivation, not EBV, to be an independent risk factor for BOS and death.\n\nRecently, there has been interest in the role of the torque teno midi virus anellovirus in lung transplantation [46]. In the studies to date, there has been no significant correlation of anellovirus and the allograft outcomes of ACR or CLAD [47, 48].\n\nFungal colonizations and infections after lung transplantation are common, and the majority are due to Aspergillus species. Single center studies report 1-year colonization rates of between 10 and 30 % for Aspergillus [49\u201351, 52\u2022\u2022]. A multicenter study found a cummulative 1-year incidence for invasive fungal infections of 8.6 % [53], the vast majority of which were due to Aspergillus species.\n\nSome, but not all, studies have shown an association between Aspergillus colonization and an increased risk of subsequent BOS (CLAD). The earliest study of the effect of fungal infections on the development of BOS noted that both bacterial and fungal infections, as well as acute cellular rejection (ACR), were associated with the development of BOS in 161 LTR [54]. Gram-positive bacteria and fungal infections (largely Aspergillus spp.) held the greatest risk. Subsequent to this, Weigt et al. [55] established Aspergillus colonization as a risk factor for subsequent BOS in their single center study of 171 LTR. In this cohort, 31 % of patients either developed colonization or invasive infection due to Aspergillus, with Aspergillus fumigatus being the most frequently encountered species (58 %). In their multivariate model containing ACR and Aspergillus colonization as covariates, both were found to increase the subsequent risk of BOS and death due to BOS. In a follow-up validation study utilizing the data from 780 patients from both Duke University and UCLA, Weigt and colleagues [56\u2022] categorized pre-BOS Aspergillus colonization according to the diameter of the conidia into large or small (\u22643.5 \u03bcm) species. Small conidial species included A. fumigatus, A. nidulans, A. terreus, and A. flavipes. In the multivariate Cox model, small conidial species colonization, but not large species, was associated with both subsequent BOS and death at both centers and in the combined cohort [56\u2022].\n\nContrary to the above studies, Peghin [51] recently published their single-center experience with life-long inhaled Ambisome prophylaxis against invasive fungal disease and did not find that Aspergillus colonization was a risk factor for CLAD in the over 400 LTR followed. Quite the opposite, they found that CLAD was a risk for Aspergillus colonization or infection (HR 24.4, CI 14\u201342). It should be noted that this was a study that retrospectively reviewed the incidence and risk factors for Aspergillus isolation in patients that were on life-long inhaled prophylactic therapy and that the rate of Aspergillus colonization at 15 % was nearly half that seen in either of the Weigt studies, which may have reduced their ability to find an effect of Aspergillus upon subsequent CLAD. It is also possible that life-long Ambisome inhalation decreases the risk of CLAD development from Aspergillus colonization.\n\nAccepting that at least small conidial Aspergillus colonization is a risk factor for subsequent CLAD, what can be done to reduce this risk? The use of life-long inhaled Ambisome has reduced the risk of both colonization and subsequent CLAD derived from Aspergillus in one study [51]. However, this was not definitively demonstrated in their study, in part because we do not know if in their pre-Ambisome era Aspergillus colonization was a risk factor for CLAD. Mansh et al. [52\u2022\u2022] reviewed voriconazole use in 455 LTR and found that voriconazole use reduced colonization by 50 % (CI 0.34\u20130.72), as well as all-cause mortality in those colonized by 66 % (CI 0.13\u20130.91). However, there was also an increased risk of squamous cell carcinoma of 73 % (CI 1.04\u20132.88) with any exposure to voriconazole, while there was no associated risk with either inhaled Ambisome or posaconazole. They did not report on risk factors for CLAD in their cohort.\n\nThe report by Peghin suggests that long-term inhaled Ambisome prophylaxis may reduce overall rates of colonization and invasive disease. However, the second Weigt study found that inhaled amphotericin compounds for prophylaxis may favor colonization by small conidial species (HR 1.34, CI 0.95\u20131.96). If this is the case, inhaled amphotericin may not be without risk. Despite the apparent effectiveness of universal voriconazole prophylaxis [52\u2022\u2022, 57], the established risks and complications of chronic voriconazole increasingly suggest that it has a limited role in routine prophylaxis [52\u2022\u2022, 58]. Further studies are required to confirm whether other azoles or inhaled Ambisome can reduce the rate of CLAD due to Aspergillus colonization.\n\nAs early as 1993, Horvath et al. [59] noted that two-thirds of pulmonary infections in LTR were bacterial, and subsequent investigations confirmed that over 80 % were bacterial in origin [60\u201362]. Gram-negative bacteria make up the majority of bacterial infections, with Pseudomonas aeruginosa being the most frequently isolated, between 25 and 58 % of the time [54, 63\u201365]. At our center, like others, Staphylococcus aureus is the most frequent gram-positive bacteria isolated in 14 to 30 % of cases (15 % of our recipients) [54, 59, 62, 64\u201366].\n\nBecause of the tremendous infectious burden imposed by both Ps. aeruginosa and S. aureus bacteria in LTR, many investigators have explored the association between posttransplant bacteria and transplant outcomes. In 2009, Gottlieb et al. [64] examined the effect of gram-negative bacterial colonization, of which 73 % were Pseudomonas, in 59 LTR with cystic fibrosis and noted that a loss of colonization was protective against the development of BOS by Cox modeling. Gupta et al. [67] and Valentine et al. [54] both found that infections due to gram-positive bacteria increased the hazard risk for BOS development. These data suggest that both gram-positive and gram-negative, mostly S. aureus and Ps. aeruginosa, respectively, infection or colonization was likely to increase BOS risk.\n\nTo better understand if such an association is plausible, it is important to understand the effect of bacterial infection upon the respiratory tract. Animal model and in vitro studies demonstrate significant inflammatory responses by airway epithelial cells (AEC) to stimulation by both Pseudomonas and Staphylococcus [68]. Moreover, toll-like receptors (TLR) are expressed by a variety of airway cells including dendritic cell, macrophages, and AEC, and respond to a broad range of pathogens. CD14 is part of the TLR4 receptor complex, along with MD2, and soluble CD14 is itself more abundant in lung allografts. Soluble CD14 enhances the binding of TLR4 to the lipopolysaccharide (LPS) of gram-negative bacteria and the lipoteichoic acid of gram-positive bacteria. A single nucleotide polymorphism within recipient TLR4 that is associated with decreased sensitivity of TLR4 was found to be protective against ACR [69]. Pseudomonas itself can preferentially cause CD4 T cell activation and proliferation, via exoenzymes such as exotoxin-A, though such exoenzymes may require preprocessing by an appropriate antigen presenting cell [70, 71]. Pseudomonas causes an accumulation of lymphocytes in the perivascular space and stimulates T cells to produce both IFN-\u03b3 and IL-1, both of which have been associated with allograft rejection. Indeed, Yamamoto [72] showed in a murine orthotopic lung transplant model that tolerance can be broken by Pseudomonas infection and that neutrophils from Pseudomonas-infected (but not from uninfected) mice co-stimulate T cells via CD80/86 interactions with CD28 (CTLA-4). Borthwick et al. [73] showed that Pseudomonas may have a role in enhancing epithelial to mesenchymal transition, possibly via interaction with TLR. These findings suggest that Pseudomonas in particular may enhance or induce an alloimmune response within the lung allograft, thereby providing a potential mechanism for induction of ACR and potentially CLAD.\n\nWithin the human lung allograft, both gram-positive and gram-negative organisms are accompanied by BALF neutrophilia, but only gram-negative organisms are associated with increased levels of the ELR+ chemokine CXCL8 and decreased lung function (as measured by FEV1) [74\u201377]. An interaction between Pseudomonas and Staphylococcus and the CXCR1/2 chemokine/ligand axis is particularly relevant for lung transplantation. The ELR+ chemokines (CXCL1, CXCL5, CXCL7, CXCL8) are chemotactic for both neutrophils and lymphocytes expressing CXCR1 or CXCR2 [78]. CXCR1+ lymphocytes have been found more frequently in the blood of cystic fibrosis patients than noncystic fibrosis patients [77], suggesting that chronic colonization with Pseudomonas and or Staphylococcus promotes expansion of CXCR1+ lymphocytes. Pseudomonas infection or colonization within the lung allograft may promote activation and migration of lymphocytes into the lung allograft. Furthermore, damage to the lung allograft epithelium, as could be caused by Pseudomonas or Staphylococcus infection or colonization, leads to increased HLA-DR expression by AEC [79\u201381]. AEC also release soluble class I HLA after stimulation by IFN-\u03b3 via a metalloproteinase-dependent pathway [82]. Pseudomonas or Staphylococcus may therefore both directly damage the lung allograft epithelium, while also recruiting lymphocytes that may recognize nonself proteins, potentially leading to expansion of the pool of alloreactive lymphocytes and persistent allograft damage.\n\nOur recent work examining the lung allograft response during ACR shows a severe inflammatory response that involves both the adaptive and innate immune systems [83]. Episodes of ACR demonstrated elevation of the innate pathway molecules TLR2, MYD88, \u03b2-defensin, and surfactant, as well as DMBT1, the latter of which is upregulated by LPS of gram-negative bacteria [84]. Innate immune pathways including phagosomes, hepatocyte growth factor, and nitric oxide signaling are involved in the host response to bacterial invasion and epithelial damage [85]. Activation of EIF-2 and Rac signaling during ACR was apparent, suggesting that the upstream pathways of PI3K, MMP2 and 9, and IL-13 were upregulated during ACR. These pathways suggest potential mechanistic links between ACR and fibrotic CLAD [86].\n\nExamining Pseudomonas specifically, Vos et al. [87] evaluated the effect of Pseudomonas colonization upon BOS in 92 LTR. Patients were considered colonized if (1) they had \u22652 consecutive Pseudomonas-positive samples after the first three postoperative weeks with between 4 weeks and 6 months between samples, and (2) patients had to be \u201cclinically stable\u201d at the time of Pseudomonas-positive samples, thus not with an active infection. In a Spearman univariate analysis, Pseudomonas \u201ccolonization\u201d was an important risk factor for BOS, but in a multivariate logistic regression, it only trended toward significance (p = 0.06) in this small cohort. That same year, Botha et al. [88] also published their experience with Pseudomonas in 155 LTR. Colonization was also the condition of interest, as opposed to infection, and colonization was split into two categories: \u201cde novo\u201d colonization meant no Pseudomonas isolation prior to transplant, while \u201cpersistent\u201d colonization meant isolation of Pseudomonas both before and after transplant. It was not clear how intervening infection by Pseudomonas was handled, and it should be noted that of the 64 patients with Pseudomonas colonization, 73 % had cystic fibrosis. Using a Kaplan-Meier survival analysis, de novo colonization after transplantation was shown to increase the risk of BOS. Of the 20 patients with de novo colonization for whom the risk of BOS was increased, it seems that very few had cystic fibrosis, while of the 44 LTR with persistent colonization, only two were without cystic fibrosis. In describing the microbiome of 57 Australian postlung transplant patients, 50 % of whom had cystic fibrosis, Willner et al. [89] suggested that Pseudomonas recolonization of the allograft in cystic fibrosis patients is protective against BOS. These findings argue that Pseudomonas recolonization in cystic fibrosis patients after transplantation may not be harmful. In response to the Botha study, Vos et al. [90] reanalyzed their initial data, splitting their cohort into persistent and de novo colonization and found nearly the exact opposite; of those colonized, persistent colonizers did worse and most had cystic fibrosis.\n\nMany chronically colonized patients, especially those with cystic fibrosis, harbor mucoid Pseudomonas strains. In a comparison of mucoid versus motile Pseudomonas strain effects on AEC, both increased production of ELR+ chemokines, although the mucoid strains were not as activating as were motile Pseudomonas strains [91]. Examination of mRNA transcripts of AEC from cystic fibrosis and noncystic fibrosis patients after stimulation with Pseudomonas strain PAO1 confirmed that both mutant and nonmutant AEC saw increases in ELR+ chemokine production. However, mRNA for IL-8/6 did not increase until after 48 h in mutant AEC, and mutant AEC were less responsive to stimulation by Pseudomonas, probably because of increased basal chemokine/cytokine production [92].\n\nA murine study to evaluate effect of \u201cearly\u201d versus \u201clate\u201d mucoid and nonmucoid Pseudomonas strains from cystic fibrosis patients measured virulence in part by ELR+ chemokine production [93]. All strains had the same pulse field gel electrophoresis patterns, with the nonmucoid strains demonstrating decreased virulence over time, while the mucoid strains demonstrated increasing or stable virulence over time. Significantly, only mucoid strains were able to inflame the distal airways (via migration), while nonmucoid strains remained in the central airways. In a study of 446 cystic fibrosis patients, Aaron et al. [94] found that acquisition of the transmissible \u201cLiverpool\u201d strain resulted in increased risk of death and lung transplantation over those patients with unique/nonepidemic strains of Pseudomonas.\n\nDrug resistance may play a role in strain-specific effects. Interestingly, Shteinberg et al. [95] found that the hazard for development of BOS was increased in those with quinolone-resistant bacteria compared to those individuals either with quinolone-sensitive (HR 3.7) or no gram-negative bacteria (HR 3.6) after transplantation.\n\nTogether these findings suggest that either strain-dependent differences or de novo colonization by a novel strain are associated with worsening of lung function. However, Walter et al. [96] and many others have found no significant alterations by dominant colonizing Pseudomonas strains from before or after transplantation, begging the question, are particular strains bad before transplant, but good after?\n\nIn the largest study to date on Pseudomonas and lung transplantation, we took a decidedly different approach and employed Markov analysis to determine state-specific effects of Pseudomonas on lung transplantation. Markov analysis allowed for determination of specific hazard rates for each covariate in each \u201cstate\u201d transition, the first being a healthy posttransplant state with movement to the (second) BOS state. That is, we measured the risk that each covariate yielded in moving from a healthy condition without BOS to one with BOS. By classifying each Pseudomonas isolation episode as either a colonization or infection, we were able to separate the effects of these two conditions. Importantly, unlike prior studies, we took into account the inflammatory environment of the allograft as measured by the CXCR1/2 ligand chemokine axis [97\u2022\u2022]. Movement to the BOS state was significantly influenced by Pseudomonas infection, but not colonization, with a dependence upon CXCL1 BALF levels. Together, the presence of Pseudomonas and elevated levels of CXCL1 increased the risk of BOS, with higher levels of CXCL1 further augmenting the risk (HR 3.3). Significantly, increases in BALF CXCL5 concentrations were independently associated with subsequent BOS risk, as was Aspergillus isolation and ACR episodes (in a dose-response manner).\n\nUsing a similar approach, we investigated the effect of Staphylococcus aureus isolation on lung allograft function [66]. Interestingly, we found that S. aureus was only a risk of subsequent BOS when CXCL5 was present in the allograft. CXCL5 levels increased the subsequent risk of BOS in the presence or absence of S. aureus, but the presence of Staphylococcus augmented its effect by 8.8 % (HR 1.09 per 100 pg/mL versus HR 1.01). Indeed, the negative effect of Staphylococcus was present only when concentrations of CXCL5 were \u22651200 pg/mL. In this slightly different model and cohort, overall, Pseudomonas (colonizations and infections) were significantly associated with subsequent BOS (HR 1.89), as was ACR. Thus, in our studies of both Staphylococcus and Pseudomonas, we were able to better understand the relationship between bacterial infection/colonization and subsequent CLAD by considering the allograft\u2019s inflammatory state.\n\nColonization and infection with respiratory pathogens can result in a severe inflammatory environment within the lung allograft. Whether this inflammation is the result of such infections, it appears very likely that a persistent inflammatory environment is the underlying cause of progression to CLAD. Despite the significant immunosuppression postlung transplantation, a tremendous inflammatory environment is found during ACR, and after CARV in the form of DAD. Findings with both Pseudomonas and Staphylococcus, and perhaps with viruses, do suggest that the underlying allograft inflammatory milieu is at least as important a determinant of the graft fate as is the infection. Pathogen-specific prophylactic interventions may be effective at reducing their occurrence posttransplantation and their impact on CLAD, such as with CMV. Yet, while prophylactic strategies that reduce Aspergillus colonization rates exist, the impact of these interventions on subsequent development of CLAD remains to be determined. Targeted antibiotic therapy, whether inhaled or systemic, or surgical intervention, such as sinus surgery, may help to reduce the burden of bacterial colonization in those colonized, but such strategies are unlikely to have great impact upon those not already colonized. The etiology of CARV is so diverse as to preclude the use of virus-specific interventions to prevent allograft damage and therefore CLAD. Thus, identifying LTR at greatest risk for infections that predispose to CLAD should be a priority, along with appropriate risk reduction strategies, such as via individualized immunosuppression. Further studies are required to illuminate the mechanisms by which infectious organisms promote the generation of CLAD, allowing us to implement novel therapies directed not solely at the pathogen, but simultaneously at deleterious allograft responses to these pathogens."}