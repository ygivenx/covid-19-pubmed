{"title": "A multivariate threshold stochastic volatility model", "body": "It is a stylized fact that financial data exhibit changes in volatility over time and these changes tend to be serially correlated. A popular model for modeling this changing variance property is the autoregressive conditional heteroscedastic (ARCH) model introduced by Engle [17] and is extended to generalized ARCH (GARCH) by Bollerslev [6] . An alterative volatility modeling strategy is the stochastic volatility (SV) model, originated by Taylor [34] . Although GARCH models have been the main stream in the industry to model financial assets, many research papers have documented advantages of using SV models, including Harvey et al. [19] , Jacquier et al. [21, 22] , Kim et al. [23] , Danielsson [13, 14] and So et al. [31] . Readers can refer to Ghysels et al. [15] and Shephard [28] for more extensive review of SV models.\n\nSince the first multivariate SV (MSV) model proposed by Harvey et al. [19] , theoretical researches on MSV models class have been conducted. The extension to multivariate class enables us to analyze the financial returns across different securities and markets. The knowledge of returns correlation structure is vital in many financial applications, especially in risk management. Furthermore, it enhances statistical inference and volatility forecasting. For example, So et al. [32] introduced a MSV model that can explain any lead-lag relationship of the volatility structure. Asai and McAleer [3] considered two types of asymmetric MSV model. Asai and McAleer [4] developed a dynamic correlation MSV model. Basic MSV models have been modified to capture different features of financial data or to reduce the dimensionality of the parameter space. Factor MSV models were built up to handle high dimension financial data [10, 12] . So and Kwok [30] developed a multivariate long memory SV model, which was showed to be more consistent with empirical stylized facts than traditional MSV models. Detailed reviews and comparisons on MSV models are given in Danielsson [14] , Asai and McAleer [2] and Yu and Meyer [38] .\n\nAsymmetry effect in volatility of financial assets means different responses in volatility to good and bad news. In particular, bad news tends to increase future volatility more than good news does. A popular explanation of such asymmetry is the leverage effect given by Black [5] and Christie [11] , in which asymmetric SV and MSV models were developed on the basis of the leverage effect [1, 2, 8, 20] . Empirical results in Asai and McAleer [1, 3] suggested that multivariate models are more preferable than univariate models in modeling asymmetry. Besides, the asymmetry effect can also be modeled using thresholds structure. This has been studied in the time series and univariate GARCH literature extensively [16, 26, 35, 36] . Recently, a multivariate threshold GARCH model with time-varying correlations has been proposed by Kwan et al. [24] . In the univariate SV literature, So et al. [33] proposed a threshold SV (THSV) model, in which the asymmetry effect is modeled through a threshold setting that the autoregressive parameters in the SV equation change according to the sign of the previous returns. The THSV model successfully captures the mean and variance asymmetries simultaneously, and was demonstrated through the strong evidence of asymmetries in the empirical data. However, the multivariate extension of the model has not been developed in the literature. This paper aims to fill this gap.\n\nThe THSV model is developed from the stochastic volatility model proposed by Taylor [34] . Asymmetric effect in variance is modeled through the threshold setting that the two regimes are determined by the sign of lagged returns. In addition, the model also considers the mean asymmetry since the dependence on the sign of previous returns in the magnitude of returns was discussed in the literature [25] . Under these considerations, the THSV model incorporates a threshold type of model structure into the autoregressive dynamic of both returns and volatility as follows:\n\nA multivariate THSV (MTHSV) model is developed based on this model. The lack of a closed form expression of the likelihood function makes the estimation of the parameters of SV models being a major topic in the literature. Many estimation methods developed for univariate SV models have been extended to be applicable in multivariate cases, including Quasi-Maximun Likelihood [30] , Simulated Maximum Likelihood [14] , as well as Markov Chain Monte Carlo (MCMC) [8, 10, 31, 33, 37] . MCMC methods are also applied in this paper.\n\nThe rest of this paper is organized as follows. Section 2 introduces the MTHSV model and discusses the methodologies and procedures of the Bayesian analysis of the model. Section 3 discusses the parameter estimation of our model. Section 4 presents a simulation experiment to study the effectiveness of our Bayesian estimator. An empirical analysis on three stock market indices is presented in Section 5. A conclusion is given in Section 6.\n\nLet r t = (r 1t , r 2t , . . . , r kt ) be the k-dimensional time series of interest. In practice, the row of r t represents different security returns in a portfolio. If one would like to investigate the relationship among different stock markets, the row of r t would be the market indices. One major advancement in this paper is to allow different time series structure in r t based on recent changes in a threshold variable. By doing this, we can use extra information to determine the time evolution of returns and volatility. We define a set of Bernoulli random variables s t by\n\nwhere z t is the threshold variable. In general, z t can be a function of the k-dimensional return variable r t or any exogenous variable. The MTHSV model is given by the following equations:\n\nwhere u t and \u03b7 t are stochastically independent multivariate white noise processes, y t = (y 1t , y 2t , . . . , y kt ) and \u03b1 t = (log h 1t , log h 2t , . . . , log h kt ) . This MTHSV model generalizes the MSV model in Harvey et al. [19] to allow the coefficient matrices 0s t , 1s t , 0s t+1 and 1s t+1 to depend on z t . Then, the mean and volatility asymmetries can be incorporated in the SV modeling while accounting for the interdependence among security returns. Following So et al. [33] , we parameterize 0s t , 1s t , 0s t+1 and 1s t+1 as\n\nThe k \u00d7 1 vectors 0 , , 0 , and the k \u00d7 k matrices 1 , C, 1 , D are unknown parameters to be estimated. To facilitate further discussion, we use the following notations h t = (h 1t , h 2t , . . . , h kt ) , H t = (h 1 , h 2 , . . . , h t ) , R t = (r 1 , r 2 , . . . , r t ) , S t = (s 1 , s 2 , . . . , s t ) and Y t = (y 1 , y 2 , . . . , y t ) for the rest of the paper. In particular, the conditional variance of y t , i.e. Var(y t |H t ) isH t = diag{h 1t , h 2t , . . . , h kt }. The model specification in (2) implies that r it are uncorrelated time series. In dealing with real market returns data, we suggest doing the pre-whitening by principle component analysis to make possible correlated r it become uncorrelated. Specifically, letr t be financial returns at time t and (\u03bb 1 ,\u00ea 1 ), (\u03bb 2 ,\u00ea 2 ), . . . , (\u03bb k ,\u00ea k ) be the eigenvalue-eigenvector pairs of the sample covariance matrix of the pre-transformed returnsr 1 ,r 2 , . . . ,r n and\u00ea = (\u00ea 1 , . . . ,\u00ea k ) . Then, we obtain r t =\u00ear t which is fitted to the MTHSV model in (2) . This pre-whitening step will help us capture the time-varying correlation of financial returns.\n\nIn the risk management point of view, it is important to model the time-varying correlations among different time series because the correlations play an essential role in measuring portfolio risk. In order to understand the relationship in different time series, we compute Corr( r at , r bt |H t , R t\u22121 , \u03b8), the conditional correlation of r at and r bt given H t and R t\u22121 for a, b = 1, . . . , k, under the MTHSV model. Consider the mean equation in (2) and the principle component transformation r t =\u00ear t . Since the inverse of\u00ea,\u00ea \u22121 =\u00ea always exists, we can transform the mean equation back t\u00f5 r t =\u00ea 0s t +\u00ea 1s t r t\u22121 +\u00ea y t . Let (\u00ea ) a be the a-th row of\u00ea . For 1 \u2264 a, b \u2264 k,\n\nTherefore, we have the conditional correlation given by\n\nSimulation techniques described in Section 3 were adopted to estimate the smoothed correlation Corr (s) ( r at , r bt ), which is defined as the posterior mean of Eq. (3).\n\nIn the Bayesian analysis of the MTHSV model, MCMC technique is adopted and the implementation is outlined in this section. Let \u03b8 denote a vector of all unknown parameters including \u03b7 , 0 , , 1 , C, 0 , , 1 and D. We begin with the full conditional density of unknown variables. Let \u03c9 = [r 0 , H n , \u03b8 ] be the variable of interest. Following the idea in the derivation of the univariate case in So et al. [33] , the multivariate version of the full conditional density is derived as\n\nAccording to Liu et al. [27] , parameters convergence will be slow if highly correlated parameters are treated individually. As a result, it is suggested to treat highly correlated parameters as a block in order to speed up the convergence rate. In this paper, we use the same grouping of parameters as in So et al. [33] , since it is believed that high correlation within the parameter groups still exist in the multivariate case. The three groups for \u03b8are: the first group is the mean equation parameters 0 , , 1 , C; the second group is the variance equation parameters 0 , , 1 , D; and the last group is \u03b7 . The mean and variance parameters can be sampled from their full conditional densities directly, which are extracted from (4) . With the use of conjugate priors, the multivariate normal prior induces a multivariate normal conditional density. Therefore, the sampling of the mean parameter and variance parameters is quite straightforward since they are sampled from well known distributions. Similar idea is also applied in the drawing of r 0 . Full details are provided in the Appendix A.\n\nIf we drew \u03b7 directly from its full conditional density, the speed of convergence would be slow since H n is a latent variable of the MTHSV model. According to Liu et al. [27] , integrating out H n can speed up the convergence. Therefore, \u03b7 is drawn from f ( \u03b7 |\u03b8 \u2212 \u03b7 , r 0 , R n ) instead of its full conditional density to enhance the convergence. To facilitate the sampling, symmetric random-walk Metropolis algorithm is applied here. If we draw the covariance matrix \u03b7 directly in the Metropolis step, boundary problem occurs and results in a slow convergence. To avoid this problem, it is proposed to draw the correlation matrix \u03b7 of \u03b7 and its variance components separately in two Metropolis steps. Let\n\nbe the corresponding correlation matrix.\n\nLet \u03c3 denote (log \u03c3 11 , log \u03c3 22 , . . . , log \u03c3 kk ) , and \u03c3 (i) be the i-th candidate. At the i-th iteration, simulate a new iterate \u03c3 (i+1) according to the k-dimensional normal transition probability function\n\nand accept the new iterate \u03c3 (i+1) with acceptance probability\n\nOtherwise, set \u03c3 (i+1) = \u03c3 (i) . S 1 is the step size that controls the size of a Metropolis step. In order to have fast convergence, the optimal acceptance rate from our experience is between 0.2 and 0.5. The acceptance probability can be computed by noting that\n\nIt can be shown that the conditional distribution of Y n , f (Y n |\u03b8) can be computed by one pass of the Kalman Filter [18] under the Gaussian state space model in Eq. (5).\n\nRe-construct the element of the upper triangular matrix of \u03b7 into \u03c1 = (\u03c1 12 , \u03c1 13 , . . . , \u03c1 k\u22121,k ) . Similar to the drawing of \u03c3, the M-H step for sampling \u03c1 is implemented by drawing a new candidate \u03c1 (i+1) from a k(k \u2212 1)/2-dimensional multivariate normal with mean zero and covariance S 2 , and accept the new candidate with probability\n\n) .\n\nAn uniform prior for \u03c1, i.e. f (\u03c1) = I(A), where A is the event of that \u03b7 is positive definite and I(.) is an indication function.\n\nIt remains the drawing of the latent variable H t to complete the MCMC sampling scheme. As originated in Shephard and Pitt [29] , multi-move sampler is an efficient tool for sampling latent state variables in non-Guassian univariate state space models and it enhances the convergence as compared with a single-mover sampler [21] . In order to use the multi-move sampler, the MTHSV model has to be formulated into a partial non-Gaussian multivariate state space form. Let \u03d5 t = (log y 2 1t , log y 2 2t , . . . , log y 2 kt ) and \u03b5 t = (log u 2 1t , log u 2 2t , . . . , log u 2 kt ) . The rather complicated distribution of \u03b5 it , log \u03c7 2 1 , can be approximated by a mixture of normal distributions, i.e. f (log u 2 it ) \u2248 P j=1 q j f (log u 2 it |\u03b3 it = j), where log u 2 it |\u03b3 it = j \u223c N k (\u03bc j \u2212 1.2704, \u03c4 j ), q j = Pr(\u03b3 it = j), \u03b3 it is a discrete mixing variable having values from 1 to P and P = 7 is selected in this paper as suggested in Kim et al. [23] . Since the rows of \u03b5 t are independent, the distribution of \u03b5 t can be described by k independent log \u03c7 2 1 random variables. The drawing of \u03b3 t can be done directly through its full conditional density with the use of an independent normal conjugate prior. Given the \u03b3 t 's and under the normal mixture approximation, the state space form of the MTHSV model can be written as follows:\n\nwhere\n\nAdopting the idea of applying the multi-move sampler for multivariate state space models in Carter and Kohn [7] , we decompose f (\u03b1 1 , \u03b1 2 , . . . , \u03b1 n |\u03b3 1 , \u03b3 2 , . . . , \u03b3 n , \u03b8, Y n ), the conditional joint density of \u03b1 1 , \u03b1 2 , . . . , \u03b1 n into f (\u03b1 n |\u03b3 1 , \u03b3 2 , . . . , \u03b3 n , \u03b8, Y n ) n\u22121 t=1 f (\u03b1 t |\u03b1 t+1 , \u03b3 1 , \u03b3 2 , . . . , \u03b3 n , \u03b8, Y t ).\n\nTherefore we can draw the state vectors from \u03b1 n to \u03b1 1 sequentially. After running the Kalman filter one time, the optimal estimator for the state vector and its MSE matrix, A t and P t , for t = 1, . . . , n, are generated. Conditioned on \u03b3's , \u03b8 and Y t , it can be seen that (\u03b1 t , \u03b1 t+1 ) follows a multivariate normal distribution and the Kalman filter gives the following full conditional distribution of (\u03b1 t , \u03b1 t+1 ) |\u03b3 1 , . . . , \u03b3 n , \u03b8, Y t N 2k\n\nA t\n\n1s t+1 P t 1s t+1 P t 1s t+1 + \u03b7 .\n\nUsing the formula of conditional distribution for multivariate normal variable, \u03b1 t | \u03b1 t+1 , \u03b3 1 , . . . , \u03b3 n , \u03b8, Y t follows the k-dimensional normal with\n\nfor t = n \u2212 1, . . . , 1.\n\nAs a result, with the i-th MCMC iterate H (i) t , the conditional correlation Corr( r at , r bt |H (i) t , R t\u22121 , \u03b8 (i) ), 1 \u2264 a < b \u2264 k can be evaluated for i = M + 1, . . . , M + N accordingly. Then, the following Monte Carlo estimator of the smoothed correlation Corr (s) ( r at , r bt ),\n\ncan be obtained.\n\nIn this section, we will illustrate the proposed Bayesian estimation through a simulation study. Time series of length n = 4000 are simulated from a three-dimensional model (k = 3). The parameters are chosen according to empirical stylized facts and presented under 'True values' in Table 1 . For example, \u03b7 is set so that the implied correlations of the volatility series are reasonably large, in which The mean parameter matrices 0 s t and 1 s t have small magnitude in their entries to reflect the weak autoregressive dynamic in financial returns. We also select 10 to have large diagonal values to indicate high persistence in volatility in the lower regime (s t = 0). The diagonals of 10 are larger than that of 11 to incorporate the empirical fact that usually the lower regime has higher persistence in volatility [9] . The weighting of the threshold variables were selected Table 1 Sample means of the posterior mean for the 2 regimes based on 100 simulation replications so that the contribution of each of the three returns are nearly the same,\n\nSimulated data of sample size n = 4000 are generated for 100 independent replications. For each replication, M + N = 10000 iterations are carried out with the first M = 2000 burn-in iterations discarded before analyzing the posterior distribution. We investigate the properties of the posterior mean estimator in Table 1 which presents the sample mean of the 100 posterior mean estimators, together with the corresponding standard errors computed by the sample standard deviations of the 100 posterior means. The mean of the posterior mean estimators are close to their respective true values, indicating that the biases of estimation by the posterior means are small. In fact, we observe very close estimates from both posterior mean and median on the average. Moreover, all standard errors are reasonably small. In summary, the experiment evidents that both posterior mean and posterior median can provide us reliable estimates for the unknown parameters in the MTHSV model.\n\nThe data we use for empirical analysis are daily closing price of three major market indices, namely SP500 of US, FTSE100 of UK and Hang Seng Index (HSI) of Hong Kong. All data are obtained from Datastream International dated from 3 July 1985 to 30 June 2005, giving a total of 5165 return observations. The daily return is defined as the log-difference of the index price, y t = (log p t \u2212 log p t\u22121 ) \u00d7 100, where p t is the closing price at time t and \"log\" in the formula is the natural logarithm. Typical volatility clustering feature with some spikes of high volatility that may be explained by market crashes or well-known financial events can be observed from the plot of the three daily return series 1 . From the summary statistics of the returns data in Table 2 , highest correlation is observed between the returns of SP500 and FTSE100 (0.413), and the least is between SP500 and HSI (0.154). Besides, the data also exhibit standard properties of asset returns time series, including close to zero sample mean, negative sample skewness and excess sample kurtosis. One of the key issues before executing the MCMC scheme for the empirical data is to decide the threshold variable. A reasonable choice is the lagged one daily return of SP500 since the US stock market plays a major role in the world market movement. We define the lower regime (s t = 0) and the upper regime (s t = 1) by the lagged one SP500 return less than and greater than zero respectively. It turns out that 47% and 53% of the returns are in the lower and upper Table 3 Posterior mean estimates and the respective posterior standard deviations of the parameters for the empirical application Table 2 , which presents summary statistics of returns in the two regimes, it is observed that the variance of the three indices are all higher for the lower regime than that for the upper regime. The correlation structure of the three time series is also quite different when the US market goes up rather than going down. The above findings give supportive evidence of the mean and variance asymmetry that a threshold volatility model should be necessary.\n\nAs discussed in Section 2, we first perform the pre-whitening on the three-dimensional return vectorr t , in which the three entries represent the return of SP500, We then fit the MTHSV model in (2) to r t using the Bayesian method in Section 3. To implement our MCMC sampling scheme for the empirical data, 100000 iterations are preformed, with the first 20000 burn-in iterations being discarded. Table 3 reports the posterior mean and the corresponding standard derivation (in parentheses) of the parameters for the two regimes. The eigenvalues (in descending order) of 1 s t and 1 s t are also given in the table. To explore the mean asymmetry implied by the model, we reproduce the mean equation ofr t as in the lower and upper regimes. It is evident that the coefficients in the autoregressive matrix are predominantly negative in the lower regime with magnitude larger than that in the upper regime. Therefore, clear mean asymmetry is documented from the MTHSV parameters. From Table 3 , we can observe clear variance asymmetry from the different values in 0 s t and 1 s t for different s t . In fact, the largest eigenvalue of 1 s t in the lower regime is substantially larger than that in the upper regime, indicating that the variance in the lower regime is more persistent. This kind of persistence asymmetry has not been documented in the literature.\n\nIn this subsection, we analyze the time-varying correlation Corr (s) ( r at , r bt ) among the three indices. In the subsequent discussion, we let Corr(r 12 ), Corr(r 13 ) and Corr(r 23 ) be the smoothed correlation between the daily returns of SP500 and FTSE100, SP500 and HSI, FTSE100 and HSI, respectively. Fig. 1 displays the plot of the three correlations. The mean along the horizon are 0.347, 0.069 and 0.163 respectively. The result seems reasonable as the highest correlation is found between the returns of SP500 and FTSE100, with no negative correlation segment. In the plots of the correlations, we have highlighted three segments that are worth analyzing.\n\nThe first segment covers the period from 1985 to 1992. A spike in the correlations is observed during the 1987 worldwide crash, Black Monday. The impact of the Black Monday on Hong Kong market emerged when the Hong Kong exchange was re-opened after four-day closing. HSI fell dramatically for more than 40% on that day and the corresponding correlations (Corr(r 13 ), Corr(r 23 )) rise quickly to the local maximum levels of 0.183 and 0.364 respectively. The second spike happened on 5 June 1989 when Corr(r 13 ) and Corr(r 23 ) suddenly jumped to high points, which are the global maxima along the horizon. In fact, it is not surprising to have such high correlation, since HSI dropped dynamically for 582 points on that day.\n\nThe second segment covers the period from December 1992 to March 1996. During this period, Hong Kong market exhibited high correlation with the US and UK market. Under the prospective economy in the 1990s, speculation in the stock market was a rising atmosphere, which was indicated by the high turnover in this period. Besides, as the negotiation of Hong Kong 97 handover issue became increasingly intensive during this period, investors were very sensitive to the political relationship among Hong Kong, China and Britain. The first two local peaks of Corr(r 13 ) and Corr(r 23 ) in this period are likely due to the political reason of the handover issue. To conclude, the reasons for the high correlation period are the increasingly close financial relationship with the US and UK market.\n\nThe third segment is from October 1997 to August 1998. The first extraordinary high correlation time period is attributed to the 1997 Asian financial crisis that affected Hong Kong and other markets from October 1997 to around January 1999. It caused a highly correlated period among all three series. Negative values in Corr(r 13 ) and Corr(r 23 ) are recorded from April 2002 to August 2003. We divide this period into two parts to discuss: April 2002-October 2002 and March 2003 -June 2003. The main cause for the first part can be the September 11 incidence in 2001. Its economic impact on the US market was critical. On the contrary, the shadow of the incidence did not affect the Hong Kong and China markets much. During this period, the China economy was expanding quickly, from which Hong Kong benefited a lot. The opposite situation caused the negative correlations between the returns of HSI and SP500. In the second part, the US economy revived gradually, however, the SARS (severe acute respiratory syndrome) outbreak in Hong Kong causes Corr(r 13 ) and Corr(r 23 ) still being negative. The SARS induced a serious economic consequence to Hong Kong. As there were only rare cases of SARS in US and UK, the effect to their economy was insignificant and thus making the HSI returns negatively correlated with the SP500 and FTSE100 returns.\n\nIn this paper, we introduce a multivariate threshold stochastic volatility model to incorporate both mean and volatility asymmetries in financial time series. We also derive how to estimate dynamic correlation in the series. Bayesian estimation by MCMC is demonstrated to be effective and reliable. When applying our model to real data, we confirm the evidence of the asymmetries from the model parameter estimates. We also identify asymmetry in the volatility persistence. From the MTHSV modeling, the estimated dynamic correlation help us understand the interdependence of US, UK and HK stock markets in the past twenty years.\n\nwith N 2k+2 (\u03bc 0i , 0 i ) being the prior distribution of \u03b2 i and Bayesian results on regression give \u03b2 i |\u03b8 \u2212\u03b2 i , r 0 , H n , R n \u223c N 2k+2 (\u03bc p i , p i ), where\n\nFor the sampling of the variance parameters, we let \u03b2 i = [ i0 , i , ( i1 , . . . , ik ) , (D i1 , . . . , D ik ) ] , i = 1, . . . , k, and \u03b2 = (\u03b2 1 , \u03b2 2 , . . . , \u03b2 k ) . Observe that the term f (h 1 |\u03b8, r 0 ) in (4) has little effect on the joint conditional posterior density. By neglecting this term, we have f (\u03b2|\u03b8 \u2212\u03b2 , r 0 , H n , R n ) \u221d n t=2 exp \u22121/2(\u03b1 t \u2212 0s t \u2212 1s t \u03b1 t\u22121 ) \u22121 \u03b7 (\u03b1 t \u2212 0s t \u2212 1s t \u03b1 t\u22121 ) f (\u03b2).\n\nUsing multivariate regression results, the joint conditional density is proportional to\n\nwhere (\u03b2 1\u03b22 \u00b7 \u00b7 \u00b7\u03b2 k ) = (X X) \u22121 X Y , thus we derive\u03b2 = (\u03b2 1 ,\u03b2 2 , \u00b7 \u00b7 \u00b7 ,\u03b2 k ) , = \u03b7 \u2297 (X X) \u2212 1 s n log h 1,n\u22121 log h 2,n\u22121 \u00b7 \u00b7 \u00b7 log h k,n\u22121 s n log h 1,n\u22121 s n log h 2,n\u22121 \u00b7 \u00b7 \u00b7 s n log h k,n\u22121\n\nIncorporating the prior distribution of N k(2k+2) (\u03bc 0 , 0 )I(A 2 ), where A 2 represents the domain constraint for the variance parameters that all elements of | 1 s t | < 1 and the absolute value of diagonal elements of 1 s t are larger than the corresponding off-diagonal elements in the same row, (7) is proportional to\n\nTherefore, we have \u03b2|\u03b8 \u03b2 , r 0 , H n , R n \u223c N k(2k+2) (\u03bc p , p ), where p = ( \u22121 + \u22121 0 ) \u22121 , \u03bc p = p ( \u22121 \u03bc + \u22121 0 \u03bc 0 )."}