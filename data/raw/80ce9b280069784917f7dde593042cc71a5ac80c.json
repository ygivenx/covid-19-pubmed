{"title": "Pathogen Removal from Wastewater during Groundwater Recharge", "body": "solid wastes, and sewage oxidation ponds. Additional sources of pathogens in groundwater may involve artificial recharge of groundwater aquifers with renovated wastewater including deep well injection, spray irrigation of crops and landscape, basin recharge, and land application of sewage effluent and sludges. Leakage of sewage into the groundwater from septic tanks, treat ment lagoons, and leaky sewers is estimated to be over a trillion gallons a year in the United States [6] .\n\nIt should be realized that, as opposed to surface water pollution, con tamination of groundwater is much more persistent and is difficult to erad icate. Because restoration of groundwater quality is difficult, time-consuming, and expensive, efforts should be made for the protection of groundwater quality rather than only for its restoration after degradation.\n\nSecondary sewage treatment including disinfection by chlorination may not be able to remove all of the pathogens present in sewage. Thus, intentional or unintentional recharge of groundwater with treated sewage effluent may be potentially hazardous to human and animal life.\n\nSoil is considered a living filter, capable of removing pathogenic mi croorganisms from applied wastewater. The extent to which soil can remove these microorganisms depends on several factors such as the nature of the soil, the nature of the pathogen concerned, temperature, and antagonism from native microflora. Because of their large size, parasitic protozoa and helminths may be efficiently removed by filtration through soil and may not be able to gain entrance into the groundwater.\n\nBacterial removal by soils also occurs largely by filtration, although adsorption is also involved. Viruses, on the other hand, are thought to be removed by the process of adsorption only [7] . Unfortunately, however, viruses cannot be considered as permanently immobilized because they have been shown to elute and migrate further in soil following rainfall events [8] [9] [10] .\n\nSeveral investigators have reported on the isolation of viruses from groundwater [11] and several outbreaks of viral hepatitis, yersiniosis, ty phoid, and shigellosis have also been attributed to contaminated groundwater [1] . Documented evidence of health problems associated with groundwater recharge is, however, lacking.\n\nThe paucity of information on health problems associated with groundwater recharge programs may reflect either the absence of a problem, lack of intensive surveillance, or the insensitivity of present epidemiologic tools to detect recurrent small-scale incidents of disease. Often the low fecal car riage rates of agents of infectious disease and the low background of enteric disease in the United States has been cited as further evidence that the potential of public health hazard as a result of direct or indirect reuse of wastewater is minimal. It should be realized, however, that levels of enteric disease in the United States are low primarily because of good sanitation, personal hygiene, and a network of sanitary engineering works. As a result of this low exposure to pathogens, the population at large may have become highly susceptible to even small numbers of pathogens.\n\nWaterborne outbreaks of disease are no longer on the decline in this country (Figure 9 .1). A total of 50 waterborne outbreaks occurred during 1980, increasing the annual average of outbreaks to 39 for the 5-year period from 1976-1980. This number represents more than a 50 percent increase over the 1971-1975 average of 24. The 5-year averages have steadily in creased from an annual average of ten during [1951] [1952] [1953] [1954] [1955] . Before that pe riod, the trend was declining [12] .\n\nIt should be emphasized that reporting of waterborne disease out breaks, particularly in individual systems, is notoriously poor. According to Craun [1] outbreaks in municipal water systems, which number 40,000 and serve about 177 million people, are probably the most likely to be reported. Outbreaks in semipublic systems, which number about 200,000 and serve numerous transients, are the next most likely to be reported. The least likely to be reported are the outbreaks in individual water systems, which number about 10,000,000. In fact, one third of the individual groundwater supplies in a rural neighborhood of Oregon were found to be fecally contaminated in a recent survey [13] .\n\nWaterborne hypothesis cannot be proved in all instances because epidemiologic investigations are sometimes incomplete or conducted long after the outbreak has subsided. Also, the surveillance of waterborne diseases by the Centers for Disease Control (CDC) is largely passive and clearly rep resents a fraction of the total number that occur. According to CDC, \"the likelihood of an outbreak coming to the attention of health authorities varies considerably from one locale to another depending largely upon consumer awareness, physician interest, and disease surveillance activities of state and local health and environmental agencies. Large interstate-outbreaks and outbreaks of serious illness are more likely to come to the attention of health authorities.\"\n\nOf 673 documented outbreaks of waterborne disease from 1946 to 1978, 425 (63%) were attributed to illness of probable viral etiology (e.g., hepatitis A, poliomyelitis, gastroenteritis). This number probably represents only a fraction of the actual number of virus-caused outbreaks, because of the difficulties involved in proving a viral etiology of a waterborne outbreak. In fact, direct evidence of virus involvement in waterborne outbreaks is limited to hepatitis A, adenovirus, and recently to Norwalk agent and rotavirus [3] .\n\nThe lack of documentation of waterborne viral disease outbreaks may be ascribed to limitations in methodology for the detection of viruses in water and relative insensitivity of epidemiologic techniques to detect lowlevel transmission of viral diseases through water. It is easy to recognize the outbreaks of infectious hepatitis by the water route because of their explo sive nature and characteristic symptomatology. Most enteric viruses, how ever, cause a wide variety of symptoms so that scattered cases of acute illness would probably have too varied symptoms to be attributed to a single etiologic agent. Also, the presence of small numbers of viruses in water may result only in an inapparent infection in a person coming in contact with contaminated water. The virus may then multiply in the respiratory and gastrointestinal tract of that person who may, in turn, act as an effective carrier and transmit the virus to others. The development of acute disease in these contact persons will be epidemiologically classified as \"transmitted by direct contact\" rather than being waterborne. Intensive surveillance is, therefore, necessary to determine the \"real\" cause of an outbreak.\n\nA discussion on epidemiology is incomplete without consideration of minimum infective dosage of various microorganisms. Infective doses of most bacterial pathogens are relatively high. For instance, approximately 10 8 enteropathogenic Escherichia coli or Vibrio cholerae cells must be con-sumed by healthy male volunteers to produce disease in a significant pro portion of subjects. In case of Shigella, however, 10-100 cells are enough to cause dysentery. Similarly, the infectious dose of protozoan cysts and helminth ova is very low, perhaps 10. The symptoms of helminth infections are dose-related, however. Currently available information suggests that even a single virus particle may produce infection under favorable condi tions. After reviewing infective dose data for various microorganisms in human subjects, Akin [14] reached the conclusion that infective dose for some members of bacterial, viral, and parasitic groups may be as low as =^10 detectable units.\n\nPathogenic microorganisms such as bacteria, viruses, protozoa, and parasitic worms are almost always present in domestic sewage. The number and types of organisms present in sewage, however, vary from community to com munity depending on urbanization, population density, sanitary habits, sea son of the year, and rates of disease in the contributing community [15] .\n\nThe most common bacterial pathogens associated with sewage are Salmonella, Shigella, Vibrio, and Campylobacter (Table 9 .1). Salmonella occurs [17] . Since 1973, however, 31 cases of cholera have been documented along the Gulf Coast. The strains from all these cases appear essentially identical, suggesting that the toxigenic V. cholerae 01 has persisted in that region for at least 8 years. Extra efforts should, therefore, be made to keep track of this potential problem.\n\nMore than 110 different virus types may be present in raw sewage (Table 9 .2). They range in size from about 27 nm for polio virus to 70 nm for rotavirus and up to 100 nm for enteric coronavirus. All virus groups found in sewage contain single-or double-stranded RNA except adenoviruses, which consist of double-stranded DNA. These viruses are capable of causing a variety of illnesses at very low dosage levels [14] . The amount of virus present in raw sewage is highly variable but as high as 500,000 infec tious virus particles per liter have been detected [18] .\n\nStudies indicate that bacteria and viruses are not removed effectively from wastewaters during primary treatment [19] ; removal of viruses during secondary treatment (active sludge) is dependent largely on virus adsorption to solids. Since rotavirus adsorbs poorly to activated sludge floes, it can be speculated that wastewater treatment processes that are highly effective in the removal of enteroviruses may not be as effective in removing rota and reoviruses. Even within the enterovirus group, virus adsorption to activated sludge was found to be both type-and strain-dependent [56] . It stands to reason, therefore, that different viruses will have different removal char acteristics during activated sludge treatment.\n\nAn average of 90 to 95 percent of the enteric bacteria in sewage are reported to be removed by activated sludge process (Table 9 .3). Coagulation with alum or lime is considered to be generally efficient for virus removal. In laboratory studies, 3-4 log reduction of viruses is common following lime treatment at pH 11. In field studies, however, viruses were isolated from lime sludge and lime-treated effluent [20] . Other tertiary treatments such as ferric chloride-polyelectrolyte flocculation, sand or granular filtration, re verse osmosis, and carbon adsorption have been found to significantly re duce the level of pathogens.\n\nFeachem et al. [21] reviewed the literature on pathogen removal by various sewage treatment processes. removal, but to look at orders of magnitude.\" They further stated that to talk of percent removal is misleading because a 99 percent removal of path ogens from raw sewage containing 10 5 pathogens per liter will produce an effluent that still contains 10 3 pathogens per liter. This level may still be of great public health concern, depending on how the effluent is going to be used. As efficient as it may be, sewage treatment processes cannot be ex pected to remove/inactivate all of the pathogens present. Disinfection of treated wastewater is, therefore, practiced to ensure further inactivation of microorganisms. In the United States, chlorination is practically the only process used for disinfection of wastewater. Unfortunately, however, there is a great variability in resistance to chlorine among different microorga nisms. It is generally agreed that bacteria are much more susceptible to chlorine than are viruses and protozoan cysts. Also, chlorine may be very [21] . effective against mircoorganisms cultivated in the laboratory under artificial conditions, but it may not be as effective on naturally occurring strains of bacteria and viruses.\n\nThe fate of pathogenic bacteria and viruses in the subsurface will be deter mined by their survival and their retention by soil particles. Both survival and retention are largely determined by the three factors shown in Figure  9 .2. Climate will control two important factors in determining viral and bacterial survival: temperature and rainfall. The survival of microorganisms is greatly prolonged at low temperature; below 4\u00b0 C they can survive for months or even years [18] . At higher temperatures, inactivation or dieoff is fairly rapid. In the case of bacteria, and probably viruses, the dieoff rate is approximately doubled with each 10\u00b0 C rise in temperature between 5\u00b0 C and 30\u00b0 C [22] . Above 30\u00b0 C temperature is probably the dominant factor determining virus survival time. Rainfall mobilizes previously retained bac teria and viruses and greatly promotes their transport in groundwater. Sev eral studies have shown that the greatest degree of drinking water well contamination occurs after periods of heavy rainfall [23] [24] [25] .\n\nThe nature of the soil will also play a major role in determining survival and retention. Soil properties influence moisture-holding capacity, pH and organic matter-all of which will control the survival of bacteria and virus in the soil. Other soil properties such as particle size, cation exchange ca pacity, and clay content will influence retention. Resistance of microorga nisms to environmental factors will vary among different species as well as strains. Bacteria are believed to be removed largely by filtration processes while adsorption is the major factor controlling virus retention [18] .\n\nThe following sections are a summary of the recent state of knowledge on factors currently believed to influence microbial persistence and transport in the subsurface.\n\nThe straining or filtration of bacteria at the soil surface is a major limitation in their travel through soils. When suspended particles, including bacteria, accumulate on the soil surface, as water passes through the soil these par ticles themselves become the filter [26] . Such a filter is capable of removing even finer particles, by bridging or sedimentation, before they reach and clog the original soil surface. This phenomenon will in fact largely be dom inant if only a portion of the suspended particles are larger than the pore openings. As soon as a few such particles have accumulated, they become the straining surface for finer particles [26] .\n\nIn studies in which E. coli suspended in distilled water was allowed to percolate into sand columns, Krone [26] found that after the first arrival of bacteria the concentration in column effluents continued to rise until a max imum was reached, after which it fell, suggesting that accumulating bacteria at the soil surface enhances the straining removal.\n\nThis same effect is seen during the land application of domestic sewage when repeated cycles of flooding and drying of infiltration basins is practiced [27] . For example, at the Flushing Meadows Project near Phoenix, Arizona, treated sewage effluent is spread into basins underlaid with loamy sand. The greatest numbers of coliforms and fecal coliforms are observed after the start of each new inundation period when newly infiltrated water arrives at the bottom of sampling wells, after which time a general decrease in values occurs. A similar phenomenon occurs when water containing microorga nisms is pumped into recharge wells.\n\nStudies using sandy soils of various effective porosities indicate removal of bacteria from a liquid percolating through a given depth of soil is inversely proportional to the particle size of the soil. The greatest removal of bacteria occurs on the surface mat (top 2-6 mm) that forms on the soil.\n\nAdsorption is the major factor in the removal of viruses by soil and also plays a role in bacterial removal. Factors that reduce the repulsive forces between the two surfaces, such as the presence of cations, would be ex pected to allow closer interaction between them and allow adsorption to proceed. The very small size of clays, their generally platy shapes, the oc currence of large surface area per given volume, make them ideal adsorption sites for bacteria and viruses in soils. Thus, adsorption phenomena will play a more important role in the removal of microorganisms in soils that contain clays [26] . Many factors are known to control microbial adsorption to soils and these are listed in Tables 9.4 and 9.5.\n\nSoils differ considerably in their textural, chemical, and mineralogical prop erties and hundreds of soil types have been classified in this country [28] . Furthermore, both vertical and horizontal variability is a normal character istic of many soils. It is generally agreed that fine-textured soils retain mi croorganisms more effectively than sandy soils since the soil clay mineral fraction displays a high sorptive capacity toward viruses as a result of its high surface area and ion-exchange capacity. Following examination of nine [94] .\n\nsoils from Arkansas and California, it was shown that virus adsorption in creased with the clay content and the specific surface area of the soil [29] . Iron oxides, particularly magnetite, also display a high affinity toward viruses [30] . Hori et al. [31] found that polio virus removals from distilled water in 6-in columns of three Hawaiian soils, including two low-humic latosols (Lahaina and Wahiawa) and a volcanic cinder (Tantalus), averaged >99, >99, and 22 percent, respectively. With the two low-humic latosols, there was a trend of decreased retention over the 5-day test period. Goyal and Gerba [32] noted considerable differences in the abilities of nine different soils to adsorb a number of enteric viruses. Statistical analysis indicated that pH was the most important soil characteristic influencing virus retention, with soils having a pH <5 giving consistently high retention. Exchangeable alu minum was another factor that correlated with the adsorption efficiency of In contrast to these findings, Wang et al. [35] and Lance et al. [36] found greater removal of poliovirus in sandy soils than total and fecal coliforms, and fecal streptococcus. But the lowest removal was observed with coliphage f2 [35] , indicating that virus type plays a significant role in the extent of virus removal. Additional studies are needed on the relative re moval of bacteria and viruses by soil types.\n\nMoore et al. [37] recently reported that poliovirus type 2 adsorption to 34 different soil materials suspended in a synthetic freshwater was neg atively correlated with soil organic matter content and with available neg ative surface charge as measured by adsorption capacity for a cationic polyelectrolyte. Soil pH, surface area, and elemental composition were not significantly correlated with virus adsorption. Furthermore, additional stud-ies by this same group indicated that the two poorest adsorbents for both poliovirus and reovirus among 34 different soil materials were a muck soil and a silt loam, both of which had high organic matter content [37] . These authors were also able to show a highly negative correlation between virus adsorption and the capacity of soils to bind a cationic polymer, PDADM (polydiallyldimethyl ammonium chloride). It was suggested that the ability to bind the polymer could serve as an indicator of the extent of viral ad sorption [37] .\n\nThe results of these studies indicate that soil type greatly influences the extent of virus transport or retention. It may be possible to distinguish soils by general class with respect to virus retention, based on their textural, mineralogic, and chemical properties. However, further studies with a wide range of soil types and viruses are needed to determine if such classifications are possible and to identify the soil characteristics that most influence virus retention.\n\nThe effects of pH on virus adsorption to soils are explainable on the basis of electrochemical features of virus and soil surfaces. The surface charge of a virus is influenced primarily by ionization of the carboxyl and amino groups on the outer surface of the virion protein capsid; and at neutral pH, most viruses are negatively charged. Soils also tend to be generally electronega tive at neutral pH; therefore, virus adsorption is not favored due to repul sion of the two negatively charged surfaces. However, if the pH of the surrounding medium is lowered, protonation causes decreased ionization of virion carboxyl groups and increased ionization of amino groups. As a re sult, viruses become less electronegative or even electropositive at lower pH levels.\n\nAlthough soil particles will also tend to become more electropositive at lower pH levels, the isoelectric points of soil particles are generally lower than those of viruses. For example, electrophoretic mobility studies have shown that a common soil clay mineral, montmorillonite, is negatively charged at pH 4.5 to 10.5. Muck soils also have a high negative charge [38] . At lower pH levels, the viruses may be electropositive but the soils are still electronegative, thereby resulting in electrostatic attraction and increased adsorption. The relationship between virus adsorption and pH is not clearcut, however, because of many complicating factors. The pH of the soil, as conventionally measured, does not reflect necessarily the pH at the surface of soil colloidal particles such as clays. Various soil components (clay, sand, oxides of aluminum and iron) display different isoelectric points. There is also a lack of information on the isoelectric points of more than 100 viruses that occur in wastewater or groundwater. So far, we know that the isoelectric point varies with virus type and strain [38] [39] .\n\nThe results of a number of studies indicate that virus retention by soils generally increases at lower pH levels. In an early report Drewry and Eliassen [29] found decreased bacteriophage Tl, T2, and f2 adsorption to Ar kansas and California soils at higher pH levels. More recently, Burge and Enkiri [33] found that the rates of bacteriophage 0X174 adsorption to five soils were significantly correlated with soil pH. In batch adsorption studies with a variety of viruses and nine soils by Goyal and Gerba [32] , pH was found to be the single most important soil factor influencing adsorption. Soils having a saturated pH less than 5 were the best adsorbers. Studies by Sobsey et al. [34] showed that poliovirus type 1 and reovirus type 3 adsorp tion to eight different soil materials suspended in settled sewage at pH levels between 3.5 and 7.5 was generally greater at the lower pH levels. In studies by Duboise et al. [40] with cores of sandy forest soil receiving poliovirus in sewage effluent at various pH levels between 5.5 and 9.0, virus retention was best at pH 5.5, and the release and migration of retained viruses by subsequent distilled water applications was lower from the cores that re ceived sewage effluent having lower pH values. Similar observations have been made for bacteria [41] .\n\nThe types and concentrations of ionizable salts in the soil-water environment greatly influence the extent of bacteria and virus transport. In general, in creasing concentrations of ionic salts and increasing cation valencies enhance virus adsorption. Divalent cations (e.g., Ca 2+ , Mg 2 + ) are very efficient in promoting virus adsorption to a sandy soil [42] . Cations are necessary to reduce the repulsive forces on both the virus and soil particles and allow adsorption to take place. Viral and bacterial retention by soils is generally greater in the presence of sewage effluents than in distilled water [40] [41] .\n\nWastewater effluents have indeed higher conductivity (500-600 fxmhos/ cm) than distilled water (2-10 fxmhos/cm) or rainwater (20-40 |xmhos/cm). Rainwater, being of lower conductivity than sewage effluents, may thus lead to reduced viral and bacterial adsorption or to desorption with the subse quent redistribution of these organisms within the soil profile. This phenom enon was well demonstrated via soil core studies under controlled laboratory conditions [8, 34, 40, 41] . Landry et al. [43] showed that virus penetration was more extensive in rainwater-rinsed cores than in wastewater-rinsed cores. Moreover, the desorbed viruses may readsorb at greater depths. Heavy rainfall might then remobilize soil-bound viruses with the potential contam ination of groundwater supplies [10] . However, it now appears that the ability of rainwater to release viruses depends on the soil type, the release being more pronounced in sandy than in clay soils [34] . The elution pattern also depends on the virus type and strain. For example, poliovirus 3 and echovirus 6 were mobilized by artificial rainwater, whereas echovirus 1 was not affected. The elution pattern of the reference strain of poliovirus 1 differed from that of field and mutant strains [9] .\n\nRainfall will also effect bacterial retention by lowering ionic concen tration and increasing infiltration rates. Several surveys have indicated that rainfall and well depth are related to microbial groundwater quality. Studies in Washington indicated that shallow drinking water wells average medium coliform values of 8 MPN per 100 ml with an average depth of 9.4 m (31 ft), while deep wells with an average depth of 153.3 m (503 ft) average 4 MPN per 100 ml [15] . It was also observed that virtually all bacterial con tamination coincided with the periods of heaviest rainfall. Brooks and Cech [44] observed in rural eastern Texas that practically all dug wells with depths of 50 ft (15 m) or less were positive for either fecal coliforms or fecal strep tococci. While presence of fecal bacteria was much less common in deeper wells, some wells as deep as 250 ft (80 m) were positive. Increased levels of bacterial contamination of drinking well water after periods of rain have been noted in several studies [23] [24] [25] 45] . In one study, it was noted that while an increase in coliform bacteria appears almost immediately after periods of heavy rainfall in shallow wells, in deeper wells the increase did not occur until 2 weeks later [46] . Thus, any satisfactory study of well water quality should include sampling during periods of highest rainfall.\n\nSoluble organic materials are known to compete with viruses and bacteria for adsorption sites. It may then be possible that organics present in sewage may interfere with virus sorption to soils. However, several studies have shown that viruses are well adsorbed to various types of soils in the presence of secondary and even primary wastewater effluents. As discussed above, wastewater effluents contain enough salts to overcome any interference by soluble organic matter.\n\nHumic and fulvic acids are highly colored organic compounds that are naturally present in both water and soils. Recent studies indicate that these compounds can cause increased virus transport through soils not only by interfering with virus adsorption but also by causing desorption. Bitton et al. [48] found that poliovirus retention by columns of sandy soil was exten sively reduced when applied in highly colored (high concentrations of humic and fulvic acids) cypress dome water compared to its retention from tap water. More recently, Scheuerman et al. [49] reported extensive interfer ence by humic and fulvic acids with poliovirus type 1 retention in columns of organic sediment, muck soil, and brown-red sand. Soils that were capable of retaining all or most of the applied virus in the absence of these organics retained considerably less virus in their presence. The extent of virus trans port through the columns correlated with the color of the column effluents. This phenomenon was confirmed by Bixby and O'Brien [50] , who re ported that fulvic acids complex MS2 phage and prevent its adsorption to soil. More recently, such soils were found to display a lower adsorption capacity than other mineral soils [34, 37] .\n\nThe results of a number of studies suggest that organic soils and other soils or waters with high concentrations of humic and fulvic acids may not be suitable for land application of wastewater. The effects of other organics in waters and soils on virus retention remain uncertain. Additional studies are needed to further understand and quantify the effects of humic and fulvic acids in water and soil on the infectivity and retention of a variety of viruses in different soils. Such studies are also needed for other classes of water, wastewater, and soil organics.\n\nHydraulic conditions in soils receiving wastewater appear to have a consid erable effect on virus transport for at least some soils. Such conditions as flow rate, hydraulic loading, and application frequency may all influence the extent of virus migration through soils. Vaughn et al. [51] reported that infiltration rate greatly influenced poliovirus removal in a groundwater re charge system where tertiary effluent was applied to a coarse sand-fine gravel soil. Recharge at 75 to 100 cm per hour resulted in considerable virus movement into groundwater while at two lower recharge rates, 6 and 0.5-1.0 cm per hour, there was considerably less virus movement. At the lower infiltration rates, the surface mat of sewage solids that formed on the soil surface may have contributed to the greater virus removals observed. Lance et al. [8] found that poliovirus type 1 removal was not affected by infiltration rates in the range of 15 to 55 cm per day. More recently Lance and Gerba [52] found that increasing flow rates from 0.6 to 1.2 m per day resulted in increased movement of viruses down the column. However, there was no further increase in virus movement at flow rates up to 12 m per day.\n\nIn comparative studies of several soils it was found that by linear regression analyses, the rate of virus removal in soil columns was negatively correlated with the flow rate of the percolating sewage effluent [53] . The authors suggested that flow rate of water through the soil may be the most important factor in predicting the potential virus movement into groundwater.\n\nLittle virus movement has been observed in unsaturated soil columns [54] . Although the results of at least some studies suggest that virus migra tion increases with increasing hydraulic loads and flow rates and under con ditions of saturated flow, further studies are needed with a wide range of soil types and field conditions to quantify the extent of virus movement through soils under different hydraulic conditions.\n\nRecent studies have shown that different types and strains of viruses are not equally retained by soils. These virus-specific differences in adsorption to soils are probably related to physicochemical differences in virus capsid surfaces. Although all enteric viruses possess outer capsids comprised of polypeptide subunits and generally behave as charged, amphoteric, colloidal particles, the surfaces of the virions differ in the details of their configura tion, charge density and distribution, and other features. In fact, even the same virus can display different surface properties that will influence its physicochemical behavior as a result of conformational changes brought about by pH effects and interactions with soluble chemicals and particulate surfaces [55] .\n\nGoyal and Gerba [32] found that different enteric virus types and strains varied in their ability to adsorb to soils. For example, adsorption efficiencies of six different strains of echovirus type 1 in suspensions of sandy soil in deionized water ranged from 0 to 99.7 percent. Type and strain dependence of enterovirus adsorption to a sandy loam soil suspended in distilled water was also reported in another study from the same laboratory [56] . Adsorp tion efficiencies of ten different virus types and strains ranged from 0 percent for echovirus type 1, strain V239, and Coxsackie virus B4, strain V216, to 99.9 percent for echovirus type 7, Wallace strain, and poliovirus type 1, strain LSc. Landry et al. [9] reported type and strain differences in enter ovirus adsorption to sandy soil cores. Vaccine strain poliovirus type 1 (LSc), a widely employed enterovirus model in soil and other environmental stud ies, was efficiently adsorbed but not readily eluted with either distilled water or sewage effluent. Some of the other enteroviruses tested, including field strains, were less efficiently adsorbed and more easily eluted. It was con cluded that vaccine strain poliovirus type 1 may be an inappropriate model for studying the nature and extent of virus transport in soils.\n\nIn contrast to the findings from batch laboratory studies by the same group, Hurst et al. [57] found that under field conditions at a rapid infiltra tion site, echovirus type 1, Farouk strain, did not migrate as far down in the soil as poliovirus type 1, strain LSc. They suggested that the adsorptive behavior of viruses in laboratory batch studies may not be totally reflective of their behavior under field conditions, possibly because of virus adsorption to soil particles prior to infiltration.\n\nIt is now agreed that poliovirus type 1 adsorbs well to most soils. It was recently concluded that viruses may be grouped into three categories according to their adsorptive behavior [39] . Category 1 contains the poorly adsorbed viruses (echovirus 1, echovirus 11, Coxsackie virus B4, 0X174, MS2) and category 2 includes the highly adsorbed viruses (poliovirus 1, echovirus 7, Coxsackie virus B3, T2, and T4). Phage f2 was placed in a third category exhibiting the lowest adsorption of all viruses tested.\n\nAt the turn of the century, it was found that the eating of raw vegetables grown on soil fertilized with raw sewage resulted in outbreaks of typhoid fever. As a result, the survival of enteric bacteria in soil systems has been extensively studied. There are several major reviews on the survival of en teric bacteria in soil [58] [59] [60] , and we will only consider herein factors that affect the length of survival of these bacteria. Less is known about virus survival. Most enteric bacterial pathogens dieoff very rapidly outside of the human gut, whereas indicator bacteria such as E. coli will persist for longer periods of time. Survival times among different types of bacteria and viruses vary greatly and are difficult to assess without studying each type individ ually. In most cases, it appears that 2 to 3 months is sufficient for reduction of pathogenic to negligible numbers once they have been applied to the soil, although survival times as long as 5 years have been reported [59] . Factors known to influence bacterial and viral survival in the soil are listed in Tables 9.5 and 9.6.\n\nA major factor determining the survival of bacteria in soil is moisture. Young and Greenfield [61] showed that moisture was a factor in the viability of E. coli in soils. Beard [62] stated that moisture was the most important deter mining factor in the survival of Salmonella typhosa. Bacterial survival was determined in various types of soil exposed outdoors in clay flowerpots. The survival in all types of soil tested was found to be greatest during the rainy season. In sand, where drying was rapid due to its low moisture-retaining power, survival time was short-between 4 and 7 days during dry weather. In soils that retain a high amount of moisture such as loam and adobe peat, the organisms persisted longer than 42 days.\n\nBouma et al. [63] have suggested that survival data for fecal organisms could be compared with soil-moisture characteristic curves, and hence the distance of soil filteration necessary for removal be defined as a function of moisture content.\n\nSoil moisture also influences virus survival in soil. Bagdasar'yan [64] reported that enteroviruses survived three to six times longer in soils with 10 percent moisture content than in air-dried soils. Duboise et al. [5] found that poliovirus type 1 was inactivated considerably more rapidly in drying soil, as the moisture content decreased from 13 to 0.6 percent, than in the same soil type maintained at 15 or 25 percent moisture content. Inactivation of 99 percent of the initial viruses occurred within 1 week in drying soil but took 7-8 and 10-11 weeks in soils with 25 to 15 percent moisture content, respectively.\n\nYaeger and O'Brien [55] compared the degree of poliovirus inactiva- ? tion in eight different soils saturated with riverwater, groundwater, or septic wastewater and in the same soils that were allowed to dry out during the course of the experiment. Upon drying, none of the initial viruses was de tectable in any of the dried soils (>99.999% inactivation), but considerable quantities were still present in the same types of saturated soils. In experi ments on the rate of poliovirus inactivation at different soil moisture levels, there was a sharp increase in the inactivation rate at 1.2 percent soil moisture compared to that at 2.9 percent. Hurst et al. [66] also observed differences in poliovirus inactivation rates at different soil moisture levels, with the greatest inactivation rate at a moisture level of 15 percent. Inactivation proceeded more slowly at both higher and lower moisture levels, but the slowest inactivation rates were at 5 and 10 percent.\n\nIn a field study on virus survival in a rapid-infiltration system for wastewater, Hurst et al. [57] found that virus inactivation rates were greater in more rapidly drying soils. Allowing soils in rapid-infiltration systems to pe riodically dry and become aerated between wastewater applications en hances virus inactivation. The effects of both drying and aerobic microbial activity may contribute to virus inactivation under these conditions. In stud ies on the mechanisms of virus inactivation in soils, Yeager and O'Brien [55] found that the loss of poliovirus infectivity in moist and dried soils resulted from irreversible damage to the virus particles, including (1) dis sociation of viral genomes and capsids, and (2) degradation of viral RNA. In both moist and dried nonsterile soils, viral RNA was released from cap sids and found in a degraded form. In dried, sterile soils, viral RNA was released but remained largely as intact molecules. Viral capsid components were not readily recoverable from drying soils due to irreversible binding, but they could be recovered as empty capsids from moist soils. Further experiments with dried viruses showed that their capsids became isoelectrically altered. The results of these studies suggest that poliovirus and perhaps other viruses are inactivated by different mechanisms in moist and drying soils.\n\nTemperature is a major factor in the survival of enteric organisms in soil and other environments. Temperature affects chemical and biologic pro cesses in soils, which may indirectly affect the survival of enteric viruses and bacteria. S. typhosa may survive as long as 24 months at freezing temper atures [62] . Mirzoev [67] pointed out that in areas with prolonged winterse.g., the Russian Arctic-the processes of soil self-disinfection are slowed down or suspended. He showed that low temperatures (down to -45\u00b0 C) were very favorable for the survival of dysentery bacilli, which he was able to detect 135 days after it had been added to the soil. Van Donsel et al. [68] found that a 90 percent reduction in the number of fecal coliforms took 3.3 days in the summer and 13.4 days in the winter in exposed soil plots.\n\nBagdasar'yan [64] observed that viruses could survive up to 170 days in soil at 3 to 10\u00b0 C and that survival was higher at 3 to 10\u00b0 C than at 18 to 23\u00b0 C. Similar observations were made by Lefler and Kott [42] with regard to poliovirus type 1 and bacteriophage f2 survival in a sandy soil in Israel. Yeager and O'Brien [55] found that Coxsackie virus Bl inactivation rates in sandy loam soils suspended in riverwater, groundwater, and septic wastewater increased as temperatures were increased from 4 to 37\u00b0 C. In pilotscale outdoor studies on poliovirus persistence on vegetables and in soils irrigated with sewage effluent in Cincinnati, Ohio, Larkin et al. [69] and Tierney et al. [70] found that 99 percent inactivation in soils took about 2 months during the winter months and only 2 to 3 days in the warm summer months of June and July. In a field study by Hurst et al. [57] on virus survival and movement in a rapid-infiltration system for wastewater, the rate of inactivation of indigenous viruses was greater in the fall than in the winter, possibly due in part to the effects of higher temperatures in the former season.\n\nThe direct effects of ionic salts and pH on microbial survival in soils have been less extensively investigated than their effects on virus retention by soils. Hurst et al. [57] determined that virus inactivation in soils correlated with soil levels of resin-extractable phosphorous, exchangeable aluminum, and soil pH. Because these same factors also influence virus adsorption to soils, the observed differences in survival rates may be related to changes in the extent of virus adsorption to the soil material and, therefore, changes in the extent of virus protection from inactivation in the adsorbed state.\n\nBeard [62] also found that the death of S. typhosa was very rapid in peat soil with a pH between 3 and 4. Kligler [71] found that moist, slightly alkaline soils were the most favorable for the survival of S. typhosa. Cuthbert et al. [72] inoculated various peat (pH 2.9-4.5) and limestone (pH 5.8-7.8) soils held in the laboratory with E. coli and Strep, faecalis. They found that both organisms could persist for several weeks in the limestone soils, but would die out in a few days in acid peat soils. They felt that the low pH could act to adversely affect not only the viability of the organism but also the availability of nutrients or to interfere with the action of inhibiting agents.\n\nThe frequent addition of broth culture fluid to soil has been found to in crease the survival of S. typhosa [59] . Under field conditions, it has been found that some aftergrowth of E. coli and Strep, faecalis can occur, partic ularly after wet weather [68] . The survival of fecal coliforms is greatly ex tended in organic soils over that observed in mineral soils [73] . The extended survival and growth in organic soils may be due not only to the presence of organics but to the high moisture-holding capacity of these soils [73] .\n\nThe effects of organic matter on enteric virus survival in soils have not been established, but recent findings suggest that fulvic and humic acids may mask virus infectivity by a reversible process. Bixby and O'Brien [50] found that fulvic acid complexation of bacteriophage MS2 caused consid erable loss of infectivity and prevented adsorption to soil. The infectivity of the complexed phage could be restored by treating with 3 percent beef extract solution at pH 9.\n\nSoil moisture, temperature, pH, and the availability of organic matter can also indirectly influence the survival of enteric bacteria by regulating the growth of antagonistic organisms [68] . Bryanskaya [74] showed that actinomyces in soil were capable of suppressing the growth of salmonella and dysentery bacilli. In addition, the longer survival time of enteric organisms after inoculation into sterilized soil as compared to unsterilized soil found by a number of workers [59] indicates that antagonism is an important fac tor. Tate [73] observed that the protozoan population of a muck soil in creased dramatically after addition of E. coli and suggested that soil protozoa could play a significant role in the decline of these organisms in these soils. Since it is evident that enteric bacteria are capable of utilizing nutrients found in nature, it could be argued that competition by the natural soil microflora is in large part responsible for their eventual disappearance from the soil.\n\nBagdasar'yan [64] noted greater enterovirus inactivation in nonsterile than in sterile sandy and loamy soils, incubated at 3-10 and 18-23\u00b0 C. In more recent studies by Sobsey et al. [34] on rates of poliovirus and reovirus inactivation in eight different soil suspensions in settled sewage at 20\u00b0 C, the time required for 99 percent inactivation was almost always shorter in nonsterile than in sterile suspensions. Hurst et al. [66] observed increased inactivation of poliovirus and echovirus in nonsterile sandy soil wetted with distilled water and incubated under aerobic conditions at 23\u00b0 and 37\u00b0 C, compared to sterile control samples. However, inactivation rates in sterile and nonsterile samples were similar at 1\u00b0 C under aerobic conditions and at 1\u00b0, 23\u00b0, and 37\u00b0 C under anaerobic conditions. Thus, appreciable virus in activation due to microbial activity in soils appears to occur only under aerobic conditions and at moderate to high temperatures.\n\nAlthough the mechanisms of microbially mediated antiviral activity in soils have not been fully elucidated, Yaeger and O'Brien [55] have reported differences in poliovirus structural changes during inactivation in sterile and nonsterile soils depending on soil moisture level. In both sterile and non sterile soils under moist conditions, viral RNA was probably damaged be fore release from capsids. In sterile, dried soils released RNA genomes remained largely intact, but in nonsterile, dried soils the released RNA was degraded. The role of microbially produced nucleases in these findings is uncertain.\n\nData available indicate that viruses survive longer than bacteria in soil (Ta ble 9.7) [75] . Field and laboratory studies using McFeters's-type survival chambers indicate that enteric bacteria can survive from a few days to more [22] . than a month [76] [77] . It is also possible that under some conditions they could regrow in groundwater if sufficient nutrients are present. E. coli bac teria have been found to survive and even multiply on organic matter filtered out from lake water during underground recharge projects in Israel [78] . In some areas of Israel surface water during the rainy season is used to recharge the underground water supply. During those parts of the year when there is an increased need for water the same wells transformed to pumping wells. During such projects it was found that although the water pumped under ground contained less than 2 coliforms per 100 mL after chlorination, the repumped water contained counts as high as 10 5 -10 6 per 100 mL, which persisted for long periods of time after the initiation of pumping. Subsequent studies showed that organic matter that had accumulated in the sand around the well casing enabled the regrowth of the few remaining coliforms. Also of interest was the finding that so long as recharge continued, the bacteria did not multiply; it was only during the period between recharge and pump ing that growth occurred [79] .\n\nEnteroviruses have been detected at the surface of soils irrigated with sewage in the United States [80] . A field study revealed virus survival for at least 28 days in soil following application of a package treatment plant effluent in a cypress dome in Gainesville, Florida [10] . Other field studies confirmed the important role played by temperature and soil moisture in virus persistence in soils [57, 81] . Similarly, it appears that virus survival in sludge-amended soils is controlled primarily by desiccation and soil tem perature [69, 82] . During surface application of digested sludge on soils in Pensacola, Florida, it was shown that indigenous enteroviruses were able to survive only 9 days after sludge application [83] .\n\nA simple conceptual model based on the current state of knowledge on indicator and pathogen dieoff has been described by Reddy et al. [22] . Microbial dieoff was described by assuming first-order kinetics. First-order dieoff rate constants (k) were calculated from the literature for enteric mi crobial dieoff in soil-water systems. Correction factors were presented to adjust constants for changes in temperature, moisture, and pH of the soil. Average dieoff rate constants (log 1() /day _1 ) for selected microorganisms are shown in Table 9 .7. In the article by Reddy et al. [22] , data on dieoff of viruses during anaerobic digestion were used. Only data on virus dieoff in soil systems is shown in Table 9 .7. These values were obtained from various experiments and represent an average value of several soil and environ mental variables. Such an approach could prove useful for estimating mi crobial survival in soil-water systems, but a greater database is needed especially for viruses and other pathogenic bacteria. Also, most of our da tabase on microbial survival is in soil-water systems and not in groundwater.\n\nEven though there have been no reports of disease outbreaks associated with land treatment of wastewater, there are a growing number of studies concerning the detection of viruses in groundwater after wastewater appli cation to land or direct groundwater recharge. These studies are summarized in Table 9 .8.\n\nWellings et al. [10] demonstrated vertical and lateral movement of virus in secondary effluent discharged into a Cyprus dome (a wetland eco system). Poliovirus 1, Coxsackievirus B4, and echoviruses 7, 11, and 14 were recovered from 3 m-deep wells in three of 71 samples, at concentrations ranging from 4 to 353 PFU. Viruses migrated 7 to 38 m laterally from the application point and survived at least 28 days.\n\nThe soil at this site ranged from a top 0.6 m layer of black organic soil (4-12% clay) to a sandy clay and a solid blue clay with a permeability of 3 x 10\" 2 cm per minute to 3 x 10~6 cm per minute. Thus, the viruses moved horizontally as well as vertically and survived many days under ambient conditions, indicating a necessity to evaluate such sites for their aquifer movement and transmission of viruses to drinking water sources.\n\nIn an earlier study, Wellings et al. [84] recovered viruses from groundwater after spray irrigation of secondary sewage effluent onto an Imolokee sand (little or no silt or clay). Of particular interest in this study was that viruses survived chlorination, sunlight, spraying, and percolation through 3 to 6 m of sandy soil; furthermore, after a period of heavy rains, a burst of viruses was detected in samples that had previously been negative. These studies demonstrate that soil type, rainfall, and other factors can affect viral movement into groundwater, and that viruses are capable of surviving long periods-which, when combined with the ability to move long distances laterally, could lead to wide dispersal through an aquifer. Vaughn and Landry [85] and Vaughn et al. [86] reported isolations of viruses from four groundwater recharge sites, from a stormwater recharge basin, and from groundwater under a sanitary landfill in New York. These sites have soils of coarse sand, fine gravel, and 1 to 2 percent silt. At the groundwater recharge sites, viruses were recovered at depths up to 11.4 m and at distances up to 45.7 m from the injection point of secondary or tertiary chlorinated effluent. As much as 22 to 33 percent of the 100-gal samples at the four sites were positive for viruses, with concentrations of 1.3 to 10.6 PFU per gallon. In addition, total coliforms were found in these samples. In order to reach the groundwater, viruses moved through 5.5 to 9 m of the overlying soil.\n\nMoreover, at the 12 Pines site, viruses were discovered in groundwater under basins where effluent seeded with viruses was applied at rates of 6 to 100 cm per hour. The slower infiltration rates were more effective in re moving the viruses, suggesting that site management is important.\n\nBoth the landfill and stormwater recharge basin also yielded viruses. At the landfill stie, viruses were detected at depths of 22.8 m and up to 408 m downstream. Coxsackievirus B3 and other unidentified viruses were de tected. At the stormwater recharge site, samples taken at 9-m depths directly in the basin were positive for echoviruses 11 and 23 and for Coxsackievirus A6. This contamination may have originated from runoff from cesspools in the area.\n\nSchaub and Sorber [87] reported on a study of viruses in groundwater under rapid infiltration cells at Ft. Devens, Massachusetts. The soil consisted of silty sand and gravel underlaid by bedrock. The groundwater contained viruses at depths of 29 m and lateral distances of 183 m, with concentrations of about 8.3 percent of the applied effluent. Fecal streptococcal bacteria were also found in the 28.9 m-deep well. Marker f2 virus was applied at this same site; only about 50 percent of the virus was removed, and it was detectable for at least 11 days. This site was deemed to have poor filtration properties, which points out the need for site-specific evaluation.\n\nAt the Vineland, New Jersey, rapid-infiltration site [88] primary ef fluent was applied to Cohansey sand and coarse gravel. Viruses were found at 16.8 m depths and up to 250 m lateral distances in 19 of 40 samples. Polio-, echo-, and Coxsackie viruses were identified. Total coliforms and fecal coliforms were found consistently at depths up to 6 m beneath the recharge basins. Total coliforms also occasionally occurred at greater depths and downstream. In contrast, no fecal coliforms were found in samples taken below 9.1 m and coliforms occurred only once in a shallow well 50 m downgradient. Thus, viruses penetrated deeper into the ground and moved longer distances than did the coliforms.\n\nThe potential for viruses to migrate great distances, as in the previous study, was further demonstrated by Noonan and McNabb [89] , who used the phages 0X174 and T4 to demonstrate lateral movements of 140 m and 911 m, respectively, in New Zealand groundwater in just 96 hours. The viruses moved at greater than 300 m per day and survived for at least 7 days. In laboratory studies, 6.2 days were necessary for a 90 percent reduc tion in liter; so in this case, the viruses could theoretically travel at least 2.5 km in groundwater before a 90 percent reduction could be effected under these conditions. Viruses in groundwater at other recharge sites have been studied with varying success. At the Flushing Meadows site near Phoenix, Arizona [90] , it was found that a fine loamy sand over coarse sand and gravel effectively removed viruses. Laboratory studies confirmed that this soil was an excellent adsorber. No viruses were detected in any of the samples of renovated water, even though levels of 158 to 475 PFU per liter were detected in the effluent applied. However, coliform organisms were detected in the reno vated water, suggesting that the removal mechanisms must have been dif ferent for viruses and bacteria, and that viruses may have been present.\n\nSince this site is no longer in existence, these findings cannot be confirmed. However, since then, virus has been detected in a sample from an 18.3 mdeep well at a nearby land application site. The isolate was identified as Coxsackievirus B3.\n\nAt two land treatment sites where sewage is used to irrigate cropland, both positive and negative virus isolations have been made [80, 88] . At the Lubbock, Texas, site, Coxsackievirus B3 was isolated from a depth of 30.5 m; at Roswell, New Mexico, no virus isolates were detected in samples taken from 3 to 30 m depths. In the latter case, irrigation is seasonal and inter mittent, whereas application at the Lubbock site is continuous.\n\nAt an operational land application site in Kerrville, Texas [91] , no viruses were detected in the monitoring wells at depths of 10.7 to 19.8 m even though viruses could be detected in 1.4 m-deep lysimeters.\n\nIn one often-cited report [92] on the Santee project, no viruses were detected in renovated water. This is not surprising, since the detection meth ods available at that time were not quantitative. These negative results must therefore be considered highly questionable, as should the results obtained at the Whittier Narrows, California [33] , projects, which did not employ techniques sensitive enough to detect low levels of virus. This situation reiterates the need for careful evaluation of methods used in any report before negative conclusions are accepted.\n\nSummaries of data on the soil penetration of bacteria at some of the most important rapid-infiltration systems land treatment sites are presented in Table 9 .9. The data suggest that bacteria at rapid-infiltration sites may pen etrate about 10 m vertically and variable distances laterally. These distances are, of course, highly site-specific, and the vertical distance may be more than 10 m but is usually much less.\n\nTo prevent the entry of enteric bacteria into groundwater, it would thus be advisable (unless an underdrain system is installed) not to site land treatment systems where the water table is shallow, particularly if the soil is sandy or gravelly, large cracks or root tunnels are present, or a thin soil mantle overlies rock with solution channels or fissures. This is especially true for rapid-infiltration systems.\n\nOnce in the groundwater, the bacteria may travel long distances in situations where coarse soils or solution channels are present, but normally the filtering action of the matrix should restrict horizontal travel to only a few hundred feet. The actual distance travelled also depends on the rate of movement of the groundwater and the survival time of the bacteria. The rate of movement of groundwater is highly site-specific but often is ex tremely slow. \n\nFrom the foregoing discussion, it is apparent that many factors control the removal of pathogenic bacteria and viruses during the percolation of sewage through the soil. Most of this chapter has dealt with the fate of viruses in soil because of their apparent greater potential for health problems associ ated with land treatment. Although the presence of viruses in groundwater has been demonstrated, it would appear that with proper site selection and management the presence of viruses could be minimized or eliminated. The key is to define the processes involved in the survival and transport of pathogens in groundwater. With proper design, land treatment could be used as an effective method for reducing the number of pathogens in wastewater. With the proper soil type, viruses and bacteria can be reduced to levels as effectively as by chlorination as currently practiced, after the travel of wastewater through only a few centimeters of soil. As we have shown, high removals by soil can be achieved from even raw wastewater. In the soil natural processes will eventually destroy the pathogens. Thus, in groundwater recharge operations, the soil should be considered as part of the treatment process and not simply as a final disposal source. The key to operating such systems for pathogen removal is to gain an understanding of the processes involved and methods by which they can be quantified and controlled. Based on both field and laboratory experiments, several potential treatment practices may be useful in enhancing virus removal during land application of sewage, and these are summarized in Table 9 .10. [11] ."}