{"title": "National and Regional Influenza-Like-Illness Forecasts for the USA", "body": "Basic model 98 The DICE package has been designed to implement meta-population epidemic modeling 99 on an arbitrary spatial scale with or without coupling between the regions. Our model 100 for coupling between spatial regions follows ref [24] . We assume a system of coupled 101 S-I-R equations (susceptible-infectious-recovered) for each spatial region. In this 102 scenario, the rate at which a susceptible person in region j becomes infectious (that is 103 transitions to the I compartment in region j) depends on: (1) the risk of infection from 104 those in the same region j, (2) the risk of infection from infected people from region i 105 who traveled to region j, and (3) the risk of infection encountered when traveling from 106 region j to region i. To account for the three mechanisms of transmission, ref [24] 107 defined the force of infection, or the average rate that susceptible individuals in region i 108 become infected per time step as:\n\nwhere D is the total number of regions. In our case, unlike reference [24] , the 110 transmissibility is not the same for all regions and it is allowed to depend on time: \u03b2 j (t). 111\n\nGiven this force of infection we can write the coupled S-I-R equations for each region as:\n\nin the mobility matrix is one and in the limit of no mobility between regions the mobility matrix m ij is the identity matrix so that \u03bb i (t) = \u03b2 i (t) Ii Ni and we recover the 118 familiar (uncoupled) S-I-R equations:\n\nThe level of interaction between spatial regions is determined by the mobility matrix 120 and its interaction kernel, \u03ba(r ij ):\n\nThis kernel is expected to depend on the geographic distance between the regions (r ij ), 122\n\nand following Mills and Riley [24] we use a variation of the off-set power function for it: 123 \u03ba(r ij ) = 1 1 + (r ij /s d ) \u03b3 (9) where s d is a saturation distance in km and the power \u03b3 determines the amount of 124 mixing between the regions: as \u03b3 decreases there is more mixing while as \u03b3 increases, 125 mixing is reduced. In the limit that \u03b3 \u2192 \u221e there is no mixing between regions and we 126 recover the uncoupled SIR Eqs. (5) (6) (7) . The DICE package is designed to allow the \u03bb j (t)S j (or \u03b2 j (t)\n\nNj in the uncoupled case):\n\nscaling by percent clinical p C j , and adding a baseline B j . The term p C j is the proportion 133 of infectious individuals that present themselves to a clinic with ILI symptoms and B j 134 is a constant that estimates non-S-I-R or false-ILI cases. The integral runs over one 135 week determining the number of model cases for week t i . \u2206 t approximates the time 136 delay from when an individual becomes infectious to when they visit a sentinel provider 137\n\nfor ILI symptoms and is set to 0.5 weeks based on prior calibration [25, 26] . Eq. 10 138 describes how DICE relates its internal, continuous S-I-R model to the discrete ILI data. 139\n\nIn the next section we describe the procedure used for fitting this property (by 140 optimizing the parameters: \u03b2 j , s d , \u03b3 , B j , and P C j ) to an ILI profile.\n\nTo allow for different models for the force of infection/contact rate, we write this term 142\n\nin the most general way as a product of a basic force of infection, R 0 j , multiplied by 143 three time dependent terms:\n\nThe first time dependent term, F 1 (t), allows for a dependence of the transmission rate 145 on specific-humidity, the second (F 2 (t)) on the school vacation schedule, and the third 146 (F 3 (t)) allows the user to model an arbitrary behavior modification that can drive the 147 transmission rate up or down for a limited period of time. For the purpose of the CDC 148 challenge we only considered models involving either F 1 (t), F 2 (t), both, or none (i.e., 149 the contact rate does not depend on time), and the functional form of these terms is 150 discussed in sections S1 Text and S2 Text of the Supporting Information. curve was also fitted directly (without any regional information) using all the models 164 and priors, but these direct results were only used at the end of the season when 165 estimating the performance of each of our procedures. 166 In the coupled scenario, the MCMC procedure uses Eqs. (2) (3) (4) along with Eq. (10) to 167 simultaneously generate candidate profiles for the coupled ten HHS regions. The 168 log-likelihood of the ten regional profiles is calculated and combined with the proper 169 relative weights to generate a national log-likelihood which is minimized. It is important 170 to note that in the coupled scenario we only optimize the national log-likelihood, and 171 not the individual region-level likelihoods, but the parameters we optimize are still 172 mostly region specific (only s d and \u03b3 are not). We also tried fitting the coupled model 173 to the regional log-likelihoods, however the results of the fits were not as accurate as the 174 ones obtained when the national likelihood is optimized (see Discussion). In the previous section we described a traditional MCMC procedure which uses a log 191 uniform distribution for the parameters, which we term an uninformative prior (UP).\n\nEarly in the flu season, before the ILI curve takes off, this fitting can result in peak 193 intensities that are significantly larger/lower than expected (based on historic values) 194 and/or peak weeks that are inconsistent with past values. One way to constrain the 195 predictions, which has been used by others [28, 29] , is to use an informed prior (IP).\n\nTo generate informative priors, we used each of the models supported by DICE to fit all 197 previous seasons (starting from 2004) at both the national and regional levels. we also use a heated informed prior, where the Gaussian temperature is increased by an 218 order of magnitude (which is equivalent to increasing the variance by a factor of ten). In 219\n\nthe Results section we refer to the fitting procedures that use a prior as IP and HIP for 220 informed prior and heated informed prior, respectively. Informed priors were used only 221 with the uncoupled SIR Eqs. In a future study we plan to explore how they would 222 extend to the coupled MCMC procedure.\n\nUsing discounted historical data for not-yet-seen future time points 224 In addition to informative priors, we also used data augmentation to make maximum 225 use of prior data within a mechanistic framework. For each week during the challenge, 226 our data augmentation was a form of extrapolation in which future unobserved time 227 points were assumed to take either a historical average or values equal to those in the 228 most similar prior season. However, these historically augmented time points were not 229 counted within the likelihood with the same weight as actual observations. The\n\nweighting was equal to the value of the Pearson correlation between the observed data 231 in the current year and the historical data for the same period from the year used for 232 augmentation. We shifted from the historic data to the most similar data at epidemic 233 week 6 (EW06) when we subjectively determined that the current season is very 234 different from the historic average. The augmented data was also y-shifted so that it used for both the coupled and uncoupled fits and also using a heated augmented 237 procedure (where the log-likelihood is again heated by a factor of ten During each of the CDC weeks DICE was used to fit both the regional and the national 242 most recent incidence data using the combinations of coupling, priors and models \n\nThis total of 32 model-runs were used to make forecasts of incidence at both the 252 national and regional levels. For each region, we simulate three MCMC chains each with 253 10 7 steps and a burn time of 2 \u00d7 10 6 steps. The smallest effective sample size that we 254 report for any parameter was greater than 100. After sampling from the individual 255 posterior densities of each region, we calculated our national forecast as the weighted 256 sum of the regional profiles with the weights given by the relative populations of the 257 regions. The national curve was also fitted directly (without any regional information) 258 using all the models and priors, but these direct results were only used at the end of the 259 season when estimating the performance of each of our procedures.\n\nEarly in the season we were experimenting with the coupled procedure and we began to 261 use it as described in the manuscript with the DA and HDA priors only on EW 50 and 262\n\nwith the UP prior only on EW 9. Hence, some of the coupled results reported in this 263 section were not available in real-time and were generated at the end of the season (but 264 using only the %ILI data that was available in real-time at each forecast week.)\n\nEach week a single forecast was selected from these results for each of the ten HHS 266 regions and the national. At the regional level we selected a single forecast from one of 267 the (32) uncoupled or coupled procedures enumerated in the previous paragraph. We given a forecast with a set of probabilities for p, with p i being the probability for an 285 observed outcome p i , the logarithmic score is:\n\nFor onset and peak week the score is calculated using the probability assigned to the 287 correct bin plus those of the preceding and proceeding bins (the bin size is one epidemic 288\n\nweek). For peak intensity and the 1 \u2212 4 week forward forecast, the score is calculated 289 using the probability assigned to the correct bin plus those of the five preceding and 290 proceeding bins (the bin size is 0.1%).\n\nModels selected for forecasts 293 We selected different FOI variants during different weeks. At the regional level, 294 although we selected the most flexible humidity and school vacation assumptions (HV) 295 more often (47.9% 134/280) than the alternatives (Fig 1) , we did select humidity-only 296 For assumptions about coupling, once the coupled procedure was available, it was often 322 selected for both the national profile and most regions (1, right panel), with the 323 exception of regions 1 and 8. We found that the coupled procedure used regions 8 (and 324 to a lesser extent 1) as a way to reduce the error to the national fit, at the cost of 325 producing poor fits to these regions, hence their coupled results were rarely selected for 326 submission. The aggregate option for the national selection was only selected at EWs 5 327 and 6, the weeks prior to the peak and the peak week itself. For these two weeks our \n\nAlthough our forecasts gave potentially useful information over and above the NULL 372 model for the timing of the peak week (Fig 3) and for the amplitude of peak intensity, 373 the peak week of EW06 was the same as the historical mean. Between EW50 (eight 374 weeks before the season peaks) and EW04 (two weeks before the season peak) our 375 forecast correctly predicted to within \u00b11 week of the observed peak week (EW06). One 376\n\nweek before the season peaks, and at the peak week (EW05 and EW06), our model 377 forecast has an error of two weeks.\n\n. CC-BY 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/309021 doi: bioRxiv preprint Forecasts based on the mechanistic model performed better than the historic NULL 379 model for the peak intensity (Fig 3 A /B/C/D). Two weeks before the peak week (and 380 three weeks early in the season) we started predicting the correct peak intensity of 5.1% 381 (to within \u00b10.5%). The mean and median historic values are significantly lower (4.4% 382 and 4.1% respectively) and outside the \u00b10.5% range. Our apparent forecast 383 performance for intensity appears to drop off at the end of the season. However, this is 384 an artifact of the forecasting work flow. Once the peak had clearly passed, the final 385 model was selected for reasons other than the peak intensity and the already-observed 386 peak intensity was submitted.\n\nSelected forecasts based on the mechanistic model did not accurately predict onset. are arranged based on their CDC score (averaged across all weeks, numbers on the right 428 y-axis) from best (top) to worse (bottom). Coupled models were more accurate than The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/309021 doi: bioRxiv preprint average model.\n\nFor predicting ILI incidence for the 2016-17 season, which followed similar trend to the 439 historical average, coupled models that used data augmentation were more accurate 440 than coupled models that did not use data augmentation. However, on average for 441 historical seasons, coupled models that did not use augmented data were more accurate 442 than those that did. Also, on average for historical seasons, coupled models that 443 included humidity were more accurate than those that did not (see dark banding in 444 upper portion of charts on the right hand side of Fig 4) . The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/309021 doi: bioRxiv preprint We were able to compare our performance over the course of the season to the 481 performance of the other teams using the public website that supports the challenge 482 (www.cdc.gov/flusight). Averaged across all weeks of forecast and all forecast targets, 483 we were ranked 13 out of 29 teams. For 1-, 2-, 3-and 4-weeks ahead forecasts we were 484 ranked 6, 11, 9 and 16 respectively; again, out of 29 teams. We were ranked 14 for the 485 timing of onset, 5 for the timing of the peak and 14 for intensity of the peak. Probing 486 beyond the overall rankings, our performance was similar to the other better-performing 487 teams in the challenge. Also, our performance improved substantially as measured by 488 both in absolute terms and relative to other teams across the season (Figs S6 and S7). 489\n\nIn this study, we have described our participation in a prospective forecasting challenge. 491\n\nAlthough we drew on results from a large set of mechanistic models, our single forecast 492 for each metric was made after choosing between available model results for that metric 493 in that week and was therefore somewhat subjective. We performed poorly at the start 494 PLOS 20/43 . CC-BY 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/309021 doi: bioRxiv preprint of the competition when our mechanistic models consistently over-estimated incidence. 495\n\nHowever, during the middle phase of the season, our models produced less biased 496 estimates and consistently outperformed non-mechanistic models based on the average 497 of historical data. A robust testing of model variants using historical data suggests that 498 spatially coupled models are systematically better than historical NULL models during 499 the middle of the season and are not significantly worse even at the start of the season. 500 We evaluated a simple ensemble and showed that the subjective model choice was 501 better. However, the ranking of individual models suggests that an ensemble of coupled 502 models may outperform our subjective choice. We are considering exactly this 503 experiment for the upcoming season.\n\nThis study is slightly different from some prior studies of influenza forecasting [30] in 505 that it describes and assesses a subjective choice between multiple mechanistic models 506 as the basis of a prospective forecast, rather than describing the performance of a single 507 model or single ensemble of models used for an entirely objective forecast. Although 508 this could be viewed as a limitation of our work, because individual subjective decisions 509 cannot be reproduced, we suggest that the explicit description of a partially subjective 510 process is a strength. In weather forecasting, there is a long history of evaluating the 511 accuracy of entirely objective forecasts versus partially subjective forecasts [31, 32] .\n\nBroadly, for each different forecast target and each forecast lead-time, there has been a 513 gradual progression over time such that objective forecasts become more accurate than 514 subjective forecasts. We note also that although we describe the subjective process as it 515 was conducted, we also provide a thorough retrospective assessment of the predictive 516 performance of each model variant. 517 We may refine our ensemble approach for future iterations of the competition. It seems 518 clear that the coupled models produce more accurate forecasts than the uncoupled 519 models for most targets, so we would consider an ensemble only of the coupled model 520 variants. We will also consider weighted ensembles of models and attempt to find 521 optimal weights by studying all prior years. Also, data were often updated after being 522 reported and we did not include an explicit reporting model in our inferential framework 523 (also sometimes referred to as a backfill model). Rather, we used knowledge of past The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/309021 doi: bioRxiv preprint adjustments to data during our discussions and eventual subjective choice of models. 525 We aim to include a formal reporting model in future versions of our framework. when evaluated using the historical data. This prospective study supports recent 530 retrospective results suggesting that influenza forecasts can be more accurate if they 531 explicitly represent spatial structure [33, 34] . Given that the model structure we used to 532 represent space was relatively coarse [24] , further work is warranted to test how forecast 533 accuracy at finer spatial scales can be improved by models that include iteratively finer 534 spatial resolution.\n\nIn submitting forecasts based on uninformed mechanistic priors using an uncoupled 536 model at the start of the season, we failed to learn lessons that have been present in the 537 influenza forecasting literature for some time [30] . Historical variance is low during the 538 start of the season and the growth pattern is not exponential. Therefore, it would be 539 reasonable to forecast early exponential growth only in the most exceptional of not-yet-seen time points, are likely to perform better. Also, forecasting competitions 543 may want to weight performance differentially across time, with greater weight given to 544 forecasts during periods where there is a higher variance in incidence.\n\nModels that included humidity forcing performed better on average in our analysis of all 546 historical data than equivalent models that did not include those terms, especially for 547 the forecasting of ILI 1-to 4-weeks ahead [35] . However, we did not see similar support 548 for the inclusion of school vacation terms improving accuracy, which has been suggested 549 in a retrospective forecasting study at smaller spatial scales (by this group) [36] . The The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/309021 doi: bioRxiv preprint actual epidemiological week so that it was consistent with our presentation of accuracy 555 of other forecast targets. However, it may be more appropriate in some circumstances to 556 present accuracy of targets associated with the peak relative to the eventual peak [11] . 557 We found the experience of participating in a prospective forecasting challenge to be 558 different to that of a retrospective modeling study. The feedback in model accuracy was 559 much faster and the need for statistically robust measures of model likelihood or q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q EW44 and relate the local SH, q j (t), to the reproduction number as: The second term in Eq. 11 allows the transmission rate to depend on the weekly school 650 vacation schedule (p j (t)) and we implement is as:\n\nDICE fits the effect of school closure by optimizing the parameter \u03b1, which is in the "}