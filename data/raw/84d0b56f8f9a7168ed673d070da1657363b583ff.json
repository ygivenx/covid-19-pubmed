{"title": "Classification of COVID-19 in chest X-ray images using DeTraC deep convolutional neural network", "body": "Diagnosis of COVID-19 is typically associated with both the symptoms of pneumonia 2 and Chest X-ray tests. Chest X-ray is the first imaging technique that plays an 3 important role in the diagnosis of COVID-19 disease. Fig. 1 shows a negative example 4 of a normal chest x-ray, a positive one with COVID-19, and a positive one with the 5 severe acute respiratory syndrome (SARS). 6 In the last few months, World Health Organization (WHO) has declared that a new 7 virus called COVID-19 has been spread aggressively in several countries around the 8 world [1] . Fast detection of the COVID-19 can be contributed to control the spread of 9 the disease. One of the most successful algorithms that have been proved its ability to 10 diagnosis medical images with high accuracy is convolution neural network (CNN ). For 11 example, in [2] , a CNN was applied based on Inception network to detect COVID-19 level features. Those features were fed into a Support Vector Machine SVM as a 17 machine learning classifier in order to detect the COVID-19 cases. Moreover, in [5] , a 18 CNN architecture called COVID-Net based on transfer learning was applied to classify 19 the CXR images into four classes: normal, bacterial infection, non-COVID and 20 COVID-19 viral infection. 21 Several classical machine learning approaches have been previously used for 22 automatic classification of digitised chest images [6, 7] . For instance, in [8] , three 23 statistical features were calculated from lung texture to discriminate between malignant 24 and benign lung nodules using a support vector machine classifier. A grey-level 25 co-occurrence matrix method was used with Backpropagation Network [9] to classify 26 images from being normal or cancerous. With the availability of enough annotated 27 images, deep learning approaches [10, 11] have demonstrated their superiority over the 28 classical machine learning approaches. CNN architecture is one of the most popular 29 deep learning approaches with superior achievements in the medical imaging domain [12] . 30 The primary success of CNN is due to its ability to learn features automatically from 31 domain-specific images, unlike the classical machine learning methods. The popular 32 strategy for training CNN architecture is to transfer learned knowledge from a 33 pre-trained network that fulfilled one task into a new task [13] . This method is faster 34 and easy to apply without the need for a huge annotated dataset for training; therefore 35 many researchers tend to apply this strategy especially with medical imaging.\n\nClass decomposition [14] has been proposed with the aim of enhancing low variance 37 classifiers facilitating more flexibility to their decision boundaries. In this paper, we 38 adopt and validate DeTraC [15] for the classification of COVID-19 in chest x-ray images 39 1 . This is by adding a class decomposition layer to the pre-trained models. The class 40 decomposition layer aims to partition each class within the image dataset into several 41 sub-classes and then assign new labels to the new set, where each subset is treated as an 42 independent class, then those subsets are assembled back to produce the final 43 predictions. For the classification performance evaluation, we used images of chest x-ray 44 collected from several hospitals and institutions. The dataset provides complicated Then we apply the class-decomposition layer of DeTraC to simplify the local structure 52 of the data distribution. In the second phase, the training is accomplished using a 53 sophisticated gradient descent optimisation method. Finally, we use the pre-trained CNN model using the collected chest X-ray image dataset. We used the 64 off-the-shelf CNN features of pre-trained models on ImageNet (where the training is 65 accomplished only on the final classification layer) to construct the image feature space. 66 However, due to the high dimensionality associated with the images, we applied PCA to 67 project the high-dimension feature space into a lower-dimension, where highly 68 correlated features were ignored. This step is important for the class decomposition to 69 produce more homogeneous classes, reduce the memory requirements, and improve the 70 efficiency of the framework.\n\nMarch 30, 2020 3/9\n\n. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\n\nis the (which was not peer-reviewed) The copyright holder for this preprint Now assume that our feature space (PCA's output) is represented by a 2-D matrix 73 (denoted as dataset A): A = {a 1 , a 2 , . . . . . . .., a n } , where n is the number of images, 74 a i = (a i1 , a i2 , . . . .., a in ), and L is a class category. A and L can be rewritten as\n\nwhere \u03ba is the number of classes and m is the number of features. For class 76 decomposition, we used k-means clustering [16] to further divide each class into 77 homogeneous sub-classes, where each pattern in the original class L is assigned to a 78 class label associated with the nearest centroid based on the squared euclidean distance 79 (SED):\n\nwhere centroids are denoted as c j .\n\nAccordingly, the relationship between dataset A and B can be mathematically 82 described as:\n\nwhere the number of instances in A is equal to B while C is defined as\n\nAlso, the feature space of both dataset A and B can be illustrated as: freezing the weights of low-level layers and update weighs of high-level layers.\n\nFor fine-tuning the parameters, the learning rate for all the CNN layers was fixed to 90 0.0001 except for the last fully connected layer (was 0.01), the min batch size was 64\n\nMarch 30, 2020 4/9\n\n. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\n\nis the (which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.03.30.20047456 doi: medRxiv preprint with minimum 256 epochs, 0.001 was set for the weight decay to prevent the overfitting 92 through training the model, and the momentum value was 0.9. With the limited 93 availability of training data, stochastic gradient descent (SGD) can heavily be 94 fluctuating the objective/loss function and hence overfitting can occur. To improve 95 convergence and overcome overfitting, the mini-batch of stochastic gradient descent 96 (mSGD) was used to minimise the objective function, E(\u00b7), with cross-entropy loss\n\nwhere x j is the set of input images in the training, y j is the ground truth labels 98 while z(\u00b7) is the predicted output from a softmax function. functions and three different kernel filters. We adopted the last fully connected layer 122 into three classes and initialised the weight parameters for our specific classification 123 task. Secondly, we used k-means clustering [16] to apply the decomposition step and 124 divide each class into two subclasses (i.e. k = 2). Finally, we assigned the new labels to 125 the new sets, where each subset is treated as an independent class. More precisely, we 126 constructed a new dataset (we called dataset B) with six classes (norm 1 , norm 2 , 127 COV ID19 1 ,COV ID19 2 , SARS 1 , and SARS 2 ), see Table 1 .\n\nMarch 30, 2020 5/9\n\n. CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\n\nis the (which was not peer-reviewed) The copyright holder for this preprint . . CC-BY-NC-ND 4.0 International license It is made available under a author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\n\nis the (which was not peer-reviewed) The copyright holder for this preprint .\n\nbetween the different classes in the dataset. CNN s can provide an effective and robust 162 solution for the detection of the COVID-19 cases from chest X-ray CXR images and this 163 can be contributed to control the spread of the disease. Here, we adopt and validate our 164 previously developed deep convolutional neural network, we called DeTraC, to deal with 165 such a challenging problem by exploiting the advantages of class decomposition within 166 the CN N s for image classification. DeTraC achieved high accuracy of 95.12% with 167 ResNet on CXR images. "}