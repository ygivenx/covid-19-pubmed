{"title": "Aponed Soil Ecology Review Pathogens in livestock waste, their potential for movement through soil and environmental pollution", "body": "Most farm livestock are housed for at least part of the year, and during this period, faeces, urine, bedding material and waste water is collected, either as semiliquid slurry or solid manure. It is estimated that approximately 200 million t of waste are produced by livestock in England and Wales each year (National Rivers Authority, 1992) . Cattle and sheep account for about 90% of this total with about half being voided directly onto pasture during grazing and half being collected in buildings. Although of potential value as fertiliser, these wastes pose a pollution threat due to their high biochemical oxygen demand and their ability to release nitrates and phosphates to the aqueous environment. The codes of Good Agricultural Practice for Protection of Water and Air (MAFF, 1992a,b) contain advice and recommendations to enable farmers to minimize the risk of chemical pollution. However, livestock wastes also contain large numbers of microorganisms, including many potential pathogens (Keamey et al., 1993a) and it is only recently that concern has been expressed about the possible spread of these pathogens to the human.population (Fernan-dez-Alvarez et al., 1991) . Although biological pollution is mentioned in the MAFF guidelines (MAFF, 1992a) , further research is required before detailed recommendations can be made.\n\nPathogen dissemination from livestock wastes to water supplies may occur following direct leakage to drainage systems from wastes in buildings or stores, or indirectly following the application of waste to land. In addition, the potential exists for transfer of pathogens to the water phase from faeces deposited onto pasture during livestock grazing. Depending on soil type and conditions the route from soil to water course will vary. Much of the permanent grassland in the UK is on impermeable soils which means the most likely route of pollution is as surface or sub-surface runoff. However, on more permeable soils the most likely route of pollutant transfer is down through the soil profile to land drains or ground water. Low rate sprinkler irrigation of wastes, in addition to pathogen dispersal through soil, also results in the possibility of aerosol dispersal. Undoubtedly bacteria, protozoa and viruses will all be present in aerosols but the period over which they retain viability will be largely dependent on environmental conditions. It is generally considered that to decrease the possible risk of air contamination, wastes should be dispersed when there is a low wind speed, warm bright sunlight and a relative humidity of between 40-60% (Elliott and Ellis, 1977; MAFF, 1992b) .\n\nMany pathogens are excreted in the faeces of infected, and in some cases, healthy 'carrier' animals. These include bacteria, viruses, and protozoa (Larsen and Munch, 1986; Hinton and Bale, 1991 ; West, 1991 ) . Whilst some pathogens are obligate parasites and are of limited concern, others can survive saprophytically in the environment for long periods, although in some cases survival is restricted to a transmissive cyst or spore stage. Examples of some of the pathogens found in animal wastes which may cause human disease are shown in Table 1 , although in many cases it has not been conclusively proven that animals are the source of human infection. A wide range of pathogenic microorganisms are included and it is beyond the scope of this review to cover them all, some of the most important are perhaps those responsible for gastrointestinal infections and we aim to illustrate this review with selected examples of bacteria, protozoa and viruses responsible for diseases of the digestive system.\n\nIn the well-developed countries of Western Europe and North America where drinking water treatment facilities are designed essentially for bacterial removal, the incidence of large scale waterborne bacterial gastroenteritis is now rare. However, over the last two decades there has been increasing concern over the emergence of 'new' forms of enteritis, caused by protozoan parasites and enteroviruses (West, 1991) . These new agents of disease may be indicative of changes in agricultural practice. However, it may be that the scale of the problem in both humans and livestock has only just been realized following recent improvements in detection methods and epidemiological surveillance, or that other factors such as increased travelling abroad or changes in socio-economic conditions have changed the risk of exposure. In some cases, what was previously identified as salmonellosis or gastroenteritis of unknown cause may now be correctly identified as cryptosporidiosis. The recorded UK incidents of cryptosporidiosis and rotavirus infections of cattle (these will predominantly be of calves) over the period 1984 to 1992 are shown in Fig. 1 with corresponding numbers of salmonellosis (caused by Salmonella dublin, Salmonella typhimurium and all other serotypes) for comparison. These numbers, obtained from the Veterinary Investigation Diagnosis Analysis issued by the Central Veterinary Laboratory are probably an underestimate of the extent of the problem as they show only the number of incidents diagnosed. subsequent repeated diagnoses relating to the same incident are not included in the data and, in addition, many cases may have not been reported. However, they do illustrate that the reported incidence of cryptosporidiosis and rotavirus infections have increased although this again could result from heightened awareness rather than real increases in occurrence. The reported incidence of salmonellosis declined over the same period.\n\nMicrobial and chemical composition together with the rate and extent of movement of the microbiological component following application to land will vary with waste type. It has been shown that organic compounds are able to compete with viruses for adsorptive sites on soil colloids (Carlson et al., 1968) , and studies have shown that waste type can influence viral transport in soil. Results obtained by Dizer et al. (1984) illustrated this by showing adsorption of virus particles from a tertiary (chemically) treated wastewater effluent to be greater than that from the corresponding secondary (biologically) treated effluent. Similarly, Lo and Sproul (1977) demonstrated that extraneous organic matter competed for adsorption sites with poliovirus. They showed that not only was viral adsorption decreased but that desorption of bound virus from silicate minerals also occurred in the presence of proteinaceous material. However, contrasting results were obtained in a study by Rees (1990) investigating the movement of faecal coliforms in soil following the application of different waste types. Whilst waste type still affected the degree of microbial movement in this case it was shown that whilst bacteria were detected in the leachate of columns treated with dirty water 1-3 h after simulated rainfall, it took twice as long for them to appear in the leachate of slurry treated columns. This may have been a result of the physical retention or binding of the bacteria within the slurry matrix.\n\nThe major source of contamination on most farms is likely to be from slurry or farmyard manure. Prior to agricultural intensification, livestock were often bedded on large amounts of straw and the waste managed as farm yard manure (Jones, 1982 size and the number of housed animals has increased there has been a move towards the collection of waste in a semi-liquid slurry form which contains only a minimum amount of solid bedding material. It is estimated that 50-60% of waste from housed cattle is now managed as slurry (Smith and Unwin, 1983) . Traditionally, farm yard manure was composted, an aerobic process where temperatures often rise as high as 70\u00b0C and therefore the majority of pathogens were destroyed (Jones, 1980) . However, in intensive systems slurry is collected and stored under conditions which rapidly become anaerobic and hence temperature rise and the Table 1 Examples of pathogenic microorganisms which my be found in livestock waste ( compiled from information contained in Wray (1975) ; Williams (1979) ; Reddy et al. (1981) ; Larsen and Munch (1986) ; Henry (1991) ; Hinton and Bale (1991) and West (1991) )\n\nBacteria Viruses Protozoa/parasites concurrent destruction of pathogens, seen in composting, does not occur (Rankin and Taylor, 1969) . A common practice linking all the types of waste discussed is their disposal onto grass or arable land. Apart from the potential for water pollution and human infection being considered in this review, another reservoir of infection may lie in ingestion of contaminated herbage by livestock, both during grazing or after harvesting and ensiling.\n\nLarge volumes of dirty water are also often generated on livestock farms. This may include water used to clean milking parlours and floors of animal houses plus rainfall runoff from concrete areas contaminated with animal excreta. Such water is commonly irrigated onto grassland so is also a potential source of pathogens.\n\nIn this section we aim to use selected examples of bacteria, protozoa and viruses to highlight the range of gastroenteritis-type diseases which may be transmitted from animals to humans by different groups of pathogenic microorganisms.\n\nEscherichia coli (family Enterobacteriaceae) is the predominant microaerophilic microorganism in the human and animal gut, occurring at densities of up to 1 x 109 g-l wet weight faeces. The species is comprised of many biovars, the majority of which are harmless commensals under normal circumstances. However, a few strains of enteropathogenic E. coli are responsible for diarrhoeal outbreaks in both animals and man. Whilst disease in adults is generally only an inconvenience, infection in the very old or very young, or in undernourished populations may be life threatening.\n\nE. coli is frequently used as an indicator organism for detecting environmental faecal pollution, especially that of water (Wray, 1975; Hinton and Bale, 1991) . Studies with E. coli have shown that survival in water is influenced by many factors, including temperature (Flint, 1987) , illumination (Barcina et al., 1990) , nutrient levels (Lim and Flint, 1989 ) and competition and predation (Korhonen and Martikainen, 1991) .\n\nLess information is available on factors affecting survival in soils and slurry. However, Burrows and Rankin (1970) showed that E. coli survived in slurry for up to 11 weeks. Results obtained by Kearney et al. (1993b) have shown a decrease in the viability of pathogens, including E. coli, in slurry following anaerobic digestion, suggesting that management techniques may be used to reduce the pathogen content of slurry prior to land application. Survival times for E. coli in soil appear to be significantly lower than in slurry, with reported times ranging from 7-8 days (Taylor and Burrows, 1971 ) to a few weeks (Linton and Hinton, 1984) .\n\nThe genus Salmonella (family Enterobacteriaceae) is large and diverse, comprising about 2000 serotypes. They are Gram negative, rod-shaped bacteria which do not ferment lactose. Salmonellae are relatively resistant microorganisms and can survive saprophytically outside the host in harsh environmental conditions for many months (Hinton and Bale, 1991 ) . The majority of Salmonella spp. will infect many animal species including man, although some will preferentially infect certain animals for example, Salmonella cholerae-suis in pigs. Infection is more common in young animals and hence peaks of disease outbreaks in cattle and sheep can be observed around lambing and calving times (Fig. 2) .\n\nSalmonellae can survive in slurry for long periods of time (Findlay, 1972; Jones et al., 1977) . Similarly, Stewart (1961) showed Salmonella typhimurium to survive in soils for periods of at least 110 days. More recent results (Turpin et al., 1993) indicate that Salmonella cells in soil may persist for even longer periods in a viable but non-culturable state, thus they would not be detected by traditional plate count techniques. Studies are needed to investigate if such non-culturable cells are still capable of causing disease. These findings illustrate the potential both for microbial contamination of animals grazing on or eating silage prepared from slurry-sprayed pastures, and for indirect contamination through runoff or percolation through soil.\n\nThe occurrence of Salmonella in rivers has often been linked to contamination by cattle or their wastes (Hooper, 1970; Clegg et al., 1983) . The potential for dissemination of Salmonella spp. is great as counts in excess of I X 6 10 colony forming units (cfu) g-J cattle faeces have been reported (Clinton et al., 1979) . Stud-ies are therefore required to investigate ways in which bacterial numbers may be reduced prior to the application of wastes to land (Havelaar, 1986) . Chlorination of human drinking water will, generally destroy Salmonella spp. However, in rural areas where drinking water is supplied by wells and streams which drain off land where extensive grazing takes place, such as the uplands of Wales, hazards could still exist.\n\nMembers of the genus Cryptosporidium are coccidian protozoa of the family Cryptosporidiidae, phylum Apicomplexa (Current, 1987) . Although there are seven recognized species of Cryptosporidium the majority of research has focused on Cryptosporidium paroum as this species is the cause of clinical disease in man and zoonotic infections in livestock and other mammals . Until recently cryptosporidiosis was considered rare in animals and man, and associated only with immunocompromised patients. However, research over the last decade has resulted in its recognition as an important pathogen of both animals and man. Many studies in different countries have demonstrated that C. parvum is detected in a large proportion of diarrhoeal outbreaks of cattle, sheep and pigs (Reynolds et al., 1986; Angus, 1990; Robert et al., 1991; Villacorta et al., 1991 ) . In cattle and sheep cryptosporidiosis and the associated diarrhoea is almost exclusive to young animals and thus peaks of disease outbreaks occur around lambing and calving times ( Fig. 2) . Infection with Cryptosporidium often occurs in conjunction with other enteropathogens such as rotavirus, enteropathogenic E.coli and Salmonella spp., and such multiple infections increase both morbidity and mortality rates (Angus, 1990) .\n\nInfection with Cryptosporidium occurs following ingestion of the transmissive oocyst (4-6/xm in diameter). Oocysts are excreted in large numbers (up to 1 \u00d7 101\u00b0 g-~ ) in the faeces of infected animals (Smith, 1992) and, since ingestion of as few as ten oocysts can result in disease, the potential for infection is huge. The severity of disease is governed by the immunological status of the host (Ungar, 1990) . In man, infection may occur at any age, although due to their lower hygiene levels, incidence in pre-school children is greater than in older children and adults (Grimason et al., 1990 ). (Current, 1987) . In such cases the diarrhoea may be irreversible and will ultimately result in death. Infection in the immunocompetent patient is generally less severe. Symptoms include diarrhoea, abdominal pain, anorexia, vomiting, fever and flu-like malaise. These symptoms generally last 7-14 days although general feelings of malaise and mild abdominal cramps may persist for up to a month. Symptoms generally commence 5-10 days following oocyst ingestion with excretion of infective oocysts commencing with the onset of diarrhoea, and often continuing long after disease symptoms have ceased (Ungar, 1990) .\n\nContamination of water courses with Cryptosporidium is potentially a problem because oocysts are not totally removed by current water treatment practices. The transmissive oocyst is resistant to the levels of chlorine routinely used in water treatment plants (West, 1991) and sand-bed filtration is currently the only effective method of removal (Smith, 1992) . Ozonation is currently being investigated as an alternative (Finch et al., 1993a) although the high concentrations required for effective removal may be impossible to achieve at the normal temperatures used in waste water treatment plants (Robertson et al., 1994) . The detection of cryptosporidia in both water and faecal samples relies on microscopic identification of oocysts (Smith et al., 1993) . Owing to the low numbers of oocysts in water, and the low numbers required for infection, detection relies on the filtering of large volumes of water through cartridge filters with a nominal pore size of 1/~m. Following the concentration of oocysts, samples are stained. Several methods can be used which include auramine phenol, modified Zeihl Nielson or FITC labelled monoclonal antibodies (Casemore, 1992) . In addition, differential dye inclusion by viable and dead oocysts enables viability assays to be carried out (Campbell et al., 1992) . All of these assays are time consuming and rely on identification by trained personnel. Possible alternative methods, including the use of flow cytometers to automatically sort and count monoclonal labelled preparations are therefore being investigated (Vesey et al., 1991 ; Vesey et al., 1993) \n\nMembers of the genus Giardia are binucleate flagellate protozoa of the order Diplomadida, phylum Sarcomastigophora (Adam, 1991) . Three species have been differentiated on the basis of host range and morphological characteristics. Like C~ptosporidium, the majority of research has focused on one species, Giardia lamblia (also known as Giardia intestinalis or Giardia duodenalis), which is responsible for disease in mammals (including man), birds and reptiles.\n\nThe life cycle of Giardia is simple, consisting of only two stages, an infective cyst and a vegetative trophozoite. Following cyst ingestion, excystation occurs in the small intestine and two trophozoites are released. These divide by binary fission in the small intestine and are responsible for the symptoms of giardiasis. Some of the trophozoites encyst, are shed in the faeces and the lifecycle is completed following ingestion by a new host.\n\nWaterborne transmission via the infective cyst (7-14#m) has been recognised as one of the major factors in the spread of Giardia. Giardiasis is now the most common cause of waterborne epidemic diarrhoea in the United States (Deng and Cliver, 1992) . Infected wild and domestic animals such as beavers, muskrats, birds, cats, dogs and cattle and their wastes have all been implicated as sources of contamination with Giardia cysts (de Regnier et al., 1989) . In support of this Rose et al. (1988) demonstrated that river water passing through an area of intensive animal farming had significantly greater levels of Giardia contamination than at its lake source outlet. Infection can occur following ingestion of as few as ten cysts (Smith, 1992) and the incubation period following ingestion of cysts prior to the onset of symptoms is generally 7-14 days (Adam, 1991) . The severity of disease varies greatly from asymptomatic to chronic diarrhoea. In addition to diarrhoea, common symptoms which may persist for up to 6 weeks include abdominal cramps, nausea, loss of appetite, malaise and weight loss.\n\nDetection of Giardia cysts in water or faecal samples is by immunofluorescence microscopy. Like oocysts of Co,ptosporidium, Giardia cysts cannot be cultured in vitro and hence dye inclusion, excystation, or animal infectivity tests are necessary to determine viability. The thick surface of cysts means that penetration by gene probes is prevented, a factor hindering the future development of molecular detection methods (West, 1991 ) .\n\nAlthough Giardia cysts are less tolerant of chlorine than Co'ptosporidium oocysts, the concentrations used in drinking water treatment in the UK are still generally not sufficient to successfully destroy cysts (West, 1991 ) ; owing to their thick outer layer, high doses of germicidal UV irradiation are also ineffective. As for C~ptosporidium, sand filtration (Rose et al., 1989) Bitton et al. (1974) , Tan et al. ( 1991 ) , Huysman and Verstraete (1993a) Wong and Griffin (1976) , Worrall and Roughley ( 1991 ) Wollum and Cassell (1978) (1988) currently appears to be the most effective technique for removing cysts from water. Ozone has been shown to have cysticidal properties in laboratory studies (Finch et al., 1993b) and hence may be of use although more data is required on the effect of factors such as treatment temperatures and water quality before an accurate picture of its reliability and feasibility in water treatment plants is achieved.\n\nRotaviruses are a relatively recently discovered group of the Reoviridae and are now recognised as one of the major causes of non-bacterial infantile diarrhoea (WHO, 1979) . As with the other organisms, infection is via the faecal-oral route with up to 1 \u00d7 109 infective virions being excreted per gram of faeces (Wekerle, 1986) . Infection results in symptoms ranging from subclinical to mild diarrhoea to severe and occasionally fatal dehydrating illness. Symptoms are generally most severe in infants up to 2 years of age, although adults may be infected. Malnourished and immunocompromised individuals are more susceptible to disease and in these cases mortality rates are much higher (Kapikian and Chanock, 1985) .\n\nThe association between rotavirus and waterborne gastroenteritis has highlighted the need for research on both the occurrence and fate of the virus in livestock waste, and aquatic and terrestrial systems (Pancorbo et al., 1987; Ward et al., 1989) . A study by Reynolds et al. (1986) of 490 calves with diarrhoea showed that rotavirus was the most frequently isolated causative agent, being responsible for > 50% of the recorded outbreaks. The number of recorded incidents of rotavirus infection in the UK in recent years is shown in Fig. 1 , and it can be seen that since the mid 1980s the number of reported cases has almost doubled.\n\nUnless land is saturated or of an impermeable nature, when wastes are applied vertical movement of microorganisms through the soil will occur. Despite evidence of the existence of a wide variety of pathogens in livestock waste, few studies have examined vertical or horizontal movement of these microorganisms through soil. In the absence of such information we have drawn on material accumulated in relation to comparable non-pathogenic microorganisms in order to highlight the major factors influencing microbial movement in soil. These factors, together with those affecting horizontal movement are summarized in Table 2 .\n\nSoil type is a major factor influencing microbial transport in soils (Bitton et al., 1974; Smith et al., 1985; Paterson et al., 1993) owing partly to differences in absorptive properties of its colloidal material. Whilst the solid phase of soil is comprised of organic matter, sand, silt and clay, it is the organic matter and clay particles that have the greatest effect on movement as a result of microbial adsorption to their negatively charged surfaces. Such adsorption is believed to be largely responsible for the retention of viruses in soil (Goyal and Gerba, 1979) whereas with the larger bacteria and protozoa, filtration and sedimentation are also important. Soil pore size will also significantly affect movement of bacteria and protozoa through soil although viruses, because of their small size, are less likely to be affected. Griffin and Quail (1968) investigated the role of moisture on the movement of Pseudomonas aeruginosa in soil and concluded that whilst continuous water films were a prerequisite for bacterial movement, unless the soil pores were above a certain size translocation would be severely restricted. They suggested that for rod-shaped bacteria a pore diameter of less than l-l.5/zm would severely restrict passage either by active or passive movement. It has frequently been shown that greater microbial movement occurs in coarse soils with larger pore spaces than in finer textured soils where pore sizes are significantly smaller (Bitton et al., 1974; Tan et al., 1991; Huysman and Verstraete, 1993a) . For example, Patni et al. (1984) examining the bacterial contamination of drainage water from manured land showed that the percentage of annual rainfall that percolated to depths below the drains was greater in coarse as opposed to fine textured soil, suggesting the potential for dissemination of pathogens is greater in soils of the former type.\n\nThe majority of studies investigating the effect of both soil type and other variables on microbial movement have been carried out in laboratory soil columns. Much debate has focused both on the relevance of using such microcosms and on the relative benefits of intact as opposed to disturbed soil. Although Bitton et al. (1979) suggested that soil columns may give rise to misleading results, if care is taken with design, most workers acknowledge that they have a part to play, at least in preliminary studies (Burns, 1988; Bentjen et al., 1989; Bolton et al., 1991 ) .\n\nSoil which has been mixed or sieved prior to use bears little resemblance in terms of structure to undisturbed soil in the field. Macropores which include channels formed by plant roots, earthworms and other soil micro-and mesofauna, cracks caused by freeze-thaw cycles and fissures caused by soil drying will all have been removed by processes such as sieving and laboratory studies using such soil may demonstrate significantly less microbial movement than intact soil cores. For example, Smith et al. (1985) comparing movement in an intact vs. the corresponding disturbed soil showed that at least 93% of the inoculated E. coli cells were retained in disturbed soil from which the majority of channels and macropores had been removed by mixing. In contrast, in the intact cores only 21-73% of inoculated cells were retained, indicating the role of macropores in bacterial transport. Similarly, Van Elsas et al. ( 1991 ) showed greater transport of Pseudomonas fluorescens to greater depths in undisturbed soils than in those which had been repacked. This increased transport in undisturbed soil is considered to be due to water flow bypassing the main filtering effect of the soil by flowing through macropores (Thomas and Phillips, 1979; White, 1985) . Protozoal cysts, being considerably larger than bacterial cells and therefore more likely to be dependant on macropores for their transport, may be expected to show an even greater response to a lack of macropores in disturbed soils. However, repacked soil cores do have a role to play in our understanding of how factors other than soil structure, such as adsorption to the soil matrix, can affect microbial transport (Gannon et al., 1991) .\n\nWith the exception of fungi, which can grow through air-filled pores, the microbial population of soil is restricted to the aqueous phase and the solid-liquid interface. Hence, soil water content will not only affect movement but also survival of microorganisms in soil, with different species exhibiting considerable variation in their ability to withstand both high and low water contents. For example, Pseudomonas spp. are known to be highly susceptible to drying conditions (Labeda et al., 1976; Wessendorf and Lingens, 1989; Hozore and Alexander, 1991) , whereas other species such as Arthrobacter and Azospirillum are relatively resistant (Labeda et al., 1976; Bashan et al., 1991 ) . As soil pores become increasingly water filled, bacteria may find themselves in an anoxic or at least microaerophilic environment (Griffin, 1981) and for obligate aerobes this will probably result in decreased viability and survival.\n\nStudies of both bacteria and viruses indicate increased movement in saturated soils. As matric potentials fall, water will drain from pores and hence water content together with pore size will determine the ability of microorganisms to move through soil whether by active movement or Brownian motion with results generally indicating increased movement in saturated soil (Wong and Griffin, 1976; Worratl and Roughley, 1991 ) . Studies by Postma et al. (1989) suggest a possible explanation for this phenomenon. In their study, maximum incorporation of Rhizobium leguminosarum cells into soil aggregates occurred when the bacterium was inoculated into soil at low water contents. As the water content at time of inoculation increased, the numbers of cells bound in stable aggregates decreased; they hypothesized that this was due to water in pores preventing penetration by the bacteria.\n\nIn addition to soil water content, percolating water, either in the form of irrigation or rainfall will affect translocation through the soil matrix. Trevors et al. (1990) showed that in the absence of downward water flow, movement of a Pseudomonasfluorescens strain in soil columns was negligible, whereas following percolation the bacterium could be detected throughout the soil column and in the leachate. Similarly, Madsen and Alexander (1982) showed increased movement of both Rhizobium and Pseudomonas following percolation of soil cores.\n\nWater flow rate, as governed by the intensity of rainfall, will also affect the rate and extent of translocation with faster flow rates increasing movement of both bacteria (Wollum and Cassel, 1978; Trevors et al., 1990; Huysman and Verstraete, 1993b) and viruses (Lance and Gerba, 1980; Lance et al., 1982) . Field studies support these observations. Evans and Owens (1972) showed that the concentration of coliforms and enterococci in a subsurface drain of a field receiving pig wastes increased during high rates of drain discharge. Similarly, Patni et al. (1984) found higher con-centrations of total coliforms, faecal coliforms and faecal streptococci in drainage waters from manured fields following periods of heavy rainfall.\n\nSaturated water flow is another factor which must be considered. In this situation water flow is through large pores and channels and hence the filtering effect of soil is largely bypassed (McCoy and Hagedorn, 1979) and hence the risk of both chemical and biological pollution increased. Rahe et al. (1978) illustrated this showing rapid ( 1500 cm h-1 ) transport of E. coli cells through saturated hillslope soils. High recovery rates indicated that once cells had entered macropores they were relatively unaffected by passage through the soil profile.\n\nThe surface properties of microorganisms may affect their association with soil particles and hence their survival and transport in soil (Huysman and Verstraete, 1993c) . Hydrophobicity, cell size and properties such as the presence of cellular appendages have all been shown to affect microbial movement (Stenstrom, 1989; Gannon et al., 1991; De Mot et al., 1991 ) . However, such properties do not act in isolation and are influenced by external factors such as the presence of cations and the organic matter content of the soil or waste.\n\nThe mobility of viruses in soil is related to the properties of the amphoteric viral protein coat (Frankenberger, 1986) . It is widely accepted that viral adsorption is increased in the presence of cations, as the repulsive forces of the virus particles and soil colloids are neutralized (Bitton, 1975) and that the formation of virus-cation-clay bridges (i.e. the increase in virus adsorption) increases with increasing positive charge (Frankenberger, 1986) .\n\nBoth high and low pH values are known to decrease the survival of most bacterial and viral pathogens (Hurst et al., 1980; Reddy et al., 1981) although protozoal cysts are in general considered more resistant to extremes of pH (Williams, 1979) . Both the biological and physico-chemical properties of soil are affected by pH and this in turn will affect survival and transport of microorganisms. However, pH measurements of soil reflect only its bulk pH and not those of individual microenvironments. Within the soil, spatial variations in pH will influence the survival and transport of micro-organisms within and between microenvironments.\n\nThe effect of pH on virus movement appears largely to be related to an indirect effect on adsorption. Viruses are amphoterically charged but are negative at most soil pH values (Burge and Enkiri, 1978) . Adsorption and movement of viruses appear to be strongly correlated with increases in soil pH (Duboise et al., 1976, Burge and Enkiri, 1978; Goyal and Gerba, 1979) and bacterial cells may be similarly affected (Kemp et al., 1992) .\n\nPlant roots have, on numerous occasions, been shown to influence the movement of bacteria in soil, although little data exists in relation to viral or protozoal movement. The majority of information on this topic has been obtained from investigations of root colonization by biocontrol agents or plant growth promoting rhizobacteria, or from risk assessment studies of genetically engineered microorganisms. Root growth in general increases the translocation of bacteria through soil (Howie et al., 1987; Trevors et al., 1990; Van Elsas et al., 1991 ; Kemp et al., 1992) and the extent of the effect may be increased further with the presence of percolating water (Mawdsley and Burns, 1994) .\n\nSoil temperature may influence the transport of microorganisms through soil by its effect on dispersal, survival or adsorption (Kemp et al., 1992) . In general, low temperatures favour survival of both viruses (Yeager and O'Brian, 1979; Hurst et al., 1980) and bacteria (Kibbey et al., 1978; Zibilske and Weaver, 1978) . However, the majority of studies have compared survival at 37\u00b0C with those at lower (e.g. 4\u00b0C) temperatures. In the UK soil temperatures are unlikely to rise much above 15\u00b0C and for most of the year will be significantly lower and hence studies over a more realistic range of temperatures are required. Similarly, studies to investigate factors such as periodic freezethawing (a common phenomenon during UK winters particularly in upland sheep-farming areas) are needed.\n\nAlthough it is known that some microorganisms can move actively through soil, for example, in response to root exudates or secretions (Bashan, 1986; Gamliel and Katan, 1992) , the role of motility in influencing trans-port through soil is equivocal (Issa et al., 1993) . It is known that flagellar synthesis is dependant on environmental conditions and in the nutrient limited soil environment, even if flagella are produced, bacteria may not produce sufficient energy for movement within the small water films surrounding micropores (Stotzky, 1972; Catlow et al., 1990) .\n\nMicro-and mesofauna may play a significant role in the transport of microorganisms through soil although little research has tocused on this possibility. The grazing activities of microphagous soil fauna may also influence the survival of pathogenic microorganisms, particularly bacteria. Dispersal may occur either by transfer on the surface of mesofauna (Ruddick and Williams, 1972) or following passage through the gut, although the viability of organisms may be affected by this process (Pedersen and Hendriksen, 1993) . Channels produced during the movement of earthworms and other organisms are also likely to affect the movement of percolating water and therefore any microorganisms it contains. The importance of earthworms in bacterial transport following slurry application was shown by Opperman et al. (1987) who demonstrated significantly greater movement of cofiforms in soil columns amended with earthworms (Eiseniafoetida) than in control columns without worms.\n\nOn impermeable substrata, or in saturated soils additional water may be lost through surface runoff (Moore, 1989) although in some conditions infiltration (saturated flow) or surface storage may occur. Runoff from agricultural land after natural rainfall or irrigation often reaches water courses which are subsequently used as sources for public water supplies. Consequently, when such land has been treated with animal (or human) wastes the possibility exists for the transmission of pathogens to the human population (Patni et al., 1985) . Contamination of water courses via runoff has been reported from grazed land (Doran and Linn, 1979; Jawson et al., 1982) , feedlots (Young et al., 1980) , land treated with animal manures or slurry (Thornley and Bos, 1985) and sewage treated land (Dunigan and Dick, 1980) . Many studies have illustrated the role of runoff from both grazed and waste treated land, in decreasing water quality. Results from a study by Doran and Linn (1979) comparing the bacteriological quality of runoff from a grazed vs. non-grazed area showed faecal coliform counts to be five to ten times higher from the grazed area. In a similar study Jawson et al. (1982) showed faecal coliform counts in runoff still exceeded the water quality standard up to 1 year after removal of cattle from the land, suggesting that these organisms have the ability to survive in the environment. In addition to direct pollution by farm animals, Thornley and Bos (1985) found that runoff from barnyard and manure piles resulted in drainage waters having both biological and chemical characteristics of domestic sewage, leading subsequently to an adjacent river exceeding provincial guidelines for water quality.\n\nAs with vertical movement, the rate and extent of horizontal movement will be influenced by environmental factors. The main factors influencing the degree of contamination in runoff are: rate of surface die-off, volume and type of waste applied, topography of the land, weather at the time of application and the degree of water infiltration (Evans and Owens, 1972; Culley and Phillips, 1982; Patni et al., 1985; Baxter-Potter and Gilliland, 1988; Moore, 1989) . However, further studies are required to establish how these factors interact with one another before an understanding of how to minimize the risk of pollution is achieved.\n\nFrom this review it is clear that livestock wastes are undoubtedly a major source of pathogens with infective propagules being excreted in the faeces of both diseased and carrier animals. However, less is known about the risk of transfer of these pathogens to the human population. Relatively little research attention has been devoted to the survival and transport of these pathogens in agricultural systems where they may persist for considerable periods. It is clear that the practice of returning waste to land results in the potential for spread of pathogens to both human and animal populations through the contamination of herbage and water courses.\n\nIn the medium term two approaches are available that might reduce the scale of the problem; treatment of slurry or treatment of water.\n\nAerobic or chemical treatment of wastes on farm could remove the microorganisms at source before application, but although research is in progress and aeration may reduce survival of Salmonella spp. (Munch et al., 1987) data is not available for other pathogens such as protozoa. Anaerobic storage in slurry holding tanks is practised and has been shown to reduce numbers of pathogenic bacteria (Kearney et al., 1993b) but again information on the survival of other pathogens under these conditions needs further investigation. Two possibilities exist for water, treatment with ozone and/or sand filtration, but again the research has yet to be completed. Thus, neither of these approaches can be relied upon in the short term, whereas a knowledge of the major factors influencing the rate and extent of movement of pathogens through farm systems and soil could at least lead to guidelines being put into place to lessen the chance of dispersal of pathogens into water.\n\nIn this review, as well as the more traditional pathogens such as Salmonella, some recently emerging pathogens such as Cryptosporidium have been considered. Paucity of information for these 'new' pathogens and for movement of the more established pathogens after direct application of livestock wastes has necessitated extrapolation from information published for other microorganisms. Of the many interacting factors influencing movement of microorganisms through soil, soil type and soil water content and flow are commonly quoted as the most important. Soil type will vary dramatically in different regions of the UK where grass or arable land is fertilised with livestock waste and consequently the filtering effect of the soil is also likely to vary significantly. Agricultural practice will also affect both the survival of microorganisms and their subsequent transport with the type of waste, the degree of soil disturbance during and after application and the presence of root crops all likely to influence the degree of pathogen dissemination. This review highlights the lack of direct information on the movement in and across soil of pathogenic microorganisms present in livestock waste following the application of the waste to land. Isolated studies, mainly with pure cultures of viruses and bacteria, have demonstrated some of the many interacting factors which are likely to influence microbial movement in soil. Results from these studies indicate the complex nature of the process, and the difficulties in trying to predict or model movement based on limited information. Detailed research using a range of conditions representative of those encountered in the field are required before accurate models or predictions which take account of the many interacting factors governing movement can be made."}