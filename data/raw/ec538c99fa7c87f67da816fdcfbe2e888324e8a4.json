{"title": "Sources of Harm: Prescription Drugs, Surgery, and Infections", "body": "The high frequency of medical harm shows that it is largely caused by mainstream clinical practices and not due merely to infrequently used interventions that most of us might hope to avoid. Of the causes summarized in Table 5 .1, just three are responsible for more than 80% of all instances of harm: prescription drugs, medical procedures (primarily surgery, but inclusive of other procedures such as diagnostic tests), and hospital-acquired infections. That is, interventions patients are most likely to receive are the ones that cause most harm. Although the full extent of harm from these practices is still emerging, all have in fact been leading causes of harm throughout the history of their use. Chapter 5 discussed the tendency over more than a decade for successive studies of biomedical harm to reveal progressively higher rates than had been reported in earlier studies (e.g., Classen et al., 2011; Kohn et al., 2000; Landrigan et al., 2010) . That pattern wherein more detailed analyses have tended to reveal ever greater levels of harm is repeated in the present chapter which considers specific causes of harm. Detailed study of specific causes not merely confirms that biomedical harm is extensive, but that some causes are individually responsible for more death and disability than even relatively recent analyses had suggested were due to all causes collectively.\n\nHarm from prescription drugs is often referred to as an adverse drug reaction (ADR), which has been defined as a \"noxious and unintended\" effect of a drug administered in the course of biomedical intervention (WHO, 1969, p. 6) . The term adverse drug event (ADE) is also used, especially in more recent literature, with the two terms sometimes being used interchangeably. It can be useful, however, to distinguish between the two, with ADE having a wider meaning that encompasses two subclasses of events: First, as mentioned, ADR refers to harm caused by prescription drugs. Second, an adverse drug interaction (ADI) is harm due to a prescribed drug having negative effects when taken simultaneously with one or more other drugs, whether prescribed or not. The distinction between ADR and ADI is warranted, considering the high proportion of patients who take multiple drugs. Even drugs that may not harm when taken individually can interact harmfully when taken simultaneously. ADIs, then, include harm from the interactive effects of multiple prescribed drugs taken by the same patient, as well as single or multiple prescribed drugs taken against a background of other drug use, both over-the-counter and recreational, whether licit or illicit. To reiterate, ADE is inclusive of both ADR and ADI.\n\nAlmost 40% of the 393 instances of medical harm reported in Table 5 .1 were due to ADEs. Wrong dosage is the most frequent cause, although harm also results from a variety of other actions, including wrong drug prescribed, wrong drug delivered (when the correct drug was prescribed), the prescribing of a drug despite the patient having a known allergy to that drug, and incorrect timing of delivery (too frequent or infrequent dosing). The root causes of such actions are also varied, and include inadequate drug knowledge by the prescribing physician, incomplete patient information, failure to adhere to prescribing recommendations, transcription errors on forms, and lapses in physician judgment. To avoid such errors, guidelines are promulgated, but with limited success. Lack of success cannot be attributed to guideline complexity, since much of the advice is prosaic, including the following requests of doctors to: take account of other drugs the patient may be taking, ask the patient about allergies before beginning the proposed drug treatment, explain potential side effects to patients, ask about side effects after treatment begins, and be aware that new symptom presentation following commencement of medication could be a side effect and not a symptom of the patient's medical condition (Aspden et al., 2007) .\n\nAlthough ADEs are the most frequent adverse medical event summarized in Table 5 .1, none resulted in death in the Classen et al. (2011) study. In the wider population, however, fatal ADEs are far from rare. The thalidomide tragedy in the 1960s brought heightened awareness of ADEs, including ADE fatality. In the late 1950s and early 1960s, use of thalidomide as a treatment for morning sickness during pregnancy led to many infant deaths and to many infants being born with major deformities, including radically undeveloped limbs (Smithells and Newman, 1992) . Those events prompted large-scale prospective studies of ADEs involving monitoring of defined patient populations to determine ADE incidence.\n\nA meta-analysis of 39 studies conducted in the United States over a period of 32 years focussed on two separate patient populations, those admitted to hospital because of an ADE and those who experienced an ADE while in hospital (Lazarou et al., 1998) . Extrapolating from the study findings, Lazarou et al. (1998 Lazarou et al. ( ) estimated that, in 1994 ,000 patients in the United States experienced a fatal ADE, representing approximately 4.6% of fatalities from all causes. By that estimate, death due to the taking of prescribed drugs alone exceeded the upper limit estimated by the Institute of Medicine (IOM; Kohn et al., 2000) for all medically caused deaths. Additionally, taking account of the national mortality statistics for 1994 (Singh et al., 1996) , the Lazarou et al. (1998) findings suggest that death from prescribed drugs was the fourth leading cause of mortality in the United States, after heart disease, cancer, and stroke.\n\nThe Lazarou et al. (1998) findings are consistent with findings from other studies published before and since. In an early review, Einarson (1993) pooled data from 36 international studies and found that more than 5% of all hospital admissions were the result of ADEs. In a large British study, more than 6% of 18,820 hospital admissions were found to have been medication-related (Pirmohamed et al., 2004) . The median bed stay was 8 days, accounting for 4% of the hospital bed capacity. Broadly similar findings have been reported for other countries, including Finland, where 5.0% of 1511 deaths in one large hospital over a period of 1 year were found to be medication-related (Juntti-Patinen and Neuvonen, 2002) . In a nationwide Dutch study, almost 2% of all acute hospital admissions during a 1-year period were ADE-related, and of these, 6% were fatal (van der Hooft et al., 2006) . In Sweden, fatal ADEs were found to be the country's seventh most common cause of death (Wester et al., 2007) .\n\nIn the aforementioned Finish study (Juntti-Patinen and Neuvonen, 2002) , the drugs most commonly associated with fatalities were cytostatics used in the treatment of cancer, and antithrombotics used to reduce blood clotting. In Sweden, three-quarters of fatal ADEs were found to be due to gastrointestinal and brain hemorrhages, mostly due to the use of antithrombotic drugs (Wester et al., 2007) . Gastrointestinal bleeding was also found to be the most common cause of medication-related hospitalization in Britain (Pirmohamed et al., 2004) and the Netherlands (van der Hooft et al., 2006) . In the aforementioned Dutch study (van der Hooft et al., 2006) , as with similar studies in other countries discussed in more detail below, the frequency of ADE-related hospitalizations in the national central registry grossly underestimated the true rate, with only 1% of all such events being reported to the registry.\n\nThe most comprehensive surveillance of medication harm may be that which forms part of the National Poison Data System maintained by Poison Control Centers in the United States. Of over 2 million \"exposures\" in 2012, including morbidity at all levels of severity and mortality, the most frequent substance class was analgesic medications, which accounted for almost 12% of all cases of poisoning (Mowry et al., 2013) . Of a total of approximately 300,000 cases of medication error, the most common were inadvertent double-dosing, ingesting the wrong medication, and incorrect dose.\n\nSystematic studies of harm from prescribed drugs have been ongoing for decades. No one denies that such harm is extensive, often serious, and sometimes fatal. In that context, it would be reasonable to expect that success in containing, if not eradicating, the problem would be a cornerstone of the much-vaunted onward advance of biomedical science and practice. In a large study to address that question, trends in harm from prescribed drugs were analyzed in English hospitals over a 10-year period from 1999 to 2008 (Wu et al., 2010) . Over 500,000 admissions were examined showing that the annual number of medication-related admissions increased by almost 80% over the period, and mortality rate following admission increased 10%. That is, despite it being known for a long time that prescribed drugs are a leading cause of patient harm-including death-evidence shows that the problem has not diminished but has worsened.\n\nThe overall rates of medication-related hospital admissions and fatalities conceal the fact that risk of harm is not evenly distributed throughout the patient population. Of all patient groups, the elderly are by far at greatest risk, with the prescribing of inappropriate drugs, in particular, consistently being found to be a cause of harm. For example, a Taiwanese study used a comprehensive nationwide database to examine visits by patients aged 65 years and older to community and hospital clinical services over a 3-year period (Lai et al., 2009) . Anatomic, therapeutic, and chemical codes were used to identify instances of potentially inappropriate drugs. Almost 20% of nearly 200 million visits were found to have included a prescription for a potentially inappropriate drug, with almost two-thirds of patients in the study being dispensed at least one inappropriate drug each year.\n\nInappropriate drugs in the Taiwanese study were more likely if the patient was female, and if the prescribing physician was a general practitioner, male, and of older age. Other smaller-scale studies have produced similar findings. In the United States, for example, a study of 389 hospitalized patients aged 75 years or older found that 28% had been administered an inappropriate drug according to standard criteria, and 32% of patients experienced medicationrelated harm (Page and Ruscin, 2006) . In a recent Australian study, 26% of more than 100,000 elderly veterans had at least one medication-related hospitalization within the 5-year period of the study (Kalisch et al., 2012) . Similarly, in a recent Irish study of inpatients aged 65 years and older, 26% of 513 patients were identified as having suffered medication-related harm while in hospital (O'Connor et al., 2012) .\n\nNotwithstanding high reported rates of harm from prescribed drugs in older patients, there is every possibility that the true rate is higher than that revealed in the studies. Physical instability, psychomotor unsteadiness (e.g., tremor), cognitive decline (e.g., mental confusion), and sleep disturbance-including both drowsiness and insomnia-are symptoms commonly associated with natural aging. However, these are also common side effects of prescribed drugs, especially when multiple drugs are taken simultaneously (Fabian, 2013) . It is evident that harm from prescribed drugs in elderly patients often goes unidentified because of confusion with the effects of aging. In a telephone survey of residents aged 65 years and older, the likelihood of having experienced harm from prescribed drugs in the previous 6 months was related to the number of prescribing physicians caring for the patient (Green et al., 2007) . The mean number of prescribing physicians was three, and the probability of experiencing medication harm increased by almost one-third for each additional physician in attendance. Similarly, in the Taiwanese study mentioned above, the provision of subsidies for medical expenses appears to have endangered patients by facilitating access to medical services that, in turn, contributed to a higher level of inappropriate drugs being prescribed.\n\nThe preceding studies suggest a pattern of cause and effect that is reminiscent of a phenomenon well-known in biomedical science. This is the doseresponse relationship, which describes the change in effect caused by varying levels of exposure. For example, a small dose of a particular drug may have little effect, a moderate dose may be therapeutic, and a large dose fatally toxic. The principle applies to populations as well as individuals, as for example, when the number of people harmed by environmental air pollution varies proportionately to the density of pollutants in the atmosphere. It is an irony of modern medicine that studies of medical harm suggest that biomedical healthcare itself is similarly fashioned. Broadly speaking, there appears to be a dose-response relationship between harm and level of exposure to clinical medicine (e.g., number of medical consultations, number of drugs prescribed, number of attending physicians, etc.), with harm increasing proportionately to increases in the amount of medical care received.\n\nIn addition to the high incidence of harm from medically supervised use of prescribed drugs, the incidence of unintentional serious harm and death from self-administered overdose of medical drugs, obtained by prescription or illicitly, has increased markedly. The increase has been particularly pronounced in relation to death from opioid analgesics prescribed for pain relief. In the United States, for example, the rate of death, usually from respiratory depression, attributable to prescribed opioid overdose more than doubled in the decade after 2000 (Bohnert et al., 2011; Paulozzi et al., 2012a) and currently exceeds fatal overdose from illicit use of heroin and cocaine combined (Paulozzi et al., 2012a, b) . As discussed in Chapter 14, sufficient access to pain management involving opioid analgesics is more the exception than the rule worldwide, especially in developing countries (Seya et al., 2011) . In contrast, there is a consensus that opioid analgesics are markedly over-prescribed in the United States, an opinion confirmed by the incidence of fatal opioid overdosing in that country.\n\nThe situation in the United States appears to be the result of cultural changes in the practice of medicine (Lembke, 2012) . Patients, it seems, have come to expect greater compliance from doctors, who in turn are less inclined to refuse patients' requests. Change in medical culture appears to have been abetted by legal mandate in certain circumstances requiring compliance with patients' requests for pain relief. In addition, the convenience of prescribing drugs, and profit from their sale, tend to put patients' requests for pain relief ahead of other considerations, including patients' own ultimate welfare. This is especially evident when drugs such as opioids are prescribed for patients known or suspected of being addicted. Prescribing in those instances is self-evidently not effective as intervention for drug addiction, whereas more appropriate intervention (e.g., education and counseling) is time consuming. According to Lembke (2012 Lembke ( , p. 1580 for physicians, treating pain pays, whereas treating addiction does not.\n\nConsequently, there now exists a culture of comparatively unrestrained prescribing of opioid analgesics, and other drugs, especially psychiatric drugs, including benzodiazepines, antidepressants, and antipsychotics, which is responsible for the dramatically increased incidence of death due to prescribed drug overdose (Jones et al., 2013 Although harm from prescribed drugs has been consistently identified as a leading cause of mortality and morbidity, the precise scale of the problem is obscured by substantial noncompliance with reporting obligations. Many countries have what are known as spontaneous reporting systems, which are usually administered by a central or regional regulatory authority, and in some countries reporting is mandatory. Reports of harm from prescribed drugs are received from medical doctors and other health professionals, including pharmacists and nurses. The main function of such systems is to provide a repository of information about the frequency, range, and severity of harm in order to gauge the safety of prescribed drugs currently being used in clinical practice. Such systems are intended to provide a more detailed, representative, and longer-term depiction of drug effects than studies conducted by pharmaceutical companies during premarketing clinical trials of new drugs and postmarketing surveillance once drugs become available for use in clinical practice. Consequently, the quality of the information stored in such repositories is important for public safety, and underreporting poses serious potential threats.\n\nIn an assessment of overall levels of reporting, Hazell and Shakir (2006) reviewed 37 separate studies from 12 high-income countries. The studies had used various methods for estimating reporting levels, including comparing spontaneous reports with data from alternative sources that allowed more comprehensive scrutiny-such as hospital admission data, discharge notes, and insurance claims databases. The findings from the 37 studies indicated widespread underreporting. The underreporting rate was estimated for different settings (hospitals and general practice) and for different drugs, and the rates of underreporting were found to be high in all areas of clinical practice. Specifically, the median rate of underreporting was a remarkable 94%.\n\nGeneralizing from those results, it appears that medication-related harm is overwhelmingly not referred to the reporting agencies established specifically to record such events. It is possible, however, that a single overall rate gives a distorted account of the situation due to a likely bias against reporting common, less serious instances of harm, which comprise the majority in most settings. There was some confirmation of that suspicion in the Hazell and Shakir (2006) study. The median underreporting rate for \"serious/severe\" harm was indeed found to be lower (i.e., more such events were reported) than the overall rate. However, the difference between the two rates was not great, wherein the median underreporting rate for serious harm was 85%. That is, despite a degree of selective reporting related to severity of events, underreporting remains staggeringly high even for serious harm \"including suspected reactions with fatal outcome\" (Hazell and Shakir, 2006, p. 391) .\n\nSome of the main reasons given by healthcare personnel for not reporting harm from prescribed drugs are lack of time, other priorities, unfamiliarity with the reporting process, and lack of understanding of the purpose of reporting (Hazell and Shakir, 2006) . In an attempt to increase reporting levels, many countries have extended existing systems to allow patients to report instances of harm they have sustained. One such system is the Yellow Card Scheme in the United Kingdom (Fortnum et al., 2012) . When introduced in 1964 following the thalidomide tragedy, the scheme was initially available only to doctors, dentists, and coroners, but was later extended to include pharmacists, nurses, and midwives.\n\nSince 2005, electronic, paper, and telephoned incidents from patients have also been accepted, and Fortnum et al. (2012) reported that 18% of notifications to the scheme were from patients. Although that level of participation may appear promising, it should be remembered that underreporting by healthcare personnel consistently exceeds 90% (e.g., Hazell and Shakir, 2006) . It follows that-at 18% of all reports in the scheme-notifications from the public represent a small fraction of the total number of adverse events that actually occur. That inference was confirmed by survey results reported by Fortnum et al. (2012) involving a representative sample of more than 2000 of the general population in the United Kingdom. Although about one-quarter of respondents reported having experienced a side effect of medicine, less than 10% had heard of the Yellow Card Scheme and just three people in the entire sample of 2000 had ever used it. This amounts to an underreporting rate in excess of 99%.\n\nThe highest incidence of medical harm comes from prescribed drugs, but medical procedures, especially surgery, possess greater lethality than other causes. Of the comparatively small number of deaths reported in Table 5 .1, half were due to medical procedures, a proportion not dissimilar to the estimated 40-45% reported in studies involving larger numbers of deaths (de Vries et al., 2008; Thomas et al., 2000) . Prompted by the IOM report of medical fatalities (Kohn et al., 2000) , strenuous efforts have been made to reduce rates of surgery-related mortality, and some encouraging trends toward improved safety have been noted in some areas. A recent large national study in the United States found that operative mortality rates for high-risk cancer and cardiovascular surgery declined during a 10-year period for all eight procedures that were studied (Finks et al., 2011) . Reduction slightly exceeded one-third for one procedure (abdominal aortic aneurysm repair), but reductions in mortality rate for the remainder were approximately one-fifth or less. Thus, despite encouraging trends, overall progress toward reducing surgery-related mortality has been limited.\n\nIn biomedical healthcare there is a category of avoidable harm referred to as never events. Unfortunately, the label signifies an aspiration rather than a reality. Although everyone agrees that these serious events, including retained foreign objects and wrong-site surgery, should never happen, they are not necessarily any more seriously harmful to patients when they do happen than other categories of medical harm. Rather, what distinguishes never events is not that they should never happen (the invocation of the Hippocratic Oath, First, do no harm, informs us that patients should never be harmed), but that they are conspicuous. It is their visibility that has led to these events being branded by the medical profession as uniquely unacceptable harms. Objectively, it is impossible to argue that never events are more unacceptable than other forms of serious and fatal medical harm. The distinctive feature of never events is that they embarrass the professionals who are responsible for their occurrence. Other forms of medical harm, including death, that are less conspicuously avoidable, and therefore do not threaten physician accountability, are not regarded as never events by those who cause them.\n\nOf particular concern to physicians is the fact that never events have a comparatively high likelihood of being successfully litigated on a charge of medical negligence. A charge of negligence for failing to remove a surgical object from a patient's body cavity, or of performing surgery on the wrong patient or the wrong body part, is easily proved on the basis of res ipsa loquitur (\"the thing itself speaks\"). This doctrine states that a breach of duty of care under some circumstances is proven without reference to any evidence other than the event itself. Certainly, never events should never happen, but the label has more to do with them being indefensible in medicolegal terms than the scale of harm caused. In other words, never events are deemed unacceptable not because of harm to patients, but because of potential reputational and material harm to physicians.\n\nThe images in Figure 6 .1 illustrate the potentially public nature of retained foreign objects. Foreign objects are materials left inside patients upon completion of open surgery, and include surgical sponges, sharps (e.g., syringe, scalpel, and scissors), and other surgical instruments (e.g., clamps). Sponges are the most common, accounting for about one-half to two-thirds of retained objects (Gawande et al., 2003; Lincourt et al., 2007) . While some patients with a retained object may remain asymptomatic for extended periods, others present with infection, cramping, obstruction, or other complications that sometimes result in death. Retained is a curious expression in this context, because it seems to imply an active effect, even fault, on the part of the unconscious patient; as if the object came to inhabit the patient through some means other than surgeon error.\n\nCounting of sponges, sharps, and other instruments during open surgery is an almost universal practice, conducted several times during each operation (before surgery, before wound closure, and at skin closure). Although intuitively appealing, instrument counting, in the words of one group of researchers has \"remained surprisingly primitive\" as a way of preventing retained objects (Egorova et al., 2008) . Counting is also surprisingly burdensome. In one study of successive patients undergoing general surgery, counting occupied an average of 9 minutes per case (Greenberg et al., 2008) . Moreover, counting discrepancies occurred in more than 10% of cases, with each discrepancy requiring an average of 13 minutes to resolve. Delays of that order can have serious and lethal consequences due, for example, to postponement of patient transition to intensive care for monitoring and maintenance of vital functions.\n\nIt has been found that in less than 2% of instances of count discrepancies is a retained object actually found (i.e., almost all count discrepancies are false alarms) (Egorova et al., 2008) . Conversely, in most cases where surgery was later found to have resulted in a retained object, a correct instrument count had been recorded (Cima et al., 2008; Gawande et al., 2003) . Considering the delays caused by counting and the possible consequences of such delays, the costbenefit advantage of counting may not always be obvious to the surgical team. However, the threat of litigation if a retained object is discovered in the absence of instrument counting, guarantees counting's place as an operating-room ritual.\n\nAlthough universally practiced, instrument counting is known to be incapable of delivering the long-held medical aspiration of making retained foreign objects a never event of surgery. Given that counting, and especially count discrepancies, cause delays in surgery, it may be concluded that instrument counting, which imperfectly addresses the patient harm it is intended to avoid, is itself a cause of harm, although the amount of that harm remains unknown for wont of being comprehensively evaluated. In the meantime, due to the fallibility of manual counting by surgical personnel, work has proceeded on the use of computer-assisted counting of sponges using barcodes and use of gauze sponges tagged with a radiofrequency identification device (Hariharan and Lobo, 2013) . Some success has been reported, but elimination of the problem of retained foreign objects is evidently not imminent. \n\nAnother highly visible type of surgery-related harm is that of wrong-site surgery, with all such instances being regarded as serious and reportable never events. Wrong-site surgery subsumes a variety of errors, including operating on the wrong patient, performing the wrong procedure (i.e., not the surgery that was indicated and intended), and operating at the wrong site of the body. The last of these includes performing the intervention on the wrong side of anatomically symmetrical structures (e.g., the left side of the body instead of the right), at the wrong location or body part (e.g., the wrong finger or wrong level on the spine), and wrong location within a structure (e.g., anterior versus posterior). When surveyed, one-in-five hand surgeons reported that they have performed wrong-site surgery (typically wrong-finger surgery) (Meinberg and Stern, 2003) and one-in-two neurosurgeons reported having performed wrong-level lumbar surgery (Mody et al., 2008) .\n\nCommensurate with the seriousness of wrong-site surgery, great effort has gone into trying to develop effective protocols to deal with the problem. However, in a comprehensive study, the conclusion of the authors was that wrong-site surgery continues to \"occur regularly\" (Clarke et al., 2007) . The study, which was conducted over a 30-month period in the State of Pennsylvania, recorded 427 events, of which 59% were near misses. Of the remaining 41%, surgery was started, and in half of those it was done to completion. More recent analyses are no more encouraging. A recent review of the evidence concluded that \"wrong site surgery [is] a 'never event' [that] continues to occur at an alarming rate\" (Cobb, 2012, p. 232) .\n\nCasting an optimistic glance in the direction of the airline industry, the same author argued that:\n\nThe checklist has served the airline industry well for many years. However, the \u2026 process is distinctly less organized and less strictly enforced in medical institution policy which continues to rely on surgeon and staff memory to avoid medical errors\u2026. Just as pilot compliance with the checklist has successfully minimized errors in flight, so too we as surgeons must accept the process and make the designated crosschecks part of our procedures. (Cobb, 2012, p. 232) However, the confidence vested in action checklists may be misplaced. If surgical instrument counting, a form of action checklist, is known to be of limited effectiveness in preventing retained objects (e.g., Egorova et al., 2008) , is there reason to expect aviation-style action checklists to be successful in preventing wrong-site surgery?\n\nConsidering the relatively high risks associated with surgery and awareness that the risks may not be evenly distributed between hospitals, it has become increasingly common for the performance records of hospitals to be made public. It is assumed that, armed with such information, patients can exercise informed choice, and the resulting \"market forces\" will create competitive pressure to encourage overall improvements in quality. However, great care is needed in relation to the nature of the information that is made available if it is to be truly helpful. For example, patients considering where to have surgery may be inclined to infer that their chances of survival are highest at hospitals that have a history of zero fatality for the particular operation they require. When this prediction was tested empirically using data from a large national survey of hospitals in the United States, the findings were less than comforting for patients (Dimick and Welch, 2008) .\n\nThe study focussed on five types of operation having high operative mortality: coronary artery bypass grafting; abdominal aortic aneurysm repair; and resections for colon, lung, and pancreatic cancer. Hospitals where no operative fatalities had been reported for a 3-year period were compared for fatalities with all other hospitals in the subsequent year. The study was designed to see if hospitals that had a continuous 3-year record of no fatalities in specific operative categories (there were almost 3000 such hospitals in the study) maintained their good record in the fourth year when compared to other hospitals (of which there were 12,000) that had experienced one or more fatalities for the same operations during the same 3-year period. This provides a reasonable simulation of what patients might do if supplied with information concerning records of performance for different hospitals.\n\nContrary to what prospective patients are likely to expect, hospitals with a reported operative mortality of zero did not maintain lower than average mortality in the subsequent year for any of the five types of operation, and actually had a significantly higher mortality rate for pancreatic cancer. That is, the study showed that zero-fatality rate for specific types of operation, in the absence of other information, cannot be interpreted as an indicator of greater surgical safety. One reason for the findings could be the statistical phenomenon of regression toward the mean, whereby extreme values or outliers that are obtained when a variable is measured first will tend to be closer to the mean when a second measurement is taken. 1 Accordingly, hospitals that posted a mortality-free record may have experienced an aberrant or outlier result that was not maintained when measurements were repeated.\n\nStatistical artifact, however, may only partially account for the seemingly paradoxical results. A fuller explanation is likely to include the fact that the hospitals reporting zero-fatality for specific types of surgery also tended to perform comparatively few of those operations in the 3-year period of initial screening (a tendency that was pronounced for pancreatic cancer resection). All other things being equal, fewer operations equates to fewer opportunities for fatalities to occur. Thus, the apparent good record of the zero-mortality hospitals was probably partly the result of their relatively low volume of surgeries and consequent reduced opportunity for surgery-related fatalities.\n\nThat interpretation is supported by other research which shows that high volume in relation to particular types of surgery tends to be associated with lower mortality rate (Dimick and Welch, 2008 ) (consistent with the aphorism \"practice makes perfect\"). Thus, by attending a hospital that has performed comparatively few of a particular type of operation with apparently good results, patients may incur a higher risk than attending a hospital that has performed many such operations despite some of those not being successful. Considered more broadly, the Dimick and Welch (2008) findings show that, despite the undeniable right of public access to information concerning all aspects of healthcare, the provision of overly-simplified information, without relevant contextual detail, may not always be helpful to patients and may sometimes be harmful. Conversely, the provision of more detailed information may also not always be helpful to prospective patients not used to evaluating complex detail.\n\nNotwithstanding doubts about usefulness to patients of public performance indicators intended to communicate the comparative safety of surgery in different hospitals, some healthcare systems have adopted procedures that make public the performance records of individual surgeons. However, if the performance of fewer operations undermines the utility of hospital-wide information, the alleged safety record of individual surgeons is destined to have even less utility because the frequency of operations performed will be so low for many surgeons as to prevent statistically-meaningful comparison (Walker et al., 2013) . Low number of operations performed by individual surgeons means that the reputation of some will benefit unwarrantedly due to a spurious statistical rating of good performance whereas others will suffer reputational damage due to a spurious poor rating.\n\nMoreover, there is variability in the preoperative health status of patients. Therefore, surgeons could be wrongly identified as having a poor record if the patients they treat are at higher risk than the patients of other surgeons performing the same operation. Conversely, complacency due to an apparently good record of performance could be encouraged in surgeons whose referral base includes a disproportionately high number of patients at low risk. Such biases could lead to competition between surgeons to treat low-risk patients to the neglect of high-risk patients. Furthermore, reporting the performance of individual surgeons ignores the fact that patient outcomes often depend on the performance of individuals in a surgical team, as well as the performance of separate elements within complex healthcare systems. The quality of perioperative care, management of patients' vital status during recovery, and followup care after discharge can all be important contributors to surgery outcomes, including death. Even when there is patient choice, which often there is not, it remains decidedly unclear whether supplying patients with information about the performance record of individual surgeons benefits patient outcomes or contributes to improved quality of surgery and associated healthcare.\n\nA popular image of modern hospitals is that they are (or should be) scrupulously clean: sanctuaries free of the multitude of germs that inhabit the world outside. Certainly, it was not always that way. Figure 6 .2 shows a woodcut depicting a scene from a medieval hospital, which evidently would have been far from germ-free. The scene shows patients sharing beds and corpses being stitched into burial shrouds on the floor; a scene that seems remotely distant from what we have today. The true picture of the modern hospital, however, is quite different from popular image, and not as far removed from the hospitals of former times as we might wish. In addition to being places of harm from prescribed drugs and surgical procedures, hospitals are incubators of some of the most intractable and deadly microorganisms to be found anywhere.\n\nHealthcare-associated infection (HAI or HCAI) refers to infection not present until such time as a patient comes into contact with a healthcare setting. HAIs have been most intensively studied in relation to hospital settings; hence, the essentially synonymous term, hospital-acquired infection is widely used, which conveniently is also represented by the acronym, HAI. However, healthcare-associated infection is the preferred term because it better reflects the reality that infection can be acquired as a consequence of medical care delivered in any setting. An equivalent term, which is declining in usage, is nosocomial infection; derived from the Greek words, nosus (disease) and komeion (to take FIGURE 6.2 Triptych showing the H\u00f4tel Dieu in Paris (circa 1500). Note. Comparatively well patients (on the right) were separated from the very ill (on the left). Although hospital routine has evidently changed substantially since the medieval era, problems of hospital safety remain substantially intractable. (Source: http://commons.wikimedia.org/wiki/File:Hotel_Dieu_in_Paris_ about_1500.gif.) care of), the term refers to disease (more specifically, infection) contracted while under medical care. As a general guide, infections that become clinically evident after 48 hours of hospitalization are considered to be HAIs. Those that occur after the patient is discharged from hospital are considered healthcareassociated if the infective organism is likely to have been acquired during the hospital stay, especially if the organism is known to inhabit hospitals while being less common in the community. HAIs also include surgical site infections that occur within 30 days after the operative procedure or within 1 year of a surgical implant.\n\nA national survey involving 445 hospitals in the United States in 2002 found that among 37.5 million hospital discharges there were 1.7 million HAIs in a single year, a rate of 4.5% of all hospitalizations (Klevens et al., 2007) . The majority of the hospitals in the study were part of a national infections surveillance system, whereby deaths involving patients with an HAI were reviewed and the role of the infection in the death was assessed as having been causal, contributory, not related, or unknown. In cases of multiple HAIs, the assessment was made for each infection separately. By this means, of more than 150,000 deaths among patients with HAI, approximately one-third were attributed to causes unrelated or unknown. Thus, in about 100,000 patients (i.e., almost 6% of all patients with an HAI), the infection was assessed to have caused or contributed to the patient's death. As an annual figure, this number, it might be recalled, is higher than the IOM (Kohn et al., 2000) estimated upper limit for all medically caused deaths.\n\nRecently, the Centers for Disease Control, CDC (2015) in the United States published infection data for all states from a sample of more than 14,500 hospitals and healthcare facilities. The study revealed a national rate for healthcareacquired infection of approximately 1-in-25 patients for 2013. Although that estimate and the earlier one by Klevens et al. (2007) are quite similar, the more recent CDC (2015) result is slightly better (4.0% versus 4.5%) indicating that there may have been some small improvement in recent years. The classification of infection type was similar in the two studies. In the Klevens et al. (2007) study, 80% of infections were of four main types: catheter-associated urinarytract infections, surgical-site infections, ventilator-associated pneumonia, and catheter-associated bloodstream infections. Table 6 .1 shows that urinary-tract infections were the most common, with an incidence almost twice that of surgical-site infections, which in turn were only slightly more common than bloodstream infections and pneumonia. The table also shows that the likelihood of death due to HAI (i.e., the \"lethality\" of infection) was substantially higher for bloodstream infections and pneumonia than for urinary tract and surgicalsite infections.\n\nDespite the high rate of HAIs in the United States, higher rates have often been reported for other countries (see Figure 6 .3). In a recent European study of 20,000 patients in 66 hospitals from 23 countries, 7.1% were found to have an HAI (Zarb et al., 2012) , which means that about 1-in-14 patients were infected compared to the most recent estimate for the United States of 1-in-25. An older, World Health Organization(WHO)-sponsored study conducted in the late 1980s in 14 countries from four regions (Europe, Mediterranean, South-East Asia, and the Western Pacific) found that approximately 1-in-10 patients was infected while in hospital (Tikhomirov, 1987) . It is a consistent finding that rates are higher for poorer than for richer countries. A meta-analysis of more than 200 studies of HAI in developing countries reported a pooled prevalence of 15.5% (Allegranzi et al., 2011) , more than twice the rate for Europe and almost four times that reported for the United States. That is, Figure 6 .3 suggests that an average of approximately 1-in-6 inpatients in developing countries acquire an infection as a result of being hospitalized. Table 6 .2 summarizes results for different medical specialties, where it can be seen that the rate of HAI varied considerably from a low of less than 1% for psychiatry to a high of more than 28% for intensive care (Zarb et al., 2012) . That is, almost one-third of the most acutely ill and vulnerable patients (those need intensive intervention) acquired an infection while in care. In summary, HAIs are prevalent and represent a serious global endemic source of harm caused by medicine.\n\nThe main cause of HAIs is known, and in theory most HAIs are preventable using readily available and relatively simple procedures (Calfree, 2012) . However, the reality of the intractability of HAIs again illustrates profound intrinsic limitations of medical practice. It will be recalled from Chapters 1 and 2 that substantial control over infection in the general community was delivered as part of the epidemiologic transition. It is an irony, therefore, that modern healthcare practices intended to relieve suffering and spare lives are the cause of a global epidemic of infection-related death. It is a double irony that the main cause of HAI is something as banal as a lack of hygiene by healthcare personnel. Poignant as those ironies are, they are eclipsed by the further realization that decades of routine medical practice have honed new infections that are among the deadliest known. \n\nWhile inadequate healthcare hygiene is the main cause of HAIs, the specifics of the pathogenesis of HAIs are nevertheless varied. Infections can be localized to particular bodily sites or they can be systemic (affecting the body generally), and may involve any or all systems of the body. Infectious microorganisms may come from endogenous or exogenous sites. Endogenous sites include organs of the body normally inhabited by microbes, including the nose, mouth, and throat, the gastrointestinal system, and the genitourinary system. Exogenous sites are those other than the patient, including medical devices and equipment, the healthcare environment (e.g., door handles, walls, and other surfaces), visitors, and most importantly healthcare personnel as they move from one location of the hospital to another. In addition to being located at multiple sites in the healthcare environment, infectious organisms have multiple routes of transmission. Many infections in the nonhospital environment are transmitted by means of a carrier or vector. Vector-borne diseases that remain common in some regions of the world include malaria, dengue fever, hemorrhagic fever, encephalitis, and typhus. Common vectors for such infections include mosquitoes, ticks, flies, fleas, lice, birds, bats, rats, and other vermin. The main vector in the transmission of infections in hospitals is human. While this may include patient-to-patient and visitor-to-patient transmission of disease, by far the most potent infectious-disease vectors in healthcare settings are healthcare personnel-principally doctors and nurses.\n\nMost HAIs (about 80%) occur in association with the use of medical instruments. These include central venous catheters (for delivering fluids and for monitoring body functions), urinary catheters (to drain the bladder; see Box 5.2), endotracheal tubes (to provide a clear airway to and from the lungs), and medical ventilators to assist breathing (Calfree, 2012) . The main reason for these devices and procedures causing infection is inadequate hygiene by those tasked with delivering curative care, and the main mechanism by which this happens is failure by doctors and nurses to wash their hands. Although HAI is sometimes portrayed as new, hospitals have always been sites of infection transmission, as may be surmised from the scene depicted in Figure 6 .2. Proof that healthcare personnel are vectors of infectious disease and the vital role of hand hygiene by healthcare personnel in preventing infection was demonstrated more than 150 years ago.\n\nAn Austro-Hungarian doctor, Ignas Semmelweis, working in Vienna in the 1840s, is credited with having made the initial breakthrough discoveries showing that doctors could be the vectors of appalling death and disease due to puerperal fever in maternity hospitals (see Box 6.1 and Figure 6 .4). Puerperal fever, also known as childbed fever and the doctors' plague, is a bacterial infection contracted by women during childbirth, miscarriage, or abortion, especially\n\nDuring the early period of the medicalization of childbirth, puerperal fever was a major cause of death for mothers and newborns. As discussed in the text, physicians were the main cause of what was also known as childbed fever and the doctors' plague, a highly contagious bacterial infection that can rapidly develop into fatal septicemia (blood poisoning). In the absence of sterile procedures, placental separation during childbirth creates conditions that are highly susceptible to infection, and epidemics of puerperal fever accompanied the expansion of hospitals due to the rich infective environment harbored therein.\n\nChance circumstances at the University of Vienna General Hospital in the midnineteenth century provided near-perfect conditions for a controlled experiment, which revealed that insanitary practice by physicians was a leading cause of death from puerperal fever. Admissions to the obstetrics department, which at that time was Europe's largest, were more-or-less randomly allocated to either of two wards. The wards were identical in almost all respects, including physical facilities, ventilation and temperature control, bed density, patient diet, hygiene of the bed linen, and demographic characteristics of the women. Until 1841, the two wards were staffed by a combination of physicians and midwives, but a change in policy brought a change in staffing arrangements. One ward came to be staffed by physicians and medical students, and the other staffed by midwives and midwifery students (Figure 6.4) .\n\nAfter graduating from medical school at the University of Vienna, Semmelweis trained as an obstetrician at the Vienna General Hospital. While there, he observed that the mortality rate for puerperal fever was substantially higher in the ward staffed by physicians than in the ward staffed by midwives. He surmised that the difference in mortality rate was probably related to the different duties performed by the two groups. He noted, in particular, that the physicians and their students routinely performed autopsy dissections, whereas the midwives did not. Semmelweis hypothesized that puerperal fever was caused by the \"conveyance of decomposed animal-organic matter\" carried on the hands of physicians and transferred to Continued BOX 6.1 The Father of Infection Control-cont'd expectant mothers at the time of childbirth. Crucially, he devised an intervention to test his hypothesis. Beginning in 1847, physicians and medical students were required to wash their hands in a solution of bleach prior to assisting with deliveries. Mortality due to puerperal fever in that ward immediately fell to a level approximating that of the ward staffed by midwives. Figure 6 .4 shows that during the period before 1841, when both wards were staffed by a combination of physicians and midwives, the average rate of mortality due to puerperal fever was similar for the two wards. From 1841 to 1846, the mortality rate increased sharply for the ward staffed by physicians and fell for the ward staffed by midwives. The role of physicians in transmitting disease, concealed when both wards were staffed by physicians and midwives, was revealed. That role was confirmed when the new hand-washing regimen mandated by Semmelweis was introduced and the mortality rate in the ward staffed by physicians fell to a level approximating that of the ward staffed by midwives.\n\nSemmelweis was not the first to observe that puerperal fever is caused by physical contact between mothers in childbirth and those who attended the births. In 1843, the American physician, poet, and novelist, Oliver Wendell Holmes, published an essay in which he argued that physicians were transmitting the disease between successive patients they visited (Holmes, 1843) . He declared that \"doctors were instruments of death\" by failing to thoroughly clean themselves, their clothing, and their instruments after attending a patient who had the disease and before going onto the next motherto-be. He even presaged Semmelweis' specific findings with the observation: \"A physician holding himself in readiness to attend cases of midwifery, should never take any active part in the post-mortem examination of cases of puerperal fever.\"\n\nEarlier still, about a half-century before Semmelweis conducted his work, a Scottish physician, Alexander Gordon, asserted that puerperal fever \"seized such women, only as were visited, or delivered, by a practitioner, or taken care of by a nurse, who had previously attended patients affected with the disease\" (Gordon, 1795) . In repudiation of the then popular miasma theory of disease, Gordon also argued that puerperal fever is not due \"to a noxious constitution of the atmosphere.\" Given that Holmes knew of Gordon's work and acknowledged its importance (Lowis, 1993) , it is possible that Semmelweis was familiar with both.\n\nWithout entering into the longstanding debate over who deserves most credit for discovering the link between insanitary practices and puerperal fever, it is worth mentioning that Semmelweis is distinguished among early pioneers of healthcareacquired infection by being the first to provide systematic data confirming the efficacy of hand hygiene in limiting the spread of infectious disease. What unites Semmelweis, Holmes, and Gordon is their shared perspicacity and tenacity. They are all likewise united, as are many bearers of uncomfortable ideas before and since, by how they were ignored and sometimes berated by professional colleagues for the views they espoused and the forcefulness with which they argued them. In his day, Semmelweis suffered many rebukes, but today he is applauded as the Father of Infection Control (Best and Neuhauser, 2004) . when these occur in unhygienic surroundings. The term has since been replaced by more specific terminology that identifies the site and severity of infection. Broadly, pathogenic organisms that invade the bloodstream and lymph system may cause potentially fatal septicemia (blood poisoning). When Semmelweis first drew attention to the possibility, there was resistance among physicians to the suggestion that they themselves were a common cause of patient death. However, bacteriological discoveries later in the nineteenth century, including those of Louis Pasteur and Robert Koch, led to acceptance of the germ theory of disease over the previously popular miasma theory. Confirmation of the germ theory provided convincing evidence that healthcare personnel, practices, and procedures can be a potent cause of disease.\n\nJust as basic hand hygiene has been shown to be effective in limiting the spread of disease in the community (see Box 1.2), the critical role of hand hygiene for limiting the spread of disease in hospitals has been a generally accepted fact for more than a century. Hospital-based protocols for the surveillance, prevention, and control of HAI centered on hand hygiene have been in place since the 1950s (Haidee and Custodio, 2012) . In 2005, the WHO launched a global campaign to reduce HAI and identified the promotion of hand hygiene as a priority (Pittet et al., 2009 ). The WHO guidelines provide healthcare personnel, hospital administrators, and health authorities with specific recommendations for FIGURE 6.4 Mid-nineteenth century mortality due to puerperal fever in the University of Vienna General Hospital. Note. The intriguing story of Ignas Semmelweis has entered medical folklore, which may account for discrepancies in detail to be found in the varied literature describing his observations. In particular, some accounts of his work refer to a mortality rate due to puerperal fever of almost 20% when doctors assisted childbirths compared to a rate of 2% for midwife-assisted births. The estimates reproduced here are among the more conservative of those reported. (Adapted from Funkhouser, 2012, Table 1 , p. 5.) improving practices to reduce the transmission of pathogenic microorganisms in healthcare settings (WHO, 2009). Figure 6 .5 is illustrative of the standards promulgated by the WHO, wherein healthcare personnel are required to perform hand hygiene between the last hand-to-surface contact with an object outside the \"patient zone\" and the first contact in the patient zone; before an aseptic task (e.g., giving an injection or performing wound care); immediately after a care task associated with risk of exposing hands to body fluids and before any subsequent hand-to-surface exposure; when leaving the patient zone and before touching an object outside the patient zone; and after hand exposure to any surface in the patient zone but without touching the patient (Sax et al., 2007) . For some tasks, the use of gloves is standard procedure, and hand hygiene is required before donning gloves. Use of gloves, however, is not a substitute for hand washing.\n\nHygiene guidelines and protocols have been shown to reduce HAI incidence (Pittet et al., 2011; WHO, 2009) , and for that reason the WHO and health authorities worldwide are justified in making every effort to promote the highest possible level of adherence to such protocols. Despite such efforts, however, observational studies show that both the frequency and the quality of hand hygiene remain persistently suboptimal, thereby ensuring the continuance of WHO, 2009.) HAI as a common cause of disease and death. Even 90% adherence to hand hygiene protocols is believed to be insufficient to eliminate HAI. Yet, in practice, frequency of hand washing by healthcare personnel routinely falls below (often well below) 50% of that required by accepted guidelines and protocols (Boyce and Pittet, 2002) .\n\nIn summary, despite concerted effort, the problem of healthcare hygiene has to date remained largely intractable. Realities indicate that the problem is intrinsic to healthcare practice, and therefore healthcare hygiene is certain to continue, and may worsen, as a leading cause of medical harm. The occurrence of infection, due largely to suboptimal healthcare hygiene during routine medical practice, typically requires additional clinical intervention to treat infected patients. The most common interventions for healthcare-acquired infection include the use of antibiotics. However, use of antibiotics contributes to the emergence of antibiotic-resistant infectious microorganisms, a problem that has grown to such proportions as to threaten infection control globally.\n\nThe art of war is deception; that is deceiving the enemy. But in the war against microbes we have deceived ourselves by misusing, under using and overusing antibiotics. (Ghafur, 2010, p. 144) Antimicrobial drugs (antibiotics) are of several types, including antibacterials, as well as antivirals, antifungals, and antiparasitics. Some microorganisms survive exposure to antimicrobial drugs, and are said to be resistant. Resistance may be intrinsic or acquired, but the latter is of particular concern because it means that drugs that had previously been used to treat specific infections may no longer be effective. Use of antibiotics creates a selective advantage for the survival of the organisms with genes for resistance, and encourages the spread of antibiotic resistance throughout an ecosystem of bacteria. Due to the intensive use of antibiotics in healthcare settings, hospitals generally, and intensive-care facilities in particular, are major sources of acquired drug resistance. Resistant organisms are not only transmitted within healthcare settings but also into the community by patients when discharged. The problem is especially critical when pathogenic organisms develop resistance to several drugs that had previously been found useful in clinical practice. These multiple drug (or multidrug) resistant (MDR) pathogens (\"superbugs\") pose a growing threat to population health worldwide (WHO, 2012) . Public awareness of multidrug resistance is most strongly associated with various serious infections that have become increasingly endemic in healthcare settings. The more familiar pathogens include the Gram-positive bacteria methicillin-resistant Staphylococcus aureus (MRSA), vancomycin-resistant enterococci (VRE), and Clostridium difficile (C. difficile), and the Gramnegative Acinetobacter, Pseudomonas aeruginosa, and Escherichia coli BOX 6.2 Gram-Positive and Gram-Negative Bacteria Hans Christian Joachim Gram (1853 -1938 . (Source: http://www.ncl.ac.uk/dental/ oralbiol/oralenv/tutorials/christian_gram.htm.)\n\nHans Christian Joachim Gram was a Danish bacteriologist. While working in the morgue of the city hospital of Berlin, he developed a method, which bears his name, for staining bacteria. The Gram stain is almost always the first step in the identification of a bacterial organism, and it is used to differentiate bacterial species into two main groups. Gram invented the method not for the specific purpose of distinguishing one type of bacterium from another, but for the more general purpose of enabling bacteria to be seen more readily in stained sections under a microscope. As typically employed, a Gram stain is made using an initial stain of crystal violet and a counterstain of safranin. Bacteria that turn blue or purple when stained are called \"Gram positive,\" whereas those that turn pink or red when counterstained are called \"Gram negative.\" Some organisms are Gram-variable, meaning that they may stain either positive or negative, and others are Gram indeterminate. Alternative techniques for identifying bacteria are also available (e.g., genetic markers).\n\nDifference between bacteria in response to the Gram stain technique is due primarily to variability in the chemical structure of the cell wall, which is also associated with differences in susceptibility to antibiotic treatment. For example, vancomycin can kill Gram-positive bacteria, but is ineffective against Gramnegative pathogens. Gram staining provides a method for obtaining a general indication of bacterial type, and its main advantage is the rapidity with which it provides results compared to techniques that depend on the production of bacterial cultures. Thus, patients suspected of bacterial infection have body fluids or biopsy tissues stained by the Gram method, and the results are used to inform initial antibiotic treatment in advance of cultivation of microbiological cultures for purposes of further pathogen identification and treatment selection.\n\n(E. coli) (see Box 6.2). Some occurrence of bacterial resistance is possibly an inevitable consequence of antibiotic use, including use that is appropriate and well-regulated. However, the problem of antimicrobial resistance is greatly exacerbated by misuse, which has contributed substantially to the emergence of appalling and fatal infectious bacteria that are resistant to multiple antibiotics.\n\nIt is widely accepted that at least half and probably more of the antibiotics used in clinical practice are misused. In one study, 100 consecutive admissions to hospital emergency departments were identified in which a common class of antibiotics (fluoroquinolones) was prescribed, and the appropriateness of the intervention was judged according to institutional guidelines (Lautenbach et al., 2003) . Of the 100 patients, use of the antibiotic was judged to be inappropriate in 81. Of the 19 patients for whom the antibiotic was appropriately prescribed, only 1 received both the correct dose and duration of therapy.\n\nOne of the most common misuses of antibiotics is in treating acute upper respiratory tract infection, or the common cold, characterized by symptoms of nasal stuffiness and discharge (rhinitis), sneezing, sore throat (pharyngitis), and cough. The frequency of colds tends to decrease with age, with young children having on average 6 to 10 and adults 2 to 5 colds per year (Eccles, 2005; Heikkinen and J\u00e4rvinen, 2003) . Cumulatively, colds impose an immense economic burden in terms of healthcare costs, and absences from work, school, or day care. Many people seek remedies for the discomfort caused by colds, but there is little effective treatment. In general medical practice, antibiotics are widely prescribed for patients who present with a cold, despite the fact that colds are caused by viruses known to be unresponsive to antibiotics (Kenealy and Arroll, 2013; Simasek and Blandino, 2007) .\n\nIn one study that utilized over 100,000 computerized records covering a 12month period for 17 general practices in New Zealand, upper respiratory tract infection was noted for almost 1 in 10 consultations (McGregor et al., 1995) . Of these, approximately 4 of every 5 were prescribed 1 of 15 different antibiotics. Comparison of clinical outcomes for patients who did and did not receive antibiotic treatment showed no differences in recovery from cold symptoms. In the United Kingdom, consumption of antibiotics increased by 36% in the decade to 2010, and the proportion of patients prescribed antibiotics for coughs and colds rose from 36% in 1995 to 51% in 2011 (Editorial, 2014) .\n\nUse of antibiotics for treating colds is not merely ineffective it can induce negative side effects such as diarrhea (Kenealy and Arroll, 2013) . Additionally, antibiotic treatment of infection can, paradoxically, expose patients to increased infection risk (Wat, 2004) . The normal human gut is colonized by an estimated 100 trillion microbes that assist with vital functions such as digestion, immune defense, and nutrient production (Turner and Thompson, 2013) . While increasingly less effective against multiresistant pathogens, antibiotics, especially widely-used broad-spectrum agents, are active against native bacterial species. Thus, by simultaneously undermining the integrity of native flora and being increasingly less effective against pathogenic species, antibiotics have the potential to increase vulnerability to infection.\n\nWhile much attention in recent years has been focussed on multiresistant Grampositive bacteria such as MRSA, VRE, and C. difficile, Gram-negative bacteria are currently arousing increased concern (Kumarasamy et al., 2010) . The explanation for this shift in attention is that resistance is developing faster in Gram-negative than in Gram-positive bacteria, and fewer antibiotics are either available or in development to provide therapeutic cover against Gram-negative bacteria. These bacteria have not only been responsible for devastating hospitaland community-acquired disease, but their rapid spread has been aided by human travel and migration (Schofield, 2011) . One particular form of international travel that has been identified as having markedly enhanced potential to accelerate the rate of bacterial transmission worldwide is medical tourism, sometimes called added value travel. This involves people traveling between countries in pursuit of lower-cost medical procedures, often for elective surgery, such as cosmetic procedures, but increasingly also for corrective surgery. It is claimed that, in India alone, this trade, which is forecast to increase, currently caters for 450,000 people per year as part of an industry worth about USD2 billion (Walsh and Toleman, 2011) .\n\nParticularly dire warnings have been sounded in relation to hospital-acquired New Delhi metallo-\u03b2-lactamase-1 (NDM-1), 2 which is not to a single bacterial species but a transmissible genetic element capable of encoding multiple resistance genes (Moellering, 2010) . Bacteria containing this genetic element (or variants) acquire resistance to almost all antimicrobial agents. The ability to transmit among usual Gram-negative bacteria confers enormous potential for the NDM-1 gene pool to go largely undetected. It has been estimated that at least 100 million Indian residents carry NDM-1 bacteria as normal gut flora having the potential to cause vast numbers of cases of largely untreatable infection (Walsh and Toleman, 2011) . The first confirmed appearance of NDM-1 was in Sweden in 2008 in a patient who returned home with the infection after being hospitalized in India (Yong et al., 2009) and identification of other similar cases quickly followed. Bacteria containing the gene have since been isolated in many countries covering most regions of the world, raising fears about the \"uncontrollable spread of pandemic clones for which new and effective antibiotics are currently not available\" (Rolain et al., 2010 (Rolain et al., , p. 1700 ).\n\nIt will be recalled that improvements in public sanitation, including sewage disposal and the provision of clean water, in England and Wales during the eighteenth and nineteenth centuries were essential factors in the decline in infectious diseases that define the epidemiologic transition. In that context, it is notable that the reservoir of NDM-1 infection in the Indian subcontinent has been attributed primarily to poor sanitation for hundreds of millions of residents (Walsh and Toleman, 2011) . It should also be noted that there is a history in India of easy access to antibiotics with or without a prescription. Indian physician Abdul Ghafur has claimed that \"India, is the world leader in antibiotic resistance, in no other country [have] antibiotics been misused to such an extent\" (Ghafur, 2010, p. 144) . High levels of bacterial pollution of the environment and endemic infection in the population have encouraged antibiotic use in India as a substitute for sanitation. Considering the largely unfettered access to antibiotics, continuing rapid development of antimicrobial resistance in community and healthcare settings is largely guaranteed. International travel, especially medical tourism, threatens to exacerbate the global transmission of increasingly antibiotic resistant pathogens.\n\nNotwithstanding the immense quantities of antibiotics consumed by people, that source accounts for less than half of the world's total consumption (WHO, 2012). The remainder goes into animal husbandry and aquaculture, where antibiotics are mass administered to healthy food-producing animals for the purposes of promoting growth and preventing disease. The fact that the quantity of antibiotics that goes to healthy animals exceeds the total amount used to treat disease in humans is universally accepted as gross misuse and a major contributor to the emergence of multidrug resistance. The additional fact that some of the same antibiotics used in medicine are also used in food production further compounds the problem of their overuse in animal husbandry. Such use not only contributes to the emergence and spread of resistant bacteria, but also increases the risk of cross infection from animals to people (Collignon et al., 2009) .\n\nAntibiotic use in animals, as in humans, causes increased antibiotic resistance in bacterial pathogens while also contributing to the transfer of resistance genes to other intestinal bacterial species (Khachatourians, 1998) . The greater the number of resistant bacteria present in the intestinal flora of animals, the greater is the likelihood of genes encoding resistance being disseminated into the environment. This could include transfer to wild animals, birds, and fish, thereby adding to existing threats from emerging infectious diseases in wildlife populations (Daszak et al., 2000) . Additionally, there is increased risk of transfer of resistance genes to humans from the consumption of farmed animals. Consequently, not only can resistant animal pathogens cause human disease, but resistance genes transferred from animals to the normal intestinal flora of humans can also cause disease. Thus, the carriage of resistance genes by pathogenic as well \"normal\" bacteria greatly increases the threat of infectious diseases being disseminated throughout human populations. Notwithstanding the enormous harm from healthcare-acquired infections, the extent of that harm is thought by some to be dwarfed by the potential threat to health from resistant bacteria emanating from current practices in animal husbandry (van den Bogaard and Stobberingh, 2000).\n\nA policy package has been proposed by the WHO (2012) for stemming harm from antibiotic resistance. The package includes six actions: surveillance of antimicrobial resistance and use; rational antimicrobial use and regulation; reducing or eliminating antimicrobial use in animal husbandry; infection prevention and control; fostering innovations; and political commitment. The essentials of each strategy are summarized in Box 6.3. Of many strategies proposed to counter antibiotic resistance, particular attention to date has been given to drug innovation, antibiotic stewardship, and isolation practice. Monitoring of antibiotic use and occurrence of resistant bacteria as a basis for planning strategies, and for mobilizing local, national, and international resources and commitment to action. Currently, surveillance varies between countries and regions, and coordination is needed to provide more extensive and uniform geographic coverage Measures to ensure better use of antibiotics Much of the antimicrobial resistance problem stems from the misuse of antibiotics, particularly excessive use. If antibiotics were always prescribed appropriately and only when needed, the treatment correctly followed, never used in agriculture or aquaculture, and if substandard and counterfeit products could be abolished, selective pressure on bacteria to become resistant would be reduced. Development of regulations and practical measures is needed, as is political agreement to put into practice the regulations and measures that are required Reducing antimicrobial use in animal husbandry Antibiotics are used widely and in immense quantities for preventing disease and promoting growth of livestock, poultry, and fish reared for food production. Although some countries have banned the use of antibiotics as growth promoters, the practice remains widespread. Legislation and regulation with enforcement are needed in many countries to control the use of antibiotics in animal husbandry Considering the inexorable increase in antimicrobial-resistant infections, a dearth of new antibiotics, and little incentive for industry to invest in research and development in this field, innovative approaches are reputed to be crucial for the development of new products to counter the rise of antimicrobial resistance. Although an enabling environment for innovation depends on support from policy decisionmakers, history shows that new antibiotics are also likely to be misused Political commitment to enable options for action\n\nThe global health crisis due to antimicrobial resistance concerns us all. It is a question of whether or not there will be effective antibiotics to treat many important lifethreatening infections in the future. Antimicrobial resistance can be reduced, and despite knowledge gaps, strategies and practical measures could be applied more widely. Mobilizing the necessary expertise and resources to mount a concerted effort to prevent and control antimicrobial resistance will depend on the cooperation and commitment of policy decision-makers in all countries Adapted from WHO, 2012.\n\nA recurring lament of those working in the field of multidrug resistance is the dual problem of growing demand for antimicrobial agents to combat the relentless spread of resistant organisms and the dwindling supply of suitable agents as existing ones fall prey to increased resistance. One oft-proposed strategy seeks to outstrip resistant strains by developing new antibiotics to replace those for which resistance has emerged. The strategy assumes that in time the new agents will also succumb to the relentless spread of resistance, at which time they must then be replaced by still newer agents. No one has addressed the problem of how many cycles this process might need to be repeated, but in principle it could continue ad infinitum. It seems, however, that this replacement strategy is advocated more often for want of something better to do, rather than genuine belief that it can work. The accepted reality among many commentators is that bacteria \"overwhelm us with their superior numbers, they reproduce with remarkable speed, and they develop extremely efficient ways to exchange and promulgate resistance genes\" (Moellering, 2010 (Moellering, , p. 2379 . That the replacement strategy is more aspiration than realizable goal is evidenced by the antibiotic development \"pipeline\" being largely empty.\n\nOver the past decade there has been a crescendo of claims by industry leaders, health authorities, and policy makers about a putative innovation crisis in pharmaceutical research. Reasons for the crisis in drug innovation (in general, not only antibiotics) include overcoming practical and intellectual challenges of new drug discovery, conducting multiple trials to determine safety and efficacy, and navigating the regulatory hurdles involved in obtaining approval for clinical use, with the whole process taking possibly 10-15 years to complete one cycle. Additionally, with respect to antibiotics, there is the likelihood of a relatively short period of effectiveness (and profitability) due to loss of efficacy from resistance, and the need for further replacement with the next new drug. In short, it does not pay the pharmaceutical industry to go to all that trouble and expense to develop drugs that bacterial resistance may render redundant before costs can be recouped and profits reaped. Light and Lexchin (2012) , however, have argued that the innovation crisis, at least, as usually portrayed, is a myth. The real crisis they explain is that current incentives do not reward companies for genuine innovation in drug development. Rather, companies are rewarded for redesigning existing drugs in ways that allow the modified product to be promoted as \"new.\" Typically, the new drugs offer little advantage over earlier versions, and may even be less effective, a topic discussed in the next chapter. The relevant point here is that \"telling 'innovation crisis' stories to politicians and the press serves as a ploy\" to extract benefits from government such as taxpayer subsidies and protection from competition (Light and Lexchin, 2012) . At present, industry strategy is to focus on the easier challenge of developing new drugs of low efficacy that are not needed while ignoring the bigger challenge of developing drugs of high efficacy, including new antibiotics, that everyone believes are needed. Industry's emphasis on profitability, not need, is reflected in the global distribution of the research effort dedicated to the development of drugs in general. Moreover, comparing high-and low-income countries, there is an almost fourfold greater number of drugs in the development pipeline for diseases prevalent in highincome countries (where high profits are to be made) than for diseases prevalent in low-income countries (Fisher et al., 2014) . In that regard, industry priorities contribute directly to health inequalities globally.\n\nIt has been argued that concerted effort by governments and regulatory agencies is required to reorder incentives in favor of genuine innovation without jeopardizing industry's capacity to make profit (Light and Lexchin, 2012) . Although such arguments are generally predicated on criticism of past industry priorities and commitments, it may be confidently predicted that industry will support any reordering of incentives designed to safeguard continued profitmaking. Intervention of the kind proposed is tantamount to government being urged to use public funds to intervene in the free market for the purpose of underwriting commercial ventures. It is well to remember, however, that profit-based innovation has thus far led to decidedly perverse outcomes in the form of progressive erosion of antibiotic potency and the threat of global pandemic infection from resistant pathogens. Against that background, public guarantee for continued private-sector profit seems an unlikely solution for dealing with the long-term threat from antibiotic resistance.\n\nGiven the dim prospect that new antimicrobial drugs will achieve any kind of wholesale thwarting of resistant pathogens, a strong movement has emerged over the past decade in support of strengthening policies to slow the pace with which antimicrobial resistance develops (Lim, 2012) . The main strategy for achieving that outcome is antibiotic stewardship, which refers to coordinated efforts to improve policies, guidelines, education, regulations, and surveillance for the appropriate use of antibiotics, including optimizing doses and duration of treatment and minimizing inappropriate use (e.g., Bartlett, 2011; Charani et al., 2010; Fishman, 2006) . Such proposals, however, bear a striking resemblance to proposals intended to address the problem of healthcare hygiene. Both are examples of the evident inability of biomedicine to respond decisively and effectively to longstanding and incontrovertible evidence of the harm it causes.\n\nThe need for antibiotic stewardship in policy governing the responsible use of antibiotics has been known for as long as antibiotics have been in use. As such, the sudden strong advocacy of stewardship at this point in history cannot but invite clich\u00e9d thoughts along the lines of \"too little too late\" and \"closing the barn door after the horse has bolted.\" So far, evidence is lacking of any appreciable strengthening of stewardship. Consequently, little can be said about the likely effectiveness of stronger stewardship in averting future pandemics of resistant pathogens which decades of inadequate stewardship have helped to create.\n\nConsidering the general lack of success in curtailing harm caused by antimicrobial resistance, those responsible for caring for infected patients search for practical measures in clinical practice to manage the consequences of dwindling antibiotic efficacy. One such measure is the use of contact isolation, which includes physical separation of patients to prevent person-to-person spread of infection; use of masks, gloves, gowns, and other protection; and special procedures for the handling and disposal of contaminated items, including body fluids and materials used in clinical care. As with instrument counting, discussed earlier in this chapter, isolation has considerable intuitive appeal as a strategy for limiting harm. However, as with instrument counting, studies have found that the efficacy of contact isolation can be disappointing and that it can cause unexpected harm for the patients who are isolated.\n\nReminiscent of problems discussed above in relation to healthcare hygiene in general, and especially handwashing, a continuing major challenge is to achieve the necessary levels of healthcare personnel compliance with required protocols for contact isolation to be effective as a means for preventing the spread of MDR organisms (Huskins et al., 2011) . Additionally, compared to patients not isolated, patients who are isolated have been found to be at increased risk of harm, including delays in treatment and increased incidence of adverse events (Zahar et al., 2013) . The fact that harm may be more frequent for isolated patients is salient because of the high levels of surveillance and staffing that accompany isolation, with the staffing ratio in the Zahar et al. (2013) study being one nurse for every two patients. The findings provide further confirmation that irrespective of evident great \"care,\" implied here by the provision of high levels of materials, personnel, and expertise characteristic of intensive isolation care, little happens in clinical medicine without patients being harmed.\n\nAs well as increased risk of physical harm, extensive literature shows that contact isolation contributes to psychological harm. A review of evidence found that isolated patients reported less satisfaction and increased levels of anxiety and depression (Morgan et al., 2009) , and it appears that hospitalized older patients may be particularly vulnerable to such harm (Tarzi et al., 2001) . F\u00e4tkenheuer et al. (2014) have proffered an interesting argument based on the notion that isolation, such as imprisonment, is the prototypical punishment that society imposes on wrongdoers. As such, it is unsurprising that patients subjected to isolation may experience increased anxiety, depression, and resentment. Indeed, apart from absence of uniformity concerning suitable isolation methods, such as use of gowns, gloves, masks, and isolation rooms, considerable uncertainty exists in hospitals regarding the circumstances that warrant the use of contact isolation. Considering the legal and other safeguards that exist in society to prevent unwarranted isolation, such as wrongful imprisonment, F\u00e4tkenheuer et al. have questioned the absence of safeguards against \"wrongful isolation\" in hospitals.\n\nMoral hazard refers to the tendency for decision makers to take actions involving higher risks when a greater proportion of benefit and a lesser proportion of cost arising from the action accrue to the decision maker. Such situations are characterized by what economists call information asymmetry in which one party in a transaction has more relevant knowledge about what is being transacted than the other party. Medical practice is fraught with moral hazard, wherein greater knowledge about clinical \"transactions\" resides with practitioners who benefit financially, socially, and professionally, while risksincluding negative side effects of treatment-disproportionately accrue to patients. The overuse of antibiotics is illustrative. Antibiotics have provided doctors with a convenient and professionally sanctioned means of responding to patients' requests for care, even when treating self-limiting conditions such as common cold for which antibiotics are ineffective. In that context, it is striking that much of the discourse about harm from antibiotic resistance alludes to \"unintended consequences\" from well-intentioned actions.\n\nAs usually understood, the phrase unintended consequences refers to outcomes that were not merely unintended but also were unanticipated (Merton, 1936) . In that regard, the emergence of antibiotic resistance might be said to have been unintended in that antibiotic therapy is not typically used with the intention of producing MDR organisms. However, the emergence of resistance was always anticipated. From the earliest clinical use of antibiotics more than 70 years ago, antibiotic resistance was not merely observed but was wellunderstood and predicted on the basis of principles of Darwinian selection (Davies and Davies, 2010) . Therefore, to regard antibiotic resistance as an unintended consequence is to engage in euphemism and prevarication. The likely reoccurrence of antibiotic resistance following the introduction of each new antibiotic has certainly been anticipated. Global population endangerment from the misuse of antibiotics in the absence of strenuous action to at least impede if not stop the evolution of antibiotic resistance, when its occurrence was anticipated all along, is illustrative of the moral hazard intrinsic to biomedical healthcare and commercial husbandry. 6.5.5 Given Past Neglect, What Does the Future Hold?\n\nBesides MDR pathogens, including essentially untreatable strains, truly unintended (i.e., unanticipated) consequences of the dissemination of antibiotics might still occur. Although antibiotic resistance in the natural environment is known to predate the human discovery of antibiotics, most bacterial species are not intrinsically resistant to manufactured antibiotics. Resistance is acquired due to exposure to antibiotics, a process that has been accelerated beyond measure due to the immense quantities of antibiotics manufactured and distributed annually, a large proportion of which is released unchanged into the environment as waste. This creates vast microbial ecosystems containing strong selection pressures that favor antibiotic-resistant strains. Gillings and Stokes (2012) have argued that the rapid and widespread evolution of antibiotic resistance in bacterial pathogens is evidence of the dramatic influence humans can have on evolutionary processes (much as was discussed in Chapter 2 in the context of niche construction theory), which in this instance has led to change in the rate of bacterial evolution. Many antibiotics are designed to have a broad spectrum of activity, which imposes selection pressures on a correspondingly broad range of bacterial species. Gillings and Stokes speculate that an environment saturated with antimicrobial agents has the potential to influence genetic mutation, recombination, and lateral gene transfer in ways capable of dramatically accelerating the natural rate of microbial evolution. In consequence, existing microbial pathogens may become progressively more dangerous, and novel species of virulent and resistant pathogens could emerge. These possibilities underlie much of the concern about the emergence of antibiotic resistance.\n\nThe oft-repeated claim in the scientific literature as well as in public media that widespread antibiotic resistance signals a possible return to the pre-antibiotic era is partly true while also being untrue in important respects. The part that is true is the possibility of a return to population levels of infection similar to those that existed before the epidemiologic transition. However, implied attribution that the epidemiologic transition was brought about by the advent of antibiotics is mistaken. It is not merely mistaken, it is impossible because the epidemiologic transition preceded the advent of antibiotics.\n\nAs described in Part 1, the epidemiologic transition was not due to improvements in clinical medicine, with or without antibiotics. It was the result of farreaching changes in human habits and habitats precipitated by the Industrial Revolution. Moreover, to the extent that death and morbidity from largely untreatable infections are common in healthcare settings, it could be said that within the confines of the modern hospital the world has already substantially returned to the pre-antibiotic era. The spread of antibiotic-resistant infections from hospitals to communities could well mark wholesale return to epidemic levels of population infection equivalent to, or even greater than, those that existed before the epidemiologic transition. If so, the epidemics will be due not so much to loss of antibiotic potency but to misuse of antibiotics. In short, the belief that loss of antibiotic efficacy will by itself cause a return to high levels of population infection is false. Rather, the real threat lies in population dissemination of new, untreatable, and largely \"unnatural\" strains of infectious pathogens. Pathogens caused by the use of antibiotics and against which humans have little or no natural resistance. Unlike the past, confronted with new pathogens possessing high mortality and efficient transmission, strong immunity buttressed by highly efficient physical barriers such as are provided by modern sanitation and hygiene may no longer be sufficient.\n\nThe use of antibiotics in some developing countries as a substitute for the lack of clean water and safe disposal of waste (Editorial, 2014) is reminiscent of industrial-scale animal husbandry wherein animals living in cramped and insanitary conditions are indiscriminately fed antibiotics. The time may come when public infrastructure for the delivery of clean water and disposal of sewage for human populations no longer has the transformative effects on health that it had in the countries that were fortunate enough to adopt policies of public sanitation and hygiene before the advent of antibiotics. New resistant microbes may emerge for which natural defenses are few and technological defenses ineffective, with potentially catastrophic effects for human populations. The advent of antibiotics, sometimes trumpeted as the greatest medical achievement of the twentieth century, has the potential to end in global health disaster from epidemics of novel infectious diseases selectively engineered by the misuse of antibiotics.\n\nThe gravity of the threat to personal and population health from antibiotic resistance may be gauged from the frequency and solemnity of public statements from public health authorities and governments. Reports of new and threatening pathogens such as severe acute respiratory syndrome (SARS), Middle East respiratory syndrome coronavirus, and avian influenza A (H7N9) appear at regular intervals (Frieden et al., 2014) . Additionally, there is the threat of bioterrorism involving the intentional release and dissemination of biological agents, including antibiotic-resistant organisms. The World Health Assembly recently passed a resolution requiring the Secretariat of the World Health Organization to urgently draft an action plan on global antimicrobial resistance (WHO, 2014) . The European Commission has confirmed the high priority it attaches to measures intended to combat antimicrobial resistance with the awarding of nearly \u20ac800 million for transnational collaborative research into antimicrobial resistance in the context of human health, animal health, food supply, and the environment (Geoghegan-Quinn, 2014; WHO, 2014). United States President Barack Obama (2014) recently issued an executive order titled, Combating Antibiotic-Resistant Bacteria. The President's announcement declared the threat of antibiotic-resistant bacteria to be a national security priority, and a task force to implement countermeasures has been established under joint oversight of departments of defense, agriculture, and health.\n\nStories of the threat of new infectious organisms emerging to devastate humanity are ever present in the public media, and they tend to sabotage discussion about more effective ways for promoting personal and population health than can be achieved through provision of evermore biomedical healthcare. In that sense, biomedicine derives succor from stories of disease epidemics, because people are inclined to believe that biomedicine possesses the most (possibly, the only) effective strategies for defeating new diseases. The pharmaceutical industry, too, is much assisted, because such threats can be used to justify evermore taxpayer support for industry \"innovation\" in drug development.\n\nDiscussion about the outbreak of Ebola virus in West Africa has included speculation about the disease having spread from fruit bats to other animals and ultimately to humans. However, perhaps a story having greater prescience than ones often told about novel virulent diseases migrating from remote wilderness areas will have biomedicine itself caste in the role of villain. That story might foretell a future of devastating global disease that has migrated from antibiotic-saturated waste in a densely-populated part of the developing world where antibiotics are used as substitute for sanitation infrastructure. The central plot of that story would be the contribution of profligate biomedical misuse of antibiotics to the emergence of epidemics of multi-and totally-drug-resistant pathogens against which humans may have fewer natural defenses than against any of the past plagues of history. Whereas many look to biomedical healthcare to save us from impending plague, biomedicine may yet prove to be the cause of future plagues of heretofore unknown devastation."}