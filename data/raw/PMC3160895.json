{"title": "Prediction of Peptide Reactivity with Human IVIg through a Knowledge-Based Approach", "body": "Given their key role in the immune response, antibody-protein interactions play a major role in a variety of clinical domains (infectious diseases, autoimmune diseases, oncology, vaccination and therapeutic interventions). For this reason, the prediction of antibody-protein interactions can be of critical importance [1]\u2013[2]. The antibodies have a wide range of heterogeneous structures generated by genomic recombination: the number of human antibodies is estimated to be around 1010 and 1012\n[3]. The antibodies interact with proteins (called antigens) through their binding sites (called paratopes).\n\nThe region of the antigen bound with the paratope is called epitope. Two types of epitopes are typically distinguished in protein-antibody interaction studies: conformational and linear epitopes. A linear/sequential epitope is recognized by its linear sequence of amino acids (primary structure). In contrast, most antibodies recognize conformational epitopes with a specific three-dimensional structure.\n\nAll potential linear epitopes of a protein are short peptides that can be synthesized and arrayed on solid supports, e.g. glass slides [4]. By incubating these peptide arrays with antibody mixtures, such as human serum or plasma, it is possible to determine specific interactions between antibodies and peptides.\n\nThe binding site of a linear epitope has a typical length ranging between 8 and 10 amino acids. An antibody binds to its epitope/peptide independently of the physical position of the binding site within the peptide. Every amino acid has a different impact on the epitope reactivity; this is not only due to its physicochemical properties but also to its interaction with the neighboring residues within the whole peptide sequence.\n\nIt has been often assumed that a specific antibody selectively binds to a specific sequence. However, experimental data indicate that many antibodies bind to a panel of related (or even distinct) peptides with different affinities. The open question is whether there exist rules that enable the prediction of common peptide/epitope sequences, which can be recognized by human antibodies.\n\nIn order to address this problem, the DREAM (Dialogue for Reverse Engineering Assessments and Methods) Consortium issued the Epitope-Antibody Recognition (EAR) Specificity Prediction Challenge (Challenge 1). In the experimental work leading to this challenge, 75534 peptides were incubated with commercially available intravenous immunoglobulin (IVIg) fractions. IVIg is a mixture of naturally occurring human antibodies isolated from up to 100000 healthy individuals. From this dataset, high-confidence negative and positive pools of peptides were determined. Training and test datasets were assembled from these peptide pools. The epitope-antibody recognition challenge consists of determining whether each peptide in the test set belongs to the positive or negative set starting from the data of the training set.\n\nA so-called \u201cbonus round\u201d was proposed beside this main challenge. It consists of generating \u201cin-silico\u201d a list of positive and negative new peptide sequences, which should significantly differ from the ones contained in the training set. The lists provided by the best performing teams will be subsequently experimentally evaluated.\n\nIn the literature, epitope prediction has been focused primarily on sequence-dependent methods based on various amino acid properties, such as hydrophilicity, solvent accessibility, secondary structure and others [5]\u2013[16]. Several methods based on machine learning approaches have been applied, too [17]. They comprise hidden Markov models (HMM), artificial neural networks (ANN) and support vector machines (SVM) [18]\u2013[22]. Machine learning methods have been frequently coupled with the so-called scale-based approach; this approach exploits one or more scales of amino acid properties to weight each residues of the sequence of interest. In particular it has been shown that the combination of different scales with several machine learning algorithms have better performances than single scale methods [23].\n\nWe coped with the DREAM challenge by resorting to a classical supervised machine learning strategy with knowledge-based feature construction. After the definition of the problem features, we developed a logistic regression classifier that showed a very good performance on the test set.\n\nMoreover, we developed a new method for dealing with the bonus round challenge and we generated a list of de-novo peptides that will be further experimentally assessed.\n\nThe training set contained 13638 peptides and was created by selecting 3420 peptides from the positive set and 10218 peptides from the negative set. Two features of each peptide were provided: the amino acid sequence and a measure of the peptide reactivity to the IVIg antibodies. The predictive model of the peptide reactivity was trained on this dataset.\n\nThe test set contained 13640 peptides and was formed by grouping the remaining 3421 positive peptides and the remaining 10219 negative peptides. Only the sequence of these peptides was provided for the initial phase of the challenge, while their class (positive or negative) was made available to us only when the results of the challenge had been published.\n\nThe construction of a proper set of features is the most important step of the development of a successful predictive model.\n\nIn particular, we considered two sets of features for every peptide: the first set is computed from the peptide sequence, while the second set is generated taking into account the entire training set.\n\nThe values of all the features have been normalized between 0 and 1.\n\nIn order to generate the first set of features, we exploited information about the peptides and the epitopes reactivity.\n\nIn more detail, we used the following peptide attributes:\n\nAs mentioned in the introduction, several approaches have been used for epitope prediction; the so-called scale-based approach exploited one or more scales of amino acid properties to weight each residues of the sequence of interest [2], [18], [25]\u2013[28]. The use of multiple scales was essential to predict epitope location reliably, as reported by Blythe et al. [29]. Therefore, we considered some of the most promising amino acid properties reported in these studies, by resorting to a set of widely used scales (i.e. the five scales reported in Table 1) [9]\u2013[13]:\n\nThe five attributes described above were computed on the basis of the correspondent amino acid scale, computing the maximum value within a sliding window of 9 residues. The size of the sliding window was chosen because it is known that the binding site covered by an antibody typically includes a stretch of 8 to 10 amino acids [36]\u2013[37].\n\nThe second set of features has been generated taking into account the entire training set. To obtain such features, every peptide was aligned with all the others by both the Needleman-Wunsch algorithm (global alignment) and the Smith-Waterman algorithm (local alignment) [38]\u2013[39]. In this way, a scoring matrix [13638\u00d713638] has been computed. In this way, we have generated a set of additional features, as follows:\n\nThe rationale for selecting the features mentioned above is related to the so-called classification for homology (sequence similarity), which consists of classifying a sequence (in terms of structure and function) looking at the most similar sequence in a dataset of available sequences [40]\u2013[41]. The principle is that similar sequences have similar structures and, thus, similar functions (in this case similar reactivities to antibodies) [42].\n\nIn our case, for example, a peptide has a high value of MaxScore0_nw, if the negative examples contain at least another very similar peptide. Moreover, the MaxScore feature is used to check the importance of the absolute value of a good alignment, while the DiffMaxScore attribute takes into account the difference between class groups.\n\nIt is important to notice that the use of the information about the class (i.e. positive or negative example) during the feature generation phase requires to properly designing the cross-validation phase in order to avoid overfitting.\n\nFinally, the two types of alignments have been used to understand whether the reactivity depends on the entire sequence of the peptide (global alignment) or on a small portion (local alignment), as hypothesized.\n\nBecause the training set was made of 13638 examples and the generated features were 37, a features selection step was not mandatory. However, we decided to filter the features to obtain a more parsimonious model. We resorted to a filtering strategy because the use of wrapper methods would have made the cross-validation approaches (and in particular the leave-one-out strategy) computationally very demanding. We have applied three different procedures for feature selection, thus obtaining three different subsets of features.\n\nAs mentioned above, the final aim of this challenge is to discover whether there exist rules that enable to predict that a peptide/epitope sequence is recognized by human antibodies. For this reason, we mainly considered classifiers that provide a predictive model easy to be interpreted.\n\nTo evaluate the best classifier, the performances have been assessed applying the so-called \u201cleave-one-out\u201d cross-validation approach. This approach is particularly suited in our case, since, together with maximizing the size of the training set, it allows to properly generating the features related to the alignment scores.\n\nThe model was assessed not only in terms of its predictive performance but also taking into account its interpretation, i.e. by considering the contribution of the different features included in the prediction.\n\nTogether with standard performance measures, such as accuracy, sensitivity and specificity, we also computed the F-measure of the predictive model. The F-measure is the harmonic mean of precision (positive predictive value) and recall/sensitivity. As a matter of fact, in order to develop a model that is useful to generate new reactive peptides, it is important to maximize both precision and sensitivity: it means to have a high probability that the peptide predicted to be positive is really reactive and that the reactive peptides are correctly classified.\n\nAs previously mentioned, we decided to select, among the best classifiers, the model with the clearest interpretation. In the case of logistic regression, we evaluated the reliability of the regression coefficients by comparing their values and signs with what was expected in the light of the available knowledge.\n\nAs mentioned in the previous sections, the classifiers have been trained on the entire training set. The selected model was then applied on the test set (3421 positive and 10219 negative peptides).\n\nThe predictions of all the participants to this DREAM5 challenge have been evaluated and compared. Teams were ranked according to their performance score based on two metrics: the area under the precision versus recall (PR) curve and the area under the receiver operating characteristic (ROC) curve. P-value was defined as the probability that a given or larger area under the curve value is obtained by a random prediction. The overall final score was defined as minus the logarithm of the geometric mean of the ROC and PR p-values.\n\nThe first step of our strategy is to obtain clusters of similar peptides. In particular we exploited the scoring matrix computed by aligning every sequence with all the others with the Smith-Waterman algorithm (local alignment). We chose local alignment because the results of the main challenge showed that it has higher predictive performance than the global one (see Results). We obtained a distance matrix by subtracting each element of the normalized scoring matrix to one. Then, we applied hierarchical clustering with complete linkage and we used a cut-off value equal to 0.7 to generate the clusters.\n\nWe selected three types of clusters by exploiting the information about the peptides reactivity.\n\nA multiple-alignment was then performed on the sequences of each cluster. Thanks to this strategy it was possible to compute the conservation of each amino acid in a specific position.\n\nWe generated a motif for every sequence 15 amino acids long and belonging to each cluster/multiple-alignment. In detail, we considered all the amino acids composing each of these sequences ordered by the conservation in the corresponding multiple-alignment (computed in terms of information as shown in Figure 2). A residue was kept as constant in the motif if it satisfied the first constraint of the bonus round (no more than three consecutive amino acids already present in the training set). The remaining amino acids are less conserved and do not satisfy the constraint of the bonus round; so these residues were allowed to vary within their amino acid group or following the variation patterns in a specific position reported in the multiple-alignment results. The amino acids groups were obtained by clustering amino acids on the basis of the BLOSUM50 matrix. A motif was thus generated for every sequence in the clusters.\n\nAll the possible sequences have been generated starting from the motifs extracted with the method described in the previous paragraph. Such new sequences were then filtered in accordance with the second constraint of the bonus round (identity with the other sequences not higher than 5 amino acids in a window of 11).\n\nThe predictive model used in the main challenge (model B) was exploited to predict the reactivities of the remaining new peptides. This prediction has been used to rank the new peptides in terms of predicted reactivity.\n\nWe selected the 1100 peptides with the highest predicted reactivity generated from the positive clusters and the 1100 with lowest predicted reactivity obtained from the negative clusters. Finally, we randomly selected 1100 elements from the uncertain clusters.\n\nAs described in the previous section, we generated 37 features to predict peptide reactivity to human antibodies. We applied three different procedures for feature selection: no selection (subset A), selection based on collinear attribute elimination and on the M5 method and (subset B) and selection based on the LASSO method (subset C). The subset B and C contain 28 and 27 remaining attributes, respectively. The subsets B and C are partially different (see Table 2).\n\nAs explained in the Methods section, we learned five different classifiers on the three features subsets. Cross-validation was performed with a leave-one-out approach. The models obtained by applying decision tree and rules learner are reported in the supplementary material (see Text S1 and Text S2).\n\n\nTable 3 shows the results obtained in terms of mean accuracy, sensitivity, specificity, precision and F-measure:\n\nThe logistic regression models obtained by considering feature subsets B and C have been evaluated in terms of their explanation capabilities.\n\nFirst of all, we analyzed the two subsets of features by giving some explanations about the removed attributes (zeros are assigned to removed attributes in Table 2, columns 4 and 5).\n\nWe then analyzed the estimated coefficients of the logistic regressions in order to further investigate which was the most reliable between the two models. In particular, the estimated coefficients of both models are reported in Table 2, columns 4 and 5. These coefficients have been evaluated on the basis of the available knowledge but also on the basis of the correlation of each feature with the class, as computed in the training set (Single Regression Coefficients - SRCs). The second column of Table 2 reports the regression coefficient computed for each attribute, while column 3 reports its F-measure.\n\nBased on all these considerations, we selected model B as the best final model, even if model C had a higher F-measure.\n\nThe selected model was used to generate predictions on the test set data (3421 positive and 10219 negative peptides). The predictions of our model, as well as of the other participants to DREAM5 challenge 1, were evaluated in terms of a score based on the area under the precision versus recall (PR) curve and the area under the receiver operating characteristic (ROC) curve.\n\nThe results obtained by Model B and Model C are reported in Table 4. Both models had a very high performance in terms of PR and ROC, as shows in Figure 3. It is important to note that Model B achieved the highest score.\n\nBy analyzing the scores of all the participants, reported in Table 4, it can be noted that two teams (our team and team 725) clearly over-performed all the others.\n\nAs explained in the previous section, the final output of the bonus round is a list of 1000 new peptide sequences for each of the three classes: high reactivity (H), low reactivity (L) and medium reactivity (M).\n\nThe procedure for the generation of these peptides follows the steps described in the Methods section and schematically reported in Figure 1.\n\nIn the first phase we used the scores of local alignment to cluster the available sequences. As result of this first phase, about 7000 clusters with different size have been created.\n\nThen we exploited the class information to select three types of clusters. By applying the rules described in the Methods section, we selected 23 positive clusters, 27 negative clusters and 4 uncertain clusters. An example of positive cluster and an example of negative one are shown in Figure 2: the figure depicts the multiple alignments of the two clusters and their representation through sequence logos [49].\n\nThe motif generation phase resulted in a few thousands sequences for each class group (i.e. H, L and M).\n\nFinally, we computed the predicted reactivity for all the sequences generated from the positive and negative clusters. The final list was formed by: i) the 1100 peptides with the highest predicted reactivity generated from the positive clusters, ii) the 1100 with lowest predicted reactivity from the negative clusters and iii) 1100 peptides randomly selected from the uncertain clusters. As shown in Figure 4, the distributions of the predicted reactivity clearly separate the peptides coming from the positive clusters and the negative ones. This demonstrates the validity of the strategy adopted to generate new peptides.\n\nThe experimental test of the real reactivity of these peptide sequences is still ongoing.\n\nIn the present work we described the procedure implemented to cope with the Epitope-Antibody Recognition (EAR) Specificity Prediction Challenge of the DREAM5 competition. The aim of the EAR challenge was to extract rules able to predict the binding of a peptide/epitope to a human antibody. A training set of peptides with experimentally identified high and low reactivity to human antibodies was provided. The challenge consists therefore in determining whether the peptides of an independent test set belong to the positive or negative set.\n\nAs mentioned in the previous section, we have exploited a machine learning approach to analyze the data, after a knowledge-based feature generation phase. In particular we extracted two types of features for every peptide: (i) sequence-dependent features, which are based on both general information about peptides and knowledge about the propensity of a peptide to interact (amino acid frequencies, antigenicity, accessibility, etc.); (ii) dataset-dependent features, which are generated by exploiting the scores obtained by aligning every peptide of the training set with all the others with both global and local alignment. A total of 37 features have been finally generated.\n\nWe considered three different subsets of such attributes, based on different feature selection strategies. As a last step, we learned some simple classifiers, which have been evaluated with a leave-one-out cross-validation approach. Since the final aim of the EAR challenge is to extract rules able to explain the propensity of peptide to react, we selected classifiers able to provide a model easy to be interpreted (e.g. logistic regression, rule learners, decision trees, etc.).\n\nThe classifier finally selected was built with the logistic regression, one of the most widely used classifiers, able to predict the probability of the class on the basis of both continuous and discrete features. The best results were achieved by using a reduced subset of features; in particular, taking into account the model interpretation needs, we selected the logistic regression fitted with the features obtained by M5 method.\n\nThe evaluation of the prediction of the model on the test set showed the validity of the approach: the model had one of the best performances of the challenge. As a note, the performances of the model on the test set are higher than the one obtained with cross-validation on the training set (e.g. F-measure metrics are 71.26% and 71.15%, respectively).\n\nIn general, this good performance has demonstrated that, even if the prediction of epitope reactivity is a difficult problem, there are ways to obtain promising predictive models based on the combination of prior knowledge and data analysis [50].\n\nTogether with the high performance of the proposed reactivity prediction model, the present work highlights some open issues concerning the propensity of a peptide to react with human antibodies.\n\nThe future developments of this work will concern the test of our model on other datasets related to the prediction of epitope reactivity. Preliminary encouraging results have been achieved on some peptides of the IEDB (Immune Epitope DataBase) [52].\n\nThe final aim of the challenge was to elucidate the mechanisms of epitope reactivity with human antibodies; for this reason, a \u201cbonus round\u201d was proposed beside this main challenge. To this end, we have developed a method based on a clustering approach. We grouped the peptides of the training set in about 7000 clusters by using as distance the score of the local alignment. Then, we selected 23 positive, 27 negative and only 4 uncertain clusters by a-posteriori taking into account of the class of the peptides. It is worthwhile mentioning that the small number of negative and positive clusters demostrates that there are many rules underlying peptide reactivity. Each rule has thus a small support; this is probably related to the wide variability of the antibodies.\n\nThe clusters have been used to extract a set of motifs that were the basis to generate an initial list of potential new peptides. We predicted the reactivity of such new peptides relying on our model: the sequences with highest and lowest predicted reactivity formed the final list of de-novo peptides. The results of the experimental test of the real reactivity of these peptide sequences will be available in the near future."}