{"title": "", "body": "The global burden of food-borne disease is currently unknown but the World Health Organization (WHO) has responded to this data gap by launching a new initiative (www.who.int/foodsafety/foodborne_disease/ferg/en/index.html) to provide better estimates. In 2005 it was reported that 1.8 million people died from diarrhoeal diseases (www.who.int/mediacentre/factsheets/fs237/en/), largely attributable to contaminated food and drinking water. This is not just an underdeveloped world problem. About 76 million cases of food-borne diseases, resulting in 325,000 hospitalizations and 5000 deaths, are estimated to occur each year in the United States of America (USA) alone .\n\nThere are over 200 known microbial, chemical or physical agents that can cause illness when ingested (Acheson, 1999) . Over the last 20 years, at least in the industrialised world, food-borne diseases caused by bacteria, parasites, viruses and prions have significantly moved up the political agenda and generated, on occasions, substantial media attention.\n\nIn the face of such public concern, public health efforts have been directed mainly towards the well-recognised food-borne diseases and pathogens in the food chain. In contrast, resources for emerging foodborne diseases have tended to be allocated in an incident driven manner, i.e. in response to the extent of perceived emerging health threat (for example BSE). In an attempt to reduce disease burden, the monitoring of food-borne diseases and pathogens in the food chain has been implemented and a farm-to-fork approach has been adopted encouraging all sectors of the food production chain to improve hygiene and actively incorporate structured approaches to food safety, such as HACCP principles. Underlying such industry-based changes has been an enormous research effort leading to the generation of improved methods for the diagnosis of intestinal disease and the detection of food-borne pathogens. Over the last 20 years this research has also used modern technology to generate genome sequences, identify pathogenic mechanisms, provide evidence-based risk assessments for policy development and even develop some effective intervention strategies such as vaccines for food-producing animals or post-harvest treatments. With all this input, a substantial downwards trend in food-borne disease, should be expected. However, evidence from disease surveillance for such a positive impact remains sparse.\n\nBaseline surveillance data is essential to observe changing levels in food-borne disease. Nevertheless, even today few countries worldwide routinely collect such data on infectious intestinal disease and even fewer have consistent and comparative data going back over 20 years or so with which to identify trends. This lack of data makes it hard for public health officials and microbiologists to determine the cost benefit of their work. For the general public, who are constantly faced with yet another \"food safety\" scare, the impression is one of increasing numbers of outbreaks, and new threats on top of old ones.\n\nOur understanding of the microbial agents of intestinal illness remains limited. Comprehensive diagnostic studies of intestinal infectious diseases (see for example Tompkins et al., 1999) , indicate that between 50 and 60% of all causative agents are unidentified. In addition, gastrointestinal illnesses caused by toxin producing bacteria, such as Bacillus cereus, are almost certainly underestimated due to lack of diagnostic tools. The only certainty is that the list of agents of infectious intestinal disease will continue to grow as new microbes are recognised and as food processing and eating habits change. Before 1960 the major causes of gastrointestinal disease were recognised as Salmonella spp., Shigella spp., Clostridium botulinum and Staphylococcus aureus. During the 1960s Clostridium perfringens, and B. cereus were added and then in the 1970s, rotavirus and norovirus. In the 1980s and 1990s there was a flurry of additions including Campylobacter, Yersinia, Listeria monocytogenes, new strains of Escherichia coli such as O157:H7, Cryptosporidia and Cyclospora. It seems highly probable that new food-borne pathogens will be discovered in the 21st century. Many of these will be zoonotic in origin given that such pathogens are twice as likely to cause new and emerging diseases than non-zoonotic agents. In addition, already known pathogens can evolve thereby adding to the public health risks. For example zoonotic food-borne bacteria are increasingly becoming resistant to antimicrobials.\n\nRegardless of the pathogen multiple factors have contributed to or are contributing to changing trends in food-borne diseases. These include:\n\n\u2022 rapid population growth and a demographic shift towards an ageing population. \u2022 an increasingly global market in vegetables, fruit, meat, ethnic foods, and even farm animals, some of which originate from countries without appropriate microbiological safety procedures. \u2022 improved transport logistics and conditions, which enable agents to survive on food products and reach the consumer in a viable form. \u2022 an increasingly transient human population carrying its intestinal flora worldwide. \u2022 changing eating habits, such as the consumption of raw or lightly cooked food, and the demand for exotic foods, such as bushmeats. \u2022 the shift from low-to high-protein foods as nations develop economically with a concomitant and global greater dependency on meat and fish products \u2022 higher proportions of immunologically compromised individuals either as a consequence of changing demographics producing an increasingly elderly population or the generation of highly susceptible groups with immunosuppressive diseases or treatments. \u2022 changing farming practices, for example intensification to produce cheaper food or a shift to free-range/organic animal production to respond to consumer welfare concerns. \u2022 the increasing intrusion of man on native wildlife habitats.\n\n\u2022 climate change, for example bringing novel vectors into temperate regions or temperature-associated changes in contamination levels.\n\n(www.fao.org/ag/agn/agns/files/HLC1_Climate_Change_and_ Food_Safety.pdf) Improvements in the microbiological safety of foods have been largely driven by public demand in response to disease outbreaks. These improvements have been implemented by international standards and legislation, and are considered to have had an impact on diarrhoeal incidence as reflected in trends reported worldwide (http://www.who.int/whr/2008/whr08_en.pdf). A continued decline in diarrhoeal disease as a cause of death, particularly in the young, is a prediction of the WHO. Such a prediction presumes that the situation regarding food safety will not only be maintained but will be rolled out into those areas of the world increasingly responsible for global food production. However, regardless of the improvements in production, processing and monitoring along the food-chain, few food-borne pathogens, if any, appear to have been successfully contained. Even with the extensive campaign undertaken towards the control of BSE, this disease is still being detected in cattle (www. oie.int/eng/info/en_esbru.htm). Thus despite all the efforts from scientists, governments and industry it appears that food-borne disease will continue as a major public health problem worldwide, with enormous implications for both the social welfare of populations and for national economies.\n\nIn this manuscript we have attempted to summarise trends in the prevalence of bacterial (including antimicrobial resistance), viral and parasitological infectious agents in the food-chain and indicate the major issues to be addressed in the future for the prevention and control of food-borne diseases.\n\nBacterial food-borne agents have, to date, been the most well investigated and monitored causes of intestinal infectious disease. In some EU countries, such as The Netherlands (www.rivm.nl/infectieziektenbulletin/bul1607/art_trends.html), surveillance has shown a downward trend in the number of cases of reported bacterial enteritic disease in recent years, but even in those countries the disease burden remains substantial.\n\nThroughout the 1990s and until today, three major food-borne bacterial targets (Salmonella spp., Campylobacter spp. and E. coli) have persisted, commanding the most research and surveillance attention from government agencies and, to a large extent, the most awareness from the food industry. More recently there has been a growing concern about L. monocytogenes. These bacterial pathogens, together constitute the greatest burden of food-borne illness for which etiology is known. Not surprisingly therefore these diseases command the majority of public health interest and policy maker awareness in intestinal infectious diseases. They also provide clear examples of the persistence of bacterial food-borne pathogens despite considerable efforts aimed at prevention and control.\n\nSalmonella spp. colonise a wide range of hosts and all the major livestock species (poultry, cattle, and pigs) can become colonised, frequently asymptomatically, eventually producing contaminated meat and other food products. Food-borne outbreaks of salmonellosis are routinely observed and frequently reported. This is a reflection of a low infectious dose in humans, especially when delivered in certain foodstuffs such as chocolate, an ability to grow in unprocessed food and in the environment allowing amplification, and long term survival and, therefore, ease of recovery from contaminated foods. Such diverse habitats also provide opportunities for adaptation and evolution and this is demonstrated by the changing trends in salmonellosis and associated agents that have been observed in recent years.\n\nAn increase in salmonellosis during the 1980s was clearly observed throughout the developed world. This increase largely comprised S. enteritidis phage type (PT) 4, which was epidemiologically and microbiologically linked to shell eggs and poultry. Research has demonstrated that this Salmonella has adapted to preferentially colonise the avian reproductive tract, persist in the ovary and oviduct and survive in hen's eggs (Gantois et al., 2008) . The effectiveness of such a strategy for the success of this agent is remarkable. Intervention against S. enteritidis PT4 in the form of hygiene interventions, including the culling of infected flocks using a \"topdown\" approach and vaccination, first of breeder flocks and then of layers. This significantly reduced egg-associated infections during the late 1990s in several European countries but from 2000 there has been further increase in salmonellosis, this time with non-PT4 strains, including PT1, PT14B and PT21. Outbreak data, coupled with extensive laboratory investigations, has suggested that at least some of these strains are once again associated with egg contamination. Thus as one Salmonella type is controlled, others appear to evolve to fill the gap in what is obviously a very useful niche for this organism.\n\nA similar picture of evolutionary change has been seen in other Salmonella spp. Such a change in S. typhimurium has been linked to the use of antimicrobials in food production and this will be described in detail later.\n\nA further trend recently identified in Salmonella infections has been an increased association of outbreaks with previously unusual vehicles, like fresh produce. Many such crops are now produced in developing countries where manure is frequently used as a natural fertiliser. Ongoing studies suggest that some Salmonella spp. have now evolved to attach to and colonise vegetables (Barak et al., 2005; Klerks et al., 2007; Franz and van Bruggen, 2008) . For this purpose they have exploited existing virulence factors such as type III secretion mechanisms.\n\nThus it seems increasingly that Salmonella spp. are remarkably adaptable organisms able to evolve to fill new niches and respond to environmental challenges. Post-genomic studies are beginning to demonstrate how such agents can adapt to occupy novel habitats. Certainly some Salmonella spp. may undergo genome degradation where loss of DNA may lead to improved regulatory function of certain genes, thus improving survival mechanisms and providing new host and novel environmental habitat opportunities.\n\nAlthough Salmonella commands considerable media attention, Campylobacter spp. are the most commonly reported cause of acute bacterial food poisoning in the European Union (http://www.efsa. europa.eu/EFSA/DocumentSet/Zoon_report_2006_en,0.pdf) and, therefore, a major target for reduction in the public health burden of intestinal infectious diseases. Few European countries have consistent and longterm data on campylobacteriosis but in the United Kingdom case reports have been recorded since 1982. Infections increased year on year until 2000 after which there was a drop of about 20% until 2004. This drop was mirrored in several other countries (http://www.rivm.nl/infectieziektenbulletin/bul1607/art_trends.html) raising hopes that interventions had been effective but since then there has been a further slow increase (http://www.hpa.org.uk/webw/HPAweb&HPAwebStandard/ HPAweb_C/1195733838402?p=1191942152851) (http://www.hpa. org.uk/hpr/archives/2008/hpr0208.pdf).\n\nThe reasons for the variations in incidence of this disease are unclear and the explanations are complex. Because under reporting of campylobacteriosis is significant (Tompkins et al., 1999) , communitybased changes in public health attitudes and resources could readily influence trends. It is tempting to consider that interventions introduced to prevent and control campylobacteriosis have had an effect. Certainly since the early 1980s enormous effort has gone into identifying and controlling the sources of infection. This effort has been largely focussed on the poultry industry as Campylobacter contamination of poultry meat from colonised chickens is considered the major source. National strategic plans have been adopted in several countries targeted at the on-farm, processing and kitchen hygiene levels. However, there are no available consistent interventions to prevent or reduce poultry infection on the farm and the implementation of available post-harvest interventions, such as use of hyper-chlorinated water washes, has been limited (for example in Europe, by legislation). To date a few, mainly Scandinavian (particularly Iceland and Norway), countries have managed to substantially reduce poultry flock prevalence, which has allowed the separation and post-harvest treatment of broiler meat from positive flocks to be economically viable. In New Zealand the focus has been on postharvest interventions mainly by the introduction of hyper-chlorinated water washes and targets for carcass contamination. Surveillance in these countries suggests that such major strategic efforts can be effective, but only in part. The reason for this is unclear but may indicate that other sources are also important.\n\nAnother potential influence could be changing population susceptibility due to acquired immunity and changing demographics. The evidence for this is growing (Miller et al., 2005) and certainly in the United Kingdom there is a recognisable shift in infection away from infants towards the elderly (http://www.hpa.org.uk/webw/HPAweb& HPAwebStandard/HPAweb_C/1195733853810?p=1191942152851). There is a growing awareness of the effect of acquired immunity on the epidemiology of campylobacteriosis (Havelaar et al., 2009) . Thus the impact on the population of reducing regular exposure to Campylobacter antigens by removal of campylobacters from broiler meat needs to be a future consideration.\n\nA final influence affecting trends in infection could be changes in the Campylobacter population. However, Campylobacter spp., unlike Salmonella, have no useful historical typing data with which to investigate changing trends in bacterial populations. The population structure of Campylobacter jejuni is now known to be weakly clonal, which is a reflection of the plasticity of the Campylobacter genome. This is susceptible to point mutations and genomic instability and can readily take up foreign DNA. This results in an enormously diverse population of types regardless of which typing system is used. Nevertheless, it is now clear that some stable clones of C. jejuni have persisted over time and distance (Manning et al., 2001) , and such clones may provide insight on changing trends. The introduction of Multilocus Sequence Typing (MLST) as a harmonized epidemiological tool will, in the future, enable the following of population changes.\n\nC. jejuni/coli cannot grow outside a host. However, they rapidly and effectively respond and adapt to environmental stresses such as antimicrobials, temperatures, dehydration, bacteriophages etc, by exploiting this genomic plasticity. Campylobacter appears to have used this adaptive capacity to evolve to occupy new niches and to survive stressful ones enabling these organisms to become ubiquitous in the environment. In this process changes to the physiology of the organism may well result in variation in the mechanisms, as yet unknown, which cause illness in humans. One example of this is the rapid and effective acquisition and persistence of resistance to fluoroquinolones and this will be discussed later.\n\nOverall, its genomic diversity and adaptive capacity have enabled various Campylobacter spp. to be remarkably successful commensals in most warm-blooded animals. Unfortunately in humans the outcome of infection is less than pleasant. There is little evidence that the various targeted intervention strategies adopted or planned in Europe, such as freezing contaminated carcasses, will be effective at reducing campylobacteriosis (www.efsa.europa.eu/EFSA/efsa_locale-1178620753812_1178716893972.htm) and without doubt the adaptability of this organism suggests that it will be able to continue to circumvent our attempts in the future.\n\nE. coli is another highly successful gut coloniser in many host species. E. coli strains isolated from intestinal diseases have been grouped into at least six different diarrhoeagenic E. coli (DEC) groups based on specific virulence factors and phenotypic traits; these include enteropathogenic E. coli (EPEC), enterotoxigenic E. coli (ETEC), enteroinvasive E. coli (EIEC), enteroaggregative E. coli (EAggEC), diffusely adherent E. coli (DAEC), and Vero cytotoxinproducing E. coli (VTEC) or Shiga toxin-producing E. coli (STEC). Foodassociated outbreaks have been particularly associated with VTEC, and to a lesser extent EPEC, ETEC and EaggEC strains.\n\nAmong the VTEC strains, E. coli O157:[H7] (i.e. VTEC O157) has become widely recognized as a very important cause of food-borne illness over the last two decades. With improved detection methods it has become increasingly clear that types of VTEC, other than O157, are also causes of food-borne human intestinal infectious disease worldwide, especially O groups O26, O103, O111 and O145 E. coli O157.\n\nE. coli O157 was first recorded in 1982 in outbreaks of severe bloody diarrhoea in North America. Such outbreaks increased dramatically and became widespread in the following years. It has been estimated that in the United States, E. coli O157:H7 causes 73,000 illnesses and 250 deaths annually. The first recognized community outbreak of O157:H7 in Europe occurred in the United Kingdom in the summer of 1985 and further outbreaks and sporadic cases have been reported throughout Europe ever since. In England and Wales, 33% of outbreaks are food-borne (Gillespie et al., 2005) . In the early outbreaks the sources were most often found to be contaminated beef meat, often minced, and the organism is widespread in the guts of asymptomatic cattle. As a reflection of the seriousness of such outbreaks, extensive legislation, new food handling practices and food-producer education have been introduced and implemented over the last 20 years. Despite these, large outbreaks still occur mainly due to producer incompetence; most recently an outbreak among schoolchildren in south Wales in 2005 involved 157 cases, with the death of a five year old school boy (http://news.bbc.co.uk/1/hi/wales/south_east/6983113.stm). Professor Pennington, who chaired the subsequent enquiry, stated \"The requirements for food hygiene that were in place at the time of the Outbreak should have been sufficient to prevent it.\" (http://wales.gov. uk/ecoliinquiry/?lang=en). So it seems that even though lessons have been learnt, and processes changed accordingly, outbreaks cannot be avoided. Also, importantly, risk factor studies indicate a shift from contaminated meat products towards environmental transmission in some countries, such as via contact with farm animals or gardening (Coia et al., 1998) . This could constitute major future challenges for public health interventions of this potentially serious disease.\n\nEnteropathogenic E. coli (EPEC) is also considered a potential foodborne pathogen, though surveillance for this DEC type is generally poor. Although the true association with food vehicles is unclear, sporadic infections with this type continue to be reported with chicken and beef as common sources. Both enterotoxigenic E. coli (ETEC) and enteroaggregative E. coli (EAggEC) may also be associated with food-borne outbreaks albeit infrequently.\n\nMost of current knowledge on trends and persistence of foodborne E. coli infections is derived from studies on VTEC. As indicated previously, in the early outbreaks the sources of VTEC were most often found to be contaminated beef meat but today almost any vehicle in contact with ruminant feces is potentially a source including vegetables, sprouts, fruits, meat products (such as dry fermented sausages), juices and milk (both pasteurized and unpasteurized) as well as fecally-contaminated drinking, recreational and bathing waters and novel transmission routes for outbreaks continue to arise. In 2006 an outbreak of E. coli O157 was linked to the consumption of fresh, bagged, baby spinach, with 26 US states and Canada reporting 205 cases of illness and 3 deaths. Subsequent investigations implicated the presence of wild boar in the fields as the source of infection. The reason for this changing profile is unclear but may indicate an evolving bacterial population taking advantage of novel niches.\n\nInterestingly geographical differences in both prevalence and serotype distribution of all VTEC types are reported. Not all of these differences are explainable by variation in diagnostic approaches. These observations suggest some country-specific host specificity, possibly as a result of husbandry factors or restricted exposure. Moreover, although non-O157 VTEC are also common in ruminants, many types are rarely implicated in human disease, indicating the evolution of type-specific differences in virulence leading to hostspecificity in the outcome of infection.\n\nA disturbing feature of E. coli is its ability to continuously evolve types never previously reported or characterized. A recent example was an O103:H25 VTEC isolated during an outbreak in Norway. On genetic analysis (virulotyping) this strain possessed virulence genes, which had only been isolated once before from a sporadic case in Norway three years prior to the outbreak. Recent comparative genomic analysis of VTEC strains, particularly O157, has clearly demonstrated the ancestral backbone of this group of organisms. A combination of the gain and loss of genetic elements and mobility of virulence factors has resulted in a stepwise evolution of lineages (Wick et al., 2005; Wu et al., 2008) , which have diverged in terms of pathogenicity and host association. The generation of novel combinations of virulence factors is resulting in the ongoing emergence of new virulotypes, which are able to occupy previously unrecognized niches.\n\nThere are of course many bacteria transmitted via food-borne routes and causing disease in humans. The focus of policy makers tends to be on those pathogens described above on the basis of predominance in outbreaks, severity of disease outcomes, major prevalence of infections and/or public perception. More recent approaches to measurement of burden of disease suggest that such criteria may not always indicate the relative importance of less wellrecognized food-borne pathogens. Moreover, the importance of \"minor food-borne\" pathogens may change over time. L. monocytogenes is one such pathogen. Although, listeriosis is a relatively rare disease, the infection has a high fatality rate (20-30%). L. monocytogenes acts as an opportunistic pathogen most often affecting those who are immune compromised (e.g. by immunosuppression or with HIV/AIDS), pregnant women, unborn or newly delivered infants, and the elderly. The organism is commonly found in soil, surface water, plants and foods but because it is able to grow at refrigeration temperatures, packaged ready-to-eat foods are common vehicles of infection.\n\nThe observed pattern of listeriosis in several European countries is reported to have changed during (Denny and McLauchlin, 2008 . There was an increase in the number of laboratory confirmed cases, especially in patients aged 60 years and over. Moreover, the clinical presentation of disease has also changed, with more cases presenting with bacteraemia in the absence of central nervous system involvement (Gillespie et al., 2009 ). The reason for this differing pattern is, as yet, unknown but changes in food consumption habits in the elderly may have contributed.\n\nSalmonella, Campylobacter and strains of E. coli are well-established examples of common food-borne pathogens. They are markedly different in terms of epidemiology, physiology, ecology, host association and virulence properties, but together enable some generic conclusions to be drawn on the overall persistence of food-borne bacterial disease over the last 20 years. Although these are the major bacterial pathogens monitored, many others are also transmitted through food. At anytime such relatively minor food-borne pathogens, like L. monocytogenes, can also become major problems. Investigating the reasons for such shifts in patterns of food-borne disease provides valuable information for future risk management strategies.\n\nFrom the examples discussed above, for which data can be assessed over relatively long periods, it would seem that there is little evidence we are winning significant ground in the battle against food-borne illness caused overall by bacterial pathogens. In fact even the most successful interventions, such as vaccination of chickens against Salmonella, have done little more than reduce the pathogen load in the food chain. It can be speculated that such reductions in exposure could have some adverse affects, for example, by altering the immune status of the population. There are already disturbing trends such as shifts away from illnesses, such as campylobacteriosis and listeriosis, in the young towards the increasingly growing older population. In addition these pathogens are constantly evolving and adapting enabling the exploitation of novel opportunities, for example, new vehicles created by modern processing techniques, new retailing fads or new food consumption habits. This highlights the need for multidisciplinary research, and especially the inclusion of social sciences, to investigate changing trends in food-borne disease.\n\nDespite the substantial investments made by governments and industry alike, these bacterial pathogens still feature as major public health problems. However, these investments have not been without their successes; a combination of biosecurity and vaccination has largely eliminated S. enteridis PT 4 from the breeder and layer flocks in many European countries, while legislation and retailer education have sufficiently improved hygiene to reduce E. coli 0157 in cooked meats. Clearly we need to share and implement throughout Europe those strategies that are effective while maintaining constant vigilance against the ability of such organisms to adapt to changing environments and to exploit the opportunities that arise to occupy novel niches.\n\nAntimicrobial resistance is a particular issue for bacterial pathogens in the food chain. For more than 50 years, antimicrobial agents have been an essential component of infectious disease treatment, in both human and veterinary medicine, and the use of such agents has resulted in the development and spread of antimicrobial resistance. The public health consequences of this resistance can involve increased frequency of treatment failures and severity of infection including prolonged duration of illness, progression to systemic infections, increased hospitalization, and increased mortality (www. who.int/foodsafety/publications/micro/en/report.pdf).\n\nAny kind of antimicrobial use, be it for human, animal or plant health purposes, can select for emergence of resistance and further promote the dissemination of resistant bacteria and resistance genes. As antimicrobial resistance disrespects all borders, whether political or biological, antimicrobial use in one ecological compartment can have a consequence on the resistance status in another (Kruse and Sorum, 1994) . Consequently resistance selected for in the agricultural sector can contribute to the public health burden.\n\nFood can be a source of both antimicrobial resistant bacteria and resistance genes. The presence in food of antimicrobial resistant pathogenic bacteria, such as Salmonella spp. or Campylobacter spp., can provide a direct infection hazard following ingestion or food handling. The transfer of resistance genes to a bacterium pathogenic for humans, either directly, or via a commensal, such as E. coli and Enterococcus spp., is viewed as an indirect hazard. Mobile genetic elements harbouring resistance determinants can readily be transferred horizontally between bacteria from terrestrial animals, fish and humans and through various routes including food; furthermore, such transfer can take place in naturally occurring environments such as the kitchen (Kruse and Sorum, 1994) . The relative contribution of each route to the risk of antimicrobial resistance in microorganisms of public health concern is too complex, with too many uncertainties to estimate, but there is increasing evidence that food is important. In addition, antimicrobial resistance may be a consequence of the direct contact of bacteria with the residues of antimicrobial agents in food. However, whilst acknowledging the toxicological concerns with antimicrobial residues, this mechanism of antimicrobial resistance spread seems less important than the previously mentioned routes (www.who.int/foodsafety/publications/micro/en/report.pdf).\n\nIn the following section a number of examples of food-borne antimicrobial resistance in bacteria are discussed.\n\nFood is an important infection route for Salmonella including those that are resistant (European Food Safety Authority, 2006) . Antimicrobial resistant Salmonella causing food-borne human disease are well documented (www.who.int/foodsafety/publications/micro/en/ report.pdf). Implicated foods are typically beef, pork, poultry, dairy products, but also eggs and fresh produce. Reports also confirm transmission of the strains from the food animal, into foods, and subsequently to the human population. Furthermore, sometimes the emergence of the antimicrobial strain has been linked to use of antimicrobial agents at the farm level. There is direct evidence that antimicrobial use in animals selects for antimicrobial-resistant nontyphoid Salmonella serotypes. These bacteria can be transmitted to humans via food or direct contact with animals (http://www.who.int/ emc/diseases/zoo/oct97.pdf).\n\nTo some extent antimicrobial resistance in Salmonella is serotypedependent, with resistance and multiple-resistance common in serotypes such as Typhimurium, Virchow, Derby and Newport. The most common resistances observed are typically to those antimicrobials that are frequently used in animal husbandry (European Food Safety Authority, 2006). S. enteriditis rarely displays multiple-resistance, although resistance to antimicrobials such as nalidixic acid coupled with decreased susceptibility to ciprofloxacin is increasing in prevalence. S. typhimurium definitive phage type (DT) 104 often expresses multiple-resistance. Although declining in incidence in Europe, this S. typhimurium strain remains a significant public health hazard world-wide (Threlfall, 2000) . Extended spectrum betalactamase (ESBL) resistance has also recently arisen worldwide in Salmonella. Strains exhibiting such resistance have been detected in both humans and animals (www.cvi.wur.nl/NR/rdonlyres/A906A4C0-A458-423E-B932-28F222385988/83791/MARAN_2007_def3.pdf).\n\nSalmonella typhi and paratyphi A do not have a food animal reservoir but infections can be spread by eating food that has been improperly handled by infected individuals, or by drinking water that has been contaminated by sewage containing the bacteria. Substantive outbreaks of typhoid fever caused by antimicrobial resistant strains, with significant mortality, have been reported in developing countries as a result of contaminated water supplies (Mermin et al., 1999) .\n\nFood, in particular poultry meat, is considered the most common infection route for thermophilic Campylobacter, including antimicrobial resistant strains. A temporal association between the emergence of resistance, particularly to fluoroquinolones, in animals and humans following the introduction of the use of these antimicrobials in animal production has been demonstrated (http://whqlibdoc.who.int/hq/ 1998/WHO_EMC_ZDI_98.12_(p1-p130).pdf, http://www.who.int/ foodsafety/publications/micro/en/report.pdf). Reports from some, but not all, countries show that Campylobacter from poultry meat are frequently resistant, especially to fluoroquinolones, while casecontrol studies have identified foreign travel as a risk factor for the acquisition of a quinolone-resistant Campylobacter infection, with food as a likely vehicle.\n\nFoods are important vehicles for human infection with Shigella and Vibrio spp., including antimicrobial resistant strains. Food-borne outbreaks of infections with antimicrobial resistant Shigella and Vibrio spp. have been reported. For Shigella, implicated foods have included seafood and fresh produce, and for Vibrio outbreaks a variety of food products have been involved, most often seafood, as well as water.\n\nWorldwide, MRSA is a significant and increasing cause of nosocomial infections. Furthermore, community-acquired MRSA infections are an emerging problem. MRSA has recently also become a zoonotic issue following detection in various companion and foodproducing animals, including horses, dogs, cats, pigs, cattle, chickens, rabbits, seals, and birds. A particular MRSA strain, so-called NT (\"nontypeable\" by pulsed-field gel electrophoresis) MRSA or sequence type (ST) 398 (by MLST), has increasingly been isolated from pigs and pig farmers. Currently an EU-wide baseline study of the prevalence of MRSA in breeder pigs is ongoing to better understand the epidemiology of this emerging strain in Europe. A recent Dutch study showed that MRSA can be detected at very low concentrations (<10 cfu/g) in unheated meats from various domestic animals and fowl. This survey indicated that the overall prevalence of MRSA was 11.9% of 2217 retail samples of raw meat, with highest prevalence in poultry meat. For all meat types, the MRSA strains were predominantly (85%) of the NT ST398 type (de Boer et al., 2009) . Thus, other livestock may be a significant source of MRSA. Nevertheless, it is currently unclear to what degree the MRSA types in animals, and in particular the emerging clone ST398, are food safety, or even public health, risks.\n\nCases of illness following the consumption of MRSA-contaminated food have been described, presumably originating from the food preparers. Case-control studies in both Denmark and The Netherlands have shown that people at risk of colonisation with ST398 are most likely to be working or living on farms and mainly in direct contact with animals. Thus, in accordance with the EFSA Biological Hazards Panel opinion, animals and animal products remain a potential source of community-acquired MRSA and this requires risk assessment (www.efsa.europa.eu/EFSA/efsa_locale-1178620753812_1211902408708. htm). Moreover, food-associated MRSA may be an emerging problem (van Loo et al., 2007) .\n\nInfections with multi-resistant E. coli are an important public health problem. Commensal E. coli can be a source of resistance genes for pathogenic E. coli strains. (www.who.int/foodsafety/publications/ micro/en/report.pdf). The spread of resistance genes from animal to human E. coli, and from commensal to pathogenic Enterobacteriaceae, has been documented (www.who.int/foodsafety/publications/micro/ en/report.pdf). The role of food in such transfer is not yet known and needs further investigation. The transfer of resistance genes from E. coli to Salmonella has been demonstrated experimentally in the poultry intestinal tract (Gast and Stephens, 1986; Poppe et al., 2005) and there are some reports indicating the acquisition of resistance plasmids by E. coli and Salmonella in the human gut (Su et al., 2003; Yan et al., 2005) . Moreover, the exchange of resistance genes between bacterial clones has been demonstrated experimentally in water, soil, on kitchen towels, on cutting boards, and on the surface of foods (Kruse and Sorum, 1994; Walsh et al., 2008) .\n\nEnterococci are important causes of nosocomial infections, and vancomycin-resistant enterococci (VRE) is a particularly serious problem. A reservoir of VRE in food-producing animals has been created by the former use of avoparcin, a glycopeptide antimicrobial, as an antimicrobial growth promoter in animal production. VRE can also be isolated from animal products as well as from farmers and other non-hospitalized humans. Molecular studies indicate that the horizontal transfer of resistance genes plays an important role in the persistence of VRE in animal environments and that the vanA gene can be transferred from animal to human isolates. Although there is little evidence of human infections being directly linked to the consumption of VRE-contaminated foods, the reservoir of VRE in food-producing animals presents a risk of vancomycin-resistance being transferred to virulent human strains through food and other routes. (www.who.int/foodsafety/publications/micro/en/report.pdf).\n\nManaging the human health risks associated with antimicrobial resistant bacteria in the food chain requires national and international, interdisciplinary and inter-sectoral cooperation. In response, the Codex Alimentarius in 2007 set up a Task Force to specifically address risk assessment and risk management related to antimicrobial resistance associated with food (www.codexalimentarius.net/web/ archives.jsp?lang=en).\n\nThe prudent use of antimicrobial agents in all sectors is a key aspect of the prevention and control of antimicrobial resistance (http://whqlibdoc.who.int/hq/2000/WHO_CDS_CSR_APH_2000.4. pdf; www.who.int/foodsafety/publications/micro/mar04/en/index. html). This is acknowledged by various international organizations, such as the WHO, OIE, FAO, and the EC, as well as professional associations and national authorities. Such prudence will not only safeguard the efficacy of antimicrobial drugs in veterinary medicine, but importantly, will prevent the emergence and spread of undesirable resistance phenotypes in pathogens and commensal bacteria transmissible between animals and humans, including via food. In particular the use of antimicrobial agents for growth promotion should not be allowed because it enhances the development and spread of antimicrobial resistance. Consequently the EU banned the use of all growth promoters from 1st January 2006. Outside the EU, the situation differs. For instance Norway does not allow use of antimicrobial agents for growth promotion, whereas the policy in United States remains liberal. An appropriate regulatory system for the approval and licensing of antimicrobial agents is an important aspect of the prudent use of antimicrobials. Antimicrobials should be available on prescription-only. Interestingly, profit by the veterinarian from the sale of antimicrobial agents, seems to negatively impact on prescribing practices (Grave and Wegener, 2006) , therefore regulatory systems should prevent practitioners receiving payment for prescribing antimicrobials in order to prevent misuse and overuse of antimicrobial agents.\n\nIt is critical that antimicrobial use is not considered in isolation from infection control (www.who.int/foodsafety/publications/micro/ mar04/en/index.html). The best way of minimizing the need for and use of antimicrobials is by disease prevention, which relies on a holistic approach encompassing animal husbandry and management, nutrition, animal welfare, and vaccination. Routine prophylactic use of antimicrobials should be never be used as a substitute for good animal management practices.\n\nAnother important aspect of prudent use is accurate diagnosis and antimicrobial susceptibility testing. Before initiating antimicrobial therapy, the practitioner should ascertain that such therapy is justified. Empirical use of antimicrobials should be avoided whenever possible and antimicrobials should be preferably prescribed on the basis of laboratory diagnosis and antimicrobial susceptibility testing. When antimicrobial therapy is initiated, it is important to choose the appropriate antimicrobial product and administration route. Ideally, only diseased animals should be treated, and the treatment should be as individual as possible. However, in the case of poultry and farmed fish this is not practical, and mass-treatment is accepted following a relevant diagnosis. Metaphylaxis, where clinically healthy animals are treated along with their diseased \"neighbours\", should be avoided. Prophylaxis should be minimised. Local treatment should be preferred to systemic treatment when the infection is localized and accessible to topical products. Consideration should be given to the potential public health consequences of resistance to the antimicrobial in question. In general, narrow-spectrum (and older) antimicrobials, if appropriate and available, should be preferred to broad-spectrum drugs. Furthermore, veterinarians should only prescribe antimicrobial formulations that are approved for the species and the indication concerned. Antimicrobials identified as critically important in human medicine (http://whqlibdoc. who.int/hq/1998/WHO_EMC_ZDI_98.12_(p1-p130).pdf, www.who. int/foodborne_disease/resistance/en/; www.who.int/foodborne_ disease/resistance/antimicrobials_human.pdf), should only be used in animals if their use is justified. These include the fluoroquinolones and the 3rd and 4th generation cephalosporins.\n\nClearly antimicrobial resistance is a rapidly changing challenge. The evolution and adaptation of the bacterial agents and the changes in antimicrobial use, whether commercially or legislatively driven, are major influences on the impact of antimicrobial resistance on public health. Therefore the monitoring of antimicrobial resistance and antimicrobial usage in human and animals should be an integral part of the prevention and control of antimicrobial resistance. Such data provides useful information on trends in resistance, which are necessary for risk assessment and risk management and a basis for choosing, implementing and evaluating interventions (www.who.int/ foodsafety/publications/micro/mar04/en/index.html.\n\nVirology is a rapidly expanding science, leading to the discovery of new viruses at a seemingly increasing pace. The past two decades alone have witnessed the emergence of the SARS coronavirus, and the realization that highly pathogenic avian influenza viruses (HPAI) of subtypes H7N7 and H5N1 are able to infect humans Yuen et al., 1998) . We also learned that this applies to other zoonotic viruses that previously went unnoticed such as Nipah virus, and new genotypes of hepatitis E virus (Chua et al., 1999; Yazaki et al., 2003) . Each of these viruses is capable of causing significant illness and mortality in humans. In addition to this list, several other viruses have been discovered, some of which may have been around for much longer but simply escaped detection. A typical example has been the discovery of two additional coronaviruses causing human illness as a result of enhanced research following the SARS outbreak.\n\nThe above mentioned examples, SARS, avian influenza and hepatitis E, are viruses that are present in the intestinal tracts of infected humans and animals, and are shed into the environment through feces which can contain high levels of virus. SARS coronavirus was spread into the human population through the preparation and consumption of food animals that appear to have contracted the infection from another reservoir, probably bats (Lau et al., 2005) . Infectious H5N1 avian influenza virus has been grown from duck meat and the consumption of duck blood has resulted in the infection of humans (Tumpe et al., 2002) . While this is hardly a large-scale food habit, the above incidents have captured media attention and have raised the question if food-borne introduction could be one of the routes by which new viral diseases can enter the human population. Although difficult to state with certainty, there is consensus among virologists that the probability of the emergence of new viruses, or the evolution of old viruses into new forms, is inevitable given the demographic, economical, and sociological changes that we are now facing. An example is seen in the transportation of living animals in the globalizing food-market, the changing food-habits towards consumption of exotic products, and expansion of the human population (Brown, 2004) .\n\nRemarkably, the microbiological quality control criteria for food globally still relies on standard counts of coliform bacteria that were developed as indicators for fecal contamination. There is now ample documentation that these criteria are insufficient to protect against viral food-borne infections. For example high loads of infectious human pathogenic viruses have been detected in foods at retail that passed all microbiological control criteria, and this has led to discussions about the validity of proof for a recall. It is, therefore, important to understand the fundamental properties of food-borne viruses in order to design improved strategies capable of controlling both classes of pathogens:\n\n\u25cb Viruses do not grow in food: Viruses need living cells to replicate, and almost all food-borne viruses are strictly human pathogens. This means that the transmission via food reflects faecal contamination, with the persistence of viruses on or in the product, but no replication. Zoonotic viruses such as hepatitis E or tick-borne encephalitis virus may also be present without fecal contamination in animal products such as pig liver or cow's milk, but again will not replicate without living cells. Given the numerous reports of norovirus outbreaks in association with bivalve molluscan shellfish, the possibility of virus replication has been considered, but there is no evidence. \u25cb Most food-borne viruses are (very) infectious, spreading rapidly from one individual to the next: For the most common food-borne viruses, only a few infectious particles (10-100) may result in a high probability of infection, whereas very high loads of viruses may be shed in stool samples of infected individuals (10 6-7 per gram of stool or more). Therefore, unless the initial cases in a food-borne transmission are detected, the event may present as a person-to-person outbreak that will not be attributed to food as a source of the infection. \u25cb There is no systematic surveillance for food-borne viral disease: There is a range of clinical syndromes associated with different foodborne viruses. Noroviruses, astroviruses, and rotaviruses for instance cause acute gastro-enteritis with vomiting and diarrhoea, whereas hepatitis A and E viruses may cause hepatitis that can be recognized by the development of abdominal pains and jaundice (Table 1) . Enteroviruses may cause a range of clinical syndromes, varying from diarrhoea to meningitis and rash illnesses. Most countries have some level of reporting of food-borne illness outbreaks, but few of these systems include viral food-borne illness. Case-based surveillance exists for hepatitis A and enteroviruses, but is not usually focused on detecting food-borne transmission as a source of the infection. As a result, national statistics on food-borne viral disease are not easily available and, where present, likely to reflect significant under-reporting. In the UK, for each case recorded in the national surveillance system, an estimated 136 cases are present in the community (O'Brien, 2008) . Food-borne transmission has been documented for viruses belonging to at least 11 known families. Noroviruses and hepatitis A food-borne illnesses have most frequently been documented, but several other viruses have also been identified as food-borne (Table 1 ) Koopmans and Duizer, 2004) . All these viruses are capable of infecting a host following oral ingestion, and need to be able to pass the stomach and those proximal parts of the small intestine with contents that are rich in digestive enzymes and bile salts. Therefore, the viruses associated with food-borne transmission are typically non-enveloped particles that are stable outside the host and consequently should remain infectious in the environment or on food. However, Nipah virus and tick-borne encephalitis viruses, for instance, have lipid envelopes and, therefore, probably have a reduced stability. Nevertheless, these viruses have been associated with foodborne infection (Luby et al., 2006; Kr\u00edz et al., 2009) .\n\nNoroviruses are now recognized as one of the most common causes of gastro-enteritis at the community level (de Wit et al., 2001) . However, because the symptoms are relatively mild, infections go largely unnoticed, except during major outbreaks, especially those in health care institutions, such as nursing homes and hospitals, where high-risk patients may present with more severe symptoms . Both food-and water-borne transmission can occur, but the relative importance of these routes compared to person-toperson spread is unknown.\n\nNoroviruses are a genetically diverse group of viruses. Although, genotyping and strain typing are increasingly used to understand the epidemiology of noroviruses at the research level, these tools are not currently used in routine diagnosis, which could enhance the detection of common-source outbreaks. To enable such routine application the standardisation and harmonisation of strain and genotype nomenclature is required.\n\nThe Food-borne Viruses in Europe network (FBVE) has developed a joint electronic database to facilitate data comparison and harmonise strain nomenclature (www.rivm.nl/bnwww) Koopmans et al., 2003) . Between 2001 and 2007, data from over 10,000 outbreaks were analysed showing that the proportion of foodborne outbreaks varies greatly between countries, presumably reflecting differences in national surveillance systems. Of all reported outbreaks with sufficient epidemiological information, 10% were reported as food-borne, 2% as waterborne, and the rest as person-toperson outbreaks . Within the database several international common-source outbreaks, linked to raspberries and shellfish, were reported . This data was used to identify parameters that discriminated food-borne from person-toperson outbreaks. Using these parameters in model predictions, the estimated proportion of food-borne outbreaks was increased by 50% (Verhoef et al., 2009) .\n\nThe genogroup II.4 strains (GII4), predominated throughout the reporting period, and in all countries, and were more frequently associated with person-to-person outbreaks and health care settings than with food-borne outbreaks. As non-GGII4 strains were almost 9 times more likely to be food-borne, the use of rapid typing techniques early in an outbreak investigation could reduce the proportion of outbreaks requiring more intensive follow-up (i.e. suspected foodborne).\n\nMolecular typing is also providing information on trends in disease. Interestingly new variants of GII4 emerged in 2002 GII4 emerged in , 2004 GII4 emerged in and 2006 ; each time displacing the resident virus population within months across Europe indicating viral evolution (Siebenga et al., 2007 (Siebenga et al., , 2009 . Molecular analysis of the emerging variants showed that a limited number of mutations are consistently found with each new variant, suggesting that this evolution is immune driven (Siebenga et al., 2007) . Data from syndromic surveillance in The Netherlands has indicated that these new variant strains can be associated with increased and significant mortality.\n\nRecent expert advice on food-borne viruses for Codex Alimentarius (www.who.int/foodsafety/publications/micro/mra13/en/index. html ) concluded that there are five virus-commodity combinations for which prevention and control measures should be considered: Noroviruses and hepatitis A in bivalve molluscan shellfish or fresh produce or prepared foods and rotaviruses in water for food preparation and emerging viruses in selected commodities. Further details for each combination are given below.\n\n\u25cb Noroviruses and hepatitis A in bivalve molluscan shellfish: Outbreaks of norovirus illness and hepatitis A following consumption of bivalve molluscan shellfish have been extensively documented (i.e. Le Guyader et al., 2006) . The consensus is that the consumption of shellfish is associated world-wide with an increased risk of viral infection. Although there is no systematic surveillance data for shellfish harvesting areas, where this is done, virus contamination is found with a high frequency due to regular sewage contamination. Often multiple viruses are present in contaminated shellfish, adding the extra risk to consumption of simultaneous ingestion and infection with two related viruses possibly resulting in the mixing of viral genes to generate new, recombinant viruses. This is a process for which the outcome, in terms of pathogenicity and behaviour of the progeny viruses, is unpredictable and therefore, from a virological point of view, highly undesirable. The clinical impacts of noroviruses and hepatitis A are quite different: noroviruses illness can be prevalent but cause relatively mild gastro-enteritis whereas hepatitis caused by hepatitis A virus is less common but can have serious consequences. In addition, for hepatitis A virus the risk is increasing as improved hygiene levels mean fewer, asymptomatic childhood infections occur and the proportion of immune individuals in the population is declining. Consequently the potential for outbreaks and illness is increasing in unvaccinated individuals. Prevention through vaccination is recommended for food-handlers (Atreya, 2004) . \u25cb Noroviruses and hepatitis A in fresh produce: Noroviruses and hepatitis A virus are also well documented in fresh produce, with large outbreaks (often international) reported related to the consumption of contaminated berries and green onions (Le Guyader et al., 2004; Wheeler et al., 2005) . The suspected source of contamination in these cases is presumed to be polluted irrigation water. Although this is plausible, conclusive evidence is lacking and there is remarkably little knowledge of the exact growing conditions for these products produced for the international market. \u25cb Noroviruses and hepatitis A in prepared foods: Arguably the majority of food-borne viral illness results from the contamination of foods by food-handlers shedding viruses. Any contaminated food items, not treated in a manner that will inactivate the viruses after handling (e.g. by cooking), are potential sources of infection. The evidence for such modes of transmission is extensive; often associating outbreaks with clear breaches of hygiene codes. Unsurprisingly a risk factor analysis for norovirus gastro-enteritis in a large community-based study in The Netherlands found a correlation between the increasing rate of infection and decreasing kitchen hygiene (de Wit et al., 2003) . The study also estimated that 10-15% of noroviruses cases were attributable to food contamination. Whether this reflects the attributable risk elsewhere is currently unknown. \u25cb Rotaviruses in water used for food preparation: Group A rotaviruses are the most common cause of hospitalization for diarrhoeal disease in infants and are globally responsible for a significant number of deaths, particularly in non-industrialized countries. While the burden of rotavirus illness has been extensively mapped across the world, very little attention has been paid to identifying the potential modes of transmission other than person-to-person spread. Given the young age at which rotaviruses have the greatest impact, the use of powdered milk reconstituted with poor quality water, seems a likely source. Evidence for this has been difficult to obtain. Bottle-feeding has been identified as a risk factor for rotavirus infection in young children (Duffy et al., 1986) , but this could also be explained by the lack of immune protection acquired from breast-feeding, rather than the consumption of contaminated milk. \u25cb Emerging viruses in selected commodities: Outbreaks associated with food-borne transmission of newly emerging viruses are a low probability event but have a potentially high impact. The examples of SARS and avian influenza, and the relatively uncontrolled foodborne transmission of less dangerous viruses, illustrate that, should a novel pathogen with efficient food-borne transmission arise, we are likely to be ill prepared to handle such an event.\n\nSystematic surveillance of food-borne illness among humans, as well as expedited international data exchange, can assist in early identification of such outbreaks.\n\nA major hurdle in determining the need for control of food-borne viral diseases is the lack of population-based estimates of the burden and cost of illness due to food-borne viruses. Surveillance data, where available, greatly under report the true incidence of infection and illness. The biggest challenge, however, is to reliably attribute the proportion that is food-borne. Estimates of the proportion of viral illness attributable to food are debatable but range from around 5% for hepatitis A to 12-47% for norovirus.\n\nAnother hurdle to the control of food-borne viral disease is the detection of viruses in foods. Such detection largely depends on molecular techniques, because culture is either difficult (hepatitis A) or even impossible (noroviruses). Such methods are confounded by challenges like viral evolution leading to the requirement for new PCR primers, focal sources like food handlers, or relatively low concentrations of target. Nevertheless, significant progress has been achieved in some foods such as shellfish and for outbreak investigations. However, the results can lead to confusion because virus-positive foods may comply with regulations based on the testing of coliforms. Thus foods may pass regulatory requirements on the basis of bacterial content but still constitute a public health risk because of the presence of pathogenic viruses. Moreover, results from food testing and patient testing may be discordant due to the presence of multiple strains and PCR-based detection may be disputed because it does not provide information about the viability of the target organism. Clearly, future guidance is needed on the use of molecular-based virus detection methods.\n\nIn conclusion, food-borne transmission of viruses has long been recognized, but as of 2008, the microbiological quality control criteria for food globally rely on standards that have been developed for bacterial food-borne infections. There is now ample documentation that these criteria are insufficient to protect from viral food-borne infections, and that the burden of food-borne viral illness is significant. It is important to understand the fundamental differences between viral and bacterial pathogens in order to design improved strategies capable of controlling both classes of pathogens. Strategies to prevent viral food-borne disease should focus on primary prevention of contamination of food early in the food chain, for example, by regulating the standards for irrigation water. In view of the lessons of the past decades, in which several new viral disease problems emerged, and the food market has become a global one, developing ways to control food-borne viral illness should become a priority.\n\nParasitism is a symbiotic relationship between two organisms in which the parasite benefits for growth and reproduction to the harm of the host. Parasitism is carried out by many organisms but for the purposes of this paper the term refers to protozoa and helminths.\n\nProtozoa are unicellular eukaryotes, which replicate inside, but can also survive outside, their host. Helminths are eukaryotic parasitic worms, ranging from a few millimetres to several meters in length, and include cestodes (tapeworms), trematodes (flukes) and nematodes (roundworms). Approximately 300 species of parasitic worms and over 70 species of protozoa have been described that can infect humans. Inevitably, parasite and host interact, and excessive harm done to a host, making it less competitive, also endangers the survival of the parasite. Many parasitic infections are asymptomatic, others cause short-lived effects, and still others may persist in the body for decades, causing chronic disease. For example, the gastrointestinal pinworm Enterobius vermicularis mainly causes itching, and affects more than 200 million people worldwide (Elston, 2003) . In contrast ascariasis, which is also very common with a worldwide distribution, can result in severe infections causing approximately 60,000 deaths per year, mainly in children (O'Lorcain and Holland, 2001) . Up to 10% of the population of the developing world is infected with intestinal wormsa large percentage of which is caused by Ascaris.\n\nParasites that cause food-borne infections and outbreaks are shown in Table 2 . Enteric parasitic infections can be transmitted by the fecal-oral route by eating intrinsically contaminated food or via uptake of free-living parasitic stages from the environment (eggs, cysts and oocysts). Contamination of food products (e.g. fruits, vegetables and meat) can be introduced via feces, soil, irrigation water, sewage, human handling or improper processing of infected meat. Intrinsically contaminated food is caused by parasitic infections of food-production animals or wildlife and can transmit parasites because the product itself is infected (e.g. meat or fish). An example is trichinellosis, a disease caused by a nematode that is exclusively foodborne in origin. Meat of infected swine, originating from small scale backyard farming, horses and wild boar are well known causes of trichinellosis in Europe (Pozio, 1998) .\n\nParasites differ from many bacterial food-borne pathogens in that they do not replicate outside the host, and that they are generally not susceptible to the antibiotics that kill bacteria. Furthermore, most parasites have an environmental resting stage (egg, cyst or oocyst), which is resistant to desiccation, disinfectants and other stresses. Moreover, the probability of causing infections with very low doses is high (e.g. Cryptosporidium spp.; Teunis et al., 2002) . These characteristics tend to hinder the control and prevention of food-borne parasitic diseases.\n\nThe risk of contracting parasitic infections via food in the developed world is presumed to be relatively low. It is certainly lower than in developing countries, because of the accompanying features of poverty i.e. lack of sanitation and control measures, malnutrition, illiteracy and overcrowding. Nevertheless, most food-borne parasites have a worldwide distribution. Even in developed countries estimating the risk of food contamination is often difficult due to the lack of awareness of (public) health professionals and research in this field. The relatively mild or non-specific symptoms, long incubation periods, and unavailable or inadequate laboratory methods, which are typical for parasitic diseases, contribute to under diagnosis of infection. Therefore, accurate data on the incidence, sources and transmission routes of human parasitic infection and illness is scarce and often based on infrequentlyrecognized outbreaks.\n\nIn the case of food-borne parasites, many elements are still lacking to fulfil a risk-based approach as proposed by the Codex Alimentarius Commission, and which is required to implement any risk-based control program. In many cases, parasitic food-borne outbreaks are either not recognised or not identified. In particular, the recovery of parasite stages from food products needs considerably more research.\n\nMolecular identification of parasites is now increasingly important but is still immature compared with bacterial and viral identification methods. The establishment of a European database to study Cryptosporidium and Giardia isolates is one of the challenges for the future (https://hypocrates.rivm.nl/bnwww/MedVetNet/; http://www.hpabioinfodatabases.org.uk/zoopnet/).\n\nThe factors contributing to the increased concern in food-borne parasitic infections are largely the same as for all food-borne pathogens, and some specific examples are of current interest. For instance Echinococcus multilocularis, a cestode parasite causing a serious zoonotic disease, was described for the first time in foxes (its main reservoir in Europe) in The Netherlands in 1999 (van der Giessen et al., 1999) and subsequent surveillance and mathematical modelling then demonstrated the emergence of the parasite in Dutch wildlife (Takumi et al., 2008) . The emergence of such environmental reservoirs probably resulted in the first autochthonous human case diagnosed in 2008. However, little is known about human risk factors because of the long incubation time (5-15 years) but raw vegetables and fruit contaminated with eggs of this parasite are often proposed as one of the transmission routes to humans (Kern et al., 2004) .\n\nAnother factor contributing to the increased concern about foodborne parasites is the rising demand for protein-rich food products such as fish. It is therefore expected that novel, or even wellestablished, fish parasitic infections, such as those caused by Opistorchis, Clonorchis and Anisakis, will emerge in the future.\n\nFood-borne parasitic infections can differ immensely in incidence and disease outcome, and therefore in disease burden. It has, for example, been estimated that 71,000 cases of cryptosporidiosis occur in The Netherlands yearly. In most cases the patient just suffers a selflimiting gastroenteritis, but in immuno-compromised individuals this parasite can cause severe disease (de Wit et al., 2001) . In contrast, although the incidence of E. multilocularis is considered to be low in Europe (Bardonnet et al., 2003) , this parasite causes a serious liver disease requiring lifelong anthelmintic treatment with high cost consequences (Eckert et al., 2000) .\n\nDisease burden can be weighted by disability adjusted life years (DALYs) estimations. DALYs are the sum of years of life lost (YLL) and years lived with disability (YLD). Estimation of the disease burden in (Cook et al., 2000) . Nevertheless, there remains a large uncertainty around source attribution and well designed studies are needed in the future.\n\nReducing the risk of parasitic infection from food relies on several levels of intervention. Traditionally, intrinsic parasitic food-borne infections are controlled at the end of the meat production chain, e.g. the monitoring of individual swine carcasses to control and prevent trichinellosis in humans. It has been shown that these measures are inefficient and largely ineffective in industrialised animal husbandry systems (Pozio, 1998) . Modern food production requires a risk-based approach in which several critical control points are monitored. Parasite-free farming implies strict indoor housing of animals including pest control, proper feed preparation and storage, and general hygienic measures. Such an approach is effective to prevent Trichinella infections in swine and might also be effective to prevent other food-borne infections such as Toxoplasma. However, the current trend is for more extensive (outdoor) livestock rearing to comply with increasing public demand for management practices to improve animal welfare. Such free-ranging livestock, in close contact with both the environment and wildlife, constitutes an emerging risk for parasitic infections (Van der Giessen et al., 2007) .\n\nThe education of farmers, veterinary and public health professionals is essential to improve knowledge and awareness of the risks to humans caused by zoonotic diseases circulating in livestock and the measures needed to reduce spread of all pathogens to products of the food chain. In case of contaminated food products, prevention can be achieved by simple measures including the strict personal hygiene of food handlers and the use of potable water for food processing. For example, the use of sewage or slurry for the irrigation of fruits and vegetables that are eaten raw should be prohibited for a period of ten months preceding harvest. Finally, consumers should be aware of the risks of eating raw food and the possible routes of getting food-borne infections.\n\nThe control of most parasitic diseases is complicated due to their presence in wildlife reservoirs and the lack of vaccines for livestock. One control strategy under consideration is interference with the often complex life cycle of the parasite. For example, Toxoplasma gondii is a ubiquitous parasite using almost all warm-blooded vertebrates as hosts, including humans. Humans can become infected by ingestion of oocysts, excreted by cats, via contaminated soil or water, or foods. A second means of transmission is the ingestion of tissue cysts present in raw or undercooked meat or meat products from so-called intermediate hosts (e.g. sheep and cattle). Even vertical transmission can occur, from mother to child, when women become infected during pregnancy. However, cats are the only definitive hosts for Toxoplasma, responsible for shedding oocysts into the environment. Effective vaccination and/or treatment of cats in order to prevent shedding of oocysts would break the cycle and reduce environmental contamination.\n\nThe expertise in, and awareness of, parasitology in general, and food-borne transmission in particular, is limited. Identification of risk factors, in particular, is hampered by long incubation periods. In addition, because of a lack of tools to define the epidemiology of these infections, the role of food-borne parasites in intestinal infectious disease is underestimated. In a society where there are increased demands for animal welfare friendly production systems, and the globalization of food production, the risks of introducing (or reintroducing) parasitic diseases are high. Therefore, maintaining and extending knowledge in this field is increasingly important.\n\nThis manuscript has reviewed the trends over the last 20 years and challenges for the future of four very different categories of foodborne infectious disease. Each category has its unique challenges but surprisingly many common factors have become apparent. Over millennia, all food-borne pathogens have developed efficient and effective strategies, which exploit, wholly or in part, food as a vehicle to transfer from one human host gut to another, or from an animal to a human. The mechanisms involved are complex and varied but all are able to survive intervening periods in the environment, and then avoid the human innate gut defenses to colonize and multiply rapidly before enabling effective dispersal, frequently through fluid feces, back into the environment to progress again through the cycle. Each of these pathogens occupies a unique ecological niche in this foodrelated cycle.\n\nIt is clear that intestinal infectious disease issues, whether caused by bacteria (antibiotic resistant or not), viruses or parasites, continue to be a major cause of public health concern and social and economic cost worldwide. It is also clear that, at least for viruses and parasites, the extent of this cost is largely unknown and the call is for appropriate surveillance/monitoring, research and intervention. However, experience over the last 20 years indicates that the considerable effort directed at the major bacterial food-borne pathogens appears to have had little impact on the problems in many countries. This does not mean that the strategies adopted are ineffective but that the effect is probably obscured by other changing factors.\n\nThe list of factors influencing the prevalence of such diseases is long and their relative importance largely unknown. The underlying changes may be associated with the pathogens, the sentinel hosts (humans) or other extraneous (political, economic or environmental factors). It is well recognized that the food-borne bacterial pathogens are evolving in response to environmental challenges and in doing so can display new virulence properties and occupy new niches. In addition, the susceptibility of the human population to such infections is also changing as a result of declining acquired immunity with improved hygiene and increasing proportions of immuno-compromised individuals associated with changing demographics and immunosuppressive treatments and illnesses.\n\nClearly a constant dialogue between public health, veterinary and food safety experts, with multidisciplinary skills, is essential in order to signal new threats, to monitor changing trends in well-recognised diseases, to detect emerging pathogens, to understand transmission routes, to develop control effective strategies and to ensure the priority of food hygiene during production and processing."}