{"title": "Invasion thresholds and the evolution of nonequilibrium virulence", "body": "The now conventional method for considering the evolution of virulence is about three decades old (Anderson and May 1979, 1982). It assumes that the parasite population has gone to its dynamic equilibrium (the endemic phase), such that the parasite population is no longer spreading in the host population. This model identifies the combination of transmission and virulence that leads to highest parasite fitness. The result is that selection maximizes the parasite reproductive number, R0 (or more properly, maximizes R; Day and Gandon 2007). R0 is a dimensionless number that equals the number of new infections started during the lifetime of the first infected individual in a susceptible population (R is the number of new infections from an infected individual once the parasite has established itself in the host population.) The formula for R0 is simply the parasite fecundity rate times the average lifetime of the infection. Although R0 is defined for the first infected host in a naive population, what maximizes R0 also maximizes R because the only difference between them lies in the value of S (Ebert and Herre 1996; Day and Gandon 2006; Gilchrist and Coombs 2006). The result that selection at the dynamic equilibrium favors maximization of R0 parallels the usual demographic result that selection favors maximal lifetime reproductive output in a stable population (Wilson and Bossert 1971; Charlesworth 1994). We will expand on the implications of R0 maximization below, but it is most informative to do so in the broader context of the second virulence evolution model, considered next.\n\nLenski and May (1994) pointed out that selection on parasite parameters was different during the epidemic phase than at dynamic equilibrium: maximizing R0 no longer maximized fitness if the parasite population was expanding. Again from demography, selection favors early births over late ones in a growing population, so during the epidemic phase, there is a benefit to early transmission and its consequent shorter generation time even when it lowers life-time reproductive success of the infection. In the model, earlier reproduction is achieved by a higher transmission rate, which in most models also results in higher virulence because of an assumed trade-off between transmission and virulence.\n\nThe Lenski and May model lays the foundation for the argument we develop here, so we offer a simple version in the form of an \u2018SI\u2019 model. For a constant density of susceptible hosts, S, and an absence of genetic variation in parasite and host parameters, the epidemic is characterized by one equation for the change in abundance of infected individuals, I:\n\n (1a)\n\nwhere \u03b2 is the transmission rate, and \u03b4 is the combined death rate of infected individuals [\u03b4 is the sum of an intrinsic host mortality rate and a virulence, or parasite-induced mortality, and aside from this difference, equation (1a) is otherwise the same as equation (2) in Lenski and May (1994) and Gilchrist and Coombs (2006)]. The total host population is simply N = S + I. A constant density of susceptible hosts is reasonable whenever the infection is so rare that most hosts have not yet been infected. The per capita rate of pathogen spread is then:\n\n (1b)\n\nThis quantity is a measure of parasite fitness in the epidemic (a type of invasion fitness, Metz et al. 1992), because it defines how rapidly the parasite spreads; indeed, the quantity on the right of equality (1b) is the intrinsic rate of increase of I.\n\nThe rate of spread is a function of parasite transmission (\u03b2) and the death rate of infected individuals (\u03b4), two parameters that are typically assumed to be subject to a trade-off boundary (Fig. 1 top; Ebert and Bull 2003) . A trade-off means that the parasite cannot increase \u03b2 without incurring increasing death rates (\u03b4), although a more stringent criterion on the trade-off, such as the concavity used here, is required to select intermediate levels of virulence (Sasaki and Iwasa 1991). Following Lenski and May (1994) for now, we let \u03b4 be the sum of a constant host mortality plus virulence; we will refer to \u03b4 as simply virulence without loss of generality. Given that the parasite is confined to a trade-off but is allowed to evolve along the trade-off, the combination of \u03b2 and \u03b4 maximizing parasite fitness during invasion is given by\n\n2\n\nwhich is graphically represented as the dot along the trade-off function whose slope is S (Fig. 1, bottom; shown in comparison to the R0 maximum). In prior work, the fitness \u2018optimum\u2019 found in this way is usually regarded as the phenotype that the parasite will evolve toward (and will ultimately attain, if the environment does not change). As demonstrated by Lenski and May (1994), this optimum changes as the density of susceptible hosts is reduced by the parasite, ultimately coinciding with the R0 maximization (Fig. 1). Thus, the optimum stops changing when the epidemic is over and the population has reached dynamic equilibrium between host and parasite (and parasite virulence is optimal).\n\nBoth prior perspectives essentially restrict evolution to the trade-off function, with an emphasis on optima. In the Lenski\u2013May model, the optima are temporary, changing as the density of susceptible hosts changes. Both prior perspectives differ from a new approach that incorporates dynamics, selection and genetics simultaneously (Day and Proulx 2004; Day and Gandon 2006, 2007). This latter approach allows the virulence and transmission parameters to vary anywhere within the zone of attainable phenotypes, and it maps changes in the mean phenotypes as a function of selection and of genetic covariances between the two traits. The optima in this new approach are not altered, but the model is extended to include the evolutionary and population dynamics. This newer method thus subsumes the former ones.\n\nOur goal is to recognize a possible feature of virulence evolution in parasites that newly invade a host species. More importantly, the same feature may apply when an established-parasite evolves to overcome host resistance or immunity. The method we use in developing this argument is compatible with that of Day and Gandon (2006), although our arguments are presented as if evolution proceeds via a succession of successful mutants rather than by obeying covariances of variation that is already present. Either type of model can be used to make the same point, however.\n\nAn optimum is best regarded as a long-term endpoint of evolution. Prior to attaining an optimum, however, the evolutionary dynamics apply (as codified by Day and Gandon 2006, for example). Even before dynamics are relevant, the issue is merely what range of parasite phenotypes/genotypes can invade the host population. The invasion threshold provides the boundary to the range of parameters that allows invasion. It is the set of all (mutant) parameter combinations for which the parasite neither invades nor goes extinct. Thus, parameter values on one side of the invasion threshold will allow invasion, whereas those on the other side will lead to loss/extinction.\n\nThe invasion threshold is easily found in our model. Extending result (1b) above, the pathogen invades if dI/dt > 0, or\n\n3\n\nThe invasion threshold is thus found by replacing the inequality in equation (3) with equality. The set of parameters for invasion of a host population whose density is S* can be represented in a two-dimensional coordinate system as the points falling below a line of slope S* passing through the origin (Fig. 2, top) and above the trade-off boundary. This graph illustrates why the transmission and virulence state (\u03b2, \u03b4) that maximizes fitness gives an inadequate picture of the levels of virulence that can invade the population. Any point inside the region between the invasion boundary line and the trade-off boundary represents a pair of parasite values (\u03b2, \u03b4) that can invade. Thus, the population is susceptible to invasion by far more virulent parasites and by far less virulent parasites than those at the optimum, a point made by Andre and Hochberg (2005). Although all values below the line can invade, not all have the same fitness, so further evolution is expected whenever the invading genotype is not at the optimum.\n\nFollowing Day and Proulx (2004), if the invading parasite persists and becomes established, it is expected that virulence and transmission will begin to evolve toward values that improve parasite fitness. Indeed, if evolution to the optimum is fast enough, the duration of nonoptimal parasite behavior could be ignored. Yet, the approach to optimum virulence may be slow for a few reasons: (i) the optimum may be changing (Lenski and May 1994), (ii) virulence evolution will be influenced by the genetic covariance or mutational properties between virulence and transmission (Day and Gandon 2006), and (iii) there may simply be little genetic variation (see also Day and Proulx 2004). As Lenski and May (1994) pointed out, (i) the optimum will shift toward progressively lower virulence values as the density of the susceptible hosts is reduced by the epidemic. Thus the optimum will not be static, and the parasite can do no better than adapt toward the current optimum. Even in the absence of this effect, parasite evolution may be slow to reach the optimum because of (ii), pleiotropy or genetic covariances. Selection favors mutations with a higher fitness than the currently dominant strains. These mutations may improve transmission but may result in virulence further away from its optimum. Fig. 2 (bottom) shows that fitness isoclines run parallel to the invasion boundary, so all points on a fitness isocline have the same fitness, assuming that S remains constant. As can be seen for the trade-off boundary drawn, there is a wide range of virulence associated with each step of evolution toward the optimum, until the optimum is neared (depending on the shape of the trade-off). Thus, particularly during the initial phases of invasion, evolution of higher parasite fitness need not be accompanied by a change in virulence. Of course, other factors may also slow the approach to equilibrium, but these two follow directly from our model.\n\nThe invasion threshold model has been presented as though the only outcome of host infection is death. In such a system, the initial parasite invasion would be followed by a reduction in host density to the dynamic equilibrium, and the resulting low absolute host density would greatly limit opportunities for the re-invasion of any parasite mutants that had an even more devastating impact on the host. Yet, host death is not the only outcome of infection. Recovery and consequent immunity is typical of many parasites (not necessarily precluding the death of some infected hosts). How does recovery affect our model? Here, we restrict ourselves to the extreme case that recovery is complete, so that a recovered individual cannot be re-infected by the same strain (see van Baalen 1998 for models of virulence evolution with partial recovery).\n\nMost basically, if a large fraction of the host population is immune, a large advantage can be gained by parasite mutants that can overcome the host immunity but also retain the ability to infect susceptible hosts (S). Those mutants have their own invasion threshold, and depending on their parameters, those constraints may be much more lenient than the constraints applying to parasites unable to escape host immunity (Fig. 3). Thus, parasites that engender host immunity have the potential to cause repeated invasions, with potential high and devastating virulence each time. The dynamics of this process are sensitive to the nature of host recovery and virulence, however. A highly virulent parasite (most infections lethal) that reaches high abundance in the host population will crash the host population and not leave many recovered hosts, at least in the short term. Until host numbers rebound, there would be little opportunity for new parasite invasions because of the low absolute density of hosts. If recovery rate from infection is instead high, virulence (host mortality) is necessarily low, and the parasite impact on host density will be slight. In this latter case, the host population is soon prone to invasion of mutants that escape immunity. Thus epidemics that kill large numbers of hosts will experience longer lags before possible reinvasion than epidemics that do not kill many hosts.\n\nThe addition of recovery does change the interpretation of the preceding model somewhat. The derivations above remain the same, but the \u03b4 term (now denoted \u03b4\u2032) is no longer just host mortality. Instead, the \u03b4 terms are replaced by \u03b4\u2032, where\n\n\n\nand \u03c1 is the recovery rate of infected hosts (to a state in which they can no longer be infected). Thus, if recovery from infection is allowed, the derivations and figures above merely substitute \u03b4\u2032 for \u03b4, and the trade-off functions now combine recovery with virulence, as shown in Fig. 3. On intuitive grounds, parasite dynamics are sensitive to the loss of infected hosts, but it does not matter whether those infections are lost because the host died or because it recovered.\n\nThe main implication of this change for evolution of virulence theories is that evolution of higher \u03b4\u2032 no longer implies evolution of higher virulence. Without specifying the relationship between virulence and recovery, higher \u03b4\u2032 could mean a higher recovery rate, with no change in virulence or even a decline in virulence (Fig. 4). This indeterminacy applies to all evolution of virulence theories, and it is not otherwise possible to predict an optimum virulence per se when recovery is involved in the trade-off with virulence. The indeterminacy poses little problem for the invasion threshold perspective, however: the invasion threshold perspective merely specifies a range of possible virulence levels that can potentially invade. This range may be reduced by the inclusion of recovery, but it will always be wider than the range spanned by the optima.\n\nBefore proceeding to empirical examples, it is useful to consider the distinction between the standard R0 maximization model, the Lenski and May\u2019s (1994) dynamic optimum model, and invasion threshold as alternative perspectives on the evolution of virulence. There is obvious overlap among these models (and both are nicely subsumed in the covariance method of Day and Gandon 2006), but the emphases from them have differed. The R0 maximization model offers a single optimum, albeit one that may be sensitive to environmental conditions. It assumes dynamic equilibrium exists between host and parasite, hence does not apply when new parasite mutants invade. The other two models, Lenski\u2013May dynamic optimum and the invasion threshold, are similar in that both apply to invasions. The only difference is that one emphasizes the change of virulence optima during the invasion, the other addresses the range of virulence values that can invade and the nonequilibrium states that may persist after invasion. Without knowing the optima, the Lenski\u2013May and invasion threshold perspectives are difficult to distinguish, as either or both could obtain across repeated invasions. However, observing the evolution of an increase in virulence (instead of a decrease) as the epidemic matures would support the invasion threshold model for the initial virulence, because the Lenski\u2013May optima shift toward decreasing virulence as the epidemic matures. Likewise, if hosts merely die from the infection and do not recover (and are not resistant), then the invasion threshold model cannot possibly apply after dynamical equilibrium has been reached, because there is no reservoir of immune or resistant hosts to be exploited by a mutant parasite.\n\nFor many parasites, evolvability to escape existing immune and resistance profiles is highly adaptive. Long-term parasite success may depend not so much on the ability to achieve evolutionary equilibrium, as in the classic virulence evolution models, but rather to keep changing, staying ahead of host defenses and continually jumping outside the parameter space confining the parasite\u2019s recent ancestors. Such a process would ensure that the invasion threshold model is relevant at many episodes in the parasite\u2019s history. The applicability of the invasion threshold model at some times does not exclude attainment of optima at other times. Thus, over the course of history, there can be a cycling between invasion, evolution toward an optimum (perhaps indirectly), and maintenance of an optimal state. The relative importance of each phase will depend on details of the parasite and host.\n\nWe offer the caveat that the invasion threshold model is not the only model for nonoptimal virulence (Dieckmann 2002). If host and parasite populations cycle, or if environmental factors cause host populations to fluctuate profoundly, there will be no single virulence optimum, and the best the parasite might do is to track a moving optimum [Day and Gandon 2006, 2007]. Likewise, if hosts are infected by multiple strains of parasites, parasite\u2013parasite competition within hosts will often lead to nonequilibrium evolutionary dynamics (Frank 1996; Bull et al. 2006). It should also be noted that different mathematical definitions of virulence have different evolutionary consequences (Day 2002), but again, our point about nonequilibrium dynamics should hold under many of those alternatives.\n\nWe start with two pathogens that elicit host immunity but clearly do not exhibit repeated invasions by mutants that escape immunity. Humans are the only known natural hosts for measles and polio viruses. Successful vaccines have greatly reduced the incidence of both infections, and the vaccines derived from decades-old isolates have remained effective without apparent evolution of novel antigens that escape vaccine-induced immunity (Schrag et al. 1999; Macadam et al. 2006). Both viruses, therefore, are good candidates for the R0 maximization model, but their virulence optima are difficult to establish, and alternatives to the R0 model have been proposed at least for polio (Levin and Bull 1994; Frank 1996). In addition, the virulence of measles is notoriously sensitive to host nutritional status, so it is not clear what level of virulence to apply to the model. Even without knowing whether these viruses have achieved an optimum level of virulence, both viruses appear to be good candidates for viruses that violate the invasion threshold model (at least in contemporary populations) by virtue of their failure to generate escape mutants.\n\nAs an aside, the lack of \u2018escape\u2019 mutants capable of infecting immune hosts is puzzling, as both viruses have RNA genomes, which are thought to be prone to rapid evolution. Furthermore, three antigenically distinct polioviruses are known (and each is included in the vaccine), yet no others have evolved in response to vaccine pressure (Macadam et al. 2006). These two viruses highlight the point that, contrary to common perception, some parasites may not be able to adapt to altered environmental conditions.\n\nThe flu virus is notorious for its recurrent epidemics in humans, and these epidemics arise from various forms of viral evolution to escape host immunity. Flu thus exhibits one of the main features of the invasion threshold model. There is also documented variation in virulence, with the highest virulence associated with some of the new mutants (see below).\n\nFlu dynamics are governed largely by the interaction of host immunity and viral surface antigens as well as evolution of the viral antigens (Webster et al. 1992). Influenza is typed according to two viral antigens, the hemagglutinin (\u2018H\u2019 type) and neuraminidase (\u2018N\u2019 type); we will limit ourselves here to the different H types. There is a wide variety of H types in nature, due partly to the fact that different influenza A strains span a wide variety of warm-blooded hosts. Currently, H1 and H3 are circulating in humans, but H2 was abundant in the past.\n\nThere are two classes of H mutants that invade humans. One class consists of simple point mutants of existing H types (referred to as subtypes, because of a process known as \u2018antigenic drift\u2019). Most annual epidemics consist of these subtype mutants, and subtype evolution is substantial enough to largely overcome immunity to the same ancestral type from several years in the past (Ferguson et al. 2003). The other class consists of H types introduced from other species (a process of \u2018antigenic shift\u2019). Flu virus with novel H types have a profound advantage because there is no prevailing immunity in humans against those types. Three world-wide flu pandemics of the 1900s were notorious for causing large numbers of infections and thus large numbers of deaths; all were due to viruses that had acquired H types that humans had not previously experienced. Not all viruses with novel H types readily spread in humans, however, and many of these introductions have simply died out. We thus have a reasonable understanding of what types of molecular variation enable a flu virus to escape prevailing immunity, although this advantage by itself is not sufficient to enable spread in the human population.\n\nThe virulence of influenza variants varies somewhat, although it is difficult to apportion mortality between the virus (its intrinsic virulence) and the host (whether it has any prevailing immunity to the strain). The case mortality rate of the H1N1 1918 flu that killed 20\u201340 million people worldwide was reported to be about 1%, somewhat more than a 10-fold excess of the typical mortality rate per infection of the viruses of today (Taubenberger and Morens 2006). The virulence of this strain appeared to wane over a few years. H1N1 disappeared in the 1950s, and its accidental reintroduction in 1977 to naive hosts did not lead to the high mortality rate of 1918, so it appears that the virulence per se evolved downward (Kilbourne 2006). Although mortality rates of the usual antigenic shift strains remain relatively constant, some high virulence exceptions are known (e.g., an H3N2 strain from 1997; O\u2019Donnell et al. 2003), and there may well be many low-virulence variants that go unnoticed. However, the H5N1 strain (bird flu) that is circulating widely in birds has a case mortality rate exceeding 50% in humans, far in excess of the mortality rate observed in any strain that established itself in humans (Webster et al. 2006).\n\nH5N1 has not established itself in the human population, but the obvious fear is that it can do so and maintain its high mortality rate, at least during its first round of global spread. The invasion threshold perspective is thus especially relevant here. Ewald has used the public media to argue that the virulence of H5N1 will quickly evolve to low levels, should it invade (Orent 2005); this view has not been widely accepted (Normile 2005), and the perspective of this paper is that, even if the H5N1 optimum in humans is low virulence, the epidemic could have devastating effects before it neared the viral optimum.\n\nFeline calicivirus (FCV) is an RNA virus of domestic cats. A large variety of FCV strains is known to circulate concurrently, with sequence divergence in the variable region of the capsid protein gene ranging as much as 50% between strains (Coyne et al. 2007). Virulence varies among isolates, from asymptomatic to highly virulent, the latter being as high as 50% mortality (termed VSD strains, for \u2018virulent systemic disease\u2019). Multiple strains often circulate within a local cat population. Vaccines are available, but vaccination neither prevents viral infection nor prevents viral replication within a cat, so it appears that cross immunity among strains is only partial (Coyne et al. 2007).\n\nConsistent with the invasion threshold model, nearly a dozen separate outbreaks of VSD have been reported. When subjected to a phylogenetic analysis, the different VSD strains appear to have independent origins from less virulent ancestors. Additionally, the VSD outbreaks appear to have been terminated by viral extinctions, possibly from reducing the local cat density (Radford et al. 2007). The die-outs could be interpreted as the failure to evolve optimal virulence (consistent with the invasion threshold model), or as evidence that near-optimal strains are replacing the VSD strains as host density wanes (consistent with the Lenski\u2013May model).\n\nMost agricultural animals used as food sources, such as pigs, chickens, and cattle are housed at high densities and in conditions of stress that facilitate the spread of infectious diseases. Even if a farm\u2019s livestock is wiped out by an infection, new animals may be brought in and maintained at high densities again. This artificial maintenance of high host density is in contrast to the usual pattern in epidemiological models that parasites regulate the densities of their hosts. These enforced high host densities have been suggested to be especially prone to the evolution of highly virulent parasites, because virulent parasites do not die out even when their hosts do. Although cleanups following an outbreak are usually attempted, the same buildings and grounds are often used for restocking, allowing any remaining environmental source of parasite to reinvade.\n\nThe difficulty of applying equilibrium theory to these situations is illustrated by the pig virus transmissible gastroenteritis coronavirus (TGEV). Historically, a highly lethal gut infection of piglets in pig farms, a mutant form evolved (porcine respiratory coronavirus, or PRCV) that not only had altered tissue tropism but also apparently lower virulence (Kim et al. 2000). PRCV differs from TGEV by a small deletion and a couple point mutations, yet it infects the pig respiratory system and is often much less virulent than TGEV. There is some antibody cross reactivity between TGEV and PRCV, thus the population of one form of the virus interferes with the other, and it is suspected that a low virulence PRCV was responsible for the disappearance of TGEV in some pig farm areas. PRCV now exists in forms of high and low virulence. This example thus represents what may be a single mutant invasion in the recent history of TGEV. To what extent PRCV spread because it could overcome prevailing immunity (as assumed by the invasion threshold model) or because it had other advantages, is not clear.\n\nAnother viral scourge of agriculture is Marek\u2019s disease virus (MDV) of chickens (Hirai 2001; Davison and Nair 2004). MDV has shown a progressive evolution toward increasing virulence over four decades, but again, many strains circulate and some have low virulence. Live vaccines have been used for three decades, the virus used in them having been changed twice. As with FCV, the vaccines do not prevent infection and replication by other strains, and it is widely suspected that the vaccines may have fostered the evolution of progressively higher virulence (references within Davison and Nair 2004; Hirai 2001). (We lack the control of viral evolution at high chicken density in the absence of the vaccine to have any confidence that the vaccine was the cause in the higher virulence evolution.) With MDV, there is considerable ambiguity in the causes of virulence evolution as well as in the spectrum of virulence evolution itself. It may well be that vaccines have selected escape mutants time and again. Whether escape mutants retained near-optimal virulence or not is difficult to establish, because there is a strong ascertainment bias \u2013 avirulent viruses are not noticed by chicken farmers. Thus, without understanding the range of virulence levels that have evolved, it is not practical to discriminate among the models. Such a system seems ripe for testing the models, however.\n\nThere is sufficient evidence to suggest that the invasion threshold model is relevant to the evolution of many infectious agents, but little evidence to suggest how often it is important. Recommendations for use of this perspective are thus accordingly muted. Certainly, it seems wise in virulence management efforts to be aware that a broader range of virulence might invade than is optimal and that evolution to an optimum may not be rapid. It would be obvious folly to ignore a case in which the predicted optimum was low virulence but in which a highly virulent parasite could invade and persist. If the perspective offered here proves to be broadly relevant, then its impact is to support and even bolster any concerns about the evolution of high virulence but also to raise the specter of temporary high virulence in parasites expected to equilibrate at low virulence.\n\nThe most useful work at this stage would be to contrast predicted virulence optima with actual virulence levels over time. Calculating virulence optima has not met with much success, however, likely because the optimum invariably depends on an unknown trade-off and potentially on many environmental factors. Thus, most tests of virulence evolution models have been relative, i.e., correlating virulence level with some environmental characteristic and determining if the correlation is in the right direction. Direct, quantitative tests of virulence optima are rare, nonexistent for human pathogens. If optima cannot be calculated, then it is of course difficult to test any nonequilibrium model against an optimality model. But an alternative to testing whether virulence is optimal is to observe the dynamics of virulence evolution. If virulence does not change over long periods after invasion, despite a dropping susceptible host density, then it would seem that virulence has been nonoptimal during much of the time."}