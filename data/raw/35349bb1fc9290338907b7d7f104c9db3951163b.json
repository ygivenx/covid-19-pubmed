{"title": "ABSTRACTS C01 Pharmacodynamics of Entresto\u00ae (Sacubitril/Valsartan) Versus Placebo in Dogs with Preclinical Myxomatous Mitral Valve Disease C02 Trimethylamine-N-Oxide and its Precursors in Dogs with Degenerative Mitral Valve Disease Comparison Between the Effects of Torsemide and Furosemide on the Renin-Angiotensin-Aldosterone System of Normal Dogs C04 Transvenous Echocardiography in Conscious Sedated Horses C06 Complications and Outcomes of Multi-Institution Transvenous Pacemaker Implantation", "body": "The objective was to assess the diagnostic utility and feasibility of using a 3-10MHz, 8 French, 90cm intracardiac echocardiography (ICE) catheter (Acuson AcuNav\u00ae) to evaluate cardiac structures and function in conscious horses sedated with xylazine.\n\nTen apparently healthy horses (458-619kg) from the Texas A&M uni- The procedure was well tolerated with only mild, intermittent ventricular and supraventricular arrhythmias that resolved with ICE catheter repositioning.\n\nWe conclude that ICE is feasible, safe, and allows for acquisition of repeatable diagnostic imaging planes in conscious, sedated horses. It could potentially be useful in clinical situations where TTE may be technically difficult to perform or poorly tolerated in horses.\n\nJulia R. Treseder, Nicole L. LeBlanc, Katherine F. Scollan Oregon State University, Corvallis, OR, USA Sotalol is a class III anti-arrhythmic drug that is commonly prescribed in the treatment of ventricular tachyarrhythmias in dogs. The antiarrhythmic effects of sotalol are mediated by an increase in action potential duration and prolongation of atrial and ventricular repolarization via antagonism of the delayed rectifier potassium current.\n\nThese effects have been demonstrated to be independent of sotalol';s \u00df-blocking properties. However, \u00df blockade may result in reduced myocardial contractility and also contribute to slowing of the sinus rate. In patients with existing heart disease, a cardiodepressant drug effect may be clinically relevant, yet the inotropic properties of sotalol are not well-characterized in dogs. The aim of this study was to investigate the inotropic and chronotropic effects of sotalol on healthy, awake dogs.\n\nTen adult, large-breed dogs were recruited from the veterinary community at the Oregon State University College of Veterinary Medicine. Dogs were considered healthy based on history, physical exam, oscillometric blood pressure measurement, transthoracic echocardiography, and a 10-lead electrocardiogram. Each dog also had a baseline 24 hour Holter monitor performed. Sotalol at a dose of 1-2 mg/kg orally q12h was then administered for 12-16 days, followed by a second evaluation including the same diagnostics tests. Physical exam parameters, blood pressure measurements, Holter data, echocardiographic measurements including three-dimensional (3D) left ventricular (LV) volumes and 3D strain were measured at each evaluation. Baseline and post-treatment measurements were assessed for normality, and compared statistically with paired t-tests for normally distributed data and Wilcoxon signed rank tests for non-normally distributed data. 3D data were available for 7/10 dogs. No correction was made for multiple comparisons.\n\nTen dogs were included in the study, with a mean age of 3.4 years (range, 1.1-6.4 years) and mean weight of 26.1 kg (range, 21-35.8 kg).\n\nThe mean sotalol dose administered was 1.56 \u00b1 0.23 mg/kg. Heart rate on exam was significantly (p = 0.036) lower post-treatment (81 \u00b1 23 bpm) than pre-treatment (101 \u00b1 26 bpm). Maximum heart rate on\n\nHolter monitor was also significantly (p = 0.002) lower on sotalol (195 \u00b1 14 bpm) than at baseline (215 \u00b1 13 bpm). Several echocardiographic indices of systolic function were altered compared to baseline:\n\nFractional shortening (FS) using two-dimensional (2D) and M-mode (MM) measurements was significantly reduced on sotalol (2D 28.9%, interquartile range (IQR) 25.0-30.2; MM 24.9 \u00b1 5.7%) compared to baseline (2D 30.7%, IQR 28.7-33.8; MM 32.5 \u00b1 2.6%) with p = 0.010 and p = 0.004 for 2D and M-mode measurements, respectively. Similarly, ejection fraction (EF) via Simpson';s method of disks (SMOD) was significantly (p = 0.002) lower on sotalol (48 \u00b1 6.8%) than baseline (53.8 \u00b1 4.4%). On sotalol, there was a 12.4 \u00b1 8.2% increase in LV end-systolic dimension on 2D, and a 12.6 \u00b1 12.4% increase on Mmode measurements (p = 0.001, p = 0.010, respectively). There was no significant difference in the 3D left ventricular volumes, nor in global longitudinal or circumferential strain, twist, or torsion.\n\nThe results of this study suggest that sotalol has negative inotropic and chronotropic effects in healthy dogs. Standard echocardiographic measurements of systolic function showed a small but statistically significant decrease after sotalol treatment, with a mean reduction in EF (SMOD) of 5.8%. The lack of significance for 3D imaging may reflect the variability in 3D measurements and the small sample size. The effects of sotalol in dogs with structural heart disease should be prospectively assessed to further elucidate the clinical significance of decreased systolic function, and the implications of this reduction in patients at risk for heart failure.\n\nnous pacemaker implantation in a large number of institutions. In addition, we wished to identify factors that may predispose patients to the development of complications.\n\nA multicenter retrospective analysis of dogs who underwent transvenous pacemaker implantation between January 1st, 2000 and There was a significant difference in survival time between 3AVB and SSS (p = 0.043).\n\nMajor complications (n=130, 21.8%) included lead dislodgement (37 episodes), lead perforation (5 episodes Transvenous pacemaker implantation is associated with a relatively high complication rate. Predisposing factors for specific complications were unable to be identified. 3AVB was associated with a longer survival time compared to SSS, though did not differ from other bradyarrhythmias.\n\nveterinary studies investigating transdermal atenolol at equivalent oral atenolol dosages have found the majority of cats receiving transdermal atenolol did not have therapeutic plasma atenolol concentrations 2 hours after administration, and none had therapeutic plasma atenolol concentrations 12 hours after administration. These results raise questions regarding the direct substitution of transdermal doses at equivalent oral doses, and the inherent variability of compounded medications. Therefore the goals of this study were to optimize a non-patented transdermal atenolol formulation and assess atenolol dosage amount and frequency in healthy cats using this formulation.\n\nWe hypothesized that an optimized transdermal atenolol formula at a higher transdermal dosage rate administered q12h will result in therapeutic (> 260 ng/mL) atenolol concentrations in healthy cats.\n\nWe collaborated with Oregon State University (OSU) College of Pharmacy researchers to create a transdermal atenolol formulation that had optimal drug release and good permeation in a steady-state manner. Different concentrations of atenolol gels in a hypomellose carrier and carbomer base were evaluated by an in vitro diffusion study using of treatment, transdermal atenolol was administered and blood samples were collected for atenolol serum concentrations at 3, 6, and 12 hours after topical application. After phlebotomy at 3 and 6 hours post-atenolol administration, an ECG was also performed and average heart rate (HR) measured. Gradual tapering of transdermal atenolol subsequently occurred over 4 days.\n\nAll enrolled cats successfully completed the drug trial and no cats experienced any adverse side-effects. Two cats initially received a maximum transdermal dose of 12.5 mg q12h and serum atenolol concentrations were subtherapeutic (< 260 ng/mL) at 3, 6, and 12 hours post-atenolol.\n\nThe transdermal atenolol dose was increased to 25 mg q12h, and the same 2 cats were re-enrolled in the study using the higher atenolol dosage after a 4 week washout period. Three cats have completed this updated study protocol at the higher atenolol dosage. Two of the 3 cats In this population, the majority of GSD had type II PDA anatomy that was amenable to ACDO deployment. Predisposition for large MDD and occasional, unusual PDA anatomy suggests that transesophageal echocardiography may be beneficial for optimal procedural planning in this breed.\n\nSix, healthy, middle-aged, male beagles were randomized to receive torsemide (0.1mg/kg PO q12h), furosemide (2.0mg/kg PO q12h), or placebo for 10 days during 3 separate experiments in a cross-over design, each separated by a 10-day washout period. Blood was collected on days 1, 5, and 9 and 24-hour urine samples were collected, ending on days 2, 6, and 10. Serum aldosterone was quantified via liquid chromatography-mass spectrometry (LC-MS)/MS and angiotensin metabolites were quantified with LC-MS/MS and equilibrium analysis (Attoquant Diagnostics, Vienna Austria). Urine aldosterone was quantified via radioimmunoassay (Beckman Coulter) and used to calculate the urine aldosterone-to-creatinine ratio (UAldo:C). After repeated measures analysis and Bonferonni correction, variables with an adjusted P < 0.05 were investigated further, using Tukey';s method.\n\nSerum AngI, AngII, Ang1,7, Ang1,5, AngIV, and aldosterone and the UAldo:C were significantly increased in the diuretic groups, as compared to placebo on days 5/6 and 9/10. Increases in these parameters were greatest in the torsemide group, but failed to reach significance.\n\nSerum AngIII increased after diuretic therapy, yet values did not differ significantly from placebo.\n\nNovel components of the circulating RAAS are significantly increased during therapy with both torsemide and furosemide and mirror changes in the 'classical'; RAAS. Repeatability, intra-observer, and inter-observer image acquisition variability and measurement variability were quantified by average coefficient of variation (CV). Lower and upper limit bounds on the coefficient of variation were calculated using exact theory and logistic regression of the upper limit against repetitions of 5, 10, 15, and 25 was used to determine the highest precision for each modality.\n\nEvaluation of the left ventricular size by M-mode had the highest repeatability (CV = 8.8%) and lowest intra-and inter-observer variability for both image acquisition (CV = 9.3%) and measurement (CV = 4.3%) . Repeatability of 3DE image acquisition (CV = 21.1%) and measurement (CV = 8.6%) was slightly better than 2DE image acquisition (CV = 21.5%) and measurement (CV = 8.9%). The intraand inter-observer variability of 3DE (CV = 18.9%) was also slightly better than then 2DE (CV = 22.3%). 2DE left atrial to aortic ratio measurements had higher repeatability (CV = 9.0%) and less variability (CV = 9.5%) than volume assessed by 3DE image acquisition identified among the GFD dogs tested (11 taurine, 4 carnitine).\n\nTwenty-seven dogs with DCM were fed NGFD. Of these, 5 of 11 tested were taurine deficient (3 vegetarian Echocardiograms of dogs with DCM fed GFD, and specifically GFD-1, suggest more advanced disease or a diet-enhanced pathophysiology compared to dogs eating NGFD.\n\nCats with CHF had: higher serum leucine-rich alpha-2-glycoprotein1 compared to healthy controls; higher serum amyloid A compared to asymptomatic CM and healthy controls; higher ceruloplasmin compared to asymptomatic CM (P < 0.05). In univariate survival analysis models, serum alpha-1-acid glycoprotein (AGP) level was found to be associated with a higher risk of death in CHF cats (P = 0.007). Multivariable analysis suggested that serum AGP (P = 0.009), body weight (P = 0.023) and LA/Ao ratio (P = 0.013) were independent prognostic factors in CHF cats.\n\nFindings suggest that systemic inflammatory response occurs in feline congestive heart failure due to primary cardiomyopathies. Acute phase proteins can be used with other clinical parameters or biomarkers for disease monitoring and prognostication in feline cardiomyopathies. CHF, and pancreatitis in humans and dogs. The aim of this prospective study was to assess fPLI and TLI values between healthy cats and cats with primary CM with or without CHF. In addition, a retrospective evaluation of pancreatic histology from cats with CM was performed.\n\nCats were prospectively recruited into three groups: 1) healthy controls (H group), 2) primary CM (CM group), and 3) CM with active or historical CHF determined by a board-certified cardiologist (CHF group). All included cats underwent a physical exam, blood pressure, echocardiogram, fPLI, TLI, complete blood count (CBC), and chemistry panel. Cats with evidence of hypertrophic cardiomyopathy (HCM) also had total T4 measured. Routine pancreatic histopathology from cats affected by primary CM were retrospectively reviewed by a boardcertified anatomic pathologist for histologic evidence of pancreatic injury. Differences between groups were assessed by Kruskal-Wallis tests and association assessed by Fisher';s exact tests.\n\nA total of 25 cats were included and classified into the H (n=4), CM (n=10), and CHF (n=11) groups. There were no statistical differences in age, body weight, or body condition score between groups. CM diagnoses included HCM (4 CM, 5 CHF) , hypertrophic obstructive cardiomyopathy (5 CM, 2 CHF), unclassified cardiomyopathy (1 CM, 2 CHF), and restrictive cardiomyopathy (2 CHF) . In the CHF group, 6/11 cats had active CHF (pulmonary edema or pleural effusion) at the time of blood collection. Gastrointestinal signs included vomiting (2 CM, 2 CHF) , anorexia (2 CM, 1 CHF) , and weight loss (1 CM, 2 CHF) . Median values for the control, CM, and CHF groups did not differ for fPLI (1.6, 2.2, and 1.8 \u03bcg/L) or TLI (35, 27.4, and 39.9 \u03bcg/L).\n\nFive CM and 3 CHF cats had fPLI values greater than the feline reference range, 2 CM cats had increased TLI values, and 1 CM cat had a deceased TLI value. Active CHF was not statistically associated with an abnormal fPLI or TLI result (P > 0.99; P > 0.99).\n\nRetrospective pancreatic histopathology of 16 cats with CM found a spectrum of morphologic lesions potentially related to pancreatic ischemia. These included exocrine vacuolation (6/18) , focal or multifocal coagulation necrosis (2/16) , and saponification of pancreas-associated adipose tissue (5/16) . Of the 10 cats with possible cardiac-related pancreatic ischemia, 5/10 had active or historical CHF. Other common feline pancreatic lesions were also identified, including islet amyloidosis (6/16) , mild to moderate lymphocytic inflammation (8/16), and periductular fibrosis (6/16) .\n\nThese preliminary data demonstrate no statistically significant differences in pancreatic biomarkers of cardiomyopathic cats with or without CHF. Potentially relevant histopathologic pancreatic changes were identified, suggesting that biomarkers may vary with time or disease severity and not reflect cardiac-induced injury. The left atrium may enlarge in various directions, although is conventionally measured on echocardiography in one-dimension using a short-axis right parasternal view indexed to aortic diameter (LA:Ao). The maximal diameter from a right parasternal long-axis view has also been utilized as an assessment of LA size. Two-dimensional (2D) measurements and volume calculations have replaced one-dimensional linear measurements for chamber quantification in humans and canine echocardiographic exams.\n\nThe aims of this retrospective study were to compare LA size by conventional 1-dimensional linear measurements to calculated 2D LA volumes (LAV) and compare minimal and maximal values. Our hypothesis was that LAV would provide superior sensitivity (Se) and specificity (Sp) for identifying cats with CHF from those without CHF.\n\nMedical records were reviewed for cats with complete echocardiographic exams performed at the Oregon State University Veterinary\n\nTeaching Hospital (OSU-VTH) between January 2008 and July 2017. and 7) maximal left atrial diameter (LAD) from the right parasternal long-axis view. Volumes were calculated using the monoplane modified Simpson';s method of discs (MOD). Volume measurements were also indexed to body weight (kg). Minimal measurements were made just after the P wave and maximum measurements made just after the T wave on simultaneously recorded ECG. Receiver operator curves were used to assess area under the curve (AUC) and optimal cut-offs with associated Se and Sp to distinguish groups.\n\nA total of 162 cats were included in the study and classified as healthy (n=56), CM (n=62) and CHF (n=44). Healthy cats were younger than both the CM and CHF groups (p < 0.0001) and the groups did not differ in body weight. LAV measurements from the RLA and LAP views were statistically different (p = 0.0005). was classified according to whether it had \"increased\", \"decreased\" or been \"maintained\" over each interval and was entered as an explanatory variable. Additional explanatory variables that were included in models had been recorded at the first examination in each interval. The association between changes in heart murmur intensity and the rate of cardiac remodeling provides evidential support to the utility of longitudinally monitoring murmur grade. In clinical practice, an increase in murmur grade may indicate that a more rapid rate of DMVD progression has occurred and could be used to recommend further echocardiographic evaluation.\n\n(range:10-108). In 47 dogs, STE data was obtained from three scanning planes. The mean peak radial strain at the apex (A-Rs) was 44.7 \u00b1 13.0%, the mean peak radial strain at the papillary muscle level (PM-Rs) was 41.1 \u00b1 14.7%, and the mean peak radial strain at the base (B-Rs) was 34.1 \u00b1 15.7%. The mean peak circumferential strain at the apex (A-Cs) was -16.4 \u00b1 5.3%, the mean peak circumferential strain at the papillary muscle level (PM-Cs) was -14.8 \u00b1 3.4%, and the mean peak circumferential strain at the base (B-Cs) was -15.8 \u00b1 4.2%.\n\nAs Cats had increased BCS (P = 0.013), insulin (P < 0.001), NT-proBNP (P = 0.001) and cTn-I (P < 0.001). Correlations were present between NT-proBNP and max-IVSd (P = 0.048), max-LVWd (P = 0.009), sum-LVWd (P = 0.012) and LA-remodeling (P = 0.030), between c-TnI and sum-IVSd (P = 0.039) and LA-remodeling (P = 0.009), and between SAA and sum-IVSd (P = 0.030) and n-IVSd (P = 0.048). Age was correlated with LA max (P = 0.026) and glucose (P = 0.027). BW and BCS were correlated with n-LVWd (P = 0.041), M-LVWd (P = 0.035), IGF-1 (P = 0.001), and insulin (P = 0.017), glucose (P = 0.041) and IGF-1 (P = 0.021), respectively. Cats with LA remodeling (n = 27) had higher max-LVWd (P = 0.026) and sum-LVWd (P = 0.012), NT-proBNP (P = 0.017) and c-TnI (P = 0.006). Cats with generalized hypertrophy (n = 11) had higher max-IVSd (P = 0.003), sum-IVSd (P < 0.001), max-LVWd (P = 0.001), sum-LVWd (P < 0.001) and SAA (P = 0.018).\n\nThe results suggest a role for insulin, IGF-1 metabolism and inflammation in aHCM. Further research on the contribution to aHCM is needed. The study was designed as a randomized, blinded, controlled experimental trial in which 30 Sprague Dawley rats were assigned equally into six treatment groups: 1) saline (negative control); 2) serotonin (5-HT positive control); 3) ALK5 inhibition (ALK5 positive control); 4) ALK5 inhibition plus serotonin (synergistic); 5) ALK5 inhibitor plus cyproheptadine (serotonin antagonist); and 6) ALK5 inhibitor plus clopidogrel (antiplatelet). Each group was treated for 14 days then sacrificed and the hearts were collected and stained with hematoxylin and eosin (H&E) for histopathologic examination. The results were scored based on a previously published semi-quantitative method for mitral valve pathology where the score ranged from 0 (no changes) to 12 (most severe changes).\n\nThe [median (range)] for each treatment group was as follows: Negative control [4.5 (0.5 -6) ]; 5-HT positive control [3 (1.5 -5) ]; ALK5 positive control [3.5 (0 -5) University, Sayama, Saitama, Japan, 3 Shiraishi Animal Hospital/Animal Cardiovascular and Thoracic Surgery Center/Tokyo University of Agriculture and Technology, Sayama-shi, Saitama, Japan, 4 Tokyo University of Agriculture and Technology, Fuchu, Tokyo, Japan, 5 The University of Tokyo/Animal Cardiovascular and Thoracic Surgery Center, Bunko-ku, Tokyo, Japan, 6 Nihon univ., Fujsawa, Kanagawa, Japan, 7 Nihon University, Fujisawa, Kanagawa, Japan\n\nIn this study, the purpose was to clarify changes in blood gas during surgery when mitral valve plasty surgery was performed using cardiopulmonary bypass(CPB).\n\nThe subjects were 54 dogs with mitral regurgitation.For anesthesia inhalation anesthesia was combined with moderate hypothermia method.\n\nTiming of conducting blood gas sample examination was pre: before initiating CPB, partial: after starting CPB, total: after aortic cross-clamping, rebeat: after aortic declamping, post: after completing CPB. In conclusion, toceranib elicited weaker reversal properties on pulmonary arterial remodeling and RVH, and therefore, a low dose of toceranib in comparison with sorafenib may not be a promising therapeutic agent for cardiopulmonary remodeling and PAH. Obesity is the most common nutritional disease in cats and is increasing in prevalence. Excess body fat predisposes the animal to deleterious effects on heart function and systolic blood pressure (SBP) alterations, arrhythmias and radiographic and echocardiographic changes have been described. However, there is not much information regarding the effects of obesity on the cardiovascular system of cats. This study aims to evaluate these effects on cardiovascular system of domestic cats and compare them with cats with normal body conditions. Thirty-six cats were allocated in two groups (20 obese cats and 20 cats with normal body condition) and submitted to SBP measurement; electrocardiogram (ECG); and chest radiograph to evaluate the cardiac silhouette by vertebral heart size (VHS). The echocardiographic measurements were evaluated, establishing a relationship between the data obtained and Body Weight, Body Condition Score (BCS) and Body Mass Index (BMI). SBP and VHS were statistically higher in obese animals in contrast to normal cats. In obese cats, the mean SBP was 148.5 \u00b1 29. 6 Weight. A quadratic relationship was also observed between left atrial-to-aortic root diameter ratio (LA:Ao) and Body Weight. In addition, the relationship between LVFWd and BMI, although not considered significant, presented P values slightly above 0.05. Obese cats showed higher BPS and VHS than normal cats, which led to an increase in echocardiographic measurements. This study has shown that obesity promoted cardiac function impairment in the studied cats and, therefore, that it is important to monitor these animals since even asymptomatic ones may present changes in cardiac parameters. The study aims at measuring heart rate variability in Holstein cows, fetuses and neonates through a descriptive evaluation of continuous fetomaternal and neonatal electrocardiogram recordings during the perinatal period. Heart rate (HR) and heart rate variability (HRV) were assessed by fetomaternal electrocardiography (ECG). Fetomaternal measurements were taken six times pre-partum and in neonates six times after calving. Heart rate, time-domain variables and frequencydomain variables were analyzed in 23 Holstein cows and 18 neonates.\n\nNo significant changes were observed in maternal or fetal RR intervals and HR. In the fetuses, the standard deviation of beat-to-beat interval (SDNN) decreased significantly from 38.08 \u00b1 2.6 ms to 28. 9 \u00b1 2.4 ms (p < 0.05), but the root mean square of successive beat-to-beat differences (RMSSD) did not change significantly. Fetal heart rate and RR interval differed statistically from the day before delivery (163 \u00b1 7.5 bpm; 381 \u00b1 24.2 ms) to the day after calving (131 \u00b1 5 bpm; 472 \u00b1 16. The equine maternal pheromone (EMP) has been used as a tool to calm equines facing new or stressful situations, which forces physiological adaptations and alterations related mainly to increases in heartrate (HR) and behavioral alterations. This study aims at assessing the effects of EMP treatment in colts undergoing hoof trimming for the first time, employing the behavior of heartrate variability (HRV) as the main parameter. We assessed 20 colts with average age of 9 months that underwent hoof trimming for the first time. The animals were divided in two groups and a randomized double blind experimental design was employed. The treatments (EMP and placebo) were administered and the Holter monitor was put in place. After 20 minutes, the procedure was started. The HR (measured through the conventional method) and HRV were measure at two moments: 20 minutes before trimming (M1) and immediately after trimming (M2 The measurement of heart rate variability (HRV) was reported as an acceptable method for assessing the level of stress and numerically express the neurohormonal effect exerted on the heart rate. Normal values for physiological parameters in larger breeds are often used as reference values in ponies. However, heart rate increases in smaller animals and, in adult ponies, is higher than in adult warmblood horses.\n\nLittle is known about the effect of pregnancy signalment on heart rate variability values in the equine species. This study aimed at determining physiological ranges for heart rate (beats per minute) and heart rate variability in equine mares at different months during gestation (10 months). The ECG recordings were made once a month and the data were used for analysis. Heart rate (HR) and HRV were assessed by maternal electrocardiography (ECG). Maternal measurements were taken ten times pre-partum and heart rate variability was analyzed in the time-domain.\n\nSignificant changes were observed in the fourth and tenth month of pregnancy for RR interval (1238.53 \u00b1 100.37 ms; 962.60 \u00b1 234.11 ms) and HR (49.42 \u00b1 4.84 bpm; 62.43 \u00b1 11 .53 bpm) (p = 0.018), corresponding to the smallest and largest value respectively. No significant changes were observed in the standard deviation of beat-to-beat interval (SDNN) (p = 0.466) or the root mean square of successive beat-to-beat differences (RMSSD) (p = 0.760). Time-domain analysis has demonstrated a significant increase in the mean RR intervals and HR with the progression of pregnancy and has also established that HRV is influenced by HR, as a higher HR was associated with a lower HRV in the mare. Renal dysfunction caused by primary cardiovascular disease is considered to be a class of cardiovascular renal disorders (CvRD). In small animal medicine, CvRD in cardiac patients is a novel research area. In this study we aimed to evaluate CvRD in cats with congestive heart failure (CHF) and primary cardiomyopathy (CM) by measuring cardiac and renal functional markers.\n\nTwenty-one client owned cats diagnosed with primary CM (16 CHF and 5 asymptomatic) from a referral Cardiology Service were enrolled.\n\nTwenty healthy cats were used as controls. Serum N-terminal-pro brain naturetic peptide (NT-proBNP), symmetric dimethylarginine (SDMA) and creatinine levels were measured in a reference laboratory. Relevant clinical information and survival status of CHF cats were recorded. One-way analysis of variance (ANOVA), Student's T tests, Spearman's rho and Cox proportional hazards models were used for statistical analysis.\n\n(C44) ABSTRACTS NT-proBNP, SDMA and creatinine levels were positively correlated and significantly different among the three groups of cats. CHF cats had higher serum NT-proBNP than asymptomatic CM cats and healthy control cats, and higher SDMA and creatinine than healthy controls (P < 0.05). Cats with CHF that died had higher NT-proBNP (P = 0.001) and SDMA (P = 0.007) but not creatinine (P = 0.922) compared to survivors; however, neither of the markers were significant prognostic factors in multivariable survival analysis models.\n\nStudy results suggest that CvRD is present in CHF cats with primary cardiomyopathy. Furthermore, SDMA is a novel biomarker in cats with CHF and primary CM that could be used for disease management and prognostication. As a consequence of the turbulent high-velocity flow and changes in fluid shear stress around the mitral valve, changes in platelet function may be involved in the pathogenesis of myxomatous mitral valve disease (MMVD). The aim of this study is to investigate whether the changes in coagulability vary with the severity of MMVD in dogs.\n\nWe retrospectively reviewed charts from dogs with MMVD. The classification of MMVD dogs was based on the ACVIM staging. We compared results from the following test: white blood cell counts (WBC), platelet count (PLT), mean platelet volume (MPV), prothrombin time (PT), activated partial thromboplastin time (APTT), fibrinogen (Fib), Creactive protein (CRP), antithrombin III (ATIII), fibrin degradation products (FDP), activated clotting time (ACT), platelet function (PF), and clot rate (CR).\n\nA total of 95 dogs were evaluated; 27 dogs with ACVIM Stage B2, 45 dogs with Stage C, and 24 dogs with Stage D. Fibrinogen and CRP were significantly increased as the disease progressed (P < 0.05). Dogs in Stage D had significantly higher WBC, PLT, and PF when compared to dogs in Stage B2 (P < 0.05). There were no significant differences in MPV, PT, APTT, ATIII, and FDP among the groups.\n\nThe platelet function and activity declined in dogs with MMVD. WBC, CRP, and Fib increased, which is consistent with increased inflammation as the MMVD progressed. The inflammatory response may play an important role in increasing platelet function as the mitral valve function deteriorates.\n\nN-Terminal Pro-B-Type Natriuretic Peptide (NT-proBNP) Left atrial rupture (LAR) is an uncommon complication of myxomatous mitral valve disease, usually leading patients to die suddenly or in a few hours, but some dogs can survive for a long period of time.\n\nCongestive heart failure (CHF) was previously hypothetized to reduce long term survival. Doppler derived echocardiographic parameters influenced by atrial pressure, such as peak early (E) left ventricular filling wave velocity and E to isovolumic relaxation time (E:IVRT) ratio usually provide informations about congestive heart failure. Although echocardiographic prediction of CHF at the time of LAR diagnosis would be helpful for prognosis, reduction in left atrial pressure due to chamber emptying to pericardial space could hinder this predictive analysis.\n\nThe study retrospectively reviewed hospital recordings from dogs with diagnosis of LAR based on necropsy and/or echocardiographic findings, which included all of the following criteria: (1) myxomatous mitral valve disease with mitral regurgitant flow aliased on color Doppler study filling over 60% of the left atrium, (2) LA:Ao ratio > 1.5 on two-dimensional right parasternal short-axis view, (3) pericardial effusion and (4) organized echogenic material suggestive of cloth within pericardial space. Dogs that died from non cardiac cause were not included.\n\nSix dogs met the criteria for inclusion, being 4 males and 2 females from different breeds: Toy Poodle (n = 3), Pinscher (n = 2) and Chihuahua (n = 1). Mean age was 12.3 years (range, 10 to 15 years) and mean body weight was 5.0 kg (range, 2.8 to 9.0 kg). Clinical signs included cough (n=6), weakness or colapse (n=5) and tachypnea (n=4).\n\nMost dogs (n = 5) had systolic systemic arterial blood pressure lower than 71 mmHg. All dogs were hospitalized after diagnosis and had systemic arterial blood pressure greater than 100 mmHg after therapy with intravenous crystalloid (n=6), dobutamine (n = 5), noradrenaline (n = 2) and/or pericardiocentesis (n = 1).\n\nThoracic radiographs were performed at the time of LAR diagnosis and 3 dogs had marked interstitial and alveolar perihilar infiltration (CHF group) while the remainder 3 dogs had no pulmonary abnormalities and also no prior history of decompensated heart failure (non-CHF group). Diabetes mellitus (DM) is a common endocrinopathy in dogs and its impact on the cardiovascular system is still unclear in this species. In human medicine, serum fructosamine concentration (SFC) use as a cardiovascular prognostic is growing. The aim of this study was to evaluate correlations among systolic blood pressure (SBP), SFC, and insulin dose in use by diabetic dogs. A cross-sectional study was designed including diabetic dogs under treatment with NPH insulin (mean dose 0.62 U \u00b1 0.24 U/kg, range 0.25 to 1.2 U/kg) for a period of 2 to 60 months (25.6 \u00b1 17.8 months). The patients were assessed by Doppler vascular method to verify SBP in agreement with ACVIM guidelines. SFC were measurement by a colorimetric assay. Eighteen diabetic dogs (10.6 \u00b1 2.9; 10.8 \u00b1 8.1 kg) and twelve healthy control dogs (10.4 \u00b1 3.1 years; 13.0 \u00b1 9.4 kg) paired by breed, sex and age were included. There was a significantly positive correlation between SBP and SFC in diabetic dogs (r = 0.54; P < 0.05) as well as in control dogs (r = 0.57; P < 0.01). Insulin dose and SBP correlation only approach significance (r = 0.41; P = 0.08). Also, there was no correlation between time of diagnosis and SBP (r = 0.17; P = 0.47). Our findings suggests that there is association between SFC and hypertension in dogs. This results emphasize the importance of the SBP monitoring in diabetic dogs, and suggests that insulin dose may be a more important factor than the time of diagnosis as a risk factor for hypertension in canine diabetic patients. Amiodarone is predominantly a class III anti-arrhythmic drug that also blocks sodium channels, and calcium channels, and beta2-adrenergic receptors. It is commonly used for the treatment of tachyarrhythmias, most notably ventricular tachyarrhythmias. As a lipophilic, iodinated benzofuran-derivative medication, amiodarone has unique pharmacological and structural properties that not only distinguish it from other anti-arrhythmics, but warrants careful surveillance of certain metabolic processes. Its composition can lead to the inhibition of 5 0deiodinase activity, resulting in a decrease in Triiodothyronine (T3) production. Amiodarone and its main metabolite, desethylamiodarone may also block T3 binding to its respective receptor. Amiodarone induced thyroid dysfunction has been documented in people. We aimed to determine if amiodarone alters thyroid function in dogs treated for significant tachyarrhythmia.\n\nRecords from our institution were reviewed to find dogs treated for tachyarrhythmias with amiodarone whose retrievable information was complete in regard to amiodarone dosing and thyroid function testing before and after starting amiodarone. Ten client-owned dogs were identified, and their records were evaluated for data regarding history, signalment, anti-arrhythmic medications, echocardiographic findings, other cardiac medications, electrocardiogram findings, Total T4 (T4), and thyroid stimulating hormone (TSH) levels before and after initiation of amiodarone, amiodarone doses, and length of time between initiation of amiodarone and post T4 and TSH testing.\n\nThe median age of evaluated patients was 8 years (range, 7-11). There were 6 males and 4 females with no sexually intact patients. Eight dogs initially received other anti-arrhythmic therapy (2/8 mexiletine monotherapy, 2/8 sotalol monotherapy, 3/8 mexiletine/sotalol dual therapy, 1/8 sotalol/diltiazem dual therapy). Two dogs did not receive antiarrhythmic medication prior to evaluation. Amiodarone was instituted most commonly in dogs with systolic dysfunction +/-congestive heart failure, intolerance to particular anti-arrhythmic, or tachyarrhythmias refractory to other antiarrhythmics. Median maintenance amiodarone dose was 7.52 mg/kg/d (range, 6.32-10.17) preceded by a median amiodarone loading dose of 15.46 mg/kg/d (range, 14.14-20.34) for 7 days.\n\nThe median pre-amiodarone T4 value was 1.2 nmol/L (range, 0.7-1.9), while the median pre-amiodarone TSH value was 0.245 ng/mL (range, 0.06-0.55). Median post-amiodarone T4 was 1.95 nmol/L (range, 0.8-2.8), with median post-amiodarone TSH of 0.565 ng/mL (range, 0.08-1.99). Wilcoxon signed-rank analysis showed that TSH increased (p = 0.005) after amiodarone initiation. Median time to postamiodarone thyroid testing was 37 days (range, 6-239) for T4 and 23.5 days (range, 6-239) for TSH after starting the drug, while median time between pre-amiodarone and post-amiodarone testing was 28.5 days (range, 6-246) for T4 and 24 days (range, 6-246) for TSH. No clinical signs of hypothyroidism were noted at time of recheck.\n\nAmiodarone administration has been shown to alter thyroid function in humans. Our retrospective study aimed to find a relationship between amiodarone administration and thyroid parameters in dogs. In our study population, TSH increased after amiodarone administration, though no signs of hypothyroidism were observed. To our knowledge, thyroid parameter changes have not been previously documented in dogs treated with amiodarone. Additional prospective evaluation with a larger population is needed determine the significance of this finding. Shiraishi Animal Hospital/Animal Cardiovascular and Thoracic Surgery Center/Nihon University, Sayama, Saitama, Japan, 2 Nihon University, Fujisawa, Kanagawa, Japan, 3 Shiraishi Animal Hospital/Animal Cardiovascular and Thoracic Surgery Center/Tokyo University of Agriculture and Technology, Sayama-shi, Saitama, Japan, 4 The University of Tokyo/Animal Cardiovascular and Thoracic Surgery Center, Bunko-ku, Tokyo, Japan, 5 Animal Cardiovascular and Thoracic Surgery Center / Japan Small Animal Medical Center, Tokorozawa, Saitama, Japan, 6 Tokyo University of Agriculture and Technology, Fuchu, Tokyo, Japan\n\nThe purpose of this study was to assess the effectiveness of mitral valve plasty (MVP) for treating pulmonary hypertension (PH) secondary to mitral valve disease in dogs. Twenty-three dogs (7-14 years of age) with preoperative PH, that underwent MVP under cardiopulmonary bypass between 2014 and 2017, were included. PH was diagnosed if the peak tricuspid valve regurgitation (TR) velocity was >3 m/s at echocardiography. Cardiac examination was performed before the operation and during follow-up (1 month, 3 months). Sildenafil was administered to dogs with residual PH if severe right-side heart overload (flattening of ventricular septum) and/or clinical signs (exercise intolerance, cyanosis) were observed. Median TR was 3.4 m/s (range 3.1-4.4 m/s) at preoperative examination. There were no deaths due to residual PH until 3 months after surgery. PH was improved in 9 (45%) patients at 3 months. TR disappeared in 4 patients and TR velocity was decreased in 5 (median 2.5 m/s; range 2.1-2.9 m/s). Eleven (55%) patients exhibited residual PH. Median TR was 3.3 m/s (range 3.0-3.7 m/s). Sildenafil was administered to 2 (18.2%) patients.\n\nPH was a negative prognostic factor in dogs with mitral valve regurgitation. Our results suggest that MVP is an effective treatment for dogs with PH secondary to mitral valve disease. Further study is needed to clarify long-term prognosis and treatment of patients that exhibit residual PH after surgery. Detection of equine kidney injury in initial stages, when intervention is likely to be most successful, is hindered by limited markers of early renal damage in horses. N-acetyl-\u03b2-D-glucosaminidase (NAG), a lysosomal enzyme in renal tubular cells that is released into urine during tubular insult, has shown promise for early identification of acute kidney injury in humans and other species. The aims of this study were to validate an assay for urinary NAG (uNAG) in horses and to correlate uNAG index with other markers of renal tubular dysfunction. An enzymatic assay was validated using coefficients of variation (CV), spike and recovery, and linearity of dilution. Urine and plasma were collected from 7 nonazotemic and 7 azotemic horses. Spearman rank correlation and Wilcoxon rank sum tests were used to compare uNAG index with plasma creatinine, urinary fractional excretion of sodium (FE Na ), and urinary gamma-glutamyltransferase (uGGT) index.\n\nIntra-and inter-run CV, percent recovery after spiking, and linearity of dilution were satisfactory. There were significant correlations between uNAG index and plasma creatinine (p-value < 0.05) and between uNAG index and FE Na (p-value < 0.01). Median uNAG indices were significantly higher (p-value < 0.05) in azotemic horses, in horses with increased FE Na , and in horses with increased uGGT index. Urinary NAG can be measured in horses and shows correlation with current biomarkers of renal dysfunction. Additional work is needed to determine the timing of increase in uNAG index relative to onset of kidney injury in horses and to evaluate clinical utility in equine patients. Twenty-eight cases were identified. Prevalence of UTI in our equine cases was 0.13% between 2009 and 2016. Trakehner and Holsteiner horses were significantly overrepresented compared to the hospital population (p < 0.05) and UTI were more frequent in females (p < 0.05). Urinary tract infections were associated with other diagnostics involving the urinary tract such as bladder emptying problems in 64% of the cases. Eighty-four bacteria were isolated from 54 cultures.\n\nEscherichia coli and Enterococcus spp. were the most common bacteria representing respectively 31% and 29% of isolated bacteria.\n\nTrimethoprim-sulfonamide, enrofloxacin and ceftiofur were the most commonly used antibiotics, especially at the beginning of hospitalization, and respectively 22%, 39% and 42% of isolated bacteria were sensible to these drugs. Seventy percent of isolated bacteria were multi-drug resistant. These results have to be placed in a context where two equine patients represented 31% of the isolated bacteria. Evaluation of the response to treatment was limited by the study design.\n\nIn conclusion, UTI is uncommon in horses and we identified a breed and sex predisposition. Both gram positive and negative bacteria were identified, and a high prevalence of multi-drug resistant bacteria can represent a therapeutic challenge in horses with urinary tract infections in an hospital setting. The study aim was to apply a validated canine scoring system to assess the incidence of acute kidney injury in hospitalized horses. We hypothesized that the incidence of acute kidney injury in horses is similar to that reported in other species.\n\nClinical records from hospitalized adult horses, August 2015-October 2017, were reviewed. Horses must have been hospitalized for \u22653 days and had serum creatinine concentration measured twice. Horses that were diagnosed with primary renal pathology or were azotaemic on baseline serum biochemistry were excluded. A veterinary acute kidney injury scoring system was applied based on percentage increase in serum creatinine concentration from baseline: stage 0 (< 150%), stage 1 (150-199% or \u2265 26.5 \u03bcmol/L), stage 2 (200-299%) or stage 3 (\u2265 300%). 227 horses were included; 17.6% had an acute kidney injury (40/227).\n\n16.7% were classified at stage 1 (38/227) and 0.9% as stage 2 (2/227). No horse had a stage 3 acute kidney injury.\n\nThe incidence of acute kidney injury in this population of hospitalized horses is similar to that reported in dogs and humans. Serum creatinine concentrations could be monitored in hospitalized horses to allow identification and early treatment of acute kidney injury. Further work is required to establish the impact of stage 1 acute kidney injury on long term equine health.\n\nComparison of Two Collection Methods for Cerebrospinal Fluid Analysis from the Standing, Sedate Adult Horse practiced; however, CSF collection from the space between the first and second cervical vertebrae (C1-C2) has also been described. The purpose of this study was to compare collection times, CSF cytology results, and equine protozoal myelitis (EPM) titers between the two collection sites.\n\nHealthy adult horses (n=14) and horses with a complaint of neurologic disease (n=7) were used. Cerebrospinal fluid was collected from both sites in randomized order. Continuous data were analyzed using mixed-effects linear models and count data using mixed-effects negative binomial regression. Statistical significance was set at P < 0.05. Medical records of adult horses and foals admitted to a Veterinary Teaching Hospital from 1979 through 2017 were examined for cases presenting with signs of diffuse brain disease, and serological or postmortem diagnosis of Eastern Equine Encephalitis. There were 104 cases that met the inclusion criteria. Data retrieved included season at admission, signalment, physical examination, neurologic evaluation, and clinicopathologic findings at presentation; as well as duration of hospitalization, treatment, and case outcome. Where available, historical information (i.e. vaccination status, treatment prior to referral) was also included.\n\nThe median age at presentation was 1.4 years (range: 0.1-13.4 years), with Thoroughbred and Quarter Horse breeds most common. Cases were typically admitted during summer (63 %), and less frequently during spring (17 %), fall (11 %), and winter (9 %). Prognosis associated with equine lymphoma is often grave, and treatment is often non-curative. Few studies have evaluated long-term outcome following chemotherapy in horses treated for lymphoma.\n\nThe purpose of this study was to report long-term outcome of horses with lymphoma treated with chemotherapeutic protocols. Eleven horses were included following medical record search and case recruitment via the ACVIM LAIM and Oncology Diplomate listserves.\n\nEight horses had multicentric lymphoma and three horses had cutaneous lymphoma. T-cell rich large B-cell lymphoma was the most common immunohistochemical classification (n = 6). Three horses were EHV-5 positive on biopsy samples of neoplastic tissue. Chemotherapeutic agents included cyclophosphamide (n = 9), vincristine (n = 9), lomustine (n = 8), L-asparaginase (n = 7), doxorubicin (n = 6), cytosine arabinoside (n = 2), chlorambucil (n = 1), and intra-lesional cisplatin (n = 1). Adjunctive treatments included corticosteroids (n = 9) and valacyclovir (n = 3).\n\nComplete remission was achieved in 5 horses (45.5%), partial response was achieved in 3 horses (27.3%), stable disease was achieved in 1 horse, and 2 horses died during treatment. Overall response rate was 73% (8/11). All 3 horses with EHV-5 associated lymphoma achieved complete remission. Two pregnant mares were treated, with one mare surviving to foaling. Overall median survival time was 13 months (range, 1 -41 months). Median survival time for multicentric lymphoma (n = 8) was 7.5 months (range, 1 -28 months) and median survival time for cutaneous lymphoma (n = 3) was 21 months (range, 16 -41 months). Seven of 11 horses exhibited a total of 11 adverse effects directly attributed to chemotherapy. Adverse effects were graded according to the VCOG-CTCAE grading system (grade 1 alopecia, n = 2; grade 1 combined neutropenia and lymphopenia, n = 2; grade 1 lymphopenia, n = 1; grade 1 lethargy, n = 1; grade 2 gastrointestinal signs, n = 1; grade 2 injection site reaction, n = 1; grade 2 hypersensitivity, n = 1; grade 4 hypersensitivity, n = 1; grade 5 hypersensitivity, n = 1). Higher grade adverse effects were most commonly associated with doxorubicin administration (n = 3), including one horse that died 18 hours post-administration. This report is limited by its retrospective nature, particularly the variation in treatment.\n\nHowever, these findings show that chemotherapy can be used successfully for treatment of equine lymphoma. Adverse effects, most commonly mild, occurred in approximately two-thirds of treated cases.\n\nMedical and Surgical Treatment of Primary Hyperparathyroidism in 17 Equids (1999) (2000) (2001) (2002) (2003) (2004) (2005) (2006) (2007) (2008) (2009) (2010) (2011) (2012) (2013) (2014) (2015) (2016) parathyroid hormone (PTH); 2) normal PTH with high calcium and negative PTH-related protein; or 3) histopathologic identification of a parathyroid adenoma.\n\nSixteen horses and one mule fulfilled the inclusion criteria. The most common presenting complaints included weight loss (12), hypercalcemia (10), anorexia (6) , and colic (2) . The median ionized calcium at presentation was 2.66 mmol/L (range, 2.14 -4.95 mmol/L; reference range 1.58 -1.9 mmol/L), and the median PTH concentration was 23.7 pmol/L (range: 3.8 -128.63 pmol/L; reference range 0.6 -11 pmol/L). Suspected abnormal parathyroid tissue was localized in 12/17 equids by ultrasonography (7/13) and/or technetium 99m sestamibi scintigraphy (10/11). Five out of five successfully excised tumors were located at the thoracic inlet, and surgery resulted in complete cure. One peri-thyroid tumor was excised; however, the horse remained hypercalcemic following surgery. Four additional cases treated surgically, five treated medically, and two not treated also remained hypercalcemic.\n\nParathyroid adenomas in equids can be successfully localized with ultrasonography and/or scintigraphy. Surgical excision appears more likely to be successful if a single abnormal gland is identified at the thoracic inlet. Client-owned horses were recruited. Horses with abnormal physical examination or complete blood cell count, incomplete data, or with signs of pituitary pars intermedia dysfunction were excluded from further testing. The CGIT was performed after overnight grain fasting. Serum samples were stored at -80 C and the biomarkers were tested via previously validated ELISA or colorimetric assays. Age, body condition score (BCS), cresty neck score (CNS), baseline glucose, baseline insulin and triglycerides were also recorded. Characteristics of horses categorized as having insulin dysregulation and of those that did not were compared.\n\nOf the 32 horses that met inclusion criteria, 12 horses (37.5%) were determined as having insulin dysregulation. Age, BCS, baseline glucose, triglycerides, MG, D-lactate, L-lactate, TNF-\u03b1, IL-6 and MCP-1 did not differ significantly between the two groups of horses. In univariate analysis, baseline insulin was significantly associated with insulin dysregulation (P < 0.05), but not in multivariate logistic regression.\n\nOf note, horses with CNS \u2265 3 had 11 times higher odds of having insulin dysregulation (OR 11.3, 95% C.I. 2.04-63.08, P < 0.05). In this study, inflammatory markers, MG and D-lactate were not good predictors of insulin dysregulation. The EIA has been evaluated in horses, however, information is lacking in healthy and sick newborn foals. Our study sought to evaluate GLP-1 (total and active), GIP, and insulin response to fasting and dextrose (oral and intravenous) administration in healthy newborn foals.\n\nOral and intravenous glucose tolerance tests were performed in 17 healthy Standardbred foals < 72 hours old. Following 1 hour of fasting, a bolus of dextrose (300 or 500 mg/kg) was administered orally or intravenously. Blood incretin and insulin concentrations were measured at 0, 5, 10, 15, 30, 45, 60, 90, 120, 150, and 180 In foals allowed to nurse, incretin concentrations increased above baseline within 15 minutes of nursing. Minimal incretin response with oral dextrose but rapid incretin release after nursing indicates that 500 mg/kg was insufficient for a strong EIA stimulation, that higher dextrose dosing is required, or that factors in milk may be important to activate the EIA in newborn foals. The aim of this study was to determine if hyperinsulinaemia could be reduced and laminitis prevented in insulin-dysregulated ponies, by using the sodium-glucose co-transport 2 (SGLT-2) inhibitor velagliflozin. Forty-nine ponies with varying degrees of insulin dysregulation, based on an oral glucose test (1 g dextrose/kg BW), received either velagliflozin (0.3 mg/kg, p.o., s.i.d., n = 12), or a placebo (n = 37), throughout the study. A maintenance diet of lucerne hay was fed for 3 weeks, followed by a high-NSC challenge diet (12 g NSC/kg BW/day) for up to 18 days. On the second day of the diet challenge blood glucose and serum insulin were measured over 4 h after feeding. Results are expressed as geometric mean (95% CI). The maximum concentration of glucose was lower (P = 0.022) for the velagliflozin group at 9.4 mM (8.0 -11.0) versus 11.9 mM (10. 5 -13.4) Oral glucose tests (OGT) are currently recommended for diagnosis of insulin dysregulation (ID). As horses suffering from ID are prone to laminitis especially when exposed to high amounts of sugar it would be desirable to reduce the amount of diagnostic glucose. Furthermore, a reduced glucose amount enables various routes of application.\n\nAim of this study was to determine whether a dosage of 0.25g or 0.5g glucose per kg bodyweight (BW) instead of 1g/kg BW would be useful for clinical settings and sufficient to distinguish between insulin sensitive and insulin dysregulated horses.\n\nEighteen Icelandic horses of different sex, age, bodyweight and uncertain metabolic status were tested each by application of 0.25g/kg BW (LOGT), 0.5g/kg BW (MOGT) and 1g/kg BW (OGT) glucose dissolved in 2L water and administered via naso-gastric-tube. Blood samples were collected for five hours and were analyzed for insulin and glucose.\n\nBlood glucose concentration was significantly lower in LOGT compared to OGT (P < 0.0004) from 60 minutes and significantly lower in MOGT compared to OGT from 90 minutes (P < 0.0001) after application. Insulin concentration after 30 minutes was significantly lower in LOGT compared to MOGT (P < 0.05) and OGT (P < 0.01). No statistically different insulin concentrations were detected between MOGT and OGT until 135 minutes (P < 0.001). Moreover, insulin dynamics in MOGT and OGT allowed satisfying differentiation in insulin sensitive and insulin dysregulated horses.\n\nSumming up, a reduction of glucose to 0.5g/kg BW in OGT can be recommended without loss of diagnostic value. In experiment 1, 14 horses were allowed access to hay or pasture prior to the OST. In experiment 2, 10 horses were fasted overnight prior to the OST. For both studies, corn syrup formulation order was randomized and oral sugar tests were performed one week apart.\n\nBlood was drawn for measurement of blood glucose and insulin concentrations at T0 (prior to administration of corn syrup) and 30, 60, 75, 90, and 120 minutes after administration of corn syrup. Blood glucose was measured using a handheld glucometer and serum insulin was measured using a radioimmunoassay. Data was analyzed for normality. Insulin concentrations were log transformed for normality.\n\nChanges in glucose and insulin concentration at each time point, area under the curve (AUC), maximum concentration (C max ), and time at C max (T max ) were compared between formulations using a two way analysis of variance with repeated measures. Bland Altman analysis was used to determine agreement in insulin concentrations between formulations. There were no significant differences between Karo and Crown syrup formulations at any individual time points for insulin or glucose concentrations in either experiment (P > 0.2) There were no significant differences between the area under the curve, T max , or C max for insulin or glucose concentrations with Karo compared to Crown syrup (P > 0.1). Bland-Altman analysis of insulin concentrations indicated a mean bias (Karo-Crown) of 4 \u03bcIU/mL (95% limits of agreement, \u221211.7 to 19.6 \u03bcIU/mL; experiment 1) or a mean bias of 1.6 \u03bcIU/ml (95% limits of agreement, \u221211 to 14.2 \u03bcIU/ml; experiment 2) for insulin concentrations at 75 minutes. This study suggests that horses have similar glucose and insulin responses to these two formulations of corn syrup.\n\nRemona Horn, Fran\u00e7ois-Ren\u00e9 Bertin The University of Queensland, Gatton, Queensland, Australia Equine metabolic syndrome (EMS) and pituitary pars intermedia dysfunction (PPID) are the most common hormonal disorders in horses and can coexist in the same patient. The aim of this study is to combine two diagnostic tools to diagnose PPID and EMS at once within 30 minutes. It was hypothesised that measured values from the 2-step insulin response test and the thyrotropin-releasing hormone (TRH) stimulation test performed in combination would not differ from the values obtained when tests are performed independently.\n\nTwenty-one horses were tested for EMS and PPID using a 2-step insulin response test and a TRH stimulation test respectively and classified as EMS, PPID, EMS and PPID or controls. For combined testing, insulin and TRH were injected simultaneously. Results were compared among protocols by paired t tests or Wilcoxon signed rank test and Bland-Altman analysis.\n\nBased on independent testing, 8 horses were considered as controls, 4 as EMS only, 3 as PPID only and 6 as EMS and PPID. Independent or combined testing conditions did not significantly affect ACTH concentrations before or after TRH injection nor it changed the percentage of reduction in blood glucose after insulin injection when compared within groups or overall (p > 0.05). In one control horse, combined testing resulted in a larger increase in ACTH after TRH injection consistent with a diagnosis of PPID.\n\nCombination of the TRH stimulation test and the 2-step insulin sensitivity test appears as an attractive and rapid tool to diagnose EMS and PPID at the same time in horses. the curve (AUC) and peak concentrations for insulin and glucose were assessed using a one-way ANOVA (significant at P < 0.05). Repeatability was assessed using Bland-Altman Plots. Significant differences were not noted between KLCS and FCS for either AUC or peak concentrations. However, when insulin results were compared to the ID positive insulin cut off, tests with fructose correctly identified horses with ID only 8 of 14 times; OSTs without fructose identified ID in 12 of the 14 tests. Based on this, fructose does not have a substantial impact on glucose metabolism in horses, but may interfere with insulin responses during an OST. Vitamin E is essential for neuromuscular function. Oral supplementation with natural (\"RRR\") \u03b1-tocopherol has been the mainstay of therapy in horses with hypovitaminosis E. However, there is a subset of non-responsive horses. The objectives of this pilot trial were to evaluate the safety and efficacy of an injectable RRR-\u03b1-tocopherol preparation delivered subcutaneously. We hypothesized that RRR\u03b1-tocopherol injection would increase serum and cerebrospinal fluid (CSF) \u03b1-tocopherol concentrations in healthy adult horses. Six mixed breed horses (3 mares and 3 geldings) and two untreated horses (1 mare and 1 gelding) were enrolled. In Phase I, horses were randomly assigned to receive RRR-\u03b1-tocopherol (5000 IU/450kg of 600 IU/mL) by subcutaneous (n=3) or oral (n=3) administration. Moderate tissue reaction following injection necessitated adjustment of the preparation through reduction of the RRR-\u03b1-tocopherol concentration to 500 IU/mL. Following an 8-week washout period, horses received the reciprocal treatment in Phase II with the new preparation at an equivalent dose. Alpha-tocopherol concentrations of serum and CSF collected over a 7d period were determined by HPLC. There was no difference in baseline serum (P=0.07) or CSF (P=0.20) concentrations and no residual effect noted, indicating appropriate washout. Serum (P < 0.0001) and CSF (P=0.0.007) \u03b1-tocopherol concentrations increased significantly post-injection only when the 500 IU/mL product was administered, with serum concentrations peaking at 24h post-injection. This injectable formulation may therefore be useful in cases refractory to oral supplementation. However, caution is warranted due to the marked local tissue reaction observed in all horses. Hypophosphatemia, hypokalemia, and hypomagnesemia are associated with various diseases in equids. Despite the interactions between these analytes and energy metabolism, evaluation of their concentrations in critically ill equids with lipid disorders is not frequently performed; therefore, the incidence of these abnormalities in these patients remains unclear. Medical records from 54 hospitalized small equids [ponies (multiple breeds), American Miniature Horses, and donkeys] greater than 2 years of age with serum triglyceride concentrations greater than 200 mg/dL admitted between 2002-2017 were reviewed, and relationships between biochemical analytes were assessed (Chi-square analysis).\n\nMost patients (59%) survived to discharge, while 41% were euthanized or died. Patients were stratified into quartiles based on triglyceride concentrations (1 st quartile 207-343 mg/dL, 2 nd quartile 386-638 mg/dL, 3 rd quartile 668-989 mg/dL, and 4 th quartile 1014-3281 mg/dL). Equids with triglycerides in the 1 st and 2 nd quartiles were more likely to survive than those with triglyceride concentrations in the 3 rd and 4 th quartiles (OR = 1.66; p < 0.05). Hypophosphatemia (P < 2.5 mg/dL), hypokalemia (K < 3.0 mEq/L), and hypomagnesemia (total Mg < 1.29 mg/dL) were observed in 25%, 16.1%, and 10.7% of all cases, respectively. Only potassium concentration was significantly correlated with triglyceride concentrations (\u03c1 = -0.318; p < 0.05).\n\nEquids with triglyceride concentrations in the 3 rd and 4 th quartiles were more likely to be hypokalemic (OR = 3.92; p < 0.05). Hypophosphatemia was not associated with survival, and most (72%) equids with hypertriglyceridemia and hypophosphatemia survived. Evaluation of phosphorus, potassium, and magnesium is recommended in equids with dyslipidemias. horses during endurance racing and its influence on performance have been studied, but information is lacking for Thoroughbred racehorses.\n\nOur objective was to assess the effect of supra-maximal exercise on the lipidome of racehorses.\n\nFour Thoroughbred geldings of similar body condition and age were used. Horses were housed in the same barn and fed the same diet.\n\nEach horse underwent treadmill exercise to fatigue at 115% of its _ VO 2 max (10.6\u00b10.6m/s; 10% slope). Venous plasma samples were obtained before and immediately, 15 and 30mins post-exercise, and evaluated using an untargeted lipidomics approach at West Coast Metabolomics Center. Data was analyzed using principal components analysis and 1-way RM ANOVA (significance was set at p < 0.05). 965 plasma lipids were detected. Of these, 184 were \"known\" as their spectra and retention index are linked to library entries. After exercise, plasma levels of eight lipids changed significantly, likely reflecting the occurrence of lipolysis. Briefly, an increase of unsaturated fatty acids (11,14-eicosadienoic, 9-11-octadecadienoic and \u03b1-linoleic acids) and a decrease of saturated fatty acids (Icosanoic, heptadecanoic, lauric and myristic acids) and phospholipids (Sphingomyelin) were observed.\n\nThis pilot study provides valuable information regarding changes in the lipidome of Thoroughbreds associated with supramaximal exercise and will serve as a reference to guide future studies of the racehorse metabolome. analyses. 2DST was recently described to be a feasible method to quantify LA function in healthy horses. We aimed to provide proof of concept for use of 2DST to detect compromised LA booster pump function in horses.\n\nWarmblood horses with atrial fibrillation, successful TVEC and continued normal sinus rhythm for at least one month thereafter were included in this study. Echocardiography was performed 24h, 72h and 1mt after TVEC. Maximum LA area (LAA max ) and LA diameter (LAD max ) as well as active and passive LA fractional area change (FAC) were measured using 2DE on a right-parasternal 4-chamber view focusing on the left atrium. LA dimensions were measured at endsystole and allometrically scaled to a body weight of 500 kg. Global longitudinal peak strain (S L ) and strain rate (SR L ) during active booster pump function were measured on the same recordings using 2DST analyses. Measurements were judged in relation to previously established reference intervals. Friedman one-way ANOVA with Dunn';s multiple comparison test was performed to detect differences between timepoints. Linear regression analysis was performed to describe associations of S L and SR L with conventional 2DE measurements of LA size and function, considering for repeated measurements within horses. P < 0.05 was considered significant.\n\nThirteen Warmblood horses fulfilled the inclusion criteria. Measurement of all indices at all 3 timepoints was feasible in 6/13 horses, whereas severe LA enlargement prevented measurement in 7 horses.\n\nLA contractile dysfunction 24h after TVEC was detected in 5/6 horses based on active LA FAC and global S L . Active LA FAC did not change over time (p = 0.14) and remained below reference limits in 5/6 horses. Global S L significantly increased from 24h to 1mt after TVEC (p = 0.028); at that time, S L of all 6 horses was within (but at the lower range) of the reference interval. SR L was below the reference interval in 2/6 horses 24h after TVEC and within reference limits in all 6 horses 1mt after TVEC (p = 0.30). Strain and strain rate were significantly associated with active FAC (p2 adj =0.76 and p2 adj =0.77), passive FAC (p=0.016, R 2 adj =0.55 and p=0.016, R 2 adj =0.55), LAA max (p2 adj =0.85 and p2 adj =0.88), and LAD max (p2 adj =0.83 and p2 adj =0.85), with lower S L and SR L in larger atria.\n\nThis study shows that 2DST is useful to detect compromised LA contractile function in horses after conversion of AF to NSR using TVEC.\n\nStrain and strain rate are negatively related to LA enlargement. The clinical value of 2DST to predict the risk of recurrence of atrial fibrillation will have to be established in future studies. Monensin is highly toxic to horses and inadvertent ingestion can result in cardiac dysfunction and death. The objectives of this prospective study were to determine the cardiovascular and athletic outcome of horses exposed to monensin.\n\nPhysical examination, exercise stress testing, ECG (pre-and during exercise) and echocardiography (pre-and post-exercise) were performed in 76 horses exposed to monensin-contaminated feed. Four horses were examined within 2 weeks of exposure (acute period).\n\nTwenty-nine horses were examined between 15 and 45 days postexposure (subacute period) and 70 horses were examined after 4 to 10 months of rest (chronic period). Follow-up information was obtained by telephone interviews approximately 16 months after exposure for 56 horses.\n\nThree of the 4 horses (75 %) presented during the acute period died or were euthanized; all horses had clinical signs and cardiac anomalies at rest. Nineteen of the 29 horses (66 %) examined during the subacute period had cardiac anomalies (upon physical examination (11), cardiac examination at rest (16) and with exercise (5)). Four to 10 months after exposure, 31 of the 70 horses (44 %) had cardiac abnormalities (upon physical examination (6) , cardiac examination at rest (22) and with exercise (13)). Sixteen months after exposure, 34 (53 %) of the 64 horses with known outcome had returned to their intended use, including 10 horses with cardiac anomalies in the previous months.\n\nClinical outcome of horses exposed to sublethal doses of monensin is highly variable and commonly result in long-term cardiac dysfunction leading to exercise intolerance and even death.\n\nComparison of Non-invasive, Invasive Central and Invasive Peripheral Blood Pressure in the Standing Horse (coccygeal) was measured using a commercial oscillometric device (Mindray Passport 12) and corrected for the vertical distance between the base of the tail and the heart base. Measurements were obtained under baseline, high (dobutamine), and low (acepromazine) blood pressures. Mean bias, SD of the bias, and Pearson';s product correlation (R) were calculated from data obtained from 11 horses.\n\nMean bias/SD of the bias/R between IBPc and IBP were -3 mmHg/12 mmHg / 0.92 for systolic, 2.8 mmHg/ 6.1 mmHg /0.96 for mean, and 5.5 mmHg/ 7.3 mmHg/ 0.91 for diastolic pressures. Mean bias/SD of the bias/R between IBPc, and NIBP were -1.3 mmHg/ 12.1 mmHg/ 0.91 for systolic, 6.4 mmHg/ 11.4 mmHg/ 0.86 for mean, and 10.1 mmHg/ 15.7 mmHg/ 0.72 for diastolic pressures.\n\nMean bias/SD of the bias/R between IBP and NIBP were 0.1 mmHg/ 12.8 mmHg/ 0.91 for systolic, 3.2 mmHg/ 11.1 mmHg/ 0.88 for mean, and 4.7 mmHg/ 15.7 mmHg/ 0.72 for diastolic pressures.\n\nMeasuring IBPc without a surgical approach was feasible. IBP is an acceptable surrogate for IBPc but these are not interchangeable under all circumstances. The NIBP device tested had acceptable accuracy and precision for systolic pressure following ACVIM suggested criteria and approximated the criteria for mean blood pressure. Diastolic pressure measurements were less accurate and precise. Continuation of glycolysis in erythrocytes after blood collection may cause an artifactual in vitro increase of methylglyoxal, and consequently of its metabolite D-lactate. Sodium fluoride (NaF) inhibits enolase in the glycolysis pathway. Our hypotheses were that equine blood collected in NaF tubes would result in both valid and lower Dlactate values when compared to serum tubes, and that D-lactate concentrations would be stable up to 6 months at -80 C.\n\nBlood was collected in both serum and NaF tubes from 23 horses and kept on ice until centrifugation for separation of serum or plasma.\n\nSamples were frozen at -80 C until analysis (after 1, 2 and 6 months) with a previously validated commercial assay (D-Lactate Colorimetric Assay Kit, BioVision, Inc., Milpitas, CA, USA). D-lactate values measured from blood collected in serum tubes had a mean (\u00b1 SD) concentration of 0.26mmol/L (0.09), 0.27mmol/L (0.09) and 0.17mmol/L (0.07) after 1, 2 and 6 months, respectively. From the NaF tubes, the mean D-lactate concentrations were 0.05mmol/L (0.01), 0.06mmol/L (0.01) and 0.03mmol/L (0.01) after 1, 2 and 6 months, respectively. D-lactate was significantly different (P < 0.0001) between serum and NaF samples, and when comparing 6 months to 1 and 2 months within the NaF tube type (P < 0.0001).\n\nUse of NaF tubes is recommended for equine blood collection for determination of D-lactate concentration, as use of serum tubes results in inflated and inaccurate values. Furthermore, longer-term storage (>2 months at -80 C) appears to result in sample degradation and should be interpreted with caution. Adult horses and ponies fulfilling at least two criteria of an adapted SIRS-score were included. A standard human protocol measuring activated platelets and platelet-leukocyte-aggregates (PLA) with fluorescence flow cytometry in platelet-leukocyte-rich-plasma (PLRP) was established in horses. Activation of platelets was determined by increased presentation of CD62P and CD154 on platelets. Activation and PLA were measured before and after in vitro activation of platelets with collagen. Ten healthy adult horses and ponies served as controls. Statistical analysis included proof of normal distribution followed by two-way ANOVA and post-hoc Bonferroni tests.\n\nThe 19 included horses and ponies with SIRS had significantly more activated platelets and PLA in native PLRP than controls: CD62P 11.73 \u00b1 3.74 % in SIRS and 1.74 \u00b1 0.36% in controls (P = 0.0004); CD154 2.10 \u00b1 0.91 % and 0.40 \u00b1 0.08% respectively (P = 0.119); PLA 6.23 \u00b1 1.18 % and 2.46 \u00b1 0.32% respectively (P = 0.031). Six horses survived. There was a trend for more activation and PLA in nonsurviving horses. Furthermore a trend for reduced in vitro activation with collagen was detected in the non-survivors. This is the first study demonstrating increased platelet activation and platelet-leukocyte-aggregates with fluorescence flow cytometry in clinical cases of equine SIRS. Likewise platelet activation could be a prognostic factor in these patients. Antiplatelet therapy (e.g. clopidogrel) could be an additional therapeutic option in clinical cases of SIRS and other inflammatory diseases to prevent complications and improve outcome. In a cross-sectional study, serum samples from 454 Thoroughbred foals (aged 58-183 d) were analysed for anti-EqHV non-structural (NS)3-specific antibodies (Abs) with the luciferase immunoprecipitation system (LIPS) and for EqHV RNA by quantitative real-time polymerase chain reaction (qRT-PCR). Farms of origin (n=26) were situated in the Western Cape Province, South Africa. Descriptive analysis was performed to study associations between EqHV infection status, age and gender. Identified EqHV isolates were sequenced, with subsequent phylogenetic analysis of genomic portions located in the NS3-gene.\n\nAbs were detected in 83.7% (380/454) of samples -the highest seroprevalence reported yet in an equine population. The RNA prevalence of 7.9% (36/454) was within the previously reported range. Increasing foal-age was associated with decreasing prevalence of Abs and increasing prevalence of EqHV viraemia. South African EqHV strains didn';t cluster separately to published sequences of EqHV strains.\n\nIn conclusion, EqHV is circulating in the South African Thoroughbred population and appears to be more prevalent than in other horse populations worldwide.\n\nValidation of an In-Clinic Enzyme-Linked Immunosorbent Assay for Diagnosis of Leptospirosis in Horses Serum from naturally infected horses was randomly selected from samples submitted to the Animal Health Diagnostic Center at Cornell University that were identified as positive on the MAT in any serovar (n = 31). A random selection of MAT negative samples was also included for testing (n = 20). All samples (n = 148) were tested with the IDEXX SNAP Lepto. The performance of the test kits was compared to the MAT. The accuracy was measured in terms of the relative sensitivity and specificity with a cut-off point for positivity in the MAT of \u2265 100. The relationship between the MAT titer and the probability of positivity in the IDEXX SNAP Lepto was assessed using logistic regression analysis.\n\nResults indicated that the test kits have high specificity (100%). Sensitivity was poor at titers \u2264400 (0 -36%) and moderate at titers 800-1600 (50%), but was excellent at titers \u2265 3200 (90-100%).\n\nThe IDEXX SNAP Lepto provides a rapid in-clinic test for evidence of antibody response to Leptospira species in horses, with excellent specificity and high sensitivity with increasing titers. Leptospirosis associated abortion and acute renal disease often result in MAT titers of \u2265 6,400. This test kit may allow for prompt stall-side or field determination of Leptospirosis status in these cases. Bacterial and viral microbiotas often inhabit and share the same microenvironments, however, interest in their potential contribution in promoting health or disease has only recently gained attention. The objective of this study was to characterize the nasal bacterial microbiota of healthy horses (control) and horses shedding equine herpes virus-1 (EHV-1) using next generation sequencing technology.\n\nThe nasal bacterial microbiota of 10 EHV-1 and 10 control horses from a single farm experiencing an outbreak of EHV-1 was characterized using the Illumina MiSeq platform targeting the V4 region of the 16S rRNA gene. All EHV-1 horses had fever, limb edema and were positive on PCR of nasal swabs, within one week after the first case was confirmed EHV-1 positive. Control horses were animals from the same farm that showed no clinical signs during the outbreak and were negative for EHV-1 on PCR.\n\nNasal bacterial microbiota of healthy and EHV-1 was significantly different in community membership (Jaccard index) and structure Dorsal Displacement of the Soft Palate (DDSP) has been well described in race horses 1, 2 . Even though a link between DDSP and lower airway inflammation has been suggested in race horses 3 , the treatment of choice remains surgical. DDSP has also been described in sport horses 4 although no efforts have been made to correlate this with lower airway inflammation.\n\nA retrospective study was performed over a period of 3 years: and phone contact of 22 horses. Treatment was successful in 22/25 cases. These horses stopped coughing or making a noise and were performing up to expectation. Treatment failures occurred in 2 very chronic cases and 1 case where the DDSP occurred after tie back surgery.\n\nThis study shows that in this sport horse population, DDSP was associated with lower airway inflammation in a large proportion of cases and can be managed medically. There was a significant increase in PGE 2 levels in ischemic-injured tissues treated with t-TUCB as compared to untreated ischemicinjured tissues (p = 0.0151). The untreated and t-TUCB-treated ischemic-injured tissues had significantly reduced TER compared to the non-ischemic tissues (p < 0.0001 and p = 0.0001). However, there were no statistical differences between ischemicinjured tissues treated with or without t-TUCB. We conclude that t-TUCB is a novel modulator of PG levels, resulting in increased PGE 2 in tissues injured by ischemia without significantly impairing recovery of barrier function. Therefore, t-TUCB may have a future use to treat animals with diseases such as strangulating obstruction.\n\nPharmacokinetics of and 28 days after discharge (Day 28). Samples were semiquantitatively cultured on ESBL-agar. Differences between groups were analysed using the Chi-square test, odds ratios and two-way repeated measures ANOVA.\n\nPrevalence on Day 0 was not different between groups (p = 0.47).\n\nHorses treated with CEF and P/G were more likely to shed ESBL-producing Enterobacteriaceae compared to NOAMD on Day 3 (OR: 0.4, p = 0.07 and OR: 6.8, p = 0.04, respectively) and Day 28 (OR: 0.2, p = 0.02 and OR: 6.3, p = 0.003, respectively). ESBL counts increased from Day 0 to Day 3 in all groups (CEF p = 0.001, P/G p < 0.001, NOAMD p = 0.02). ESBL bacterial count was significantly higher in the P/G group compared to CEF and NOAMD group (p = 0.001 and p < 0.001, respectively) and was also significantly higher in the CEF group compared to NOAMD group (p = 0.001).\n\nwith ESBL-producing Enterobacteriaceae. Administration of cefquinome did not induce higher shedding rates compared to administration of penicillin/gentamicin as a standard antibiosis. This highlights the need for reducing antimicrobial use overall.\n\nJennifer R. Bauquier, Simon R. Bailey University of Melbourne, Werribee, Victoria, Australia Mitochondrial products, especially mitochondrial DNA, are proinflammatory in human studies, presumably due to their bacterial evolutionary origins. Therefore their release from tissue necrosis may be an important contributor to the inflammatory response in the horse. The aim of this study was to determine the inflammatory response to mitochondrial products in an in vitro equine whole blood assay.\n\nMitochondria were isolated from liver tissue of a systemically healthy horse by cell lysis and centrifugation. Mitochondria were then fragmented by freeze-thawing and serially diluted from 1:1 to 1:512 in PBS, and added to aliquots of whole blood from 6 healthy horses, mixed 1:1 with RPMI medium, with one aliquot serving as a negative control. Aliquots were incubated rotating at 37 C for 21 hours. The inflammatory response was determined by measuring TNF-\u03b1 in the supernatant using a murine L929 fibroblast bioassay.\n\nMitochondrial fragments caused an inflammatory effect in equine whole blood, producing a concentration-dependent increase in TNF-\u03b1 release into the plasma/supernatant, which fitted to a sigmoidal concentration-response curve. There was a 7.3-fold increase in TNF-\u03b1 production at the lowest dilutions of mitochondrial fragments (557.5 \u00b1 470.5 pg/mL at 1:2 dilution compared with 76.1 \u00b1 33.9 pg/mL in whole blood incubated with no fragments).\n\nThe release of mitochondrial fragments from localized tissue damage, inflammation or necrosis might contribute to the clinical severity of SIRS, and possibly offer a mechanism for the development of SIRS in horses in the absence of obvious gastrointestinal disease or infection.\n\nFurther work is warranted to investigate the significance of inflammation caused by mitochondrial fragments in horses, including novel anti-inflammatory therapies. The electrocardiogram is an indispensable tool in the diagnosis of arrhythmias and electric conduction disorders in the equine heart.\n\nHowever, several electrocardiographic variables may be influenced by factors such as species, age, gender, breed and morphofunctional constitution, highlighting the importance of knowing normal characteristics for distinct species, breeds and development stages. This study aims at assessing the electrocardiographic development in the frontal plane and apical-to-basal derivations during the last days of pregnancy (35, 28, 21, 14, 7 and 1 day before birth) in 10 donkeys of the Pega breed. Therefore, the electrocardiogram was conducted in a computer-interpreted electrocardiography device in the frontal plane and apical-to-basal derivations for 5 minutes without sedatives, tranquilizers or anesthetics. The results are shown in Table 1 . We did not observe physiological or pathological cardiac arrhythmias or electric conduction disorders in the animals assessed. The heartrates observed in frontal plane and apical-to-basal derivations presented minimal changes between the studied moments during pregnancy and the predominant cardiac rhythm observed in 100% (60/60) of the females was sinus tachycardia, with the heartrate increasing as the birth got closer (58\u00b18.47 bpm in the 35 th day before birth and 61,3\u00b111 bpm at birth). Bifid and biphasic P waves were predominant at all moments.\n\nWe observed significant differences in the duration of PR intervals (ms) in the frontal plane and apical-to-basal derivations, and in the QT interval (ms) in both derivations; as well as a significant increase in R wave amplitude. The electrocardiographic parameters of pregnant donkeys diverge in terms of duration, amplitude and morphology in (E39) contrast with other donkey and equine breeds and these findings highlight the importance of obtaining specific values for distinct species, breeds and pregnancy stage so a safer prenatal care can be achieved. Key genes involved in the transport of calcium (Ca 2+ ) across the sarcoplasmic reticulum (SR) encode proteins such as the ryanodine receptor (RYR), which releases Ca 2+ from the SR, and SR calcium ATPase (SERCA), which pumps Ca 2+ back into the SR. Newly discovered regulatory micropeptides such as MRLN, PLN and SLN inhibit SERCA, thereby controlling intracellular Ca 2+ and contractility. The transcript expression or protein abundance of these micropeptides in horses is unknown. The purpose of this study is to determine the relative expression of equine Ca 2+ regulatory genes in left ventricle, right atrium, and gluteal muscle. RNA was extracted from tissues collected from 7 horses and reverse transcribed into cDNA. Transcript abundance was quantified using qRT-PCR and data normalized to GAPDH (within sample). Data was compared using an ANOVA, with gluteal used as a baseline, and results were corrected for multiple testing. Following a single dose, mean maximum concentration (C max ) was 16.61 ug/mL at 1.35 hours (T max ). APAP remained above presumed therapeutic concentrations (10 ug/mL) for two hours postadministration and was undetected by 12 hours. Elimination half-life (T \u00bd ) was 2.78h. No significant accumulation was noted following multiple doses. Average C max of APAP following repeated oral dosing was 15.85 ug/mL, with a T max of 0.99 hours and T 1/2 of 4 hours. SDH was significantly decreased (pre: 13.84 U/L, post: 10.52 U/L, p = 0.013) and total bilirubin was significantly increased (pre: 1.99 mg/dl, post:\n\n3.47 mg/dl, p = 0.004) following the last dose. No statistically significant changes were noted in gastroscopy scores (pre: 9.67 mean, post:\n\n10.08 mean, p = 0.75). Dose simulations suggested higher doses and/or shorter dosing intervals may be indicated.\n\nThis study demonstrated the safety of acetaminophen with repeated oral dosing over 14 days. This study also confirms that the 20 mg/kg dose used in previous clinical reports reaches proposed therapeutic concentrations after oral administration to fed horses, however a shorter 6-8 hour dosage interval may be required for improved efficacy. heart rate was detected. This study identified that dexmedetomidine was rapidly but incompletely absorbed after subcutaneous administration. Higher plasma concentrations after intravenous administration were associated with increased blood pressure, compared with subcutaneous administration. These results suggest a need for dosage adjustment based on route of administration for dexmedetomidine.\n\nLucia Mentink 1 , Simon R. Bailey 2 , Jennifer R. Bauquier 2 1 University of Melbourne, Wollongong, New South Wales, Australia, 2 University of Melbourne, Werribee, Victoria, Australia Plasma phosphate concentration (P) and plasma calcium concentration (Ca) change in human sepsis and experimentally-induced systemic inflammatory response syndrome in horses. These easily measured parameters might be useful biomarkers for equine colic. This study aimed to determine the usefulness of P and Ca as prognostic and diagnostic biomarkers in horses with colic.\n\nRecords of horses presenting for colic (including colitis) were reviewed. Controls were healthy teaching horses. P and Ca, and Ca:P were compared between horses with colic and controls. Additional comparisons were made between horses with strangulating, nonstrangulating and inflammatory colic lesions, and survivors and nonsurvivors. Correlations with haematocrit, white cell count (WCC) and fibrinogen were examined.\n\nRecords from 101 colic cases and 24 controls were included. Colic cases had significantly higher P (1.2-fold increase, P=0.037) and significantly lower Ca (1.06-fold decrease, P=0.03) and Ca:P (1.15-fold decrease, P=0.005) than controls. There was no difference in P, Ca or Ca:P between colic lesion groups, but Ca was significantly lower for strangulating and inflammatory lesions compared to controls (P < 0.05), and Ca:P was significantly lower for inflammatory lesions compared to controls (P < 0.05). Weak but significant correlations were found between P and haematocrit, WCC and fibrinogen, but not Ca and these parameters. Ca:P was significantly correlated with fibrinogen and haematocrit but not WCC. Ca and P were not significantly correlated. There was no association between P, Ca or Ca:P and survival.\n\nNeither P, Ca or Ca:P were useful alone as biomarkers, but can contribute to the overall clinical picture. Nine halter-bred American Quarter Horse foals (age range 1 day to 3 months) from a single farm in central Ohio were presented to the OSU CVM for evaluation of diarrhea, lethargy, and inappetance. One foal died within 12 hours of admission, while two foals were euthanized within 2 hours of admission (poor response to resuscitation in one and suspected gastrointestinal rupture in another). Rotavirus PCR performed on feces was positive in 4 foals. One foal was positive for Clostridium difficile on fecal culture, while the rest were negative for Clostridium perfringens/difficile, Salmonella, and Coronavirus. Four foals were discharged from the hospital, but re-presented within 2-3 weeks for persistent inappetance, lethargy, and failure to thrive, and were subsequently diagnosed with pyloric outflow obstruction based on gastroscopy, persistent nasogastric reflux, and barium gastrography.\n\nOne foal re-presented for caudal esophageal stricture, and was euthanized after poor response to treatment. Three foals were euthanized due to pyloric outflow obstruction, while 1 was discharged. Necropsies performed on 3 foals revealed severe gastric distention and pyloric/duodenal stenosis.\n\nWhile gastroduodenal ulceration (EGUS) has been suspected in association with rotavirus, the incidence of multiple cases of pyloric outflow obstruction in association with rotaviral enteritis has not been documented as well in horses as it has in human neonates. EGUS in foals is common (prevalence ranging from 25-50%), and frequently clinically inapparent. Rarely, these lesions may produce stricture and gastric outflow obstruction. This report describes gastric outflow obstruction diagnosed in multiple foals in association with an outbreak of rotavirus.\n\nStephanie Vijan 1 , Katarzyna Dembek 2 , Steven Reed 3 , Nathan Slovis 4 , Ramiro Toribio 5 Septicemia is the leading cause of mortality in newborn foals. Progesterone is mainly known for its role in pregnancy; however, it is also a precursor to adrenocortical and neuroactive steroids and likely plays important functions in equine neonates. Human studies have demonstrated that progesterone modulates immunity and predisposes to inflammatory conditions. However, the mechanisms by which progesterone influences outcomes in sick foals remain unclear. The goal of our study was to measure blood concentrations of inflammatory cytokines and serum amyloid A (SAA) in healthy and hospitalized foals, and to determine their association with progesterone, severity of disease, and mortality. We hypothesized that hospitalized foals will have higher progesterone, 17 \u03b1 -hydroxyprogesterone and cortisol concentrations that will be associated with the inflammatory response, disease severity and mortality. Foals (n = 62) were divided into three groups based on severity of disease (septic [n = 31], sick non-septic [SNS; n = 21], and healthy [n = 10]), and hospitalized foals (SNS and septic) were divided into two groups based on survival (survivors and non-survivors). Blood samples were collected on admission. Hormones were measured by radioimmunoassay, and cytokines by ELISA.\n\nProgesterone, 17 \u03b1 -hydroxyprogesterone, cortisol, and interleukin 1\u03b2 concentrations were significantly higher in septic and SNS compared to healthy foals (P < 0.05). Leukocyte and neutrophil count as well as IgG concentrations were lower, while SAA concentrations were significantly higher in hospitalized compared to healthy foals (P < 0.05).\n\nInterleukin 4 concentrations were significantly higher in non-survivors than survivors. IgG and interleukin 6 concentrations were positively correlated. Progesterone was significantly lower in non-survivors and negatively correlated with SAA (P < 0.05). These results suggest that progesterone, in addition to cortisol, may be involved in the adrenocortical response to stress from critical illness and could influence the inflammatory response in sick foals. This is the first study to associate progestogens with markers of inflammation in hospitalized foals. \n\nand in animal models of sepsis, but have not been FDA approved for use in horses in the US. The objective of the pilot study was to evaluate a single dose of novel anti-TNF antibody in neonatal foals with sepsis.\n\nThe study was a single-dose, multi-center, clinical trial. Foals aged 0-96 hours with sepsis as defined by a sepsis score \u2265 11 or sick (nonseptic) defined as rectal temperature 102.5 F and blood glucose 180 mg/dL were enrolled. Foals were administered anti-TNF antibody ACTH levels were measured at Day 0 (baseline) and over time (variable by storage method). Plasma samples were stored in either -80 C, -20 C or samples placed between ice packs and stored at -20 C. Plasma samples were stored at -80 C for 3, 7, 30, 60 and 90 days, or stored at -20 C for 3, 7, 30 and 60 days, or stored between ice packs at -20 C for 3 and 7 days prior to determination of resting ACTH concentration. Plasma samples were shipped to the Animal Health Diagnostic Center, Cornell University, Ithaca, NY for measurement of resting ACTH concentration. Within each storage method, ACTH levels over time were compared to baseline (nonfrozen Day 0 plasma) using a paired t-test (i.e. each horse serving as its own control and p < 0.05 was considered statistically significant).\n\nData were summarized with mean, standard error (SE) and percent change from baseline (%CFB). Mean ACTH level on Day 0 for plasma stored at -80 C was 392.2 pg/mL that declined 6.9% to 365.0 pg/mL by Day 90. Through Day 60, the %CFB never varied more than 2%. On Day 90, the %CFB was -6.9% although not reaching statistical significance (p = 0.1042), a trend toward significant degradation was observed. Mean ACTH level on Day 0 for plasma stored at -20 C was 392.2 pg/mL that declined 5.3% to 371.4 pg/mL by Day 60. The %CFB was not statistically significant (p = 0.0590) at Day 60 although a decreasing trend was observed.\n\nMean ACTH level at Day 0 for plasma stored between ice packs at -20 C was 392.2 pg/mL that declined 1.1% to 387.9 pg/mL by Day 7. No significant degradation (p = 0.4860) of ACTH was observed by Day 7. None of the storage methods resulted in sample degradation that differed significantly from baseline. Trends toward degradation were observed on Day 90 in -80 C stored samples and on Day 60 at -20 C stored samples. No significant degradation was observed in ACTH from plasma samples stored between ice packs at -20 C for 7 days. Freezing plasma for short periods of time at -20 C or at -80 C for at least 90 days resulted in no statistically significant degradation of plasma ACTH compared to non-frozen plasma baseline samples. Further studies should be conducted to further evaluate the effects of freezing on plasma ACTH concentrations in larger populations of horses. The aim of the study was to evaluate the effects of weight gain, achieved by providing healthy horses a low-carbohydrate and fat rich diet followed by pasture, on insulin sensitivity, blood pressure and serum cortisol concentrations.\n\nWeight gain was induced in 9 Standardbred mares fed a fat supplemented forage diet at 2.5 times the daily requirements for 22 weeks.\n\nHorses were then turned out to pasture for 4 weeks. Insulin sensitivity was measured before and after weight gain and after 4 weeks of pasture using the euglycemic hyperinsulinemic clamp method. Body weight, body condition (BCS), blood pressure and serum cortisol was monitored throughout the study.\n\nAll horses became obese during the weight gain period (BCS \u2265 7.0).\n\nMean arterial blood pressure increased gradually during the weight gain period and was significantly higher than initial values at the end of the weight gain period (78 \u00b1 3 mmHg vs 92 \u00b1 3 mmHg). The mean arterial blood pressure remained at a higher level on pasture (93 \u00b1 3 mmHg). Insulin sensitivity (M:I 60 ) did not change during weight gain In conclusion, obesity was associated with an increase in blood pressure that was not associated with change in insulin sensitivity. The purpose of this study was to compare cortical bone thickness and density of the third metacarpal bone in horses with PPID (PPID + with pars intermedia [PI] histology scores of 4-5 / 5; n = 9), aged horses without PPID (PPID -, PI histology score < 3; n = 6), and young horses (YOUNG [ < 8 years]; n = 5). Following euthanasia the right third metacarpal bone was removed and CT scans were performed. Images were used to measure thickness (mm) and density (Hounsfield Units\n\n[HU] of a region of interest) of the dorsal, palmar, medial, and lateral cortices at the midpoint of the diaphysis. Data were analyzed by ANOVA and ANOVA on ranks. Significant (p < 0.05) differences were found in palmar cortex thickness between PPID + and YOUNG (YOUNG greater) and in lateral cortex thickness between PPIDand both PPID + and YOUNG (PPIDgreater than both PPID + and YOUNG). For bone density the only significant (p < 0.05) difference detected was in palmar HU between PPID + and YOUNG (YOUNG greater). Although minor differences were found in cortical bone thickness and HU between groups, there was not a consistent effect of PPID + , as compared to PPIDand YOUNG. Further, it was difficult to separate effects of age and PPID status. In conclusion, substantial changes in third metacarpal cortical thickness or density were not found in this cohort of PPID + horses. (3). Sixty-one percent were female, while 31% were geldings, and 7% stallions. Fifty-eight percent survived to discharge, while 41% died or were euthanized. Degree of hyperlipemia was not associated with survival. The most common primary diagnosis was enterocolitis (36%); 17% were diagnosed with a form of colic (medical or surgical), while other diagnoses included primary hyperlipemia, botulism, pneumonia, dystocia, guttural pouch empyema, and lymphoma.\n\nThirty-three percent were treated via voluntary alimentary intake, 28% were administered intravenous dextrose (IVD), 15% were administered enteral nutrition via nasogastric tube (EN-NGT), and 11% were administered both IVD and EN-NGT. Thirteen percent were treated with partial parenteral nutrition, often in combination with nasogastric feeding and intravenous dextrose. Fourteen percent were treated with insulin. Average duration of hospitalization was 5.7 days. Hyperlipemia in hospitalized equids is a common comorbid disorder and does not necessarily require expensive or intensive treatment. Prognosis for survival was fair and not associated with the degree of hypertriglyceridemia. Our objective was to identify risk factors associated with the within-herd prevalence of BLV-infected cows. We hypothesized that, as well as previously established risk factors, management practices associated with calf rearing and fly control would affect within-herd BLV prevalence.\n\nA risk assessment and management program questionnaire (RAMP-Q) was developed and distributed to all bovine veterinarians in Atlantic Canada. All dairy farms shipping milk and who had bulk tank milk (BTM) samples collected in January and April 2017 (n=605) were eligible to participate in the RAMP-Q. BTM samples were tested with ELISA for levels of anti-BLV antibodies to estimate within-herd prevalence. RAMP-Q results were combined with demographic information collected from each farm and with the mean BTM ELISA results. Multivariable linear regression was performed to investigate the association between RAMP-Q risk factors and within-herd prevalence of BLV infection.\n\nOne hundred RAMP-Qs were returned, with participants from each province in Atlantic Canada (New Brunswick, 22; Newfoundland, 3; Nova Scotia, 49; Prince Edward Island, 26) . Factors significantly associated with increasing level of within-herd BLV prevalence included history of clinical BLV within the herd (23.7% increase; 95% CI 6.8-39.9%) and history of purchasing BLV-suspect cattle (19.0% increase; 95% CI 3.4-37.0%). No significant difference in within-herd prevalence was associated with needle and injection (P-value 0.69), fly control (P-value 0.56), or rectal sleeve practices (P-value 0.48), or the use of bulls for natural breeding (P-value 0.81).\n\nImportant factors associated with increasing within-herd BLV prevalence include a history of prior diagnosis of clinical BLV and history of purchasing cows of unknown BLV status. In this study, there was no significant association of any previously established risk factors with increasing within-herd prevalence of BLV infection. The purpose of this prospective case-control study was to describe bacterial communities in the nasopharynx (NP) of preweaned dairy calves with and without ultrasonographic lung lesions. Additional objectives included evaluating the effects of previous antibiotic therapy and age on the NP microbiota composition. A total of 257 Holstein heifer calves were enrolled into a separate study investigating the genomics of resistance to bovine respiratory disease (BRD) over a 4-week follow up period. Calves were examined twice using thoracic ultrasound and clinical respiratory score (early exam: 4 weeks old; late exam: 7 weeks old). From this population, case and age-matched controls were selected to undergo deep NP swabbing for the current study. Cases were defined by the presence of significant ultrasonographic lung lesions (\u2265 1 lobe completely consolidated). Controls were defined by the lack of these lesions.\n\nThe NP swabs were taken at the time of exam and calf information was collected from farm management software. Swabs were placed in phosphate buffer solution, and stored at -80 C. Following DNA extraction, the V4 region of the 16S rRNA gene was amplified using PCR. Libraries were sequenced using the MiSeq platform. The Diversity data was analyzed using t-tests and general linear models.\n\nComparisons of relative abundance (RA) of genera between groups were performed using Kruskal Wallis tests. Multiple linear regression was used to investigate the impact of time point of exam and antibiotic treatment, in the month prior to examination, on RA of genera.\n\nIn total, 50 swabs (1:1 case to control) were collected. Two swabs were lost during transport, therefore, 48 swabs (cases = 23, controls = 25) obtained from 44 calves, were used for analysis. Thirty-five (73%) swabs were collected during the late exam. Overall, the most common genera were Acinetobacter sp, Escherichia sp, Mycoplasma sp, Pasteurella sp and Psychrobacter sp. Alpha diversity was not different between cases and controls (P = 0.78), nor between early and late time points (P = 0.37). The RA of Mycoplasma sp. was higher in controls (P = 0.03) and the RA of Pasteurella sp. tended to be higher in controls (P = 0.08). The RA of both Mycoplasma sp. and Pasteurella sp. was not affected by exam time point or antibiotic treatment (P > 0.75 and P > 0.12, respectively).\n\nTo the authors'; knowledge, this is the first study to evaluate the community dynamics of the NP microbiota from calves with and without ultrasonographic lung lesions. We did not expect to identify a higher RA of Mycoplasma sp. in the control calves, as previous studies have shown a higher RA of Mycoplasma sp. in calves with BRD compared to healthy calves. Future studies are needed to better understand this discrepancy, including metagenomics studies to infer speciation and determine pathogenicity of the identified Mycoplasma genus. It would also be important to know if the duration of ultrasound lesions affected the RA of pathogenic bacteria. This study helps to demonstrate the complexities of identifying NP microbiota changes associated with disease status. This may impact future attempts to utilize NP microbiota characteristics in diagnosis and treatment of BRD. A diagnostic test evaluation was performed. Fecal samples were collected per rectum from calves less than 6 months of age (n=119). The study population was stratified on disease status -healthy or scouring.\n\nTwo-grams of each sample were fixed and tested via a commercially available rapid test marketed for use in human healthcare, and IFA, the recognized gold standard testing method. Isolates were submitted for genetic typing. toxic changes (10/15), hypoglycemia (11/17; range: 0.3-10.9 mmol/ L), hyperkaliemia (9/18; range: 3.6-8.3 mmol/L), acidemia (6/13; range: 6.8-7.5) and neutropenia (5/15; range: 1.6-22.7 cellsx10 9 /L).\n\nBased on univariate statistical analysis, fatal outcome was significantly (p < 0.05) related to dehydration, recumbency, hypothermia, metabolic acidosis, hypoproteinemia, leucopenia and neutropenia.\n\nFatality rate was 60% (12/20). Necropsy was performed on 11 calves and confirmed the clinical diagnosis.\n\nAbomasitis has a guarded prognosis in calves. Clinical and clinicopathologic findings were shown to be associated with a fatal outcome.\n\nDiego Gomez-Nieto 1 , Laura Avellaneda-Franco 2 , Alejandro Reyes 2 , Luis Arroyo 3 , J. Scott Weese 4 1 University of Florida, Gainesville, FL, USA, 2 Department of Biological Sciences, Universidad de los Andes, Bogot\u00e1, Colombia., Bogota, Cundinamarca, Colombia, 3 Ontario Veterinary College, Guelph, ON, Canada, 4 Dept of Pathobiology Ontario Veterinary College University of Guelph, Guelph, ON, Canada\n\nThe concept of the existence of a \"gut virome\" is very recent although the presence of viruses as pathogens in calf intestine has been documented for more than 40 years. In contrast to the bacterial microbiota, little is known regarding the development, establishment and factors that modify the gut virome during the neonatal period. The objective of this study was to characterize the fecal virome of healthy and diarrheic neonatal dairy calves.\n\nTwenty diarrheic calves (DC) (ages of 1 to 30 days) and 20 agematched healthy control calves (HC) were enrolled. Viral nucleic extraction was performed using a commercial Kit. Synthesis of viral cDNA was completed using a primer containing a fixed 18bp plus a random nonamer. Twenty samples from HC were mixed in equimolar quantities in 4 sets as well as 20 DC samples. The 8 total pooled samples were sequenced using MiSeq-lllumina-Platform. Raw sequences quality was assessed using FastQC. Then, low-quality reads were removed with Trimmomatic. CD-HIT-EST was used to cluster reads with >90% sequence identity. The five more representative sequences of each cluster were used to perform a de novo assembly using SPADES. LefSe was used to obtain molecular markers, which can be used in diagnosis.\n\nCaudovirales viruses, mainly viruses belonged to Myoviridae family, were found in all pools. A total of 223 contigs that could be associated with neonatal calf diarrhea were identified but these had no available annotation with any database. Sequences belonging the Retroviridae family were found predominantly associated to all the DC. Escherichia phage was found in 3 of the 4 pools that composed the DC group. HC shared Enterobacteria phage phiX174 sensu lato, and the DC shared Blood was collected from 30 Alpine goat kids at 0-12 hours of age prior to receiving any colostrum, at 24-48 hours of age after receiving colostrum, and at 7-14 days of age. Serum was harvested and the protein measured using a digital Brix refractometer, an optical refractometer, and the Beckman colorimetric method at a commercial laboratory. Linear regression and correlation coefficient analysis was performed for all two-way results: Brix x optical, Brix x laboratory colorimetric, and optical x laboratory colorimetric.\n\nThere was significant relationship between the three serum protein analysis methods with a high degree of positive correlation between the digital Brix and optical refractometer (P < 0.0001; r = 0.87), and a moderate positive correlation between the laboratory colorimetric measurements and the digital Brix (P < 0.0001; r = 0.50) and optical refractometer (P < 0.0001; r = 0.62). Regression analysis showed a digital Brix percentage of 8.4% could be used to predict a serum pro- Survival rate of downer cows treated on farm or in a hospital setting is estimated between 11.3% and 50%. Identifying prognostic indicators could be useful in reducing unnecessary treatments on animals with a poor prognosis.\n\nThe primary objective of this study was to predict prognosis associated with downer cows treated at a referral hospital. A secondary objective was to identify prognostic factors associated with the outcome.\n\nThis retrospective study included all recumbent dairy cattle older than 15 months that were presented between 1994 and 2016 (n=1472 cases). Information regarding history (age, lactation status, duration of recumbency), hospitalization (outcome, duration, number of days of flotation therapy, diagnosis) and blood analysis results (CBC, biochemistry) were obtained. A multivariable logistic regression model was built to explore the association between hematology and biochemistry parameters and survival.\n\nOverall survival rate was 50.1%. Cows that survived were significantly younger and were recumbent for a shorter period of time. They had lower fibrinogen values and higher neutrophils counts at arrival than cows that did not survive. Finally, cows that survived had significantly lower values of AST, CK, BUN, creatinine, and phosphorus and higher total CO 2 value at arrival than cows that did not survive. An increase in fibrinogen, AST, and creatinine values were significantly associated with lower odds of survival.\n\nWe concluded that the overall survival rate of downer cows treated in-hospital with flotation therapy is approximatively 50%. Further, some historical elements, CBC and biochemistry values can be used to select cases with a better chance of survival.\n\nEvelyn MacKay Texas A&M University, College Station, TX, USA\n\nMacrolides are important antimicrobials that may be useful agents for the control of infectious ovine abortion, which has economic, animal health, and human health impacts. Pregnant ewes were given a single dose of 2.5mg/kg tulathromycin subcutaneously and drug concentrations were measured in fetal plasma, maternal plasma, and amniotic fluid. Catheters were surgically placed in the fetal vasculature and the amnion at 115 (+ / -2 ) days gestation for sampling at 4, 8, 12, 24, 36, 48, 72, 144 , and 288 hours after administration. Maternal plasma samples were collected at time points of 0, 2, 4, 6, 8, 12, 24, 36, 48, 72, 144 , and 288 hours. Serum concentrations and pharmacokinetic values in the ewe were similar to those previously reported in non-pregnant ewes. Tulathromycin was present in fetal plasma and amniotic fluid, indicating therapeutic potential for use against organisms in these compartments, though concentrations were lower than those found in maternal plasma. Notably, the pharmacokinetics in the fetus were quite different than those found in the ewe, with plasma concentrations reaching a plateau at 4 hours and remaining at this concentration for the remainder of the sampling period (288 hours), raising questions about how this drug is handled and metabolized in the fetus. pre-weaned dairy calves, suggesting potential as a preventative strategy against respiratory disease. The objective of this study was to evaluate the effect of orally administered NaI on BRD treatment frequency and weaning weights of pre-weaned dairy calves.\n\n427 female pre-weaned dairy calves, aged 18 (\u00b12) days and housed in individual hutches on a ranch in central California, were used for this study.\n\nThe calves were divided into treatment (20mg/kg NaI orally on day 0 and day 4) and control groups (no treatment). A subset of calves of both groups (70 treatment calves and 70 control calves) were given respiratory and ultrasound scores on day 0 (baseline) and day 7. Medical treatments were recorded for the entire study period and all calves were weighed at weaning.\n\nUltrasound scores, change in ultrasound scores from baseline and respiratory scores of treatment calves on day 7 were significantly higher (P=0.001, P=0.0127 and P=0.0243, respectively) than those of control calves. In addition to having higher respiratory and ultrasound scores, treatment calves had higher odds of being treated for respiratory disease (OR 2.04, P=0.0003) than controls. Despite these apparent increases in respiratory disease in the treatment group, average daily gain and weaning weights did not differ between groups.\n\nThe findings of this study do not support the use of oral NaI as a preventative strategy against respiratory disease in pre-weaned dairy calves. can be curative. Non-resectable lesions are very difficult to manage and treatment modalities for such cases (radiation therapy and photodynamic therapy) are limited to tertiary referral hospitals. Recently, an immunomodulating drug has been approved for mixed mammary carcinoma in dogs and cats and sarcoids for horses via intralesional injection. The product (Immunocidin\u00a9) is a mycobacterial cell wall extract with immunomodulating effects. It works as a non-specific immunotherapy activating natural killer cells, monocytes and macrophages.\n\nThis report describes the use of Immunocidin\u00a9 in two mature bovines with non-resectable OSCC. These animals were considered companion animals and the clients agreed they would not enter the food chain. A 3-year-old bucking bull was examined for a rapidly growing mass of the lower lid and medial canthus of two-weeks duration. An extirpation was performed under local blocks and sedation. Reoccurrence was noted at suture removal and the mass was debulked with cryotherapy applied. Aggressive reoccurrence occurred within two weeks. A total of four intralesional injections of Immunocidin\u00a9 were administered at about two week intervals. After 9 months of therapy, the bull has regression of OSCC. The bull continues to do well with no reoccurrence at this time, 13 months after the first appointment. A 12-year-old Longhorn cow was examined for an extensive ocular and periocular mass of several months duration. An extirpation and regional debulking was performed under general anesthesia; intralesional injection of Immunocidin\u00a9 was performed at initial surgery and twice more at 3 week intervals. Initial results were promising, however the owner reported that the Longhorn';s health regressed; she was having difficulty chewing, hearing, developed a head tilt and could not see from her remaining eye. There was no external growth from the surgical site. She was found dead in pasture one morning, three months after the initial surgery. This is a limited case series with the hopes of utilizing Immunocidin\u00a9 in more OSCC cases to further our understanding of treatment with this agent. This may be an appropriate alternative treatment for economically or emotionally valuable animals that will not be consumed. tests following uterus lavage.We hypothesised that influx of functional PMNLs in uterus can be achieved by different MCWF concentrations in dose-dependent manner following IU administration. It is anticipated that increased presence of active PMNLs would have beneficial effect on the reproductive performance in dairy cows by reducing the incidence of clinical and subclinical endometritis at the end of histological puerpuerium thus improving conception rate.\n\nStudy was conducted on commercial dairy operation with 1200 milking Holstein cows. Experimental study protocol was reviewed and approved by institutional Animal Care Committee prior to the study start. Forty lactating cows in average 45.8 days postpartum were selected for the study purposes. Inclusion criteria included history of easy calving, no retained placenta, absence of signs of clinical endometritis and average body condition score of 3 (1 to 5 scale). Prior to MCWF treatment, baseline status of uterine lining was determined by cytology examination. Stained slides were evaluated under microscope to determine the percentage of PMNL's per 300 cells. Following cytology assessment, cows were randomly assigned in four experimental groups with 10 cows per group. On day 0, cows in control group were treated IU with 0.33g of oysterglycogen (proven PMNL attractant), dissolved in 60 ml 0.9%NaCl while animals in MCWF groups received IU dose of either 2.5ml, 5ml or 10ml MCWF diluted in 0.9% NaCl to a total volume of 60ml. Twenty-four hours later, uterine cytology sample from same spot (corpus uteri) was taken and subjected to new cytomorphology analysis and PMNL counts.\n\nIn addition, uterine lavage samples were obtained immediately after second cytology sampling. PMNL activity was analyzed by Flow-Auto- None of the cows had elevated PMNL counts prior to the treatment as determined by cytology. At 24h post treatment PMNL counts in all groups were elevated, however, and statistically significant differences were noted only in groups receiving 5 and 10 ml of MCWF (p < 0.0012 and p < 0.0048 respectively). Even though there were no statistically significant differences observed in control and 2.5ml MCWF groups there was a trend in PMN increase with 54% and 14% increase respectively (p < 0.052 and p < 0.16) compared to day 0. FACS analysis on ROS activity revealed similar ROS % for all experimental groups (39.7, 37.6, 40.6 and 38.9% for control, 2.5,5 and 10ml MCWF groups, respectively). Calculated OBI demonstrated that cows receiving 5 and 10ml of MCWF had the highest reaction (OBI=779.7 and 812.02 respectively) compared to control (OBI=578.8) and 2.5ml MCWF (OBI=221.9). Data on reproductive performance showed that 9/10 cows in 2.5 and 5ml MCWF groups and 7/10 cows in 10ml A hypothetical population of cows was generated using a Monte Carlo simulation, and the milk discard time determined from the simulated population. The result of this method was compared to the safe-concentration-by-linear-regression, safe-concentration-per-milking, and timeuntil-safe-concentration methods recommended by regulatory agencies.\n\nComparable milk discard times were generated from all methods, which suggested a longer milk discard time is necessary for this cohort of cows with mastitis. The prediction of the population method was sensitive to the range of milk production volume selected for the simulation. This novel method utilized all available data, including data below the assay quantification limit. The study demonstrated the viability of a population physiologically-based model for estimation of milk discard times. Augmenting innate mucosal defense mechanisms with iodine is effective at killing bovine bacterial and viral respiratory pathogens in vitro and could be a valuable preventative strategy against respiratory disease in dairy calves. The objective of this study was to determine the kinetics of iodine in nasal secretions following oral administration of 20mg/kg inorganic iodine (NaI), in order to assess the feasibility of using NaI to prevent bovine respiratory disease in vivo.\n\n7 female pre-weaned Holstein calves aged 3-5 weeks and housed in Davis, CA, were used for this prospective clinical study.\n\nCalves consumed 20mg/kg of NaI, which was added to their milk once, after baseline samples (blood and nasal secretions) were collected (T=0). Consecutive samples were then obtained at 1, 3, 6, 12, 48 and 72 hours post-administration. Samples were submitted to a diagnostic lab for analysis of iodine concentration via mass spectrometry.\n\nIodine concentrations were significantly elevated over baseline levels in nasal secretions (P = 0.0017) and serum (P < 0.0001) at all time points sampled. Both serum and nasal fluid iodine concentrations peaked at 6 hours, with a serum mean concentration of 17,188ng/ml and a nasal fluid mean concentration of 56,383ng/ml. No adverse effects were noticed in any of the calves.\n\nThis study shows that oral administration of NaI increases iodine concentrations in airway fluids of pre-weaned dairy calves, to above effective concentrations in vitro, and could augment upper respiratory defense mechanisms. Further studies are needed to determine if sodium iodide is effective as a preventive strategy against respiratory disease in dairy calves. The objective of this retrospective study was to describe the signalment, history, clinicopathological, endoscopic, ultrasonographic, radiographic and post-mortem findings as well as treatments and outcomes of adult cattle diagnosed with pharyngeal laceration/trauma.Medical records of cattle > 1 month of age admitted to a Veterinary Teaching Hospital from January 1995 to January 2017 with pharyngeal perforation/trauma identified by oral or endoscopic examination were reviewed.\n\nTwenty-seven cases met the inclusion criteria. In all cases but one, the primary complaint was dysphagia and swelling of the pharyngeal area.\n\nTwelve (45%) cows had a history of being administered a bolus of monensin and 5 (20%) of calcium; 3 a magnet (11%); 1 (4%) iodine; 1 aspirin; and 1 (4%) vitamins; 3 (16%) unknown bolus. Reported clinical signs included subcutaneous emphysema in 23 (85%) cows, swelling of the throatlatch in 17 (63%), pain on palpation in 17 (63%), nasal discharge in 14 (52%), foul odour from the nose and mouth in 12 (44%), ptyalism in 12 (44%), dyspnea in 15 (56%) and an upper respiratory noise in 12 (44%). Oral examination findings were reported in 22 (81%) cows. A foreign body (FB) (monensin bolus) lodged in the pharynx was observed in 5 (20%) cows while pharyngeal laceration without FB was reported in 12 (44%) cows. Endoscopic examination was performed in 21 (78%) cows. A FB lodged in the pharynx was observed in 2 cows and in 12 cows the perforation was identified in the dorsal aspect of the pharynx. Radiographs of the neck and throatlatch were performed in 21 (78%) cows and a FB was detected in 8 cows (rumensin bolus, n=6; magnet, n=2). The presence of gas, either subcutaneously or between fascial planes, emphysema of the pharyngeal region (n=20), soft tissue swelling (n=17) and pneumomediastinum (n=16) were commonly reported. Treatment was attempted in 24 cows. Manual retrieval of the monensin bolus lodged in the pharynx was possible in 5 cows in which the FB was observed during oral exam. Surgical removal of FB was carried out in 4 cows. In 2 cows a monensin bolus was retrieved and a magnet in the other 2 cows. A combination of antimicrobial agents and analgesic anti-inflammatory drugs were administered to all 24 treated cows. Seventeen (63%) cows were discharged from the hospital whereas 10 (37%) were euthanized. Eight (46%) out of 17 surviving cows had pharyngeal trauma associated with monensin, 1 (6%) with an iodine bolus, 3 (18%) with a magnet, 1 (6%) with a vitamin bolus, and 4 (24%) with an unknown bolus. All 5 cows that suffered pharyngeal trauma associated with administration of a calcium bolus were euthanized due to the severity of the clinical signs.\n\nPharyngeal trauma is a rare condition in adult cattle which can cause serious morbidity and mortality if not diagnosed and treated early.\n\nSuccessful treatment appears to be related with the nature of the penetrating FB.\n\nSusan Arnold 1 , Simon Platt 2 , Georgina Stewart 2 , Marc Kent 2 , Renee Barber 2 1 University of Georgia, Athens, GA, USA, 2 University of Georgia Veterinary Teaching Hospital, Athens, GA, USA Primary intraparenchymal brain tumors, including astrocytomas, glioblastomas, and oligodendrogliomas, collectively comprise approximately 35% of all primary brain tumors in dogs. The prognosis for dogs with any of these tumor types is generally guarded to poor. The median survival time regardless of treatment type is approximately 230 days. Due to numerous challenges associated with diagnosing, grading, treating, and reporting survival outcomes, there is currently no gold standard therapy for these tumors in dogs. Additionally, the similarities between canine and human primary intraparenchymal brain tumors lend translational opportunity to the development of novel treatment delivery systems for canine brain tumors. Glial tumors invade and migrate along white matter tracts and blood vessels, which is a characteristic that can be exploited. Catheters lined with nanofiber particles have been developed to structurally mimic these conduits.\n\nThe conformation guides tumor cells away from the tumor site to an extracranial reservoir. In this study we describe the techniques associated with stereotactically-guided implantation of nanofiber-lined catheters in dogs with naturally occurring and histopathologically confirmed astrocytomas and oligodendrogliomas. The purpose of this study was to evaluate the safety and feasibility of stereotactically- Although this study is small and cannot prove treatment efficacy, these findings support our hypotheses that stereotactic guidance of nanofiber catheters is safe, feasible, and encourages tumor cell migration out of the cranial cavity. This is the first stage in a large clinical trial that ultimately aims to evaluate the safety and efficacy of nanofiber catheters in the treatment of canine brain tumors. Repetitive transcranial magnetic stimulation (rTMS) is a non-invasive, safe and painless procedure that is applied in humans to modify the activity of specific neural circuits of the brain. Via electromagnetic induction, a magnetic field generator produces small electric currents on cortical neurons in order to affect neuronal function. The antiepileptic effect of rTMS has been demonstrated in humans with drug-resistant epilepsy. Therefore, a single-blinded randomized placebo-controlled clinical trial was designed to assess the efficacy and safety of rTMS in dogs with drug-resistant idiopathic epilepsy.\n\nAfter random assignment into the treatment or placebo group, dogs received active or sham stimulation, respectively. All dogs in both groups were sedated during the whole procedure using the same anesthetic protocol. Both groups received repetitive active or sham stimulation for 90 minutes per day for five consecutive days in total.\n\nThe efficacy of the procedure was evaluated by comparing monthly seizure frequency (MSF) and monthly seizure day frequency (MSDF) during a retrospective 3-month period with a prospective 3-month follow-up period. Three months after sham stimulation, the dogs in the placebo group also received treatment. Adverse effects and complications were reported.\n\nUntil this stage, five dogs were included, four in the treatment and one in the placebo group. In the treatment group, both median MSF and MSDF decreased (P = 0.1 and P = 0.059, respectively) showing a statistical trend of potential interest. In the placebo group, the limited sample size (n = 1) does not permit statistics at the current stage.\n\nHowever, this dog did show no reduction in seizure frequency following sham stimulation, while the seizure frequency reduced by 94% when the dog received active stimulation afterwards. Overall, the procedure seems safe as no significant or serious adverse effects or complications were reported.\n\nIn conclusion, these preliminary results suggest that rTMS is a safe procedure that might decrease median MSF and MSDF and result in an improvement in seizure management in dogs with drug-resistant epilepsy. However, a larger number of dogs is required for both groups before definitive conclusions can be made. Using a non-randomized cross-over design, nine clinically healthy cats received a single dose of 500 mg of approved ER-LEV PO. Thirteen blood and 1-2 CSF samples were collected over 24 hours. After a one-week washout period, the study was repeated with a single oral dose of 500 mg compounded ER-LEV. LEV was quantitated by immunoassay. Plasma and pooled CSF LEV concentrations versus time data were subjected to noncompartmental pharmacokinetic analysis and data were compared between formulations using a paired t-test.\n\nRegardless of formulation, CSF LEV closely mimicked plasma concentrations. Significant differences (P < 0.05) between formulations were limited to plasma Cmax (ug/mL) (approved 126 +/-33; compounded 169 +/-51) and tmax (approved 5.1 +/-1.6; compounded 3.1 +/-1.5).\n\nWith a half-life of 12.6 +/-1.6 hours and 12.7 +/-2.0 for approved and compounded, respectively, both formulations maintained concentrations above the human therapeutic reference interval for at least 12 hours.\n\nThis study demonstrates that both approved and compounded ER-LEV maintains human therapeutic LEV concentrations in healthy cats 12 hours after oral administration, supporting 12-hour dosing intervals. This study also demonstrates that plasma LEV monitoring can be used as an accurate representation of CSF LEV concentrations in cats. printed spinal models to ex-vivo spines and computed tomographic (CT) images with the eventual goal of replacing cadaver spines. We hypothesized that the spatial accuracy of 3D printed stereolithographic models of the canine thoracolumbar vertebral column would not differ from cadaveric bones.\n\nThoracolumbar vertebral columns were harvested from 3 adult canine cadavers. CT scans were acquired and rendered as 3-D surface models. Stereolithograph models were generated and printed by a stereolithography printer with clear methacrylate photoactivated resin. Cadaveric specimens were prepared by heated soft tissue maceration. Uniform measurements were acquired from T12 through L4 from the cadaver spines, CT images, and models. Neurological examinations were performed prior to the study and daily after surgery. A standard brain MRI with intravenous gadolinium contrast agent was performed immediately, 7 days and 30 days following surgery, after which the dogs were humanely euthanized for histopathological analysis of the brains. The presence of intratumoral chlorambucil indicated an altered blood brain barrier that varied from case to case. Despite sporadic previous reports of neurotoxicity, prolonged seizure-free intervals supported a high safety margin at this dose in this species. Metronomic chlorambucil was well tolerated. Ventriculoperitoneal shunt obstruction is a major complication in canine and human hydrocephalus, however obstruction typically occurs in the chronic setting. In order to develop a self-clearing ventricular catheter, a hydrocephalus model prone to early shunt obstruction would be beneficial. Autologous blood was injected into the right lateral ventricle of 32.3 \u00b1 5.2 kg, male, 6 month old pigs during terminal (n=3) and survival (n=14) procedures. Median intraventricular intracranial pressures were 9 mmHg (baseline), 66 mmHg (peak) and 20 mmHg (6 minutes post-blood injection).\n\n14.4 ml of blood caused profound hypertensive hydrocephalus in the terminal procedures but the first survival pig could not be recovered from anesthesia. Using 10 ml of blood, hypertensive hydrocephalus occurred in 12 of 13 pigs. In one pig, the subarachnoid space was inadvertently injected and hydrocephalus did not Fenbendazole produces these effects at a mean inhibitory concentration (IC 50 ) of 150 ng/ml, which might be an initial target for therapeutic CSF concentrations. Our study aimed to describe the time course of fenbendazole in plasma and CSF after oral administration to dogs. Doses were designed to target a CSF concentration approaching 150 ng/ml. Fenbendazole was detected in canine plasma and CSF using high performance liquid chromatography; the limit of detection was 10 ng/ml and 5 ng/ml, respectively.\n\nFenbendazole administered to two dogs at 50 mg/kg was not detectable. Dogs were subsequently treated with 100 mg/kg (n = 4) and then 200 mg/kg (n = 2 due to adverse effect), resulting in an average peak plasma concentration (ng/ml) of 131. 5 The aim of the study was to determine the precision of the novel MRI-based patient-individual stereotactic brain biopsy device in dogs.\n\nTwenty-two canine cadavers with 2 target points each were used to determine accuracy. First, specific bone anchors and MRI-markers were secured to canine cadaver heads. Afterwards CT and MRI examinations of the heads were performed. Two target points and corresponding trajectories were defined on each MRI: left caudate nucleus and right piriform lobe. Based on MR-images, patient-individual frames including rigid needle placement ports to reach defined target points were constructed and printed with a 3D-printer. The needle was to enter the brain in a gyrus and not to penetrate the ventricles.\n\nThe frames were secured to the bone anchors. Minimal-invasive access to the brain was created using a tool guide. The biopsy needle was placed through the needle placement port up to the predetermined depth. Afterwards CT examinations of the heads with biopsy needles placed in each target point were performed. Needle placement error was determined after fusion of MRI and CT examinations.\n\nError was defined as deviation in mm between needle tip and anticipated target points.\n\nThe total median needle placement error for all 42 target points was 0.84 mm (range: 0.09-2.76; outlier: 4.11). The median needle placement error for the caudate nucleus only was 0.67 mm (range: 0.09-1.25) and for the piriform lobe 0.85 mm (range: 0.14-2.76). Therefore, the MRI-based patient-individual stereotactic brain biopsy device reaches higher accuracy than most other described brain biopsy systems. In SM dogs, the distance between the rostral end of the palate and i) sella turcica (P = 0.049) ii) foramen magnum basioccipital (P = 0.030) were significantly reduced, as was the maximum distance through the palate centroid (P = 0.015). However, the reduced distance between the brain and frontal bone was highly significant (P < 0.001). The reduction in distance between the olfactory bulb and the sella turcica may be of interest (P = 0.054). Discriminate analysis/logistic regression revealed that rostral skull flattening dominated any model but when removed, ratio of maximum distance through the palate centroid to cerebral height to cerebrum height was highly significant (P < 0.001).\n\nThe characteristics of CKCS with SM include osseous insufficiency in the skull and changes in the shape of the soft palate which were implicated by machine learning technology. On the other hand, the activity of desaturase (delta-5 desaturase and delta-6 desaturase), which metabolizes EPA and DHA from precursors, has been reported to be lower in Japanese than in Westerners, possibly due to dietary culture as Japanese have historically ingested EPA and DHA directly from seafood. We hypothesized that Japanese dogs share historically similar diets with Japanese and may have a lower desaturase activity compared with Western dogs. The aim of this pilot study was to investigate the composition of FAs in the erythrocyte membrane and plasma, and to evaluate desaturase activity in Japanese dogs and non-Asian dogs.\n\nProspective study. Twenty-five Shiba dogs without CCD and 57 non-Asian dogs without CCD were used. The FAs (omega-3 PUFA, omega-6 PUFA, monounsaturated PUFA, and saturated PUFA) composition of the erythrocyte membrane and plasma were measured from blood samples using gas chromatography. The difference between Shiba dogs and non-Asian dogs was evaluated using the Wilcoxson rank-sum test.\n\nShiba dogs had a significantly lower composition (%) of EPA (median: These findings might suggest that Shiba dogs have lower desaturase activity than non-Asian dogs. The high incidence of CCD in Shiba dogs may be associated with the low composition of omega-3 FAs in erythrocyte membrane. Studies on FAs using dogs with a unified diet are required to clarify the metabolic difference between Japanese dogs and non-Asian dogs, and to elucidate the association between FAs and CCD. Radiography is valuable, however published toy breed-specific radiographic measurements are lacking and diagnosis remains largely subjective. The purpose of this study was to establish objective radiographic criteria for the diagnosis of AA instability in toy breed dogs. Neutral lateral and ventrodorsal radiographs of 102 toy breed dogs (92 control, 10 affected) were retrospectively reviewed. The median C1-C2 overlap (the distance of overlap between the C2 spinous process and the dorsal arch of C1) was +4.65 mm in control dogs and -5.00 mm in AA cases. A C1-C2 overlap \u2264 +1.55 mm was the most sensitive (100%) and specific (94.5%) radiographic measurement in the diagnosis of AA instability. We performed three relative measurements: the atlantodental interval to dorsal atlantodental interval ratio (ADI/DADI ratio), the relative dens length and the C1-C2 angle.\n\nThese three relative measurements had good specificity (94.5%, 86.9%, 98.9% respectively), lower sensitivity (80.0%, 66.7%, 60.0%) and were not influenced by body weight (p > 0.05). Absolute measurements (e.g. absolute dens length, atlantoaxial distance) were significantly correlated with body weight (p < 0.05) and their utility in the diagnosis of AA instability could not be established. Decreased C1-C2 overlap strongly supports AA instability. The ADI/DADI ratio, relative dens length and C1-C2 angle may provide further support but may be normal in individual cases. mean pre trial seizure frequency for both groups was calculatedgroup 1: 1 seizure every 9 days; group 2: 1 seizure every 7 days. The overall mean post trial seizure frequency for both groups was decreased. Group 1: 1 seizure every 16 days; group 2: 1 seizure every 9 days. Side effects were limited, with 1 dog experiencing an increase in seizure frequency and 1 dog displaying negative aversive behavior when the device was applied.\n\nIn conclusion, this treatment modality represents a possible additional treatment for refractory epileptic dogs that is non-invasive and has limited side effects. Traditionally, cervical spondylomyelopathy (CSM) has been classified into disc-or osseous-associated forms. However, there are dogs that suffer from both forms, and this has not been thoroughly evaluated. Our goal was to report the MRI findings associated with single or multi-level osseous, disc and ligamentous compressions in dogs diagnosed with CSM.\n\nWe retrospectively reviewed 180 magnetic resonance imaging (MRI) cases previously diagnosed with CSM. Inclusion criteria were diagnosis of CSM using MRI and presence of compression in two or more directions. Location of compressive lesions, most severe compressive lesion, direction of the compression (dorsal, ventral, lateral, and combined) , and presence of spinal cord hyperintensity were recorded.\n\nForty-five dogs (25%) met the inclusion criteria: 32 were large-breed (21 Dobermans) and 13, giant-breed (7 Great Danes). The majority was older than 6 years of age (36/45), with 29 (64%) being males.\n\nForty two (93%) dogs had dorsal and ventral spinal cord compression in the same level; of these, 27 (64%) also had spinal cord compression at one or more other sites. Seven dogs (15%) had circumferential spinal cord compression. The most severe compressive lesion was at C6-7 or C5-6. Spinal cord hyperintensity on T2-W images was present in 35 (77%) dogs.\n\nOur findings indicate that a sizeable portion of CSM-affected dogs suffer from combined compressions. It is important to routinely and carefully evaluate all cervical levels to make sure these are not overlooked, as the high proportion of spinal cord hyperintensity may suggest they represent a more severe form of the disease. Formalin-fixed, paraffin-embedded sections from 5 GME and 3 NME (total 8 dogs) samples were used in this study. Staining for PDGFR-\u03b1, PDGFR-\u00df, VEGFR-2, c-Abl, and c-Kit was carried out using standard immunohistochemical procedures developed for use in formalin fixed tissues. Immunohistochemical evaluation assessed staining positivity of each TKs and staining intensity and distribution of TK positive cells.\n\nOverall staining intensity was graded as no immunostaining, weak immunostaining, moderate and intense immunostaining at \u00d740 magnification. Distribution of positively staining cells (% cells affected) was evaluated in five separate fields at \u00d7200 magnification and was graded as follows: 0%, 1-9%, 10-50%, 51-100%.\n\nAll samples stained positive for PDGFR-\u00df (8/8 [100%]) with the majority of samples exhibiting relatively intense staining and broad distribution. A large number of the samples also had weak to moderate staining for PDGFR-\u03b1 (4/8 [50%] ) and c-Kit (4/8 [50%] ) with various distribution. c-Abl was identified in 3/8 (37.5%) with relatively moderate staining intensity and distribution. Only 1/8 sample showed a weak and restricted VEGFR-2 (12.5%).\n\nThere was no statistically significant association between GME and NE samples in terms of TK expression (P > 0.05 for all).\n\nKnown targets of conventional multitargeted TKIs are expressed in canine GME and NME of this study. These TKs could be involved in key aspects of the pathogenesis of autoimmune encephalitis and especially PDGFR-\u00df may have important role in biologic activity of the disease.\n\nBased on this proof, the targeted therapy for the over-expressed TKs may have potential as new treatment modality of GME and NME.\n\nAustin Kerns 1 , Nina Kieves 1 , Laurie Cook 2 , Sarah Moore 1 1 Ohio State University, Columbus, OH, USA, 2 Ohio State University, columbus, OH, USA Electronic von Frey anesthesiometry (VFA) has been previously reported by our laboratory and others as a useful method of mechanical quantitative sensory testing (QST) for evaluating neuropathic pain in dogs. Intraobserver agreement has been previously shown to be good to excellent; however, interobserver agreement has not been previously reported and is vital to the use of this technique in multicenter veterinary clinical trials in neuropathic pain. The goal of this study was to evaluate the interobserver agreement of sensory thresholds obtained using electronic VFA in a group of normal small breed dogs. No statistical difference between MTR and FA was noted between groups. AD and MD were significantly lower in dogs that did not recover. Findings support that quantitative imaging surrogates of axonal integrity may be important prognostic indicators in dogs with SCI. Despite studies demonstrating that lower doses of toceranib (2.4 -2.9 mg/kg every other day) provides drug exposure sufficient for target inhibition while reducing the frequency of drug-related adverse events, gastrointestinal (GI) toxicity continues to be the most commonly encountered side effect in dogs receiving toceranib at this dose. The degree of toxicity is variable among individual dogs and currently there are no clinical or molecular markers to identify those dogs that would benefit from the use of concomitant medications to prevent GI toxicities. This is critical as the development of GI toxicity significantly impacts patient morbidity and quality of life, decreases treatment intensity, increases the cost of treatment, and leads to discontinuation of therapy. The University of Tokyo, Bunkyo-ku, Tokyo, Japan, 2 Anicom Specialty Medical Institute Inc., Shinjuku-ku, Tokyo, Japan, 3 The University of Tokyo, Tokyo, Tokyo, Japan\n\nGene mutations in various canine tumors have been explored. In canine histiocytic sarcoma (HS), the mutations of TP53 and PTPN11 genes have been reported to be frequently observed. However, there has been no report on the comprehensive analysis of gene mutations in canine HS. The objective of this study was to conduct the comprehensive analysis of mutations of protein coding genes in dogs with HS by whole exome sequencing.\n\nGenomic DNA was extracted from the tumor tissues of three dogs that were histologically diagnosed with HS. For the analysis of germline DNA sequences, genomic DNA was also extracted from normal tissues or peripheral blood of these dogs. Whole exome sequencing was performed using Illumina NextSeq 500. The alignment of processed reads to the canine reference genome (CanFam 3.1) was carried out using Genome Analysis Toolkit. VarScan was used for calling of the somatic variants in each dog and SnpEff was used for the annotations of the variants. The extracted somatic variants were filtered by the read depth and the putative impact for the gene functions. The variants in the genes known to be associated with the pathogenesis of human tumors were validated using Sanger sequencing.\n\nWhole exome sequencing generated the mean read depth of 630\u00d7, and 99.2 % of the unique reads could be mapped to the canine reference genome on average. After the analysis of the data, 11 variants in 11 genes, 17 variants in 16 genes, and 14 variants in 13 genes were extracted as the somatic mutations in Dogs 1, 2, and 3, respectively.\n\nOf these variants, the mutations of TP53 (Dog 1), PDGFRB and N4BP2 (Dog 2), and SH3KBP1 (Dog 3) were confirmed by Sanger sequencing.\n\nThis study revealed somatic mutations of TP53, PDGFRB, N4BP2, and SH3KBP1 genes in canine HS. We previously reported the high incidence of TP53 gene mutations in canine HS. N4BP2 was reported to interact with BCL3, a target of PI3K/Akt and MAPK/ERK pathways, and SH3KBP1 was shown to induce down-regulation of protein tyrosine kinase that activates PI3K/Akt and MAPK/ERK pathways (Fig. 1) .\n\nAlthough further studies are needed to know the frequencies of the gene mutations, findings obtained in the present study will lead to the introduction of molecular targeted therapy directed to PI3K/Akt, MAPK/ERK, and p53 pathways in canine HS. and age-and breed-matched (in dogs) and age-matched (in cats) to cases. SDMA and creatinine concentrations were compared between cases and controls by cancer type. SDMA concentrations were significantly higher in dogs and cats with lymphoma (P < 0.0001) and significantly lower in dogs with lipoma, mammary adenocarcinoma and mammary carcinoma (P \u2264 0.003) as compared to controls. Creatinine concentrations were significantly lower in dogs with mammary adenocarcinoma and mammary carcinoma and in cats with lymphoma (p\u22640.0008) when compared to controls. Odds ratios (OR) and 95% confidence intervals (CI) were calculated to determine the association between SDMA and tumor type ( Table 1 ). The results indicate that in both cats and dogs, cases of lymphoma are associated with increased SDMA concentrations with a large portion of these cases having concurrent creatinine concentrations within the reference interval.\n\nAlthough the etiology of increased SDMA concentrations in these cases was not determined, SDMA may be an early marker of renal involvement and reduced GFR in recently diagnosed cases of lymphoma. To assess the impact of probiotic treatment on the prevalence and severity of CID, a randomised, double-blinded, placebo-controlled, crossover trial was performed in dogs with cancer scheduled to receive doxorubicin. Dogs received treatment for 14 days, starting on the day of doxorubicin administration, with either a probiotic formulation containing Enterococcus faecium NCIMB 10415 (2 x 10 9 CFU) or a placebo. A CID assessment form was developed for daily completion by the owner for five days, starting four days after treatment with doxorubicin, and a score was calculated to describe the severity of the event. In addition, a quality of life (QoL) assessment form was developed to assess the QoL of the dog during each treatment period. Faecal samples were collected before administration of doxorubicin and during and after treatment with the probiotic or the placebo. Faecal DNA was extracted and a quantitative polymerase chain reaction was developed to detect and quantify the presence of the specific probiotic strain.\n\nFifty dogs were recruited, 32 took both the probiotic formulation and the placebo, 11 took either product only, and seven dogs died of their cancer or were removed from the trial, leaving 43 cases for evaluation.\n\nFaecal consistency was described as abnormal in 80% of dogs in the probiotic group and 83% in the placebo group. Faecal frequency was increased in 51% of dogs in the probiotic group and 44% in the placebo group. There was no difference in the diarrhoea event scores whilst the dogs took either trial product (p > 0.05). In addition, there was no difference in QoL score between each trial period, but there was a significant correlation between QoL and diarrhoea score; QoL was considered to be worse when the diarrhoea was more severe (p < 0.0001). Also, there was a significant correlation between QoL and tumour type; dogs with lymphoma were described as having a significantly worse QoL compared to dogs with sarcomas or carcinomas to the unique nature of the nanoparticle design they vibrate when exposed to the appropriate wavelength of light generating controlled and targeted heat. Our hypothesis is that heat generated with laser light induced nanoparticle vibration will cause cancer cell death, thereby provide definitive therapy in low grade mast cell tumors.\n\nEighteen with low grade mast cell tumors, < 1.5 cm, were randomized into either treatment or control groups. All dogs received Benadryl, 2 mg/kg/12 hours, and Pepcid AC, 0.5mg/kg/24 hours. On day one dogs received a 2 hour IV infusion of nanoparticles. On day two, the treatment group dogs had light therapy applied to the tumor using a diode laser -810 nm, 12W/cm 2 . Dogs were evaluated once a week for four weeks and then monthly. Data collected included signalment, tumor size pre-infusion and pre-laser therapy application, response to therapy, duration of response, and any toxicities. At the endpoint, the mice were euthanized, and the tumors were collected. Histologically, necrotic areas in the tumor tissues were evaluated. Finally, immunohistochemistry of HER2 was performed using urinary bladder tissues of 23 dogs with TCC and 8 healthy dogs.\n\nIntensive staining localized to cell membrane was defined as HER2 protein overexpression. The aim of this study was to assess the toxicity and efficacy of a doxorubicin/ cytarabine (DC) combination protocol in dogs with acute myeloid leukemia (AML). A cohort of 6 dogs with persistent cytopenia, and bone marrow cytology and/or core biopsy diagnosis of AML were treated with same day doxorubicin at 30 mg/m 2 or 1 mg/kg IV over 20 minutes, followed by cytarabine at 300 mg/m 2 with constant rate IV infusion over 4 hours, every 14 days. Prednisone (2 mg/kg PO q24h) was also administered. Hematologic results, adverse effects and outcomes were assessed every 1-2 weeks during DC therapy.\n\nSix dogs were treated with the DC protocol over a period of two years. Median age was 9.4 years (range 1-10) with median weight of 17.4 kg (range 3.7-32.2 kg). Dogs presented with anemia (n=6) and leukopenia (n=2) or thrombocytopenia (n=2). Two dogs had circulating blast cells. Median number of treatment cycles was 6 (range 1-9).\n\nDose reduction was required in 2 dogs due to grade 4 neutropenia or grade 3 gastrointestinal adverse effects (GIAE). One dog developed dilated cardiomyopathy (DCM) after a cumulative doxorubicin dose of 180 mg/m 2 . Two dogs are still alive 305 and 799 days after diagnosis; one dog died due to DCM at 380 days while cytopenia was in remission, and three dogs died from progressive AML 13, 29 and 217 days after diagnosis, respectively. Improvement in cytopenia was noted in all but the two dogs that died within 30 days.\n\nThe DC protocol was overall well tolerated. Four of 6 dogs survived longer than 6 months. Further studies with larger sample size are warranted. The purpose of this study was to assess the role of Palladia in the treatment of inoperable, metastatic, or recurrent canine pheochromocytomas.\n\nRetrospectively, medical records of dogs that had a diagnosis of a pheochromocytoma and treatment with Palladia were reviewed for information regarding response to Palladia, observed side effects, and overall outcome. Five dogs were identified that fit the inclusion cri- It is incurable once infiltrated into bone and lung metastasis, and the traditional therapeutic approach is less effective. Tumor cells rely on glycolysis, rather than mitochondrial oxidative phosphorylation, for energy production even under oxygen-rich conditions, which is termed as \"Warburg effect\". Since Warburg effect is characteristic for tumor cells, glucose metabolism is considered to be a therapeutic target in this regard. In this study, we investigated the contribution of glucose transporters on the cell growth of canine melanoma.\n\nCanine melanoma cells (MCM-N1) were cultured in Dulbecco';s Modified Eagle';s medium containing 1 g/L glucose and 10% fetal bovine serum. Cell growth was measured by 3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyl tetrazolium bromide reduction assay. The cells proliferated for three days in a time-dependent manner. When treated with WZB-117, a pan-glucose transporter inhibitor, the cell growth was clearly attenuated. We observed, by RT-PCR, that mRNAs of glucose transporter subtypes GLUT1 and 3 were dominantly expressed in canine melanoma. The protein expression of GLUT1 and 3 was confirmed by Western blotting. We, then, investigated the contribution of GLUT subtypes on the cell growth by subtype-specific knockdown of GLUT1 and 3. When the cells were transfected with GLUT1 and 3 siRNAs, the cell growth was inhibited. We also observed that the expression of proliferation marker Ki67 was inhibited in GLUT3 knockdown cells, whereas the inhibition was less in GLUT1 knockdown cells, hence suggesting that GLUT3 dominantly contributes to cell growth in canine melanoma.\n\nIn conclusion, it is likely that glucose transporter is a promising therapeutic target for canine melanoma. plasma with and without Mg, data were analyzed using a paired t-test.\n\nSignificance was set at the P < 0.05 level.\n\nBlood samples from 15 dogs were included. Cortisol and T4 values were significantly different between plasma and serum samples (both without Mg). For cortisol and T4, concentrations measured in EDTA plasma were 34% and 45% higher than in serum samples, respectively (P < 0.001 for both). The addition of Mg to plasma significantly decreased the measured cortisol and T4 concentrations (P < 0.001 and P = 0.016, respectively). After addition of Mg, the cortisol concentrations measured in EDTA plasma were no longer significantly different from those measured in serum; however, for T4, the concentrations measured in EDTA plasma remained significantly different from serum.\n\nUse of EDTA plasma significantly increases the measured concentration of cortisol and T4 obtained by Immulite. Addition of Mg to plasma samples can overcome the effects of EDTA when measuring cortisol, but not T4. Thus, EDTA plasma can be used to maximize cortisol stability if Mg is added to the sample before assay via Immulite. Osmotic diuresis is considered the cause of polyuria in diabetes mellitus. However, people with a mutation in the renal sodium-glucose cotransporter 2, and diabetic patients treated with drugs that block this transporter (SGLT2i) have profound glycosuria without polyuria.\n\nThe purpose of this study was to determine if isolated renal glycosuria will induce polyuria in cats.\n\nThe study was approved by the University Animal Ethics Committee.\n\nThe study consisted of four, 5-day study periods separated by 7-day washout periods, in which eight healthy male cats were randomly allocated to control or treatment with 10mg of dapagliflozin (SGLT2i) once daily based on a previous pilot study. In each of the four 5-day study periods, we recorded daily food and water intake and urine output, and a urine aliquot was collected. Blood was obtained at the beginning and end of each study period. Data were analyzed with a linear mixed-effect model that included treatment and day-oftreatment as fixed effects, and cat as a random effect. Statistical significance was set at 0.05.\n\nDapagliflozin induced a 566-fold increase in urine glucose loss (41.0 \u00b1 12.6 mmol/d vs. 0.07 \u00b1 0.15 mmol/d). There were no differences in daily urinary excretion of sodium, potassium, and chloride between groups. Also, there were no differences in water intake (259 vs. 282 mL), body weight (4320 vs. 4321 g), and urine production (231 vs. 190 mL).\n\nThese results call in to question the generally accepted hypothesis that glycosuria-induced osmotic diuresis is the primary cause of polyuria in diabetes mellitus. Of note, in adulthood in both species, the expression of PAX4 has been shown to contribute to reprogramming of exocrine cells and \u03b1-cells into insulin-producing \u03b2-cells; induction of ARX expression in \u03b2-cells leads them to reprogramming into \u03b1-cells. We recently discovered that diabetic cats have an increased number of cells in the exocrine pancreas that stain positive for a marker of proliferation (proliferating cell nuclear antigen; PCNA), in particular nearby islets.\n\nBecause proliferation increases reprogramming efficiency in rodents, we hypothesized that these cells may anticipate reprogramming in cats. Aim of the study was to test if diabetic cats have an increased number of cells in the endocrine and exocrine pancreas expressing developmental markers of \u03b2and \u03b1-cells, suggesting reprogramming.\n\nIn 9 diabetic and 9 well-matched control cats, the pancreas was col- Toujeo\u00ae is more predictable and longer-acting compared to glargine 100 U/ml (Lantus\u00ae) in people. The duration of action of Tresiba\u00ae is over 40 hours which allows a flexible daily schedule of administration.\n\nWe hypothesized that Tresiba\u00ae would have longer duration of action compared to Toujeo\u00ae in healthy cats. Six healthy purpose-bred cats, each received 0.4 U/kg SQ injections of Tresiba\u00ae and Toujeo\u00ae on two different days, > 1 week apart. Blood glucose (BG) was measured every 5 min and glucose was administered intravenously at a variable rate with the goal of maintaining BG = 85 mg/dL (\"isoglycemic clamp\"). Glucose infusion rate was used as a measure of exogenous insulin action. The Shapiro-Wilk test was used to assess normality and normally distributed parameters were compared using paired t-tests.\n\nOnset of action (T OA ) was similar (79 \u00b1 27 min for Toujeo\u00ae, 60 \u00b1 21 min for Tresiba\u00ae, P = 0.3) but the end of action (T EA ) and duration of action (T DUR = T EA -T OA ) were longer for Toujeo\u00ae vs. Tresiba\u00ae (T DUR = 828 \u00b1 130 min vs. 620 \u00b1 148 min, respectively, P = 0.04; T EA = 907 \u00b1 135 min vs. 679 \u00b1 127 min, respectively, P = 0.03). There were no other significant differences between the two formulations.\n\nBased on these preliminary data, Toujeo\u00ae is longer-acting and therefore better suited than Tresiba\u00ae as a once-daily insulin formulation in cats.\n\nJean-S\u00e9bastien Palerme 1 , Laura R. Van Vertloo 2 1 Iowa State University College of Veterinary Medicine, Ames, IA, USA, 2 Iowa State University, Ames, IA, USA Renal proteinuria has been associated with both subclinical and clinical hypothyroidism in people; however, little is known about the effect of renal proteinuria on the thyroid status of companion animals.\n\nThe purpose of this study was to determine if thyroid status, assessed by total T4 (TT4), free T4 (fT4) and thyroid-stimulating hormone (TSH), differed between ill dogs that were proteinuric versus nonproteinuric.\n\nIll proteinuric dogs, defined by a urine protein/creatinine ratio (UPC) > 1 with negative urine culture, and ill non-proteinuric dogs were prospectively enrolled in this cross-sectional study. All dogs underwent physical examination, complete blood count, serum chemistry, urinalysis, and thyroid panel; urine from proteinuric dogs was submitted for culture and UPC. Descriptive statistics and student';s t-tests were used to determine differences between groups, with significance of p < 0.05.\n\nTwenty-two ill proteinuric dogs and 8 ill non-proteinuric dogs were enrolled in the study. Serum total protein concentrations were higher in non-proteinuric dogs (p =0.015), though albumin levels did not differ between groups (p = 0.06). Median UPC for proteinuric dogs was 5.1 (range 1.9 -16.5). Interestingly, proteinuric dogs had a significantly higher mean serum cholesterol than non-proteinuric dogs (p = 0.04). No significant difference in mean TT4 (p = 0.403) or fT4 (p = 0.396) was found between proteinuric and non-proteinuric dogs; however, mean TSH was significantly higher in proteinuric dogs (p = 0.002).\n\nThese results suggest that renal proteinuria influences thyroid homeostasis and should be considered when interpreting thyroid status of dogs. The thyroid stimulating hormone (TSH) stimulation test has been used to assess thyroid reserve in studies of hypothyroid dogs, however limited data are available for cats. The purpose of this study was to assess the effect of mild to moderate concurrent illness on the response of euthyroid cats to the TSH stimulation test.\n\nThis was a prospective study of 35 client-owned and shelter-housed mature adult cats. A full examination including systolic blood pressure, routine hematology, biochemistry and urinalysis, measurement of urine protein-creatinine ratio, total thyroxine (tT4), free thyroxine (fT4) and TSH, and a TSH stimulation test were performed. Cats thought to be 7 years or older were recruited, however the age of shelter cats could not always be verified. Hospitalized cats and cats receiving thyroid-suppressive medications were excluded. Cats were divided into 3 groups based on their physical examination and laboratory results: group 0 (no concurrent illness detected), group 1 (mild concurrent illness e.g. moderate dental disease or stable IRIS stage II chronic kidney disease) and group 2 (moderate concurrent illness e.g. untreated moderate to severe hypertension, anemia, hypoalbuminemia, proteinuria and/or hypokalemia). Results are reported as median (range). Post-TSH tT4 concentrations (post-tT4) and the ratio of tT4 concentrations before and after TSH administration (tT4 ratio) were compared between the 3 groups using the Kruskal Wallis H-test.\n\nTwelve cats were owned and 23 cats were shelter-housed. Two shelter-housed cats were diagnosed with hyperthyroidism and excluded from further evaluation. In the remaining 33 cats, baseline tT4 was 25.9nmol/l (17. 2-39.3), post-tT4 was 64.4nmol/l (29.4-102) and tT4 ratio was 2.41 (1.56-3.95 ). There was no significant difference (p > 0.05) in post-tT4 or tT4 ratio between the 3 groups (group 0, n=8; group 1, n=16; group 2, n=9), therefore no effect of mildmoderate illness on the TSH stimulation test results in this study. In conclusion, diabetic cats have erythrocytes with increased protein oxidation byproducts and reduced antioxidant capacity, suggesting increased oxidative stress. Because oxidative status was not ameliorated by treatment, it is possible that oxidative stress is persistent or needs longer treatment duration to decrease. The reason behind reduced TBAR in diabetic cats remains elusive. Lastly, oxidative status is not different between cats with and without remission. Hospital population cats with DKA were enrolled into a randomized, prospective, blinded, clinical trial. Cats with blood glucose (BG) > 300mg/dL, glucosuria, blood pH < 7.35 but > 7.0, and a blood betahydroxybutyrate (BOHB) concentration > 2.0mmol/L were enrolled.\n\nCats were randomly assigned to receive an IV continuous rate infusion of lispro or regular insulin administered at an initial dose of 0.09U/kg/ hr and adjusted as previously described (doi: 10.1111/vec.12298).\n\nSix cats were enrolled into each treatment group. No adverse events were observed in association with IV lispro administration. The median time to resolution of hyperglycemia (BG < 250mg/dL) was significantly shorter in cats treated with lispro (7h [range 2-10h]) compared to cats treated with regular insulin (12.5h [8-20h] ; P = 0.02).\n\nThere were no significant differences in the median times to resolu- Bland-Altman plots and Passing-Bablok regression were used to assess agreement and risks for error, respectively. Proportional errors were found between serum and plasma samples for ACTH, cortisol, TT4, FT4, and TSH; systematic errors were also found for FT4. Results confirm significant differences between these sample types and that they are not directly interchangeable. Incompletely filled EDTA tubes are associated with significantly higher cortisol concentrations and significantly lower ACTH concentrations when compared to completely filled EDTA tubes.\n\nWhen measured by chemiluminescent immunoassay, serum should be used for cortisol, TT4, FT4, and TSH, while plasma from completely filled EDTA tubes should be used for ACTH.\n\nInvestigating the Effect of Thyroid Stimulating Hormone Administration on Radioactive Iodine Uptake in Hyperthyroid Cats -Sponsored By Dechra Veterinary Products Hypoadrenocorticism in dogs is confirmed by performing an ACTH stimulation test. Although rare, hypoadrenocorticism is a differential diagnosis for many clinical and clinicopathological findings in canine patients, therefore a simple inexpensive way to rule it out is desirable.\n\nA prospective study was performed to test the hypothesis that the urine cortisol:creatinine ratio (UCCR) is more specific than basal cortisol for the diagnosis of hypoadrenocorticism. Client-owned dogs with clinical signs or clinicopathological abnormalities for which hypoadrenocorticism was a reasonable differential diagnosis were enrolled. Cases were excluded if they had received prior therapy with glucocorticoids, mitotane, or trilostane. Urine for UCCR was obtained in all dogs prior to performing an ACTH stimulation test.\n\nA total of 135 dogs were enrolled. 5 dogs were diagnosed with hypoadrenocorticism (pre-and post-ACTH serum cortisol < 2.0 mcg/dL) and 130 dogs were diagnosed as non-hypoadrenal (NH). UCCR ranged from 0 to 1 (RR:8-24) in the hypoadrenocorticism dogs, and from 4 to > 613 in the NH group. Basal cortisol ranged from \u2264 1 to 14.7 in the NH group. For the diagnosis of hypoadrenocorticism, sensitivity and specificity of basal cortisol \u2264 1 or \u2264 2 were 100% and 93.1%, and 100% and 65.4% respectively. Using a cut-off of \u2264 3, UCCR was 100% sensitive and 100% specific for diagnosis of hypoadrenocorticism. UCCR is significantly more specific than basal cortisol \u2264 2 (p=0.0001) and basal cortisol \u2264 1 (p=0.0034). These results suggest that UCCR allows hypoadrenocorticism to be ruled out in more patients, compared to basal cortisol. The purpose of this prospective study was to evaluate the accuracy of Bayer Diastix\u00ae for detection of glucosuria in cat litter over 8 hours.\n\nGlucose was added to previously frozen feline urine samples to achieve 90 urine samples with approximate glucose concentrations of 50, 125, 375, 750, and 1500 mg/dL. For each sample, the pad that detects glucose was cut off from 3 Diastix\u00ae reagent strips, added to clay litter-filled Petri dishes and soaked with 3 drops of one of the urine samples. An estimate of the urine glucose concentration was determined by a trained, blinded observer by comparing the color change of the pieces to the color chart in the Diastix\u00ae package insert immediately, as per manu- A randomized crossover study using 8 healthy cats with a 14-day washout period was used to assess the effect of dexmedetomidine(10 \u03bcg/kg IV) and saline on glucose, lactate, cortisol, insulin, glucagon, and nonesterified fatty acid (NEFA) concentrations at baseline (t=0), and then 20, 60, 120, and 180 min post administration. Nonparametric distribution was established with the Shapiro-Wilk test. Comparisons between groups were performed with a Wilcoxon matched pair signed rank test.\n\nComparisons within groups were performed with a Friedman test using Dunn's multiple comparisons for post-hoc analyses.\n\nNo significant differences were identified between groups, within the saline group, and within the dexmedetomidine group for insulin, cortisol and lactate concentrations. Significant differences (P < 0.05) were observed within the dexmedetomidine group: increased blood glucose concentration at 60 min (11.55, [5.9-16.6] , mmol/L) and 120 min (12, [6.1-13.8 ], mmol/L) compared to t=0 (6.05, [4.8-13.3] , mmol/L); decreased serum glucagon concentration at 120 min (3.8, [2.7-8.8 ], pg/mL) and 180 min (4.7, [2.1-8.2] , pg/mL) compared to t=0 (11.85 This prospective study investigated the veracity of a recent retrospective study, where we found a significant negative correlation between serum total thyroxine (TT4) and glucose concentrations in cats. To that end, we used a naturally-occurring hyperthyroid cat model to determine the effect that a range of serum TT4 concentrations would have on serum glucose concentrations.\n\nThe study was approved by the University Animal Ethics Committee.\n\nAn apriori power analysis indicated that six cats per group would suffice to detect a difference of 15 \u00b1 15 mg/dL on repeated measures of serum glucose on the same cat with a power of 0.8. Ten hyperthyroid cats were randomly allocated in a crossover design to receive treatment with a long-acting carbimazole or to have treatment withheld.\n\nThe experimental design consisted of four, 14-day study periods that were separated by 21-day washout periods. We collected serum on days 1, 3, 7, 10, and 14 of each of the four study periods and measured serum glucose and TT4. Data were analyzed with a linear mixed-effect model that included TT4 as a fixed effect, and cat as a random effect. Statistical significance was set at 0.05. The objective of this study was to determine peri-operative characteristics and outcome in cats undergoing surgical treatment for PHPT.\n\nThis was a multi-institutional, retrospective study with medical record data collection and via telephone follow-up. Cats undergoing surgical treatment and histopathological evaluation of resected tissue were included. Cats were divided into pre-operative ionized calcium (iCa) groups corresponding to the 33 rd , 67 th , and 100 th percentiles of the study population's pre-operative iCa results.\n\nThirty-two cats were included in the study. Mean cat age was 13.3 \u00b1 2.4 years and mean cat body weight was 4.9 \u00b1 1.3 kg. iCa was above reference range in all cats (median 1.8 mmol/L (IQR 1.5,1.9)). All cats underwent cervical exploratory surgery and abnormal tissue was identified and removed in all cats. Histopathologic diagnosis was parathyroid adenoma in 20/32 (62.5%) cats, parathyroid endocrine carcinoma in 7/32 (21.9%) cats, parathyroid hyperplasia in 3/32 (9.4%) cats, and parathyroid cystadenoma in 2 (6.3%) cats. At discharge, 6/32 (18.8%) cats had hypercalcemia, 5/32 (15.6%) had hypocalcemia, and 21/32 (65.6%) cats had iCa within reference range. Overall median survival time was 1109 days (95% CI 856 -1332). Survival time was not significantly associated with pre-operative iCa group (p = 0.139), hypocalcemia at discharge (p = 0.326), hypercalcemia at discharge (p = 0.955), or diagnosis of carcinoma (p = 0.930).\n\nIn this cohort of cats, parathyroid adenoma was the most common cause of PHPT and surgical treatment results in favorable survival times. Therefore, the objective of the present study was to determine the changes in circulating AA concentrations in dogs with HAC.\n\nTwenty-eight dogs newly diagnosed with pituitary-dependent hyperadrenocorticism (PDH) were enrolled in this case-controlled study, and 6 healthy beagles were also included as controls. Serum concentrations of 21 AA (alanine, arginine, asparagine, aspartate, cysteine, glutamate, glutamine, glycine, histidine, isoleucine, leucine, lysine, methionine, phenylalanine, proline, serine, taurine, threonine, tryptophan, tyrosine, and valine) were analyzed using a 600 MHz 1 H nuclear magnetic resonance spectrometer.\n\nOrthogonal partial least square-discriminant analysis (OPLS-DA) plots showed a separation between PDH and healthy dogs. Dogs with PDH showed significant increases in median serum concentrations of arginine (P = 0.0039) and aspartate (P = 0.0123) but significant decreases in glutamine (P = 0.0127) and serine (P = 0.0287), compared to healthy dogs.\n\nOur study showed that circulating concentrations of some AA were affected in dogs with PDH, indicating that chronic hypercortisolemia may precipitate a disturbance in AA metabolism. Further studies are necessary to clarify the association between AA profiles and consequences of hypercortisolemia in dogs. Canine diabetes mellitus is a common disease that may have parallels to human type 1 diabetes (T1D). We recently identified variances in serum metabolomic profiles between fasted diabetic and healthy dogs, some having similarities to those previously identified in human T1D patients. Given that obtaining fasted samples in diabetic dogs can be difficult in practice, the purpose of this study was to expand these efforts to compare untargeted metabolomic profiles in nonfasted diabetic and healthy control dogs.\n\nSerum from diabetic dogs (n=6) and healthy control dogs (n=6) were analyzed by liquid chromatography-mass spectrometry profiling. Dogs were breed and/or body weight matched, and time of sample collection post-feeding was approximately matched between pairs. Metaboanalyst was utilized for data analysis to identify differences in metabolomic profiles between the two groups.\n\nBased on a heat map analysis of both known and unknown metabolites, clear clustering of metabolites between diabetic and control groups was observed. In diabetic dogs compared with healthy control dogs, many metabolites were significantly (P < 0.01) downregulated, including those involved in tryptophan metabolism as well as several amino acids. Fewer metabolites were significantly (P < 0.01) upregulated and included microbial derived citramalate and the organic acid alpha-hydroxyisobutyric acid. Multiple metabolic perturbations, including those listed above, were similar to those previously found in fasted diabetic dogs.\n\nIn sum, metabolomic profiles differ between non-fasted diabetic and healthy dogs, with some parallels to those found in fasted dogs. Metabolomic alterations may give insight into the pathogenesis of canine diabetes. Future studies to confirm these findings and develop targeted assays to detect metabolites that may be used as biomarkers of canine diabetes are warranted. Some studies had shown serum cortisol concentration increases, and corticotropic hyperplasia due to environmental stressful agents. This observation explains physiological effects caused by stress. Nevertheless, few studies have tried to correlate chronic exposure to stress with hypothalamic-pituitary-adrenal axis activity in dogs, and hyperadrenocorticism (HAC) development. The present work aimed to clarify whether dogs with pituitary-dependent HAC (PDH) were more exposed to stressful situations throughout their lives when compared to healthy animals. A 25-item questionnaire regarding temperament, socialization, social interaction, level of environmental enrichment and daily habits was developed. Owners of both recently diagnosed PDH and healthy dogs were invited to answer the questionnaire. Twenty newly diagnosed PDH dogs were included in the study. Subjects were matched with forty healthy dogs (control group) by sex, age, and breed (1:2 ratio). Exclusion criteria for the control group were: HAC suspicion, chronic glucocorticoid therapy, and glucocorticoid's exposure over the last month. Odds ratio estimates (OR) and 95% confident intervals (95% CI) were reported, and P-values less than, or equal to 0.05 were considered statistically significant. Dogs with HAC were more than ten times more exposed to neutering (OR = 11.4, 95%CI: 1,38 -94,06, P < 0,05). However, no other significantly correlation was found between social isolation, confinement, exposure to canned foods or plastic toys, phobias or separation anxiety, and HAC. Even variables under study considered potential stress relievers did not suggested any protective effect. These results emphasize neutering as a potential risk-factor to HAC development and instigate further studies on possible mechanism behind. is used to evaluate pancreatic endocrine function and predict which patients will become diabetic after pancreatectomy. The purpose of this study was to describe the CTA characteristics of the pancreas in cats with chronic DM and to compare those findings to healthy control cats.\n\nIn this prospective cross-sectional study, 15 cats with naturally occurring DM present for > 1 year and 10 age matched, healthy control cats were utilized. Sedated CTA exams of the pancreas were performed in all cats. The time to arterial enhancement, time to peak portal enhancement, pancreatic attenuation and arterial to portal attenuation ratio (A:P) was determined in all cats and compared between groups. A student t-test was used for statistical analyses. The purpose of this study was to examine BA metabolism in dogs with naturally-occurring DM and to relate these findings to changes in the intestinal microbiota.\n\nAdult dogs with a clinical diagnosis of DM were prospectively enrolled along with age-matched healthy control dogs. The fecal microbiota were analyzed by 16S rRNA gene next-generation (Illumina) sequencing. Fecal concentrations of primary (cholic/chenodeoxycholic) and secondary (lithocholic/deoxycholic/ursodeoxycholic) BA were measured using gas chromatography and mass spectrometry.\n\nbetween healthy controls and dogs with DM. Statistical significance was set at P < 0.05.\n\nTen diabetic dogs and 10 healthy controls were enrolled. Fecal microbial diversity was lower in DM dogs when compared to healthy controls. PCA based on unweighted Unifrac distance metric did not reveal significant clustering between dog groups. However, linear discriminate analysis effects size (LEfSe) detected 27 differentially abundant bacterial taxa (a= 0.01, LDA score >2.0). While Gammaproteobacteria was overrepresented, Erysipelotrichia, Clostridia, and Bacteroidia were underrepresented in DM dogs compared to healthy controls (P < 0.05 for all). Total primary BA were increased in DM dogs compared with healthy controls (P = 0.03) and lithocholic acid was decreased (P < 0.05) in dogs with DM.\n\nResults indicate that dogs with DM have both intestinal dysbiosis and associated BA alteration. The pattern of dysbiosis and altered BA composition is similar to that seen in humans with DM. Further investigation is necessary to determine whether dysbiosis is a cause or consequence of DM and whether it is associated with poor glycemic control. were to evaluate the diagnostic utility of IHC and clonality testing for the diagnosis of IBD and LSA in cats, to assess the level of agreement between EB samples from the USI and LSI, and to determine the diagnostic utility of procuring LSI samples.\n\nA total of 62 cats with CE (gastrointestinal signs of > 3 weeks duration) were retrospectively (n = 19) and prospectively (n = 43) enrolled at the Veterinary Specialty Hospital, San Diego, CA. All cats had UGE and LGE performed with EB samples obtained from both sites. All cases were retrospectively or prospectively reviewed by a single board-certified pathologist (MRA) and were then categorized as \"IBD\", \"possible LSA\", \"probable LSA\", or \"LSA\". Samples were also submitted for IHC and clonality testing, as previously described.\n\nBased on HE staining alone, 41/62 cats (66.1%) were classified as having IBD and 21/62 (33.9%) as having LSA. After consideration of IHC and clonality, 13/62 cats were classified as having IBD (21.0%) and 49/62 as having LSA (79.0%). Thirteen of 26 cases (50.0%) diagnosed as \"IBD\" and 15/15 cases (100%) diagnosed as \"possible LSA\" or \"probable LSA\" based on HE staining alone were subsequently diagnosed with LSA after the addition of IHC and clonality testing. Using Cohen';s Kappa statistic (k), agreement between USI and LSI samples was moderate (k = 0.65) based on HE staining alone, and also moder- Six healthy adult research beagles with a subclinical Giardia spp. infection and a C. canis co-infection were administered FPP as directed by the manufacturer by mouth, daily, for 3 days. Fecal samples were collected 7 and 3 days before FPP (days -7 and -3), on the first day of administration (day 0), and 4, 14, and 21 days after the start of administration (days 4, 14, 21). Fecal DNA was extracted and qPCR assays were performed to assess the abundance of total bacteria, Faecalibacterium, Turicibacter, E. coli, Streptococcus, Blautia, Fusobacterium, and C. hiranonis and to calculate a previously published dysbiosis index (DI). Bacterial groups and DI were compared across time points using the Friedman test and Dunn';s post-test as appropriate. Statistical significance was set as p < 0.05.\n\nThe abundance of Fusobacterium increased between days 0 and 4 (p < 0.01), otherwise there were no statistically significant changes in the DI or abundance of bacterial groups before and after treatment with FPP. Additionally, the DI in this group of dogs was similar to that of previously evaluated healthy dogs; only 2 of 6 dogs had transiently increased DI results (DI > 2 at 1 pre-treatment time point for each). The CE group was composed of 46 males and 22 females, the median age was 6.3 years (min-max: 1-16 years). No significant differences for age or sex were identified between CE and CTRL dogs.\n\nSerum IL-2, IL-6, and TNF-\u03b1 concentrations were significantly increased in the CE group when compared to CTRL dogs. Results for both groups are shown in the table below. No correlation was found between age, sex, and any of the serum cytokine concentrations.\n\nUsing a cutoff value of > 14 pg/mL for IL-6, sensitivity for discriminating CE and CTRL dogs was 84% and specificity was 72%. Using a cutoff value of > 2.2 pg/mL for TNF-\u03b1, sensitivity was 76% and the specificity was 80%. The areas under the curves for IL-6 and TNF were 0.81 and 0.84, respectively. The first principal component of PCA explained 85.5% of the variance where TNF-\u03b1 was the major contributor.\n\nIn conclusion, dogs with CE have increased concentrations of IL-2, IL-6, and TNF-\u03b1, but we were unable to identify any significantly altered concentrations for IL-8. Further studies are needed to assess the utility of these cytokines as diagnostic or prognostic markers in dogs with chronic enteropathies. However, their impact on GI motility has not been evaluated. This study assesses the effects of metoclopramide, erythromycin and exenatide on gastric emptying (GE) and gastric motility in comparison to placebo.\n\nIn a randomized, double-blind, 4-way crossover design, 8 healthy cats were administered placebo (saline PO or SC), metoclopramide (0.5 mg/kg SC q8h), erythromycin (1 mg/kg PO q8h) or exenatide (1.2 \u03bcg/ kg SC q12h) for 2 consecutive days followed by a minimum 5-day washout period. Cats were randomized to a treatment group. Sonographic assessment of GE was performed in dorsal recumbency at 0, 15, 30 and 60 minutes following a solid test meal (20% of daily energy requirements), and at 30-minute intervals thereafter for 8 hours. Mean cross-sectional area of transverse images of the relaxed antrum was obtained for each time point, and expressed as a percentage of the maximal antral area. The area under the curve (AUC) was calculated and 25% -90% GE times (GET) determined. The motility index (MI) of antral contractions was plotted against time. A mixed model ANOVA with cat as a random effect and treatment as fixed effect was used to assess the difference in each fractional GET and MI AUC between treatments. Posthoc pairwise comparisons were examined with the Tukey';s test as appropriate.\n\nThe rate of GE following metoclopramide or erythromycin treatment was significantly faster compared to that after placebo or exenatide.\n\nThere was a statistically significant difference at all fractional GE between GET following metoclopramide and erythromycin treatments when compared to placebo (p = 0.002 -0.049 and p = 0.001 -0.015 for metoclopramide and erythromycin respectively) and exenatide Sixty dogs anesthetized for elective ovariectomy were evaluated for GER and 27 dogs identified with GER and having contents with a pH of < 4 were included in the study. An esophageal pH/impedance catheter (Divarsatek\u2122, Milwaukee) was placed shortly following anesthesia using endoscopic guidance with the catheter tip placed approximately 3 cm cranial to the lower esophageal sphincter. A GER episode was defined as an orally progressing decrease in impedance (50% decrement in ohms) from the pre-episodic esophageal baseline recording. When esophageal pH < 4 remained at the conclusion of the surgery esophageal lavage was performed. Tap water in 60 mL aliquots was instilled through a gastric tube and carefully suctioned. If after an interval of 2 minutes post lavage esophageal pH was still under 4, another aliquot was instilled and again suctioned until pH > 4. Paired t test, Wilcoxon matched pairs test and Spearman';s rank correlation coefficient were used to analyze parametric and nonparametric data.\n\nOf the 27 dogs having strongly acidic GER (pH < 4), 16 dogs were able to neutralize their esophageal lumen pH before the end of the procedure. These 16 dogs increased their esophageal lumen and GER pH from 2.1 \u00b1 0.8 to 5.4 \u00b1 0.9 during the anesthesia (p < 0.0001). 14/27 dogs did not neutralize their esophageal lumen and GER pH having esophageal lumen and GER pH of 2.9 \u00b1 0.9 at the end of the procedure. Esophageal lavage with tap water increased the lumen and GER to 4.1 \u00b1 1 in 11/14 (78%) of dogs (p = 0.003). The volume of water used for lavage was not associated with the changes in lumen and GER pH (r = -0.19, p = 0.50).\n\nIn the present study, we show for the first time that some dogs are capable of neutralizing strongly acidic GER. The dogs that were unable to clear acidic GER are possibly the ones more predisposed to esophagitis or stricture formation. Esophageal lumen lavage with water in dogs having strongly acidic pH increased the esophageal lumen and GER pH in a majority of dogs suggesting esophageal lavage might be beneficial in preventing GER complications.\n\nJanne G. Lyngby 1 , Jillian Haines 2 1 University of Copenhagen, Frederiksberg C, Hovedstaden, Denmark, 2 -Washington State University, Pullman, WA, USA Megaesophagus (ME) has a high mortality rate associated with the difficulty of managing patients' feeding. Currently there are no evidencebased guidelines available for determining the best diet consistency in dogs with ME.\n\nThe aim of this study was to compare esophageal clearance times (ECT) of food with different consistencies in dogs with congenital idiopathic ME, and to assess if esophageal contrast videofluoroscopy can be used to guide management of dogs to improve clinical signs and quality of life.\n\nTwenty-one dogs with congenital idiopathic ME were included. For evaluation, each dog was placed in a Bailey chair and administered barium sulfate orally in three forms: liquid, slurry and within canned food meatballs. The amount of barium and food was determined by bodyweight and resting energy requirement. Contrast videofluoroscopy of the esophagus was obtained at baseline and every 5 minutes for up to 30 minutes or stopped sooner if esophageal content had cleared. Each patient received specific recommendations for management based on ECT of the different diet consistencies, frequency of regurgitation, presence of esophageal reflux, decreased gastric motility, and body condition score. The follow up communication was performed to assess compliance and response to management changes.\n\nNo clearance was observed in 29% of dogs fed liquid, in 43% of dogs fed slurry and 67% of dogs fed meatballs. There was a significant difference (p < 0.001) between groups with the ECT of liquid being faster compared to both meatballs and slurry. There was no significant difference in ECT between slurry and meatballs, but the median percentage of esophageal clearance was 50% (interquartile range 0-79%) for slurry and 0% (interquartile range 0-60%) for meatballs. (7), hemorrhage (2), mucosal irregularity (5), and a polypoid lesion (1) . Intestinal lesions included erosions (3), hemorrhage (1), irregular mucosa (5), and a mass in the duodenum (1) and jejunum (1) . (1) Cats with chronic enteropathy frequently undergo endoscopy and assessment of intestinal biopsies using histopathology, immunohistochemistry, and clonality testing (PCR for antigen receptor rearrangements (PARR)). However, there is a paucity of data on findings for these modalities in a cohort of healthy cats. Thus, the aim of this study was to describe results of histopathology, immunohistochemistry, and PARR in endoscopically derived duodenal biopsy specimens from clinically healthy, client-owned cats.\n\nTwenty clinically healthy, client-owned cats underwent gastroduodenoscopy at the Veterinary Medical Teaching Hospital at Texas A&M University (Animal Care and Use Protocol 2015-0276 CA). Tissue specimens were collected from the stomach (18 cats) and the duodenum (20 cats) and were evaluated according to the WSAVA scoring system by a board-certified pathologist (MRA) who was blinded to the health status of the cats. In addition, samples were evaluated by routine immunohistochemistry and clonality testing without disclosure of the clinical status of the cats.\n\nCats had a median age of 9.5 years (min-max: 3 to 18 years), body weight of 5.0 kg (min-max: 2.9-8.6 kg), and body condition score of 6 (min-max: 5 to 9). Sample quality was reported as very good in all cases. Histologic evaluation of the stomach revealed a mean gastric score of 1.77 (\u00b1 1.59) and a mean duodenal score of 3.50 (\u00b1 1.89).\n\nImmunohistochemistry of duodenal samples revealed epitheliotropic and/or lamina propria infiltrates that were CD3+ in all cases. Results of clonality testing in duodenal samples revealed clonal rearrangements in 8 cats and polyclonal rearrangements in 6 cats. In 5 cats, results were suggestive of clonal rearrangements in a polyclonal background. Results for one cat were reported to be consistent with pseudoclonality due to a low quantity of target DNA. An interpretation of small cell lymphoma based on immunohistochemistry and clonality testing was reached in 12 of these healthy cats. In one additional cat, results were interpreted as emerging small cell lymphoma, and an interpretation of enteritis was given for 6 cats. Results from one cat were deemed uninterpretable due to pseudoclonality.\n\nIn conclusion, intestinal biopsies from clinically healthy cats commonly show abnormal findings using histopathology, immunohistochemistry, and clonality testing without any apparent clinical significance. While the sensitivity of clonality tests is reported to be high, these results imply that further assessment of the specificity of this diagnostic modality is warranted. A total of 2,349 spots were identified, of which 9 were differentially expressed with a \u2265 2-fold change between healthy cats and cats with IBD and SCL (p \u2264 0.01). Eight of these 9 spots were also differentially expressed between cats with IBD and those with SCL (p \u2264 0.04). LC-MS/MS identified proteins of the annexin and apolipoprotein families, and malate dehydrogenases in the differentially expressed spots.\n\nOur results show differences between the mucosal proteome of healthy cats, cats with IBD, and cats with SCL. These proteins might hold potential for the development of minimally-invasive biomarkers for the differentiation of IBD and SCL in cats with chronic enteropathy. Further studies to validate these findings are warranted. The essential amino acid tryptophan and its degradation products (e.g., serotonin) are important in the regulation of T-cell response within the intestine as well as intestinal motility. Furthermore, bacteria metabolize tryptophan into various indole-derivatives, which also serve as signaling molecules, activating pathways in other organ systems (e.g., brain, liver, kidney). Alterations in tryptophan metabolism is associated with inflammatory bowel disease (IBD) in humans, and dietary supplementation with tryptophan has been shown to have antiinflammatory effects in experimental colitis models. The aim of this study was to evaluate changes in the tryptophan-serotonin-indole pathway in dogs with intestinal disease.\n\nFecal samples from 8 dogs with idiopathic IBD and 10 dogs with acute hemorrhagic diarrhea (AHD) were collected. Fecal samples from 10 healthy dogs were included as a control group. All 28 samples were extracted using methanol-chloroform before targeted analysis by TSQ Altis Triple Quadrupole liquid chromatography-mass spectrometry.\n\nChromatograph peaks were compared with a standard curve for quantification, and adjusted for initial fecal weight. The following metabolites were measured: acetylcholine, anthranilic acid, indole, indole-3-acetaldehyde, indole-3-acetamide, indole-3-acetic acid, indole-3-carboxaldehyde, indole-3-lactic acid, serotonin, tryptamine, tryptophan, and tyramine. Fecal metabolites were compared amongst groups using Kruskal-Wallis tests, followed by Dunn's multiple comparisons tests. Significance was set as p < 0.05.\n\nIn the AHD group, anthranilic acid, indole, indole-3-acetamide, and indole-3-lactic acid were significantly increased (p=0.036; 0.004; 0.029; and 0.023, respectively), and serotonin, and tryptamine were decreased (p=0.037; and 0.178, respectively) compared to healthy controls. Fecal tryptophan was increased 2-fold in dogs with IBD (not significant, p=0.524), and 8.5-fold in dogs with AHD (p < 0.001) compared to healthy control dogs.\n\nSignificant differences in fecal metabolites from the tryptophan-serotonin-indole pathway were found in dogs with AHD compared to healthy control dogs. Further studies are needed to determine the clinical implications of these differences. Thirteen dogs diagnosed with idiopathic IBD, that previously failed to respond to treatment with elimination diets and metronidazole, were enrolled. Stool samples were collected from all dogs before initiating therapy with prednisone, after 3 and 8 weeks, and more than one year after beginning treatment. Thirteen healthy dogs were enrolled in the study as a control group. Stool samples were kept frozen at -80 o C until DNA extraction. The microbiota was characterized using Illumina sequencing of 16S rRNA genes. Data were analyzed using Quantitative Insights Into Microbial Ecology (QIIME). Beta diversity was evaluated with the phylogeny based unweighted UniFrac distance metric, and statistics were performed with the Analysis of Similarities (ANOSIM).\n\nIn the IBD group, clinical disease severity (CIBDAI) at baseline was scored as moderate to severe. All dogs achieved partial or complete remission of clinical signs by 3 or 8 weeks of treatment, and CIBDAI scores were significantly reduced after 8 weeks of treatment (p < 0.001). At baseline, dogs with IBD showed differences in microbial composition when compared to healthy dogs, as unweighted Uni-Frac distances demonstrated significantly different beta diversity between groups (p=0.001, R=0.462). Differences in the IBD group included increased Firmicutes (p < 0.001) and Actinobacteria (p=0.027), and reduced Bacteroidetes (p < 0.001), Fusobacteria (p < 0.001) and Proteobacteria (p=0.006). Within the IBD group, beta diversity was still significantly changed at 8 weeks (p < 0.001) compared to healthy controls. At the 1 year follow up, diversity metrics placed the microbiome of treated dogs closer to that of healthy dogs, but they were still significantly different from those of healthy controls (p=0.003, R=0.258).\n\nOur results suggest that, while treatment can be effective in improving clinical signs, the dysbiosis associated with IBD is still present after more than one year after the initiation of immunosuppressive therapy, even when dogs were clinically well controlled. Observed to expected ratios for dilutional parallelism ranged from 77.4 to 162.9%, with a mean of 119.3%. Intra-assay variability ranged from 16.9 to 36.7% (mean %CV for all samples and machines: 25.1%).\n\nInter-assay variability ranged from 14.1% to 51.2% (mean %CV for all samples and machines: 31.8%) and most samples resulted in two (7 samples) or even three (5 samples) diagnostic bins (i.e., within the reference interval; gray range; suggestive of pancreatitis) during the experiment.\n\nThe new VetScan cPL rapid test for the VetScan VUE shows poor linearity. This is of clinical significance as the working range of this assay is very narrow, making dilution necessary for samples with higher cPLI concentrations. Also, the assay is not very precise (mean %CV: 25.1%). Finally, inter-assay variability is unacceptably high (mean % CV: 31.8%), affecting the actual diagnostic bin in many cases. In conclusion, the VetScan cPL rapid test for the VetScan VUE lacked linearity, precision, and reproducibility. range: 4 to 5) and 6 (8 %), over-conditioned (median: 6 to 6 -7; range: 5 -6 to 8). Sixty-one dogs (88 %) had documented weight loss at the time of diagnosis; 30 (43 %) had severe (\u226510 %), 22 (32 %) had moderate (5 -9.9 %), and 9 (13 %) had mild (0.1-4.9%) loss. Two dogs were lost to follow-up and 29 out of 69 dogs (42 %) died or were euthanized following treatment failure. There were no significant effects of body condition score, percentage weight loss, body weight, appetite, serum albumin, cholesterol, cobalamin, and folate concentrations, canine chronic enteropathy activity index, and duration of signs on mortality (P>0.05). However, dogs that had higher caloric intake at diagnosis had increased number of days to death or euthanasia following treatment failure (P = 0.002, correlation coefficient = 0.571).\n\nParameters associated with malnutrition at the time of diagnosis of PLE due to CE or lymphangiectasia in dogs in this study were not a predictor of mortality following treatment failure and therefore cannot be used to predict response to treatment. However, alternative measures of malnutrition may be required to definitively investigate the role of malnutrition in the prognosis of canine PLE. Total FFA concentrations at baseline were not significantly increased in dogs with CE relative to healthy dogs (p = 0.099). The healthy canine FFA reference interval was found to be 12-26 mg/mg, and 44% (25/57) of dogs with CE had increased FFA (median \u00b1 SD, [minmax]: 66 \u00b1 37 mg/mg, , p < 0.001). The FFA concentrations for these dogs after one month of treatment were significantly decreased (19 \u00b1 35 mg/mg, , p < 0.001) and were no longer statistically different from the healthy dogs (p = 0.64), with 60% (15/25) no longer exceeding the healthy dog reference interval. Therefore, further analysis on the granulomatous gastritis in 11 MDs was performed.\n\nMedian age was 75 months (range, 20-118 months); there were 6 male (3 castrated) and 5 female (all spayed) dogs. Six dogs had a history of suture-associated granuloma, which were surgically resected 1-25 months prior to their inclusion in the study. Fever was commonly observed (median 39.0 C, range 37.5-40.1 C), and elevated serum C-reactive protein (>1.0 mg/dl) was observed in 9 dogs (median 10 mg/dl, range 0.1-20 mg/dl). On histopathologic examination, no foreign material was detected in all cases. Four dogs initially underwent pyloroplasty or gastroduodenostomy to resect the granuloma.\n\nSubsequently, they received immunosuppressive therapy within 2 months after the surgery due to recurrence of the lesion (n = 2) or based on the veterinarians'; decision (n = 2); the other 7 dogs were initially treated with immunosuppressive drugs. As a result, all dogs received immunosuppressive therapy with prednisolone (1-3 mg/kg/ day) and/or cyclosporine (5-6 mg/kg/day). After the initiation of immunosuppression, clinical signs were resolved and serum C-reactive protein concentration decreased to the reference range in all dogs within 2 months. Nine of the 11 dogs showed recurrence of the lesion when prednisolone was tapered (median duration from the initiation of immunosuppression: 55 days, range: 14-394 days); they responded well to re-induction of immunosuppression with higher-dose prednisolone (2-4 mg/kg/day) or with addition of cyclosporine or azathioprine. Median follow-up period was 462 days (range, 28-2,343 days), and 3 dogs died at 40, 322, and 1,450 days after initial presentation.\n\nThe causes of death were aspiration pneumonia (n = 2) and hepatic tumor (n = 1).\n\nIn conclusion, immunosuppressive therapy was effective in the management of granulomatous gastritis in MDs, and prevention of vomiting (i.e. aspiration pneumonia) may be important for ensuring a good prognosis. As described in a previous study, granulomatous gastritis was likely to occur in MDs, and a history of suture-associated granuloma seemed to be a risk factor. However, there were several cases of dogs that had never undergone surgery. Future studies on the innate immune systems of dogs in these cases are warranted.\n\nHirotaka Igarashi 1 , Keisuke Konishi 2 , Eri Uchida 3 , Takashi Tamamoto The expression levels of all tested genes, with the exception of IL-4, were significantly up-regulated in the polypoid lesion. When the rate of increase in the expression of each gene was compared, the rates of increase of IL-1\u03b2, IL-6, IL-8, and IL-17 were significantly higher than that of IL-10, whereas the rates of increase of IFN-\u03b3 and TNF-\u03b1 were significantly lower than that of IL-10. The number of Tregs in the polypoid lesion was significantly increased compared to that in the noninflamed colonic mucosa of ICRP-affected MDs and control dogs. The number of macrophages was not significantly different between the groups. There was a significant positive correlation between the expression level of IL-10 gene and that of Foxp3 gene (r = 0.749, P < 0.001). In addition, a significant positive correlation was observed between the expression level of IL-10 gene and the number of Tregs (r = 0.527, P < 0.01).\n\nIn summary, the upregulation of IL-10 was significantly correlated with the distribution of Tregs in polypoid lesions of ICRP-affected MDs. However, the rate of increase in the expression level of IL-10 was relatively low compared to that of proinflammatory and Th17 cytokines. Therefore, the increase in numbers of Tregs and antiinflammatory cytokines in polypoid lesions was considered to be a reactive change and was insufficient to regulate the development of inflammation. Further analysis on the association between Treg distribution in the lesion and the prognosis, including the response to immunosuppressive therapy, are warranted.No The affected dogs were housed in a single shelter and the design was approved by the shelter and by the Clinical Review Board. A fecal score was determined by 1 of 4 trained observers that was masked to the diet groups on each sample by comparing to a standardized score sheet: 0 = no stool; 1 = very hard and dry; 2 = firm but not hard; 3 = normal, little or no segmentation, moist; 4 = very moist, log shaped; 5 = very moist, piles; 6 = texture but no defined shape; and 7 = watery puddle. To qualify for the study, each dog had to present with a fecal score > 4 and have hematochezia, mucus, or straining. The dogs were randomized to be fed 1 of the 2 diets and all were administered fenbendazole at 50 mg/kg, PO, daily for 5 days and metronidazole at 10 -15 mg/kg, PO, twice daily for 5 days. A dog had to be in the study for at least 4 days to be included in the data analysis. The proportions of dogs with a fecal score of less than 5 on the day of adoption or the last study day (Day 9) and the proportions of stools in each group with a fecal score of greater than 3 were compared by Fisher's exact test with significance defined as P < 0.05.\n\nA total of 52 dogs were entered into this pilot study, with 22 dogs (11 per diet) completing the protocol to date. All of the dogs fed the high fiber diet had a fecal score less than 5 on the last day of the study which was statistically different than dogs fed the control diet ( A total of 17 fecal samples from dogs with acute diarrhea treated with either FMT (2.5 to 5 g of donor stool/kg diluted in 60 cc saline via enema; n = 10) or metronidazole (MTZ at 15mg/kg PO BID for 7 days; n = 7) were collected before (T0), after 1 week (T2), and after 4 weeks (T3) of each intervention. Fecal DNA was evaluated for quantitative PCR (qPCR) analysis for selected bacterial groups (total bacteria, Faecalibacterium spp., Turicibacter spp., Streptococcus spp., E. coli, Blautia spp., Fusobacterium spp., and C. hiranonis) and results were used to calculate the Dysbiosis Index (DI). Feces were evaluated using a fecal scoring system (Nestle PURINA fecal scoring system). DI and the fecal score were compared between both groups using a Wilcoxon ranksum test. The presence of dysbiosis (DI > 0) was compared between both groups using a fisher's exact test. A p < 0.05 was considered to be statistically significant.\n\nThe fecal score did not differ significantly between the 2 groups at either T0 or at T2 (p = 0.200 and p = 0.116, respectively). At T3, the FMT group had a significantly lower fecal score than the MTZ group (p = 0.020). DI did not differ significantly at T0 between the two groups (p = 0.961). At T2 and T3, the FMT group had a significantly lower DI than the MTZ groups (p = 0.001 and p = 0.002, respectively). Recovery from dysbiosis was also evaluated, and the FMT group had a significantly lower rate of dysbiosis (30% [3/10] Fat-loading resulted in significantly longer gastric transit times when compared to controls (p < 0.01). Also, gastric retention of the capsules occurred significantly more commonly in dogs fed either corn oil or dairy cream (p < 0.01). While 10/16 fat-loading studies resulted in gastric retention of the capsule for more than 12 hours, none of the control studies had gastric retention. In addition, gastric retention occurred significantly more often with dogs fed corn oil than dairy cream (p < 0.05). Though gastric retention limited the number of cases where visual assessment of the small intestinal mucosa could be performed, 5/6 fat-loaded studies were subjectively judged to have moderate to marked prominence of villi with increased numbers of dilated lacteals when compared to control studies.\n\nSmall intestinal wall thickness did not differ significantly between control and fat-loaded dogs. However, mucosal speckling scores of the jejunum were significantly greater in dogs fed cream or oil than in control dogs (p < 0.05).\n\nThough fat-loading might increase prominence of duodenal villi, gastric transit times were significantly prolonged resulting in the inability of capsule endoscopy to visually assess the small intestines in over half the cases in this study. Future studies investigating fat-loading techniques should include the use of traditional push endoscopy to overcome this limitation and allow consistent assessment of the intestinal mucosal appearance.\n\nImmunolocalization of S100A12 and its association with Helicobacter spp colonization in canine gastric mucosa Rafael R. Departamento de Salud Animal, Universidad de Caldas, Manizales, Manizales, Caldas, Colombia S100A12 is a novel inflammatory marker that has been evaluated in both humans and animals. Increased concentrations of S100A12 in the gastric mucosa of humans with Helicobacter pylori infection have previously been reported. The gastric mucosa of dogs is frequently colonized by several Helicobacter species, however there is a poor association between Helicobacter organism density and mucosal inflammation. The purpose of this study was to evaluate gastric tissue localization of S100A12 by immunohistochemistry (IHC) in dogs and determine correlations between the density of Helicobacter organisms and S100A12 containing cells in the lamina propria of dogs with gastric disease and in healthy control dogs.\n\nLocalization of S100A12 positive cells and Helicobacter organisms was studied using paraffin-embedded gastric biopsies, 11 from dogs with chronic gastritis and 9 from healthy control dogs (5 of these were obtained post-mortem after the patient had presented to the emergency service at the Veterinary Teaching Hospital at Texas A&M University, none of which had gross or histopathological lesions suggesting gastrointestinal disease and 4 were research dogs from Universidad de Caldas). No dog had received antibiotic or corticosteroid treatment in the last two weeks prior to the collection of gastric biopsies. IHC was performed using antibodies directed against canine S100A12 (cS100A12) and Helicobacter spp., respectively. cS100A12 staining in the lamina propria was quantified and classified into absent, mild, moderate, or severe and Helicobacter density was graded using similar criteria. Histopathological evaluation was conducted following the World Small Animal Veterinary Association (WSAVA) grading scheme. Spearman';s rank correlation was used to evaluate any possible associations between cS100A12 with Helicobacter density and histopathology findings. A Mann-Whitney U test was used to compare ordinal variables between healthy and sick dogs. Immunoglobulin (Ig)-binding to gut bacteria likely activates immune responses locally and systemically however it has never been investigated in dog IBD yet. Therefore, our study investigated whether the humoral immune response against commensal gut bacteria in IBD is greater than that of healthy dogs. Additionally, whether the Ig-binding bacteria potentially triggers an exacerbated immune response that aggravates gut homeostasis.\n\nFresh fecal material was collected from 20 IBD dogs and 9 clinical healthy dogs (mean age \u00b1 SD = 6.1 \u00b1 3.9 and 6.6 \u00b1 2.1 years respectively). All patients were diagnostic confirmed by endoscopic biopsy and had no history of receiving immunosuppressive medication. This work compares the amount of fecal bacteria binding to IgG and IgA in vivo between IBD and healthy canines by flow cytometric analysis.\n\nIn addition, the extent of macrophage phagocytosis and macrophage activation by fecal bacteria derived from IBD vs. healthy dogs were investigated by both flow cytometric analysis and ELISA (TNF-\u03b1 and IL-10). Comparison between groups was evaluated using t-test and statistical significant was set at P < 0.05 level.\n\nWe found that fecal bacteria from IBD dogs already bound both IgA and IgG subclasses of Ig at significantly higher levels and extensive than bacteria from normal dogs (IgA; P = 0.018, IgG; P = 0.0002).\n\nInterestingly, there was no correlation between % Ig-bound bacteria and the degree of scoring index (Canine IBD Activity Index; CIBDAI; 6.8 \u00b1 3.73 (mean \u00b1 SD), r = 0.19 and Canine Chronic Enteropathy Clinical Activity Index; CCECAI; 8.2 \u00b1 4.2, r = 0.27). Moreover, our results suggested that the IgG which bound to gut bacteria was mainly derived from local mucosal immune activity; not systemically; since serum incubation with E. coli isolates was not different between IBD and healthy animals.\n\nIn addition, when compared to bacteria from normal control animals, IBD fecal bacteria significantly stimulated higher levels of phagocytosis in canine primary macrophage (P = 0.02) as well as in DH82 cells; canine macrophage tumor cell line (P = 0.04). The upregulation of surface activation markers (MHC II, CD40, CD86 and CD80) in response from both groups was comparable. Phagocytosis of IBD gut bacteria activated macrophages and stimulated higher production of TNF-\u03b1 than normal gut bacteria (P = 0.047). In contrast, IL-10 production from primary macrophages incubated with IBD fecal bacteria was significantly decreased compared to normal flora from healthy dogs (P = 0.045).\n\nOverall, the results showed that IBD dogs had higher Ig-bound fecal Fecal samples were obtained from healthy dogs (n = 24) and dogs with acute diarrhea (n = 11). DNA was extracted for analysis of major bacterial groups by qPCR, and a targeted gas chromatography-mass spectrometry assay was used to quantify fatty acid, sterol, and bile acid concentrations in feces. A dysbiosis index was calculated based on the abundances of major bacterial taxa (DI; reference limit < 0 with values \u2265 0 indicating dysbiosis). Statistical analysis was performed using Mann Whitney tests with significance set at p < 0.05.\n\nFecal concentrations of stearic acid (p = 0.018), arachidonic acid (p < 0.001), and nervonic acid (p = 0.037) were increased in dogs with acute diarrhea compared to healthy dogs. Cholesterol (p = 0.018) concentration was increased, while coprostanol (p = 0.047), campesterol (p = 0.002), stigmasterol (p = 0.029), fucosterol (p < 0.001), \u03b2-sitosterol (p < 0.001), and sitostanol (p < 0.001) concentrations were all decreased in dogs with acute diarrhea. The ratio of secondary bile acids to total bile acids concentration was decreased in dogs with acute diarrhea (p = 0.039). The dysbiosis index was significantly increased in dogs with acute diarrhea (p < 0.001) compared to healthy dogs.\n\nIn conclusion, our results suggest that numerous metabolic changes occur concurrently with alterations of the microbiota in dogs with acute diarrhea. Fecal metabolite patterns in some dogs with acute diarrhea resemble those found in humans with bile acid or fatty acid diarrhea.\n\nIn humans, mice and pigs, Paneth cells locate in crypts close to intesti- In the present study, we performed a targeted re-sequencing of the two Mb region on Ch11, including all 10 of the newly identified candidate genes, using a custom-designed sequence capture array (SelectSure XT custom 0.5-2.9 Mb, Agilent).\n\nIn brief, a hybridization DNA library was prepared using the selectSure XT Library Prep Kit (Agilent) following the manufacturer instructions.\n\nThe targeted region on Ch11, 1Mb up-and downstream of the most significant SNPs, was captured using the custom-designed sequence capture array (SelectSure XT custom 0.5-2.9 Mb, Agilent). Subsequently, captured libraries were indexed and subjected to DNA sequencing on Illumina platform, followed by alignment/mapping to the canine genome (CanFam3.1). Haplotypecaller was used to call variants, followed by hard-filtering extracted SNPs and Indels as recommended in GATK's best practices. SNPs were annotated using the SNPEff and Variant Effect Predicting (VEP) tools. The variants were divided into different groups based on genomic coordinates. The SNPs present only in cases (diagnosed with IBD), controls as well as overlapping SNPs with different alternative alleles in case vs control groups were further investigated.\n\nIn the control group, 1 known missense SNP was identified in exon 1/10 of the SLC22A5 gene, which has been identified to be associated with IBD using both approaches. This SNP was present in 7/20 con- In the case only group, we found one missense SNP (moderate impact, deleterious based on SIFT score) and one in the splice region (low impact, with 1/28 cases sequenced). Seventeen SNPs (5 known and 12 new ones) were identified within 1kb upstream of gene TSS coordinates and 32 SNPs (7 known and 25 new ones) downstream. Two of these SNPs with modifier impact were located within 1kb upstream of IL-3, a hematopoetic cytokine driving the development of myeloid stem cells, which was previously identified to be associated with IBD in both approaches that we used (enrichment and list of genes involved in human IBD). Two SNPs were found downstream of PDLIM (a protein with cysteine-rich double zinc fingers involved in proteinprotein interaction and cytoskeletal organisation) and IL-13 (involved in IgE synthesis, chitinase up-regulation and hyperresponsiveness of mucosal surfaces) and one new SNP was found downstream of IL-4.\n\nInterestingly, all these genes have also been associated with a higher risk of development of human IBD.\n\nIn summary, we have identified several SNPs in the genes for canine IL-3, IL-4, IL-13 and PDLIM, which, based on the known function of their corresponding proteins, further our insight into the pathogenesis of IBD in GSDs. Medical records of 300 cats that received a RBC transfusion and/or major crossmatch between January 1, 2013 to December 31, 2016 were reviewed retrospectively. Information recorded included previous transfusion history, major and minor crossmatch results (tube method), volume of pRBCs administered, pre-and post-transfusion PCV, adverse events, and patient outcome. For 10 cats, a crossmatch was performed using both the gel and tube methods for comparison.\n\nRBC compatibility data was available for 154 transfusion na\u00efve cats, 23 (14.9%) of which showed some degree of incompatibility (1+ to 3+ hemagglutination) on the major crossmatch to 1 or more donors. Of 55 cats previously transfused, 15 cats (27%) were incompatible (1+ to 2+ hemagglutination) on the major crossmatch to 1 or more donors, significantly more than in the transfusion na\u00efve group (P = 0.042).\n\nPacked RBC transfusions were administered to 249 cats, and a tube crossmatch was performed for 167 cats (67%) prior to their first pRBC transfusion; the remaining 82 cats received type-compatible, noncrossmatched pRBCs. The median volume of pRBCs administered during the first transfusion was 5.3 mL/kg (range, 2.4-18) . The median increase in PCV post-transfusion was 5%; cats receiving crossmatchcompatible pRBCs did not have a greater increase compared to those without a crossmatch. Febrile transfusion reactions occurred more often in cats that received typed, non-crossmatched pRBCs (n = 8) than cats administered crossmatch-compatible pRBCs (n = 4) (P = 0.022). Of the 246 cats receiving pRBC transfusions, 188 (76.4%) survived to hospital discharge. A pre-transfusion crossmatch was not associated with improved survival to discharge or at 30 or 60 days post-transfusion.\n\nA crossmatch was performed using both the tube and gel method for 10 cats (total of 31 crossmatches). For 9 recipient cats (24 crossmatches), there was agreement between results of the tube and gel methods, with the exception of 1 cat having a 2+ and 3+ major incompatibility to the same donor with the tube and gel methods, respectively, likely a result of the subjectivity of grading. Differing results observed for 1 cat, with a negative tube but 4+ mixed field agglutination gel result for autocontrol and major crossmatch tests with 3 donors, were attributed to marked rouleaux. Microscopic evaluation and saline replacement during the tube crossmatch supported an interpretation of rouleaux rather than hemagglutination.\n\nRBC incompatibility noted in 15% of transfusion na\u00efve cats suggests that the prevalence of naturally occurring non-AB RBC alloantibodies is sufficiently high to justify the recommendation to perform a blood crossmatch prior to all (including the first) RBC transfusions in cats.\n\nThe Use of High-Dose IgM-Enriched Human Immunoglobulin in Canine Immune-Mediated Hemolytic Anemia Dogs diagnosed with primary IMHA at UK specialty hospitals were prospectively enrolled. All dogs received prednisolone or dexamethasone alongside clopidogrel. Patients were randomized to receive Pentaglobin \u00ae at 1g/kg on up to two occasions, or a control group. No additional immunosuppressive drugs were allowed within the first 7 days of treatment and other supportive treatments were given at the discretion of the attending clinician. Remission was defined as a stable PCV for 24 hours.\n\nTen of 11 dogs from the treatment group and 2 of 3 dogs from the control group achieved remission and survived to hospital discharge.\n\nSurvival and time to remission were not significantly different between groups. The volume of packed red blood cells transfused, normalized for body weight, was not significantly different between groups. Potential adverse reactions to Pentaglobin \u00ae occurred in two patients but clinical signs may have been related to the patients'; underlying disease. Treatment with high-dose Pentaglobin \u00ae was well tolerated by patients but no significant advantage was found in this small study.\n\nLarger studies are warranted to identify any potential benefits. test at the end of the 2 week rotation. Immediately following the pretest, the treatment group received the learning module and module satisfaction survey. The survey asked students to rate their level of agreement to 10 statements on a 1-5 scale (1= strongly disagree to 5=strongly agree). All students were asked to complete an optional retention test, composed of questions from the pre and posttests, 1 month later.\n\nA total of 45 students completed both the pre and posttests and were included in the study. Of these students, 23 were in the treatment group and received the module and 22 were in the control group.\n\nThirty-three of the 45 students (73%) also completed the retention test (18 from the treatment group and 15 from the control group).\n\nStudents in the treatment group scored significantly higher on the posttest (p < 0.001) and retention test (p = 0.002) than those students that did not receive the learning module. Mean post test scores were 73.8% and 56.1% and mean retention test scores were 71.2% and 46.6% for the treatment and control groups respectively. Nineteen of the 23 students (83%) in the treatment group completed the satisfaction survey. Students taking the survey indicated that the module was easy to use (mean 4.89), that information was presented in a clear manner (mean 5), and 89% of students agreed that the module was a good use of their educational time (mean 4.73).\n\nIn conclusion, a transfusion reaction instructional module can be deliv- analyzer. If pH was less than 6.5, then pH was measured by standard pH meter. All units were evaluated for \"swirl\" and evidence of visual clumping. Platelet size distribution was evaluated by Flow cytometry.\n\nBoth apheresis protocols were managed without adverse reaction to the donors. Immediate post apheresis counts confirmed a consistent harvest of 1.0 x 10 11 +/-1.2 x 10 6 by both devices. Red blood cell contamination was less than 0.6 x 10 6 /ul. White blood cell counts were less than 6.0 x 10 2 . Platelets prepared by the Haemonetics technique had a decrease in pH and increase in lactate when compared to platelets prepared by the Terumo technique. However, this difference was not statistically significant. Flow cytometric evaluation suggested a higher population of platelets in the 2.53-5.0 micron size range in the concentrates prepared by the Haemonetics technique. There was no significant difference between techniques using standard methodology for evaluation. Both techniques provided platelet concentrates that met acceptance criteria for standard apheresis units.\n\nMaria Lyraki 1 , Miss Alice Sloan 2 , Ian Ramsey 2 1 Small Animal Hospital, University of Glasgow, Langford, Bristol, England, United Kingdom, 2 Small Animal Hospital, University of Glasgow, Glasgow, Scotland, United Kingdom\n\nTo evaluate ear prick sampling as a possible alternative to venous sampling using a point-of-care (POC) meter for the assessment of haemoglobin (Hb) and haematocrit (Hct) in dogs.\n\nSimultaneous venous and ear prick blood samples were collected from 53 dogs that were considered to be anaemic (n = 17), non-anaemic (n = 30), or polycythaemic (n = 6) and were undergoing blood sampling as part of their clinical investigation. Hb and Hct were measured on both samples using a POC meter that requires a 2 microliter sample volume and which has been previously validated in our hospital and shown to have a correlation (r) of 0.96 with standard laboratory analysers and a co-efficient of variation of less than 5 %. Hb and Hct measurements were also obtained from the venous samples using one of two reference analyzers in 40 of the dogs. Pearson';s correlation co-efficient was calculated for the two sets of POC results and the bias calculated (and expressed as mean +/-standard deviation).\n\nIn agreement with previous studies, the POC results for Hb and Hct from the venous samples were significantly correlated with the laboratory analysers (0.98 and 0.97 respectively). The results for Hb and Hct from the ear prick samples when measured using the POC device were significantly correlated with the POC results of the venous samples (r = 0.93 for both). The calculated biases were 0.17g/l (+/-1.56) for the Hb and 0.36% (+/-4.6) for the Hct respectively, which is consistent with the small degree of peripheral haemoconcentration. However, in 8 of the 53 (15 %) samples the peripheral sample was more than 15 % different from the venous sample, a difference that could have been clinically significant (see Figure 1 ).\n\nThe measurement of Hb and Hct using a simple ear prick test with a POC meter that requires a small sample volume may be a useful alternative to conventional venous blood sampling for the evaluation of these parameters in dogs, however there is a small positive bias and some clinically significant variation. PT and TEG analysis with four activators, RapidTEG, 1:100 tissue factor (TF100), 1:3700 tissue factor (TF3700), and kaolin, were compared. Spearman correlation coefficients were calculated between ratios (peak to baseline PT; peak reaction time (R) of TEG to baseline R of TEG) and anti-Xa concentration.\n\nOral rivaroxaban administration exhibited predictable anticoagulant effects and was well tolerated by healthy dogs. There were no clinical FIGURE 1 A Bland-Altman plot comparing the average Hb concentration (g/dl) with the difference between the Hb concentration when measured using venous and peripheral blood signs of minor or major hemorrhage and gastrointestinal side effects in any dosing groups. The highest anti-Xa value and longest delayed R of TEG and PT were observed 3 h after the administration of rivaroxaban; however, the anticoagulant effect in TEG and plasma rivaroxaban concentration decreased significantly from 8 h after administration.\n\nInter-individual differences in drug effects were observed as expected, and further experiments to monitor the anticoagulant effects were performed. The results showed that the anti-Xa concentration and point-of-care PT ratio were strongly correlated (R = 0.82, P < 0.001).\n\nR ratios of RapidTEG-TEG, TF100-TEG, and TF3700-TEG showed a significant correlation with rivaroxaban concentration measured using the anti-Xa assay (R = 0.76, P < 0.001; R = 0.82, P < 0.001; and R = 0.83, P < 0.001, respectively). fibrinogen. Due to wide inter-individual variations in plasma FVIII and VWF levels among healthy dogs, there is concern about uniformity and standard potency of CRYO to treat dogs with hemophilia A or VWD. While Greyhounds are commonly used as blood donors, previous studies have documented lower plasma VWF and fibrinogen content in Greyhounds compared to non-Greyhounds. Greyhound plasma, therefore, may not yield high potency CRYO. The objectives of this study were to determine if: 1) plasma hemostatic protein content is a good predictor of CRYO potency; 2) there is a difference in quality of CRYO prepared from Greyhounds versus non-Greyhounds; and 3) canine CRYO produced by our protocol meets human blood banking standards.\n\nA 450 mL unit of blood was collected from 20 Greyhounds and 20 non-Greyhounds enrolled in a blood donor program. CRYO was prepared from fresh frozen plasma (FFP) using standard methods; all blood component volumes were recorded. Aliquots of FFP and CRYO from each unit were analyzed for FVIII, VWF, and fibrinogen content.\n\nRecovery, the percentage of total factor content in FFP retained in CRYO unit, was calculated for each factor.\n\nThere was a positive correlation between FVIII, vWF and fibrinogen concentration in FFP and their respective factor content in CRYO (P < 0.0001, \u03c3 0.723-0.763). Median recovery was greatest for VWF (65%), followed by fibrinogen (49%) and FVIII (33%), with no differences between Greyhounds and non-Greyhounds. There was no difference in median FVIII (95 and 94 IU/unit) or vWF (210 and 264 IU/unit) content of CRYO units when comparing Greyhounds and non-Greyhounds, respectively. However, median fibrinogen content in CRYO was less in Greyhounds (223 mg/unit) compared to non-Greyhounds (332 mg/unit) (P = 0.0005). Nevertheless, there was no difference between Greyhounds and non-Greyhounds for the number of CRYO units meeting human blood banking standards for any of the 3 hemostatic proteins: VWF, 19 Greyhounds and 18 non-Greyhounds (CRYO from 2 VWF-deficient Dobermans did not meet standard); fibrinogen, 17 Greyhounds and 20 non-Greyhounds; and FVIII, 8 Greyhounds and 11 non-Greyhounds.\n\nIn conclusion, the factor content in donor FFP is strongly associated with CRYO potency, suggesting that pre-screening of blood donors may enhance CRYO quality. CRYO prepared from Greyhounds is not inferior to that from other breeds, justifying use of their plasma for This retrospective study included the following dogs: 90 with SIRS, 50 healthy, 50 with chronic diseases. SIRS grading was based on how many criteria were fulfilled. APPLE fast score was allocated in SIRS dogs. Mortality rate was assessed at 7 and 15 days after admission.\n\nHemolytic or hemorrhagic disorders were excluded. SIRS grading and APPLE fast score groups were compared to the outcome. Types of anemia and NRBCs counts were evaluated in three study populations and to the outcome. APPLE fast scores >25 (p = 0.03) and SIRS grading >2 (p = 0.001) were associated with poor outcome. In SIRS group, anemia was present in 56/90 dogs. The most frequent types of anemia were mild (45%) or moderate (43%), microcytic (55%) or normocytic (41%), and normochromic (93%). Anemia and its severity were associated with poor outcome (p = 0.0197). SIRS group showed worse anemia patterns than the other two groups (p < 0.001). The presence of NRBCs occurred in 22/90 of SIRS dogs and was associated with poor outcome (p = 0.005). NRBCs count were significantly higher in the SIRS group than healthy dogs (p = 0.0007).\n\nMild-moderate, micro-normocytic normochromic anemia is a frequent finding in canine SIRS. Our results suggest that circulating NRBCs and their amount could be an additional negative prognostic value. and delayed relapse (remission period of >60 days, n=10), the tapering rate of prednisolone was significantly higher for the acute relapse episodes than for both the delayed relapse and non-relapse episodes (P=0.04 and P=0.01, respectively).\n\nThese results suggest that a rapid decrease in the prednisolone dosage can cause early recurrence of pIMT.\n\nSarah Shropshire, Christine Olver Colorado State University, Fort Collins, CO, USA Greyhounds have several hematologic differences from other breeds of dogs, including higher hematocrit and hemoglobin concentration and lower neutrophil and platelet counts. It has also been observed that some Greyhounds have a propensity to bleed excessively 36-48 hours following minor traumas or routine surgeries. The exact etiology behind this bleeding is unknown however several studies have postulated this may occur due to hyperfibrinolysis. Dynamic viscoelastic testing using thromboelastography (TEG) allows for not only assessment of coagulation but also fibrinolysis. TEG has been performed previously in Greyhounds but no study has investigated fibrinolysis variables via TEG in the presence of tissue plasminogen activator (tPA) in healthy Greyhounds. Therefore, the purpose of this study was to evaluate if Greyhounds appear hyperfibrinolytic as compared to non-Greyhounds.\n\nTissue factor-activated TEG with tPA added (TF + tPA-TEG) was performed in six healthy client-owned Greyhounds and six healthy laboratory Beagles. For TF + tPA-TEG, reaction time (R), clotting time ( The \u03b1, MA, MRTG, TG, platelet count and fibrinogen were significantly lower and the K and hematocrit were significantly higher in the Greyhounds. There were no statistical differences for R, LY30, CL30, LY60, CL60, TMRTG, MRL, TMRL and CLT between the groups.\n\nAs noted in previous studies, the Greyhounds had higher hematocrits and lower platelet counts as compared to non-Greyhounds. Greyhounds appeared significantly hypocoagulable (increased K and decreased \u03b1, MA, MRTG and TG) but did not appear hyperfibrinolytic as compared to non-Greyhounds. It is possible that hyperfibrinolysis in Greyhounds may not be related to responsiveness to tPA or that hyperfibrinolysis is not detected via TF + tPA-TEG in the preoperative setting and cannot be used to predict bleeding. Additional studies are warranted to further investigate the mechanism of bleeding appreciated in this breed.\n\nSarah Shropshire, Christine Olver Colorado State University, Fort Collins, CO, USA Whole blood impedance platelet aggregometry can be performed with several different agonists to evaluate platelet function. Although the manufacturer recommends disposal of stored reagent after 1 month, the viability after reconstitution of these reagents under different storage conditions is unknown. If the reagent viability is stable for long periods of time, assay costs could be decreased dramatically.\n\nTherefore, the purpose of this study was to determine the viability of reconstituted arachidonic acid (AA) and adenosine diphosphate (ADP) platelet agonists stored under two conditions up to 6 months. 60\u03bcl aliquots of reconstituted AA and ADP were stored at -20 C and -80 C monthly for six months. Six healthy staff-owned dogs were enrolled for the study. A physical examination, complete blood count (CBC), diagnostic panel, and urinalysis were performed in all enrolled dogs. Platelet aggregometry was performed on all dogs using fresh and stored aliquots of AA and ADP reagents on the same day. The area under the curve (AUC) was recorded from each platelet aggregometry analysis. Repeated measures (RM) analysis (one-way ANOVA) was performed and subsequent time points (1, 2, 3, 4, 5, 6 months) were compared to fresh AUC results.\n\nAll dogs appeared clinically healthy and the CBC, diagnostic panel, and urinalysis were normal. There were no differences in the AUC obtained from fresh samples at any time point or at either temperature for AA or ADP.\n\nIn dogs, the whole blood impedance platelet aggregometry reagents AA and ADP are viable for up to six months when stored at -20 C or -80 C. We conclude that these reagents can be stored up to 6 months, obviating the need to discard viable reagents, and decreasing assay cost. The objective of this study was to measure cytokine/chemokine concentrations after LR and IR in canine stored whole blood. Red blood cell (RBC) storage lesion caused by irradiation and LR were compared.\n\nBlood samples were obtained from 10 healthy Beagle dogs. The collected blood samples were divided into four groups of 10 samples each (no treatment, LR, IR, and LR + IR). Leukocytes were removed by filtration in the LR group and gamma radiation (25Gy) was applied in the IR group. Immunologic factors (WBCs, interleukin-6 [IL-6], C-X-C motif chemokine ligand 8 , and tumor necrosis factor-alpha [TNF-\u03b1]) and storage lesion factors (blood pH, potassium and hemolysis) were evaluated on days 0, 7, 14, 21, and 28 from aliquots of each group.\n\nIL-6 and CXCL-8 concentrations in control (no treatment of stored whole blood) were significantly higher during storage, which indicates a high probability of transfusion reactions such as FNHTR. On the other hand, the LR group did not show changes in cytokine/chemokine concentrations, and the storage lesion was relatively mild compared to that in other groups. Irradiation significantly increased CXCL-8 after 14 days of storage, but irradiation of leukoreduced blood did not increase CXCL-8 during 28 days of storage. However, storage lesions such as hemolysis, increased potassium, and low pH were observed 7 days after IR of blood, regardless of LR.\n\nIn conclusion, LR is beneficial in preventing transfusion reactions and storage lesion. However, IR of canine whole blood was not suitable for long-term storage because of increasing factors of CXCL-8 and storage lesion. IR of leukoreduced blood is beneficial to avoid immune reaction, however, storage lesion should be considered upon storage. Results of these studies identify that a majority of normal and diseased dogs harbor a rich and diverse bile microbiome. This microbiota is likely to contain previously unrecognized beneficial as well as deleterious bacteria. Tailoring bile culture media to routinely identify these bacteria is likely to improve our understanding and diagnosis of canine hepatobiliary disease. The objective of this study was to determine whether increases in these potential biomarkers were associated with moderate to severe fibrosis or necroinflammatory activity in dogs with various hepatopathies. Forty-four client-owned dogs with clinical evidence of liver disease and 10 healthy purpose-bred dogs were enrolled, all undergoing liver biopsies by laparoscopy or laparotomy. Serum IL-6, CCL2, CRP, AST and ALT were measured within one week before scheduled liver biopsy; liver histopathology was evaluated using the METAVIR scoring system used in human medicine, blinded to clinical presentation. Median serum IL-6 was approximately twice as high in dogs with high fibrosis scores (15.5 pg/ml; range, 1.4 to 235 pg/mL) compared to dogs with low fibrosis scores (7.6 pg/mL; range, 1.4 to 148.1 pg/mL), with marginal significance (P = 0.05).\n\nMedian serum CCL2 was significantly higher in dogs with active necroinflammation (444 pg/mL; range, 144 to 896 pg/mL) compared to dogs without detectable necroinflammation (326 pg/mL; range, 59 to 1692 pg/mL; P = 0.008), but with considerable overlap between groups. Neither serum CRP nor AST:ALT ratios were significantly different based on fibrosis or necroinflammatory scores. Descriptive statistics were used to analyze categorical variables (age, gender, breed, side effects to Cys) and continuous variables (Cys dose, time to remission, ALT concentration). Means, medians, ranges, and standard deviations were calculated for continuous data. Wilcoxon, Student t-test, Fisher';s exact test, or survival analysis was used to evaluate the impact of prognostic factors (pre-treatment clinical scores, hypoalbuminemia, hyperbilirubinemia, ascites, fibrosis on histopathology, prolonged PT/aPTT) on remission.\n\nTwenty-five different breeds were represented. Ages ranged from 0.7-14 years (median 8.0 years). Fifty-two percent were female spayed and 43% were male castrated. The most common treatment side-effects were gastrointestinal signs, which ranged from mild inappetence to vomiting and diarrhea in 44% (22/50) and gingival hyperplasia in 26% (13/50). Seventy six percent (38/50) achieved remission with a median time to remission of 2 months (0.75-12 months). The median dose at the time of remission was 7.8 mg/kg/ day (1.5-12.7 mg/kg/day). No association was found between prognostic factors and remission with the exception of hypoalbuminemia. There was an increased likelihood of remission (p < 0.05) and a decreased time to remission in dogs with hypoalbuminemia (p < 0.05).\n\nIn conclusion, Cys therapy was tolerated and effective in achieving normalization of ALT in dogs with presumed immune mediated CH. Previously reported prognostic factors did not negatively impact the ability to achieve ALT normalization with Cys therapy.\n\nLesli Kibler, Cailin Heinze, Cynthia Webster Cummings School of Veterinary Medicine,Tufts University, North Grafton, MA, USA\n\nThe liver performs an essential role in metabolism of vitamin D (VD); deficiency of vitamin K, another fat-soluble vitamin, is common in cats with cholestatic hepatobiliary disease (CHD). We hypothesized that VD levels in cats with CHD would be significantly lower than in normal cats or sick cats with non-hepatobiliary disorders. A prospective case control study was done comparing cats with CHD disease (defined by hyperbilirubinemia and increased alanine aminotransferase), sick cats without hepatobiliary disease, and normal cats repre- Sixty-nine studies, including seven conference abstracts, reporting perioperative and/or clinical and/or surgical/interventional outcomes of dogs managed with one surgical/interventional technique and/or medical management for cEHPSS were identified. Only 19 studies were designed as prospective studies, including one non-blinded randomized controlled clinical trial, one non-blinded non-randomized controlled clinical trial and 17 uncontrolled clinical trials. The majority of the studies showed overall high risk of bias and evaluated low to very low numbers of cases per treatment group (67%) but with clearly characterized subject enrolment criteria (97%).\n\nDirect comparison of ameroid constrictor versus thin film band revealed a statistically significant difference between the two techniques with regards to the surgical outcome, with ameroid constrictor being superior. Direct comparisons also suggested that ameroid constrictor placement might have a better perioperative, clinical, and surgical/interventional outcome than ligation. However, none of these comparisons were statistically significant. Direct comparison of other techniques was not possible due to lack of data. Indirect comparison suggested that ameroid constrictor placement and complete ligation were the techniques with better perioperative, clinical, and surgical/ interventional outcome, followed by thin film band, coil embolization, and partial ligation. The outcome assessment for Amplatzer vascular plug and medical management was based on small numbers of cases to allow accurate interpretations.\n\nIn conclusion, this combined systematic review and meta-analysis provides objective evaluation of the treatment options of the cEHPSS.\n\nAmeroid constrictor was shown to be the technique with the higher likelihood of providing a good outcome. Complete ligation, thin film band, coil embolization and partial ligation were shown to be effective techniques in the treatment of cEHPSS, although less than ameroid constrictor. Blinded randomized studies with low overall risk of bias and good number of cases comparing different treatment modalities that routinely include postoperative imaging to assess cEHPSS closure and/or acquired portosystemic shunts development are essential. Four dogs and two cats, tentatively diagnosed with \"infected EHBDO\", were enrolled in this study. UPC was performed, (1) cholecystocentesis, removing most of the bile to decompress the gallbladder and for cytology and culture/sensitivity; (2) less than 5 mL of Iodixanol 320 was injected into the gallbladder. Ventrodorsal, left oblique ventrodorsal, left lateral and right lateral projections of the abdomen were made 2 minutes after UPC, every 10 minutes for the first hour and every 30 minutes after until contrast medium was noted in the duodenum.\n\nAll patients had CBD dilation (4.2 -14.4 mm in diameter) . The contrast was noted in the duodenum in five patients. Only one dog was diagnosed with completely obstructed CBD given no contrast in the duodenum 4 hours after UPC. The rest was diagnosed with CBD dilation and gallbladder delayed emptying. The time for UPC was from 2 to 240 minutes.\n\nUPC is a feasible technique in patients with dilated CBD and can be used to confirm complete obstruction of CBD. Based on this study, the term \"extrahepatic bile duct disease\" should be used instead of EHBDO before further diagnostics, such as UPC.\n\nRommaneeya Leela-arporn 1 , Hiroshi Ohta 2 , Noriyuki Nagata 2 , Kazuyoshi Sasaoka 2 , Tatsuyuki Osuga 2 , Keitaro Morishita 2 , Noboru Sasaki 2 , Kensuke Nakamura 2 , Mitsuyoshi Takiguchi and May 2017 were retrospectively reviewed. To examine the breed, age, or sex predisposition of HCC, all cases that came to HUVTH during the study period were used as the reference population. Other possible related factors including clinicopathological findings and concurrent disorders of HCC were determined by comparison of two breed-and age matched control dogs and each HCC case.\n\nPrevalence of histologically confirmed HCC was 0.89% (41/4,607 cases). Dogs diagnosed with HCC was significantly older (median 11 years; range 9-15 years; P < 0.001) than reference population (median 9 years; range 0-20 years). Welsh Corgis were significantly predisposed to HCC (odd ratio [OR]: 4.13; 95% CI: 1.81-9.41; P = 0.0032). Breed-and age matched case control analysis revealed that thrombocytosis (27/40 cases; 67.5%), increased ALT (38/41 cases; 92.7%), increased ALP (39/41 cases; 95.1%), and hypercalcemia (12/32 cases; 37.5%) were significantly associated with HCC. In addition, 27 out of 41 dogs with HCC had at least one concurrent disorder. The most common concurrent disorder was hyperadrenocorticism (12 dogs), and the odds of hyperadrenocorticism in dogs with HCC were 3.36 times that of controls (95% Cl: 1.28-8.81; P = 0.020).\n\nThese findings indicated that aging increase the risk of development of HCC, and Welsh Corgis were predisposed to HCC. In addition, a significant association between HCC and hyperadrenocorticism was presented, suggesting that hyperadrenocorticism might play a role in the development of HCC in dogs. Lyme disease is endemic to some parts of North America, and is an emerging disease in others. Although tick preventives are available, vaccination is an increasingly common though controversial method used in the prevention of canine Lyme infection; reported efficacies of canine Lyme vaccines are highly variable, ranging from 50% to 100%. The objective of our research was as follows: to determine the efficacy of vaccines for Borrelia burgdorferi in North American dogs by comparing vaccinated dogs to those not receiving the vaccine. We used a systematic review and meta-analysis to address this objective.\n\nMonovalent and multivalent vaccines were considered eligible interventions. Our main outcome of interest was the reduction of clinical illness following exposure to B. burgdorferi. Outcome data were extracted as a binary outcome for the following clinical signs (assessed separately): lameness, anorexia, pyrexia, depression, lymphadenopathy. Experimental and analytical observational studies were considered eligible for inclusion. In addition to grey literature searches, the following electronic databases were searched with no language restrictions: MEDLINE, Web of Science, CAB Abstracts. The last search was performed on November 29, 2016.\n\nThirteen challenge trials and three observational studies were identified as eligible, and twelve challenge trials contained sufficient data to be included in our meta-analysis. A meta-analysis could not be performed for observational studies due to an insufficient number of studies. None of the challenge trials assessed lymphadenopathy, but for each of the remaining four clinical signs a separate random effects meta-analysis was performed. With the exception of anorexia, all summary odds ratios were less than the null value of 1. Overall, the findings of our meta-analysis suggest that North American Lyme vaccines reduce the odds of clinical illness in dogs following exposure to B. burgdorferi. However, these results should be interpreted with caution since a number of issues related to small sample size, study quality, and publication bias were identified. No experimental field trials were identified, highlighting a major gap in the literature on this topic.\n\nFuture studies should focus on larger sample sizes in field conditions. Data for 140 dogs, naturally infected with B. rossi, and 20 healthy control dogs were retrospectively evaluated. Owner consent was obtained for enrolment of each case, together with approval from the University';s Animal Ethics committee. MPXI was generated on an automated cell counter, ADVIA 2120, and cytokine concentrations were determined using a canine-specific multiplex assay.\n\nFifteen of the Babesia-infected dogs died (14 %). MPXI was significantly higher in the Babesia-infected dogs (P = 0.033), and in the nonsurvivors (P = 0.009), compared to the controls. For the dogs that died, significant correlations were found between MPXI and interleukin-2 (IL-2; r = 0.616, P = 0.033), IL-6 (r = 0.615, P = 0.033), IL-18 (r = 0.613, P = 0.034), granulocytic-macrophage colony stimulating factor (r = 0.630, P = 0.028) and monocyte chemo-attractant protein-1 (r = 0.713, P = 0.009).\n\nThese findings suggest that significant neutrophil activation is present in dogs with B. rossi infection. In addition, increased MPXI was associated with disease outcome and was correlated with the severity of the cytokine-driven pro-inflammatory host response. Observed to expected ratios for dilutional parallelism (5 samples) ranged from 108.0% to 137.6% with a mean \u00b1 SD of 117.7% \u00b1 8.3%.\n\nIntra-assay (6 samples) and inter-assay (7 samples) coefficients of variation (%CVs) ranged from 1.4% to 2.7%, and 3.4% to 5.8%, respectively. Observed to expected ratios for mixtures of two serum samples of known concentrations (15 pairs), ranged from 91.5% to 128.6% with a mean \u00b1 SD of 101.3% \u00b1 8.3%. Comparison with the Tridelta assay showed a non-linear relationship (R-squared = 0.46). This was especially apparent for values greater than 30 mg/L (reference interval < 7.6 mg/L) when measured by the Tridelta assay, where the Gentian results were higher than expected). Using the suggested cut-off values of 10.0 mg/L for the Gentian assay and 7.6 mg/L for the Tridelta assay, agreement between results was moderate (Cohen'; s kappa statistic = 0.52).\n\nThe evaluated assay (Gentian) was shown to be precise, reproducible, and accurate. A non-linear relationship with results from the comparison assay (Tridelta), especially for high concentration samples was shown. In conclusion, the Gentian assay appears to be sufficient for use but further work is needed to determine the optimal diagnostic cut-off value when using this assay.\n\nSarah Shropshire 1 , Steven Dow 2 , Michael Lappin 1 1 Colorado State University, Fort Collins, CO, USA, 2 Department of Clinical Sciences, Colorado State University, Fort Collins, CO, USA Direct flow cytometry is a technique that can be used to detect immunoglobulin-associated platelets in dogs. However, the present requirement is that samples must be processed within 24 hours for assessment in currently available assays which has limited its wide spread use. The purpose of this study was to develop a clinically applicable direct flow cytometric assay for detection of canine IgGassociated platelets expressed as percent IgG (%IgG).\n\nThe direct flow cytometry assay was first optimized and a cut-off value of \u2264 10% to differentiate negative and positive classifications was determined by serial direct flow evaluation of platelets from a healthy dog. The assay was then performed on samples from 9 healthy beagles and 12 client-owned thrombocytopenic dogs at four time points: fresh and 24, 48, and 72 hours after storage at 4 C and the % IgG was recorded. A repeated measures analysis (one-way ANOVA) was performed and storage time points were compared to fresh samples using Dunnett';s method. The average coefficient of variation (CV) was calculated for samples from thrombocytopenic dogs to evaluate intra-assay variability.\n\nUsing samples from healthy dogs, there were no differences among fresh and 24 and 48 hour samples but there was a difference between fresh and 72 hour samples. There were no differences among fresh and 24, 48, or 72 hour samples in thrombocytopenic dogs. Based on the cut-off value, healthy and thrombocytopenic dogs were consistently categorized at every time point. The average intra-assay CV for thrombocytopenic dogs was 4.32%.\n\nSince samples can be processed and evaluated within 72 hours, the assay can be used for samples that require shipping to a central laboratory. This direct flow cytometric assay is reproducible and represents an accessible and potentially clinically useful test for the detection of IgG-associated platelets in dogs.\n\nComparing RNA Quality and Quantity Extracted from Canine Blood Using Commercially Available RNA Extraction Kits Dahlia H. Tesfamichael, Jessica C. Pritchard, Michael W. Wood UW-Madison School of Veterinary Medicine, Madison, WI, USA Quantitative reverse transcription PCR (RT-qPCR) is increasingly used to study and diagnose disease in small animals. The performance of these assays relies upon first obtaining quality RNA in sufficient quantities. There are many commercially available kits optimized to extract RNA from human blood and one designed specifically for animal blood. The purpose of this study was to use stored canine blood to assess the performance of these commercially available RNA extraction kits using RNA yield and purity as benchmarks.\n\nThe RNA extraction performance of the RiboPure (ThermoFisher, Md.). Extracted RNA was stored at -80C until further analysis. Resultant RNA yield and purity were calculated using spectrophotometric absorbance peak measurements at 260nm and 280nm to determine nucleic acid concentration and assess for protein contamination.\n\nMedian RNA concentration and A260/280 were compared amongst groups with a Kruskal-Wallis test with Dunn';s test for multiple comparisons. Significance was defined as p < 0.05.\n\nRiboPure extraction resulted in significantly higher nucleic acid concentrations than the RNeasy Protect Animal Blood (p < 0.05) and\n\nRNeasy Mini (p < 0.001) kits ( Figure 1 ). There was no difference in median RNA concentration between RiboPure and TRIzol (p > 0.99).\n\nThere was no difference in the median A260/280 amongst the kits, indicating no significant differences in protein contamination during extraction. The mean A260/280 for each kit was 1.88, 1.89, 2.08, and 1.87; RiboPure, TRIzol, RNeasy Protect Animal Blood, and RNeasy Mini kits, respectively.\n\nThese results indicate that the RiboPure kit isolated the greatest quantity of genetic material. Further evaluation utilizing RT-PCR with no reverse transcriptase controls to assess for genomic DNA contamination of extracts is necessary to fully evaluate RNA purity.\n\nResearchers can use these findings to appropriately select an RNA extraction kit based on their priorities. The objective in this study was to investigate risk factors associated with development of Candida urinary tract infections in dogs and cats.\n\nEighteen dogs and eight cats with culture-confirmed candiduriawere evaluated in a retrospective case-control study to identify risk factors associated with candiduria. Control dogs and cats had bacterial cystitis or cutaneous Malassezia infection (dogs only). Univariate exact logistic regression was used to estimate odds ratios (OR) and 95% confidence intervals. P-values < 0.05 were statistically significant.\n\nAdministration of antibacterial drugs in the 30 days before diagnosis was associated with candiduria in dogs using controls with bacterial cystitis (OR 14.5; 95% CI 3.1-66.9) and with Malassezia infection (OR 26.4; . Antibacterial drug administration was also associated with candiduria in cats (OR 15.7; 95% CI 1.9-132.3).\n\nImmunosuppression was associated with candiduria in dogs when compared to controls with Malassezia infection (OR 4.2, 95% CI 1.4-12.8) but not significantly with bacterial cystitis controls (OR 2.7, 95% CI 0.9-8.0). Lower urinary tract diseases other than infection were associated with candiduria in cats (OR 6.7, 95% CI 1.6-27.9), but not significantly in dogs (OR 2.5, 95% CI 0.7-8.7). Neither diabetes mellitus nor history of hospitalization was significantly associated with candiduria in either species.\n\nRecent administration of antibacterial drug therapy was a potential risk factor for development of candiduria in this population; their judicious use may help prevent this fungal infection. Dogs within the HIP group demonstrated a lower shock index at the 12-hour mark (p =0.046), and this difference was still observable at the 24-hour mark (p =0.04). Blood lactateconcentration was lower at the 24-hour mark in the HIP dogs when compared to the placebo dogs (p =0.049), although this was not statistically different at the 48-hour mark (p= 0.10). There was no difference in duration of hospitalization between groups (p= 0.35). Overall survival was 16/16 (100%) for the HIP group, compared to 14/15 (93.3%) for the placebo group (p =0.48). HIP was well tolerated with no adverse events noted during drug administration.\n\nResults of this study indicate that hyperimmune plasma improves cardiovascular parameters during the first 24 hours of hospitalization.\n\nThis study did not identify a difference in clinical severity improvement, duration of hospitalization, or mortality when comparing HIP and placebo dogs. Future studies evaluating HIP dose, and timing of HIP administration relative to disease onset, are needed to better determine the clinical benefit of this product. This study was a retrospective prevalence case-control study. One This study demonstrates that Borrelia C6 seroreactivity in dogs with PLN is associated with a clinicopathologically distinct syndrome when compared with other types of PLN. Early recognition of this syndrome based on clinical findings has the potential to improve outcomes through specific aggressive and early treatment. We therefore aimed to evaluate the clinical need for antibiotics in a common condition where it is suspected primary-care veterinarians overuse antibiotics. We chose to study haemorrhagic diarrhoea in dogs, where two antibiotics are often administered as standard. Both amoxicillin-clavulanic acid and metronidazole are typically prescribed to severe cases of haemorrhagic diarrhoea, but there is no evidence that this is beneficial to the patient.\n\nA clinical trial was designed to determine whether dogs with haemorrhagic diarrhoea had an improved clinical outcome when receiving both amoxicillin-clavulanic acid and metronidazole, or whether administration of amoxicillin-clavulanic acid alone was sufficient. Dogs presenting to a private primary-care veterinary hospital with haemorrhagic diarrhoea < 3 day duration were recruited to an ethically approved, prospective, placebo controlled, blinded treatment trial with owner consent. Cases were randomised to receive either metronidazole or saline in a blinded manner, in addition to receiving standard supportive therapy; amoxicillin-clavulanic acid, intravenous fluid therapy, analgesia and a gastroprotectant. Diagnostics were performed in accordance with the usual primary-care practice protocol; routine haematology and biochemistry but no faecal C&S. The efficacy of treatment was assessed by the duration of hospitalisation, and daily clinical progress was measured by a clinical scoring system.\n\nBetween Feb 2016 and Jan 2018, 34 dogs successfully completed the clinical trial. For cases receiving metronidazole, the average duration of hospitalisation was 29.6hr (SD 15.4hr) . For the saline placebo this was 26.3hr (SD 11.5hr). There was no significant difference between the two patient groups. All dogs in the trial showed a significant improvement in daily clinical score between day 1 (admission) and day 2 (p < 0.001), but there was no statistically significant difference between the daily clinical scores when comparing the patient groups.\n\nIn summary, this clinical trial has two valuable conclusions. First, by demonstrating that two antibiotics are not necessary for treatment of haemorrhagic diarrhoea we have shown that antibiotic usage can be safely reduced in these patients. Second we have proven that rigorous clinical trials can be performed in primary-care practice in the absence of extensive diagnostics. It is hoped that similar trials examining possible overuse of antibiotics in other common conditions will be conducted in the future. Over the three 3-year periods, prevalence of FIV increased from 4.8% to 6.0% (p = 0.31) and the prevalence of FeLV decreased significantly from 1.6% to 0.3% (p < 0.03). For each year of the study, there were significantly more FIV-positive males than females (p < 0.01). Despite a 60% decrease in admissions in the third period, the prevalence of FIV for males remained similar across the years (p < 0.08), and increased for females, suggesting that FIV testing should continue among free-living community cats in San Mateo County. All participants reported being aware of Lyme disease; however, none reported that a family or household member had been diagnosed with Lyme disease. The majority of respondents stated that they knew the cause of Lyme disease (92%) and correctly identified a tick as the vector of Lyme disease. However, only half of respondents actively tried to prevent tick attachment on themselves (56%), with 29% sometimes doing so, and 23% not trying to prevent tick attachment. Similarly, only 21% of respondents undertook non-chemical efforts (e.g. trimming of brush or shrubs) to reduce ticks on their property.\n\nDespite a high awareness of Lyme disease, few of the respondents recalled their human health care provider ever discussing Lyme disease (7%). Most (97%) did not recall ever receiving information about Lyme disease from any human health care source.\n\nThe majority of respondents recalled tick prevention being discussed by their veterinarian (95%) and were administering a tick prevention product to their dog (85%). Puppies were reported to be vaccinated for Lyme disease by 40% of respondents, while 15% were not certain if vaccination had occurred.\n\nBaseline vector-borne disease testing (SNAP 4Dx\u00ae Plus\u00ae Test) for all 4 pathogens has been negative for all enrolled puppies to date (n =120).\n\nThis evaluation of baseline test results and confirmation of high petowner knowledge of Lyme disease will form the basis for ongoing and future research efforts utilizing this unique study population. Day 3, 7, 10, 14, 17, 21, 28, 35, 42, 49, and 56 . Ocular lesions or systemic signs of disease were not recognized. Oocysts were seen in the feces of one cat on Day 46.\n\nOne cat developed both IgM and IgG antibodies on Day 17; one cat developed IgG antibodies alone, first detected on Day 28, and one cat developed both IgM and IgG antibodies on Day 28. The IgG antibodies persisted through the experiment. The results confirm that cats that ingest sporulated T. gondii oocysts can become infected but shed lower levels of oocysts and have delayed seroconversion when compared to historical controls who were fed tissue cysts. The samples collected will be used in the sporozoite antibody assay titration and an ongoing study of naturally exposed cats.\n\nComparison of Immediate versus Delayed Streak Plate Inoculation of Urine Bacterial Culture and Sensitivity Testing commonly transported to external reference laboratories prior to inoculation of culture media. The objective of this study was to compare the results of bacterial culture and sensitivity testing of canine and feline urine samples when streak plate inoculation is performed immediately after sample collection versus when streak plate inoculation is delayed until arrival at a reference laboratory.\n\nThis was a prospective, observational study that included urine samples from 194 canines and 45 felines submitted for routine urinalysis and urine culture and sensitivity testing. Streak plate inoculations of urine samples were performed immediately after sample collection, and again after receipt by an outside reference laboratory. Culture and sensitivity results were compared. Additional data collected included signalment, comorbidities, presence of lower urinary tract signs, urinalysis results, and antimicrobial history.\n\nOverall agreement between immediate and delayed culture was 87%. Serum sI-CAM-1 was measured using a commercial ELISA-kit (SEA548Ca; Brunschwig) and results compared between groups using the Kruskal-Wallis Test. Associations between sI-CAM-1, disease group and outcome were tested using logistic regression analysis. The diagnostic accuracy of day 1 sI-CAM-1 to predict the occurrence of LPHS was tested using ROC curve analysis.\n\nMedian sI-CAM-1 serum concentrations were significantly higher in dogs with AKI (43.6 ng/ml, n = 18) and in dogs with LPHS (64.2 ng/ml, n = 14) compared to heathy controls (15.8 ng/ml, ; n = 31; p < 0.001). Median sI-CAM-1 was higher in dogs with leptospirosis without LPHS (37.6 ng/ml, IQR 20.9-53.4, n = 10) compared controls, and lower than in the LPHS group, but these differences did not reach statistical significance. Few day 3 samples were available for analysis, but showed similar trends with highest sI-CAM-1 in dogs with LPHS (87.5 ng/ml, IQR 44.1-101.7; n = 5) compared to healthy controls, dogs with AKI (21.9 ng/ml, IQR 10. 5-71.3; n = 5) and leptospirosis without LPHS (26.2 ng/ml, IQR 23. 2-29.3; n = 2) . However, only the difference between healthy and LPHS group was statistically significant (p = 0.015). There was no significant association between sI-CAM-1, disease group and outcome. Day 1 sI-CAM-1 predicted the development of LPHS with reasonable accuracy (AUC 0.79; sensitivity 79%, CI 49-95; specificity 73%, CI 60-84).\n\nThese findings suggest, that in the context of leptospirosis, overexpression of endothelial ICAM-1 may be associated with the development of pulmonary hemorrhage. We examined data from a regional human pediatric medical center (2010) (2011) (2012) (2013) (2014) (2015) (2016) , and from a veterinary clinical laboratory and a veterinary reference laboratory (2002) (2003) (2004) (2005) (2006) (2007) (2008) (2009) (2010) (2011) (2012) (2013) (2014) (2015) (2016) (2017) . We focused on urinary isolates from pediatric and canine populations to compare resistance patterns most common in each and to examine for the emergence of similar resistance patterns. We examined the resistance of E. coli urinary tract isolates to five major classes of antibiotics from dogs and children. We further examined the prevalence of phenotypic resistance patterns to combinations of drug classes.\n\nWe found that in canine urinary isolates, the prevalence of E. coli resistance to the class representatives of third generation cephalosporins (ceftiofur) was higher than resistance of human urinary isolates to ceftriaxone. We did not detect, however, an increasing rate of resistance in the canine isolates over the study period. The prevalence of the phenotype commonly associated with E. coli isolates of the ST131 clonal lineage, featuring resistance to both cephalosporins and quinolones, was also more common in the companion animal isolates compared to the human isolates.\n\nOur findings suggest a higher rate of E. coli resistance to third generation cephalosporins is found in canine patients compared to human pediatric patients. While this difference could be due to differences in Of the feline fecal flotation tests performed, 3,949 (0.13%) were positive for the presence of A. abstrusus larvae. In addition, 65 (2.3%) of the Baermann tests conducted were also positive. As reported in other studies, age was a significant risk factor with cats 1 to 12 months having a relative risk of 5.72 (95% confidence interval: 5.30-6.18, P < 0.0001) compared to cats older than 12 months. In contrast, there was no association observed between infection status and sex. Significant variation in Overall 5.0%, 6.8%, and 3.9% of sera were ELISA reactive to The results to date suggest that dogs with primary exposure to this dose and strain of H3N2 will be contagious for up to 5 days. The goal of this study was to evaluate the indications, dosing, potential adverse effects, and survival to discharge in dogs and cats treated with vancomycin. An additional goal was to evaluate if vancomycin treatment was based on current recommendations and best practices.\n\nRecords were retrieved using the keyword \"vancomycin\" and retrospectively reviewed.\n\nRecords from thirty-three dogs and eight cats were reviewed. The most common indications for vancomycin included infections involving the integument (10/41, 24.4%) or hepatobiliary systems (8/41, 19 .5%), endocarditis (6/41, 14.6%) , and infected orthopedic implants (6/41, 14.6% The medical records data base (IDEXX) was searched for feline cases that had blood evaluated in a PCR assay that amplifies DNA of Bartonella spp. and also had results available from a complete blood cell count completed concurrently. The cases were first classified as those being tested as blood donors and those that were suspected to be clinically ill and then samples from states with low risk for C. felis were Since other clinical information like use of flea control or antibiotics are not available, these results should be interpreted carefully. In addition, the estimated Bartonella spp. prevalence data from the blood donor cats was likely lowered by selection of cats of low risk. However, the results seem to confirm those of other smaller studies that failed to link Bartonella spp. to anemia in cats. Further studies will be required to confirm the weak association between Bartonella spp.\n\nDNA in blood and the presence of thrombocytopenia. The pradofloxacin protocol used in this study was well tolerated. Bartonella henselae bacteremia was not detected in any cat after administration of pradofloxacin even after the administration of a dose of methylprednisolone acetate. The results suggest an antibiotic effect or that the organism was cleared spontaneously. The study should be repeated with cats infected with B. henselae by exposure to infected C. felis and cats infected in the field. (3-[4,5,dimethylthiazol-2-yl]-5-[3-carboxymethoxy- diverse, yet predictable associations between specific virulence (e.g. toxin, biofilm) and antimicrobial resistance genes can be elucidated.\n\nA collection of 79 E. coli isolates collected from canine urine samples were previously characterized for O and H antigen types, antimicrobial susceptibility, and ability to form biofilm. Here, a subset of these isolates (n = 16) were characterized using whole genome sequencing on the MiSeq platform.\n\nThirteen different E. coli sequence types were recovered; two sequence types (127 and 156) were found among multiple isolates.\n\nE. coli sequence type 156 was associated with multiple samples collected from the same patient three months apart. E. coli sequence type 127 was found in three different dogs. A number of different antimicrobial resistance genes were identified, including aac(6 0 ) lb-cr, aadA, aadB, aph(3 0 )-I, bla CMY , bla CTX-M , bla OXA , bla TEM , cat, cml, cmlA, dfrA, mph(A), strA, strB, sul1, sul2, sul3, and tet(B) . The presence of several of these genes has importance in classifying these isolates as extended-spectrum beta lactamase (ESBL) producers. Sequence type 127 which represented three isolates lacked associated resistance genes. All sequenced isolates had at least one fimbriae-associated gene, and eaeH, a gene associated with E. coli attachment was found in 15 (94%) isolates. Previously, the presence of one fimbriaeassociated gene, fimH has been strongly associated with the ability to form biofilm, and was detected in 15 of 16 isolates here.\n\nIn conclusion, Escherichia coli causing canine UTIs appear diverse; still, the presence of consistent attachment and virulence genes was noted across sequence types. Antimicrobial resistance genes and phenotypic resistance to cephalosporins were detected in several samples and are concerning for therapeutic choice and animal handling considerations. Further work to explore associations among virulence, antimicrobial resistance, and biofilm potential is underway to better understand UPEC presentation and pathogenesis in dogs. In dogs that were anesthetized with Propofol, serum levels of SDMA measured after anesthesia (15.95 \u00b1 4.03 \u03bcg/dL) were significantly higher than those measured before anesthesia (11.85 \u00b1 3.06 \u03bcg/dL, P < 0.01). Levels of sCr and BUN, traditional markers of renal function, also increased. Additionally, BUN and sCr levels were significantly and positively associated with SDMA levels (r = 0.23 and r = 0.42, respectively). In the Alphaxalone-treated dogs, the average serum level of SDMA before anesthesia was 12.15 \u00b1 1.79 \u03bcg/dL, which increased to 17.70 \u00b1 4.64 \u03bcg/dL after anesthesia, whereas smaller increases were detected in sCr and BUN.\n\nIn this study, an increase in serum SDMA was observed in both Propofol-and Alphaxalone-treated dogs, whereas the levels of sCr and BUN only increased in Propofol-treated dogs. Taken together, these data suggest that serum SDMA concentration is likely to be a sensitive biomarker for kidney dysfunction. The present data shows that serum SDMA has a strong relationship with several parameters used in the evaluation of renal function, such as serum creatinine, serum phosphorus, serum BUN, hematocrit, UP/C, urinary density and reticulocytes. Serum SDMA had a weak relationship with BP. Serum SDMA increased prior to image alteration on kidney ultrasonography in 13.3% (3/30) of the dogs. Serum SDMA also increased in 15% (9/60) of dogs before values of serum creatinine were above 1.4mg / dl. The differences found in IRIS staging considering serum SDMA were: of the dogs in IRIS stage 2, 33.3% (2/6) had serum SDMA above 25\u03bcg / dl, so these dogs were reclassified from IRIS stage 2 to IRIS stage 3. Dogs in IRIS stage 3, 16.6% (1/6) had serum SDMA above 45\u03bcg / dl so this dog was reclassified from IRIS stage 3 to IRIS stage 4. So we conclude that serum SDMA is an important tool for the evaluation of renal function and should be used routinely in the evaluation of dogs infected with L. infantum. Samples were thawed in batches and analyzed once using Cata-lystSDMA, on a Catalyst One\u00ae Chemistry Analyzer, and once using LC-MS (RefMethod). The study was completed over several days, however, for each sample, all testing was completed within four hours.\n\nAll testing was completed at IDEXX.\n\nResults are reported with 95 % confidence limits in parentheses.\n\nRefMethod median SDMA was 21.5 \u03bcg/dL; interquartile range (IQR) of 11.7 to 32.5 \u03bcg/dL; range: 5.1 to 85.3 \u03bcg/dL. CatalystSDMA median SDMA was 21.7 \u03bcg/dL; IQR: 11.3 to 32.9 \u03bcg/dL; range: 1.9 to 79.5 \u03bcg/dL. No statistical difference existed between SDMA concentrations obtained by the two methods (P = 0.88; Mann-Whitney U test).\n\nPassing-Bablok regression analysis: intercept 1.0 \u03bcg/dL (0.0 to 2.0); slope 1.0 (0.9 to 1.1); Tau 0.84. The Pearson';s correlation coefficient (r) was 0.94. The mean difference (Bland-Altman plot) was 0.0 \u03bcg/dL; standard deviation: 5.7 \u03bcg/dL (4.9 to 6.4). Limits-of-agreement (LOA) plot showed no fixed or proportional bias, with increased variation at the higher end of the dynamic range where unlikely to impact clinical decisions. LOA upper limit 11.1 \u03bcg/dL (9.4 to 13.0). LOA lower limit -11.1 \u03bcg/dL (-13.0 to -9.3).\n\nFor each assay, results to the nearest whole number were assigned to one of three categories: \u2264 14 \u03bcg/dL; 15 to 19 \u03bcg/dL; \u2265 20 \u03bcg/dL. The percentage agreement (concordance) between the two assays was calculated. There was good agreement (85 %) on results classification.\n\nThe minimal bias, good concordance and excellent correlation to the reference method provide confidence that CatalystSDMA can be used for in-clinic measurement of feline SDMA. Fasting uCa:Cr that was collected at initial evaluation was considered increased if the ratio were >0.06 based on previously published data.\n\nDogs were included in this study if CaOx urolithiasis was confirmed via quantitative calculi analysis and ionized calcium (iCa), routine serum chemistry, CBC, and urinalysis were available for evaluation. Dogs were divided into hypercalciuric andnonhypercalciuricstoneforming groups. Mann-Whitney test was used to compare groups. were renal-related deaths (RD). RD and AC dogs in IRIS stage 3 or 4 at biopsy had significantly shorter survival post -biopsy (SPB) than those in IRIS stage 1 or 2 (RD p < 0.001; AC p < 0.001). RD and AC dogs with Alb < 2 g / dL had significantly shorter SPB than dogs with Alb > 2 g / dL (RD p = 0.01; AC p = 0.004). RD and AC dogs with ascites / edema at time of biopsy had significantly shorter SPB compared to dogs without (RD p = 0.001; AC p = 0.03). AC dogs with history of HT had significantly shorter SPB compared with AC dogs without a history of HT (p = 0.03). RD dogs with GS affecting \u2265 25 % of glomeruli had significantly shorter SPB than RD dogs with < 25 % GS (p = 0.03). UPC was not significantly associated with SPB in RD or AC dogs.\n\nIn this retrospective study, FSGS had a similar prevalence to what has been previously reported. Females continued to be over-represented.\n\nSevere hypoalbuminemia and IRIS stages 3 or 4 were associated with a poorer prognosis in all dogs with FSGS. Hypertension was associated with a shorter survival in dogs that died of any cause, whereas biopsy samples with at least 25 % global glomerulosclerosis were associated with a poorer prognosis in dogs that were known to have renal-related deaths. The purposes of this study were (1) to describe the population of dogs with biofilm-forming Escherichia coli (E. coli)UTIs, and (2) to determine whether there were clinical differences between dogs with biofilmforming E. coli UTIs and dogs with non-biofilm-forming E. coli UTIs. We hypothesized there would be no difference in the two population characteristics of dogs whereas biofilm-formation would be more prevalent in dogs whose UTIs are chronic, complicated, and/or asymptomatic.\n\nThis was a retrospective cross-sectional study in which we evaluated 76 client-owned animals with E. coli UTIs, divided into two groups based on the in vitro biofilm-forming capability of the E. coli isolates.\n\nBiofilm formation was established using a crystal violet assay. Medical records of the dogs were reviewed and their population characteristics (age, sex, breed, weight, body condition score) and infection characteristics (infection class, chronicity, exposure to antibiotics, pyuria, multi-drug resistance, clinical signs) were compared.\n\nThe majority (52.6%) of our isolates showed biofilm-forming capability. Dogs with biofilm-forming E. coli UTIs had a lower likelihood of multi-drug resistance (p < 0.001) than those with non-biofilm-forming E. coli UTIs. There were no other statistically significant differences between the population characteristics or infection characteristics of the two groups.\n\nWe concluded that because there are no reliable clinical indices by which biofilm-formation can be ruled out, consideration should be given to the possibility of biofilm-formation whenever E. coli UTIs are diagnosed. Additionally, the association of MDR and non-biofilmforming E. coli may antimicrobial tolerance conferred by biofilm formation. The uremia associated with chronic kidney disease (CKD) has been shown to profoundly affect the composition of the gut microbiome in people and rat models. Toxic products generated by dysbiosis may contribute to morbidity and progression of CKD.Indoxyl sulfate (IS) and p-cresol sulfate (pCS) are uremic toxins produced by colonic bacteria. The first study objective was to compare the fecal microbiome of healthy, older (> 8 years) cats (n = 11) and cats with stable CKD (IRIS stage 2-4) (n = 30). The second objective was to measure serum IS and pCS in healthy, older cats (n = 10) and compare to CKD cats (n = 28).\n\nIn this cross-sectional study, all cats had a complete blood count, chemistry panel, total T4, urinalysis, blood pressure, and fecal flotation at enrollment. CKD cats had creatinine > 1.6 mg/dL and USG < 1.035 or an elevated creatinine at at least two time points in addition to an elevated SDMA > 14 ug/dL. Healthy cats were > 8 years of age and had a creatinine < 1.6 mg/dL and USG > 1.035. Exclusion criteria were a history of antibiotic, probiotic, or antacid administration < 6 weeks prior to enrollment or a history of uncontrolled hyperthyroidism and known or suspect gastrointestinal disease. A fresh fecal sample was The number of observed species and Chao 1 were significantly decreased in CKD cats when compared to healthy cats, p = 0.026 and p = 0.0284 respectively. The Shannon diversity index was decreased in CKD cats compared to healthy cats, however it was not significant (p = 0.0617). There was no significant difference in overall clustering of microbial communities between CKD cats and healthy cats (p = 0.72). However, when individual bacterial groups were analyzed based on LDA effect size (LEfSe) several bacterial taxa were identified as being significantly different among the groups. When comparing healthy cats to CKD cats, CKD cats had significantly decreased bacterial populations belonging to the genera Holdemania, Adlercreutzia, Eubacterium, Slackia, and Mogibacterium. No significant differences in the functional potential of the microbiota were found between CKD cats and healthy cats after correcting for multiple comparisons. IS levels were found to be significantly higher in CKD cats compared to healthy cats (p < 0.0001). Healthy control cats had significantly lower IS levels compared to stage 2 (p = 0.01) and stage 3 & 4 (p = 0.0006) CKD cats. No significant difference was found between Stage 2 and Stage 3 & 4 CKD cat groups. pCS levels were not significantly different between CKD and healthy controls.\n\nIn conclusion, feline CKD is associated with decreased diversity of the gut microbiome. IS is significantly elevated in feline CKD and merits exploration as a potential therapeutic target. Additionally, IRIS stage 2 cats may suffer from a similar uremic toxin burden as cats with later stage disease. Additional work is needed to further understand the interplay between the fecal microbiome and uremic toxins. Twenty percent of cats (n = 12) were excluded due to a urinary tract infection (UTI) at presentation. The mean SDMA and creatinine were significantly higher in these cats (59.6 \u03bcg/dL and 11.7 mg/dL, respectively), compared with those without a UTI (27.6 \u03bcg/dL and 4.76 mg/dL, respectively) (p < 0.002, < 0.001).\n\nTwenty-six cats met the inclusion criteria. There was a significant positive correlation between SDMA and creatinine at the time of UO (\u03c1 = 0.732, p < 0.0001). There was no association between initial SDMA and SDMA post-decompression at 24 hours (p = 0.817) or 5-20 days (p = 0.744). Mean SDMA and creatinine at presentation (24.7 \u03bcg/dL and 4.4 mg/dL, respectively) were significantly higher compared with final values (13.7 \u03bcg/dL and 1.7 mg/dL, respectively) (p < 0.017, < 0.016).\n\nSDMA appears to be a useful marker of post-renal azotemia in cats with UO, and pre-decompression SDMA does not reflect underlying kidney disease. UTIs may be more frequent in cats with UO than historically suggested, and screening should be considered, especially if SDMA and creatinine concentrations are elevated. Seventeen cats were identified for inclusion in the study. The median age was 12 years (range 3-17 years). Spayed females (n = 14) were more prevalent than castrated males (n = 3). Anorexia (7/17), lethargy (6/17) and vomiting (5/17) were the most common presenting complaints. Common physical exam abnormalities included muscle wasting (8/17), hypothermia (6/17) , and cardiac murmurs (6/17) . Clinical signs classically associated with pyelonephritis, such as renal pain and pyrexia were present in only 3 and 2 cats, respectively. Serum chemistries and complete blood counts were available for 11 and 10 cats, respectively. Common clinical pathologic abnormalities included azotemia, hyperphosphatemia, and non-regenerative anemia in 11, 8 and 7 cats, respectively. Of the 5 cats for which urinalysis data was available, all had bacteriuria and 4 had isosthenuric urine. Of the cats that had a urinalysis performed, four also had urine samples submitted for culture. Subcutaneous ureteral bypass (SUB)\u2122 device placement is an alternative to traditional ureteral surgery. However, outcomes have not been described for treatment of benign ureteral obstructions in dogs. The purpose was to evaluate pre-operative, peri-operative (< 7 days), short (7-30 days) and long-term (> 30 days) parameters in dogs treated with SUBs\u2122 for benign ureteral obstructions. The hypothesis was SUBs\u2122 were associated with favorable technical outcomes when compared with alternatives.\n\nSUBs\u2122 were placed using fluoroscopic-and surgical-assistance. Medical records were reviewed for pre-, intra-, and post-operative data.\n\nTwelve SUBs\u2122 were placed in nine dogs (3 bilateral) . Causes of obstruction included: ureterolithiasis (9/12;75%), extraluminal compression (2/12;17%), and stricture (1/12;8%). Eleven of 12 ureters had a stent placed prior and needed a SUB\u2122 for: recurrent stricture (4/11;36%) , ureteritis (4/11;36%), or stent migration (3/11;27%) .\n\nPlacement was successful in all ureters.\n\nThe median creatinine pre-operative and 3 months post-operative was 2.1 mg/dL and 1.2 mg/dL, respectively. Seven dogs (7/9;78%) had a history of urinary tract infection(s) prior to SUB\u2122 placement.\n\nLong-term complications included infection (5/9;55%) and mineralization (6/12;50%) . Dogs that mineralized their device had a history of urolithasis. Historical pre-operative infections commonly had postoperative infections (5/7). There were no peri-operative or procedure-related deaths. No dog had worsening azotemia in the short-term. The median survival time was > 774 days, with 5/9 still alive.\n\nUse of the SUB\u2122 device in dogs is a safe and effective treatment option for benign ureteral obstructions and associated with a good prognosis. The high rate of mineralization and infections should be considered in the long-term. The objective of this study was to identify patient and stone characteristics of juvenile dogs with CaOx urolithiasis compared to mature urolith-formers.\n\nInformation on 232 juvenile (\u2264 1 year) and 39,093 mature (7-9 years) dogs with CaOx (\u2265 70%) urolithiasis was obtained from submissions to the Minnesota Urolith Center between 2012 and 2016. Fisher';s exact tests were used to identify breeds overrepresented in the juvenile group, and chi-squared tests were performed to determine whether the sex, stone location (upper vs lower urinary tract) and salt type (monohydrate vs dihydrate) differed compared to the mature group.\n\nEnglish (OR = 8.6, P = 0.0070) and French (OR = 7.5, P = 0.012) Bulldogs were overrepresented in the juvenile group. While no difference in sex was observed between the juvenile and mature groups, all juvenile and > 90% of adult English and French Bulldogs were male. Stone location did not differ between juvenile and mature dogs, however < 2% of the stones in both groups were from the upper urinary tract.\n\nJuvenile dogs were more likely to form dihydrate stones compared to mature dogs (OR = 1.7, P < 0.001), although monohydrate were predominant in both groups (79% and 87%, respectively). The objective of this prospective study was to investigate the usefulness of a minimally invasive transcutaneous GFR (tGFR) monitor (NIC-Kidney) to assess renal function in cats with naturally occurring hyperthyroidism pre (t0) and 2 weeks post radioiodine treatment (t2).\n\nEight hyperthyroid cats were included of which 5 were euthyroid at t2. Three cats remained hyperthyroid, but had significantly reduced serum T4 concentrations. Plasma GFR (pGFR) and plasma half-life (pHL) were assessed by plasma sinistrin clearance. Transcutaneous half-life (tHL) was measured in parallel using a fluorescent marker (FITC-sinistrin) and the NIC-kidney device. Plasma data was used to calculate a species-specific conversion factor to determine tGFR from tHL. Overall pGFR and tGFR were significantly correlated (Spearman'; s correlation r = 0.73, P = 0.0019). In 7/8 cats pGFR decreased by 26% (mean); 13-59% (range). It remained unchanged in 1 cat. Using tGFR, a decrease of GFR was identified in 6/8 cats with a decrease (25%; 5-40%). The remaining 2 cats showed a mild increase (9% and 32%, respectively).\n\nAlthough results are not directly comparable, transcutaneous GFR assessments is a promising minimally invasive technique to allow for GFR estimation in small animals. Further research in a larger cohort is necessary to evaluate the full potential of this method.\n\nOwner Survey of Amoxicillin-Clavulanic Acid Side Effects in Cats with and without Azotemic CKD Cats with chronic kidney disease (CKD) have an anecdotal increased frequency of side effects with amoxicillin-clavulanic acid such as decreased appetite, vomiting and diarrhea in comparison to cats with normal kidney function. In human patients with decreased kidney function, it has been shown that potentiated penicillins, like amoxicillin-clavulanic acid, have impaired clearance (by as much as 90% in severe renal impairment). This impaired clearance results in higher serum concentrations in comparison to patients with normal kidney function and reduction of dosing interval is recommended to avoid side effects. The purpose of this study was to determine the frequency of side effects in cats with and without azotemia, with the hypothesis that cats with azotemic CKD will have an increased frequency of side effects.\n\nOwners of cats prescribed amoxicillin-clavulanic acid at Colorado State University or The Ohio State University were sent a survey regarding the occurrence of side effects (yes / no), specific type of side effect (vomiting, diarrhea, decreased appetite, none) and whether treatment was altered as a result. Signalment and clinicopathologic data were obtained from the medical record for cats for which surveys were returned. Cats included in the azotemic CKD group had a creatinine > 2.0 mg/dL, USG < 1.035 and a clinical designation of CKD. Cats included in the without azotemic CKD group were those had a creatinine < 2.0 mg/dL. A cut off between groups of creatinine 2.0 mg/dL was chosen to define cohorts as impaired clearance of amoxicillin-clavulanic acid is more common in humans with a greater degree renal impairment. Chi square was utilized to assess distribution of presence of side effects (yes / no) between groups, prevalence of specific side effects and changes in therapy. 73 surveys were returned with 12 being excluded for incomplete data or no serum creatinine available. 11 cats were categorized as azotemic CKD and consisted of 4 males and 7 females, with a median age of 14 years (range 4-20 years) and a median creatinine of 2.4 (range 2.0-6.0 mg/dL). 50 cats were categorized as not having azotemic CKD and consisted of 17 males and 33 females, with a median age of 11 years (range 1-18 years) and a median creatinine of 1.4 (range 0.7-1.9 mg/dL). Owners reported 6 / 11 cats (55 %) with azotemic CKD had side effects. Specific side effects included diarrhea 5 / 11 cats (45 %), vomiting 2 / 11 cats (18 %), and decreased appetite 3 / 11 cats (27%), with 5 / 11 cats (45 %) having more than one side effect. Owners reported 20 / 50 cats (40 %) cats without azotemic CKD had side effects. Specific side effects for these cats included diarrhea 11 / 50 cats (22 %), vomiting 10 / 50 cats (20 %), and decrease appetite 7 / 50 cats (14 %), with 6 / 50 cats (12 %) having more than one side effect. The difference in distribution of side effects (yes / no) or distribution of specific type of side effects was not statistically significant, however significantly more azotemic CKD cats had more than one side effect (p = 0.009). Additionally, significantly more owners of azotemic CKD cats reported that an alteration in treatment plan was necessitated by side effects with 55 % indicating the antibiotic was stopped, changed or supportive care was added due to side effects, while only 14 % of owners of cats without azotemic CKD reported alteration in treatment plan (p = 0.003).\n\nSide effects such as diarrhea, vomiting and decreased appetite were common with amoxicillin-clavulanic acid administration in both cohorts, but may be of increased incidence in cats with azotemic CKD and result in alterations of treatment plan. Investigations are currently underway to determine if these findings are associated with a higher drug serum concentration. (1), urethral stricture (1), and urethritis (1). In conclusion, feline urinary incontinence is a rare condition most commonly associated with acquired or congenital spinal cord disorders.\n\nUrinary incontinence in cats is generally associated with a poor prognosis, with many having persistent incontinence despite therapy. All canine patients that underwent TPE for NSAID overdose at the Tufts Foster Hospital for Small Animals between January 2015 and May 2017 were included in the study, and data regarding their presentation, hospitalization, treatments, and outcome was collected.\n\nEleven cases were included in this study. Of these, the NSAID ingested was ibuprofen in six, naproxen in four, and deracoxib in one.\n\nSix patients had complications associated with the TPE treatment, with the most common complication being hemorrhage. All cases survived to discharge with three developing acute kidney injury during hospitalization, one of which went on to have chronic kidney disease.\n\nThe final outcome was correlated with dose of NSAID ingested.\n\nThis study identifies plasma exchange as an effective treatment for NSAID overdose in that none of the patients had lethal outcomes despite high NSAID dose ingestion. No presenting factor determined the likelihood of acute kidney injury apart from the initial NSAID dose.\n\nComplications were common, but were managed with supportive care and did not affect final outcome. TPE should be considered in patients presenting for NSAID ingestion.\n\npmol/L of blood ionized calcium, and normal (PTH= 1.5 pmol/L) in the cat with 1.53 mmol/L (stage 3). Hyperphosphatemia (5. Seven healthy, male cats, aged between 8 months and 5 years, were evaluated using a randomized placebo cross-over study in a pairwise fashion, each cat receiving treatment every 12 hours for a two-week period. An approximate 24-hour voided urine sample was collected at the end of each treatment period. Samples were analyzed for pH, sodium, potassium, chloride, calcium, phosphorous, magnesium, citrate, oxalate, ammonia, and creatinine. Relative supersaturation for calcium oxalate and struvite was estimated using an iterative computer program (EQUIL 93b, University of Florida, Gainesville, FL). Data were assessed for normal distribution using Shapiro-Wilk. Paired ttest (normal distribution) or Wilcoxon signed rank (non-normal distribution) were used for statistical analysis. Data were analyzed using 2-tailed statistical testing except for relative supersaturation and urine volume where 1-tailed testing was used. A p-value < 0.05 was considered significant.\n\nData from 6 cats were used due to incomplete urine collection from 1 cat. Urine saturation for struvite was significantly lower when cats received supplement compared with placebo (supplement = 0.364 \u00b1 0.193, placebo = 1.565 \u00b1 1.284; p = 0.04) and 24-hour urinary excretion of phosphorous was lower when cats received supplement compared with placeb0.o (supplement = 44.89, range = 24.4 -61.3 mg/kg/24h; placebo = 50.75, 41.4 -63.5 mg/kg24h; p = 0.04). There were no differences in other analytes, body weight, or urine volume.\n\nThere are several limitations of this study. The study was of short duration and included a small number of healthy, non-urolith forming cats. There may not have been complete urine collection despite use of modified litter boxes.\n\nThere was a significant decrease in struvite supersaturation even with these limitations suggesting determination of relative supersaturation is a better determinant of risk of urolith formation than electrolyte & mineral concentrations or excretions. The herbal supplement may be beneficial for managing struvite-associated urinary disease in cats. Although a steady state can last for long, it can be a lethal situation when a new obstruction of the hypertrophied kidney occurs. In ureteral obstruction of feline, medical and surgical treatments can be optional.\n\nResearch indicated one-month survival rates were 70% in surgical treatment group with ureterotomyureterotomy, ureteroneocystostomy or ureteral resection and anastomosis, and 58 % in medical treatment group individually. One study revealed that with stents and subcutaneous ureteral bypass (SUB) for the treatment in cats with ureteral obstruction can increase the survival rate but no parameter was associated with disease outcome. However, prognostic factors in cats with obstructive and non-obstructive BKLK syndrome remain unclear.\n\nThe aim of this study is to characterize cats with BKLK syndrome and to determine the prognostic/progression factors for cats with BKLK syndrome in obstructive and non-obstructive ureter state. First sixteen healthy cats without any abnormality in physical, blood, radiography examinations were collected to define BKLK syndrome. The divergence between kidneys on abdominal ventrodorsal radiograph in these cats ranged from 0.01 to 0.69 cm with a mean of 0.23 \u00b1 0.20 cm. We defined the mean plus two standard deviations (0.63 cm) as the cut-off value. However, considering the observational error during the measurement, exceeding 0.8cm and with the history of CKD more than 2 months was set as the criteria for BKLK syndrome in this study.\n\nForty-four cats with BKLK syndrome was further divided into obstruction group (29) and non-obstruction group (15) based on their ultrasound finding. There was no significant difference between these 2 groups with regard to the body weight and gender. All patient in obstruction group was neutered, but 25.8% were intact in nonobstruction group (P = 0.01). The length of right kidney under X-ray was longer (P = 0.034), and the ratio of the big kidney to 2 nd lumber was higher in obstruction group (P = 0.002). Presence of urolith, nephrolith and the length difference between two kidneys did not show significant difference between two groups (P = 0.977, P = 0.241, P = 0.085). In blood examinations, the obstruction group had significant lower values of eosinophil (P = 0.004), reticulocyte (P = 0.029), Cl (P = 0.044), and higher value of MCHC (P = 0.027), BUN (P < 0.001), serum creatinine (P < 0.001).\n\nComparing the non-obstruction group with control group, male proportion was significantly higher in non-obstruction group (66.7% to 50%). The clinical pathological variables revealed that the values of Hb (P = 0.001), HCT (P = 0.003), RBC (P = 0.002), ALKP (P = 0.010), Urine pH (P = 0.004), USG (P = 0.001) were found to be significantly lower in the non-obstruction group. By contrast, the value of WBC (P = 0.013), segmented cells (P = 0.023), BUN (P < 0.001) and serum creatinine (P < 0.001) were higher in non-obstruction group.\n\nThe obstruction group was further divided into survival group (20) and non-survival group (8) (within 30 days). The survival group had significantly higher body temperature (P = 0.009), HCT (P = 0.058), Hb (P = 0.036), RBC (P = 0.026) and lower neutrophil (P = 0.027), ratio of neutrophil to lymphocyte (P = 0.015) and MCHC (P = 0.041). However, the surgery intervention, renal index including BUN, serum creatinine and phosphorus between the two groups did not meet any significant difference with the exception of serum creatinine to increase the odds ratio of death. Additionally all BKLK cats were also divided into survival group (33) and non-survival group (10) (within 60 day). Body temperature (P = 0.005), reticulocyte (P = 0.022), Hb (P = 0.038), RBC (P = 0.030) were higher in survival group. And non-survival group had higher ratio of neutrophil to lymphocyte (P = 0.022), MCHC (P = 0.014), BUN (P = 0.014) and creatinine (P = 0.009). Significant positive relations were found between serum creatinine and the length of the bigger kidneys in obstruction group, while the length of the bigger kidney under X-ray was not significant different between survival and non-survival groups (P = 0.161).\n\nIn conclusion, body temperature, Hb, RBC, MCHC, and ratio of neutrophil to lymphocyte are good prognostic factors in both obstructive and non-obstructive BKLK syndrome. Surprisingly, the length of the bigger kidney cannot determine the prognosis. NGAL, a 25-kDa glycoprotein belonging to lipocalin superfamily, acts as promising renal biomarker for humans, dogs and cats. Urinary NGAL had been reported with 3 configurations, including monomer, dimer and the complex with matrix metalloproteinase-9 (MMP-9) in human and laboratory animals. It is recently characterized in canine and feline urinary disease in our research group. MMP-9 plays an important role in regulating the degradation of extracellular matrix in process such as angiogenesis, tumor growth and metastasis. Additionally it has been reported that MMP-9 involves in renal fibrosis in chronic kidney disease (CKD). In addition, HJV, the upstream modulator of hepcidin-ferroportin axis, has been identified as a novel renal biomarker of acute kidney injury (AKI) and CKD in human renal diseases. Interestingly, both HJV and NGAL serve as modulators of inflammation, MMP-9 is involved in the expression of NGAL, and association of NGAL prevents MMP-9 auto-degradation; hence it is possible that these proteins work cooperatively in the course of feline renal diseases. To resolve this unknown issue, we aimed to characterize the overall expression profile of three factors in cats with urinary diseases. In feline CKD, both NGAL and MMP-9 can represent the severity. Urinary NGAL and MMP-9 were significantly higher in CKD stage 3 and CKD stage 4 than that in the control group and CKD stage 2. However, urine MMP-9 may not be appropriate to indicate CKD progression. In CKD group and pyuria groups, both urinary NGAL and MMP-9 concentrations and their ratio to urinary creatinine had significant correlations (The Spearman correlation values were 0.64, 0.59, 0.57, and 0.61 in order). However, these correlations could not be identified in AKI group. Moreover, for detection of feline HJV, recombinant feline HJV was prepared for generation of antibody against feline HJV. At present, the expression of HJV was detected in feline urine with Western blot analysis. To quantify the concentration of HJV, development of an ELISA platform is in process.\n\nIn conclusion, urinary MMP-9 is a promising biomarker for renalurinary diseases in cats and especially for interpreted with urinary NGAL. And the role of hemojuvelin in feline renal disease can be highly expected. In cats, hyperammonemia has been documented with portal venous anomalies, advanced hepatic disease, and with deficiencies in cobalamin (B12) and arginine. A recent case series reported hyperammonemia in 4 cats with IRIS stage 4 chronic kidney disease (CKD). We hypothesized that in a larger population of cats fasting hyperammonemia would correlate with the blood urea nitrogen (BUN) and creatinine (Cr) and be independent of serum B12.\n\nA fasted blood sample was prospectively collected for ammonia and B12 analysis from 20 client-owned cats with renal azotemia (IRIS Stage \u2265 2: creatinine \u2265 1.6 mg/dL). Blood for ammonia was immediately processed and analyzed in the clinical science laboratory. Cats on medications known to decrease blood ammonia (antibiotics, lactulose, probiotics) or previously diagnosed with disease states known to increase ammonia levels were excluded from the study. Data was analyzed using Pearson's correlation coefficient and ANOVA following log transformation.\n\nEnrolled cats had a median age of 12 years (range 4-19 years) and there were 11 males and 9 females. Five out of 20 (25%), 5/20 (25%) and 10/20 (50%) were staged as IRIS Stage 2, 3, and 4 CKD, respectively.Hyperammonemia was documented in 5/20 (25%) of cats.There was a significant moderate positive correlation between BUN and ammonia (r = 0.5478, p = 0.013) but no correlation between ammonia and Cr (r = 0.4306, p = 0.058) or ammonia and B12 (r = -0.275, p =0.44). There was no difference between mean ammonia levels between the IRIS Stages (2, 3 and 4) (p = 0.162). Hyperammonemic cats did not appear to have overt neurologic signs and did not have urinary tract infections with urease producing bacteria.\n\nIn conclusion, in this pilot study of cats with renal azotemia, a correlation existed between BUN and ammonia, but not between ammonia and Cr or B12. Future studies are needed in a larger population of cats to determine the true prevalence, etiology and effect of hyperammonemia on long term prognosis. SDMA seems to be strictly eliminated by renal excretion, and its concentration highly correlates with GFR in animals and humans; therefore, this biomarker can be an earlier marker of kidney dysfunction than serum creatinine (sCr).\n\nThe objective of the prospective study was to evaluate and quantify the effects of intravenous fluid therapy (IF) or intermittent hemodialysis (IH) on renal function in a randomized group of dogs previously diagnosed with IRIS stage 4 Chronic Kidney Disease (CKD).\n\nSerum from 14 dogs treated with IH and 10 dogs treated with IF was submitted for measurement of sCr and IDEXX SDMA. Dogs in each treatment group received 5 treatment sessions, administered 48 hours apart.\n\nSignificant differences (P \u2264 0.05) were seen between treatment groups, however dogs from the hemodialysis group were the most FIGURE 1 Western blot analysis for confirming hemojuvelin in feline urine. HFE-2 represents hemojuvelin. M represents marker. A represents azotemia group. N represents non-azotemia group affected on the clearance of SDMA (X 2 =17.8, P < 0.001), sCr (X 2 = 21.6, P < 0.001), and blood urea (X 2 = 33.1, P < 0.001). A significant correlation was also found between the urea reduction ratio (URR) and SDMA. For each 10% increase in URR there was a 6.2 \u03bcg/ dL decrease in SDMA (X 2 = 13.56, P = 0.002) ( Table 1) .\n\nAlthough SDMA is a dialysable biomarker, we highly recommend evaluating it in context with the concurrent URR for a better estimate of actual GFR. Despite its removal by IH, SDMA still is a better biomarker than sCr for evaluating GFR in dogs with CKD. formance. Since few ELISAs have been validated for feline urine, our objective was to evaluate feline-specific ELISA kits for quantification of IL-2, IL-6, and IL-12 in feline urine. Urine was collected from healthy cats evaluated at the Michigan State University Veterinary Medical Center. Normal urine samples were pooled, modified to mimic disease conditions by adding water or hemolyzed blood, and then spiked with high, medium, and low concentrations of recombinant cytokines. Concentrations of IL-2, IL-6, and IL-12 were determined using commercially available feline-specific ELISA kits. The influence of urine matrix variables on test performance was evaluated by spike/recovery tests, linearity testing, and assessment of inter-and intra-assay variation. All assays underestimated high and medium spiked cytokine concentrations in urine as compared to standard assay diluents. Low spiked cytokine concentrations in urine were inconsistently detected. Urine spiked with IL-2, IL-6 and IL-12 achieved maximal quantitative recoveries of 82%, 90%, and 58% respectively. High urine specific gravity contributed significantly to poor IL-2 and IL-12 recovery Feline idiopathic cystitis (FIC) is a common lower urinary tract disease in cats that resembles interstitial cystitis/painful bladder syndrome in people. In both conditions the pathogenesis of the disease is unknown and there is no specific treatment. To investigate the molecular pathways and disease functions potentially involved in the pathogenesis of FIC, we evaluated the bladder mucosa transcriptome of affected and healthy cats. Urinary bladder tissues were collected from 3 healthy cats and from 3 FIC cats representing 3 different histological phenotypes (ulcerative, nonulcerative, and hyperplastic). RNA from bladder tissues was isolated and sequenced using high throughput next generation sequencing. Differential gene expression and molecular pathway and disease factor analysis was performed using Ingenuity Pathway Analysis (IPA) software. A significant level of gene set enrichment (-log [p] > 1.3) was identified in several annotated disease and function categories. The inflammatory response function was up regulated in the non-ulcerative and ulcerative phenotypes (zscores 1.9 and 2.6 respectively), and down regulated in the hyperplastic phenotype (z-score -3.6). The cellular growth and proliferation category was down regulated in the non-ulcerative and hyperplastic phenotypes (z-scores -2.4 and -3.7) and up regulated in the ulcerative phenotype (z-score 6.5). The cell death and survival pathway was down regulated in the non-ulcerative and hyperplastic phenotype (-2.3 and -2.2) and up regulated in the ulcerative phenotype (6.5) . Further investigation of these pathways and other target genes may provide insight into the pathogenesis of FIC and identify new therapeutic targets as well as biomarkers of the disorder for future clinical applications. The aim of this study was to follow-up CKD dogs with IRIS stages 2 or 3 based on serum creatinine concentration, and also to investigate whether and when SDMA is in disagreement with creatinine concentrations for the classification of CKD stage. The study group was composed of twenty-one CKD dogs. CKD dogs with stage 2 (n= 9) and stage 3 (n= 12) were followed-up for 12 to 15 months or until death. The evaluation by means of serum creatinine concentrations, only two CKD dogs with stage 2 changed the classification to stage 3 during the follow-up, and also in those dogs serum SDMA was increased concomitantly; however other three CKD dogs with stage 2 had the increase only in SDMA (changing the classification to stage 3) and not in serum creatinine, showing the underestimation of the stage based on serum creatinine. In CKD dogs with stage 3, during the follow-up, only two dogs changed the classification to stage 4 based on serum creatinine concentrations, however when taking SDMA concentrations (> 45 \u03bcg/dL), 9 out of 12 changed the classification to stage 4 and among them, 6 out 9 dogs that had serum creatinine < 5.0 mg/dL were already in stage 4 since the beginning of the follow-up. Urinary protein to creatinine ratio (UP/C) measures the total amount of proteins in urine compared to urinary creatinine concentration, but it does not identify the origin of individual proteins. Qualitative evaluation of urinary proteins by immunodetection could add important information as to the nature of a renal disease as albuminuria is associated with glomerular disease, and retinol-binding protein (RBP) and vitamin D-binding protein (VDBP) with tubular damage due to the impairment of tubular reabsorption of low molecular weight proteins that are normally found in glomerular filtrate. The hypothesis of this study was that qualitative methods (e.g. western blotting) in association with quantitative methods (UP/C) may provide better assessment and evaluation of the origin of proteinuria. The aim was to study dogs with chronic kidney disease (CKD) and to determine the UP/C as well as to use immunoassay (western blotting) to detect urinary albumin, RBP and VDBP. The study group was composed of CKD dogs with stage 2 (n=9) and stage 3 (n=13) and they were followed up for 12 to 15 months or until death. Fifteen clinically healthy dogs of different breeds and age comprised the control group. Coomassie brilliant blue (Bradford method) was used for UP/C determination, and antialbumin (ab112986,1:500; Abcam, Cambridge, MA), anti-VDBP (ab95469,1:500; Abcam) and anti-RBP (ab48624, 1:250; Abcam) for the western blotting. Urinary albumin, RBP and VDBP were not detected in control dogs and UP/C was 0.15\u00b10.02 (mean\u00b1SEM) with a min of 0.03 and a max of 0.4. Only one CKD dog with stage 2 had proteinuria based on UP/C (mean of the follow-up, min-max; 1.49, 0.76-3.45 ) also with loss of VDBP (tubular pattern of renal disease). In the remaining 8 out of 9 CKD dogs with stage 2, the mean of UP/C was normal (UP/C < 0.4) during the follow-up period, however the qualitative evaluation detected loss of tubular proteins (RBP and /or VDBP) in 2/8, loss of glomerular protein (albumin) in 1/8, loss of tubular and glomerular proteins in 2/8, and in 3/8 no level of proteins were found. Proteinuria (UP/C > 0.5) was observed in 7 out of 13 CKD dogs with stage 3, and a tubular pattern characterized by the predominance of low molecular weight proteins loss (RBP and or VDBP) was noticed in 5/7, and the loss of albumin and RBP, both in similar magnitude, in 2/7 (tubular and glomerular pattern). In non-proteinuric (mean during follow-up, UP/C < 0.5) CKD dogs with stage 3 (n=6), the immunodetection of albumin and RBP or VDBP were observed in 3/6, and in 1/6 only a slight amount of albumin loss was detected. These findings suggest that sequential qualitative evaluation of urinary proteins can add more information to interpretation of UP/C results. Identification of the damaged nephron segment that caused a specific pattern of protein loss could help refine the diagnosis of a specific renal disease as well as to optimize therapy. Importantly, the detection of albumin, RBP and VDBP in urine samples with normal UP/C might serve as an early marker of glomerular and tubular injury. respectively. This study aims at describing P and QT dispersions, as well electrocardiographic changes observed in dogs with CKD stage IV undergoing IHD. The animals were classified considering serum creatinine (> 5mg/dL), urinary protein/creatinine ratio (> 0.5) and systolic blood pressure (> 160mmHg). Ten dogs weighing 15-30 kg were included in the study and electrocardiographic examinations were performed before and after the first three sessions of IHD. The results were analyzed using ANOVA with Friedman's test, considering a significance level of 5%. There were significant increases in values for P maximum (p = 0.011), QT maximum (p = 0.002), QT minimum (p = 0.023), however, the changes in P and QT dispersions were not significant (p> 0.05). There were increases in PR intervals (p = 0.019), QT intervals (p = 0.034) and a decrease in the amplitude of the R wave (p = 0.002). After the second session, three dogs (30%) developed sinus arrest and another three (30%) developed supraventricular arrhythmias. The results obtained suggest that employing IHD in dogs may cause electrocardiographic changes such as arrhythmias, interferences in atrioventricular conduction, as well as in the ventricular depolarization and repolarization process. These findings highlight the importance of electrophysiological monitoring in animals submitted to this therapeutic modality. sodium/1000 kcal) has been reported to increase urinary calcium while concomitantly increasing water intake and consequently urine volume when compared to a food containing approximately 0.4% (1g sodium/1000 kcal). When foods with similar Ca, P and Mg restriction but relatively high (3.5g/1000 kcal) and low (1g/1000 kcal) sodium content were compared, it was observed that relative supersaturation (RSS) for calcium oxalate was similar and calcium excretion was significantly greater for the high sodium food. 3 This suggests that a benefit ascribed to lower urinary saturation due to increased urinary water is offset by increased urine calcium content. Long term studies have not been performed in cats comparing RSS for calcium oxalate and recurrence rates for uroliths; however a correlation does exist in humans. Another surrogate for calcium oxalate risk, the Bonn Risk Index as described by Laube et al, has been proposed as a better predictor of future calcium oxalate risk than relative super saturation. 4, 5 This study examines low and high sodium feline dry foods by using the calcium oxalate titration (COT) test first described by Davidson 6 , which is similar to the human Bonn Risk Index test. In the COT test, centrifuged, unaltered, body temperature urine is titrated with a sodium oxalate solution and monitored at 585nm until precipitation occurs. The COT value is determined by dividing the urine [Ca 2+ ] by the resultant amount of oxalate added at the point of precipitation.\n\nTherefore the COT test measures urine stability or capacity as it is influenced by the composition of urine, reflecting the interactions of inhibitors and promoters of crystal formation.\n\nA group of 12 healthy adult cats were fed two commercially available foods a,b (1g sodium/1000 kcal and 3.5g sodium /1000 kcal), in series, for 2 weeks each and 24 hour urine samples were collected at the end of each period and evaluated. The COT test was performed and Equil 2 software was used to calculate RSS from urine concentrations of NH + 4 , Ca +2 , Cl -, Citrate, Mg +2 , oxalate, PO \u22123 4 , K + , Na + , SO \u22122 4 and urine pH. SAS\u2122 version 9.2 was used for all analyses. A repeated measures regression model was used with the value of the analyte as the dependent variable and food as the independent variable. Least-square means and pair-wise differences were calculated for diet comparisons for each analyte. Two-sided tests were performed. An alpha of 0.05 was used to determine statistical significance.\n\nUrine pH (p = 0.4), RSS for struvite (p = 0.6) and RSS for calcium oxalate (p = 0.3) were not significantly different between foods. Urine from cats fed the low sodium food had a significantly (p < 0.01) greater urine specific gravity ((mean\u00b1SEM) 1.054 \u00b1 0.001 vs 1.038 \u00b1 0.002), phosphorus (2776 \u00b1 94 ppm vs 1370 \u00b1 102 ppm) and citrate concentration (2993 \u00b1 538 umol/L vs 1154 \u00b1 589 umol/L) and significantly lower calcium (45 \u00b1 7 ppm vs 80 \u00b1 8 ppm) and COT (28 \u00b1 30 vs 202 \u00b1 33) compared to the high sodium food. Compared to the high sodium food, the low sodium food improved urinary crystallization capacity as measured by the COT test by 86% and lowered urine calcium concentration by 44%. With respect to calcium oxalate crystal formation, factors associated with increased urine stability, include urine citrate and urine phosphorus and these were significantly increased by 159% and 103% respectively.\n\nFeline urine is typically metastable for calcium oxalate and complexation is affected by many factors. Increased urine water may help reduce saturation of crystal components but may also dilute inhibitors of crystal formation. This data supports that the dynamic nature of calcium oxalate precipitation testing provides additional information on the capacity of urine to resist induced crystallization which is not reflected in the traditional super saturation calculation. Elevated sodium content of foods influenced calcium excretion and appeared to lower urine resistance to induced crystal formation. Further study of the relationship between RSS and COT and long term risk for crystal and stone formation is warranted. cannula system that allows fluid flow in only one direction at a time.\n\nThese one way flow cystoscopes have worked well in small animal practice for over 30 years and still work well for diagnostic and simple corrective procedures. This system does not work well for more advanced complex transurethral interventional procedures, especially those using lasers or radio-frequency. With only one way flow the visual field is quickly obscured with debris, blood, and smoke.\n\nRepeated fluid exchanges are required to maintain adequate image quality. Discontinuing the procedure to drain and refill the bladder is time consuming, frustrating, and increases the risk of bladder trauma by over-distensionContinuous flow cannulas are available for cystoscopes that allow ingress and egress of fluid to occur simultaneously maintaining a constant bladder distension with a clear visual field.\n\nThese systems are standard instrumentation for human cystoscopy. Hyperthyroidism can mask chronic kidney disease (CKD) because of hyperfiltration and muscle loss. Symmetric dimethylarginine (SDMA) has been shown to increase earlier than creatinine in cats with CKD, and, unlike creatinine, SDMA is not impacted by lean muscle mass.\n\nFor these reasons, it has been postulated that SDMA could be a more sensitive indicator of renal function in hyperthyroid cats. The aim of this study was to describe the relationship between SDMA, creatinine, body weight and T4 to evaluate SDMA as a potential renal biomarker in hyperthyroid cats.\n\nCats were retrospectively identified from the US IDEXX Reference Laboratories database where T4, SDMA and creatinine were measured on the same sample. SDMA and creatinine were compared to T4 concentrations for the entire study population of cats. A Spearman correlation test was conducted for cats with T4 > 4.7 \u03bcg/dL. A hyperthyroid treated group was identified (T4 \u2264 4.7 \u03bcg/dL and decreased by a minimum of 2.5 \u03bcg/dL) that had body weight and laboratory results available from more than one visit. Hyperthyroid cats and a 10 to 1 comparative control group of age-matched euthyroid cats were used to evaluate body weight, creatinine, SDMA and T4 pretreatment and at 1-30, 31-60, 61-90, 91-120 days post-treatment.\n\nOf 113,535 cats that met the criteria, 14,861 had a T4 < 0.8 \u03bcg/dL, 41,032 were euthyroid (0.8 \u03bcg/dL \u2265 T4 < 2.3 \u03bcg/dL), 20,211 were in the grey zone (2.3 \u03bcg/dL \u2265 T4 \u2264 4.7 \u03bcg/dL) and 37,431 were hyperthyroid (T4 > 4.7\u03bcg/dL). Boxplots illustrate the relationship between T4 and creatinine and T4 and SDMA concentrations. A negative relationship was found between creatinine and T4 (\u03c1 = -0.37, P < 0.001).\n\nAlthough there was also a slight negative relationship between SDMA and T4, it was not statistically significant (\u03c1 = -0.008, P < 0.426).\n\nThe mean body weight of hyperthyroid treated cats (n = 1,281) at pretreatment and at all post-treatment time points was significantly less than control cats (n = 12,810) (all P values < 0.01). Hyperthyroid cats had a significantly lower mean weight pretreatment, and at 1-30 days and 31-60 days versus 90-120 days (all P values \u2264 0.03). Pretreatment creatinine was significantly decreased in comparison to all post-treatment time points (all P values < 0.001). Creatinine was significantly increased at 91-120 days in comparison to all other time points (all P values \u2264 0.007). The mean creatinine of hyperthyroid cats was significantly less than in control cats pre-treatment and up to the 61-90 day post-treatment time period (all P values < 0.01). Pretreatment SDMA was significantly decreased in comparison to all post-treatment time points (all P values < 0.001). However, after the increase in SDMA at 1-30 days, there was no significant difference in mean SDMA concentrations throughout the remainder of the treatment periods. In addition, compared to the control cats, the mean SDMA of hyperthyroid cats was only significantly lower pre-treatment (P < 0.001) but not at any post-treatment time point.\n\nCreatinine significantly decreased with increasing concentrations of T4, whereas SDMA did not. Both SDMA and creatinine concentrations increased during the immediate post-treatment period. During treatment creatinine continued to increase as cats gained weight. In contrast, SDMA remained stable during treatment and was comparable to age-matched control cats. Therefore, SDMA may be a more reliable biomarker of renal function than creatinine in hyperthyroid cats before and during treatment. We hypothesized that the herbal supplement would be associated with increased urine volume and decreased urine saturation for calcium oxalate and struvite when compared with placebo.\n\nFourteen healthy client-owned dogs were evaluated using a randomized placebo cross-over study in a pairwise fashion, each dog receiving treatment every 12 hours for a two-week period. An approximate 12-hour voided urine sample was collected at the end of each treatment period. Samples were analyzed for pH, sodium, potassium, chloride, calcium, phosphorous, magnesium, citrate, oxalate, ammonia, and creatinine. Relative supersaturation for calcium oxalate and struvite was estimated using an iterative computer program (EQUIL 93b, University of Florida, Gainesville, FL). Data were assessed for normal distribution using Shapiro-Wilk. Paired t-test (normal distribution) or Wilcoxon signed rank (non-normal distribution) were used for statistical analysis. Data were analyzed using 2-tailed statistical testing except for relative supersaturation and urine volume where 1-tailed testing was used. A p-value < 0.05 was considered significant.\n\nData from 10 dogs were used due to incomplete urine collection from 4 dogs. There were 7 females and 3 males including 4 Labrador mixes, 1 Havanese, 1 Pit bull, 1 Great Dane mix, and 3 mixed unknown breeds. Urine saturation for calcium oxalate was significantly lower when dogs received supplement compared with placebo (supplement = 2.30 +/-1.76, placebo = 3.50 +/-1.61; p= 0.047). There were no differences in other analytes, body weight, or urine volume.\n\nThere are several limitations of this study. The study was of short duration and included a small number of healthy, non-urolith forming dogs. Twelve hour urine samples were collected by owners at home, which may have introduced error in urine volume collected. Additionally, urine was collected overnight and dogs did not drink although they had access resulting in collection of low volumes of urine.\n\nThere was a significant decrease in calcium oxalate supersaturation even with these limitations suggesting determination of relative PA using two agonists (adenosine diphosphate; ADP and arachidonic acid; ASPI) and a saline control was performed in six healthy clientowned dogs at baseline and 1 week following clopidogrel administration to establish cut-off values to identify responders (R) or nonresponders (NR). A decrease of \u2265 60% for ADP at 1 or 3 hours post clopidogrel administration defined a R. PA was performed in PLN dogs at baseline and 1, 6, and 12 weeks following clopidogrel or aspirin administration. Drug concentrations and PA were measured at 1 and 3 hours post clopidogrel administration (at 1 week or 6 weeks) in both healthy and PLN dogs. Fourteen dogs were enrolled; ten PLN dogs received clopidogrel alone, three received aspirin alone, and one dog was started on aspirin but was switched to clopidogrel. Repeated measures (RM) analysis (one-way ANOVA) was performed and subsequent time points (1, 6, and 12 Chronic kidney disease (CKD) in dogs is a common clinical entity characterized by a marked decrease in renal function. In humans, there are several reports that uremia caused by renal failure affects the oral and fecal microbiomes, but there is a lack of information on the oral and fecal microbiomes in dogs with CKD. Therefore, the objective of the present study was to examine the changes in the oral and fecal microbiomes in CKD dogs.\n\nEleven dogs with CKD presenting with azotemia over 3 months and 9 healthy dogs were included in this case-controlled study. The oral swabs and fecal samples were analyzed by whole genome sequencing using an Illumina MiSeq platform. Dyslipidemia affects up to 85% of humans with chronic kidney disease (CKD) and has been associated with increased mortality and progression of CKD in addition to being a risk factor for CKD development.\n\nAltered lipoprotein profiles have been documented in dogs with CKD but this has not yet been investigated in cats. The purpose of this study was to compare serum lipoprotein profiles between cats with CKD and healthy controls. We hypothesized that cats with CKD would have higher total low-density lipoprotein (LDL) and lower total high-density lipoprotein (HDL) when compared with healthy cats.\n\nClient-owned healthy cats and cats with naturally-occurring CKD were prospectively enrolled in the study. Healthy cats had a urine specific gravity of 1.035 or greater and a serum creatinine < 1.6 mg/dl or a normal S-dimethylarginine (SDMA). Cats with CKD had a compatible clinical history, serum creatinine > 1.6 mg/dl and a urine specific gravity < 1.035. After a 12-hour fast, serum was collected for analysis of lipoprotein profiles using a continuous lipoprotein density profiling (CLPDP) technique. Serum cholesterol and triglycerides were also measured using a commercial chemistry analyzer. Area under the curves for triglyceride-rich lipoproteins (TRL), total LDL and total HDL were calculated for statistical analysis. Data were analyzed using a Wilcoxon rank sum test with significance set at P < 0.05.\n\nThirteen cats with CKD and six healthy controls met inclusion criteria.\n\nBased on creatinine values at the time of study enrollment, 11/13 cats with CKD were classified as International Renal Interest Society (IRIS) stage 2 and 2/13 cats were classified as IRIS stage 3. Triglyceride rich lipoproteins, total LDL and total HDL were not significantly different between cats with CKD and healthy controls (P = 0.187, P = 0.218, P = 0.065, respectively). Serum cholesterol concentrations and serum triglyceride concentrations were within reference range for all cats and were not significantly different between groups (P =0.484 and P = 0.080, respectively).\n\nThis study suggests that dyslipidemia may not occur in cats with CKD and implies a possible difference in the pathophysiology of CKD in cats relative to that of dogs and humans. Further studies with a larger sample size and cats with more advanced CKD are needed to confirm our findings. available to evaluate the efficacy of drug treatments. In humans, computed tomography (CT) and magnetic resonance imaging (MRI) are used to follow ADPKD progression by evaluating total kidney volume (TKV). The purpose of this study was to examine the efficacy of biomarkers and imaging modalities to evaluate disease progression in feline ADPKD.\n\nEleven ADPKD cats with the c.10063C>A PKD1 mutation were imaged using ultrasonography, CT, and MRI. CBC, serum chemistry, urianalysis, symmetric dimethylarginine levels, and glomerular filtration rate were also measured.\n\nAll ADPKD cats were clinically normal except for the presence of multiple, bilateral renal cysts. TKV measured by CT correlated with estimates using ultrasonography and MRI. TKV had no correlation with age. Fractional cyst volume (FCV) (0.01 -0.28 ml) were obtained from CT and had a moderate correlation with age (15.12 -97.08 months), with a Spearman's rank correlation coefficient of 0.627, and p = 0.044. However, FCV per age showed outliers.\n\nRenal cysts are known to increase over time in cats with ADPKD, however, this data indicates cysts progress at different rates as determined by CT-based FCV per age and cats do not have significant increases with age in TKV. Variable FCV per age supports disease progression is individual and suggests modifiers likely influence progression. FCV can evaluate disease progression of feline ADPKD and characterize the therapeutic efficacy of drugs for ADPKD. One component of assessing chronic kidney disease in cats is creatinine (Cr) concentration in blood and urine measured using an automated system based on the Jaff\u00e9 reaction or enzyme-based assay. Evidence from other species suggests Cr is over-estimated with the Jaff\u00e9 reaction, but it is not clear if this assumption is accurate for cats. This study compared these 2 automated assay methods, with a -0.3 mg/dL correction as part of the Jaff\u00e9 methodology, to measure Cr concentration in serum (SCr) and urine (UCr). Cr data was used with voided urine volume (Uvol) to calculate endogenous creatinine glomerular filtration rate (GFR) and compared to serum symmetric dimethylarginine (SDMA) concentrations.\n\nForty-eight-hr Uvol from healthy, domestic shorthair cats (N = 45 [23 males/22 females]; 7.8 yrs \u00b1 2.0 SD) occurred while individually housed with inert litter and finished with blood sample collection for SCr and SDMA. GFR was determined using both Cr assay methods.\n\nMean Jaff\u00e9 reaction SCr, UCr, and GFR are overestimated (P = 0.002), UCr (P = 0.04) with the overestimation becoming greater with increasing Cr concentration. The overall mean \u00b1 SE (min-max range) of SCr, UCr, and GFR based on the enzyme method was 1.6 \u00b1 0.2 mg/dL (1.1-2.1), 323 \u00b1 59 mg/dL (184-457), and 1.10 \u00b1 0.37 mL/min/kg BW (0.46-1.86). UCr and GFR did not differ with age or sex, whereas SCr differed with age (P = 0.04), but not sex (P = 0.74), as older cats had lower SCr (1.49 \u00b1 0.06; 8-14 yrs) versus middle-aged cats (1.64 \u00b1 0.04; 4-7.5 yrs). In addition, Uvol (range: 3.4-18.4 mL/kg/d) and USG (range:\n\n1.028-1.070 g/mL) did not differ with age or sex, whereas SDMA (range: 6-21 ug/dL) differed with age (P = 0.032), but not sex (P =0.13), with lower SDMA in older (12.1 \u00b1 0.7 SE) versus middle-aged cats(14.5 \u00b1 0.8 SE). Therefore, as part of the framework to successfully manage CKD in cats over time, selecting diagnostic laboratories that measure Cr using the enzyme method appears to improve accuracy by eliminating the detection of non-Cr compounds. This is particularly important as these data demonstrate that Cr is increasingly overestimated with the Jaffe method as Cr concentrations increase. Intermittent fasting (IF) has numerous benefits in some species, including increased insulin sensitivity, and improved neuronal repair following spinal injury from an increase in ketones. The aim of this study was to examine the immunological, metabolic and hormonal effects associated with IF in dogs.\n\nTen healthy dogs underwent three, 1-week isocaloric feeding regimens in a Latin square design: daily low-fat feeding (20% kcal ME; DLF), IF on a low-fat diet (IFLF), and IF on a high-fat (70% kcal ME) diet (IFHF). Body weight, intake, activity, lymphocyte proliferation, macrophage/neutrophil phagocytosis and respiratory burst, along with fasting blood glucose, beta-hydroxybutyrate (BHOB), leptin, ghrelin, and insulin were measured. NMR spectroscopy was used to identify changes in the fasted plasma metabolome.\n\nDogs on the IFLF lost weight [mean (\u00b1SD) (-1.7 \u00b1 1.5%)] from a lower voluntary food intake. Dogs were more active at night when fed daily than when fed intermittently. Mean fasting BHOB concentrations were highest during the IFHD phase (0.061 \u00b1 0.023mM) and lowest during the DLD phase (0.018 \u00b10.004mM). Mean fasting plasma glucose was greatest when fed daily, and lowest during the IFHD phase.\n\nIntermittent and daily feeding separated on metabolomics analysis.\n\nHormone concentrations did not differ, nor were there biologically significant differences in immune assays between dietary phases.\n\nUnlike humans and rodents, short term fasting in dogs does not produce detrimental immunological effects. The increase in plasma BHOB with IF on a high fat diet highlights its potential as a beneficial feeding regime for dogs with spinal disease. Obesity has become the most common health problem and can reduce longevity, increase risk of many chronic diseases, and adversely affect quality of life in dogs. Continuous caloric restriction (CCR) regimens have been applied for obesity treatment by creating a daily negative energy balance. However, CCR leads to decreased energy expenditure, which makes it difficult to continue to lose excess body fat and to maintain body weight after weight loss. The objective of this study was to compare the effect of CCR to an intermittent calorie restriction (ICR) regimen on body fat loss, and post-weight loss maintenance energy requirement (MERs) in obese dogs.\n\nThirty naturally obese dogs with BCS of 9 were randomized into two groups based on MERs, body weight, and % body fat. Dogs in the CCR group were fed 75% of their baseline MERs for 6 months, while the dogs in the ICR group were fed with the repeats of 75% baseline MERs for one week, and then 100% baseline MERs for one week for 6 months. Then, the caloric restriction in both groups was adjusted to 65% of baseline MERs for 2 additional months. ICR and CCR led to similar % body fat at the end of the study (35.40%\u00b1 1.38 vs 33.89% \u00b1 1.52, p > 0.05). Dogs in the CCR group significantly (p = 0.0005) lowered their post-weight loss MERs by 17.92% compared with their baseline MERs. However, dogs in the ICR group numerically increased their post-weight loss MERs by 3.43% (p = 0.08). Obesity and diabetes are leading nutrition-related disorders among pets in North America and have significant impacts on animal morbidity and mortality. The glycemic index (GI), a measure of post-prandial blood glucose response, has been shown in humans to significantly impact glucose control, insulin sensitivity, weight management, and chronic disease risk.\n\nThe purpose of this research was to determine the GI of commercially available pet foods containing different carbohydrate sources; in addition, the effects on postprandial glycemic and insulinemic response and hormones related to satiety were also investigated.\n\nFour commercial extruded diets containing different carbohydrate sources were tested. The diets were classified based on the type of carbohydrate sources they contained: traditional grains (corn, wheat), whole grains (oats, rye, barley), grain-free (peas, lentils, chickpeas) or vegan (no animal ingredients). Each diet was tested once in eleven healthy adult Siberian Huskies and the control (50% glucose solution) was tested twice per dog in a randomized cross-over design. Each meal and control provided 25g of available carbohydrate. Pre-and postprandial blood samples at 15, 30, 45, 60, 90, and 120 minutes were collected to measure whole blood glucose concentrations using a handheld blood glucose monitor. Serum insulin, ghrelin, gastric inhibitory polypeptide (GIP), glucagon-like peptide 1 (GLP-1), leptin, total peptide tyrosine-tyrosine (PYY), and pancreatic polypeptide (PP) concentrations were also analysed at these time points using a magnetic bead multiplex assay.\n\nGlycemic index was calculated as the post-prandial incremental area under the curve (iAUC) for glucose of each test diet, divided by the iAUC of the control. Glycemic indices were compared using two-way ANOVA. Concentrations of glucose, insulin and satiety hormones over time were compared between treatments using repeated-measures ANOVA. This study was approved by the University of Guelph Animal Care Committee (AUP#3650).\n\nThe effect of diet on GI was insignificant (p = 0.589), although numerical differences were observed. The diet containing traditional grains presented the highest GI of 76.9 \u00b1 18.3, while the grain-free diet presented the lowest GI of 50.5 \u00b1 13.1. The whole grain diet and vegan diet had GI values of 60.8 \u00b1 7.4 and 71.4 \u00b1 17.3, respectively. No significant effects of diet were observed for postprandial glycemic response, insulinemic response or on any of the satiety hormones measured (p > 0.05).\n\nThe lack of observed differences could be related to the gelatinization of starch during extrusion processing, resulting in a high content of rapidly digestible starch. These results suggest that different carbohydrate sources in commercial extruded diets may not have a significant effect on GI or satiety in dogs. Further research investigating the appropriateness of using the GI methodology in humans is necessary due to the high variability in postprandial glucose response observed in this study, and the unknown health benefits of low glycaemic foods in dogs. Water intake and hydration were evaluated in healthy dogs offered a nutrient-enriched water (NW) supplement while fed a maintenance dry food to maintain BW with ad libitum tap water (TW) in a bucket. Baseline (day -7) urine specific gravity (USG) was analyzed in Beagles (N = 30; 2-11 years) and 16 were selected with \u2265 1.015 USG, then equally divided into 2 groups balanced for USG. Groups received either TW or NW (containing whey protein, poultry flavoring, and glycerol) in a bowl for 56 days. Dose for each dog was 0.5:1 water-to-calorie ratio (mL:kcal ME/d) from days 1-49 and 2:1 mL:kcal ME/d for days 50-56 based on baseline calorie intake. Food calorie and total liquid intake (TLI; g/d; sum of NW or TW in a bowl and bucket water) recorded daily and used to calculate weekly mean intake amounts. USG was measured on days -7, 14, 42, 56. Linear mixed effects models were performed with main effects of treatment, time, and time-by-treatment interaction. Calorie intake was not different (P > 0.49). A time-by-treatment interaction was significant (P = 0.07) versus baseline. A significant (P < 0.01) on days 42 (1.018 g/mL) and 56 (1.014 g/mL) versus baseline (1.026 g/mL).\n\nThis study indicates that all dogs offered the NW supplement, while having free access to TW, increased their TLI and produced a more dilute urine, which suggests an improvement in overall hydration. Diabetes mellitus is a chronic disorder that results in hyperglycemia and hyperlipidaemia by insulin deficiency, sometimes leading to fatal (NM07) complications. In this study we evaluated the effect of pea and barley as only starch source on lipid profile of diabetic dogs.\n\nTwelve diabetic dogs received, randomly and by a double blind way, three diets differenced by fat level and starch source: Ba (mix of rice, pea and barley; 6.7 g of fat/1000kJ), PB (pea and barley; 9.6 g) and Co (corn; 9.8 g). A plasmatic cholesterol and triglycerides curve was performed, every 2 hours for 10 hours beginning immediately before the morning meal and insulin injection, after 60 days of each diet treatment. Statistical tests were performed and p Pea and barley-based diet caused lesser plasmatic lipid concentration, mainly cholesterol, comparably to corn diet (table 1) . PB diet results the same lipid value that Ba diet, allowing decrease of lipids levels with higher fat content diet.\n\nProbably it happened due to better glycemic control of diabetic dog receiving slow assimilation starch, and to phenolics compounds presents in pea and barley ingredients. Then, we believe that pea and barley could be interesting starch source to hyperlipidemic diabetic dogs. shadow trends in human nutrition, and a perception exists among veterinarians that many pet owners now prefer 'natural'; and 'holistic'; diets over processed foods. The purpose of the study was to determine what and how dog and cat owners feed their pets and compare to a study published ten years ago (Laflamme et al. 2008) . Both studies involved pet owner surveys: Laflamme and colleagues'; 2008 questionnaire was administered by students over the phone to randomly selected telephone directories, while this present questionnaire was administered online and was distributed to pet owners on social media. The survey was promoted to general pet owning and pet appreciation groups and not to veterinary, nutrition or other special interest groups, and was open for sharing to reach a wide audience and acquire a sample representative of the general population of pets and pet owners. The study was approved by the research ethics boards of participating institutions (REB #17-08-029). Descriptive data were reported as percentages, while significant differences between the two studies were determined using Chi Square analysis, with significance set at P < 0.05. Information from Australia and the United States only were included for analysis. The results of both surveys are summarised in Table 1 below. Where data were comparable, significant differences in feeding practices over time included: increase in feeding homemade and raw diets, decrease in daily feeding of treats, and decrease in feeding a commercial diet as the main food source in both dogs and cats; while an increase in exclusive feeding of homemade diets was also detected in cats only. In essence, the trend appears to be a shift in pet nutrition away from the complete and balanced diets currently recommended by most veterinarians, in favour of home-prepared 'human'; foods and raw meat diets.\n\nThese changing practices may predispose the nations'; pets to dietary imbalances, nutritionally-responsive diseases, and infectious diseases.\n\nGiven this information, clinicians in both general and specialty practice must be aware of the risks associated with homemade and raw diets, obtain comprehensive dietary histories from their clients, and be prepared to diagnose and treat associated diseases.\n\nFecal samples were collected from healthy dogs (n= 73). Owners completed a survey with information about health status and dietary history.\n\nNutrient content was obtained from online product guides, if the information was not provided, the pet food companies were contacted directly. The dysbiosis index (DI) was evaluated by combining the quantitative polymerase chain reaction values for E. coli, Streptococcus, Turicibacter, Faecalibacterium, Fusobacterium, Blautia, and Clostridium hiranonis.\n\nStatistical significance was set to p< 0.05. Correlations between abundance of bacterial taxa and the macronutrients were performed using Spearman';s correlations. Significance was set at p< 0.05. In conclusion, a significant correlation was found only between crude fiber and Fusobacterium. Results suggest that the macronutrient content in commercial diets has only modest impact on the abundance of major bacterial taxa in the canine microbiota. The study of lipids in biological fluids has led to substantial advances in diagnosis and therapeutics of human obesity, cancer, and kidney diseases. Considering that most of these conditions also afflict cats, we hypothesize that lipids could also serve as biomarkers for studying and diagnosing diseases in cats. However, the study of lipids in feline plasma has been limited to a few number of lipid species, mainly, fatty acids and triacylglycerols, whereas it is yet unknown if the feline urine contains any lipids. Considering this gap of knowledge, the objective of this study was to characterize the lipid composition in plasma and urine samples collected from clinically healthy young-adult cats (n=8).\n\nPlasma samples were obtained from clinically healthy young-adult (< 2 years-old) intact female cats by collecting 1 mL of blood into tubes containing citrate and then centrifuged at 1,800 x g for 8 min. Urine samples were collected by ultrasound-guided cystocentesis and immediately centrifuged at 1,000 x g for 8 min. Every cat was given a baseline complete history, physical examination, and laboratory evaluation. All had normal complete blood count, serum chemistry, and urinalysis. Lipids were analyzed using liquid chromatography/quadrupole time-of-flight mass spectrometry.\n\nIn total, 212 lipids were characterized in feline plasma and urine samples.\n\nThe origin of these metabolites was mainly from food and endogenous compounds. In plasma, glycerophospholipids showed the higher number of chemical species detected (n=101) followed by sphingolipids (n=35), glycerolipids (n=23), fatty acyls (n=22) and sterol lipids (n=3). In urine, the highest structure diversity was observed for polar lipids, namely, glycerophospholipids and sphingolipids, with 15 and 7 chemical species identified within each category, respectively. Figure 1 shows the relative abundance of each lipid category based on signal intensity found in the feline plasma and urine samples. Of note, 150 out of 212 lipids identified in this study have not been reported previously in cats. This is the first study describing the lipid composition in plasma and urine of healthy cats comprehensively. Many of the lipids found in this study have been used as biomarkers in human medicine for different pathologies including linoleic and arachidonic acids for kidney diseases; SM(38:1) and SM(42:1) for insulin resistance and nonalcoholic fatty liver disease; LPC(16:0), LPC(18:0), PC(34:1), PC(34:2), PC(36:4) and cholesterol for hepatocellular carcinoma, among others. Thus, the novel information generated in this study could lead to the discovery of novel biomarker candidates for detecting and studying feline diseases and individualized treatments for cats.\n\nSol Rivera, Nicolas Villarino Washington State University College of Veterinary Medicine, Pullman, WA, USA Glycation is a non-enzymatic reaction between the carbonyl group of reducing sugars and a free amino group in the protein. During this FIGURE 1 A) Percentages of each category of lipids found in feline plasma. Fatty acyls, FA; glycerolipids, GL; glycerophospholipids, GP; sphingolipids, SP; and sterol lipids, ST. B) Signal intensities (mean AE SEM) for the known lipids detected in feline urine process, plasma proteins form a variety of heterogeneous structures known as advanced glycation end products (AGEs). These compounds have been associated with several pathologies including obesity, diabetes, cirrhosis, cardiovascular disease, renal failure, and neurological disorders.\n\nIn contrast to human medicine, little attention has been given to AGEs in veterinary medicine. Of note, fructosamine is a biomarker used for monitoring blood sugar concentrations, but it only provides information about early glycation products. Conversely, carbonyl groups are formed during both the early and late stages of protein glycation.\n\nConsidering the fact that canine albumin contains similar glycosylatable amino acids (lysine and arginine) to those in humans, we hypothesize that abnormally high levels of glucose in a dog';s plasma leads to the formation of AGEs during the process of protein glycation. In order to address this hypothesis, plasma from healthy dogs was enriched with glucose levels similar to those reported in diabetic patients with good and poor glycemic control. Glucose-enriched and control samples were incubated for 40 days at 37 C.\n\nThe high levels of glucose glycated plasma proteins and led to the formation of AGEs as determined by 2,4-dinitrophenylhydrazine assay.\n\nThe carbonyl content in plasma increased (P < 0.05) in a glucose concentration-dependent manner (P < 0.05, Figures 1 and 2) and was positively associated with the concentration of fructosamine (P < 0.05). The fructosamine levels obtained in this study were comparable to those found in dogs suffering from diabetes (> 340 \u03bcmol/L plasma fructosamine levels). This is the first study reporting the content of protein carbonyls in canine plasma. These results demonstrate that protein carbonyls are formed in higher amount in dog';s plasma with glucose levels similar to diabetic patients compared with the plasma control. Although, these results were obtained using an ex vivo system, it provides new information about the occurrence of AGEs during glycation of canine plasma proteins. Certainly, future studies should be performed using samples from diabetic patients in order to expand our knowledge about the formation and clinical impact of these compounds in dogs.\n\nThe study of the formation of protein carbonyls, due to the glycation of proteins, could represent a new tool to elucidate the metabolic pathways that lead to the formation of AGEs and consequently aid in the development of new therapeutic strategies for the treatment of diabetic patients in dogs. \n\nAlyssa Bryce 1 , Tracey Rossi 1 , Colleen Tansey 2 , Lisa A. Murphy 3 , Reid Nakamura 4 , Ruth Murphy 5 1 Southern California Veterinary Specialty Hospital, Irvine, CA, USA, 2 Inland Valley Veterinary Specialists and Emergency \"Center\", Upland, CA, USA, 3 Veterinary Speciality \"Center\" of Delaware, Newcastle, DE, USA, 4 Veterinary Emergency and Speciality \"Center\", Thousand Oaks, CA, USA, 5 Beaumont Hospital, Dublin, Ireland, Galway, Galway, Ireland\n\nMultiple studies have found veterinarians to be at a higher risk for suicide compared to the general population. Risk factors that have been associated with psychological distress in veterinarians include being a practice associate, practicing for less than 20 years and practicing shelter medicine. For human physicians, patient complaints lead to increased risk of depression, anxiety and suicide. Secondary effects of these complaints on physicians include practicing medicine more defensively, avoiding high risk procedures or patients and performing unnecessary diagnostics. Veterinary medicine, due to the need for owners to use their own disposable income, leads to different potential sources of conflict between veterinarians and clients,\n\nThe purpose of this study was to investigate the effect of client complaints on small animal veterinary internist's welfare, their job satisfaction, as well as the way they practice veterinary medicine. A web-based anonymous questionnaire was made available through the American College Veterinary Internal Medicine sub-specialty Small Animal Internal Medicine E-mail List Serve between January 1 st and March 31 st 2017. 92 surveys were obtained and available for review. 64% of respondents had received a client complaint within the preceding 6 months with the cost of care the most common reason. The majority of respondents (96%) worried to varying degrees about a client complaint being made against them. More concerning, almost 35% reported being verbally assaulted by a client within the preceding six months and 27% reported being threatened with litigation. A majority reported that they have changed the way they practice veterinary medicine to avoid a complaint being made against them and 43% said they had considered changing their career because of client complaints.\n\nThe study confirmed that client complaints are a common source of distress for veterinary internists. The high percentage of conflicts being due to cost of care illustrates a central problem in veterinary medicine that is an issue most veterinarians cannot control. Veterinarians need to consider how client education on cost of care can be achieved. There also needs to be a way or forum that allows veterinarians to openly discuss client complaints and how to deal with them in a supportive environment. As veterinary medicine becomes more advanced and we offer more expensive treatments and procedures, the issue of client complaints and communication will likely continue to grow.\n\nStrategies to Improve Case Outcome When Referral is Not Affordable Referral to an internist is often in the best interest of a patient, particularly if the case involves a chronic, refractory, or undiagnosed condition. Unfortunately, many pet owners cannot afford the cost of referral. In these instances, the general practitioner is challenged with treating these complicated cases on a limited budget. Owners may even elect euthanasia due to cost of care. General practitioners may seek guidance from an internist in order to discuss diagnostic and treatment options for patients that need referral care but whose owners cannot afford it. Such consultations are frequently limited to a single phone conversation or email, and outcome is therefore unknown by the consulting internist. Additional strategies to improve options and outcome in these financially challenging cases may be beneficial to both general practitioners and patients. Furthermore, increasing the awareness of and preparedness of veterinary students for these challenges may improve their abilities to approach cases more efficiently when owners are on a limited budget.\n\nA descriptive study was performed to determine the usefulness of onsite consultations with a boarded internist, case follow-up with an internist, and written diagnostic and therapeutic protocols for selected internal medicine conditions. Fourth-year veterinary students participated in weekly on-site consultations and development of protocols.\n\nA total of 35 veterinarians and 15 small animal veterinary practices participated in the study. Each practice was visited three times over the course of one year, and 133 total consults were conducted. A collection of 38 protocols for different internal medicine conditions was given to each practitioner.\n\nData was collected from pre-and post-participation surveys of fourth-year veterinary students and participating veterinarians. Prior to participation, 90% of veterinary students did not feel confident choosing the best diagnostic and therapeutic approach to internal medicine cases when owners were on a budget and could not afford referral. 100% of students felt that training in this area should be part of their education. After participation in the on-site consults and protocol development, 63% of students felt confident choosing the best approach to these cases, and 59% were \"highly likely\" to use the protocols in general practice.\n\nLack of a diagnosis, uncertainty about the most appropriate diagnostics, and the need for a special procedure were the three most common reasons general practitioners recommended referral. Over 50% of participating veterinarians noted that only 25% of dog owners agreed to referral, and 94% of veterinarians noted that expense was the primary reason owners declined referral. Only 28% of veterinarians were \"always comfortable\" with these cases and 72% were \"sometimes comfortable.\" 83% of veterinarians expressed the desire for lower-cost options, such as treatment protocols, when owners cannot afford referral. After completion of the project, 83% of veterinarians noted that both the on-site consultations and protocols were \"highly beneficial.\" The areas of greatest improvement were their comfort level with treating referral-level cases in general practice, case outcome, and patient care. 100% of veterinarians believed that patient quality of life improved, and 100% wanted to continue participating in on-site consultations.\n\nIn summary, on-site internal medicine consultations and cost-effective diagnostic and treatment protocols for various internal medicine conditions benefitted both veterinary students and general practitioners.\n\nThe cost of veterinary care, especially referral medicine, is not affordable for many owners. Veterinary students should be exposed to these challenges and should be trained in the most cost-effective approach to these cases. Similarly, general practitioners may be able to more successfully and efficiently diagnose and treat challenging internal medicine cases with the proposed strategies when owners decline referral. We hypothesised that CKCS, irrespective of disease status, would have increased fibrosis in multiple organs compared with other breeds.\n\nPost-mortem samples of CKCS were collected prospectively though a donation scheme available to owners and veterinarians. Collection was irrespective of disease state or antemortem diagnosis. Clinical information was obtained where possible. Liver, pancreas, kidney and lung were stored as formalin-fixed paraffin-imbedded samples. Tissues were matched by age and histopathologic diagnosis to tissues from non-CKCS breed dogs. Sirius red staining, highlighting fibrosis, was performed and slides digitized for objective analysis. Software analysed for red staining and scored this as a proportion of the tissue volume. Those analysing were blinded to breed and pathologic diagnosis.\n\nForty CKCS (liver n=38; pancreas n=36; kidney n=37; lung n=35) & 31 non-CKCS (liver n=14; pancreas n=9; kidney n=11; lung n=12) were included, comprising 22 breeds. There was no significant difference between organ fibrosis scores in CKCS and controls. However, in CKCS, moderate but significant correlations were identified between liver fibrosis and pancreas or lung fibrosis; additionally, significant correlation was found between lung and renal fibrosis. Insufficient cases with multiple organs precluded analysis in non-CKCS.\n\nIn conclusion, CKCS didn';t show increased fibrosis compared with matched controls, but fibrosis was correlated across organs. Further studies are indicated to assess multiple organs in other dog breeds to confirm the significance of this finding. decision making, but also for cancer staging and prognostication. The purpose of this study was to describe the presence, number, size, shape, attenuation and enhancement pattern of abdominal lymph nodes on CT in healthy cats and assess for correlations to patient characteristics.\n\nSixteen healthy cats without clinical or biochemical evidence of disease underwent sedated pre-and post-contrast CT exams of the entire abdomen. The number, size, shape, attenuation, enhancement pattern and presence of intranodal fat of the following lymph \"center\"s were evaluated by two readers, including a board-certified radiologist: aortic lumbar, renal, hepatic, splenic, gastric, pancreaticoduodenal, jejunal, ileocecal, colic, caudal mesenteric, medial iliac, sacral and inguinal.\n\nAssessments were compared to patient characteristics with Pearson's correlation and student t-tests used for the statistical analysis.\n\nA total of 525 abdominal lymph nodes were readily identified on CT with caudal mesenteric, colic, hepatic, inguinal, and pancreaticoduodenal lymph nodes identified in 16/16 cats. Body weight and sex were not associated with differences in the overall number of lymph nodes identified (p =0.3845 and 0.8565, respectively). Lymph node size and shape varied between lymph \"center\"s with nearly all lymph nodes homogenously contrast enhancing (515/525). Significant negative correlations were identified between the length (p =0.0166) and width All hospitalized dogs treated with intravenous fluids during the study period were eligible for inclusion. The initial fluid therapy (rate [ml/kg/ d] and fluid type) and any in-hospital adjustments in fluid rate were recorded until discharge or death as well as the managing service (ECC, Surgery or ACVIM based specialty). Data normality was assessed using the Shapiro-Wilk test and analyzed with a t-test with a p < 0.05 considered significant.\n\nTwo hundred and eighty-three dogs were included, receiving 862 dog-days of fluid therapy, with a median duration of 3 days (range examined thoroughly with the Stewart's method and the Fencl's semiquantitative method. Along with monitoring, TNF-\u03b1 and IL-6, and nitric oxide in plasma were measured.\n\nThis study evaluated the effects of 3% HHES in controlled hemorrhagic shock dog model compared to four conventional fluids in three aspects: volume expansion, systemic and tissue perfusion response, and acid-base status. In the aspect of volume expansion, LRS, 6% HES, and 3% HHES resuscitated significantly larger volume than 7% HS and 7% HHES but LRS and 6% HES were considered as overexpansion of intravascular volume (p < 0.05). Hemodynamic data coincides with volumetric results. Three percent HHES as well as other four fluids provided sufficient systemic oxygenation and perfusion yet the further examination should be conducted in hemorrhagic shock model based on oxygen debt. Infusion of 3% HHES was beneficial to the acidotic state of hemorrhagic shock without dilutional acidosis owing to transient hypernatremia and hyperchloremia.\n\nIn conclusion, the data suggest that 3% HHES support sufficient volume expansion without overloading, return of systemic oxygenation indices and lactate to control level, and the superior resuscitation benefits on acid-base status and inflammatory stability after reperfusion injury than conventional resuscitation fluids. Thus, 3% HHES could be the best alternative solution that compensate dosage disadvantages of conventional crystalloid or colloid administration. Oxidative stress is primarily assessed through the activity of antioxidant enzymes, the concentration of endogenous antioxidants, and byproducts of oxidative damage. F2-isoprostanes, a byproduct of lipid peroxidation, were determined to be the best marker of oxidative injury in a rodent model of oxidative stress, and are stable and easily measured in urine. In people, the gold standard for measurement of urinary F2-isoprostanes is gas chromatography-mass spectrometry (GC-MS), but in animals the majority of studies have utilized enzymelinked immunosorbent assay (ELISA) for measurement of F2-isoprostanes. A previous study compared these two methods in small populations of dogs, cats, horses, and cows. Poor agreement between these methods was identified in dogs, horses, and cows.\n\nHowever, fair agreement between these methods was identified in cats. The objective of this study was to evaluate the agreement between GC-MS and ELISA for measurement of urinary F2-isoprostanes in a large population of cats including a range from healthy to clinically ill cats.\n\nSkeletally mature cats were recruited. Health status in each cat was determined by a physical examination, complete blood count (CBC), serum chemistry profile, thyroid hormone (T4) and urinalysis. Cats were defined as systemically ill if evidence of illness was identified on physical examination (persistent fever, injected mucous membranes) and/or evidence of inflammation and/or organ system dysfunction.\n\nUrine was collected non-invasively (free catch) in all cats unless otherwise indicated due to the disease process in the systemically ill cats.\n\nUrinary F2-isoprostanes were measured by GC-MS and ELISA in all urine samples.\n\nFifty cats were enrolled in the study. Twenty-five cats were determined to be healthy, while the other 25 were determined to be systemically ill. All urine samples had detectable levels of F2-isoprostanes. A significant negative correlation was identified between the two methods (\u03c1 = 0.364, P=0.009). No significant correlation was identified when the healthy and systemically ill cats were compared in sub-group analysis. Passing and Bablok regression showed poor agreement between the two methods. This comparison demonstrated a non-linear relationship and proportional bias. The concentration of urinary F2-isoprostanes as measured by ELISA was significantly lower in systemically ill cats when compared to healthy cats (P=0.002). No significant difference was identified when urinary F2-isoprostanes were measured by GC-MS (P=0.068).\n\nThese results indicate that GC-MS is the only method recommended for the assessment of urinary F2-isoprostanes in cats. The expected increase in urinary F2-isoprostanes in systemically ill cats was not identified, so caution is still warranted in interpreting this test regardless of method. Future research should use GC-MS to identify normal reference ranges and variability of urinary F2-isoprostanes in cats. Expression of inducible nitric oxide synthase (iNOS), IL-6 and IL-1\u03b2 was significantly (one-way ANOVA) decreased in LPS-stimulated RAW 264.7 cells co-cultured with na\u00efve canine MSCs compared to that in LPS-stimulated RAW 264.7 cells alone. Furthermore, antiinflammatory effects of TNF-\u03b1-and IFN-\u03b3-primed canine MSCs were significantly increased compared with those of na\u00efve canine MSCs.\n\nExpression of cyclooxygenase 2 (COX-2) and prostaglandin E 2 (PGE 2 ) were likewise significantly increased in primed canine MSCs. The level of iNOS protein in LPS-stimulated RAW 264.7 cells co-cultured with the primed canine MSCs was decreased, but it increased when the cells were treated with NS-398(PGE 2 inhibitor).\n\nIn conclusion, compared with na\u00efve canine MSCs, cells primed with TNF-\u03b1 and IFN-\u03b3 cause a greater reduction in release of antiinflammatory cytokines from LPS-stimulated RAW 264.7 cells; the mechanism is upregulation of the COX-2/PGE 2 pathway.\n\nMatthew E. Miller, Kamoltip Thungrat, Jey W. Koehler, Dawn M. Boothe Auburn University College of Veterinary Medicine, Auburn, AL, USA\n\nThe endocannabinoid system (ECS) is comprised of endogenous signaling molecules known as endocannabinoids, and the G-proteincoupled receptors to which they bind. In recent decades, research has found relationships between the ECS and memory, nociception, inflammation, appetite, metabolism, and more.\n\nIn the interest of providing a framework for the eventual development of safe and effective cannabinoid therapies in veterinary species, this paper sought to characterize the two predominant cannabinoid receptors-CB1R and CB2R-by quantification and localization.\n\nTissue samples were acquired from living adult dogs that presented to the AU-SATH Surgery Department for procedures related to the tissues obtained. Following collection, the tissue samples were placed in either RNAlater\u00ae or formalin. RNAlater\u00ae samples were stored until processing. Formalin samples were submitted to histopathology for processing. In all, 35 tissue samples were collected in RNAlater\u00ae, and 12 were collected in formalin.\n\nRNA was extracted from tissues stored in RNAlater\u00ae, converted to cDNA, and quantified using quantitative PCR (qPCR). The data were reported as ratios of CB1R or CB2R gene expression to the constitutively-expressed housekeeping gene B2M.\n\nImmunohistochemistry was run using previously-described antibodies, and selective staining was verified by Western blot.\n\nPreviously undescribed findings in the immunohistochemistry were limited; CB2 receptors stained most darkly in the endothelial cell membranes of most tissues, with less-significant staining scattered throughout the parenchyma, localized microscopically to the cell membranes.\n\nQuantification showed high expression of CB1R gene in the blood, brain, testicles, ovary and uterus, but low expression in kidney, lung, liver and lymph node. Expression values for the CB2R gene have been somewhat limited but show high expression in blood and lymph nodes. While many findings from previous studies were confirmed, such as the high concentration of CB1R in gray matter and the high concentration of CB2R in blood and lymph nodes, the study also found unexpectedly high quantities of CB2R in both the male and female gonads.\n\nAdditionally, unexpectedly low levels of CB2R expression were found in the lung and the liver compared to human and mouse models.\n\nThese results invite future investigation into the reproductive applications of cannabinoids, as well as possible upregulation following exogenous exposure to explain the relatively low expression of CB1R in liver and lung tissues. Quantification of specific regions of the canine brain may also prove useful in the development of pharmaceutical cannabinoids. The goal in this study was to evaluate the pharmacodynamics (PD) of MPA after 1 week of varying oral doses of MMF in 10 healthy cats.\n\nThe PD of MPA was evaluated following oral administration of MMF 10mg/kg PO BID (n=3), 15mg/kg PO BID (n=3), and 15mg/kg PO TID (n=4) for up to 1 week in 10 cats. Blood samples were taken prior to the first administration of MMF, 24 hours into treatment, at day 7 and 12 hours after the last oral dose of MMF.\n\nIsolation of peripheral blood mononuclear cells (PBMC) was performed using standard methods after each blood draw. All samples were cryopreserved and later thawed for subsequent flow cytometry and analyzed in 1 batch. Percentage of positively stained cells for CD4 + and CD8 + antibody were determined by flow cytometry.\n\nTotal isolated PBMC numbers were variable in all cats tested at premedication, after initiation of oral MPA on day 1, day 7, and after 12 hours of the last dose of oral MMF. There was minimal to no change in the average CD4 + and CD8 + lymphocyte counts in the 10mg/kg BID and 15mg/kg BID groups. There was a mild reduction in CD4 + but not CD8 + lymphocytes in cats treated with 15mg/kg TID of MMF. Overall, the CD4 + :CD8 + ratios were nearly the same in the 10mg/kg BID, 15mg/kg BID, and 15mg/kg TID treatment groups.\n\nThis study describes the PD of multi-day oral administration of MMF in 10 healthy cats. There was little to no change in the CD4 + lymphocyte counts in the 2 BID groups, and a mild reduction in the 15mg/kg TID group. The CD8 + lymphocytes and the CD4 + :CD8 + ratios, showed little to no change for all 3 groups. The results of this study did not\n\nshow an appreciable reduction in T cell suppression. This may be due a short treatment period or due to the presence of un-activated lymphocytes as the cats were healthy. Future studies will evaluate the PD of MPA in clinically affected feline patients receiving MMF. Recent studies have highlighted the potential for CYP3A variation in susceptibility to several common phenotypes, including cancer. The objectives of this study were to analyze the sequencing of the canine CYP3A12 gene (NCBI accession NP_001003340) from thirteen clientowned dogs with MCT (Grade II-III) and to investigate the patterns of sequence variation that related to clinical response to therapy. Fisher'; s exact test was used to assess the correlation between SNPs and clinical response. All 13 patients receiving vinblastine showed signs of toxicity, including vomiting, anorexia, and thrombocytopenia. Three sets of point mutations were found in 6 patients with silent (T 12574 C, n = 1), missense (T 12564 G, n = 2) with a change in the amino acid (Ile169Leu), and frameshift mutations (Asp153Glufs, n = 3) in the coding sequences. Three of 6 patients that showed missense (n = 1) and frameshift mutations (n = 2) presented with recurrent MCT after vinblastine chemotherapy. This could represent a further step toward predicted the clinical response of anticancer chemotherapy. between patients with controlled clinical signs (n=127, 55%) versus those with uncontrolled disease (n=105, 45%). The most common diseases being treated were encephalitis (n = 84), immune-mediated hemolytic anemia or thrombocytopenia (n = 73), inflammatory bowel disease (IBD, n = 59), and other (n = 16, e.g. atopic dermatitis, anal furunculosis, uveitis). CsA peak levels for controlled (1119 \u00b1 704 ng/ml) versus uncontrolled patients (994.84 \u00b1 606 ng/ml) failed to demonstrate a statistical difference (P = 0.15). The t 1/2 of controlled patients (20 \u00b1 40 hrs) was significantly longer than uncontrolled patients (11 \u00b1 20 hrs) (P = 0.02). Significant variability was found in both peak CsA levels and t 1/2 . Co-treatment with prednisolone, leflunomide, and ketoconazole, and diseases also increased variability. Variability in CsA disposition supports the need for TDM to establish patient therapeutic range. The IDEXX-SDMA TM test is a non-invasive test being marketed for diagnosing and monitoring chronic kidney disease in cats and dogs.\n\nThe objective of this study was to determine if the serum concentration SDMA and creatinine increase in cats with meloxicam-induced kidney damage.\n\nFemale cats (n=12) were allocated to 2 experimental groups: control group (n=6) and meloxicam group (n=6). Cats in the control and meloxicam groups were treated with saline and meloxicam, respectively. Serum SDMA IDEXX TM and creatinine concentrations were assessed before and after the administration of the treatments. Histopathology was performed on kidneys from all cats.\n\nIn the meloxicam group, severe tubular changes were observed in 5 out of 6 cats. Before starting the administration of the treatments, all cats had comparable serum concentrations of creatinine (\u22641.6 mg/dL) and SDMA (\u226414mg/dL). Unexpectedly, SDMA concentrations rose above the normal reference range only in 3 out of the 5 cats with meloxicam-induced kidney damage. The time required for SDMA and creatinine to surpass the reference concentration was similar for each cat.\n\nThis study is the first one reporting the changes in the serum concentration of SDMA in healthy cats that develop NSAID-kidney damage.\n\nResults of this study suggest that; (i) the serum concentration of SDMA did not detect kidney tubular damage induced by the repeated administration of meloxicam earlier than creatinine in cats and (ii) clinicians may be unable to detect extensive kidney tubular damage in some cats by using SDMA and creatinine, at least until glomerulus are severely affected. This was a multi-institutional study (n=5 university hospitals). Patients prescribed oral fluconazole for confirmed or suspected fungal disease were enrolled. Dosing protocols were determined by treating clinicians. One to three serum samples were collected at opportunistic times per fluconazole dose interval; samples from multiple visits were encouraged. Samples were stored frozen and analyzed with a validated liquid chromatography mass spectrometry method. Clinical signs included fever (n=6), cough (5), tachypnea (3), regurgitation (2), ptyalism (1), hematemesis (1), and hemoptysis (1). On CBC, peripheral neutrophilia (2) and neutropenia (1) were noted; bands or neutrophil toxicity were common (5) . On BALF cytology, degenerate neutrophils (4/6) and intracellular bacteria (3/6) were observed. Secondary bacterial pneumonia (4) blinded to diagnosis obtained measurements on a lateral radiograph: number of intercostal spaces from the first rib to carina (ICS), distance from caudal aspect of manubrium to carina (MC), standardized vertebral score by drawing MC from the fourth thoracic vertebrae and counting numbers of included vertebral bodies (VS), and distance from first rib to carina (RC). A two factor ANOVA was used; data were reported as mean\u00b1SEM. Seventy-eight cats were included. The mass group had increased ICS, MC, VS, and RC compared to other groups.\n\nCompared to normal, cats with CPE and NCPE had increased ICS, and CPE cats had increased MC and RC.\n\nThese radiographic measurements may aid clinicians in differentiating between mediastinal masses and pleural effusion in cats.\n\nMorgane Canonne 1 , Elodie Roels 2 , Frederic Billen 2 , Ghita Benchekroun 3 , C\u00e9cile Clercx 2 1 Ecole National V\u00e9t\u00e9rinaire de Maisons Alfort, France, Maisons Alfort, Ilede-France, France, 2 NA, Li\u00e8ge, Liege, Belgium, 3 NA, Maisons Alfort, Ilede-France, France\n\nDespite the widespread use of vaccines, Bordetella bronchiseptica (Bb) infection is still commonly diagnosed in dogs with lower airway infection. As fatal pneumonia or chronic presentation may be observed, efficient treatment is required. Aerosolized gentamicin was historically described to maximize local drug delivery with minimal systemic absorption but clinical response to standardized protocols has not been reported.\n\nThe objective of this study was to compare clinical response to two different protocols of aerosolized gentamicin in dogs with confirmed respiratory Bb infection.\n\npositive bacterial culture or PCR on bronchoalveolar lavage fluid. Dogs were recruited over a 5 years'; period (2012-2017) . In all dogs, gentamicin was aerosolized for 3 10 minutes twice daily for 3 3 weeks, using a face mask and various types of ultrasonic nebulizers. Either a dose of 4 mg/kg of gentamicin diluted with 1-4 parts of saline was used (protocol 1, n=13) or a fixed amount of undiluted 5% gentamicin (protocol 2, n=24). At first recheck after 3 to _4 weeks, treatment was either stopped or pursued in 3-week increments until clinical cure.\n\nClinical cure was defined as resolution of clinical signs (absence of cough) and radiographical lesions improvement/resolution. Proportion of dogs clinically cured at first recheck and median total duration of treatment were compared between treatment protocols; additionally, the effect of some factors (age, breed, co-infections with other bacteria including M. cynos, presence of alveolar lesions, previous steroid therapy and severity of neutrophilia of the lavage) on cure and treatment duration was analysed (Chi-square and Mann-Whitney tests).\n\nThirty-seven dogs were recruited (18 males, 19 females). Median age was 6 months [5weeks-7years] and median BW was 6.8 kg. Brachycephalic breeds, Yorkshires and Chihuahuas were overrepresented (20/37 dogs (54%)) and 35/37 dogs (95%) had previously been treated with oral antimicrobial therapy with poor or no response.\n\nTwenty dogs (54%) had alveolar pattern on thoracic radiographs suggestive of bronchopneumonia. There was no difference in demographic and clinical data between dogs included in both protocols.\n\nTreatment was well tolerated in all dogs and no undesirable effect was observed. Clinical cure at first recheck tended to be more frequently observed in dogs treated with protocol 2 (13/24 [54%] dogs) compared with protocol 1 (3/13 [23%] dogs) (p=0.06). The median duration of treatment was shorter with protocol 2 (4 weeks, range 3-9) compared with protocol 1 (6 weeks, range 3-8) (p=0.03). None of the clinical or pathological parameter studied was associated with clinical response.\n\nIn conclusion, while being more time-consuming than oral antimicrobial therapy, aerosolized gentamicin appears safe and promising for treating dogs with Bb infection, particularly for cases refractory to oral antimicrobial therapy. Protocol 2 using undiluted 5% solution for 3 10 minutes, that allows delivery of gentamycin in amounts proportional to the individual minute volume, could offer shorter duration of treatment. Abnormalities on VFSS were categorized as gastroesophageal reflux (GER), hiatal hernia, dysmotility and aspiration.\n\nThirty-two cases met inclusion criteria. Median(IQR) age was 6(18.1) years with no identified breed or sex predisposition. Median(IQR) duration of cough was 4(7.25) months. Thoracic radiographs were unremarkable in 10/32 dogs, with evidence of aspiration pneumonia in 4/32. Abnormalities on VFSS were detected in 30/32 dogs. Abnormalities included GER in 13/30 dogs with large volume GER in 5/6 dogs later diagnosed with laryngeal paralysis and 3/3 dogs diagnosed via VFSS with sliding hiatal hernia. Pharyngeal and/or esophageal hypomotility were each found in 7/30 dogs. Megaesophagus was noted in 4/30 dogs. Macroaspiration was identified in 4/30 dogs.\n\nFinal respiratory diagnoses for dogs with abnormal VFSS included chronic bronchitis (9), laryngeal paralysis (6), and laryngeal polyp (1) Tracheal collapse is a devastating disease primarily affecting small breed dogs. When medical management fails, surgical therapy with cervical tracheal rings and/or tracheal stents may be used for palliation of clinical signs. Tracheal rings may be preferred in cases of cervical or thoracic inlet collapse in order to prevent stent-associated complications such as granulation tissues, persistent cough or stent fracture. However, as tracheal collapse is considered progressive, dogs that initially improved following tracheal ring placement may have recurrent intra-thoracic airway obstruction that requires an intrathoracic stent for palliation. The purpose of this study is to evaluate the characteristics and outcome of dogs that received tracheal stents following earlier placement of tracheal rings.\n\nThe electronic medical record was searched for dogs that underwent placement tracheal rings. The records were retrieved, and records of dogs that subsequently underwent placement of a tracheal stent were further evaluated for breed, age at placement of rings and duration between rings and stent were identified.\n\nForty-seven dogs underwent tracheal ring placement during the study period, including 36 Yorkshire terriers and 11 Non-Yorkshire terriers.\n\nTwo dogs had both rings and stents placed during a single hospitalization prior to discharge. One dog was euthanized after ring placement following the development of suspected ARDS. Forty-four dogs were discharged following isolated tracheal ring placement. Nine Yorkshire terriers (19%) subsequently underwent tracheal stent placement a median of 3.6 years (range 1.3 to 5.8 years) following initial placement of tracheal rings. Dogs that underwent both tracheal rings and stenting were significantly (p = 0.03) younger than dogs that did not ultimately have both procedures at the time of the original ring placement (5.6 \u00b11.3 years; 7.6\u00b12.6 years). One dog that underwent both procedures had a seizure and died at home two days following discharge. Two dogs subsequently were euthanized due to progressive airway obstruction from stent-associated granulation tissue, and one dog died due to pneumonia.\n\nTracheal stenting may be performed after earlier ring placement in dogs with progressive airway disease. Younger age at initial ring placement as well as being a Yorkshire terrier may increase the likelihood undergoing subsequent tracheal stenting.\n\nEpiglottic Retroversion: Concurrent Diseases, Management, and Outcome in 13 Cases (2012) (2013) (2014) (2015) (2016) (2017) A. Taylor, Elizabeth Rozanski, J. Gladden Tufts University, North Grafton, MA, USA Epiglottic retroversion (ER) is the displacement of the epiglottis into the lumen of the larynx resulting in inspiratory airflow limitation and/or distress. It is unclear how often ER is a primary disease in dogs versus a condition that develops secondarily to other upper airway obstructive diseases. The goal of this study was to describe the concurrent diseases, management, and outcome in dogs with ER.\n\nThe electronic medical records system was searched for \"epiglottic retroversion,\" \"epiglottic entrapment\" and \"epiglotto-pexy.\" Diagnosis was made upon sedated oral examination and tracheoscopy, with or without doxapram administration. The records were reviewed and data was collected for descriptive analysis.\n\nThirteen dogs met the inclusion criteria. The following breeds were represented: Yorkshire terrier (n=5), and one each of chihuahua, havanese, miniature schnauzer, Parson Russell terrier, pomeranian, pug, shih tzu, and toy poodle. Seven dogs were males (6 neutered) and six were females (5 spayed). The mean age was 9.3 \u00b1 2.4 years, and the mean weight was 4.6 \u00b1 2.8 kg.\n\nTwo dogs had ER with no evidence of concurrent upper airway disease. The remaining eleven dogs had a combination of concurrent tracheal collapse, elongated soft palate, and laryngeal paralysis with concurrent elongated soft palate being the most common (n=6).\n\nTreatment included an epiglotto-pexy performed in 12 of 13 dogs, and a epiglottectomy was performed in one dog. Four dogs had a staphylectomy, and one dog underwent an arytenoid lateralization procedure. All dogs recovered and were discharged.\n\nEpiglottic retroversion may contribute to respiratory distress and is commonly is associated with other airway diseases. Additionally, epiglotto-pexy in dogs with ER may help reduce clinical signs attributable to ER.\n\nPo-ching (Lydia) Pan 1 , Christine Savidge 2 , Pierre Amsellem 2 , Stephanie Hamilton 2 1 Atlantic Veterinary College, University of Prince Edward Island, Charlottetown, PI, Canada, 2 Atlantic Veterinary College, University of Prince Edward Island, CHARLOTTETOWN, PI, Canada\n\nObjectives of this study were to compare effects of alfaxalone and propofol on laryngeal function and evaluate laryngeal function with a numerical, objective scoring system via computerized software.\n\nTen healthy beagle dogs were randomly assigned to receive either propofol or alfaxalone in this crossover prospective study. Propofol was administered at 5 mg/kg/min intravenously and alfaxalone was administered at 2 mg/kg/min intravenously until the dogs'; mouths could be opened for videolaryngoscopy. Two weeks later, dogs were evaluated using the other anesthetic agent. Videos were analyzed by GlotAnTools and Image J software.\n\nValues of the area of the rima glottidis (A) and major length axis (L) (Figure 1 ) were processed at 0.02 second increments from the final 30 seconds of recording. A normalized measure was computed as A/L, representing the \"elongatedness\" of the rima glottidis. Small (large) values correspond to thin (thick) shapes along the length axis. The breath with the greatest laryngeal movement was identified. The difference between maximal and minimal values in each breathing cycle was calculated.\n\nShape values ranged between 9.6 and 138 (pixel lengths) and the differences between maximal and minimal values ranged between 2.6 and 61 (pixel lengths). The final statistical model showed a significant drug effect (p=0.016); the variability in shape for alfaxalone was about 40% (39.5%, 95% CI: 19.6%-79.6%) of that for propofol.\n\nPropofol proved superior for evaluation of laryngeal function in healthy beagles. Software programs provided objective numbers for comparison. "}