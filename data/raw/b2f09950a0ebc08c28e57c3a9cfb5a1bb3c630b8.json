{"title": "Intake and growth in transported Holstein calves classified as diarrheic or healthy within the first 21 days after arrival in a retrospective observational study", "body": "Intestinal disorders are common in newborn calves. Several reports have estimated morbidity and treatment on dairy farms over the last few decades. Curtis et al. (1988) estimated the incidence rate of diarrhea in New York Holstein herds to be 9.9 per 100 calves during the first 14 d and 5.2 per 100 calves from 15 to 90 d. The median age of diarrhea was 6 d for the first 14 d of life and 30 d for 15 to 90 d of age. A longitudinal, cross-sectional survey on 135 dairy herds from Norway indicated relatively low diarrheic incidence: only 4.7% of the samples were classified as diarrheic over the 2 yr study (Gulliksen et al., 2009) . Meanwhile, a Dutch study observed a prevalence of diarrhea of 19.1% in calves under 22 d (Bartels et al., 2010) . In that study, the percentage of calves (51.6%) with non-normal feces-which were classified as \"custard-like\" feces or diarrhea-was highest in the second week of life compared with the first and third weeks (Bartels et al., 2010) . In Ontario herds, the greatest risk of treatment for diarrhea was at 10 d of age (Waltner-Toews et al., 1986; Windeyer et al., 2014) , with 23% of calves treated for diarrhea (Windeyer et al., 2014) . In the United States, the most recent information comes from a survey conducted in 2014, which estimated that approximately 21.1% of preweaned heifers had a digestive disease, and that diarrhea or other digestive problems accounted for 56.4% of preweaning heifer mortality (NAHMS, 2014) . Furthermore, of the preweaning heifers with digestive disorders, 71.8% were treated with an antibiotic during this period (NAHMS, 2014) .\n\nThese estimates show that neonatal diarrhea is a prevalent and recurring issue in calf management systems in the United States and worldwide. Neonatal diarrhea is frequently observed from 3 to 21 d of age, but its onset and duration is determined by the number of pathogens involved and the immune condition of the animal (Butler and Clark, 1994) . The major pathogens identified as contributing to enteric challenge in calves during the preweaning period include Escherichia coli K99, rotavirus, coronavirus, Salmonella spp., and Cryptosporidium parvum (Izzo et al., 2011; Cho and Yoon, 2014) . In a Spanish study, the detection rates of E. coli, rotavirus, coronavirus, and C. parvum were 11.9, 41.9, 7.3, and 52.3% of samples (Garc\u00eda et al., 2000) , whereas a Swiss study estimated prevalence in diarrheic calves of 6, 59, 8, and 55% (Uhde et al., 2008) , respectively. The presence of enteric pathogens in feces does not directly indicate the cause of diarrhea; however, evidence shows a strong association between the 2 (De Rycke et al., 1986; Garc\u00eda et al., 2000) . As well, 2 or more enteropathogens are often detected at the same time; C. parvum and rotavirus are the most prevalent combination (de la Fuente et al., 1999; Garc\u00eda et al., 2000) .\n\nMany of the estimates for diarrhea in dairy calves are generated from visual observation of the feces and the calf, by personnel working with the calves on a daily basis or by a herd veterinarian (Curtis et al., 1988; Gulliksen et al., 2009; Bartels et al., 2010; Windeyer et al., 2014) . Other studies have identified farms or individual calves with reported incidences of diarrhea to collect fecal samples as a way of characterizing the incidence of different enteric pathogens (de la Fuente et al., 1999; Garc\u00eda et al., 2000; Izzo et al., 2011) . Many study authors have tried to characterize the incidence and major pathogens present across many farms in a larger region or country. Visual observation of feces is the most easily identifiable sign of diarrhea, but it does not always directly indicate an infection by an enteric pathogen, which can be a limitation. However, a scoring system can rank the severity of the diarrhea by identifying feces that are normal or abnormal, with a set definition for each score. A study conducted by Araujo et al. (2015) classified calves as diarrheic when calves had an elevated fecal score (\u22653 on a 5-point scale; Lesmeister and Heinrichs, 2004) for \u22653 consecutive days.\n\nThe health of calves has been connected to longevity, and calves that have been treated with antibiotics show decreased lifetime milk production (Soberon et al., 2012) . As well, the number of days calves are sick in the first 4 mo of life has negative effects on firstlactation 305-d mature-equivalent milk yield and actual milk, protein, and fat production (Heinrichs and Heinrichs, 2011 ). An increased plane of nutrition during the preweaning period is also linked to improved lifetime production (Soberon et al., 2012; Soberon and Van Amburgh, 2013) . As a result, strategies that can improve health and maximize growth during the preweaning period should improve production potential and the longevity of replacement heifers. The objective of this retrospective observational study was to evaluate how the intake and growth of calves with diarrhea in the first 21 d after arrival compares with that of calves that remained healthy.\n\nThe database was developed from 4 experiments completed at the University of Illinois between the fall of 2013 and the fall of 2017 (Table 1) . Individual calf experimental data were obtained from Microsoft Excel (Microsoft Corp., Redmond, WA) files from each experiment. All experiments included in the data set were nutritional experiments performed under commercial settings and were not expected to induce diarrhea. Information for inclusion included experiments that recorded daily intakes of milk replacer (MR), free water (FW), electrolyte solution (EC), and starter, as well as weekly BW (PS500 electronic scale; Brecknell, Fairmont, MN) and frame measures. A total of 313 (253 male and 60 female) Holstein calves transported from a commercial farm or cattle dealer to the University of Illinois calf research facility (Urbana) were included in the analyses. Calves were enrolled within the first week of life. Upon their arrival at the research facility or selection at a local dairy farm, their blood was sampled from the jugular vein into 10-mL evacuated serum separation tubes (Becton Dickenson, Rutherford, NJ). Blood was centrifuged at 1,300 \u00d7 g for 15 min, and a refractometer was used to determine total protein concentration in serum. A criterion for inclusion for each experiment was a total protein concentration greater than 5.5 g/dL, indicating successful passive transfer of immunity, but data for colostrum administration were unavailable for any calves at the time of enrollment in the experiments. All calves were vaccinated based on normal facility protocols.\n\nCalves were housed in south-facing individual hutches (Calf-tel; Hampel Corp., Germantown, WI) placed approximately 1.5 m apart. Hutches were placed on a base of crushed rock, covered by landscape cloth and 10999 a layer of straw. Straw was checked daily, and more was added as needed. Temperature and humidity were determined using data from the local weather station (www .wunderground .com/ history/ ).\n\nIn our analysis, we used data for individual daily intake of feeds and water during the first 21 d after arrival at the research facility. Calves were fed MR twice daily at 0500 and 1630 h at a rate and composition specific to each experimental protocol ( Table 1 ). The intake of MR was recorded daily. Water was offered for ad libitum consumption throughout the experiments, and intake was recorded daily. Starter was also offered for ad libitum consumption, and intake was recorded daily in 3 of the 4 experiments. One experiment (experiment 2) did not offer starter during the first 21 d, so data for starter intake were not included in the data set. Weekly means for individual calves were used in the database, calculated from daily intakes. Total consumption for the 21 d after arrival for all variables was calculated for each calf.\n\nHealth checks were performed daily and used a consistent protocol among all experiments. Fecal scores were assigned using a scale of 1 to 4: 1 = normal and well formed; 2 = soft but still holds form; 3 = loose without form; and 4 = consistency of water (Osorio et al., 2012) . Calves were considered to have diarrhea if they had a fecal score >2; however, pathogens associated with diarrhea were not determined. Calves' overall appearance and behavior were also recorded. After arrival, calves' rectal temperature was measured daily for 3 d and then at any time when a calf showed signs of illness for the duration of the experiment. Navels were dipped in povidone iodine solution as needed until they were dry. Calves were monitored multiple times daily for illness and hydration status, with consideration for refusal of MR, skin pliability, eye recession, and visual observation of attitude, although a specific system was not implemented across experiments. Calves were treated as needed. Flunixin meglumine (Phoenix Pharmaceutical Inc., St. Joseph, MO) was administered to calves with a rectal temperature of 40\u00b0C or above. An occurrence of medication was defined as both an antibiotic and treatment with flunixin meglumine. An EC was administered as needed [experiment 1 used CHEERS Rehydration System (Nouriche Nutrition Products, O'Fallon, MO); experiments 2, 3, and 4 used Land O'Lakes Electrolyte System (Land O'Lakes Inc., Arden Hills, MN)], and the amount consumed was recorded. The amount of EC and the number of times per day it was offered were based on the hydration status of the calf and the amount of milk replacer consumed. The EC was offered first from a bottle; however, if the calf did not drink and required additional fluids to maintain hydration status, the calf was force-fed the Table 1 . Experiments from which data were used in a pooled analysis to examine the association between the health of dairy calves with intake and growth in the first 21 d after arrival at the research facility Morrison (2018) EC through an esophageal feeder. In each experiment, a single person provided oversight and management decisions for the administration of medication and EC.\n\nCalves with a fecal score of >2 for \u22653 consecutive days (Araujo et al., 2015) over the first 21 d of each experiment were retrospectively classified as diarrheic (DIA; n = 96), and the remainder were retrospectively classified as healthy (HEA; n = 217). Experiment 1 included 57 calves: 39 DIA and 18 HEA. Experiment 2 included 105 calves: 26 DIA and 79 HEA. Experiment 3 included 63 calves: 7 DIA and 56 HEA. Experiment 4 included 88 calves: 24 DIA and 64 HEA. Other health issues were minimal and were not included in the classification of health status or evaluated in combination with diarrhea. Calf data were included in the data set until day of death for individual calves.\n\nThis retrospective observational study statistically evaluated the effect of health classification on body growth, DMI, refusal of MR, diarrhea occurrence, and EC administration using the combined data from 4 experiments. Data were analyzed using PROC GLIMMIX of SAS (version 9.4; SAS Institute Inc., Cary, NC). Calf was the experimental unit. For Gaussian data, the model of variance analysis included health classification, time as a repeated measure (when appropriate), and their interaction as fixed effects. Experiment was included as a random effect in all models (St-Pierre, 2001) . Environmental temperature was included in the model as a covariate when statistically significant (P < 0.10). For BW and frame measures, initial measurements on day of arrival were used as a covariate to analyze data for each respective variable. The model of variance analysis for total cumulative intakes included classification as a fixed effect, experiment as a random effect, and environmental temperature as a covariate when significant (P < 0.10). Binary data (refusal of MR, occurrence of diarrhea, or administration of EC) were analyzed with a binomial distribution with a logit link function and a model that included classification and time as a repeated measure and their interaction as fixed effects. Experiment was included as a random effect. Count data (days refused MR, days with diarrhea, and days given EC) were analyzed with a negative binomial distribution using a log link function with the fixed effect of classification. Experiment was included as a random effect. The corrected Akaike information criterion was used to select the best covariance structure in all models. Residuals were examined for homogeneity of variance and normality assumptions by residual plots and extended Levene test. Heterogeneous variances were handled by implementing error structures that allowed for heterogeneous variances (Littell et al., 2006) . Significance was declared at P \u2264 0.05, and trends discussed when 0.05 < P \u2264 0.10. Means were separated using the Tukey adjustment.\n\nEnteric challenges continue to be one of the main health issues facing dairy calf production today. As expected with the objective of the analysis, the likelihood of occurrence of elevated fecal score (fecal score >2 for \u22653 d; Araujo et al., 2015) was greater for calves classified as DIA during the first 21 d of the experiment. The DIA calves were 5.86 [odds ratio (OR)] times more likely to have an elevated fecal score than HEA calves (P < 0.001; Table 2 ). Furthermore, the number of days that calves had an elevated fecal score in the first 21 d was lower for HEA calves than for DIA calves (1.88 vs. 6.90 \u00b1 1.19 d; P < 0.001; Table 3 ). We did not attempt to identify specific pathogens to determine the cause of the elevated fecal score, but several common enteric pathogens are implicated in calf diarrhea and likely contributed to disease in these experiments (Cho and Yoon, 2014) . The timing of infection ranges from a few days after birth to 1 to 2 wk of age or beyond, but several pathogens affect calves around 1 to 2 wk (Foster and Smith, 2009; Cho and Yoon, 2014) . Figure  1 shows the number of calves in each experiment by day first classified as diarrheic. The incidence of diarrhea as classified in this data set varied among experiments, but the average overall for the calves in our analysis was similar to a report from the United States indicating that 21.1% of preweaned heifers experience diarrhea (NAHMS, 2014) .\n\nIn these experiments, the exact age relative to birth of the calves was unknown, but we targeted enrolling calves less than 1 wk of age, and the timing of calves first being classified as DIA varied across experiments. Experiment 1 had the greatest number of DIA calves (68%), and the majority were classified as DIA within the first 5 d after arrival. These calves were estimated to be slightly older (but still under 1 wk of age) than those in the other experiments, due to their origin. As well, these calves had been transported the furthest (5 h transport time and 470 km) and were purchased from a dealer who had collected calves from multiple farms and commingled the calves before transport to our research facility. The calves from the other experiments originated from a single local farm, and research personnel selected them for inclusion in each experiment within 2 to 3 d of birth based on initial total protein and visual health assessment. Those calves were transported only 30 min and 38 km to the research facility. The proportion of calves classified as DIA in these experiments was much lower than in experiment 1, ranging from 11.1 to 27.3%. In general, we found lower incidences of DIA classification on the initial day after arrival in experiments 2, 3, and 4, but over the course of the 21 d incidence increased from d 10 to 15. Although the protocols for care were similar among experiments, the incidence, timing, and duration of diarrheic episodes in calves varied. The stressors (comingling, transportation) that calves in experiment 1 faced were likely greater than those in the other experiments, and may have impaired calves' ability to cope as well with enteric challenge (Davis and Drackley, 1998) . Calves that died within the first 21 d of arrival were included in the analysis. One calf that was classified as HEA died from bloat on d 14 after arrival. As well, 7 DIA calves died within the first 21 d after arrival, with an average day of death of 9.7 d after arrival at the research facility. Data from those calves were included until the day they died.\n\nTotal protein concentration in serum or plasma often is used on farms to evaluate passive immunity as an alternative to the gold standard, which quantifies IgG1 by radial immunodiffusion (Tyler et al., 1996; McGuirk, 2011) . Failure of passive transfer of immunity is associated with increased mortality rates (Donovan et al., 1998a; Tyler et al., 1998 Tyler et al., , 1999 . In the present study, initial serum total protein did not differ between classification groups, and values were above the recommended cutoff of 5.5 g/dL (McGuirk, 2011; P = 0.20; Table 4 ). One experiment found that total protein was not a significant risk factor for diarrhea in the preweaning period (Windeyer et al., 2014) . Results from the literature are mixed concerning the effect of successful passive transfer of immunity on reductions in diarrhea in preruminant calves. Several studies have observed no effect (McEwan et al., 1970; Caldow et al., 1988; Harp et al., 1989; Meganck et al., 2015) , but others have shown a reduction in the incidence and severity of diarrhea (Boyd, 1972; Naylor et al., 1977; Fallon et al., 1987; Lora et al., 2018) related to measures of adequate passive transfer. The type of enteropathogen, calf management, or environment may predispose calves to enteric challenge in the preweaning period.\n\nSeasonal effects may predispose calves to increased enteric morbidity. Calves born in winter had higher incidences of diarrhea than calves born in summer (Waltner-Toews et al., 1986; Curtis et al., 1988) . As well, calves born in fall were more likely to have diarrhea than calves born in the spring or summer (Windeyer et al., 2014) . In our experiment, the average ambient environmental temperature in the first 21 d after arrival was higher for DIA calves than for HEA calves (17.1 vs. 13.4 \u00b1 0.6\u00b0C; P < 0.01; Table 4 ). The odds ratio (OR) indicates the probability of an event occurring for the first classification in comparison to the second classification. If the OR is >1, the first classification is more likely to have diarrhea or be medicated than the second classification by a factor of the difference above 1. If the OR is <1, the first classification has a lower probability of occurring than the second classification.\n\n3 Fecal scores were assigned on a scale of 1 to 4: 1 = normal and well formed; 2 = soft but still holds form; 3 = loose, without form; 4 = consistency of water. Fecal scores were assigned on a scale of 1 to 4: 1 = normal and well formed; 2 = soft but still holds form; 3 = loose, without form; 4 = consistency of water.\n\nInfections (clinical and subclinical) in domestic food animals result in animals that eat less, grow more slowly, and are less efficient at converting feed to body tissue (Johnson, 1998) . In our data set, significant classification \u00d7 time interactions occurred for starter, MR, and total DMI over the 21 d after arrival (Figure 2 ). Cumulative MR intake was decreased for DIA calves compared with HEA calves (15.9 vs. 16.6 \u00b1 0.6 kg; P = 0.06; Table 4 ). This finding was likely because DIA calves were more likely to refuse MR than HEA calves (OR 2.77; P < 0.001; Table 2 ). Inflammatory cytokines mediate the reduction in feed intake in sick animals, which may be a protective mechanism in the short term (Johnson, 1998; Dantzer, 2006) . Several groups have recommended that calves should continue to be offered and consume at least part of their normal milk or MR throughout enteric challenges, because it aids in recovery (Garthwaite et al., 1994; Quigley et al., 2006; McGuirk, 2011) . Nevertheless, intake of MR solids was significantly reduced in DIA calves relative to HEA calves. As well, cumulative starter DMI was decreased for DIA versus HEA calves (0.9 vs. 1.5 \u00b1 0.5 kg; P < 0.01; Table 4 ). As a result, cumulative total DMI was also decreased for DIA calves versus HEA calves (16.8 vs. 17.9 \u00b1 1.1 kg; P < 0.01). Promotion of early consumption of starter intake is critical for rumen development and function in the preruminant calf (Drackley, 2008) . Depressed growth rates and risk of disease have been associated with reduced dry feed intake preweaning, so enhancing milk intake early in Figure 1 . Day of experiment when dairy calves were first classified as diarrheic (fecal score >2 for \u22653 consecutive days) in the first 21 d after arrival for 4 experiments included in the data set. Table 4 . Initial concentration of total protein in serum (g/dL), average ambient environmental temperature, and total cumulative intake of free water, electrolyte, milk replacer water, and total water (L/d) by dairy calves classified as healthy or diarrheic 1 in the first 21 d after arrival at the research facility life is critical for continued growth (Khan et al., 2011; Steele et al., 2016) . Diarrhea results in major water and electrolyte losses from the body through the feces (Davis and Drackley, 1998) . The reduced solids intake from MR also resulted in reduced cumulative water consumption from MR for DIA calves compared with HEA calves (104.0 vs. 108.1 \u00b1 3.4 L; P = 0.03; Table 4 ) in the first 21 d after arrival, as well as reductions within a week compared with HEA calves (Table 5) . A significant classification \u00d7 time interaction for water from MR (Figure 3 ) indicated reductions in water intake from MR for DIA calves. We found no differences within week for FW intake or cumulative FW intake (Table 5) . A significant classification \u00d7 time interaction occurred because of numeric increases in FW intake for calves classified as DIA and because of tendencies for intake to be greater on d 3, 6, and 7 ( Figure 3 ). Calves classified as DIA were more likely to receive EC (OR 394.4; P < 0.01; Table 2 ) and were given EC for more days than HEA (2.05 vs. 0.22 \u00b1 1.34 d; P < 0.01; Table 3 ). The significant classification \u00d7 time interaction supported the general trend of greater consumption of EC for DIA calves over the course of the 21 d after arrival (Figure 3) . Overall, the total cumulative intake of EC was greater for DIA calves than for HEA calves (4.2 vs. 0.5 \u00b1 0.4 L; P < 0.01; Table 4 ) and within each week, DIA calves consumed more EC than HEA calves (P < 0.05; Table 5 ). Electrolytes should not replace normal water consumed through milk, MR, or ad libitum FW, but are required as an additional source of fluids to correct dehydration (McGuirk, 2011) . Ultimately, we found no differences within week for total water intake (P > 0.05; Table 5 ). Similarly, cumulative total water intake did not differ between classifications. Taken together, this finding supports common recommendations that with the reductions in water intake from milk or MR and increased excretion of water in the feces (indicated by elevated fecal score), supplemental EC is crucial for maintaining overall water intake and electrolyte balance during enteric challenges in calves (Smith, 2009) .\n\nWater is the most important nutrient, consumed in the largest amount relative to all other nutrients (Murphy, 1992; Drackley, 2008) . Calves should have access to free water from soon after birth, in addition to the water consumed in milk or MR (Drackley, 2008) . It is important to note that calves were not restricted in the free water available to them in these experiments. As a result, total water intake was not different between classifications. If free water had been limited, the DIA calves might not have been able to maintain total water consumption, and this could have resulted in a more severe imbalance in water and electrolytes. Although we did not measure hydration status in these experiments Figure 2 . Intake of (a) starter, (b) milk replacer, and (c) total DM (g/d) by dairy calves classified as healthy (solid line) or diarrheic (dashed line; fecal score >2 for \u22653 consecutive days) in the first 21 d after arrival at the research facility. Error bars represent SE of the LSM. *Intake differed (P \u2264 0.05, Tukey-adjusted); \u2020intake differed (0.05 < P \u2264 0.10, Tukey-adjusted). except for a visual assessment by the research personnel, it may be interesting to evaluate hydration status in future experiments as an indicator of how changes in water intake may influence overall hydration and how calves may self-regulate their water balance when challenged with enteric disease.\n\nIn a survey of operations in the United States, the average age water was first offered was 6.6 \u00b1 1.3 d (range 4.1 to 10.6 d) for operations classified as large or small, respectively (USDA, 2012) . However, it is important to provide water earlier to dairy calves because they increase the amount of free water they drink after both colostrum intake and transportation (Thickett et al., 1981; Kertz et al., 1984) . Soon after arrival, all calves averaged approximately 1.5 L/d of free water intake within the first week of age. Reported data on water intake in young calves are scarce. In general, the reported values averaged less than 2 L/d for the first 3 wk and then increased with starter intake and weaning (Thickett et al., 1981; Kertz et al., 1984) . A more recent experiment determined that free water intake was similar between 2 MR feeding levels and increased as starter intake increased (Quigley et al., 2006) . On the opposite spectrum, recent work has reported water intake in calves given ad libitum access to milk (Hepola et al., 2008; de Passill\u00e9 et al., 2011) . The NRC (2001) suggests that water intake ranges from 1 L/d in the first week to 2.5 L/d by wk 4. In our data set water intake ranged from 1.5 to 3 L/d in calves under 3 wk of age.\n\nEnteric disease is associated with decreased BW gain. Actions of viruses, bacteria, and protozoa vary by species type and location in the intestine. Damaged intestinal epithelium can cause prolonged malnutrition and decrease growth rates in affected calves due to malabsorption and fermentation of undigested milk in the intestinal lumen (Cho and Yoon, 2014) . Body weight and frame growth measures are shown in Table 6 . Initial BW did not differ between classifications (P = 0.49). A classification \u00d7 time interaction for BW during the 21 d after arrival at the research facility indicated that HEA calves became heavier than DIA calves (50.8 vs. 48.7 \u00b1 0.5 kg; P < 0.01). Consequently, we found a tendency (P = 0.07) for HEA calves to have greater ADG than DIA calves (669 vs. 491 \u00b1 120 g/d). Furthermore, significant classification \u00d7 time interactions for hip height and heart girth (P < 0.01) revealed the same type of response. Body weight and frame growth measures are shown by week in Table 7 . Classifications differed for all variables except ADG of withers height. Health status, including diarrhea, has been shown to have a significant negative effect on growth during the first 6 mo of life (Donovan et al., 1998b) . Classification effects were significant on gain-feed ratio for both MR intake and total DMI: DIA calves were less efficient than HEA calves ( Table 6 ). The overall trend indicated that HEA . Intake of (a) free water, (b) electrolyte water, (c) milk replacer water, and (d) total water (L/d) by dairy calves classified as healthy (solid line) or diarrheic (dashed line; fecal score >2 for \u22653 consecutive days) in the first 21 d after arrival at the research facility. Error bars represent SE of the LSM. *Intake differed (P \u2264 0.05, Tukey-adjusted); \u2020intake differed (0.05 < P \u2264 0.10, Tukey-adjusted). calves were heavier and larger than DIA calves within 21 d of arrival. Increased preweaning ADG has been positively linked to first-lactation milk yield (Soberon et al., 2012) . As well, the health of calves has been associated with longevity; calves treated with antibiotics (indicating illness) had decreased lifetime milk production (Soberon et al., 2012) . Moreover, the number of days that calves are sick in the first 4 mo of life has been shown to have negative effects on first-lactation 305-d mature-equivalent milk yield and actual production of milk, protein, and fat (Heinrichs and Heinrichs, 2011) .\n\nOur data emphasize the continued prevalence and impact of enteric disease on preweaning dairy calves. Young calves with diarrhea have reductions in feed intake, BW gain, and feed efficiency. Serum total protein was not a good predictor for the development of diarrhea in calves after arrival. Our data highlight the differences in water intake from various sources provided to preruminant calves. It is critical to provide diarrheic calves with supplemental EC in addition to normal milk or MR and ad libitum free water to help 11007 maintain fluid balance and overall total water intake. Understanding the deficit in water intake that diarrheic calves experience relative to their healthy counterparts is important in determining ways to minimize the severity and economic impact of enteric disease on calves in modern farms.\n\nFunding for this retrospective analysis was provided by the Illinois Agricultural Experiment Station (Urbana)."}