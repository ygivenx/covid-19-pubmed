{"title": "", "body": "No doubt, the history of mankind has been shaped by the pitiless outbreaks of infectious disease pandemics. Whole nations and civilizations have been wiped off the map through the ages. The list is long: biblical pharaonic plagues that hit Ancient Egypt in the middle of Bronze Age around 1715 BC, 1 the \"\u03bbo\u03b9\u03bc\u00f3\u03c2\" in Athens from 430 to 425 BC set the end of the Periclean golden era, the \"cocoliztli\" epidemics, which occurred during the 16th century, resulted in some 13 million deaths, decimating the Mesoamerican native population, 2 the Black Death bubonic plague burst in Europe in 1348, and is estimated to have killed over 25 million people in just five years. The pandemic influenza virus of 1918-1919 swept through America, Europe, Asia, and Africa smashing the globe: the death toll was around 40 million people. Two one-year, less severe influenza pandemics followed in the next decades: the 1957 and the 1963 influenza pandemics resulted to two and one million deaths respectively (World Health Organization: http://apps.who.int/iris/handle/10665/68985). In the last decades emerging and re-emerging epidemics such as Over the last years, an intensive worldwide effort is speeding up the developments in the establishment of a global surveillance network for combating pandemics of emergent and re-emergent infectious diseases. Scientists from different fields extending from medicine and molecular biology to computer science and applied mathematics have teamed up for rapid assessment of potentially urgent situations. Toward this aim mathematical modeling plays an important role in efforts that focus on predicting, assessing, and controlling potential outbreaks. To better understand and model the contagious dynamics the impact of numerous variables ranging from the micro host-pathogen level to host-to-host interactions, as well as prevailing ecological, social, economic, and demographic factors across the globe have to be analyzed and thoroughly studied. Here, we present and discuss the main approaches that are used for the surveillance and modeling of infectious disease dynamics. We present the basic concepts underpinning their implementation and practice and for each category we give an annotated list of representative works.\n\nConstantinos I. Siettos 1, * and Lucia Russo 2 1 School of Applied Mathematics and Physical Sciences; National Technical University of Athens; Athens, Greece; 2 Consiglio Nazionale di Ricerce; Napoli, Italy Keywords: mathematical epidemiology, statistical models, dynamical models, agent-based models, machine learning models AIDS, measles, malaria, and tuberculosis cause death to millions of people each year. According to the UNAIDS report on the global AIDS epidemic, an estimated 34 million people, including 3.4 million children, were living with HIV worldwide at the end of 2010, while the related deaths and new infections were 1.8 and 2.7 million, respectively. 3 The rapid technological and theoretical progress has dramatically enhanced our arsenal in fighting epidemics and we are getting better on it. The global surveillance network is growing under an intensive worldwide effort. We are now able to produce effective vaccines and antiviral drugs and knowledge goes deep in details such as the molecular structure of a variety of viruses. A large and intensive research is evolving for the design of better drugs and vaccines. Yet, studies warn us that a new pandemicinfluenza-type is the most worrisome one-is sooner or later on the way. 4 The critical question(s) is not whether but when it will arise, how it is going to spread, how deadly it will be, who should get the vaccine when not all can, how likely are multiple waves of re-emergence and what type of intervention may be applied to stop the spread. Unfortunately, even with all the advances, we still don't have robust answers.\n\nThe problem stems mainly from two reasons: (1) the continuous and ever-lasting mutations of the viruses, and (2) the complexity in the disease transmission mechanism. Unfortunately, the odds are that in a real crisis, even if researchers succeed to come up with a vaccine tailor-made for an emerged virus strain, it is doubtful that it would stop a pandemic. 5 The complex multi-scale interplay between a host of factors ranging from the micro host-pathogen and individual-scale hosthost interactions to macro-scale ecological, social, economic, and demographic conditions across the globe complicated by technical issues such as the time lag between vaccine prototype development and commercial production and distribution imposes a real impediment to our control strategy potential.\n\nMathematical, statistical models and computational engineering are playing a most valuable role in shedding light on the problem and for helping make decisions.\n\nThe very first publication addressing the mathematical modeling of epidemics dates back in 1766. In this seminal paper, Essai d'une nouvelle analyze de la mortalit\u00e9 caus\u00e9e par la petite v\u00e9role, 6\n\nMathematical modeling and simulation allows for rapid assessment. Simulation is also used when the cost of collecting data is prohibitively expensive, or there are a large number of experimental conditions to test. Over the years, a vast number of approaches have been proposed looking at the problem from different perspectives. These encompass three general categories (see Fig. 1 ):\n\n(1) statistical methods for surveillance of outbreaks and identification of spatial patterns in real epidemics, (2) mathematical models within the context of dynamical systems (also called state-space models) used to forecast the evolution of a \"hypothetical\" or on-going epidemic spread, and (3) machine learning/ expert methods for the forecasting of the evolution of an ongoing epidemic. For all three of these categories there are again different approaches weaving a big and diverse literature. Here, we try to draw the map of these approaches and try to describe their basic underpinning concepts.\n\nOne of the most important aspects in epidemics revolves around the surveillance, early detection of possible outbreaks and patterns that may help controlling a spread. One of the very first success stories in the area is the modeling of cholera epidemic that swept through London in 1854. At that time John Snow, a physician, collected spatiotemporal data and by visualizing them in a map found that there was a particular pattern around the Broad Street water pump, 21 which actually was the zero point of transmission. His analysis helped eradicate the disease. In the dawn of 20th century Greenwood an epidemiologist and statistician was the first Professor of Epidemiology and Statistics at the London School of Hygiene and Tropical Diseases establishing a rigorous mathematical connection between fields. 22 Today, global initiatives to combat epidemics require effective domestic action mechanisms and preparedness through the globe. An intensive worldwide effort led by World Health Organization and Centers for Disease Control is speeding up the developments for the establishment of a global surveillance network. New emerged pandemics such as the AIDS, the severe acute respiratory syndrome (SARS) of 2002-2003 and the H1N1 swine flu of 2009 pandemics reminds us about the importance of surveillance and prompt outbreak detection. Toward this aim, statistical methods have enhanced our potential in fighting epidemics allowing for rapid assessment of emerging situations. Obviously, the correctness of the data and the selection of the appropriate methodology are crucial for the construction of statistical models that can capture in an efficient robust way the communicable disease characteristics.\n\nTo date, several statistical methods have been proposed (see also Unkel et al. [2012] 23 for a review of statistical methods for the detection of disease outbreaks). In the website of Centers for Disease Control and Prevention (CDC) (http://www.cdc.gov/) one can find a list of references in the field. Here we present Daniel Bernoulli developed a mathematical model to analyze the mortality due to smallpox in England, which at that time was one in 14 of the total mortality. Bernoulli used his model to show that inoculation against the virus would increase the life expectancy at birth by about three years. A translation in English and review of this work can be found in Sally Blower (2004), 7 while a revision of the main findings and a presentation of the criticism by D'Alembert appears in Dietz and Heesterbeek (2002) . 8 Lambert, in 1772, followed up the work of Bernoulli extending the model by incorporating age-dependent parameters. 9 Laplace has also worked on the same concept. 10 However this line of research has not been developed systematically until the benchmark paper of Ross in 1911, which actually establishes modern mathematical epidemiology. 11 In this work, Ross addressed the mechanistic a priori modeling approach using a set of equations to approximate the discrete-time dynamics of malaria through the mosquitoborne pathogen transmission (for a discussion and a review of this model see also Smith et al. [2012] 12 ).\n\nFollowing up the work of Ross, Kermack and McKendrick published three seminal papers which founded the deterministic compartmental epidemic modeling. [13] [14] [15] In these papers, they addressed the mass-action incident in disease transmission cycle, suggesting that the probability of infection of a susceptible (virgin from illness) is analogous to the number of its contacts with infected individuals. Hence, the rate at which susceptibles become infected is given by kSI where S and I represent population densities of susceptible and infected people, respectively. In this context, the rate at which infected individuals become recovered is given by \u03bbI, while the rate at which recovered individuals become again susceptible is given by \u03bcR; k, \u03bb and \u03bc are analogy constants. This mechanistic-deterministic representation holds strong analogy to the Law of Mass Action 16 introduced by Guldberg and Waage in 1864 and is called the SIR model, implying homogeneous mixing of the contacts and conservation of the total mass (population) as well as relatively low rates of interaction. Forty years after the paper of Ross, MacDonald extended Ross's model to explain in depth the transmission process of malaria and propose methods for eradicating the disease on an operational level. Due to the importance of MacDonald's contribution to the field by exploiting the use of computers, mathematical models for the dynamics and the control of mosquito-transmitted pathogens are known as Ross-MacDonald models. 12 At this point it would be remiss of us not to mention the work of Enko, [17] [18] [19] assessment have been also proposed. 27 Today, the above approach is used by the Centers for Disease Control in the US, Australia, France, and Italy for the detection of influenza outbreaks.\n\nWhile this approach is very popular among epidemiologists for predicting and surveillance purposes, one has to be cautious about their use as the form of the equations relies usually on ad hoc assumptions on the dependence between the dynamics of a disease and the independent factors (variables) that determine its spread. In addition, the choice of the model (linear/nonlinear), assumptions on the statistical properties (for example independence, normal distribution and fixed variance) of the unmodeled dynamics (represented by e(t)) flash a \"note of caution\" in their use especially for the surveillance and prediction of outbreaks of new emerging epidemics.\n\nTimes series analysis based on autoregressive models such as the autoregressive integrated moving average model (ARIMA) and seasonal ARIMA (SARIMA) 30-33 as well as neural networks. 34 These models relax the hypothesis of autocorrelation of regression models as well as the hypothesis of simple autoregressive models such as AR (autoregressive) and ARMA (autoregressive moving) in which past disturbances are not modeled. In this category, ARIMA models are the most commonly used. Their general form reads:\n\nwhere y(t) denotes a stationary stochastic process at time t with mean value E(y(t)) = \u03bc; z -1 is the backward shift operator defined by z -k y(t) = y(t -k) and \u0394 d is the differencing operator of order d defined by \u0394 d \u2261 (1 -z -1 ) d ; A(z -1 ) is the autoregressive operator defined as ; B(z -1 ) is the moving-average operator defined by ;\n\nand discuss the most common schemes that can be classified as follows: Regression methods. 24-29 Regression models try to detect an outbreak from time-series of epidemic-free periods by monitoring a statistic of reported infected cases, say y(t). An epidemic alert is raised when a certain threshold, say k, is surpassed, defined by , (\u03bc being the mean value of the time-series distribution) within a confidence interval (usually of 95%).\n\nA basic regression model is that proposed from Serfling which was initially constructed to monitor the deaths of influenza based on the seasonal pattern of pneumonia and influenza deaths. 24 Due to the seasonal behavior of the disease the following cyclic regression model has been addressed:\n\n\u03b8 is a linear function of time t while the coefficients are to be determined by a parameter identification technique. The cosine and sine terms are used to approximate cyclical seasonal patterns; e(t) is the noise (assumed that is Gaussian distributed with mean zero and variance \u03c3 2 ) which is estimated from the time-series. In the original paper of Serfling, y(t) was the expected mean value of total deaths due to pneumonia and influenza in units of 4-weeks periods. The model was fitted using data from 108 US cities for a 3 year period starting in September of 1955.\n\nUsing least squares estimation Serfling ended up to the following model:\n\nOther models including square terms, t 2 , to account long-term changes due to factors such as the population growth or disease where \u03bc 0 and \u03bc 1 are the mean values of the in-control and outof-control Poisson distributions.\n\nFor an epidemic that involves time-varying characteristics, such as seasonality, the reference parameter is now time-varying itself, i.e., k \u2261 k(t) .\n\nThe EWMA control chart method monitors infectious disease dynamics using the following recursive statistical estimator, which in its simple form reads:\n\nforgetting\" factor, a number between 0 and 1 which weights the significance of past values. Actually this factor reduces the importance of past observed information in estimating future. Again, an alarm is raised at time\n\nOther statistical process control methods such as temporal scan statistics have been also used. 46, 50, 51 Hidden Markov models (HMM) used to explain statistical correlation in time series. 52, 53 The question that the HMMs come to answer in epidemiology is the following: how can we infer about the dynamics of a particular infectious disease and forecast its outbreak when we cannot monitor/record explicitly the characteristics of the disease but we can observe some possible indicators of the disease? For example, can we forecast the evolution of an influenza epidemic by monitoring for example the number of reported cases as recorded through a surveillance network of physicians or in hospital units? 52, 54 HMM models are exploited exactly under these limitations/ constraints. Within this context, let us denote by Y(t) the stochastic process of the unobserved (hidden) state, e.g., the number of cases of the disease in the population at time t and with O(t) the stochastic process of the observable states.\n\nFormally, HMMs are Markov processes, i.e., stochastic processes which satisfy the so called Markov property (here for the sake of presentation we assume discrete in time Markov processes) defined by: along with the time-invariant transition probability between two realizations, say y i (.), y j (.):\n\nThe above relations simply state that all the necessary information for predicting the distribution of Y(t) at time Y(t) with a certain probability defined by P(.) is contained within Y(t -1); y(.) denotes a realization of the stochastic process Y(.).\n\nIn HMMs, the following conditional independence assumption holds: e(t) is the residual (noise) at time t representing the part of the measurement that cannot be predicted from previous measurements. For d = 0 and n a = 0 one gets the moving average model, while for d = 1, n a = n b = 0 one gets the random walk with drift. Seasonal differencing enters naturally in the above framework by considering the seasonal differencing operator where k is the length of seasonal cycle and S is the degree of seasonal differencing producing series of changes from one season to the next.\n\nThe time-series is then split in two sets: one containing the times-series serving as a training set, and another one containing the remaining data serving as a test (validation) set. The Akaike Information Criterion 35 is usually applied to identify the optimal model order by compromising between the goodness-of-fit and number of parameters. The fitted model is then used for the forecasting of disease evolution. The reliability of such approaches is limited mostly by (1) the statistical uncertainty related to the estimation of the values of the unknown parameters and (2) the hypotheses related to the statistical properties of the corresponding time series.\n\nStatistical process control methods including cumulative sum (CUSUM) charts 36-41 and exponentially weighted moving average (EWMA) 42,43 -based methods. CUSUM is probably the most common used technique for the detection of disease outbreaks. This is achieved by monitoring a cumulative performance measure over time. Let us consider the number of infected cases y(t i ) as observed at different time instances t i , i = 1, 2, \u2026, n . In its simple representation, for a single parameter process, CUSUM is defined as or in a recursive form as CUSUM (0) = 0 , i \u2265 0 where k is a reference value corresponding to the difference between to the in-control and the out-of-control mean. The process is considered to be in-control if CUSUM(i) < h with h denoting a threshold (its value is usually taken to be three times the standard deviation from the baseline/mean value of in-controlobservations). An alarm is raised at time t i if CUSUM(i) exceeds h; the process is considered to be out-of-control. The reference value k is determined by likelihood ratio based methods. [44] [45] [46] [47] [48] [49] Hence, denoting by f(\u03b8 0 ) and f(\u03b8 1 ) the probability function of the in-control and out-of-control processes with parameters \u03b8 0 and \u03b8 1 respectively, the reference value reads:\n\nThe probability functions f(\u03b8 0 ) and f(\u03b8 1 ) and their parameters can be estimated using data from past periods. For Poisson distributions the above relation reads: demographic variables (such as age, gender, social status, spatial characteristics) on the survival rates, i.e., occurrence rates of events such as death or infection in the population. 85, 86 \n\nAccording to the level of the approximation of the reality and increasing complexity mathematical models may be categorized in the following categories:\n\n\"Continuum\" models in the form of differential and/or (integro)-partial differential equations. Continuum models describe the coarse-grained dynamics of the epidemics in the population. 87-90 One might, for example, study a model for the evolution of the disease as a function of the age and the time since vaccination 91, 92 or investigate the influence of quarantine or isolation of the infected part of the population. 93, 94 Such models can be explored using powerful analysis techniques for ordinary or partial differential equations. However, due to the complexity and the stochasticity of the phenomena, most available continuum models are often only qualitative caricatures that cannot capture all of the details, therefore compromising epidemiological realism.\n\nWithin this context, the population is divided in compartments in accordance to the state of their health, such as susceptible (S), infected (I), and recovered (R). Other states of the population linked with control policies such as vaccinated (V ) and quarantined (Q) are also used.\n\nThe compartmental SIR mass-action model of Kermack and McKendrick (1922) is the basis of such models. In this representation, it is assumed that an infected individual infects a susceptible with a probability p S\u2192I and that an infected individual recovers with a probability p I\u2192R . The systems dynamics under the mass-balance formulation can be approximated by the following three ordinary differential equations: 95, 96 where , j=1, 2,\u2026, m There are three basic questions that have to be answered here: (1) what is the likelihood of the observed sequence, (2) what is the most likely hidden sequence given a ij ,b ij and the observation sequence, and (3) given the observation sequence, which are the HMM parameters, i.e., a ij ,b ij and initial distribution of observed states that maximize the likelihood of the observation sequence and/or hidden sequence. The first problem is usually tackled with the use of the forward-backward algorithm, 55 the second problem with the use of the Viterbi algorithm, 56 and the third problem with the use of the so-called Expectation-Maximization (EM) algorithm. 57 Spatial models for monitoring, identifying and forecasting disease outbreaks in different locations. [58] [59] [60] [61] [62] [63] [64] Most of the infectious diseases result to strong spatio-temporal patterns whose systematic analysis is of outmost importance for better understanding, predicting and combating outbreaks. Spatial surveillance requires the use of multivariate techniques. 65 Most of the multivariate methods can be viewed as extensions of standard univariate methods-as the ones described above-; however, there are others such as clustering, principal component analysis (PCA) based methods that do not have a common ancestor with univariate ones. 66 Kleinshmidt et al. (2000) used a two tier approach for the surveillance of malaria. 67 They used regression analysis on the larger scale and kriging 68 to interpolate the count data at an unobserved location in order to forecast the prevalence of the disease in the local scale. Cohen et al. (2010) exploited PCA to create a single surveillance index that can be used to summarize temporal and spatial trends of malaria in India. 69 Coleman et al. (2009) used the SatScan freeware software (http://www. satscan.org/) to identify malaria outbreaks to a province of South Africa by detecting time and space clusters. 70 The SatScan software is based on the spatial scan statistic 71, 72 and the Bernoulli spatial model. 73 SatScan has been also exploited by Gaudart et al. (2006) to identify spatio-temporal clusters of high risk incidence of malaria in a Mali village. 74 A temporal analysis using ARIMA technique was also undertaken.\n\nTo this end, we should also mention the use of copulas 75,76 (joint distribution functions used to model the dependencies between random variables based on given/known marginal distributions of the individual variables) for parametric multivariate analysis. Copulas can be integrated naturally within the HMM framework and hazard analysis approaches such as the Cox 77, 78 and Plackett-Dale 79 survival models to better understand and ultimately design more efficient intervention policies such as vaccination on targeted parts of the population and project future trends for risk assessment especially for fatal diseases such as AIDS. [80] [81] [82] [83] [84] Such models are used to quantify the relation of host-host interactions (see, e.g., Webb et al., 2005 104 ). In , the Ross and McKendrik model has been extended to incorporate demographics and genetic changes in the populations to simulate the spread of malaria in Mali and the plague in the Middle Ages. 105 The authors have employed the Archimedean copula approach to relate the risk of infection and biological age. In another study the authors have augmented the model by age classes and with a diffusion term to account for spatial effects in order to approximate the epidemic front wave dynamics of the Black Death between 1348 and 1350. 106 In Demongeot et al. (2012) the Ross and McKendrik SIR model has been revised to incorporate demographic and spatial dynamics introducing continuous age classes and diffusion of both human and vectors species subpopulations within the infected zones. 107 The model has been used to simulated the spread of malaria in Bancoumana, Mali.\n\nStochastic models including discrete and continuous-time individual based Markov-chain models. 108-110 These are usually individual-level models that relax the hypothesis of the mean field approximations of infinite population and perfect mixing introducing the uniqueness of the individual behavior including multiple heterogeneous characteristics. The main representative in the category is the discrete Markov chains (DMC). In DMC both time and states are defined on a discrete set of values. The states of the individuals change at every discrete time step in a probabilistic manner according to simple rules involving their own states and the states of their links satisfying the Markov property, i.e., that that the future values of the states at time t + \u0394t depend only on the values of the states at the previous time step t, i.e.\n\nFor example, for a stochastic SIRS-like model these transition rules may read:\n\n\u2022 Rule #1: An infected individual (I) infects a susceptible (S) link with a probability p S\u2192I = \u03bb if an active physical communication exists between them.\n\n\u2022 Rule #2: An infected individual (I) recovers with a probability p I\u2192R = \u03b4.\n\n\u2022 Rule #3: A recovered individual (R) becomes susceptible (S) with a probability p R\u2192S = \u03b3. This condition expresses the case of temporal immunity.\n\nWhen these transition probabilities remain constant in time, the Markov process is then called time homogenous Markov process. The links between individuals form the contact network through which the disease spreads. For simple DMC models this network is assumed to be a fully connected graph resulting to homogeneous mixing of individuals. For this case and in the limit of infinite number of individuals, the stochastic model can be regarded as a mean field deterministic model.\n\nFor a uniform distribution with z links per individual and in the limit of an infinite size population the governing equations read:\n\nHowever the above deterministic mean field approximations may impose important bias when the assumptions about infinite becomes again susceptible after a period of time 1/\u03b3 then the SIRS mean field model becomes:\n\nIn the Kermack reproduction number (R 0 ) and indicates whether the disease will become epidemic (if R 0 > 1) or it will die out (if R 0 < 1). Generally speaking, R 0 represents the average number of secondary infections produced from a single infected individual introduced into a completely susceptible population. A transmission potential index that relaxes the hypothesis of the fully susceptible population is the effective reproduction number defined as the average number of secondary infections produced from a single infected individual in a population which is already infected from a disease. The parameters of these models can be estimated using epidemic data from past periods. Within this context Coburn et al. (2009) give a review on simulating influenza including swine flu (H1N1) with SIR models. 97 Nichol et al. (2010) used a SIR model to simulate influenza dynamics in a college campus and through this to assess the impact of various scenarios of vaccinations. 98 Correia et al. (2011) used a SIR model to study the measles and hepatitis C in Portugal using data from 1996 until 2007. 99 SIR-type models have also been extended to incorporate demographics such as age distributions, mortality and spatial dependence of the spread to account for diffusion and migration effects as well as genetic mutations in the interacting populations, thus enhancing their realism. 102 Ajelli et al. (2011) developed an SIRbased metapopulation model that incorporates a spatial contact matrix describing the mixing level between Italian regions. 103 The authors used the model to predict the spatiotemporal dynamics of hepatitis A in the south regions of Italy. The model was fitted using weekly time series of reported rubella cases from 1997 to 2009. The same type of models have been also used to model nosocomial epidemics modeled both at the level of pathogen and outbreaks. Vaccination, quarantine, and/or use of antiviral drugs on targeted parts of the population have to be carefully designed for the efficient combat of an emerged epidemic. Poor understanding of the infectious disease dynamics as these emerge due to heterogeneous contact interactions may result to serious negative consequences. Over the last years, there has been an intense effort in studying the interplay between the emergent dynamics of infectious diseases and the underlying topology of transmission network.\n\nWithin this context, Kuperman and Abramson (2001) showed how changes in the rewiring probability used to construct smallworld networks influence the dynamics of a simple epidemic model. 124 It was shown that there exists a critical value of the rewiring probability that marks the onset of a phase transition from stationary endemic situations to self-sustained oscillations. Hwang et al. (2005) studied the influence of the clustering coefficient and average path length on epidemic outbreaks evolving on scale free networks. 125 Shirley and Rushton studied the impact of four different types of network topologies, namely Erd\u0151s-R\u00e9nyi, regular lattices, small-world, and scale free on epidemic dynamics. 126 studied the influence of the path length of small world networks on the dynamics of a simple SIRS stochastic epidemic model. 127 Studies on adaptive networks have only very recently begun to appear in the physics literature 128 indicating that adaptation can trigger effects that are not present in other types of networks.\n\nRegarding real-world cases, Read et al. (2008) studied the impact of social networking to the spread of a communicable disease by constructing the underlying contact network from a diary-based survey from 49 adults who recorded 8661 encounters with 3528 different individuals over 14 non-consecutive days. 123 Christakis and Fowler (2010) studied a flu outbreak at Harvard University in 2009. 129 Following 744 students they mapped the transmission network following their friends and contacts and detected the critical nodes and links that were responsible for rapid spread and could be used as early warning detectors. In particular, by measuring several statistics of the underlying network topology, they quantified the centrality of individuals in the network, i.e., how much likely is for the disease to pass and transmitted from an individual to other individuals through the network. Salath\u00e8 et al. (2010) used wireless sensors to obtain close proximity interactions during a typical day at an American high school. 130 Based on these measures, they constructed the transmission network and studied the potential of the disease to spread in terms of topological characteristics such as transitivity and average-path-length with respect to the duration of contact between students. Keeling et al. (2010) constructed two metapopulation networks based on information available from 2001 on the commuter movements between 10 000 wards in Great Britain. 121 From the cattle trading system they also constructed the movement network between 150 000 farms. They consider four infectious diseases, namely influenza and smallpox in humans and foot-and-mouth disease or tuberculosis in cattle. Comparing simulations with actual data the authors raised the question if simple network models can eventually catch the influence of movements in an epidemic. Furthermore size population, homogeneous individuals, homogenous or random regular networks do not hold. Therefore, they may miss important quantitative and/or qualitative information at the coarse-grained/emergent (continuum) level. This situation worsens as the heterogeneity becomes stronger (e.g., interactions on more complex networks with finite size populations).\n\nWithin this context, a comparison between stochastic and the analogous deterministic models is given in . 111 Lekone et al. (2006) used a stochastic SEIR model (E stands for exposed to the disease individuals) to simulate the dynamics of Ebola outbreak in the Democratic Republic of Congo in 1995. 112 Bishai et al. (2011) used a stochastic SIR model with age structure and two additional states (compartments) to describe heterogeneity in vaccination. 113 The authors combined the epidemic model with an economic model incorporating the costs of the control disease policies to study the cost effectiveness of supplemental immunization activities for measles in Uganda. Wang et al. (2012) developed a stochastic model within the SIR concept to simulate and better understand the multi-periodic patterns in outbreaks of avian flu in North America. 114 The model assumes random contact between individuals as well as environmental transmission of the virus.\n\nNon-markovian SIR-like models have been also proposed. These models incorporate \"memory\" in transmission dynamics. For example, Streftaris and Gibson (2004) propose a non-markovian SIR model for the foot-and-mouth disease outbreaks. 115 In their model they assume that individuals remain infected for a time drawn randomly from a two-parameter Weibull distribution. Randomization of classical deterministic SIR-like models, coming from the random, chemical kinetics to account for non-constant population with age classes due to birth and death processes and spatial demographics have been also been proposed. 116 Within this context, compare the dynamics of deterministic and their counterparts stochastic epidemics models for populations with constant and variable. 117 Complex network models 118-120 that are relaxing the hypothesis of the above stochastic models that the interactions between individuals are instantaneous and homogeneous. [121] [122] [123] One of the most critical problems in epidemics concerns the dynamic effects of the contact network heterogeneity. Contacts between individuals evolve under numerous complicated and strongly heterogeneous modes that are influenced by a broad spectrum of factors, ranging from the pathogen inherent variability and host-pathogen interaction stochasticity characterizing the transmission mechanisms of a particular disease, to the populationlevel ones complicated by environmental, seasonal, economic, and demographic conditions. Furthermore, in many situations the spread of an epidemic is shaped by the topology of the contact social network, and, vice versa, the dynamic evolution of the transmission network depends on the emergent dynamics of the epidemic. For example, in a severe epidemic outbreak, a change in the state of endemicity of a particular part of the population can cause a significant change in the characteristics of the transmission network (due to, e.g., link-cutting due hospitalization). Understanding this complex behavior is of outmost importance to public-health measures and policies for controlling diseases from population mobility based on TRANSIMS and epidemic models of host-pathogen and host-host interactions. 132 EpiSims, developed at Los Alamos National Laboratory creates a synthetic population based on the Transportation Analysis and Simulation System (TRANSIMS, http://code.google.com/p/transims/). The authors simulated the spread of an infectious disease in the area of Portland, Oregon, US whose network involves 1.5 million people (nodes), 180 000 locations and a total of 1.6 million vertices. Ferguson et al. (2005) developed and presented the simulations results concerning the H5N1 influenza A pandemic in Southeast Asia. 133 Their simulations involved 85 million agents residing in Thailand and a 100 km-wide zone of neighboring countries. Demographic data involving details about households, location of schools and workplaces, and population mobility where taken into account. Using the detailed agent-based simulations they evaluated the containment strategies with respect to the potential of preventing a pandemic and the distribution of drugs necessary to eradicate the spread. Burke et al. (2006) presented an agent-based model for the spread of smallpox. The model considered hypothetical towns of 6000-and 50 000 inhabitants. 134 A distribution of households, workplaces, schools, and hospital units was constructed based on US demographic data. The authors investigated the efficiency of various contagion control scenarios such as vaccination of households, children at schools, isolation of infected persons and vaccination of medical staff in hospitals. Balcan et al. (2009) investigated how shortscale and long-scale contacts due to air travel can influence the spatiotemporal pattern of a pandemic. 135 The authors made use of the GLEaM agent-based computational platform (http://www. gleamviz.org/) consisting of three data layers: the demographic/ population, the mobility-related, and the epidemic modeling layer. In this study, real-world data from 29 countries around the globe as well as air travel flowing from 3362 airports indexed by IATA were integrated into a spatial metapopulation epidemic model.\n\nOver the last years, machine learning using data extracted from internet-based communication platforms and search engines have been used to extract early indicators of social trends. Microblogging socializing services and web searching platforms have revolutionized the way private and publicly available information diffuses. Such emerging technology appears promising to data mining agents' personal behavior. For example, such services with the aid of search queries have been exploited as tools to stock-market prediction and movie box-office revenue.\n\nWithin this context Ginsberg et al. (2009) exploited the aid of search queries on the Google platform for early detection of influenza epidemic in the US. 136 The authors used around 50 million Google web queries related to influenza symptoms between 2003 and 2008. A linear model using the log-odds of a visit of a physician in a certain region and the log-odds of a related search query submitted from the same region was fitted using publicly available data from the CDC's US Influenza Sentinel Provider Surveillance Network (http://www.cdc.gov/flu/). This approach they showed that the identity of individuals in contrast to random-mover assumption can significantly influence the emergent infection dynamics. Rocha et al. (2011) simulated the spread of sexual transmitted infections using SI and SIR models evolving over the transmission network constructed from data extracted from a Brazilian Internet community where sex buyers rate their encounters with escorts. 131 The network was extended over 12 cities. They showed that due to the high clustering and the distinct communities of the underling topology, the network slows down outbreaks.\n\nAgent-based simulations. In contemporary mathematical epidemiology, agent-based modeling represents the state-of-the-art for reasoning about and simulating complex epidemic systems. These take into account details such as the transportation infrastructure of the simulated area, the mobility of the population, demographics, and epidemiological aspects such as the evolution of the disease within a host and transmission between hosts (Fig. 2) . Public-health epidemiologists, researchers, and policy makers are turning to these detailed models for reasons of ethics, cost, timeliness, and appropriateness. In epidemic systems, testing experimental conditions would put the safety of people at risk, creating an ethical problem. In other cases, real-time evaluation of an existing system may be prohibitively long. For example, in a disaster, simulation can be used to rapidly evaluate many previously unexamined alternatives. In all of these cases, since the real-world system under study is a complex system, multiagent simulations are used as they are considered to incorporate the appropriate level of complexity. For example the Models of Infectious Disease Agent Study (MIDAS, https://www.epimodels.org/midas/pubglobamodel.do), a network launched on May 1, 2004 and funded by the US National Institutes of Health has as its pilot effort the detailed modeling of the dynamics of a hypothetical flu pandemic.\n\nWithin this context, Eubank et al. (2004) addressed the use of EpiSims, a detailed agent-based simulator which incorporates data models aspiring to approximate the dynamics of real-world cases. Within this context, along with the available information ranging from the host-pathogen interaction level to the host-host, city, country, and globe level, complex network theory has provided the necessary \"glue\" for the systematic link between epidemiology demographics and sociology.\n\nOn one hand, for the bridging of the scales of modeling, one has to first find the appropriate observable variables for which deterministic or stochastic models can be expressed. To this direction, data mining techniques that have flourished over the last few years can be employed to extract such information. On the other hand, due to the complexity of the underlying multiscale interactions, such models are built on incomplete knowledge imported, e.g., as parameter, rule evolution, and contact network inaccuracies. Thus far, simple brute-force temporal simulations are used to study the behavior of very large scale detailed agent-based simulators in the presence of such inaccuracies. For example some of the rules and model's parameters, such as the virus pathogenicity-as this may be expressed in terms of the reproduction number-and different social network topologies, are examined in order to assess how such factors may influence the spread of an outbreak. However, such simple simulations are inefficient for the systematic analysis of the emergent epidemic in the parameter space. New rigorous computational methodologies, such as the equation-free multiscale framework, 96,139-142 that can be used to address this issue have the potential to expedite novel computational modeling and analysis as well as to enhance our understanding and forecasting capability to combat epidemic outbreaks.\n\nNo potential conflicts of interest were disclosed. has now been realized as a surveillance web-based tool (http:// www.google.org/flutrends/). Hulth et al. (2009) processed web queries submitted in a Swedish website related to influenza between 2005 and 2007. 137 The authors fitted two models, one for relating web queries volume with the total number of laboratory verified influenza and the number of persons exhibiting influenza-like symptoms treated by physicians in Sweden. The models were used in turn to estimate outbreaks of the disease in time as well as to predict the influenza evolution. In Chan et al. (2011) a linear model was used to relate Google search queries related to dengue in Bolivia, Brazil, India, Indonesia, and Singapore using publicly available dengue cases between 2003 and 2010. 138\n\nIn this paper, we discussed and presented key modeling methods used for the surveillance and forecasting of infectious disease outbreaks. Generally speaking, epidemiological models can be categorized in three classes: statistical, mathematical-mechanistic state space, and machine-learning based ones. Public-health organizations throughout the world use such models to evaluate and develop intervention disease outbreak policies for ever-emerging epidemics. Simulation allows for rapid assessment and decision making, providing quantification and insight into the spatiotemporal dynamics of a spread. An intensive inter-and multidisciplinary research effort is speeding up the developments in the field integrating advances from epidemiology, molecular biology, computational engineering and science, and applied mathematics as well as sociology. Nowadays, molecular, sociological, demographic, and epidemiologic data are exploited to develop state-of-the-art detailed very large-scale bottom-up agent-based"}