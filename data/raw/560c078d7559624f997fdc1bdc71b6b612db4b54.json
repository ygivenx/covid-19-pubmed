{"title": "Physica A Detecting a trend change in cross-border epidemic transmission", "body": "An infectious disease outbreak is a complex stochastic phenomenon in a spatially heterogeneous medium [1, 2] . The analysis of the observations on an outbreak includes many tasks, which range from reproducing the growing number of cases at an infected city to detecting the omen and predicting the onset of an outbreak at neighboring uninfected cities. Among them, detecting a trend change in cross-border epidemic transmission is a task of particular interest to public health authorities.\n\nWhen the public health authorities issue an alert on the risk of massive community transmission commencing worldwide, public awareness may threaten potential travelers into refraining from travels. Then it becomes less probable that infectious travelers cross national or regional borders. Border health screening at airports and isolation of infectious travelers work similarly to these voluntary risk-averse behaviors. The community transmission decelerates if such a social distancing works effectively in controlling cross-border exposure. This is an example of a beneficial trend change in epidemic transmission. Detecting whether a trend changes or not helps the public health authorities confirm the efficacy of the current practices of public health intervention and design a more effective public health program.\n\nEarly detection helps the public health authorities eliminate the bottleneck of the public health intervention and contain the epidemic quickly. Some previous related works apply a model selection technique to detecting the change of transmission parameters. Other studies apply regression analysis to the early detection of the onset of an outbreak. The dataset studied by most of these works is a uni-variate time series for the number of cases in a single geographic region. These methods are not applicable to the investigation of the travel movements between geographic regions and the crossborder epidemic transmission by infectious travelers. Few studies address a correlated multivariate time series in multiple geographic regions.\n\nThe focus of this study is investigating the efficacy of the implemented public health intervention in managing infectious travelers across borders. Findings on the public health intervention for the SARS outbreak in 2003 and flu pandemic in 2009 are presented. For this purpose, a Bayesian statistical method is developed to detect a trend change for a system of Langevin equations. The system of Langevin equations describes the cross-border epidemic transmission in a standard epidemiological SIR compartment model and a meta-population network model. The input data to the method is a time series of the number of new cases reported in multiple geographical regions.\n\nThe connection between physics and Bayesian statistics is strong. Bayesian statistical methods give physicists much scientific return in drawing conclusion from an imperfect noisy dataset. Therefore, recent studies in theoretical, experimental, and applied physics devote much effort to developing Bayesian statistical methods to solve an inverse problem for a population-dynamic system [3] . An inverse problem of particular interest to these studies ranges from determining the value of an endogenous parameter, revealing an unknown boundary condition, and finding the initial condition of a variable to detecting a trend change in an exogenous parameter. The difficulty in solving an inverse problem originates in the complexity in computing a posterior probability density function and a Bayes factor.\n\nA posterior probability density function is computed with a belief propagation algorithm to understand an SIR dynamics on an evolving network [4] . A marginal probability density function is computed by factorizing the joint posterior probability density function into the family of parameterized normal distributions to analyze the annual flow volume of a river [5] . A series of Bayes factors are computed analytically to work out a molecular trajectory in Brownian dynamics [6] . Those studies present that significant findings on the nature of a population-dynamic system are obtained with Bayesian statistical methods.\n\nA trend change in a reproductive ratio of a H5N1 avian influenza is investigated with an anomaly detection technique, and a big increase in June 2006 is found [7] . The trend change in the parameters for infection and recovery is analyzed in the early, middle, and late phases of a SARS epidemic in 2003 with an approximate Bayesian computation technique [8] . A degree distribution is selected from representative degree distributions of a heterogeneous contact network between hosts for measles, gonorrhea, and norovirus outbreaks [9] . A compartment model with stratification by age and cross immunity for multiple strains fits the number of seasonal influenza cases the best [10] . A sequential importance sampling technique is applied in selecting a compartment model from candidate compartment models with a sub-divided compartments, an additional transition between compartments, or a time delay of transitions for a common cold outbreak [11] . A Bayes factor [12] indicates the relative goodness of fit between models in those model selection techniques [3] .\n\nRegression techniques and control charts are often applied to the early detection of an outbreak [13] . The change in an emergency department visit rate is analyzed for a real time syndromic surveillance [14] . An autoregressive integrated moving average model is developed for the early detection of such a bioterrorist attack as an anthrax release and contamination. A physician visit rate is predicted from the fraction of the queries to an online search engine [15] . The increase in this rate signals an impending outbreak. The current level of disease activity is modeled as a hidden state variable in a Markov switching model [16] . This model is applied to the prospective detection of cryptosporidiosis and anthrax outbreaks. A multivariate regression method is developed to detect an outbreak more robustly from the difference between the observations in multiple geographical regions [17] .\n\nThe entire population is sub-divided into distinct sub-populations in multiple geographical regions. The geographical regions are nodes n i (i = 0, 1, . . . , N \u2212 1). N is the number of nodes. The transportation between geographical regions is a pair of unidirectional links between nodes. Observations are made at times t d (d = 0, 1, . . . , D \u2212 1) at every node. D is the number of observations. The time interval between observations is t = t d+1 \u2212 t d . The cumulative number of new cases until t d is a vector variable J (t d ) = (J 0 (t d ), J 1 (t d ), . . . , J N\u22121 (t d )) where the elements J i (t) are the cumulative number at the node n i . The number of new cases between subsequent observations is J (t d ) = J (t d+1 ) \u2212 J (t d ). The time sequence D = { J (t d )} (d = 0, 1, . . . , D \u2212 1) forms a dataset. An example of a dataset is a bundle of the daily reports on new cases from hospitals in neighboring cities.\n\nThe problem is to detect from D whether two probability parameters change or not, which govern cross-border epidemic transmission. The cross-border epidemic transmission ensues from the travel of an infectious person at an infected node to an uninfected neighboring node, and local transmission from the traveler to susceptible residents there. The probability of a person moving between nodes per unit time is the product of two factors. One is the coefficient of proportionality \u03b3 , which determines the absolute trend of movements. The other is the relative volume of spatially heterogeneous movements between nodes. The relative volume can be determined by an empirical law as a function of the topology of links. The value of \u03b3 may change once at an unknown change point t [\u03b3 ] c . Neither the topology of links nor the relative volume of movements changes in this study. The parameter \u03b1 is the probability of an infectious person contacting a person and infecting the person per a unit time. It governs a local outbreak. The value of \u03b1 may also change once at an unknown change point t [\u03b1] c .\n\nThe mathematical model of cross-border transmission is a special case of a stochastic reaction-diffusion process, which is the integration of a standard epidemiological SIR compartment model and a meta-population network model [18] .\n\nThe presence of links in the meta-population network is represented by an adjacency matrix l. If a pair of uni-directional links is present between n i and n j , l ij and l ji are 1, and 0 otherwise. The probability of a person moving from the ith node to the jth node is \u03b3 ij , which forms a N \u00d7 N matrix. The value of its elements is derived by an empirical law [19, 20] in Eq. (1). The nodal degree of the ith node is k i = \ued71 N\u22121 j=0 l ij . The empirical law is valid generally for the world-wide airline transportation network [21] .\n\nThe state of a person changes from a susceptible state, through an infectious state, to a removed (recovered) state. The time dependent variables S i (t), I i (t), R i (t), and J i (t) are the number of susceptible persons, infectious persons, removed persons, and the cumulative number of new cases at the ith node at t. The parameter \u03b2 is the probability of an infectious person removed per a unit time. In this study, \u03b2 does not change. The reproductive ratio is given by R = \u03b1/\u03b2. Movements, infection, and removal are Markovian stochastic processes.\n\nThe time evolution of those variables is given by a Langevin equation [22] , which is a system of stochastic differential equations. The Langevin equation is given by Eqs. (2) and (3) in the early phase of the outbreak when I i \u226a S i and R i \u226a S i hold true [19] . The statistical property of the terms \u03be (t) is the Gaussian white noise.\n\nij (t).\n\n(2)\n\nEquivalently, the time evolution of the joint probability density function of the corresponding probability variable vector is given by a Fokker-Planck equation, which is a partial differential equation. The Fokker-Planck equation is converted to a system of ordinary differential equations to calculate the moments of the probability variables one order after another [23] .\n\nThe total cumulative number of new cases until t is given by\n\nThe mean of J at t is given by Eq. (4) when the value of \u03b1 does not change. I 0 is the initial number of infectious persons.\n\nThe variance about the mean of J at t is given by Eq. (4) .\n\nThe moments of I i at t are not derived in closed forms. The mean of I i at t + t for small t is given by Eq. (6) when the values of \u03b1 and \u03b3 do not change. The coefficients a ip are defined by Eq. (7).\n\nThe covariance about the mean between I i and I j at t + t for small t is given by Eq. (8) . The coefficients b ijp are defined by Eq. (9) where \u03b4 is the Kronecker's symbol.\n\nIf \u03b3 changes from \u03b3 1 to \u03b3 2 at time t = t [\u03b3 ] c , or \u03b1 changes from \u03b1 1 to \u03b1 2 at t = t [\u03b1] c , the moments satisfy the boundary conditions at the change points. Their formulae become more complicated than Eq. (4) through (9) . The skewness, kurtosis, and higher order moments are ignored in this study. The probability density function P(J, t) is approximated as a normal distribution with the mean in Eq. (4) and the variance in Eq. (5) . The joint probability density function P(I , t) is approximated as a multivariate normal distribution with the mean and covariance in Eq. (6) through (9).\n\nA trend change is detected with a model selection technique [24] . Model selection is the task of selecting a model which fits a dataset the best from a set of candidate models. A model without any change points of parameters is compared with a model with a change point. The model which fits a given dataset better is selected. The latter model is selected when the trend changes while the former model is selected when the trend does not change. Two computationally efficient model selectors are presented in 4.3.\n\nThe problem is decomposed into a sequence of two sub-problems. The first preparatory sub-problem is the \u03b1 problem to detect the change in \u03b1 from the time sequence of J(t d ). The second sub-problem is the \u03b3 problem to detect the change in \u03b3 from the time sequence of I (t d ). As a preparation to solve the \u03b3 problem, given either (\u03b1,\u03b2) or (\u03b1 1 ,\u03b1 2 ,t [\u03b1] c ,\u03b2), the value of the elements of l is obtained from the time sequence of I (t d ) \u2248 J (t d )/\u03b1 t with a maximal likelihood estimation [19] . It is represented byl. The adjacency matrix does not change. The model selectors are applied here. If the model without any change points is selected, the value of\u03b3 is obtained. If the model with a change point is selected, the value of\u03b3 1 ,\u03b3 2 , andt \n\nThe relative goodness of fit between two candidate models is given by a Bayes factor in Bayesian statistics. The definition of the Bayes factor F is the ratio of two posterior probabilities in Eq. (10) when one model is parameterized by a vector quantity \u03b8 1 and the other model by \u03b8 2 [25] .\n\nThe likelihood function L(\u03b8) is equal to the probability density function P(D|\u03b8). P(\u03b8) is the prior probability density function of the parameter vector.\n\nis the domain of definition for the parameter vector. If F > 1, the first model fits the dataset better than the second model. The commonly used scale for interpretation is as follows [26] . If 10 > F > 3, the selection of the first model is substantial. If 30 > F > 10, the selection is strong. If 100 > F > 30, the selection is very strong. If F > 100, the selection is decisive. This interpretation applies to any pairs of models.\n\nThe likelihood functions to solve the \u03b1 problem are given by Eqs. (11) and (12) . It is assumed that P(D|\u03b8) is a normal distribution with the calculated mean m [J] and variance v [J] . Note that I 0 is also a parameter.\n\nThe likelihood functions to solve the \u03b3 problem are given by Eqs. (11) and (12) . It is that assumed that P(D|\u03b8) is a multivariate normal distribution with the calculated mean m [I] and variance v [I] .\n\nThe value of the integrals in Eq. (10) is obtained for the likelihood functions in Eq. (11) through Eq. (14) neither analytically nor computationally efficiently. Two computationally efficient model selectors are presented in 4.3.1 and 4.3.2. One is a marginalized likelihood selector which calculates F numerically with a Monte Carlo integration [27] . The other is a maximal likelihood selector which calculates a Schwarz's Bayesian information criterion [28] as a single point Gaussian approximation to obtain the value of F .\n\nIf the landscape of the likelihood function L(\u03b8) has a single sharp peak at the maximal likelihood estimator\u03b8, that is the global maximum, the maximal likelihood selector tends to work more efficiently than the marginalized likelihood selector. The reason for this is that the single point Gaussian approximation is suitable for reproducing the peak while the Monte Carlo integration may be inaccurate if the density of random samples is too low to reproduce the peak. On the other hand, if the landscape is rugged with multiple peaks of similar altitude, or undulating gently in , the maximal likelihood selector tends to be more erroneous than the marginalized likelihood selector. Which is more excellent depends on the nature of the \u03b1 problem and \u03b2 problem, and the conditions like the dimension of the dataset N, the number of observations D, and the dimension of a parameter vector |\u03b8|. The difference between the model selectors in detecting the trend change correctly is investigated in 5.1.\n\nAn approximate value of the integrals in Eq. (10) \n\nDiscriminating whether F > 1 or F < 1 from the approximate value by Eq. (15) forms the marginalized likelihood selector.\n\nAn approximate value of the integrals in Eq. (10) is obtained from the Bayesian information criterion C in Eq. (17) by Eq. (16) . The formula for C is derived by expanding L(\u03b8) around the maximal likelihood estimator\u03b8 as a single point Gaussian approximation and by applying the Laplace's method [29] for calculating a finite integral. It is interpreted that C is an absolute measure to quantify the best balance between the goodness of fit and model complexity. The model complexity is represented by |\u03b8|. For example, |\u03b8| = 5 when \u03b8 = (I 0 , \u03b1 1 ,\n\nDiscriminating F > 1 or F < 1 from the approximate value by Eq. (16) forms the maximal likelihood selector.\n\nThe model selectors are tested with synthesized datasets. The datasets are generated by solving the Langevin equation in Eq. (3) numerically with a pseudo random number generator, and by recording the value of the variables at the times to make observations. The prior probability density function is uninformative in . For the \u03b1 problem,\n\n\u2022 P 1 (I 0 , \u03b1, \u03b2) for the model without any change points is a constant in 1 \n\nc , \u03b2) for the model with a change point is a constant in 2 For the \u03b3 problem,\n\n\u2022 P 1 (\u03b3 ) for the model without any change points is a constant in 1 \n\nc ) for the model with a change point is a constant in 2 \n\nThe estimates of the parameters with a maximal likelihood estimation are identical to those with a maximal a posteriori estimation. The number of random samples is 10 5 for the marginalized likelihood selector. of change increases. In case of correct detection, (\u03b3 1 \u2212\u03b3 2 )/\u03b3 1 = 0.24 on the average with a standard deviation of 0.088 when the true value is \u03b3 /\u03b3 1 = 0.8, andt [\u03b1] c = 17.5 on the average with a standard deviation of 7.0. The estimates of the parameters is not so accurate as those for Fig. 2 . This implies that it is difficult to solve the \u03b3 problem accurately. The signal-to-noise ratio for the relative proportion of the number of cases in one sub-population to that in other sub-population is smaller than the ratio for the growing number of cases in the entire sub-populations. Fig. 5 shows the fraction of correct detection of the change when \u03b3 decreases at t\n\nThe marginalized likelihood estimator works more accurately than the maximal likelihood estimator when both the values of \u03b1 and \u03b3 change. The fraction is larger than 0.7.\n\nTrend change is investigated in two real datasets with the uninformative prior probability density function in 5.1 and the marginalized likelihood selector with 10 8 random samples. One dataset 1 is the World Health Organization (WHO) archive on the SARS outbreak in 2003. The other dataset 2 is the WHO archive on the flu pandemic (H1N1 swine influenza A) in 2009.\n\nThe dataset in the archives had been updated every day. It is a collection of time sequence data J i (t d ) with t = 1 day. The value of the elements of the adjacency matrix l is obtained from the time sequence of I (t d ) \u2248 J (t d )/\u03b1 t with a maximal likelihood estimation [19] . [31] . This result is in good agreement with the estimated change point on April 2. This implies that the WHO worldwide alert barely affected local outbreaks directly for three weeks. Public health intervention took few immediate effects after the WHO worldwide alert. This time gap would have been shorter if the standards for diagnosis and treatment had been established more quickly and the public health authorities had controlled local exposure more successfully.\n\nThe flu pandemic was a global outbreak of a new strain of the H1N1 swine influenza A virus. The virus appeared in Veracruz in southeast Mexico in April 2009. The pandemic spread to United States and Canada immediately, and then to the South American countries, West European countries, and Pacific Rim countries. It began to decline in November. The WHO archives the cumulative number of the reported laboratory-confirmed cases. The target geographical regions in this study are those where five or more cases had been reported in about three weeks since April 28. They are Australia, Belgium, Brazil, Canada, Chile, China, Colombia, Costa Rica, Ecuador, El Salvador, France, Germany, Israel, Italy, Japan, Mexico, New Zealand, Panama, Peru, Spain, United Kingdom, and United States. The number of geographical regions is N = 22. The number of data is D = 25. The dataset is smoothed with a moving average filter whose window size is W = 3.\n\nAny changes in \u03b3 are not detected in the dataset. International travels and cross-border exposure were not affected although the WHO raised the global pandemic alert level to the phase 5 on April 29, which signals that community transmission is sustained across national borders. This is confirmed by the estimate by the United Nations World Tourism Organization that the tourism declined by only 4% in Mexico. 3 The public awareness of the pandemic might not be as acute as that at the time of the SARS outbreak probably because the flu in 2009 was mild in contrast to the severe flu in 1918, 1957, and 1968.\n\nBut the change in \u03b1 is detected. Selecting this model is decisive. The estimated value decreases by 52% at the estimated change pointt [\u03b1] c = 7.5 which is May 5. The consequent reproductive ratio decreases fromR 1 = 3.2 toR 2 = 1.5. R 2 is nearly the same as the basic reproductive ratio obtained from epidemiological and genetic analyses in Mexico [32] and the United States [33] . Local public health authorities in many countries started mandatory school closures, requested cancellation of large mass gatherings, and took other possible social distancing measures in May [34] . The implemented intervention was effective in controlling local exposure.\n\nAlthough the findings for the SARS outbreak and flu pandemic are still merely narrative evidence, the change points are indicative of the potential impact of public health intervention on cross-border epidemic transmission. The cross-border epidemic transmission ensues from a generally complex interplay between movements and infection. These stochastic processes may have adverse effects. Cross-border movements prompt the geographical distribution of cases to reach equilibrium while infection fuels local outbreak. In this study, the complexity is resolved by decomposing the Langevin equations in Eq. (2) into smaller dimensional model selection sub-problems so that they can be solved individually and sequentially with the state-of-the-art model selectors in Bayesian statistics. The cross-border movements and local outbreak are a special case of the diffusion and reaction of substance. The method is applicable potentially to solving an inverse problem and obtaining findings on the nature of a broad class of population-dynamic systems, whose time evolution as a stochastic reaction-diffusion process is formulated with a system of Langevin equations.\n\nPublic health authorities need to understand the efficacy of raising public awareness, social distancing, and other measures when they design an effective public health program and make an urgent decision on the verge of massive community transmission. Raising public awareness includes cancellation or postponement of travels, pre-travel health advisories, giving advices via mass media on hand washing, personal hygiene, cough etiquette, the use of face masks, hand rubs, and vaccine. In addition, border health screening, arrival and departure monitoring, dedicated ambulances, isolated hospital wards, and disinfection on public transport can be implemented. It is anticipated in the current practices that quarantine on board and temperature screening at airports will stop infectious travelers from entering across national or regional borders. Such a naive anticipation gives rise to much controversy about the economic efficiency. The anticipation is tested with observations when the intervention is implemented actually. The efficacy is quantified by the change in the probability parameters, and the economic efficiency is calculated. The public health authorities can accumulate ground information from such testing to organize an internationally shared extensive knowledge base on miscellaneous individual or combined public health intervention, its rational and anticipated outcome, empirical evidence on its efficacy, and possible reasons for the gap between the anticipation and observations, along with the supplementary knowledge from field-based medical case studies, epidemiological, and genetic studies under many demographic circumstances.\n\nIn obtaining more minute ground information for the knowledge base, the method in this study will be extended to more complicated mathematical models so that multiple change points can be detected, localized change points can be analyzed, and multiple geographic resolutions can be incorporated. The combined public health intervention may take effects multiple times on different data. The trend change in the entire population may arise from large localized trend changes in only a few sub-populations (an anomaly which violates the empirical law in Eq. (1)). Adjusting resolutions may be essential in the drilling-down from country level course analysis to province, city, and district level fine analyses. These are the topics for future studies."}