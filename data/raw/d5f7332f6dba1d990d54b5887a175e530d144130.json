{"title": "Optimising Renewal Models for Real-Time Epidemic Prediction and Estimation", "body": "The time-series of infected cases (infecteds) observed over the course of an in-are provided in the Methods. The APE uses the window of data preceding time 126 s, (I s s\u2212k+1 , \u039b s s\u2212k+1 ), to predict the incidence at s + 1 and assigns a log-score to 127 this prediction. This procedure is repeated over s \u2264 t and for possible k-values. 128 The k achieving the minimum cumulated log-score is deemed optimal. Fig. 1 129 illustrates the APE for selecting between two windows k 1 and k 2 . Figure 1 : Window length selection using APE. An observed incidence curve (blue dots) is sequentially and causally predicted over time s \u2264 t, using effective reproduction number estimates based on two possible windows lengths of k 1 and k 2 (green shaded). The true reproduction number (R s ) is drawn in dashed black (inset). Its estimates for each window length areR \u03c41(s) (dark grey) andR \u03c42(s) (light grey). Large windows (k 1 ) smooth over fluctuations. Small ones (k 2 ) recover these changes but are noisy. The APE assesses k 1 and k 2 via the log-loss of their sequential predictions (red error bars shown for predictions at t 1 and t 2 under k 1 and k 2 respectively). The k-window with the smaller APE is better supported by this incidence curve. The algorithm parameters are defined in Results.\n\n. CC-BY-NC-ND 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/835181 doi: bioRxiv preprint\n\nTo successfully adapt APE, we require the posterior predictive incidence dis-132 tribution of the renewal model, which at time s is P(x | I s s\u2212k+1 ) (see Eq. (9)), 133 with x indexing the space of possible one-step-ahead predictions at s + 1, and\n\n. We assume a gamma conjugate prior distribution on R \u03c4 (s) as in 135 [8] . For some hyperparameters a and c this is R \u03c4 (s) \u223c Gam (a, 1 /c), with Gam 136 as a standard shape-scale parametrised gamma distribution. The posterior dis-137 tribution of R \u03c4 (s) is P(R \u03c4 (s) | I s s\u2212k+1 ) and is described in Eq. (1) [8] . 138 R \u03c4 (s) | I t s\u2212k+1 \u223c Gam a + i \u03c4 (s) ,\n\n139 140\n\nFor convenience we define \u03b1 \u03c4 (s) := a + i \u03c4 (s) , \u03b2 \u03c4 (s) := 1 /c+\u03bb \u03c4 (s) with i \u03c4 (s) and 141 \u03bb \u03c4 (s) are the sum of incidence (I s ) and total infectiousness (\u039b s ) over the window 142 \u03c4 (s) (see Methods). If a variable y \u223c Gam(\u03b1, \u03b2) then P(y) = y \u03b1\u22121 e \u2212 y /\u03b2 /\u03b2 \u03b1 \u0393(\u03b1) 143 and E[y] = \u03b1\u03b2. The posterior mean estimate is thereforeR \u03c4 (t) = \u03b1 \u03c4 (t) \u03b2 \u03c4 (t) .\n\nApplying Bayes formula and marginalising yields the posterior predictive dis-145 tribution of the number of infecteds at s + 1 as in Eq.\n\n(2).\n\nIn Eq.\n\n(2) we used the conditional independence of future incidence data from 149 the past epi-curve, given the reproduction number to reduce P x | I s s\u2212k+1 , R \u03c4 (s) 150 to P x | R \u03c4 (s) , which expresses the renewal model relation x \u223c Poiss(R \u03c4 (s) \u039b s+1 ).\n\nAs \u039b s+1 only depends on I s s\u2212k+1 (see Methods) there are no unknowns. Solving 152 using this and Eq. (1) gives\n\nSince \u03b8 z\u22121 e \u2212y\u03b8 d\u03b8 \u2261 \u0393(z) /y z the integral in \u03c6 1 simplifies to \u0393(x+\u03b1 \u03c4 (s) ) (\u039bs+1+ 1 /\u03b2 \u03c4 (s) ) x+\u03b1 \u03c4 (s) .\n\nSome algebra then reveals the negative binomial (NB) distribution of Eq. (4). \n\n\u03bb \u03c4 (s) +\u039bs+1 . These relations explicate how the current 165 estimate of R \u03c4 (s) influences our ability to predict upcoming incidence points. 166 Setting s = t in all the above expressions will give the prediction statistics for 167 the next (unobserved) time-point beyond the present. 168 Importantly, Eq. (4) controls the APE metric through the shape of its dis-169 tribution. We explicitly compute this to derive Eq. (5), with I s+1 as the (true) 170 observed incidence at time s + 1, which is evaluated within the context of the 171 predictive space of x, and B s+1 := log Is+1+\u03b1 \u03c4 (s) \u22121 Is+1 as a binomial term.\n\nEq. (5) is easy to evaluate using the in-built NB routines of many software.\n\nWhen computing directly, the most difficult term is B s+1 when I s+1 and \u03b1 \u03c4 (s) 176 are large. In these cases Stirling approximations may be applied. The renewal 177 model APE metric offers a simple means of finding k * := arg min k APE k , the 178 window length that optimises one-step-ahead predictive performance.\n\nOptimal Window Selection 180 We apply our APE metric to select k * for various epidemic examples, which 181 examine reproduction number profiles for large outbreaks (Fig. 2a-Fig. 2c ), 182 small ones (which are more difficult to estimate: Fig. 2d-Fig. 2e) , and a random 183 one (Fig. 2f) . We simulated epidemics for t = 200 days using a generation time 184 distribution analogous to that used for Ebola virus disease predictions in [16] . 185 We investigated a window search space of 2 \u2264 k \u2264 t /2 and computed the APE at 186 each k, over the epidemic duration (1 \u2264 s \u2264 t). Reproduction number estimates, 187R \u03c4 (s) , and incidence predictions, x | I s s\u2212k+1 , are presented on the left and right 188 panels in Fig. 2 . Predictions over the first s < k times use all s data points. 189 We find that the APE metric balancesR \u03c4 (s) estimate accuracy against one- When k is unjustifiably large not only do we observe systematic prediction 201 and estimation errors, but alarmingly, we tend to be overconfident in them.\n\nWhen k is too small, we infer rapidly and randomly fluctuatingR \u03c4 (s) values, 203 which sometimes can deceptively underlie reasonably looking incidence predic-204 tions. Consequently, optimal k-selection is integral for trustworthy inference 205 6 . CC-BY-NC-ND 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/835181 doi: bioRxiv preprint The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/835181 doi: bioRxiv preprint Figure 3 : APE prediction accuracy. We compare the APE metric (solid blue, left y axis) to the percentage of true incidence values, I s+1 that fall outside the 95% prediction intervals of x | I s s\u2212k+1 (dotted red, right y axis) over the window search space k. The dashed line is k * and panels correspond to those of Fig. 2. and prediction. Observe that small k, which implies a more complex renewal 206 model (i.e. there are more parameters to be inferred), does not generally result 207 in better causally predictive one-step-ahead incidence predictions. Had we in-208 stead naively picked the k that best fits the existing epi-curve, then the smallest 209 k would always be favoured (overfitting) [9]. 210 We emphasize and validate the predictive performance of APE in Fig. 3 . The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/835181 doi: bioRxiv preprint tify our results over 10 3 simulated epi-curves with t = 150 days. We focus on 228 step-changes in R s and examine how the successively optimal window length, 229 k * (s), computed with data up to time s, responds. If k * (s) is sensitive to these 230 changes then it is likely a dependable means of diagnosing control efficacy. Note 231 that until now, the optimal window length was k * = k * (t). 232 We consider four possible models: (a) an epidemic that is increasing and [19] and apply the APE metric over 2 \u2264 k \u2264 t /2 with t as the last available 266 incidence time point. We compare the one-step-ahead I s+1 prediction fidelity 267 and the R \u03c4 (s) estimation accuracy obtained from the renewal model under the 268 APE-selected k * to that from the model used in [8] , which recommended weekly 269 windows (i.e. k = 7) after visually examining several window lengths. Our main 270 results are given in Fig. 6 and Fig. 7 . We benchmarked our estimates against The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/835181 doi: bioRxiv preprint Figure 4 : APE sensitivity to real-time transmission changes. We simulate 10 3 independent incidence curves under renewal models with reproduction numbers indicating (a) increasing, (b) controlled, (c) recovering and (d) cumulatively controlled epidemics. In each panel the top graphs give the true (green) and predicted (cyan) incidence ranges curves, the middle ones provide the estimate of R s under the final k * (t) and the bottom graphs illustrate how the successive k * (s) choices of the APE metric vary across time. We find that k * (s) responds rapidly to significant changes in the shape of the incidence curves. This makes it sensitive to important fluctuations in R s , especially those that force R s < 1. The APE metric is suitable for real-time applications and particularly useful for diagnosing the efficacy of control measures.\n\n. CC-BY-NC-ND 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/835181 doi: bioRxiv preprint Fig. 6 . Between 8 \u2212 10% of incidence data points are better covered by using 277 k * over k = 7. This improvement is apparent in the right graphs of (a) and 278 (b) in Fig. 7 , where the k = 7 case produces stiffer incidence predictions that 279 cannot properly reproduce the observed epi-curve. Weekly windows misjudge 280 the SARS epidemic peak, predict a multimodal SARS incidence curve that is 281 not reflected by the actual data and systematically underestimate influenza case 282 counts when it matters most (i.e. around the high incidence phase).\n\nHowever, the smaller k * window results in noisier R \u03c4 (s) estimates (left graphs 284 of (a) and (b) in Fig. 7) , which may be questionable. These rapidly fluctuat- The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/835181 doi: bioRxiv preprint Figure 6 : Empirical prediction accuracy. We compare the APE metric (solid blue, left y axis) to the percentage of true incidence values, I s+1 , which fall outside the 95% prediction intervals of x | I s s\u2212k+1 (dotted red, right y axis) across the window search space k. The dashed line gives k * (black) and k = 7 (grey). The top graph presents results for the influenza 1918 dataset, while the bottom one is for SARS 2003 data. We find that heuristic weekly windows lead to appreciably larger forecasting error than the APE selections.\n\nWe might suspect that certain artefacts of the data could resolve this issue, 295 rendering a more believable combination of estimated reproduction number and 296 predicted incidence. Particularly, the influenza data seems considerably more 297 affected by the smaller look-back windows. These k * = 2 windows are needed 298 to help predictions get close to the peak incidence values of the data. However, 299 these peaks seem reminiscent of outliers and in the original analysis of [17] they 300 were attributed to possible recollection bias in patients that were questioned.\n\nRemoving these biases might be expected to lead to smoother APE-justified 302 reproduction numbers. The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/835181 doi: bioRxiv preprint Figure 7 : Selection for empirical datasets. Left graphs of each panel com-pareR \u03c4 (s) estimates (cyan with 95% confidence intervals) at APE window length k * to those when k = 7 (weekly sliding windows). Right graphs give corresponding one-step-ahead predicted incidence curves (cyan with 95% prediction intervals). Dashed lines are the R = 1 threshold (left) and dots are the true incidence counts (right). The panels examine epi-data from outbreaks of (a) pandemic influenza (1918) and (b) SARS (2003), which are available in EpiEstim [8] . Panels (c) and (d) repeat (a) and (b) respectively, but smooth outliers in the incidence data using 5-day moving averages as in [17] . Interestingly, while k * leads to less believable reproduction number fluctuations, these are justified by the available data in both smoothed and un-smoothed cases. This hints that a Poisson renewal model may not be the most appropriate for these data. The longer weekly windows, which are heuristic recommendations of previous analyses [8] , miss important characteristics of the epi-curves.\n\n. CC-BY-NC-ND 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/835181 doi: bioRxiv preprint variance equality that may limit the ability to properly predict incidence data to available epidemic data.\n\nOur approach was founded on deriving an analytical expression for the re- . Grouping is therefore employed [8] .\n\nThis assumes that the reproduction number, denoted R \u03c4 (t) , is constant over 452 the past k time units [8] , and leads to a piecewise-constant function that classifies 453 between meaningful and negligible reproduction number changes. The grouped\n\n, with parameter-independent prediction error up to the present t, which we term k * , gives the renewal model 496 that best predicts the unseen datum at t + 1.\n\nWe generally do not use\u00ce s+1 directly, but instead obtain its full predictive The optimal window, k * := arg min k APE k , is easy to compute provided the 503 predictive distribution in Eq. (9) is calculable. Fig. 1 as tailored to specific problems, both metrics converge when errors are normally 510 distributed [11] . Other score functions can be used with these one-step-ahead 511 predictions when application-specific insights are available [28] .\n\nThe APE metric has formal links to MDL and Bayesian model selection However, the APE is simpler and more transparent, requiring no difficult 521 integral evaluations [9] . Consequently, the APE not only accounts for parametric 522 complexity (implicitly), but also applies to models of arbitrary complexity [11] .\n\nThe drawbacks of APE are that it requires the data to be ordered in time, and 524 being data-driven, its computational complexity increases linearly in both the "}