{"title": "Proportional fault-tolerant data mining with applications to bioinformatics", "body": "Valuable information is one of the most powerful weapons in the current knowledge age, and hence knowledge discovery has become a popular field of research. For example, in bioinformatics, biological data grow exponentially in size and complexity. It is not an easy work to extract useful information from it. Thus an important goal of data mining in bioinformatics is to extract valuable information from a large amount incomprehensible, biological data. Traditional algorithmical techniques use pattern matching algorithms to find valuable information for biological sequences. For example, linear scan (Knuth et al. 1977) and suffix tree (Ukkonen 1995) are two well-known approaches. For more references and applications on patter matching, we refer to (Gusfield 1997).\n\nIn contrast, data mining in bioinformatics deals with different techniques and algorithms to gain knowledge from data of biological sequences, structures, and microarrays (Chen 2005). Association-rule mining, which was first investigated in (Agrawal et al. 1993), explores the relationships among data items. It is a very popular technique in data mining. For example, in the analysis of association rules of a metabolic pathway, the rule \u201cGene\n1 \u2192 Gene\n2, support = 10%, confidence = 90%\u201d means that the support of 10% indicates that Gene\n1 and Gene\n2 are expressed together in 10% of all datasets, and the confidence of 90% indicates that 90% of the metabolic pathway which activated Gene\n1 also correlated with Gene\n2. Recently, Kotlyar and Jurisica used this technique to predict protein\u2013protein interactions (Kotlyar and Jurisica 2006).\n\nThe approaches used to find association rules can be roughly classified into two categories. The first category is the Apriori-based algorithm (Agrawal and Srikant 1994). This influential algorithm generates candidate patterns according to the non-monotonicity heuristic. The two main problems of Apriori are that (1) it needs to scan the database several times and (2) it generates too many candidate patterns. Various techniques have been used to overcome these problems. In Park et al. (1995), a hash table is used to store candidate patterns to increase the scanning efficiency; Agrawal and Srikant (1994), Han and Fu (1995), and Park et al. (1995) attempt to reduce the number of transactions scanned in future iterations; Savasere et al. (1995) and Zaki (2000) adopt the techniques of partitioning and sampling; and Brin et al. (1997) proposes a dynamic pattern-counting method in which candidate patterns are added at different points during a scan. And the negative association rules are considered in Antonie and Za\u00efane (2004); Thiruvady and Webb (2004); Zhang and Zhang (2004). Moreover, the problem of mining temporal indirect association patterns is considered in Chen et al. (2006).\n\nThe second category is the tree-based algorithm, which was proposed as the FP-tree (frequent-pattern tree) in Han et al. (2000). This algorithm scans the database to find all frequent items, and compresses the database by representing the frequent items in an FP-tree. Finally, all frequent patterns can be obtained by searching the tree. When the database is large, it is sometimes unrealistic to construct an FP-tree that resides in main memory. This leads to the proposed extension of the pattern-growth concept, namely, H-mine. H-mine designs a dynamic structure to adjust links dynamically, instead of requiring an FP-tree to be maintained or a physical database to be created. The motivation of this method is to preserve space, and initially involves loading transactions into memory. However, H-mine has to maintain a head table at each level of the tree, and modify the links to build a queue of the collection of transactions containing the same prefix before the pattern support is counted.\n\nExpect for the two categories of approaches, some works study on other ways to extract association rules. Matrix Apriori (Pavon et al. 2006) utilizes simple structures such as matrices and vectors in the process of generating frequent patterns, and it also minimizes the number of candidate sets. In (Lee et al. 2006), the idea of compressions rules is proposed and a data mining structure is used to extract association rules from a database. Redundant data will then be replaced by means of compression rules. (Chu et al. 2005) uses a simple method to transform the transactions read from the database into their corresponding patterns and then accumulates the occurring times of these patterns. (Chen et al. 2002) refines sampling functions to a two-phase sampling based algorithm that attempts to reduce the errors caused by sampling functions. (Chen and Ho 2005) proposed a sampling-based method that contains three phases. The first phase draws a small sample of data to estimate the set of frequent patterns, denoted as FS. The second phase computes the actual supports of the patterns in FS as well as identifies a subset of patterns in FS that need to be further examined in the next phase. Finally, the third phase explores this set and finds all missing frequent patterns.\n\nTraditional association-rule mining extracts patterns that match exactly. However, real-world databases contain noise that can make important information ambiguous, resulting in it not appearing in the mining result. Moreover, sometimes a decision maker will not be helped by the limited knowledge mined from a small database. Therefore, we need a method that copes with such variations in an association pattern (within predefined limits), which is called a fault-tolerant (FT) pattern.\n\nIn contrast to traditional frequent-pattern mining, the mining of FT patterns must tolerate a certain degree of inexactitude. For example, coughing, fever, a runny nose, a headache, and a sore throat are all signs of catching a cold. However, these symptoms are seldom present at the same time, and hence a doctor will not diagnose the disease exactly following the rule R1: {coughing, fever, runny nose, headache, sore throat} \u00e0{catch a cold}. Instead, a better rule corresponding to the real-world situation would be R2: Patients who have at least two of the following symptoms {coughing, fever, runny nose, headache, sore throat} are catching a cold. R2 requires matching just part of the data, which illustrates the sense of allowing for fault tolerance in data mining.\n\nYang et al. (2001) was the first to propose discovering FT frequent patterns in many dimensions. Their primary motivation was to find frequent groups of transactions (user groups, web sessions, and so on.) instead of focusing on just the items themselves, allowing for the discovery of groups of similar transactions that share most items. Unfortunately, the approach proposed in Yang et al. (2001) may generate sparse patterns, which may contain subpatterns that do not appear frequently.\n\nAnother milestone of FT pattern mining is the work described in Pei et al. (2001), in which extending Apriori and developing FT-Apriori for FT frequent-pattern mining allows a complete set of FT patterns to be mined out. However, the disadvantages of Apriori-based algorithms, including a huge number of candidate patterns and high database scanning frequency, also occurred in Pei et al. (2001). In response, Wang and Lee (2002) suggested the algorithm FTP-mine that finds FT patterns using the concept of pattern growth.\n\nThe main defect of Pei et al. (2001) and Wang and Lee (2002) is their definition of the number of tolerable faults in a pattern as a fixed number. Defining the number of tolerable faults in the patterns as a fixed number of items is not objective. The matters of \u201ctolerant 1 item\u201d in a pattern with length 4 and that in a pattern with length 10 give people entirely different sense. For example, the function of a protein is determined by its structure but not sequence. It is possible that two proteins of similar function have different sequence lengths, e.g., the family of heat shock proteins. In this case, it is hard to mine them together using FT pattern mining with fixed number of tolerable faults. In this paper, we introduce the problem of mining proportional FT patterns; in these patterns, the number of tolerable faults in the pattern is proportional to the pattern length. Two approaches are proposed to solve this problem. The remainder of this paper is organized as follows: background knowledge and problem definitions are presented in Section 2, the principles underlying our approaches are presented in Section 3, Section 4 describes the experimental results, and the conclusions and future work are discussed in Section 5.\n\nLet the set of subpatterns of X with length |X|\u2013k be S, where k = #fault(|X|), and the set of subpatterns of X\nsubpattern (X\nsubpattern \u2208 set(X\nsubpattern)) with length |X|\u20131\u2013(k\u20131) be S'. Because X\nsubpattern \u2208 set(X\nsubpattern), we know that S\u2032 \u2282 S. Suppose X is not a frequent FT pattern:\n\n\nsupFT(X) < min_supFT: if there exists a frequent FT pattern X\nsubpattern (X\nsubpattern \u2208 set(X\nsubpattern)), then we have supFT(X\nsubpattern) > min_supFT. Because supFT(X\nsubpattern) is included in supFT(X), supFT(X) > min_supFT, which disagrees with the supposition. Therefore, no patterns in set(X\nsubpattern) can be frequent patterns if supFT(X) < min_supFT.supitem\nB\n(X)(x\nj) < min_supitem: if there exists a pattern X\nsubpattern, where X\nsubpattern \u2208 set(X\nsubpattern) and X\nsubpattern contains x\nj, then we have supitem\nB\n(Xsubpattern)(x\nj) > min_supitem. Since the item support of X\nsubpattern counts from S', that of X is from S, and S\u2032 \u2282 S, we obtain supitem\nB\n(X)(x\nj) > min_supitem, which disagrees with the supposition. Therefore, none of patterns in set(X\nsubpattern) that contains item x\nj can be an FT pattern if supitem\nB\n(X)(x\nj) < min_supitem.\n\n\nLemma 2.2 holds because the supports of patterns parted by the gap are from the same set of subpatterns.\n\nTwo approaches are developed using Lemmas 2.1 and 2.2. First, based on Lemma 2.1, we propose the FT-BottomUp algorithm as a basic solution, which is explained in detail in Section 3.1. Although this algorithm is closed to violent solution, it finds the complete set of proportional FT patterns.\n\nTo improve the efficiency, the second algorithm (named FT-LevelWise) is proposed. Several pruning properties are adopted in this algorithm to improve the performance. The algorithm FT-LevelWise is discussed in Section 3.2.\n\n\nTransaction database DB\nFrequent item-support threshold min_supitem\nFrequent FT support threshold min_supFT\nFT parameter \u03b4\n\n\n\nFT patterns\n/* Fi,jis the set of FT patterns with length i and containing j faults */\n\n\nMethod:\nScan DB to find the set of frequent 1-patterns, denoted as F\n1,0;\n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\text{Let}}\\;DB\\prime = DB \\cap F_{{\\text{1,0}}} ;$$\\end{document}\nMaxPattern = \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\min {\\left\\{ {\\frac{{{\\text{length of longest transaction in }}DB\\prime }}{\\delta },{\\left| {F_{{1,0}} } \\right|}} \\right\\}};$$\\end{document}\n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\text{MaxFault = \\# fault}}\\left( {{\\text{MaxPattern}}} \\right){\\text{;}}$$\\end{document}\n\nfor (int i = 2; i < MaxPattern; i++){\nj = #fault(i)generate Ci,j by Fi\u20131,j;/* Ci,j are the candidate patterns for Fi,j */Fi,j = FT_frequent(Ci,j, min_supFT, min_supitem);/* FT_frequent(Ci,j, min_supFT, min_supitem) returns the set of patternsin Ci,j that comply with the two support thresholds*/}\noutput Fi,j;\n\n\nAlgorithm 1 shows that at the first \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\left\\lceil {\\frac{\\delta }{{1 - \\delta }}} \\right\\rceil $$\\end{document} levels we can adopt the basic Apriori method since patterns at those levels tolerate 0 items as faults, and FT patterns with 0 faults are only required to pass the item-support threshold to be frequent. When the number of tolerable faults is greater than 0, FT-Apriori is used repeatedly to generate candidate FT patterns with the tolerable faults in that level.\n\n\nTransaction database DB\nFrequent item-support threshold min_supitem\nFrequent FT support threshold min_supFT\nFT parameter \u03b4\n\n\n\nFT patterns\n\nMethod:\nScan DB to find the set of frequent 1-patterns, denoted as F\n1;\n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\text{Let}}\\;DB\\prime = DB \\cap {\\text{frequent}}\\;{\\text{1 - patterns;}}$$\\end{document}\nMaxPattern = \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$\\min {\\left\\{ {\\frac{{{\\text{length of longest transaction in }}DB\\prime }}{\\delta },{\\left| {F_{1} } \\right|}} \\right\\}};$$\\end{document}\n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$${\\text{MaxFault = \\# fault}}\\left( {{\\text{MaxPattern}}} \\right){\\text{;}}$$\\end{document}\nConstruct MaxFault+1 groups, G\ni, i = 0 to MaxFault;\n\nFor each group G\ni {\nhead\ni: generate candidate by F\n1;Check whether candidates are frequent FT patterns;\ntail\ni: generate candidate by head\ni;Prune by the head of the next group (head\ni+\n1);Check whether candidates are frequent FT patterns;\nMid\nij: For\nj = 1 to depth\ni/2{Generate candidate C\nij and C\ni\n(depthi-j) by mid\ni\n(j\u20131);Prune{\nIf (candidate is the subset of mid\ni\n(depthi\u2013j+1))Set the candidate as frequent;}Check other candidate frequent FT patterns;}\nOutput\nmid\nik, k = 0 to depthi\n}\n\n\nThis subsection evaluates the performance of our approach. As mentioned in Section 2, the solutions used in previous studies on mining FT patterns cannot be used to solve the proportional FT-patterns mining problem. Therefore, our basic FT-BottomUP algorithm is used to show the improvement of the FT-LevelWise algorithm. The two algorithms were implemented in Java, and all experiments were performed on a 1.8-GHz Pentium 4 CPU with 384 MB of RAM running Windows XP. The experimental datasets were generated using an IBM synthetic-data generator. Each dataset contained 1000 different items and 10,000 transactions (i.e., an average of ten items in a transaction), and several potential frequent patterns with an average length of 8.\n\nThe parameters used in our simulation are listed in Table 2. The performances of FT-BottomUp and FT-LevelWise are compared on the basis of their execution times.\n\n\n\nIn the first simulation, the relation between the FT parameter and the number of FT patterns was considered. It is trivial that a larger \u03b4 results in the extraction of fewer FT patterns. This situation is especially obvious in the range of \u03b4 from 0.7 to 0.9, as shown in Fig. 2. When \u03b4 is over 0.9, the patterns mined out are close to traditional frequent patterns, i.e., exactly matched patterns without the FT property.\n\n\n\nFigure 3 presents the total execution time of FT-BottomUp and FT-LevelWise, which clearly shows that the latter algorithm outperforms the former one.\n\n\n\nIn second set of simulations, \u03b4 was set to the default value and the reciprocal effect of the two support thresholds was investigated. Figure 4 shows the variation in the number of FT patterns when min_supFT and min_supitem change.\n\n\n\nThe scalabilities of FT-BottomUp and FT-LevelWise with respect to the two support thresholds are presented in Fig. 5. The performance of FT-LevelWise is still universally better than that of FT-BottomUp. Moreover, with a constant min_supitem, a smaller min_supFT results in a longer execution time.\n\n\n\nAn epitope, which is known as an antigenic determinant, is a small part of the molecular structure of an antigenic molecule that is recognized by the immune system, e.g., antibodies, B cells, and T cells (Murphy et al. 2008). A linear epitope is an epitope that is recognized by antibodies by its linear sequence of amino acids, or primary structure. In contrast, a conformational epitope is a sequence of discontinuous amino acids that come together in three dimensional conformation, or tertiary structure. Macromolecular antigens such as proteins usually have many different epitopes. Moreover, the same segment of protein can be a part of more than one epitopes. In general, the length of an epitope can be from eight to 24 amino acids. Intensive research is currently taking place to design reliable tools to predict epitopes on proteins. For example, ELISA (Enzyme Linked Immunosorbent Assay) is one of well-known Immunochemical methods. The epitope prediction problem is to predict epitopes on proteins.\n\nMany viruses have a spike protein that has similar function and location within the viral membrane. However, the spike protein of the Severe Acute Respiratory Syndrome-Associated coronavirus (SARS-CoV) has noted low amino acid homology with other viral spike proteins. The low similarity of amino acid sequence suggests that the spike protein of SARS-CoV may have additional functions other than the usual functions of coronavirus spike proteins (Rota et al. 2003). For SARS-CoV, the spike protein is about 1,255 amino acids long in general. The spike protein plays an important role in interactions with receptor and inducing neutralizing antibodies. Currently, only two epitopes are reported for SARS-CoV spike proteins, namely, \u201cKLRPFERDISNV\u201d and \u201cPDPLKPTKRSF\u201d (Saha et al. 2005). In this subsection, we consider the linear epitope prediction problem on spike proteins of SARS-CoV.\n\nThe inputs of most epitope prediction tools are a protein, e.g., the B-cell epitope prediction (Saha et al. 2005). In contrast, we consider a group of related proteins as our input. Our assumption is based on that most related proteins should have the same epitopes. It is like local view (a protein) versus global view (a group of related proteins). However, as mentioned above, the spike proteins of SARS-CoV are low similarity with the spike proteins of other coronaviruses. Thus, we only consider the spike proteins of SARS-CoV. Nevertheless, spike proteins among SARS-CoV are still not similar. That is, the idea of finding common segments in these proteins does not work. It happens that the concept of fault tolerance can be used in this problem. We transform the epitope prediction problem into the fault-tolerant data mining problem as follows.\n\nWe download 209 spike proteins of SARS-CoV from NCBI database. Each protein corresponds to a transaction. By using a sliding window, each segment obtained by sliding window corresponds to an item. Note that the same segment of protein can be a part of more than one epitopes. Thus, this transformation is reasonable. In this experiment, the window size is set to 15. Totally, we obtain an item set of size equal to 3,306. We expect that the output pattern is a set of epitope candidates since the pattern and each of its items obtain enough supports determined by min_supFT and min_supitem. The parameters used in our experiment are listed in Table 3.\n\n\n\nBy using our algorithm, the result we obtained is one maximal itemset with length 850 (respectively, 1,036) for min_supitem equal to 0.65 (respectively, 0.6). By checking the obtained itemsets, the two reported epitopes (mentioned above) for SARS-CoV spike proteins are exactly contained in this result. It shows that our proposed approach is potential for predicting epitopes.\n\nFor fixed FT data mining, while the number of tolerance faults is over 3, FT-Apriori algorithm (Pei et al. 2001) runs out of memory. Therefore, we consider the case that the number of tolerance faults equal to 3 and min_supitem = 0.65. In the results, four maximal itemsets (with length 680, 768, 367, and 229, respectively) are obtained. The union of these four sets has similar effect to the set of size 850. It shows that the proportional FT data mining is better than the fixed FT data mining for this application.\n\nNote that in this experiment we do not consider the property test of epitopes. For example, to be an epitope, we should consider some properties such as hydrophilicity, flexibility/mobility, accessibility, polarity, exposed surface, and turns. However, it is beyond the purpose of this paper.\n\nIn this paper, we propose the concept of proportional FT mining of frequent patterns. In contrast to previous studies on FT data mining, the number of tolerable faults in FT patterns found by our approach is proportional to the length of the patterns. The maximum number of tolerable faults can be obtained by evaluating the maximum possible length of an FT pattern. Two algorithms that find an effective solution to the problem of mining proportional FT frequent patterns are designed. The FT-BottomUp algorithm generates all candidate patterns with the number of fault items at each level. The FT-LevelWise algorithm divides all FT patterns into several groups, generates candidate patterns from both sides of each group, and applies some criteria to prune candidate patterns. Both algorithms extract the complete set of FT patterns. The experiments demonstrate the scalability of FT-LevelWise, which clearly performs much better than FT-BottomUp since it does not need to generate as many candidate patterns, with the database scanning time being half that of FT-BottomUp. By applying our algorithm on real data as shown in Section 4.2, two reported epitopes of spike proteins of SARS-CoV can be found in our resulting itemset and the proportional FT data mining is better than the fixed FT data mining for this application.\n\nBased upon our results, there is an ongoing challenge to find more efficient algorithms to improve the scalability of mining proportional FT frequent patterns. Another direction is to apply proportional FT data mining to real-world databases such as medical data or biological data though our proposed concept is general. As mentioned, biological data grow very fast. It is unavoidable that its data may contain noise or contaminated data. Therefore, the technique of proportional FT data mining will become an important tool in bioinformatics or biomedicine."}