{"title": "Evaluation of Data Exchange Process for Interoperability and Impact\non Electronic Laboratory Reporting Quality to a State Public Health\nAgency", "body": "Past [1] and present [2] national initiatives that promote\nelectronic health records (EHRs), also advocate for the electronic exchange of data\nacross various healthcare sectors using nationally recommended standards [3]. The critical role of public health, in the\ncontext of disease surveillance is recognized by these regulations, with\nrecommendations for electronic laboratory reporting (ELR). ELR refers to the\nelectronic transmission of labs related to reportable conditions to public health\n[4]. The emphasis on interoperability in\nrecent legislations [5] and roadmaps [6] is facilitating the focus on electronic\nmovement of data across healthcare settings. Many public health agencies have seen a\ntrend towards centralization of information technology services which adds another\nlayer of complexity to interoperability efforts. Given this landscape, it is\nessential to understand the process of data exchange and its impact on quality of\ndata being transmitted, as this is a crucial step in interoperability. In addition,\nthis holds broad implications for future priority transactions such as electronic\ncase reporting to public health.\n\nInitial research around ELR focused on comparison of paper-based reports to\nelectronic transmissions and found predominantly positive impact of ELR [7,8] on\nspecifically two metrics of data quality: timeliness and completeness. Subsequent\nstudies have assessed the role of intermediaries such as Health Information\nExchanges (HIE) [9-11] to facilitate ELR and reported\nbetter completeness of data with HIE support. Presently, studies have begun to focus\non provider reporting of notifiable diseases [12,13],\nas moving to electronic case notification [14-16] along with ELR will be\ngreat progress to support overall public health disease surveillance. Challenges in\nadoption and use of recommended codes [17-19] and need for an\ninformatics savvy workforce [20] were\nidentified as some of the issues in the move towards ELR [21].\n\nA recurring theme across these studies was assessing the quality of data, including\nexploring new venues to measure [22-24] and improve [25] it. Timeliness and completeness were the\ntwo dimensions of data quality (DQ) which were often evaluated. Metrics from DQ\nframeworks published in literature can be used as guidance in identifying additional\nparameters for assessment. Data quality assessment framework by Kahn et al. [26], identifies three DQ categories:\nconformance, completeness and plausibility, along with verification and validation\nas two DQ assessment contexts. DQ framework by Strong et al., proposes a broad\nconceptualization of the quality of data from perspective of data consumers. It\ndefines high quality data as one that is fit for use and emphasizes context around\ndata production and usage.\n\nStrong\u2019s framework proposes four DQ categories (Intrinsic DQ, Contextual DQ,\nRepresentational DQ, Accessibility DQ) comprising of fifteen DQ dimensions [27,28].\nThese include Intrinsic DQ (Accuracy, Objectivity, Believability, Reputation);\nContextual DQ (Relevancy, Value-Added, Timeliness, Completeness, Amount of data);\nRepresentational DQ (Interpretability, Ease of understanding, Concise\nrepresentation, Consistent representation); Accessibility DQ (Accessibility, Access\nsecurity). The strength of this framework is the breadth of DQ characteristics. Data\nquality is a multi-dimensional concept dependent on multitude of factors and\nadoption of data standards does facilitate DQ, but does not guarantee it [29]. Good quality data that meet many of DQ\ndimensions are critical for public health surveillance purposes. With increasing\nelectronic data exchange and emphasis on interoperability, it is essential to\nunderstand impact of various facets of data exchange on various dimensions of\nDQ.\n\nThe Minnesota Electronic Disease Surveillance System (MEDSS) [30] is the public health information system for supporting\ninfectious disease surveillance at a state level for Minnesota and operational since\n2008. It holds data on reportable conditions and receives ELRs submitted to the\nstate public health agency. MEDSS is used for case management, contact tracing and\nto support outbreak investigations. Its scope has expanded to include non-infectious\ndiseases such as blood lead surveillance and birth defects. It\u2019s a\nperson-centric surveillance system which currently holds ~1,279,986 events across\ninfectious diseases, lead and community and family health programs. Approximately\n153,880 lab tests/results were reported electronically for 2017 across six health\nsystems and four reference labs. Many healthcare systems are currently on a waiting\nlist for either onboarding/move to electronic exchange or upgrade to better version\nof reporting standard.\n\nNationally recommended standards for ELR [4]\ncomprise of HL7 2.5.1 for message format and LOINC [31] and SNOMED [32] codes for\nrepresentation of lab tests and results respectively. With increasing demands for\nelectronic data exchange for incoming data to MEDSS from clinical sectors and for\noutgoing data to Centers for Disease Control and Prevention (CDC), new informatics\ntools to support data validation and exchange were implemented. The objective of\nthis study was to assess the data exchange process and to understand its impact on\nthe quality of data in MEDSS. The overarching goal is to utilize findings for\nimprovements in informatics tools and processes to enhance the value of MEDSS by\nproviding good quality data to support various public health purposes including\ndisease surveillance.\n\nThe process of assessing data exchange for electronic lab reporting and its impact\nwas a mixed methods approach with qualitative data obtained through expert\ndiscussions and quantitative data obtained from queries of the MEDSS system. Various\nsubject matter experts (n=9) were identified spanning across the informatics team\nthat supports MEDSS operations, public health program professionals who are users of\nthe MEDSS system and its data, and the Information Technology (IT) team which\nsupports the data exchange process. The focus included both on-boarding (process of\nshifting to electronic exchange for either new reporting or migration/upgrade to\ndifferent standard) and on-going submissions. ELR is unique in that reporting can\noccur from either EHR or from LIMS (Laboratory Information Management System) and\ncan occur from healthcare delivery organization or from reference laboratories and\nthese were taken into consideration. Interviews were conducted in an\nopen-ended/discussion format and were done over time frame of November 2017 through\nFebruary 2018. Based on these discussions, two high level categories of data\nexchange process which could impact data quality were identified: onboarding for\nelectronic lab reporting and internal data exchange routing.\n\nFigure 1 displays the ELR onboarding process and\nincludes the testing and validation suite of tools offered in public domain by the\nNational Institute of Standards and Technology (NIST) [33]. The six identified key processes that influence quality of\ndata are numbered A through F (A - mapping of tests and results to appropriate\ncodes, B - NIST test bed for testing of messages, C - submit test HL7 messages, D -\nsolicit HL7 messages with test cases (e.g. specific tests, seasonal diseases), E -\ntechnical review, F - program review). Figure 2\ndisplays the internal data exchange routing process which includes the PHIN\nMessaging System (PHIN MS) [34], a CDC\nprovided software that serves as a transport mechanism for effective movement of\nmessages. This part comprises of four main components numbered G through J (G - PHIN\nMS, H - Lab code list database validation, I \u2013 Rhapsody\u00ae Integration\nEngine [35] rules, J - mapping in MEDSS).\n\nThe potential influence of the ten identified critical steps in the data exchange\nprocess and its impact on quality of data was identified through expert input using\nStrong\u2019s DQ framework as a guidance. This was followed by analysis of data in\nMEDSS by criteria identified by the informatics team. Evaluation of messages not\nmapped to any disease program in MEDSS was identified as a priority. Next,\nassessment of completeness of race and ethnicity fields before and after\nimplementation of demographic data import feature in ELR was completed. Using Influenza\nreporting as a scenario, the number of non-reportable tests that get submitted and\nadded to data in MEDSS was examined. Finally, the number of incoming messages which\nget rejected due to errors was examined to quantify the need for additional technical\nassistance.\n\nThe process of exchanging data electronically is iterative and is initiated with\nnumerous rounds of message testing and varying gradation of technical assistance\nbased on data submitter need and capabilities. Each step in the process was deemed\ncritical in its impact on the quality of data which moves across clinical sector and\npublic health. Table 1 lists the six\nidentified key processes for ELR onboarding, relevant sub-processes/notes and their\ninfluence including both DQ metric and DQ dimension. All DQ metrics (Intrinsic DQ,\nContextual DQ, Representational DQ, and Accessibility DQ) were impacted with varying\ninfluence on DQ dimensions. Some errors such as improper mapping on EHR end had a\ncascading effect and can pass through technical filters and go undetected till use\nof data by epidemiologists. Some DQ dimensions such as accuracy, relevancy,\nvalue-added data and interpretability are more dependent on users at either end of\nthe data exchange spectrum, the relevant clinical groups and the public health\nprogram professionals.\n\nTable 2 lists the six identified key processes\nrelated to on-going production submissions using the internal data exchange routing\nand their influence on data quality. Similar to the on-boarding process, all DQ\nmetrics (Intrinsic DQ, Contextual DQ, Representational DQ, and Accessibility DQ)\nwere impacted with varying influence on DQ dimensions. The three steps labelled H.\n(Lab Code List Database Validation), I. (Rhapsody Integration Engine Rules) and J.\n(Mapping in MEDSS) were deemed critical with high level of need for on-going\nmaintenance. Laboratory tests are constantly evolving along with new lab codes\n(LOINC) and organisms detected (SNOMED) and their combinations to determine disease\nchanging, some processes (H. I. J.) require frequent review. The analysis also\nrevealed the need for collaboration and some processes are dependent on coordination\nacross MEDSS informatics team, information technology (IT) staff and public health\nprogram professionals.\n\nThe results from analysis of data in MEDSS by various criteria identified by the\ninformatics team is presented in Table 3.\nEvaluation for cases which are not mapped to any disease program and assigned to\n\u201cother/unknown\u201d category yielded 952 cases. Assessment of messages for\nthese cases noted an absence of LOINC and/or SNOMED codes and their combination pair\nfor disease assignment. Next, the analysis focused on submission of non-reportable\nrespiratory diseases along with reportable conditions (Influenza) due to issues with\nspecial lab test panel, and this identified 366 cases. This was followed by\nevaluating the number of incoming messages which get rejected due to errors and\nthere currently isn\u2019t any process that keeps track of it. The corresponding\nimpact on data quality metrics due to these identified issues are also presented in\nTable 3. An enhancement was implemented\nin January 2018 to import demographic data (race, ethnicity) from ELR feeds and this\nevaluation presented in Table 4. Of the total\nof 3,651 electronic lab messages received from January through February 2018, data\non Race was present in 2,310 messages and 1680 messages received in that time frame\nhad data on Ethnicity. Comparison of this new data with already existing race and\nethnicity data in MEDSS obtained through case reporting and follow-up investigations\nrevealed 270 number of messages wherein race from ELR feed was different than one\ncurrently recorded in MEDSS.\n\nFederal regulations and incentives have offered the needed momentum towards\nelectronic reporting to public health. But, there are differences in public health\nmeasure reporting [36] with ELR lagging\nbehind immunization reporting due to complexities around multitude of labs\nassociated with reportable conditions, slow adoption of recommended codes and\nmultiple entities/professionals involved in exchange such as clinical labs,\nreference labs, ordering provider, infection control practitioner and disease\nepidemiologists. Another key factor to consider is that ELR can be generated from\nEHRs or from laboratory information systems (LIS) in reference labs or in healthcare\nsettings. This study also portrays the need for constant updates to the various\nvalidation tools to ensure errors are not being propagated across the data exchange\nchain.\n\nThis research points to the complexity of the data exchange process by illustrating\nthe numerous stakeholders involved and the critical role each one plays in moving\ntowards interoperability. It also pointed to the need for all data exchange partners\nto be informed of evolution of standards, both message formats (e.g. HL7) and codes\n(e.g. LOINC, SNOMED). Some of these exchange mechanisms require technical assistance\nfor either submitter (e.g. labs, providers) and the receiver (e.g. public health) or\nboth of them. National projects such as Digital Bridge [37] and APHL Informatics Messaging Services (AIMS) [38] are aimed to assist in data exchange across\njurisdictional boundaries in public health. The data exchange process could be set\nsuch that messages get rejected if they fail any of the checks, but will require\nmanual intervention by public health or the data reporters to understand quality\nissues around rejection and fix them.\n\nThe study also presents various testing tools (NIST test bed) and validation engines\n(Rhapsody, lab code list validation database) that help to automate quality checks\nand monitor various DQ dimensions. Approaches from other public health reporting\nsuch as immunizations wherein provider quality reports [39] are generated could be tried in the context of ELR.\nLikewise open source software tools have been proposed to support data quality\nchecks for both immunization reporting [39]\nand ELR [23,40]. Implementation and maintenance of these tools require both\nfinancial and technical resources. Importantly, there needs to be overarching\nguidance and support from national organizations such as CDC to ensure\nstandardization and to facilitate sharing of tools/resources across\njurisdictions.\n\nThe study revealed that data quality is dynamic and on-going oversight is a\ncollaborative effort by MEDSS informatics team, technical and public health program\nprofessionals. Overall, maintenance of good data quality in context of ELR needs a\nmultipronged approach with automated tools, data exchange partners education,\ntechnical assistance, regular updates of codes/tools, organizational commitment and\nnational guidelines along with support by informaticians/data quality analysts.\n\nThis research depicts the details of processes, people and technology and the need\nfor all the parts to align to make an electronic data exchange truly meaningful by\nproviding good quality to data that fits the purpose (public health surveillance in\nthis case). It highlights the benefits of standardization of data exchange processes\nwhich can be applied to other public health transactions. Many public health\nagencies have seen a trend towards centralization of information technology services\nwhich adds another layer of complexity to interoperability efforts. It underscores\nthe value of a public health informatician to be part of electronic exchange of data\nacross various sectors (clinical care, labs) and public health. Finally, this study\npresents a compelling picture of the interoperability endeavor as a team effort and\nunderscores the critical role an informatics team can play in facilitating the data\nexchange process.\n\nThe study has some limitations and focus on some dimensions of data quality by Strong\net al., is one of them. Some DQ aspects such as accessibility are not integrated\nwith exchange process and hence were excluded. The research emphasis was determined\nby criteria outlined by MEDSS informatics team, and was limited based on available\ndata during study period. Some metrics were not tracked and certain tool\nenhancements were implemented recently by IT support team and thus evaluation was\nlimited. Another limitation is that currently a large volume of ELR submitters are\nreference labs which are not required to collect race and ethnicity data and hence\ncompleteness of those data fields through ELR is limited. Some DQ errors are\nattributed to frequency of upgrade of codes/validation engine that are driven by\norganizational resources (finances, trained personnel) / institutional priorities\nand beyond the scope of this study.\n\nWith the growing demands for electronic reporting with public health, there is a need\nto understand the current processes for supporting electronic exchange and their\nimpact on quality of data. This study focused on electronic laboratory reporting to\npublic health and analyzed both onboarding and internal data exchange processes.\nInsights gathered from this research can be applied to other public health reporting\ncurrently (e.g. immunizations) and will be valuable in planning for electronic case\nreporting in near future. The study has potential implications in promoting data\nquality along with electronic exchange to support public health surveillance."}