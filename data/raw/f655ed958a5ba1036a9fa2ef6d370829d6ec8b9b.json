{"title": "Capturing sequence diversity in metagenomes with comprehensive and scalable probe design", "body": "Sequencing of patient samples has transformed the detection and characterization of important human viral pathogens 1 and has provided crucial insights into their evolution and epidemiology [2] [3] [4] [5] . Unbiased metagenomic sequencing is particularly useful for identifying and obtaining genome sequences of emerging or diverse species because it allows accurate detection of both new and known species and variants 1 . However, extremely low viral titers (as seen in the recent Zika virus outbreak 6, 7 ) or high levels of host material 8 can limit its practical utility: a low ratio of viral to host material makes genome assembly difficult or prohibitively expensive. To fully realize the potential of metagenomic sequencing, we need new tools that improve its sensitivity while preserving its comprehensive, unbiased scope.\n\nPrevious studies have used targeted amplification 9, 10 or enrichment via capture of viral nucleic acid using oligonucleotide probes [11] [12] [13] to improve the sensitivity of sequencing for specific viruses. However, achieving comprehensive sequencing of viruses --similar to the use of microarrays for differential detection [14] [15] [16] --is challenging due to the enormous diversity of viral genomes. A recent study used a probe set to target a large panel of viral species simultaneously, but did not attempt to cover strain diversity in the probe design 17 . Other studies have designed probe sets to more comprehensively target viral diversity and tested their performance 18, 19 . These overcome the primary limitation of single virus enrichment methods, i.e., having to know a priori the taxon of interest. However, these existing probe sets that target viral diversity have been designed with ad hoc approaches and are not publicly available.\n\nTo enhance capture of diverse targets, we need rigorous methods, implemented in publicly available tools, to create and rapidly update optimally designed probe sets. These methods should comprehensively cover known sequence diversity and their designs should be dynamic and scalable to keep pace with the growing diversity of known taxa and the discovery of novel species 20, 21 . Several existing approaches to probe design for nonmicrobial targets [22] [23] [24] strive to meet some of these goals but are not designed to be applied against the extensive diversity seen within and across microbial taxa. virus probe sets, and then use these to enrich viral nucleic acid in sequencing libraries from patient and environmental samples across diverse source material. We evaluate their performance and investigate any biases introduced by capture with these probe sets. Finally, to demonstrate use in clinical and biosurveillance settings, we apply these probe sets to recover Lassa virus genomes in low titer clinical samples from the 2018 Lassa fever outbreak in Nigeria and to identify viruses in human and mosquito samples with unknown content.\n\nTo design probe sets, CATCH accepts any collection of sequences that a user seeks to target. This typically represents all known genomic diversity of one or more species. CATCH designs a set of sequences for oligonucleotide probes using a model for determining whether a probe hybridizes to a region of target sequence (Supplementary Fig. 1a ; Online Methods); the probes designed by CATCH have guarantees on capturing input diversity under this model.\n\nCATCH searches for an optimal probe set given a desired number of oligonucleotides to output, which might be determined by factors such as cost or synthesis constraints. The input to CATCH is one or more datasets, each composed of sequences of any length, that need not be aligned to each other. In this study, each dataset consists of genomes from one species, or closely related taxa, we seek to target. CATCH incorporates various parameters that govern hybridization ( Supplementary Fig. 1b) , such as sequence complementarity between probe and target, and accepts different values for each dataset (Supplementary Fig.  1c ). This allows, for example, more diverse datasets to be assigned less stringent conditions than others. Assume we have a function s(d, \u03b8 d ) that gives a probe set for a single dataset d using hybridization parameters \u03b8 d , and let S({\u03b8 d }) represent the union of s(d, \u03b8 d ) across all datasets d where {\u03b8 d } is the collection of parameters across all datasets. CATCH calculates S({\u03b8 d }), or the final probe set, by minimizing a loss function over {\u03b8 d } while ensuring that the number of probes in S({\u03b8 d }) falls within a specified number of oligonucleotides (Fig.   1a ).\n\nThe key to determining the final probe set is then to find an optimal probe set s(d, \u03b8 d ) for each input dataset. Briefly, CATCH creates \"candidate\" probes from the target genomes in d and seeks to approximate, under \u03b8 d , the smallest set of candidates that achieve full coverage of the target genomes. Our approach treats this problem as an instance of the well-studied set cover problem 25, 26 , the solution to which is s(d, \u03b8 d ) ( Fig. 1a ; Online Methods). We found that this approach scales well with increasing diversity of target genomes and produces substantially fewer probes than previously used approaches (Fig. 1b, Supplementary Fig. 2 ).\n\nCATCH's framework offers considerable flexibility in designing probes for various applications. For example, a user can customize the model of hybridization that CATCH uses to determine whether a candidate probe will hybridize to and capture a particular target sequence. Also, a user can design probe sets for capturing only a specified fraction of each target genome and, relatedly, for targeting regions of the genome that distinguish similar but distinct subtypes. CATCH also offers an option to blacklist sequences, e.g., highly abundant ribosomal RNA sequences, so that output probes are unlikely to capture them. CATCH can use locality-sensitive hashing 27, 28 , if desired, to reduce the number of candidate probes that are explored, improving runtime and memory usage on especially large numbers of input sequences. We implemented CATCH in a Python package that is publicly available at https://github.com/broadinstitute/catch.\n\nWe used CATCH to design a probe set that targets all viral species reported to infect humans (V ALL ), which could be used to achieve more sensitive metagenomic sequencing of viruses from human samples. V ALL encompasses 356 species (86 genera, 31 families), and we designed it using genomes available from NCBI GenBank 29, 30 (Supplementary Table 1 ). We constrained the number of probes to 350,000, significantly fewer than the number used in studies with comparable goals 18, 19 , reducing the cost of synthesizing probes that target diversity across hundreds of viral species. The design output by CATCH contained 349,998 probes (Fig. 1c) . This design represents comprehensive coverage of the input sequence diversity under conservative choices of parameter values, e.g., tolerating few mismatches between probe and target sequence (Fig. 1d) . To compare the performance of V ALL against probe sets with lower complexity, we separately designed three focused probe sets for commonly co-circulating viral infections: measles and mumps viruses (V MM ; 6,219 probes), Zika and chikungunya viruses (V ZC ; 6,171 probes), and a panel of 23 species (16 genera, 12 families) circulating in West Africa (V WAFR ; 44,995 probes) ( Supplementary Fig. 3 , Supplementary Table 1) .\n\nWe synthesized V ALL as 75 nt biotinylated ssDNA and the focused probe sets (V WAFR , V MM , V ZC ) as 100 nt biotinylated ssRNA. The ssDNA probes in V ALL are more stable and therefore more suitable for use in lower resource settings compared to ssRNA probes. We expect the ssRNA probes to be more sensitive than ssDNA probes in enriching target cDNA due to their longer length and the stronger bonds formed between RNA and DNA 31 , making the focused probe sets a useful benchmark for the performance of V ALL .\n\nTo evaluate enrichment efficiency of V ALL , we prepared sequencing libraries from 30 patient and environmental samples containing at least one of 8 different viruses: dengue virus (DENV), GB virus C (GBV-C), Hepatitis C virus (HCV), HIV-1, influenza A virus (IAV), Lassa virus (LASV), mumps virus (MuV), and Zika virus (ZIKV) (Supplementary Table 2 ). These 8 viruses together reflect a range of typical viral titers in biological samples, including ones that have extremely low levels, such as ZIKV 6, 7 . The samples encompass a range of source materials: plasma, serum, buccal swabs, urine, avian swabs, and mosquito pools. We performed capture on these libraries and sequenced them both before and after capture. To compare enrichment of viral content across sequencing runs, we downsampled raw read data from each sample to the same number of reads (200,000) before further analysis. Downsampling to correct for differences in sequencing depth, rather than the more common use of a normalized count such as reads per million, is useful for two reasons. First, it allows us to compare our ability to assemble genomes (e.g., owing to capture) in samples that were sequenced to different depths. Second, downsampling helps to correct for differences in sequencing depth in the presence of a high frequency of PCR duplicate reads (Online Methods), as observed in captured libraries. We removed duplicate reads during analyses so that we could measure enrichment of viral information (i.e., unique viral content) rather than measure an artifactual enrichment arising from PCR amplification.\n\nWe first assessed enrichment of viral content by examining the change in per-base read depth resulting from capture with V ALL . Overall, we observed a median increase in unique viral reads across all samples of 18 \u2715 (Q 1 =4.6, Q 3 =29.6) (Supplementary Table 3 ). Capture increased depth across the length of each viral genome, with no apparent preference in enrichment for regions over this length (Fig. 2a, b, Supplementary Fig. 4) . Moreover, capture successfully enriched viral content in each of the 6 sample types we tested. The increase in coverage depth varied between samples, likely in part because the samples differed in their starting concentration and, as expected, we saw lower enrichment in samples with higher abundance of virus before capture ( Supplementary Fig. 5 ).\n\nNext we analyzed how capture improved our ability to assemble viral genomes. For samples that had incomplete genome assemblies (<90%) before capture, we found that application of V ALL allowed us to assemble a greater fraction of the genome in all cases (Fig. 2c) . Importantly, of the 14 samples from which we were unable to assemble any contig before capture, 11 assembled at least partial genomes (>50%) using V ALL , of which 4 were complete genomes (>90%). Many of the viruses we tested, such as HCV and HIV-1, are known to have high within-species diversity yet the enrichment of their unique content was consistent with that of less diverse species (Supplementary Table 3 ).\n\nWe also explored the impact of capture on the complete metagenomic diversity within each sample. Metagenomic sequencing generates reads from the host genome as well as background contaminants 32 , and capture ought to reduce the abundance of these taxa. Following capture with V ALL , the fraction of sequence classified as human decreased in patient samples while viral species with a wide range of pre-capture abundances were strongly enriched (Fig. 2d) . Moreover, we observed a reduction in the overall number of species detected after capture ( Supplementary Fig. 6a ), suggesting that capture indeed reduces non-targeted taxa. Lastly, analysis of this metagenomic data identified a number of other enriched viral species present in these samples (Supplementary Table 4 ). For example, one HIV-1 sample showed strong evidence of HCV co-infection, an observation consistent with clinical PCR testing.\n\nIn addition to measuring enrichment on patient and environmental samples, we sought to evaluate the sensitivity of V ALL on samples with known quantities of viral and background material. To do so, we performed capture with V ALL on serial dilutions of Ebola virus (EBOV) --ranging from 10 6 copies down to single copy --in known background amounts of human RNA. At a depth of 200,000 reads, use of V ALL allowed us to reliably detect viral content (i.e., observe viral reads in two technical replicates) down to 100 copies in 30 ng of background and 1,000 copies in 300 ng (Fig. 3a, Supplementary Table 5 ), each at least an order of magnitude fewer than without capture, and similarly lowered the input at which we could assemble genomes ( Supplementary Fig. 7a) . Although we chose a single sequencing depth so that we could compare pre-and post-capture results, higher sequencing depths provide more viral material and thus more sensitivity in detection ( Supplementary Fig. 7b , c).\n\nTo test whether the performance of the highly complex 356-virus V ALL probe set matches that of focused ssRNA probe sets, we first compared it to the 23-virus V WAFR probe set. We evaluated the 6 viral species we tested from the patient and environmental samples that were present in both the V ALL and V WAFR probe sets, and we found that performance was concordant between them: V WAFR provides almost the same number of unique viral reads as V ALL (1.01 \u2715 as many; Q 1 =0.93, Q 3 =1.34) (Supplementary Table 3 ). The percentage of each genome that we could unambiguously assemble was also similar between the probe sets ( Fig. 2c) , as was the read depth ( Supplementary Fig. 4 , Supplementary Fig. 8a , b). Following capture with V WAFR , human material and the overall number of detected species both decreased, as with V ALL , although these changes were more pronounced with V WAFR (Supplementary Fig. 6a , b, Supplementary Table 4 ).\n\nWe next compared the V ALL probe set to the two 2-virus probe sets V MM and V ZC . We found that enrichment for MuV and ZIKV samples was slightly higher using the 2-virus probe sets than with V ALL (2.26 \u2715 more unique viral reads; Q 1 =1.69, Q 3 =3.36) (Supplementary Table 3 , Supplementary Fig. 4 , Supplementary Fig. 8c, d) . The additional gain of these probe sets might be useful in some applications, but was considerably less than the 18 \u2715 increase provided by V ALL against a pre-capture sample. Overall, our results suggest that neither the complexity of the V ALL probe set nor its use of shorter ssDNA probes prevent it from efficiently enriching viral content.\n\nWe then evaluated how well our V ALL and V WAFR probe sets capture sequence that is divergent from sequences used in their design. To do this, we tested whether the probe sets, whose designs included human IAV, successfully enrich the genome of the non-human, avian subtype H4N4 (IAV-SM5). H4N4 was not included in the designs, making it a useful test case for this relationship. Moreover, the IAV genome has 8 RNA segments that differ considerably in their genetic diversity; segment 4 (hemagglutinin; H) and segment 6 (neuraminidase; N), which are used to define the subtypes, exhibit the most diversity.\n\nThe segments of the H4N4 genome display different levels of enrichment following capture ( Supplementary Fig. 9 ). To investigate whether these differences are related to sequence divergence from the probes, we compared the identity between probes and sequence in the H4N4 genome to the observed enrichment of that sequence (Fig. 3b) . We saw the least enrichment in segment 6 (N), which had the least identity between probe sequence and the H4N4 sequence, as we did not include any sequences of the N4 subtypes in the probe designs. Interestingly, V ALL did show limited positive enrichment of segment 6, as well as of segment 4 (H); these enrichments were lower than those of the less divergent segments. But this was not the case for segment 4 when using V WAFR , suggesting a greater target affinity of V WAFR capture when there is some degree of divergence between probes and target sequence (Fig. 3b) , potentially due to this probe set's longer, ssRNA probes. For both probe sets, we observed no clear inter-segment differences in enrichment across the remaining segments, whose sequences have high identity with probe sequences (Fig. 3b , Supplementary Fig. 9 ). These results show that the probe sets can capture sequence that differs markedly from what they were designed to target, but nonetheless that sequence similarity with probes influences enrichment efficiency.\n\nGiven that many viruses co-circulate within geographic regions, we assessed whether capture accurately preserves within-sample viral species complexity. We first evaluated capture on mock co-infections containing 2, 4, 6, or 8 viruses. Using both V ALL and V WAFR , we observed an increase in overall viral content while preserving relative frequencies of each virus present in the sample (Fig. 3c, Supplementary Table 4 ).\n\nBecause viruses often have extensive within-host viral nucleotide variation that can inform studies of transmission and within-host virus evolution 33,34 , we examined the impact of capture on estimating within-host variant frequencies. We used three DENV samples that yielded high read depth (Supplementary Table 3 ). Using both V ALL and V WAFR , we found that frequencies of all within-host variants were consistent with pre-capture levels ( Fig. 3d , Supplementary Table 6 ; concordance correlation coefficient is 0.996 for V ALL and 0.997 for V WAFR ). These estimates were consistent for both low and high frequency variants. Since capture preserves frequencies so well, it should enable measurement of within-host diversity that is both sensitive and cost-effective.\n\nTo demonstrate the application of V ALL in the case of an outbreak, we applied it to samples of clinically confirmed (by qRT-PCR) Lassa fever cases from Nigeria. In 2018, Nigeria experienced a sharp increase in cases of Lassa fever, a severe hemorrhagic disease caused by LASV, leading the World Health Organization and the Nigeria Centre for Disease Control to declare it an outbreak 35 . Previous genome sequencing of LASV has revealed its extensive genetic diversity, with distinct lineages circulating in different parts of the endemic region 3, 36 , and ongoing sequencing can enable rapid identification of changes in this genetic landscape.\n\nWe selected 23 samples, spanning 5 states in Nigeria, that yielded either no portion of a LASV genome or only partial genomes with unbiased metagenomic sequencing even at a reasonably high sequencing depth (>4.5 million reads) 35 , and performed capture on these using V ALL . At equivalent pre-and post-capture sequencing depth (200,000 reads), use of V ALL improved our ability to detect and assemble LASV. Capture considerably increased the amount of unique LASV material detected in all 23 samples (in 4 samples, by more than 100 \u2715), and in 7 samples it enabled detection when there were no LASV reads pre-capture ( Supplementary Fig. 10a , Supplementary Table 7) . This in turn improved genome assembly. Whereas pre-capture we could not assemble any portion of a genome in 22 samples (in the remaining one, 2% of a genome) at this depth, following use of V ALL we could assemble a partial genome in 22 of the 23 (Fig. 4a, Supplementary Fig. 10b ); most were small portions of a genome, although in 7 we assembled >50% of a genome. Assembly results with V ALL are comparable without downsampling ( Supplementary Fig. 10c ), likely because we saturate unique content with V ALL even at low sequencing depths ( Supplementary Fig. 7b , c). These results illustrate how V ALL can be used to improve viral detection and genome assembly in an outbreak, especially at the low sequencing depths that may be desired or required in these settings.\n\nWe next applied our V ALL probe set to pools of human plasma and mosquito samples with uncharacterized infections. We tested 5 pools of human plasma from a total of 25 individuals with suspected LASV or EBOV infections from Sierra Leone, as well as 5 pools of human plasma from a total of 25 individuals with acute fevers of unknown cause from Nigeria and 5 pools of Culex tarsalis and Culex pipiens mosquitoes from the United States (see Online Methods for details). Using V ALL we detected 8 viral species, each present in one or more pools: 2 species in the pools from Sierra Leone, 2 species in the pools from Nigeria, and 4 species in the mosquito pools ( Fig. 4b, Supplementary Fig. 6c ). We found consistent results with V WAFR for the species that were included in its design ( Supplementary Fig. 6d , Supplementary Table 4 ). To confirm the presence of these viruses we assembled their genomes and evaluated read depth ( Supplementary Fig. 11 , Supplementary Table 8 ). We also sequenced pre-capture samples and saw significant enrichment by capture (Fig. 4c , Supplementary Fig. 6c, d) . Quantifying abundance and enrichment together provides a valuable way to discriminate viral species from other taxa (Fig. 4c) , thereby helping to uncover which pathogens are present in samples with unknown infections.\n\nLooking more closely at the identified viral species, all pools from Sierra Leone contained LASV or EBOV, as expected (Fig. 4b) . The 5 plasma pools from Nigeria showed little evidence for pathogenic viral infections; however, one pool did contain Hepatitis B virus. Additionally, 3 pools contained GBV-C, consistent with expected frequencies for this region 20, 37 . In mosquitoes, 4 pools contained West Nile virus (WNV), a common mosquitoborne infection, consistent with PCR testing. In addition, 3 pools contained Culex flavivirus, which has been shown to co-circulate with WNV and co-infect Culex mosquitoes in the United States 38 . These findings demonstrate the utility of capture to improve virus identification without a priori knowledge of sample content.\n\nCATCH condenses highly diverse target sequence data into a small number of oligonucleotides, enabling more efficient and sensitive sequencing that is only biased by the extent of known diversity. We show that capture with probe sets designed by CATCH improve viral genome detection and recovery while accurately preserving sample complexity. These probe sets have also helped us to assemble genomes of low titer viruses in other patient samples: V ZC for suspected ZIKV cases 6 and V ALL for improving rapid detection of Powassan virus in a clinical case 39 .\n\nThe probe sets we have designed with CATCH, and more broadly capture with comprehensive probe designs, improve the accessibility of metagenomic sequencing in resource-limited settings through smaller capacity platforms. For example, in West Africa we are using the V ALL probe set to characterize LASV and other viruses in patients with undiagnosed fevers by sequencing on a MiSeq (Illumina). This could also be applied on other small machines such as the iSeq (Illumina) or MinION (Oxford Nanopore) 40 . Further, the increase in viral content enables more samples to be pooled and sequenced on a single run, increasing sample throughput and decreasing per-sample cost relative to unbiased sequencing (Supplementary Table 9 ). Lastly, researchers can use CATCH to quickly design focused probe sets, providing flexibility when it is not necessary to target an exhaustive list of viruses, such as in outbreak response or for targeting pathogens associated with specific clinical syndromes.\n\nDespite the potential of capture, there are challenges and practical considerations that are present with the use of any probe set. Notably, as capture requires additional cycles of amplification, computational analyses should account for duplicate reads due to amplification; the inclusion of unique molecular identifiers 41,42 could improve determination of unique fragments. Also, quantifying the sensitivity and specificity of capture with comprehensive probe sets is challenging --as it is for metagenomic sequencing more broadly --due to the need to obtain viral genomes for the hundreds of targeted species and the risk of false positives from components of sequencing and classification that are unrelated to capture (e.g., contamination in sample processing or read misclassifications). Targeted amplicon approaches may be faster and more sensitive 7 for sequencing ultra low titer samples, but the suitability of these approaches is limited by genome size, sequence heterogeneity, and the need for prior knowledge of the target species 1, 43, 44 . Similarly, for molecular diagnostics of particular pathogens, many commonly used assays such as qRT-PCR and rapid antigen tests are likely to be faster and less expensive than metagenomic sequencing. Capture does increase the preparation cost and time per-sample compared to unbiased metagenomic sequencing, but this is offset by reduced sequencing costs through increased sample pooling and/or lower-depth sequencing 1 (Supplementary Table 9 ).\n\nCATCH is a versatile approach that could also be used to design oligonucleotide sequences for capturing non-viral microbial genomes or for uses other than whole genome enrichment. Capture-based approaches have successfully been used to enrich whole genomes of eukaryotic parasites such as Plasmodium 45 and Babesia 46 , as well as bacteria 47 . Because designs from CATCH scale well with our growing knowledge of genomic diversity 20,21 , it is particularly well-suited for designing probes to target any microbes that have a high degree of diversity. This includes many bacteria, which, like viruses, have high variation even within species 48 . Beyond microbes, CATCH could benefit studies in other areas that use capture-based approaches, such as the detection of previously characterized fetal and tumor DNA from cell-free material 49, 50 , in which known targets of interest may represent a small fraction of all material and for which it may be useful to rapidly design new probe sets for enrichment as novel targets are discovered. Moreover, CATCH can identify conserved regions or regions suitable for differential identification, which can help in the design of PCR primers and CRISPR-Cas13 crRNA guides for nucleic acid diagnostics.\n\nCATCH is, to our knowledge, the first approach to systematically design probe sets for whole genome capture of highly diverse target sequences that span many species, making it a valuable extension to the existing toolkit for effective viral detection and surveillance with enrichment and other targeted approaches. We anticipate that CATCH, together with these approaches, will help provide a more complete understanding of microbial genetic diversity.\n\nProbe design using CATCH Designing a probe set given a single choice of parameters-We first describe how CATCH determines a probe set that covers input sequences under some selection of parameters. That is, the input is a collection of (unaligned) sequences d and parameters \u03b8 d describing hybridization, and the goal is to compute a set of probes s(d, \u03b8 d ). For example, d commonly encompasses the strain diversity of one or more species and \u03b8 d includes the number of mismatches that we ought to tolerate when determining whether a probe hybridizes to a sequence.\n\nCATCH produces a set of \"candidate\" probes from the input sequences in d by stepping along them according to a specified stride (Fig. 1a) . Optionally, CATCH uses localitysensitive hashing 27, 28 (LSH) to reduce the number of candidate probes, which is particularly useful when the input is a large number of highly similar sequences. CATCH supports two LSH families: one under Hamming distance 27 and another using the MinHash technique 28, 51 , which has been used in metagenomic applications 52, 53 . It detects nearduplicate candidate probes by performing approximate near neighbor search 28 using a specified family and distance threshold. CATCH constructs hash tables containing the candidate probes and then queries each (in descending order of multiplicity) to find and collapse near-duplicates. Because LSH reduces the space of candidate probes, it may remove candidate probes that would otherwise be selected in steps described below, thereby increasing the size of the output probe set. Use of LSH to reduce the number of candidate probes is optional in our implementation of CATCH; we did not use it to produce the probe sets in this work. The approach of detecting near-duplicates among probes (and subsequently mapping them onto sequences, described below) bears some similarity to the use of P-clouds for clustering related oligonucleotides in order to identify diverse repetitive regions in the human genome 54, 55 .\n\nCATCH then maps each candidate probe p back to the target sequences with a seed-andextend-like approach, in the process deciding whether p maps to a range r in a target sequence according to a function f map (p, r, \u03b8 d ). f map effectively specifies whether p will capture the subsequence at r. Further, CATCH assumes that because p captures an entire fragment and not just the subsequence to which it binds, p \"covers\" both r and some number of bases (given in \u03b8 d ) on each side of r; we term this a \"cover extension\". This yields a collection of bases in the target sequences that are covered by each p, namely: p, s, bases in s covered by p for all s in d for all candidate probes p .\n\nNext, CATCH seeks to find the smallest set of candidate probes that achieves full coverage of all sequences in d. The problem is NP-hard. To determine s(d, \u03b8 d ), an approximation of the smallest such set of candidates probes, CATCH treats the problem as an instance of the set cover problem. Similar approaches have been used in related problems in uncovering patterns in DNA sequence. Notably, these include PCR primer selection [56] [57] [58] , string barcoding of pathogens 59, 60 , and other applications in microbial microarrays [61] [62] [63] , although these are not aimed at whole genome enrichment for sequencing many taxa.\n\nCATCH computes s(d, \u03b8 d ) using the canonical greedy solution to the set cover problem 25, 26 , which likely provides close to the best achievable approximation 64 . In this approximationpreserving reduction, each candidate probe p is treated as a set whose elements represent the bases in the target sequences covered by p. The universe of elements is then all the bases across all the target sequences --i.e., what it seeks to cover. To implement the algorithm efficiently, CATCH operates on sets of intervals rather than base positions and applies other techniques to improve performance for this problem.\n\nExtensions to probe design-This framework for designing probes offers considerable flexibility. Supplementary Note 1 describes the default f map in CATCH and how it can be customized; how CATCH allows for differential identification, blacklisting sequence, and partial coverage of target sequence; and how CATCH adds adapters to probes for PCR amplification.\n\nDesigning across many taxa-Consider a large set of input sequences that encompass a diverse set of taxa (e.g., hundreds of viral species). We could run CATCH, as described above, on a single choice of parameters \u03b8 d such that the number of probes in s(d, \u03b8 d ) is feasible for synthesis. However, this can lead to a poor representation of taxa in the diverse probe set; it can become dominated by probes covering taxa that have more genetic diversity (e.g., HIV-1). Furthermore, it can force probes to be designed with relaxed assumptions about hybridization across all taxa. To alleviate these issues, we allow different choices of parameters governing hybridization for different subsets of input sequences, so that some can have probes designed with more relaxed assumptions than others.\n\nWe represent a set of taxa and its target sequences with a dataset d, with its own parameters \u03b8 d . Let {\u03b8 d } be the collection of \u03b8 d across all d. We wish to find S({\u03b8 d }), the union of s(d, \u03b8 d ) across all datasets d. CATCH finds this by solving a constrained nonlinear optimization problem:\n\nThe constraint N on the number of probes in the union is specified by the user; this is the number of probes to synthesize, and might be determined based on synthesis cost and/or array size. CATCH solves this using the barrier method with a logarithmic barrier function. By default, we use the following loss function for each d:\n\nwhere m d gives a number of mismatches to tolerate in hybridization and e d gives a cover extension, as defined above. w d allows a relative weighting of datasets, e.g., if one should have more stringent assumptions about hybridization and thus more probes. \u03b2 1 , \u03b2 2 , and the set of {w d }s can be specified by the user. A user can also choose to generalize the search to a different set of parameters:\n\nwhere \u03b8 di is the value of the ith parameter for d and \u03b2 i is a specified coefficient for that parameter.\n\nIn practice, we have used the default loss function above, with w d =1 for all d, \u03b2 1 =1, and too small a range to satisfy the constraint. That is, one or more of the parameter values may need to be relaxed (across one or more datasets) to obtain \u2264 N probes. When this happens, our implementation of CATCH raises an error and suggests that the user provide less stringent choices of parameter values.\n\nInput sequences for design of probe sets-We designed four probe sets using publicly available sequences. Design additions for synthesis and probe set data-For synthesis of probes in V ALL , the manufacturer (Roche) trimmed bases from the 3' end of probe sequences to fit within synthesis cycle limits. Probe lengths did not change considerably after trimming: of the 349,998 probes in V ALL , which were designed to be 75 nt, 61% remained 75 nt after trimming and 99% were at least 65 nt after trimming. We did not add PCR adapters for amplification to probe sequences in V ALL . We did add adapters to probe sequences in V WAFR , V ZC , and V MM (designed to be 100 nt and synthesized with CustomArray); we used two sets of adapters (20 bases on each end), selected by CATCH for each probe to minimize probe overlap as described in Supplementary Note 1. Furthermore, in these three probe sets we included the reverse complement of each designed 140 nt oligonucleotide in the synthesis.\n\nevaluations of how probe counts grow with respect to an independent variable ( Supplementary Fig. 1c, Fig. 1b , and Supplementary Fig. 2 ), Supplementary Note 2 describes input data and how we used CATCH.\n\nHuman patient samples used in this study (Supplementary \n\nWe first removed contaminating DNA by treatment with TURBO DNase (Ambion) and prepared double-stranded cDNA by priming with random hexamers followed by synthesis of the second strand as previously described 12 . We used the Nextera XT kit (Illumina) to prepare sequencing libraries with modifications to enable hybrid capture 8 . Specifically, we used non-biotinylated i5 indexing primers (Integrated DNA Technologies) in place of the manufacturer's standard i5 PCR primers. As cDNA concentrations from clinical samples are typically lower than the recommended 1 ng, input to Nextera XT was 5 \u03bcL of cDNA, except in the case of Ebola serial dilutions where input was 1 ng. Samples underwent 16-18 cycles of PCR and final libraries were quantified using either the 2100 Bioanalyzer dsDNA High Sensitivity assay (Agilent) or by qPCR using the KAPA Universal Complete Kit (Roche). We also prepared sequencing libraries from water with each batch as a negative control.\n\nWe synthesized the 349,998 probes in V ALL using the SeqCap EZ Developer platform (Roche). Since the number of features on the array was 2.1 million, we repeated the design 6 times (6 \u2715 final probe density). We used these biotinylated single-stranded DNA probes directly for hybrid capture experiments. We performed in solution hybridization and capture according to manufacturer instructions (SeqCapEZ v5.1) with modifications to make the protocol compatible with Nextera XT libraries. . The concentration of Nextera XT adapter blockers was reduced to 200\u03bcM to account for sample input <1 \u03bcg. The concentration of probes was also reduced to account for the replication of our V ALL probe set 6 \u2715 across the 2.1 million features. We incubated the hybridization reaction overnight (~16hrs). After hybridization and capture on streptavidin beads, we amplified library pools using PCR (14-16 cycles) with universal Illumina PCR primers (P7 primer: 5'-CAAGCAGAAGACGGCATACGA-3'; P5 primer: 5'-AATGATACGGCGACCACCGA-3'; Integrated DNA Technologies).\n\nWe prepared the focused probe sets (V WAFR , V MM , V ZC ) using a traditional probe production approach 67 in which DNA oligos were synthesized on a 12k or 90k array (CustomArray). To minimize PCR amplification bias and formation of concatemers by overlap extension we performed two separate emulsion PCR reactions (Micellula, Chimerx) to amplify the non-overlapping probe subsets (assigned adapters A and B as described in Supplementary Note 1). One primer in each reaction carried a T7 promoter tail (GGATTCTAATACGACTCACTATAGGG) at the 5' end. We performed in vitro transcription (MEGAshortscript, Ambion) on each of these pools to produce biotinylated capture-ready RNA probes. Pools were aliquoted and stored at \u221280C and combined at equal concentration and volume immediately prior to use. Hybrid capture was a modification of a published protocol 67 . Briefly, we mixed the probes, salmon sperm DNA and human Cot-1 DNA, adapter blocking oligonucleotides and libraries and hybridized overnight (~16 hrs), captured on streptavidin beads, washed, and re-amplified by PCR (16-18 cycles) . PCR primers and index blockers were the same as those used in the protocol for the V ALL probe set. In some cases, we changed the Nextera XT indexes during final PCR amplification to enable sequencing of pre-and post-capture samples on the same run.\n\nWe pooled and sequenced all captured libraries on Illumina MiSeq or HiSeq 2500 platforms. Pre-capture libraries for all samples were also sequenced to allow for comparison of enrichment by capture.\n\nWe performed demultiplexing and data analysis of all sequencing runs using viral-ngs v1.17.0 68,69 with default settings, except where described below. To enable comparisons between pre-and post-capture results, we downsampled all raw reads to 200,000 reads using SAMtools 70 . We performed all analyses on downsampled data sets unless otherwise stated. We chose this number as 90% of all samples sequenced on the MiSeq (among the 30 patient and environmental samples used for validation) were sequenced to a depth of at least 200,000 reads. For those few low coverage samples for which we did not obtain >200,000 reads, we performed all analyses using all available reads unless otherwise noted (Supplementary Table 3 ). Downsampling normalizes sequencing depth across runs and allows us to more readily evaluate the effectiveness of capture on genome assembly (i.e., the fraction of the genome we can assemble) than an approach such as comparing viral reads per million. It also allows us to more readily compare unique content (see below). A statistic like unique viral reads per unique million reads can be distorted based on sequencing depth in the presence of a high fraction of viral PCR duplicate reads: sequencing to a lower depth can inflate the value of this statistic compared to sequencing to a higher depth.\n\nWe used viral-ngs to assemble genomes of all viruses previously detected in these samples or identified by metagenomic analyses, including the LASV genomes from the 2018 Lassa fever outbreak in Nigeria and the EBOV genomes from the dilution series. For each virus we taxonomically filtered reads against many available sequences for that virus (Supplementary  Table 10 ). We used one representative genome to scaffold the de novo assembled contigs (Supplementary Table 3, Supplementary Table 5, Supplementary Table 7) . We set the parameters 'assembly_min_length_fraction_of_reference' and 'assembly_min_unambig' to 0.01 for all assemblies. We took the fraction of the genome assembled to be the number of base calls we could make in the assembly divided by the length of the reference genome used for scaffolding. To calculate per-base read depth, we aligned depleted reads from viralngs to the same reference genome that we used for scaffolding. We did this alignment with BWA 71 through the 'align_and_plot_coverage' function of viral-ngs with the following parameters: '-m 50000 --excludeDuplicates --aligner_options \"-k 12 -B 2 -O 3\" --minScoreToFilter 60'. We counted the number of aligned reads (unique viral reads) using SAMtools 70 with 'samtools view -F 1024', and calculated enrichment of unique viral content by comparing number of aligned reads before and after capture. viral-ngs removes PCR duplicate reads with Picard based on alignments, allowing us to measure unique content. We excluded samples where one or more conditions had less than 100,000 raw reads for reasons of comparability. Excluded samples are highlighted in red in Supplementary Table 3 .\n\nTo assess how the amount of viral content detected increases with sequencing depth (Supplementary Fig. 7b, c) , we used data from the Ebola dilution series on 10 3 and 10 4 copies. At these input amounts, both technical replicates, with and without capture and in both 30 ng and 300 ng of background, yielded at least 2 million sequencing reads. For each combination of input copies, background amount, technical replicate, and whether capture was used, we downsampled all raw reads to n={1, 10, 100, 1000, 10000, 100000, 200000, 300000, \u2026, 1900000, 2000000} reads. For each n, we performed this downsampling 5 times. We depleted reads with viral-ngs, aligned depleted reads to the EBOV reference genome (Supplementary Table 5) , and counted the number aligned, as described above. We plotted the number of aligned reads for each subsampling amount in Supplementary Fig. 7b and c, where shaded regions are 95% pointwise confidence bands calculated across the 5 downsampling replicates.\n\nTo analyze the relation between probe-target identity and enrichment (Fig. 3b) , we used an influenza A virus sample of avian subtype H4N4 (IAV-SM5). We assembled a genome of this sample both pre-capture and following capture with V ALL to verify concordance; we used the V ALL sequence for further analysis here because it was more complete. We aligned depleted reads to this genome as described above (with BWA using the 'align_and_plot_coverage' function of viral-ngs and the following parameters: '-m 50000 --excludeDuplicates --aligner_options \"-k 12 -B 2 -O 3\" --minScoreToFilter 60'). For a window in the genome, we calculated the fold-change in depth to be the fold-change of the mean depth post-capture against the mean depth pre-capture within the window. Here, we used windows of length 150 nt, sliding with a stride of 25 nt. We aligned all probe sequences in V ALL and V WAFR designs to this genome using BWA-MEM 71 with the following options: '-a -M -k 8 -A 1 -B 1 -O 2 -E 1 -L 2 -T 20'; these sensitive parameters should account for most possible hybridizations, and include a low soft-clipping penalty to allow us to model a portion of a probe hybridizing to a target while the remainder hangs off. We counted the number of bases that match between a probe and target sequence using each alignment's MD tag (this does not count soft-clipped ends), and defined the identity between a probe and target sequence to be this number of matching bases divided by the probe length. We defined the identity between probes and a window of the target genome as follows: we considered all mapped probe sequences that have at least half their alignment within the window, and took the mean of the top 25% of identity values between these probes and the target sequence. In Fig. 3b , we plot a point for each window. We did this separately with probes from the V ALL and V WAFR designs.\n\nFor our comparison of within-sample variant frequencies with and without capture (Fig. 3d , Supplementary Table 6 ), we used 3 dengue virus samples (DENV-SM1, DENV-SM2, and DENV-SM5). We selected these because of their relatively high depth of coverage, in both pre-and post-capture genomes (Supplementary Table 3 ); the high depth in pre-capture genomes was necessary for the comparison. We did not subsample reads prior to this comparison, in order to maximize coverage for detection of rare variants. For each of the three samples, we pooled data from three sequencing replicates of the same pre-capture library prior to downstream analysis. For each of these samples we performed two capture replicates on the same pre-captured library (two replicates with V WAFR and two with V ALL ), and sequenced, estimated, and plotted frequencies separately on these replicates.\n\nAfter assembling genomes, we used V-Phaser 2.0, available through viral-ngs 68, 69 , to call within-sample variants from mapped reads. We set the minimum number of reads required on each strand ('vphaser_min_reads_each') to 2 and ignored indels. When counting reads with each allele and estimating variant frequencies, we excluded PCR duplicate reads through viral-ngs. In Fig. 3d , we show frequencies for a variant if it is present at \u22651% frequency in any of the replicates (i.e., either the pre-capture pool or any of the replicates from capture with V WAFR or V ALL ). The plot shows positions combined across the three samples that we analyzed.\n\nWe estimated the concordance correlation coefficient (\u03c1 C ) between pre-and post-capture frequencies over points in which each is a pair of pre-and post-capture frequencies of a variant in a replicate. Because we had pooled pre-capture data, each pre-capture frequency for a variant is paired with multiple post-capture frequencies for that variant.\n\nWe used kraken v0. 10 For mock co-infection samples we ran kraken on all sequenced reads. To confirm that enrichment was successful, we calculated the proportion of all reads that were classified as of viral origin. To compare the relative frequencies of each virus pre-and post-capture with V ALL and V WAFR , we calculated the proportion of all viral reads that were classified as each of the 8 viral species. For this we used the cumulative number of reads assigned to each species-level taxon and its child clades, which we term \"cumulative species counts\".\n\nFor each biological sample, we first subsampled raw reads to 200,000 reads using SAMtools 70 (except for samples with <200,000 reads, for which we used all available reads). Then, we removed highly similar (likely PCR duplicate) reads from the unaligned reads with the mvicuna tool through viral-ngs. We ran kraken through viral-ngs and separately ran kraken-filter with a threshold of 0.1 for classification. For samples where two independent libraries had been prepared and used for V ALL and V WAFR , or where the same pre-capture library had been sequenced more than once, we merged the raw sequence files prior to downsampling. To account for laboratory contaminants we also ran kraken on water controls; we first merged all water controls together, and classified reads as described above. We evaluated the presence and enrichment of viral and other taxa using the cumulative species-level counts, as above. To do so we calculated two measures: abundance, which was calculated by dividing pre-capture read counts for each species by counts in pooled water controls, and enrichment, which was calculated by dividing post-capture read counts for each species by pre-capture read counts in the same sample. For our uncharacterized mosquito pools and human plasma samples from Nigeria and Sierra Leone, after capture with V ALL we searched for viral species with more than 10 matched reads and a read count greater than 2-fold higher than in the pooled water control after capture with V ALL . For each virus identified we assembled viral genomes and calculated per-base read depth as described above ( Supplementary Fig. 11 , Supplementary Table 8 ). When producing coverage plots, we calculated per-base read depth as described above for known samples, except we removed supplementary alignments before calculating depth to remove artificial chimeras.\n\nA Life Sciences Reporting Summary is available.\n\nSequences used as input for probe design are available in the repository at https:// github.com/broadinstitute/catch (see Supplementary Table 1 \n\nThe latest version of CATCH and its full source code is available at https://github.com/ broadinstitute/catch under the terms of the MIT license. For designing the V ALL probe set, we used CATCH v0.5.0 (available in the repository on GitHub). (a) Sketch of CATCH's approach to probe design, shown with three datasets (typically, each is a taxon). For each dataset d, CATCH generates candidate probes by tiling across input genomes and, optionally, reduces the number of them using locality-sensitive hashing. Then, it determines a profile of where each candidate probe will hybridize (the genomes and regions within them) under a model with parameters \u03b8 d (see Supplementary Fig. 1b for details). Using these coverage profiles, it approximates the smallest collection of probes that fully captures all input genomes (described in text as s(d, \u03b8 d )). Given a constraint on the total number of probes (N) and a loss function over \u03b8 d , it searches for optimal \u03b8 d for all d.\n\n(b) Number of probes required to fully capture increasing numbers of HCV genomes. Approaches shown are simple tiling (gray), a clustering-based approach at two levels of stringency (red), and CATCH with three choices of parameter values specifying varying levels of stringency (blue). See Supplementary Note 2 for details regarding parameter choices. Previous approaches for targeting viral diversity use clustering in probe set design. Shaded regions around each line are 95% pointwise confidence bands calculated across randomly sampled input genomes. (c) Number of probes designed by CATCH for each dataset (of 296 datasets in total) among all 349,998 probes in the V ALL probe set. Species incorporated in our sample testing are labeled. (d) Values of the two parameters selected by CATCH for each dataset in the design of V ALL : number of mismatches to tolerate in hybridization and length of the target fragment (in nt) on each side of the hybridized region assumed to be captured along with the hybridized region (cover extension). The label and size of each bubble indicate the number of datasets that were assigned a particular combination of values. Species included in our sample testing are labeled in black, and outlier species not included in our testing are in gray. In general, more diverse viruses (e.g., HCV and HIV-1) are assigned more relaxed parameter values (here, high values) than less diverse viruses, but still require a relatively large number of probes in the design to cover known diversity (see (c)). Panels similar to (c) and (d) for the design of V WAFR are in Supplementary Fig. 3 . (a) Distribution of the enrichment in read depth, across viral genomes, provided by capture with V ALL on 30 patient and environmental samples with known viral infections. Each curve represents one of the 31 viral genomes sequenced here (one sample contained two known viruses). At each position across a genome, the post-capture read depth is divided by the precapture depth, and the plotted curve is the empirical cumulative distribution of the log of these fold-change values. A curve that rises fully to the right of the black vertical line illustrates enrichment throughout the entirety of a genome; the more vertical a curve, the more uniform the enrichment. Read depth across viral genomes DENV-SM3 (purple) and DENV-SM5 (green) are shown in more detail in (b). (b) Read depth throughout a genome of DENV in two samples. DENV-SM3 (left) has few informative reads before capture and does not produce a genome assembly, but does following capture. DENV-SM5 (right) does yield a genome assembly before capture, and depth increases following capture. (c) Percent of each viral genome unambiguously assembled in the 30 samples, which had 8 known viral infections across them. Shown before capture (orange), after capture with V WAFR (light blue), and after capture with V ALL (dark blue). Red bars below samples indicate ones in which we could not assemble any contig before capture but, following capture, were able to assemble at least a partial genome (>50%). (d) Left: Number of reads detected for each species across the 30 samples with known viral infections, before and after capture with V ALL . Reads in each sample were downsampled to 200,000 reads. Each point represents one species detected in one sample. For each sample, the virus previously detected in the sample by another assay is colored. Homo sapiens matches in samples from humans are shown in black. Right: Abundance of each detected species before capture and fold-change upon capture with V ALL for these samples. Abundance was calculated by dividing pre-capture read counts for each species by counts in pooled water controls. Coloring of human and viral species are as in the left panel. Relation between probe-target identity and enrichment in read depth, as seen after capture with V ALL and with V WAFR on an influenza A virus sample of subtype H4N4 (IAV-SM5). Each point represents a window in the IAV genome. Identity between the probe and assembled H4N4 sequence is a measure of identity between the sequence in that window and the top 25% of probe sequences that map to it (see Online Methods for details). Fold-change in depth is averaged over the window. No sequences of segment 6 (N) of the N4 subtypes were included in the design of V ALL or V WAFR . (c) Effect of capture on estimated frequency of within-sample co-infections. RNA of 2, 4, 6, and 8 viral species were spiked into extracted RNA from healthy human plasma and then captured with V ALL and V WAFR . Values on top are the percent of all sequenced reads that are viral. We did not detect Nipah virus (NiV) using the V WAFR probe set because this virus was not present in that design. (d) Effect of capture on estimated frequency of within-host variants, shown in positions across three dengue virus samples: DENV-SM1, DENV-SM2, and DENV-SM5. Capture with V ALL and V WAFR was each performed on n=2\n\nreplicates of the same library. \u03c1 C indicates concordance correlation coefficient between preand post-capture frequencies."}