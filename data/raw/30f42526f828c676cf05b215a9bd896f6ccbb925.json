{"title": "Prediction of respiratory disease and diarrhea in veal calves based on immunoglobulin levels and the serostatus for respiratory pathogens measured at arrival", "body": "In recent years, high levels of antimicrobial (multi)resistance have been detected in pathogenic, commensal indicator and zoonotic bacteria in both the European and North American veal sector (Catry et al., 2005; Di Labio et al., 2007; Cook et al., 2011; MARAN, 2012) . The emergence of livestock associated methicillin resistant Staphylococcus aureus and extended beta-lactamases (ESBL's) in enterobacteriaceae from food animals has initiated a public discussion in Western Europe, which severely increased pressure on veterinary antimicrobial use (Graveland et al., 2010; Vandendriessche et al., 2013) . Antimicrobial resistance selection is predominantly driven by antimicrobial use (Bosman et al., 2013) . Therefore, the intensive antimicrobial use in the veal sector http://dx.doi.org/10. 1016/j.prevetmed.2015.04 .009 0167-5877/\u00a9 2015 Elsevier B.V. All rights reserved. urgently needs to be reduced, both for public health and political and economic reasons (MARAN, 2009 (MARAN, , 2011 Pardon et al., 2012a) .\n\nSelection of calves based on disease risk and subsequently targetting metaphylactic antimicrobial treatment toward the high risk batches, is one potential strategy to rationally reduce antimicrobial consumption. Calf selection parameters include age at arrival, body weight, infection status for bovine viral diarrhea virus (BVDV), presence of disease (umbilical infection, bovine respiratory disease (BRD) or neonatal calf diarrhea (NCD)) (Wilson et al., 2000) and sufficient uptake of colostrum (Gulliksen et al., 2009; Brscic et al., 2012; Pardon et al., 2013) . Failure of passive transfer (FPT) shows a prevalence ranging between 20 and 80% in the United States (McDonough et al., 1994; Wilson et al., 2000; Stilwell and Carvalho, 2011) . Also in Belgium on average 40% of veal calves had FPT, assuming that immunoglobulin G (IgG) levels lower than 10 g/L upon arrival indicate colostral deficiency (Pardon, 2012) . The crucial role of sufficient IgG uptake in protecting calves from BRD, NCD and mortality has been evidenced on multiple occasions (Postema and Mol, 1984; Furman-Fratczak et al., 2011; Stilwell and Carvalho, 2011 ). These effects have been shown to last up to 3 months for BRD (Virtala et al., 1996) . To evaluate colostrum uptake, several tests have been validated for healthy animals in the age category of 2-7 days (Weaver et al., 2000) . Although that cheap indirect screening tests, such as determination of total protein (TP) with a refractometer, perform reasonably well, direct determination of immunoglobulins (Ig) or IgG is generally more specific (Weaver et al., 2000) . In calves sampled within a week after birth a cut off value for IgG of 10 g/L is generally accepted to determine FPT, and has been linked with disease occurrence, although some studies reported higher cut-offs in particular situations (Waldner and Rosengren, 2009; Furman-Fratczak et al., 2011; Stilwell and Carvalho, 2011) . In contrast, it is currently unknown whether Ig levels measured at the age of arrival in veal calves (2-4 weeks old) can be used as predictors of BRD or NCD. For the veal sector it would be interesting to identify, through testing of calves upon arrival, individual calves requiring an adapted treatment and herds of origin with an insufficient colostrum management.\n\nTherefore, the first objective of the present study was to determine whether Ig's or any other protein determined by routine electrophoresis measured at arrival, are associated with occurrence of BRD or NCD in veal calves in the first weeks after arrival, and are therefore potentially useful for risk classification of calves at arrival. The hypothesis was that calves with low TP or Ig would have a substantial higher risk acquiring BRD or NCD.\n\nTo gain further insight in which antibodies might play a protective role for BRD, the second objective was to determine the association between the serostatus for 7 respiratory pathogens, measured at arrival, and BRD occurrence.\n\nSince earlier studies demonstrated a direct effect of FPT on average daily gain (ADG) in the first 3 months of life (Robison et al., 1988; Virtala et al., 1996) , the third objective was to determine which of the studied serum parameters (electrophoresis protein fractions and respiratory antibodies) and diseases were associated with ADG in the study period.\n\nThe study design was a prospective longitudinal cohort study. The study protocol was reviewed and approved by the ethical committee of the Faculty of veterinary medicine (Ghent University) under license EC 2013/184.\n\nThe study was carried out in a typical ros\u00e9 starter veal farm located in the South of the Netherlands, in January 2014. This type of operation is specialized in raising calves for 8 weeks, after which they are transported to a finisher herd. The sole criterion for farm selection was willingness to cooperate. Study calves were housed on slatted floors in the same air-space. During the first 6 weeks calves were housed individually in metal framed pens, with 1.4 m 2 floor surface and an air volume of 9.0 m 3 per calf. After this period the metal framework was removed and the animals were kept in groups of 6 animals for the remaining of the raising period. The study compartment was physically isolated from the other calf units present at the farm by full walls and a separate ventilation system. The stable was mechanically ventilated at a 20% refreshing rate and temperature was maintained at 17 \u2022 C. Calves were fed a 21.2% crude protein (CP), 17.7% crude fat (CF) milk replacer (MR) diet at dry mater base. The amount of MR was gradually increased from 1.5 L (90 g powder/L) morning and evening at day 1 to twice daily 3 L at 110 g/L at the end of the study (day 18). Milk was individually provided in drinking buckets. In addition to MR calves received chopped straw (from 20 to 50 g/day over the 18 day study period) and starter concentrates (from 10 to 350 g/day; CP = 16%; CF = 2.8%). The study group was not vaccinated and did not receive any antimicrobial group treatment at arrival.\n\nSample size was calculated to detect a 25% difference in BRD incidence between calves with more or less than 10 g Ig/L (25% vs. 50%), with 95% confidence and 80% power (Winepiscope 2.0., Thrusfield et al., 2001) . For a two-tailed test 56 animals within each group were needed. For practical reasons and to account for mortality, the study group consisted of all animals present in the same airspace, being 150 animals.\n\nFor ethical and economic reasons it was agreed beforehand that the study would finish when the responsible veterinarian deemed it necessary to initiate a group treatment. Although no objective criteria were set, this usually is done when 10% of the animals is ill on the same day, which occurs with high predictability between week 2 and 3 (Pardon et al., 2011 (Pardon et al., , 2012a . In casu, the study period lasted from arrival to day 18.\n\nAt arrival, all calves were clinically examined. Health status was monitored twice daily (morning and evening) for the duration of the study by the same veterinarian. The case definition for NCD was presence of diarrhea (partial) anorexia and depression. For BRD the case definition was based on a scoring system using the following symptoms: depression, cough, rectal temperature and nasal discharge (Table 1) . Animals with a score of \u22655 were considered a case. Omphalitis was defined as the presence of a painful umbilical swelling at arrival.\n\nAnimals diagnosed with omphalitis were treated with 10,000 IU of benzylpenicillin (Procpen30 \u00ae , Dopharma, Raamsdonksveer, The Netherlands) IM daily, for 5 days. NCD was treated with sulphadoxin-trimethoprim (Dofatrim-ject, Dopharma, Raamdonksveer, the Netherlands) (16 mg/kg IM, sid, 5 days) and meloxicam (Novem, Boehringer Ingelheim Vetmedica GmbH, Ingelheim/Rhein, Germany) (0.5 mg/kg IM, sid, 1 day). In case there was no response to treatment, NCD cases were treated with 2 mg/kg gentamicin IM (Genta-ject \u00ae 10%, Dopharma, Raamsdonksveer, Nederland). BRD cases were treated with a single injection of tildipirosin (4 mg/kg subcutaneously) (Zuprevo 18%, Merck, USA) and meloxicam. The drug use during the study period was quantified by standard daily dose methodology as described previously (Pardon et al., 2012a) . The animal defined daily doses (ADD's) for each antimicrobial drug were as mentioned above (derived from the Belgian veterinary repertory (BCFI, 2013)). For combined products (e.g. sulphonamides with trimethoprim), each administration was counted as two doses. For long acting products, a long acting factor was used. For tildipirosin this was 9.25, as recommended by the manufacturer.\n\nAt arrival and at the end of the study period (day 23) all calves were weighed with an electronic balance (Rinstrum R323) at 0.2 kg precise. Blood was taken from the jugular vein with a 20 G needle vacutainer system (Venoject, Terumo, Belgium) at arrival and at the end of the study period. Blood was centrifuged (970 \u00d7 g for 10 min at approximately 20 \u2022 C) and stored at \u221218 \u2022 C until laboratory analyses.\n\n2.3.3. Laboratory analysis 2.3.3.1. Determination of the etiology of NCD. An antigen ELISA to detect Cyptosporidium parvum, bovine coronavirus (BCV), bovine rotavirus and enterotoxic Escherichia coli (Tetrastrips, BIO K 156, Bio-X, Jemelle, Belgium) was conducted in fresh fecal samples from NCD cases.\n\n2.3.3.2. Determination of circulating BRD pathogens and serostatus at arrival. To identify circulating BRD pathogens in the study period, an antibody ELISA for bovine respiratory syncytial virus (BRSV), parainfluenzavirus (PI-3), bovine herpesvirus 1 (BHV-1), BVDV, Mycoplasma bovis (ELISA Respiratory kit, Bio-K 284, Bio-X, Jemelle, Belgium), BCV (Bio-K 127, Bio-X, Jemelle, Belgium) and Mannheimia haemolytica (Bio-K 139, Bio-X, Jemelle, Belgium) was performed on paired samples to determine seroconversion. Samples of the same animal were tested on the same plate. Determination of seroconversion and serostatus at arrival (positive or negative) were according to the manufacturer's guidelines.\n\nTo determine the amount of albumin, alpha-1 globulins (A1g), alpha-2 globulins (A2g), beta-globulins (Bg) and gamma-globulins (immunoglobulins, Ig's) in the arrival serum samples, electrophoresis was conducted by solid phase extraction (Capillarys, Sebia, France) at an accredited laboratory (Zoolyx, Aalst, Belgium) using optimized settings for animal samples. TP was measured colorimetrically on an automated biochemistry analyzer (Cobas 6000, Roche, Belgium). Quality controls previously run were within quality assurance specifications.\n\nData were analyzed with SAS 9.4 (SAS Institute Inc., Cary, NC). The unit of analysis was the individual calf.\n\nThe working hypothesis was that both total protein and Ig are predictors for BRD and NCD in veal calves, whereas the other protein fractions determined by routine electrophoresis (albumin, Ag and Bg) are not. Survival analysis was used to assess the association between the 6 serum protein fractions (TP, albumin, A1g, A2g, Bg and Ig) and the time until BRD or NCD diagnosis. Two Cox proportional hazards models (PROC PHREG) were built, with respectively NCD and BRD as outcome variable using Breslow ties. In each model, 7 predictors, being the 6 protein fractions (TP, albumin, A1g, A2g, Bg and Ig) and body weight at arrival as a potential confounder were evaluated. Calves arrived in three batches and in order to correct for clustering, arrival batch was added as fixed effect. Predictors were tested univariably both continuously as categorically, based on quartiles. If a significant effect was noted in one of the quartiles, a binary variable was constructed. The time between arrival and occurrence of NCD or BRD was defined as survival time and disease (either BRD or NCD) as the event. Censoring occurred at day 18, when the study ended, for each animal remaining undiseased. The model building procedure was as follows. First all predictors were tested univariably, and those with P < 0.20 were selected for multivariable modeling. The final multivariable model was built stepwise backwards, excluding non-significant variables. Next, all biologically relevant two-way interactions of significant fixed effects were tested. Significance was set at P < 0.05 and P < 0.10 was considered a trend. Wald's test was used to assess parameter estimate significance. Visual inspection of the log-cumulative hazard plots and/or Schoenfeld residuals (Schoenfeld, 1982) and construction of timevarying covariates were used to evaluate the proportional hazard assumption.\n\nFor significant protein fractions, their relationship with the studied disease was visualized by means of Kaplan-Meier survival curves (PROC LIFETEST) and a Log-rank test was performed. In practice, a recommendation regarding the threshold to identify future problematic animals based on a significant parameter is desired. Therefore, for significant parameters of primary interest, such as Ig, a receiver operating characteristics (ROC) curve was created to determine the optimal Ig cut-off value for BRD or NCD. Subsequently, a categorical variable was created for these variables based upon this cut-off, replacing the original continuous variable.\n\nHypothesis was that animals, seronegative for a respiratory pathogen, would experience an increased BRD hazard in the study period. A Cox proportional hazard model was built with BRD as the event variable and time between arrival and occurrence of BRD as the survival time. All cases which did not experience BRD before day 18 were right censored. Predictors tested (n = 8) were the serostatus for BRSV, PI-3, BCV, BHV-1, BVDV, M. haemolytica and M. bovis and the body weight at arrival (potential confounder). Arrival batch was added as a fixed effect to adjust for clustering. The model building procedure, evaluation and visualization were as mentioned under Section 2.4.1.\n\nWorking hypothesis was that low TP and Ig were associated with reduced ADG. Similarly, a reduced ADG in seronegative animals for any of the 7 respiratory pathogens was expected. Normal distribution of ADG was checked by Q-Q plot and by the Kolmogorov-Smirnov test. A linear mixed model (PROC MIXED) with arrival batch as a random effect to account for clustering within a batch was used. The covariance structure was specified as variance components. The effect of 15 predictors was evaluated (6 serum protein fractions (TP, albumin, A1g, A2g, Bg and Ig), 7 serostatuses for respiratory pathogens (BRSV, PI-3, BVDV, BHV-1, BCV, BHV-1, M. haemolytica and M. bovis) and 2 diseases (NCD and BRD) . First all predictors were tested univariably for their association with ADG. Continuous predictors were added continuously and in quartiles.\n\nAll predictors with P < 0.2 were maintained for the multivariable model, which was built stepwise backward, excluding non-significant variables. Pearson and Spearman's rho correlations were calculated between significant predictors and when correlation was higher than 0.60, only the most significant variable was retained in the multivariable models. Relationships between significant categorical predictors were explored by univariable logistic regression (PROC LOGISTIC). In the final model, pairwise comparisons for categorical predictors were made, with Bonferroni adjustment for multiple comparisons. All biologically relevant two-way interactions of significant fixed effects were tested. Significance was set at P < 0.05 and P < 0.10 was considered a trend. Model fit and assumptions were evaluated by checking the normal distribution of the residuals.\n\nCalves arrived at the same day in three batches, of 27, 26 and 97 calves. The largest batch originated from Germany, the other two Table 2 Serostatus at arrival and seroconversion rate to 7 respiratory pathogens of ros\u00e9 veal calves in the first three weeks after arrival at the finishing unit.\n\nPercentage of seropositives at arrival ( from the Netherlands. All calves were male, mean arrival age was 17.4 days (standard deviation (SD) = 4.7; range (R) = 12-41 days) and mean arrival weight 50.7 kg (SD = 3.5; R = 39.6-69.4). At arrival 4, calves (2.7%) had omphalitis and one (0.7%) diarrhea. In Fig. 1 the number of new cases of NCD and BRD over the study period is presented. Diarrhea only occurred in the first 10 days, with a cumulative incidence (CI) of 15.3% (23/150). Daily BRD incidence remained below 5% in the first 17 days, but at day 18 CI had accumulated to 40% (60/150). At day 18 a BRD outbreak occurred involving 40% (60/150) of the calves and the study was stopped. At this day the animals received an oral group treatment with 12 mg/kg tilmicosin phosphate (Pulmotil AC, Elanco, Indianapolis, USA) which blurred any further disease detection. In total, 61% (92/150) of the calves developed BRD in the study period of which 30.4% (28/92) relapsed. The mean score of BRD cases was 5.7 (SD = 0.8; R = 5-8) and 87.5% had a rectal temperature over 39.5 \u2022 C at treatment. Regarding NCD cases, only C. parvum was detected in 30% of the fecal samples (n = 10). The most frequent respiratory pathogens circulating during the study period were M. bovis, BCV and BVDV (Table 2) . One calf died during the study and necropsy demonstrated enteritis, dehydration and low body condition. During the study period a calf received on average 6.2 ADD's, of which 3.9 ADD's for respiratory disease, 1.9 ADD's for NCD and 0.4 ADD's for umbilical infection. ADG in the study period was 0.242 kg/day (SD = 0.142; R = \u22120.139 to 0.670).\n\nIn the study population mean total Ig concentration was 10 g/L (SD = 4.2; R = 1-25) and 41.3% (62/150) of the calves had Ig levels below 10 g/L. In Table 3 mean values of the serum protein fractions in calves with or without NCD and BRD are displayed. ROC analysis for Ig demonstrated that the optimal cut-off (area under the curve = 0.60; sensitivity = 85%; specificity = 33%) to predict whether a calf would not develop BRD was 7.5 g/L. Subsequently, Ig was added to the model as a binary variable based on this cut off. Factors univariably associated (P < 0.20) with BRD hazard were body weight at arrival (P = 0.14) and Ig (>7.5/<7.5) (P < 0.05). In the final model only Ig remained significantly associated with the time until occurrence of BRD (Table 4 , Fig. 2) .\n\nFor NCD, a significant association with the level of alpha-2 globulin was present. For every increase in alpha-2 globulin by 1 g/L the NCD hazard increased by 17% (Table 5 ). The arrival batch effect was significant, with calves from the smallest batch from the Netherlands experiencing a significantly higher NCD risk compared to the other batches.\n\nThe antibody ELISA to determine the serostatus for the respiratory pathogens studied was not interpretable in 2 calves, leaving 148 calves for analysis. Table 6 shows the BRD incidence according to the serostatus for the 7 respiratory pathogens at arrival. Univariably associated predictors of the time until BRD occurrence, which were withheld for the multivariable model, were BRSV (P < 0.001), BCV (P < 0.01), PI-3 (P = 0.12) and M. bovis (P = 0.12). The serostatus for BCV and BRSV remained significant in the multivariable model (P < 0.05) ( \n\nDescriptives on ADG according to disease status are provided in Table 3 . Factors univariably associated with ADG were albumin (P = 0.15), A1g (P = 0.13), A2g (P < 0.05), BCV (P = 0.10), BHV-1 (P < 0.05), BRSV (P < 0.05) and PI-3 (P = 0.08). The final multivariable (Table 8) . Calves with Ig levels <7.5 g/L at arrival grew on average 72 g/day (95% CI = 29-129) less, and for every increase of alpha-2 globulin by 1 g/L, ADG decreased by 12 g/day (95% CI = 0-24).\n\nIn contrast to previous studies on disease occurrence in veal calves (Postema and Mol, 1984; Postema et al., 1987; Brscic et al., 2012; Pardon, 2012) , disease detection in the present study was not blurred by the routine administration of antimicrobials at arrival. Given the intensive daily monitoring it was no surprise to find a much higher BRD incidence (60% in the first three weeks) compared to previously reported figures in white veal calves over the complete production cycle (Brscic et al., 2012; Pardon et al., 2012b) . Also for NCD the cumulative incidence in the present study was three times higher than previously reported (Pardon et al., 2012b) . These observations confirm that disease incidence is masked in practice due to the administration of antimicrobial group treatments. Given the very similar prevalence of FPT in the present study compared to previous work in Europe and the US, and because of the systematic presence of all respiratory pathogens in veal herds (Wilson et al., 2000; Pardon et al., 2011; Pardon, 2012) , the study most likely has a good external validity for the veal sector. In previous studies on maternal Ig in calves, radial immunodiffusion is mentioned as the gold standard assay for IgG determination. This test is expensive in contrast to electrophoresis or refractometry to be used at large scale in the veal industry. Therefore the authors opted to use serum electrophoresis to determine the concentration of Ig's, a test which is used routinely in many veterinary diagnostic laboratories all over Europe. At the age of 3 weeks, the Ig fraction consists for the vast majority of IgG (95%), and therefore results obtained by electrophoresis are highly similar to those from tests which only determine IgG (Burton et al., 1989) .\n\nThe main finding of the present study is a clear relation between Ig's measured at arrival and the time of BRD occurrence at the veal farm. This observation is in contrast with previous studies which could not evidence such an association (Postema and Mol, 1984;  Postema et al., 1987) . The most likely explanation for this difference is suboptimal disease expression and thus detection by the administration of antimicrobial group treatments in previous studies. Whereas in the present study the optimal cut-off to predict BRD in veal calves is 7.5 g/L, previous studies used 10 g/L as cut off. Maternal antibodies quickly decline after birth and normal IgG range for healthy calves, which have received enough colostrum, is reported to be between 10 and 15 g/L at the age of 2-3 weeks (Hassig et al., 2007) . Therefore, it is not illogical that calves with FPT have levels below 10 g/L at the age of 2-3 weeks. Calves with Ig < 7.5 g/L had a substantial higher BRD hazard and according to Berge et al. (2005) animal welfare might be compromised when no antimicrobials are administered to this group at arrival. However, since only 26% of the calves were involved, group treatment does not comply with prudent use of antimicrobials. Also, for example in the Netherlands and Belgium, prophylactic administration of antimicrobials is forbidden or strongly discouraged, respectively.\n\nAt present the most practical application of Ig determination for the veal sector will be a regular screening in calves after purchase in order to identify the herds of origin with an insufficient colostrum management. The observed association between Ig levels, measured at the age of 2-3 weeks, and BRD is also interesting for conventional dairy and beef farming. It enlarges the window in which calves can be tested for FPT up to the third week of life, facilitating routine checking of FPT in a herd. In this context it is important to emphasize that measurement of TP, the cheapest option, is no longer useful at the age of 2-3 weeks in contrast to in the first days of life. In calves aged 2-3 weeks albumin concentration has increased, decreasing the proportion of Ig's in TP, and this might explain absence of a significant association of TP and disease (Mohri et al., 2007) . Also the well-known influence of hydration status and protein loss by various causes (e.g. diarrhea) on TP levels (Weaver et al., 2000) might have played a role as some animals were already diseased at testing or shortly thereafter.\n\nWe did not find a similar relationship between Ig's and NCD, as observed for BRD. The most likely reason is that only C. parvum was identified, for which colostral antibodies do not confer protection. Also in previous studies C. parvum was the most frequently isolated pathogen in veal calf diarrhea (McDonough et al., 1994; Hoet et al., 2003) . There was however a significant association of NCD with increasing levels of alpha-2 globulin. NCD already was present at arrival or developed shortly thereafter, and therefore several animals might already have had inflamed intestines. Since the alpha-2 globulin fraction contains the acute phase proteins haptoglobulin and ceruloplasmin, this already ongoing inflammation most likely explains the observed association.\n\nWe also observed that calves which were seronegative for BCV or BRSV had an increased BRD hazard. It might signify that among all viruses, BCV and BRSV contributed the most to BRD in the first weeks after arrival. On the other hand, the observed relationship might just be due to the fact that these viruses were the most prevalent pathogen in the study group, clarifying the benefit of the presence of BCV and BRSV antibodies at arrival. It is not unlikely, that in cohorts in which another virus predominates, a seronegative status for that particular virus will be a risk factor. Nevertheless, based upon the present observations providing sufficient specific immunity against respiratory viruses before transport to the veal farm, either by vaccination or by colostrum uptake might be an interesting strategy to reduce the risk of BRD in veal calves.\n\nADG is one of the primary economic outcomes in the veal sector. Average ADG was 0.242 kg/day, which is in line with the expected growth for that diet (3.1 Mcal at day 18 at an ambient temperature of 15 \u2022 C (NRC, 2001)). The well-known negative effects of BRD and NCD on ADG (Wittum et al., 1994; Rerat et al., 2012; Pardon et al., 2013) were not observed in the present study. Possibly intensive monitoring and early treatment alleviated inflammation or BRD was only of viral origin leading to mild inflammation. The association between low Ig and ADG, observed by other authors in dairy calves, was seen in veal calves at a later age (Robison et al., 1988; Virtala et al., 1996; Berge et al., 2009 ). The lower ADG in calves with higher alpha-2 globulin concentrations, most likely reflects the increased protein and caloric cost of an ongoing inflammation (Barnes et al., 2002) .\n\nIn conclusion, a clear effect of Ig concentration at arrival on BRD and ADG in the first 3 weeks was demonstrated in veal calves. Possible applications of screening veal calves at arrival might be the identification of herds of origin with a poor colostrum management or classification of calves according to BRD risk to target antimicrobial treatment. For practical use, an Ig cut-off of 7.5 g/L is recommended. The other protein fractions determined by routine electrophoresis, including TP, did not display any association of direct practical use. Secondly, calves seronegative for BCV and BRSV at arrival had an increased BRD risk in the first 3 weeks of the production cycle. Therefore, assuring a seropositive status for these viruses either by vaccination on the farm of origin or by provision of colostrum from a vaccinated cow might be an appropriate approach to reduce the BRD risk and subsequently prudent antimicrobial use in the veal calf sector.\n\nNone of the authors of this paper has a financial or personal relationship with other people or organizations which could inappropriately influence or bias the content of the paper. The study was supported by funding of the first authors institute."}