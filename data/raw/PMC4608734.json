{"title": "Why Do We Feel Sick When Infected\u2014Can Altruism Play a Role?", "body": "Sickness syndrome is the generalized response of the host to infections. Its classical physiological signs include fever and anemia, but it also includes psychological symptoms\u2014collectively termed \u201csickness behavior\u201d (SB) [1\u20133]. These symptoms, familiar to anyone who has been sick, include fatigue, depression, irritability, discomfort, pain, nausea, and loss of interest in food, drink, social interactions, and sex. In animals, such changes can be quantified based on behavior and reflect reprioritization of motivations during disease [2].\n\nA common misconception is that pathogens directly produce these behavioral symptoms, but in fact SB is orchestrated by the host\u2019s immune and neuroendocrine systems; mammals have evolved several parallel pathways to alert the brain of inflammation and trigger symptomatic behaviors (Fig 1) [4,5].\n\nAlthough the specificities may vary, SB is widespread with respect to both pathogens and hosts: diverse pathogens, including viruses, bacteria, and protozoa [1], can trigger it, and equivalent behavioral responses characterize several vertebrate classes [1,2,7] as well as arthropods [8,9]. However, when closely examined, some genera exhibit significant variation in the extent of SB [10], which to date remains unexplained.\n\nSince SB is a conserved phenomenon that is mediated by complex immunological and neuroendocrine pathways, it clearly must have evolutionary benefits. Still, in the last 25 years, much effort has been directed at understanding the proximate reasons for SB [3], but its ultimate causation\u2014the reasons SB has evolved in the first place\u2014attracted relatively little attention.\n\nUnlike physiological symptoms of sickness, such as fever and hypoferremia, which likely boost resistance to pathogens (Box 1), behavioral symptoms remain poorly explained. Clearly, all of these symptoms impose significant costs to host fitness (Fig 2) [11,12]. Anorexia and adipsia increase the risk of starvation, loss of essential nutrients, and dehydration, particularly in the context of fever. Lethargy can lead to predation by slowing down prey and singling it out for predators [13,14]. Social disinterest decreases parental care [15,16], limits mating opportunities [17], and, together with fatigue, can lead to loss of territory and social status [7,18]. For SB to evolve, these costs must be offset by benefits\u2014what can these benefits be?\n\nThe concept that SB is a coordinated and adaptive response to infections has been established since the mid-1980s. Several comprehensive reviews have covered the historical development of this concept and considered various hypotheses regarding the adaptive role of SB [2\u20134,14,33].\n\nEarly findings suggesting that SB directly benefits the host examined anorexia. In a well-controlled study from 1979, Murray and Murray infected mice with Listeria monocytogens and force-fed them to compensate for the resultant anorexia [34]. The treated mice succumbed to the infection at high rates. Unlike the adaptive effects of fever, this remained a largely isolated study, and contesting theories still debate whether anorexia boosts resistance to pathogens and how it might do so [35]. Suggestions included deliberate restriction of nutritional elements, avoiding potentially contaminated food, and a decrease in risky foraging while weak [35]. Newly established routes linking nutrition, intestinal microbiota, and immunity [36] can now also be considered.\n\nIn 1988, a seminal paper by Benjamin L. Hart was the first to suggest that SB in its entirety is a coordinated response benefitting the host [1]. Realizing that fever and hypoferremia directly promote host defense (Box 1), Hart suggested that SB is primarily intended to serve these physiological adaptations. Specifically, he proposed that SB evolved to conserve energy needed to sustain metabolically demanding fever. Thus, immobility, lethargy, and reduced motivation to obtain food and drink could have developed to minimize muscle work and exposure to the cold. Anorexia, on the other hand, would promote hypoferremia by reducing iron intake. Other behaviors were viewed as subordinate to the primary ones that conserve energy and reduce iron. Reduced grooming, for example, could preserve fluids in the context of adipsia, whereas decreased foraging would protect a weak animal from predators.\n\nHart\u2019s hypothesis remained the dominant theory in the field [2,37\u201340], as it parsimoniously explains a large range of symptoms. Since it was proposed, though, accumulated evidence has exposed some gaps in the hypothesis; it is now time to reassess it.\n\nConserving energy to maintain fever is central to Hart\u2019s hypothesis. SB is definitely associated with reduced motivation for action\u2014and therefore with less energy expenditure. However, in many cases, fever and SB are decoupled, the one arising without the other [10]. In humans, for instance, malaise and fatigue often characterize mild infections that do not elicit fever. More importantly, several aspects of SB can actually tip the energy balance in the wrong direction. Confinement to nests and dens does not always conserve heat. In warmer climates, dens are cooler than the outside environment and mobility increases body temperature, yet desert animals still remain inside [10]. Another counterproductive symptom is reduced grooming. When mammals and birds stop grooming, their fur and plumage gradually lose their insulating efficiency, requiring more energy to maintain fever [41,42].\n\nThe most counterintuitive symptom is anorexia, which, as Hart acknowledged, deprives sick animals of calories needed to fuel fever (especially in migratory animals that cannot reduce energy expenditure by retiring to protected environments). Recognizing this caveat, Hart suggested instead that anorexia evolved to reduce iron consumption, consequently assisting another important antimicrobial response\u2014hypoferremia. It seems unlikely, though, that evolution would favor an indiscriminate reduction in food intake just to decrease iron consumption. Herbivores, for instance, can vary their diet to suit nutritional needs [43], so they could instead avoid only iron-rich foods or ingest clayey soil to interfere with iron absorption [44].\n\nMore importantly, physiologists have since gained much mechanistic insight into hypoferremia, rendering this notion less likely. Dietary iron absorption is dwarfed by the total iron reserves in the human body and the amount recycled through erythropoiesis [45]. Anorexia, therefore, can only mediate slow-acting changes in plasma iron [46]. In contrast, inflammatory agents such as lipopolysaccharide (LPS) can halve plasma iron within a few hours [47]. The direct mechanism through which infection elicits hypoferremia (Box 1) was only discovered 15 years ago [31] and involves the rapid production of hepcidin in the liver. This efficient mechanism obviates anorexia when infection requires the host to rapidly reduce plasma iron.\n\nSensing that Hart\u2019s explanation cannot account for all the symptoms of SB, several complementary theories have since been proposed. Watkins and Maier [48] stressed the importance of allodynia and hyperalgesia (reduced threshold and increased intensity of pain) in SB. They proposed that these symptoms, together with the reduced activity SB introduces, are intended to protect sensitive organs and tissues from further damage. Medzitov et al. [49] maintained that SB chiefly promotes tolerance towards parasites, rather than their clearance, although the details of this interaction remained unclear. All these theories focus on direct benefits that infected individuals may derive from SB; they disregard the indirect effects SB may have at the group level.\n\nOverall, the evidence that all the symptoms of SB directly improve host resistance to infection remains incomplete, and after several decades of research in this field, writers still debate whether and how symptoms of SB benefit hosts [3,14,33,35,50]. What, then, could a complementary evolutionary explanation be?\n\nIf gains to direct fitness cannot fully explain SB, perhaps inclusive fitness could come into play. We propose that reduced transmission of infectious disease among related individuals contributed to the evolution of SB. Although the idea that SB reduces transmission has been alluded to before [3,20,51,52], it was never recognized as a major organizing principle for SB in vertebrates. We name this theory \u201cthe Eyam hypothesis\u201d after the English mining community that isolated itself to contain an outbreak of bubonic plague in 1666. Three-quarters of the villagers reportedly died, but the surrounding communities were saved [53].\n\nThe Eyam hypothesis relies on three premises:\n\nIt is self-evident that salient symptoms of SB, such as social disinterest, depression, hyperalgesia, fatigue, and hypersomnia, reduce the mobility and social activity of infected individuals, limiting their contact with conspecifics. Likewise, sexual disinterest suppresses courtship and mating behaviors, whereas reduced parental care entails by definition less interaction with offspring. The contribution of anorexia and adipsia may be less apparent; by suppressing the motivation to eat and drink, they reduce the urge to travel in search of food and water, share meals with group members, and gather at water sources.\n\nSelf-imposed isolation may account for the folk observation that terminally ill dogs leave their owners to die alone. Similar behavior has been recorded in the wild among badgers, which, when infected with bovine tuberculosis, separated from their clan and settled in individual setts, where they died [54].\n\nTellingly, the opposite effect is observed when pathogens manipulate host behavior to their benefit. In such diseases, infected hosts become hyperactive and interact more with potential hosts: for example, rabid dogs become fearless and bite, and rodents infected with Toxoplasma gondii lose their fear of cats (the definitive hosts) [55].\n\nOn top of restricting direct contacts, SB can also limit indirect contacts between conspecifics by reducing microbial contamination of shared resources: ground, food and water (Fig 3).\n\nSymptoms such as hypersomnia, fatigue, and depression restrict the animal\u2019s radius of activity, limiting environmental contamination to its immediate surroundings. Social and sexual disinterest, as well as anorexia and adipsia, further reduce the drive of animals to travel farther afield.\n\nAnorexia and adipsia seem paramount in that respect as they prevent sick animals from contaminating shared food and water resources. Contamination of pastures (for herbivores) or carcasses (for carnivores) and contamination of water holes are undoubtedly major routes for oral and fecal-to-oral transmission in the wild. Finally, anorexia and adipsia also reduce defecation, diarrhea, and vomiting, which are the major means of spreading for enteric pathogens.\n\nWhereas strategies #1 and #2 involve self-imposed restrictions, SB can also act by provoking responses from conspecifics. In many species, group members can detect infected individuals through visual, olfactory, and chemical cues [56\u201359], distance themselves, and stop interacting with them [60]. Such signaling has been demonstrated most convincingly in eusocial insects in which chemical communication is used to coordinate social immunity (Box 2).\n\nStudies in rodents implicated the vomeronasal organ in sensing infection [72] and discouraging social and sexual interactions [59]; importantly, immune activation with LPS was enough to mark animals as sick. Even in humans, mammals with an ill-reputed sense of smell, the clothes of LPS-treated subjects can be sniffed out [73].\n\nIt is easy to accept that the detection of infected conspecifics has evolved as a protective avoidance mechanism, but the transmission of such signals could also have been selected for. Several symptoms of SB may act as infection cues: reduced self-grooming visibly distinguishes infected individuals as scruffy [1] and probably accentuates the olfactory signals they emit. Similar changes may affect vocal communication. In sparrows, for instance, the frequency and pattern of birdsong change during an inflammatory response [74]. Lastly, the stereotypic posture and motion that infected animals adopt because of fatigue and hyperalgesia can act as additional cues. Thus, LPS-treated subjects can be detected by observers based on their gait [75]. The signaling aspects of such behavioral changes are exposed by the response of sick animals to predators. Under the gaze of carnivores, sick members of a herd would attempt to disguise their vulnerability and suppress SB [14]. This observation suggests that animals can alert their kin of infection but suppress such signaling to predators.\n\nMedicine has long acknowledged the importance of isolation for containing infectious disease in humans. Behavioral interventions such as quarantine, school closures, and bans on travel and public gathering have curtailed the spread of contagious diseases such as Ebola [76], vector-mediated diseases such as bubonic plague [77], and airborne ones such as severe acute respiratory syndrome (SARS) [78]. These successes demonstrate that, regardless of the route, social isolation can reduce transmission.\n\nA question more relevant to the evolution of SB is whether self-imposed social isolation is effective in the wild. Several such examples exist: in the last decade, bat populations of many species in North America collapsed because of the \u201cwhite nose\u201d fungal disease. Although almost all of the colonies observed were decimated, some bat populations survived by adopting a solitary roosting pattern [79]. Conversely, a study in wild deer mice has shown that highly active individuals, which encountered more mice, exhibited higher viral infection rates [80].\n\nIsolation of infected people based on clinical symptoms can be effective only when they overlap with the infectious period [81]. Empirical data suggest that, in the few infectious diseases studied (barring HIV), this is indeed the case. Thus, in SARS, smallpox, and foot-and-mouth disease, this overlap exceeds 80% [81,82], and estimates for influenza range between 50% and 90% [81,83]. Since behavioral symptoms typically precede specific clinical signs, these figures likely underestimate the overlap between SB and infectivity and the potential reduction in transmission.\n\nIf indeed SB favors the fitness of other group members at the expense of the individuals, then it can be considered an instance of biological altruism. It has long been debated how altruism can become an evolutionarily stable strategy (ESS). A likely mechanism is kin selection, the positive selection of traits that increase the fitness of the individual\u2019s relatives. This initially controversial theory, put forward by W. D. Hamilton [84], has been mathematically validated and widely accepted since [85].\n\nKin selection is easy to accept when altruism is actively directed at relatives (e.g., birds feigning injury to lead predators away from their chicks), but how can it promote SB, a response that indiscriminately favors related and unrelated group members? This can only happen when the average relatedness within the social group is higher than within the entire population. Indeed, in many (although certainly not all) species, genetically related individuals are disproportionally represented in the immediate social groups in which most physical interactions occur [86\u201389]. Such bias develops because of high population viscosity, i.e., slow and spatially restricted dispersal of progeny.\n\nAnimal species vary in the degree of intergroup relatedness based on their life history. At one end of the spectrum are r-strategists whose offspring are neonatally independent and disperse widely. Under such conditions, social considerations are unlikely to drive SB. At the opposite end of the spectrum lie eusocial animals. Among these, eusocial hymnoptera have been studied most (Box 2). These insects indeed display a variety of collective disease defense behaviors, in part resembling SB, which are collectively termed \u201csocial immunity\u201d [61]. Humans, classical K-strategists who cohabit most of their lives with first-degree relatives, seem to lie closer to this pole.\n\nIntriguingly, some experimental evidence suggests that SB is actually not as universal as commonly assumed. Some birds can become infected, mount an immune response and develop fever without showing conspicuous signs of illness [90], leading to an apparently sudden death from infection [14]. In fish, administration of LPS triggers no observable behavioral changes [91]. Studies in wild mouse populations showed that the intensity of SB varies considerably among related species [10]. How this diversity relates to social structure is yet to be examined.\n\nThe Eyam hypothesis has never been directly tested, so the empirical evidence supporting it is still limited; nonetheless, it produces testable predictions. As stated above, an ESS for SB would counterbalance its cost to the infected individuals with the benefit of reducing transmission to their kin. This benefit should be proportional to pathogen virulence, the chances of transmission between individuals (infectivity), and the average relatedness of susceptible hosts. Consequently, several predictions can be examined either correlatively (1-3), experimentally (4, 5), or mathematically (6, 7).\n\nWe are so used to malaise being the essence of infection that we often forget to ask why it evolved. The social implications of SB may not be the only selective force driving it, but they clearly contribute and have been disregarded for too long. The mystery of SB is not only intellectually provoking but also clinically significant. This is because behavioral symptoms are routinely relieved using anti-inflammatory drugs such as cyclooxygenase (COX) inhibitors. According to the Eyam hypothesis, such use could prove socially irresponsible. By enabling infected people to travel widely and socialize, it interferes with a natural mechanism that prevents pathogen spread. In contrast, SB that accompanies medical procedures (such as cytokine treatment) and noninfectious diseases (such as cachexia in cancer) is a side effect that could be treated safely."}