{"title": "DATA-DRIVEN OUTBREAK FORECASTING WITH A SIMPLE NONLINEAR GROWTH MODEL TECHNICAL APPENDICES", "body": "\u2022 Data for an outbreak of gastroenteritis in a nursing home in Majorca, Spain in 2008 were estimated from a graph showed in Figure 1 of the corresponding Eurosurveillance article by Fern\u00e1ndez et al. (2) .\n\n\u2022 Data for the 2011-12 pertussis outbreak in the state of Washington were estimated from the epidemiological curve (Figure 1 of (3)) available on the CDC site (3) . Estimated number of cases are provided in the Excel file Pertussis WA 2012.xlsx. The report (3) and the epidemic curve were published before the outbreak completed its course.\n\n\u2022 Data for the H1N1 outbreak in Canada were downloaded in Excel format from the material provided online by the authors of (4). We used the entire data set for the cumulative number of cases, dated 4/12 to 6/19, 2009 , also available in the Excel file H1N1 Canada 2009.xlsx. It is important to note that this outbreak picked up after the summer break yielding another larger wave of cases (5) .\n\n\u2022 Data for a 2008 outbreak of Salmonella were estimated from a plot of the epidemiological curve available on the CDC site (6) and are provided in the Excel file Salmonella 2008.xlsx.\n\n\u2022 Ebola data (ebola data db format.xlsx) was downloaded on 09/09/2015 from information posted online by the WHO (see https://data.hdx.rwlabs.org/ dataset/ebola-cases-2014 for current version), and the cumulative numbers of confirmed, probable, and suspected cases for Guinea, Liberia, and Sierra Leone, were extracted from these data. We did not include the Liberia2 data because what were listed as cumulative numbers of cases appeared to be incident cases. The Excel files we used in our analysis are Ebola Guinea 2014.xlsx, Ebola Liberia 2014.xlsx, and Ebola Sierra Leone 2014.xlsx.\n\nEpidemiological data is typically reported as daily or weekly incidence and can be combined into a collection of points {C(t), t = 0, . . . , t m } representing the cumulative number of cases reported from the beginning of an outbreak (t = 0) to the current time t m , where t is measured in time units TU. The latter depends on the nature of the outbreak and is typically a day or a week. In order to smooth the data and interpolate C(t) on a finer grid of mesh size \u03b4t = 1/28 TU, we first remove consecutive repeated values of C(t), keeping only the first occurrence, except for values at the end of the data set, or values equal to zero. We then apply the MATLAB smooth function with default options (5-point moving average); the interpolation is performed with the interp1 MATLAB routine, with the pchip option, which provides a \"shape-preserving piecewise cubic interpolation\" (7) . If this procedure leads to negative values of C obs (which might occur at the beginning of an outbreak if there are large fluctuations in the reported number of cases), these values are removed.\n\nThe smoothed interpolated data, denoted C obs (t), is then used to estimate the observed growth rate (incidence) G obs of the outbreak, in number of cases per TU. Specifically, G obs at time t is approximated as a 2-point difference quotient calculated from the smoothed interpolated data,\n\nexcept at the end points, where a first-order approximation is used. Figure T1 illustrates the outcome of this procedure by comparing the reported incidence data G to its interpolation G obs for the 2014 Ebola outbreak in Sierra Leone. As can be seen on the figure, the process is similar to a moving window average of the daily incidence information.\n\nThe parameters C 0 and M can be estimated by hand using trial and error, or automatically.\n\nIn either case, the goal is to provide as good an approximation as possible of both the graph of G as a function of C and of the graph of C as a function of time. 3. Automated parameter estimation. The parameters that need to be estimated depend on the stage of the outbreak. If the goal is to describe an epidemic that has followed its course, then we already know the final number of cases, C 0 , and the appropriate value of M is simply found by minimizing the error E(C 0 , M ) (defined below) between the predicted and observed epidemiological curves. If we do not know the value of C 0 , which is the case for ongoing outbreaks, we use two criteria, one based on the graph of G(C), and one based on the epidemiological curve C(t).\n\nFor the first criterion, we require that the model growth rate, G, and its counterpart estimated from the data, G obs , give approximately the same number of cases over the course of the outbreak. We therefore evaluate the signed error\n\nwhere t m is the last time point for which epidemiological data are available, G(C) = (4M/C 2 0 )\n\n, G obs is the growth rate estimated from the experimental data, and C obs is the smoothed interpolated number of case as a function of time. Note that the integration is over t,\n\nThe second criterion consists in minimizing the error E(C 0 , M ), along the curve K. Specifically, we define\n\nwhere C(t) is the number of cases predicted by solving dC/dt = G(C) with the specified values of M and C 0 and a fixed initial condition. The quantity E(C 0 , M ) measures how much the two epidemiological curves, observed and predicted, differ from one another. Recent work (8) cautions against estimating epidemiological parameters from cumulative data, since cumulative fluctuations are not independent from one another. Our approach is different. First, G in the expression for E(C 0 , M ) is incidence and its daily fluctuations due to noise in the data can be assumed to be independent. Second, the fit to the cumulative epidemiological curve is only performed along a curve, not on the entire parameter space. 4. The SIR model and the logistic differential equation. The SIR model (see for instance (9) ) is given by\n\nwhere \u03b2 is the contact rate of the disease and \u03b3 the recovery rate. S represents the number of susceptible individuals, I the number of infective individuals, and R those who have recovered or died. Adding these three equations shows that N = S + I + R is conserved, indicating that a dimensionless version of the system, in which S, I and R are scaled to N , can simply be obtained by setting N = 1 in the above equations. Moreover, the total number of cases C = I + R satisfies the differential equation\n\nCombining the equations for S and R, one obtains dS/dR = \u2212\u03b2S/(\u03b3N ), which can be in- (10)). At the beginning of the outbreak, or if recovery is slow, so that R 0 R/N is small, we can expand the exponential in the expression for S in powers of R 0 R/N and obtain\n\nwhich gives R C/R 0 and I = C \u2212 R (1 \u2212 1/R 0 ) C, which is thus proportional to C. At the same time, S N at lowest order, so that the linear behavior of dC/dt is given by \u03b2S I N \u03b3(R 0 \u2212 1)C. Of course, as the disease progresses, one can no longer assume that R 0 R/N remains small, and nonlinearities come into play. If we call C 0 the final number of cases and demand that dC/dt vanish when C = C 0 , then the simplest nonlinear model that satisfies this condition together with the linear behavior for small C described above has only a quadratic nonlinearity and amounts to approximating dC/dt as a function of C by a parabola. Putting these requirements together, we therefore expect C to solve the following logistic differential\n\nThe right-hand side may be rewritten as\n\n. This is the expression used for parabola P 2 in Figure 3 of the main text. We note that a modeling explanation for approximating dC/dt by a logistic equation is provided in (11) as a behavioral response of the community in which the disease develops.\n\nWe can obtain an expression for the value of C 0 by noting that when the outbreak is over, I = 0 and thus C = C 0 = R. From N = S + I + R, together with the expression for S given above, we see that C 0 must solve the equation\n\nThis is a transcendental equation which has two solutions for R 0 > 1. One is of course C 0 = 0;\n\nthe other root gives the final number of cases and needs to be evaluated numerically. If R 0 is large, the non-zero root is close to N . If R 0 is just above 1, C 0 can be much smaller than N . Figure 3 of the main text shows that in either case the graph of G plotted as a function of C can be approximated by an inverted parabola and that the dynamics of C therefore closely follow the logistic equation. Note however that knowledge of C 0 and M is not sufficient to infer the values of the parameters \u03b2, \u03b3 (or R 0 ) and N of the SIR model, which indicates that estimating C 0 and M is different from the process of parametrizing infectious disease models from epidemiological data.\n\nWe tested the automated parameter estimation method described above on noisy data sets in order to assess the robustness of its predictions. For each data entry point C(t), we measure the distance between C(t) and C obs (t) (the smoothed interpolated data at time t). The difference w(t) \u2261 |C obs (t) \u2212 C(t)| provides an estimate of the amount of noise in the data at time t. We do not assume that the noise is the same at all times, that is we do not consider successive instances of w(t) to be realizations of the same random variable. Instead, we generate noisy data by adding to C obs (t), at time t, a random number uniformly distributed in the interval [\u2212w(t), w(t)]. We then run the automated parameter estimation method on 1000 noisy versions of the data set and record the resulting estimates for the duration, time of peak incidence, number of cases of the outbreak, and for the parameter M . We use the variability of these quantities as a measure of the robustness of our estimates to noise in the data set. Results are shown in Supplementary Table A1. 6. Epidemiological information. For each simulation of an outbreak, we define the following characteristic quantities.\n\n\u2022 Duration: time at which the number of cases C first goes above the quantity 0.9999 (C last \u2212 1), where C last is the value of C at the end of the simulation, rounded to the nearest integer. With this definition, cases may continue to occur past the duration of the outbreak if C last is large. However, this increase is not significant compared to the value of C last itself.\n\n\u2022 Peak incidence: the value of t at which G(C(t)) = M , rounded to the nearest integer value.\n\n\u2022 Total number of cases: C last , which is the predicted cumulative number of cases at the end of the simulation.\n\nThe simulation ends when the number of cases C is such that C \u2212 C 0 > C 0 /1000. Note that because of this definition, C last and C 0 are close to each other, but not necessarily equal when The start date is the date of the first reported number of cases in the data set we used, ebola data db format.xlsx. The end dates are when each outbreak was officially declared over by the WHO.\n\nThe reported peak incidence is taken as the time when the largest increment in the number of cases was recorded, except for Ebola outbreaks for which increments between reports can vary widely between positive and negative values. In such cases, we estimate the time of peak incidence as the midpoint of the interval during which reported increments were larger than those before and after the endpoints of that interval. Estimates of peak incidence therefore depend on the quality (regularity, reliability) of the reported data.\n\n7. Analysis of performance on partial data sets. For each outbreak, we define 20 data sets, corresponding to the data points S k \u2261 {C(t), t = 0, . . . , t k }, where t k = ceil(k t m /20)\n\n(the time point equal to or immediately after k twentieths of the final time t m ), for integer values of k between 1 and 20. With this notation, S 20 corresponds to the entire data set for the given outbreak. For each set S k , the automated parameter estimation procedure produces two parameters values, M k and C k 0 , which we use to estimate the duration D k , peak incidence P k , and final number of cases C k of the corresponding outbreak, using the definitions given above.\n\nWe then compare these values to those obtained from the entire data set, S 20 , and repeat this procedure for each single-wave outbreak. We use this information to plot\n\nas functions of the fraction of the total number of cases that had been reported at time t k . We then interpolate this data to approximate the predicted values of D, C, and P when a given percentage p of the total number of cases had been reported. Values for p = 10%, 30%, 50%\n\nand 70% are shown in Supplementary Table A2 for nine different outbreaks and summarized in Table 1 of the main text. Reported values in boldface were estimated from the data sets provided with this article. Italicized reported values were obtained from separate data sets for Ebola (see \"Epidemiological information\" above). For H1N1, since the data are incomplete, we estimated the peak value from the data set, but used values for the duration and size of the outbreak equal to those predicted by the automated parameter estimation method applied to the entire data set. \n\nTraining Data Reported Logistic Fit EpiGro Figure T2 : Comparison of EpiGro predictions to those of a logistic fit of the cumulative epidemiological curve on partial data sets for the 2014-15 outbreak of chikungunya in the Dominican Republic. The three panels correspond to training data sets (red stars) of increasing size. The blue circles show reported cumulative cases that were not part of the training data. The solid curve is obtained from a logistic fit and the dashed curve are EpiGro predictions. Figure T2 shows predictions of the two procedures when an increasing fraction of the available data for the 2014-15 chikungunia outbreak in the Dominican Republic is used to train the models. In the left panel (small training data set), the logistic model largely overestimates the final size of the outbreak, while EpiGro (the approach discussed in the present article) underestimates it; short-term predictions are however better captured by a logistic fit. As the size of the training data set increases (middle and right panels), EpiGro's performance is comparable to or better than the logistic fit. Figure T3 shows similar results for the 2009 H1N1 outbreak in Canada. In that case, EpiGro performs better, both for short term predictions and outbreak size, than the logistic fit. In panels 2 and 3, the minimizer found by fminsearch is not a global minimizer, and EpiGro finds a set of parameters that better fits the data. Figure T4 , for the 2014\n\nEbola outbreak in Liberia, shows a situation where EpiGro provides better short-term predictions on a small data set (left panel), although it underestimates the final size of the outbreak. In the middle panel, both models are in agreement, whereas in the right panel Epigro gives better estimates than the least square logistic fit."}