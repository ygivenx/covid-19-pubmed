{"title": "A fast and robust iterative algorithm for prediction of RNA pseudoknotted secondary structures", "body": "RNA molecules are crucial in different levels of cellular function, ranging from translation and regulation of genes to coding for proteins [1-6]. Understanding the structure of an RNA molecule is important in inferring its function [7-10]. Since experimental methods for determining RNA structure, such as X-ray, crystallography and NMR, are time consuming, expensive and in some cases infeasible, computational methods for prediction of RNA structure are valuable.\n\nCurrently computational RNA structure prediction methods mainly focus on predicting RNA secondary structure\u2014the set of base pairs that form when RNA molecules fold. When multiple homologous (evolutionarily related) RNA sequences are available, the secondary structure of the sequences can be predicted using multiple sequence alignment and comparative sequence analysis [11-22]. Alternative approaches, which can be used to predict secondary structure of a single sequence, are based on thermodynamic parameters derived in part from experimental data [23]. While thermodynamics-based approaches can be less accurate than comparative-based algorithms, thermodynamics-based approaches are applicable in cases of novel RNAs such as the many RNAs of unknown function recently reported by the ENCODE consortium [24]. Thermodynamics-based approaches can also be easier to apply to prediction of the structure of interacting RNA molecules, for example, in gene knockdown studies.\n\nMany computational thermodynamics-based methods find the structures with the minimum free energy (MFE) from the set of all possible structures, when each structure feature is assigned a free energy value and the energy of a structure is calculated as the sum of the features\u2019 energies. There has been significant success in prediction of pseudoknot-free secondary structures (structures with no crossing base pairs) [23,25,26]. While many small RNA secondary structures are pseudoknot-free, many biologically important RNA molecules, both in the cell [27,28], and in viral RNA [29] are found to be pseudoknotted.\n\nSince finding the MFE pseudoknotted secondary structure is NP-hard [30-32], polynomial time MFE-based methods for prediction of pseudoknotted secondary structures predict a restricted class of pseudoknotted structures [33-35]. These methods trade off run-time complexity and the generality of the class of structures they can predict. For example, the most general algorithm of Rivas and Eddy [33], whose running time is \u0398(n6) on inputs of length n, is not practical for RNA sequences of length more than 100 nucleotides. This has been the main reason for development of heuristic methods for prediction of pseudoknotted structures [36-41]. Although heuristic methods may not find the MFE structure, they usually run faster than the MFE-based methods that handle the same class of structures. For example, HotKnots V2.0 [36,41] is a heuristic approach that uses carefully trained energy parameters, is guided by energy minimization and can handle kissing hairpin structures. However, HotKnots is still slow on long sequences.\n\nOther methods for prediction of pseudoknotted structures, such as the IPknot method of Sato et al. [42], are motivated by the finding of Mathews [43] that base pairs with high base pairing probabilities in the thermodynamic ensemble are more likely to be in the known structure. In a comprehensive comparison performed by Puton et al. [44] on the performance of publicly available non-comparative RNA secondary structure prediction methods that can handle pseudoknotted structures, IPknot ranks first for general length RNA sequences.\n\nIncorporating known structural information can improve the accuracy of structure prediction. For example, Mathews et al. [45] used SHAPE reactivity data to improve the prediction accuracy from 26.3% to 86.8% for 5S rRNA of E. coli. Roughly, the larger the SHAPE reactivity value for a given nucleotide, the more likely it is that the nucleotide is unpaired in the structure. However, limited SHAPE reactivity data is available, and the data does not unambiguously determine whether a base is paired or not or, if it is paired, to what other nucleotide. Deigan et al. [46] created pseudo energy terms from SHAPE reactivity data, as a means of integrating such data into prediction software. They reported prediction accuracy of 96% to 100% for three moderate-sized RNAs (<200 nucleotides) and for 16S rRNA (1500 nucleotides). ShapeKnots [47] is a new method for incorporating SHAPE reactivity data for pseudoknotted structures that incorporates the pseudo energy terms into a heuristic method similar to that of Ren et al. [41].\n\nWe previously presented HFold [48], an approach for prediction of pseudoknotted structures, motivated by two goals, namely to avoid the high running time complexity of other methods for pseudoknotted secondary structure prediction and to leverage the hierarchical folding hypothesis. This hypothesis posits that an RNA molecule first folds into a pseudoknot-free structure; then additional base pairs are added that may form pseudoknots with the first structure so as to lower the structure\u2019s free energy [49]. Given a pseudoknot-free structure as input, HFold predicts a possibly pseudoknotted structure from a broad class that contains the given input structure and, relative to that constraint, has minimum free energy. HFold\u2019s running time is O(n3), significantly faster than other methods for predicting pseudoknotted structures. Several experts have provided evidence for, and support, the hierarchical folding hypothesis [49-52]. The class of structures that HFold can handle, density-2 structures, is quite general and includes many important pseudoknots including H-type pseudoknots, kissing hairpins and infinite chains of interleaved bands, with arbitrary nested (pseudoknotted) substructures. (Roughly, a structure is density-2 if no base is enclosed by more than two overlapping pseudoknotted stems.)\n\nAnother advantage of HFold over heuristic methods such as HotKnots or ShapeKnots is that unlike these methods, HFold minimizes the free energy of the possibly pseudoknotted output structure relative to the given input structure. Therefore HFold\u2019s method of adding pseudoknotted stems is better motivated energetically than that of HotKnots or ShapeKnots.\n\nWhile HFold is fast, our earlier implementation of HFold had its own shortcomings. First, due to a high pseudoknot initiation penalty in its underlying energy model, many of its predicted structures did not have pseudoknots. Also low band penalty (i.e., penalty for addition of pseudoknotted stems or bands) in its energy model encouraged addition of pseudoknotted stems when a pseudoknot was predicted. Second, if the first structure input to HFold contains base pairs that are not in the true pseudoknot-free structure for the given RNA sequence or is not the complete pseudoknot-free structure (i.e., it does not include all the base pairs in the pseudoknot-free structure), HFold is often unable to predict the known pseudoknotted structure as output.\n\nTo summarize, existing methods for prediction of pseudoknotted structures suffer from one or both of the following shortcomings: 1) slow running time, or 2) poor prediction accuracy. Moreover there is limited opportunity for the user to provide structural information, or constraints, that can guide prediction. In cases of a prediction method that incorporates user-defined constraints, it is also useful to understand the degree to which the method\u2019s accuracy persists as the input information degrades. We use the term robustness with respect to partial information or robustness to refer to this property of a method. (We note that in our definition of robustness we do not mean robust with respect to noise.) To the best of our knowledge, the concept of robustness in secondary structure prediction methods has not been studied before.\n\nIn this work we present a new method that addresses these shortcomings. Our method, Iterative HFold, takes a pseudoknot-free input structure and produces a possibly pseudoknotted structure whose energy is at least as low as that of any (density-2) pseudoknotted structure containing the input structure. Iterative HFold incorporates four different methods and reports as its final structure the structure with the lowest energy, among all structures produced by these methods. While one of its underlying methods, HFold, strictly adheres to the hierarchical folding hypothesis, the other three use iterations to extend or remove the base pairs of input structure, with the goal of finding a structure that has lower energy than the structure found by HFold. Thus, unlike HFold, iterative HFold is able to modify the input structure (while the class of structures handled by both methods is the same). This is valuable since 1) computationally produced structures may not be completely accurate and 2) while the hierarchical folding hypothesis is a useful guiding principle, there is evidence that allowing for disruption of some base pairs in the initially formed pseudoknot-free secondary structure can improve prediction [53,54].\n\nAll of Iterative HFold\u2019s underlying methods use the energy model of HotKnots V2.0 DP09 [36]; with this model, HFold obtained predictions with higher accuracy than those obtained with our earlier implementation of HFold. One of Iterative HFold\u2019s underlying methods is HFold-PKonly, which given the input structure only adds pseudoknotted base pairs. HFold-PKonly is especially useful for cases when the user has either complete information about the true pseudoknot-free structure or wants to check whether a single stem of the input structure can be part of a pseudoknot since, if the input structure only has the specific stem in question, the output structure of HFold-PKonly will determine if the given stem can be part of a pseudoknot.\n\nBased on our experiments on our HK-PK and HK-PK-free data sets that include 88 pseudoknotted structures, and 337 pseudoknot-free structures respectively, ranging in length from 10 to 400 nucleotides, a single run of Iterative HFold does not take more than 9 seconds time and 62 MB of memory. In contrast, one of the best heuristic methods, HotKnots V2.0, takes 1.7 hours and 91 GB of memory for a sequence with 400 nucleotides. Therefore our method is practical for prediction of long RNA structures. Iterative HFold bootstrap 95% percentile confidence interval for average accuracy of pseudoknotted structures of the HK-PK data set is significantly higher than that of IPknot, ((72.83%, 83.37%) vs. (54.56%, 66.25%)) and is comparable to that of HotKnots V2.0, (vs. (73.60%, 83.35%)) two of the best prediction methods available. Iterative HFold\u2019s accuracy is significantly higher than that of IPknot and HotKnots on our IP-pk168 data set. Iterative HFold also has higher accuracy than HFold even when just partial information about the true pseudoknot-free structure is provided, so it is more robust than HFold. Specifically, Iterative HFold\u2019s average accuracy on pseudoknotted structures steadily increases from roughly 54% to 79% as the user provides up to 40% of the input structure, and improves with a more modest but still positive improvement in accuracy when further structural information is provided.\n\nMany computational methods for predicting the secondary structure of an RNA (or DNA) molecule are based on models of the free energy of loops [23,25,26,33-36,48]. Table 1 summarizes the energy constants and functions used in our energy model for pseudoknotted structures. The values of these energy parameters are those of the DP09 parameter set of Andronescu et al. [36], used by the HotKnots V2.0 prediction software.\n\nWe use three data sets to analyze performance of our algorithms. Our first data set is the test data set of Andronescu et al. [36], that contains 446 distinct RNA sequences and their reference structures, of which 348 are pseudoknot-free and 98 are pseudoknotted. This set has four structures that are not in the class of structures our methods can handle (i.e., have densities higher than 2 [48]). Since the number of such structures is too small to be useful in an experimental analysis, we removed them from our set of pseudoknotted structures, resulting in a set of size 442.\n\nThere are eight cases in this data set for which the original sequence and structure were shortened to accommodate restrictions in length. We removed them from our data set, resulting in a set of size 425. From now on we use \u201cHK-PK\u201d to refer to the pseudoknotted structures in this set (with 88 structures) and \u201cHK-PK-free\u201d to refer to the pseudoknot-free structures in this set (with 337 structures). RNA sequences in HK-PK and HK-PK-free have length between 10 and 400 nucleotides.\n\nOur second data set is the pk168 data set of Sato et al. [42]. This set contains 168 pseudoknotted structures from 16 categories of pseudoknots. The sequences in this set have at most 85% similarity and have length of at most 140 nucleotides. We refer to this data set as \u201cIP-pk168\u201d.\n\nOur third data set is the test data set of Sperschneider et al. [57]. This set contains 16 pseudoknotted structures with strong experimental support. RNA sequences in this set have length between 34 and 363 nucleotides. We refer to this data set as \u201cDK-pk16\u201d.\n\nTo test the robustness of our methods on a given RNA sequence, we need to provide partial information about the true pseudoknot-free structure as input structure for that sequence. To obtain the true pseudoknot-free structure, Gbig, we remove the minimum number of pseudoknotted base pairs from the reference structure to make the reference structure pseudoknot-free. If the reference structure is pseudoknot-free, then Gbig is the same as the reference structure itself. We call the removed base pairs from the reference structure Gsmall. Blue base pairs in Figure 1 represent base pairs of the Gbig structure and green base pairs represent the Gsmall structure.\n\nFollowing common practice [36,58], we measure the accuracy of a predicted RNA secondary structure relative to a reference secondary structure by F-measure, which is the harmonic mean of sensitivity and positive predictive value (PPV). We define these values as follows: \n\nSensitivity=NumberofcorrectlypredictedbasepairsNumberofbasepairsinthereferencestructure\n\nPPV=NumberofcorrectlypredictedbasepairsNumberofpredictedbasepairs\n\n and \n\nF\u2212measure=2\u00d7sensitivity\u00d7PPVsensitivity+PPV\n\nWe also define these values as 0 when their denominators are 0. When a prediction agrees with the reference structure, the value of F-measure is equal to 1 (so are the values of sensitivity and PPV). When the values of sensitivity or PPV is equal to 0, the predicted structure does not have any base pairs in common with the reference structure.\n\nTo formally assess the dependency of measured prediction accuracy of results of a method on a given set of RNA we use bootstrap confidence intervals, a well-known statistical resampling technique [59,60]. Following the recent work of Aghaeepour and Hoos [61] and Hajiaghayi et al. [58] we calculate the bootstrap 95% percentile confidence interval of average F-measure as follows. For each vector f of F-measures (where, for example, f may be the F-measures of predictions obtained by Iterative HFold on pseudoknotted structures) we first take 104 resamples with replacement, where the resamples have the same length as the original sample vector f (|f|), and then calculate their average F-measures. These 104 calculated average F-measures represent the bootstrap distribution for the vector f. We then report the 2.5th and 97.5th percentile of this distribution (i.e., the bootstrap distribution of the 104 average F-measures calculated above) as the lower and upper bounds of the confidence interval respectively, and call it the bootstrap 95% percentile confidence interval. By reporting the bootstrap 95% percentile confidence interval for average F-measure of a method, A, on a data set, D, we say that we are 95% confident that the average F-measure of method A on data set D is in the reported interval. All calculations are performed using the \u201cboot\u201d package of the R statistics software environment [62].\n\nFollowing the recent work of Hajiaghayi et al. [58], we use a two sided permutation test to assess the statistical significance of the observed performance differences between two methods. The test proceeds as follows, given a data set and two structure prediction procedures, A and B. First, we calculate the difference mean(fA)\u2212mean(fB) in means between sets of F-measure values obtained by A and B. Then we combine the two sets fA and fB and record the difference in sample means for 104 randomly chosen ways of choosing two sets with the same size as |fA| and |fB| from the combined set. The p-value is the proportion of the sampled permutations where the absolute difference was greater than or equal to that of absolute difference of the means of sets fA and fB. Then, if the p-value of this test is less than the 5% significance level, we reject the null hypothesis that methods A and B have equal accuracy and thus accept the alternative hypothesis that the difference in accuracy of method A and B is significant. Otherwise, we cannot reject the null hypothesis. All calculations are performed using the \u201cperm\u201d package of the R statistics software environment.\n\nWe provide a high level description of our Iterative HFold algorithm.\n\nPseudocode of our Iterative HFold algorithm is available in Additional file 1. The algorithm builds on two simpler methods, the first being our original HFold algorithm [48]: \nHFold:\n Given an RNA sequence, S, and a pseudoknot-free input structure, G, find a pseudoknot-free structure, G\u2032 such that G\u222aG\u2032 is the lowest energy structure that contains G. We note that G\u222aG\u2032 might not be pseudoknotted.\n\nThe second method on which Iterative HFold builds, called HFold-PKonly, is similar to HFold except that G\u2032 may only contain base pairs that cross base pairs in G. The prediction provided by HFold-PKonly can be useful in cases where HFold does not produce a pseudoknotted structure. \nHFold-PKonly:\n Given an RNA sequence, S, and a pseudoknot-free input structure, G, find a pseudoknot-free structure, G\u2032 such that every base pair in G\u2032 crosses some base pair of G and such that G\u222aG\u2032 is the lowest energy structure that contains G among all such G\u2032s. Note that G\u2032 may contain no base pairs.\n\nIterative HFold also uses the SimFold RNA secondary structure prediction method [63], which predicts the minimum free energy pseudoknot-free secondary structure for a given RNA sequence. SimFold uses a dynamic programming method similar to Zuker\u2019s MFold method [64]. In this work we used the HotKnots energy parameters when running SimFold. In addition to an RNA sequence, S, SimFold can also take a pseudoknot-free secondary structure, G, as input and predict the MFE pseudoknot-free secondary structure that contains all base pairs of G.\n\nIterative HFold is distinguished from the above three methods, namely HFold, HFold-PKonly and SimFold, in two important ways. First, the output of HFold, HFoldPKonly and SimFold methods must contain the given pseudoknot-free input structure, G, whereas Iterative HFold may modify the input structure. This can be useful when the given input structure is not a high-accuracy estimate of Gbig, the true pseudoknot-free substructure of the reference structure. Second, while HFold and HFold-PKonly can add base pairs that cross those in G, they cannot add base pairs that cross each other, and neither can SimFold. In contrast, Iterative HFold can add base pairs that cross each other. This is particularly useful when the input structure contains limited information about Gbig, and so it is necessary both to predict base pairs in Gbig and in Gsmall in order to get a good prediction.\n\nIterative HFold is comprised of four different iterative methods. Following the description of each method, we motivate why we chose to include it as part of our overall algorithm. Iterative HFold takes as input both an RNA sequence, S and a pseudoknot-free secondary structure, G; later we show that structure G can be produced by computational methods, for example, HotKnots hotspots or SimFold suboptimal structures, when only the sequence S is initially available. \nIterative HFold:\n Given an RNA sequence, S, and a pseudoknot free input structure, G, run the following four methods and pick the structure with the lowest free energy among these four as the output structure.\n\nIterative HFold runs in O(n3) time, as it runs four methods sequentially, when each one is O(n3). \n\nMethod 1: Run HFold on S and G, and store the resulting G\u222aG\u2032.\n\nMotivation: This is the core HFold method, motivated by the hierarchical folding hypothesis.\n\nMethod 2: First run HFold-PKonly on S and G. If HFold-PKonly results in a structure G\u222aG\u2032 such that G\u2032 is not the empty structure, then run HFold with sequence S and structure G\u2032, and store the result. Otherwise, simply store G as the result. See the following example. (We note that running HFold with S and G\u2032 results in a structure G\u2032\u222aG\u2032\u2032, where it may be the case that G\u2032\u2032\u2260G (i.e., G may not be part of the result of method 2).)\n\nMotivation: When input structure G does not agree with the reference Gbig structure, it may still be the case that HFold-PKonly finds the pseudoknotted structure Gsmall (or a good approximation to Gsmall). A call to HFold with input Gsmall may then find a better approximation to Gbig.\n\nExample 1: Example of results of method 1 and method 2 of Iterative HFold. \n\n In this example, method 2 of Iterative HFold outperforms method 1: although both HFold and HFold PKonly produce the same result on sequence S and input structure G, namely the structure G\u222aG\u2032, the additional iteration in method 2, in which HFold is run with S and G\u2032, finds a structure with lower energy than that of G\u222aG\u2032.\n\nMethod 3: First run SimFold on S and G to obtain result G\u2032\u2014a pseudoknot-free structure that contains G. Then let Gupdated be the secondary structure of S containing the relaxed stems of G\u2032 that include the base pairs of G. By a relaxed stem, we mean a secondary structure containing stacked base pairs, bulges of size 1 and internal loops of maximum size of 3 (i.e., either the symmetric loop of 1\u00d71 or the non-symmetric loop of 1\u00d72 or 2\u00d71 but no other loop types; this is motivated by common practice [65]). Then run method 2 on S and Gupdated, and store the result. See Example 2.\n\nMotivation: This method can work well when the given input structure has a small number of base pairs from Gbig, because Gupdated contains stems that includes these base pairs, but avoids \u201covercrowding\u201d with further base pairs that might prevent HFold-PKonly from finding pseudoknotted stems.\n\nExample 2: Example of result of method 3 compared to all four methods of Iterative HFold. \n\n In this example, method 3 of Iterative HFold outperforms the other methods. Because the input structure G consists of just one base pair, method 1 (HFold) outputs a pseudoknot-free structure containing G. The output of both methods 2 and 4 are pseudoknotted but do not contain the base pair of the input structure G. In contrast, method 3 first adds base pairs to G, resulting in the pseudoknot-free structure Gupdated, and then adds additional pseudoknotted base pairs via method 2.\n\nMethod 4: Let S1 be the subsequence of S obtained by removing bases that are external unpaired bases with respect to input structure G. Run SimFold on S1 and G (with base indices renumbered to agree with S1), to obtain pseudoknot-free structure G\u2032. Then continue exactly as in method 3. See Example 3.\n\nMotivation: This method is very similar to method 3, but further constrains G\u2032 since the base pairs in G\u2032 cannot involve bases that are removed from S to obtain S1. This potentially increases the possibilities for pseudoknotted base pairs to be added by method 2.\n\nExample 3: Example of result of method 4 compared to all four methods of Iterative HFold. \n\n In this example, method 4 of Iterative HFold outperforms the other methods. The input structure G has a high energy value and neither method 1 (HFold) nor method 2 (HFold-PKonly) can expand the pseudoknot-free structure to add the pseudoknotted stem. Also, by adding too many pseudoknot-free base pairs, method 3 fails to find the pseudoknotted base pairs. Thus, method 4 performs better than methods 1, 2 and 3.\n\nOne of our goals is to understand the degree to which our methods are robust with respect to partial information, that is, provide a reliable prediction even when limited information about the true pseudoknot-free structure, Gbig, is available. For this purpose we generate subset structures of the corresponding Gbig, for each RNA sequence in the HK-PK and HK-PK-free data sets. For each \u03b1, 0.05\u2264\u03b1\u22640.95 with 0.05 steps, we choose each base pair of Gbig structure with probability \u03b1. We also generate 1% information and 99% information about the Gbig structure (i.e., \u03b1=0.01 and \u03b1=0.99). We repeat this step 100 times to generate 100 substructures of Gbig for each value of \u03b1 for each RNA sequence in our data sets. We then run our methods on all 100 substructures for each RNA sequence in our data sets and \u03b1 value and calculate the bootstrap 95% percentile confidence interval for average F-measure of these 100 cases as the accuracy interval for each method and each RNA sequence and \u03b1 value in our data set.\n\nWe also compare our methods when the true pseudoknot-free structure, Gbig is provided.\n\nHotKnots is a heuristic program that given an RNA sequence, first finds about 20 lowest energy stems (from the set of all stems for the given RNA sequence), called hotspots. Then keeping all these stems, it adds other non-overlapping low energy stems to the stems found in the first step, so as to minimize the energy of the overall structure, eventually producing up to 20 output structures. In our experiments, we choose the structure with the lowest energy value among the 20 output structures as the final structure predicted by HotKnots. When reporting prediction accuracy for HotKnots, we report the bootstrap 95% percentile confidence interval for the average F-measure of the lowest energy structure for all RNA sequences in our data set.\n\nIPknot is a secondary structure prediction method based on Maximum Expected Accuracy (MEA) of the base pairs. In addition to the RNA sequence, IPknot gets several parameters as input. Following, we describe each of these parameters and settings briefly. \n\n\u2022level: If structure G can be decomposed into k disjoint pseudoknot-free structures, G1,G2,\u2026,Gk, such that every base pair in Gi crosses the base pairs of Gj, 1\u2264i\u2264j\u2264k, Sato et al. say that structure G has k levels. For example, a pseudoknot-free structure has level 1, and an H-type pseudoknot has level 2. In another example, when representing the secondary structure in dot bracket format, the number of different brackets used to represent the structure is the level of the structure. IPknot can handle structures up to level 3.\n\n\u2022scoring model: The energy model used to produce posterior probabilities for each base pair is called \u201cscoring model\u201d. IPknot has 3 different scoring models, namely \u201cCONTRAfold\u201d, \u201cMcCaskill\u201d and \u201cNUPACK\u201d.\n\n\u2022refining parameters: The procedure of recalculating the base pair probabilities based on the original prediction results is referred to as \u201crefining parameters\u201d.\n\n\u2022base pair weights for each level: Positive numbers representing the rate of true base pairs in each level.\n\nWe run IPknot using the provided source code and the default parameters for scoring model and level (i.e., scoring model = McCaskill and level =2). The default values provided for base pair weights are not the same on the IPknot website (i.e., \u03b31=2 and \u03b32=16), its source code (i.e., for some cases \u03b31=2 and \u03b32=4 and for others \u03b31=1 and \u03b32=1) and the provided perl script (i.e., \u03b31=4 and \u03b32=8). We run IPknot with all of these values with and without refinement and provide IPknot\u2019s bootstrap 95% confidence intervals for average F-measures for all of our data sets as a table in the Additional file 2. Based on its performance we present IPknot\u2019s results with default settings (i.e., no refinement, scoring model = McCaskill and level =2) and \u03b31=4 and \u03b32=8, for comparison with other methods.\n\nWe compare the average accuracy of HFold, HFold-PKonly and Iterative HFold with different input structures.\n\nTo determine which input structures are good to use when Gbig is not known, we compare two different options. Since HFold (HFold-PKonly and Iterative HFold) cannot accept pseudoknotted input structures we use the following methods to produce pseudoknot-free input structures to HFold (HFold-PKonly and Iterative HFold). First, we use HotKnots hotspots [36], i.e., the 20 lowest energy pseudoknot-free stems produced in the first phase of HotKnots. We choose the lowest free energy structure predicted by each of our methods as their final prediction given these hotspots. Second, we use SimFold\u2019s MFE structure [63] where the energy parameters of SimFold are changed to match that of HotKnots V2.0.\n\nWe ran all methods on the same platform (Macbook pro. OS X 10.5.8 with 2.53 GHz Intel Core 2 Duo processor and 4 GB 1067 MHz DDR3 RAM). We use the time command to measure the running time of our methods on each sequence, and record the wall clock time.\n\nTo find the memory usage of the programs, we use the Valgrind package [66] and record the total heap usage as memory usage of each program. IPknot and HotKnots are completely written in C and so we can easily find their memory usage by running Valgrind. However, Iterative HFold program is a perl script that runs a few C programs (HFold, HFold-pkonly and SimFold) sequentially. So we find the memory usage of each C component using Valgrind and assign the maximum as the memory usage of Iterative HFold.\n\nOne of our goals is to learn what is the accuracy of each of our methods when partial information about Gbig is available (see Section \u2018Robustness test\u2019 for experimental settings). Figure 2 shows the results of this robustness evaluation, for pseudoknotted structures (Figure 2A), pseudoknot-free structures (Figure 2B) and the overall results (Figure 2C). Since HFold-PKonly cannot add pseudoknot-free base pairs to the given input structure, we do not compare its performance here with HFold and Iterative HFold. However we provide detailed performance of all versions of HFold including HFold-PKonly in Additional file 3.\n\nAs shown in Figure 2A, which pertains to pseudoknotted structures of the HK-PK data set, when provided with \u22481% of the Gbig structure as input, Iterative HFold\u2019s bootstrap 95% percentile confidence interval of average F-measures has higher accuracy than those of HFold. Iterative HFold continues to be significantly superior to HFold until approximately 90% of Gbig is available, after which HFold is more accurate. Iterative HFold is most successful when little information about Gbig is known because it can add both pseudoknot-free and pseudoknotted base pairs. In particular, using methods 3 and 4 (see Section \u2018Iterative HFold\u2019) Iterative HFold first finds a low energy pseudoknot-free structure that includes the given input structure (by extending the stems of the given structure), and then adds pseudoknotted base pairs to further lower the energy of the overall structure. However, when the vast majority of base pairs of Gbig are provided as input, HFold dominates as it keeps the base pairs of the input structure, thereby often adding base pairs of Gsmall. When 100% of Gbig is provided as input, HFold\u2019s bootstrap 95% percentile confidence interval is (85.74%,91.87%), compared with (79.36%,87.41%) for Iterative HFold.As shown in Figure 2A, Iterative HFold\u2019s average accuracy on pseudoknotted structures steadily increases from about 54% to 79% as the user provides 1% to 40% of the input structure. This improvement in accuracy slows down but still persists when further structural information is provided. If we compare the slope of the curve for Iterative HFold\u2019s average accuracy to that of HFold in Figure 2A, we can see that HFold\u2019s slope is steeper than that of Iterative HFold, making Iterative HFold more robust than HFold.\n\nFor pseudoknot-free structures of the HK-PK-free data set, as shown in Figure 2B, HFold performs better than Iterative HFold. Even with 1% information about Gbig, HFold results in (79.76%,84.32%)95% bootstrap confidence interval in comparison with (79.14%,83.84%) for Iterative HFold with the same inputs. Roughly, HFold\u2019s success for pseudoknot-free structures is because it often adds base pairs that do not cross those provided as part of the input, and thus are likely to be in Gbig.\n\nWhen 100% of Gbig is provided as input, the overall bootstrap 95% confidence interval for HFold is (96.11%,97.24%) compared with (93.85%,96.07%) for Iterative HFold.\n\nOften, partial information about Gbig is not available; this is the case for many RNAs of unknown function reported by the ENCODE consortium [24]. Therefore, we next compare the quality of results obtained by HFold, HFold-PKonly and Iterative HFold when given a pseudoknot-free input, G that is predicted by existing computational methods. One way to produce an input structure is to use an MFE pseudoknot-free structure prediction method, such as MFold. We chose SimFold as it is an implementation of MFold and, because of its energy parameters, gives more accurate predictions than MFold. Of course, when comparative information is available, the user can input such information as structural constraint as a pseudoknot-free structure to Iterative HFold and expect a better prediction result. Here we compare two methods for predicting G, namely SimFold and the hotspots produced by HotKnots V2.0. Table 2 reports the bootstrap 95% percentile confidence intervals of average F-measures. The accuracy of HFold-PKonly is significantly worse than that of HFold and Iterative HFold, both with the output of SimFold, and with the HotKnots hotspots as input, so we do not discuss HFold-PKonly further.\n\nFor pseudoknotted structures, using HotKnots hotspots as input is far superior to using SimFold as input, for both HFold and Iterative HFold. This appears to be because MFE structures predicted by SimFold tend to have more base pairs than the true pseudoknot free structure, Gbig, so that HFold and Iterative HFold are unlikely to add pseudoknotted base pairs to the input structure. For pseudoknot-free structures, using SimFold as input is somewhat better than using HotKnots hotspots, but the permutation test indicates that the difference is not significant.\n\nThe confidence intervals for HFold and Iterative HFold with HotKnots hotspots are (73.35%, 83.53%) and (72.83%, 83.37%), respectively, and on pseudoknot-free structures they are (75.53%, 80.79%) and (74.93%, 80.26%) respectively. Again, based on the result of the permutation test, the difference in the results of HFold and Iterative HFold on pseudoknotted and pseudoknot-free structures are not significant. Similarly, the permutation test shows that the difference in prediction accuracy of HFold and Iterative HFold on SimFold input is not significant.\n\nFor comparisons with other methods already in the literature, we choose to use our Iterative HFold method with HotKnots hotspots as input structure, based on its overall good accuracies in Section \u2018Accuracy comparison of different versions of HFold\u2019. We compare this method with two of the best-performing methods [44] for prediction of pseudoknotted structures, namely HotKnots V2.0 [36], a MFE-based heuristic method, and IPknot [42], a method that is based on maximum expected accuracy. (Prepared by Puton et al. [44], CompaRNA, is the website for continuous comparison of RNA secondary structure methods on both PDB data set and RNA strand. We chose IPknot because it was the best-performing non-comparative pseudoknot prediction method that can handle long RNA sequences, based on the ranking on their website as of March 25, 2014. We also noticed that Puton et al. used HotKnots V1 for their comparison, and not the more recently available and better performing HotKnots V2.0. Therefore we chose to include HotKnots in our comparisons as well. Since the focus of this paper is on prediction of pseudoknotted structures, we do not compare our results with that of Co-Fold [26] or other methods for prediction of pseudoknot free structures.)\n\nTable 3 presents the bootstrap 95% percentile confidence interval of average F-measure for Iterative HFold with hotspots as input, HotKnots V2.0, SimFold and IPknot with default setting (see Section \u2018Accuracy comparison tests\u2019) on the HK-PK and HK-PK-free data sets. For pseudoknotted structures, our permutation tests show that the difference in accuracy of Iterative HFold and HotKnots is not significant. However, the superior accuracy of Iterative HFold compared with SimFold and IPknot is significant. For pseudoknot-free structures, the difference in accuracy between IPknot, Iterative HFold, HotKnots and SimFold is not significant.\n\nTable 4 presents the bootstrap 95% percentile confidence interval for average F-measure for Iterative HFold (with hotspots as input), HotKnots and IPknot (with default setting) on the IP-pk168 and DK-pk16 data sets. Our permutation tests show that the difference in accuracy of Iterative HFold, HotKnots and IPknot on the DK-pk16 data set is not significant. However, the superior accuracy of Iterative HFold compared with HotKnots and IPknot on the IP-pk168 data set is significant.\n\nSince prediction of pseudoknotted structures are of interest to us, we only report running time comparison on pseudoknotted structures of our HK-PK data set. Figure 3 presents result of time comparison between Iterative HFold and HotKnots in a log plot (when log is in base 10). The X axis shows log(time) for HotKnots data points and the Y axis shows log(time) for Iterative HFold on the HK-PK data set. RNA sequences in this data set are between 26 and 400 bases long. HFold runs significantly faster than HotKnots and finishes under 1.5 seconds for even the longest RNA sequence in our data set (400 bases). HotKnots is faster than Iterative HFold on sequences of up to 47 bases, where Iterative HFold starts being faster than HotKnots. Iterative HFold runs in less than 8.3 seconds for all RNA sequences in this data set whereas HotKnots runs for over 6000 seconds (about 1.7 hours) on the longest RNA sequence in our data set. The running time of both HFold and Iterative HFold grows with sequence length, whereas HotKnots\u2019 running time is not directly correlated with RNA length. For example, HotKnots runs for 1665.94 seconds for one RNA sequence of length 195 (ASE-00360), while it runs for 203.12 seconds for another RNA sequence of length 195 (ASE-00131).\n\nIPknot is significantly faster than both HFold and Iterative HFold. For all sequences in this data set, IPknot produces output in less than 0.8 seconds. For detailed information about performance of each method see Additional file 4.\n\nHere we present memory consumption of HFold, Iterative HFold and HotKnots on our HK-PK pseudoknotted structures. Since HotKnots predicts and keeps about 20 structures in memory, its memory consumption can vary significantly from one sequence to another, and is not predictable. Up until 47 bases, HotKnots some times uses less memory than HFold or Iterative HFold, but for RNA sequences with 47 bases or longer, HotKnots uses much more memory than HFold and Iterative HFold. Iterative HFold\u2019s memory usage is very similar to HFold\u2019s and increases at a very low rate by the length of the RNA sequence. It starts from 48.69 MB for RNA sequences of length 26 and increases to 61.33 MB for the longest RNA sequence in this data set (400 bases long). HotKnots, however, uses as little as 16.53 MB for an RNA of length 30 bases (LP-PK1) and as much as 93419 MB for the longest RNA sequence in this data set.\n\nIPknot uses much less memory than all other methods. For the longest RNA sequence in this data set, IPknot uses less than 5.5 MB of memory in comparison to 61.33 MB of HFold and Iterative HFold and 93419 MB of HotKnots. For detailed information about memory usage of each method see Additional file 4.\n\nComparing accuracy of Iterative HFold and HotKnots V2.0 on HK-PK, HK-PK-free, DK-pk16 and IP-pk168, we found that the difference in their accuracies is insignificant on HK-PK, HK-PK-free and DK-pk16 data sets when Iterative HFold is provided with HotKnots hotspots as input. Based on our results on the HK-PK data set, with only about 15% information about the true pseudoknot-free structures, Iterative HFold\u2019s 95% percentile confidence interval is (65.08%;73.36%) (data shown in Additional file 3). If the user has about 35% information about the true pseudoknot-free structure, Iterative HFold\u2019s accuracy is comparable with that of HotKnots (i.e., (74.18%;82.30%) vs. (73.60%;83.35%)). However Iterative HFold\u2019s accuracy (with hotspots as input) is significantly better than that of HotKnots on the IP-pk168 data set. One of the advantages of Iterative HFold over HotKnots is that in Iterative HFold base pairs are added to lower the energy of the given structure while in HotKnots stems are added in a way that does not take into account the energy of stems in the previous steps.\n\nWhen reporting on time and memory consumption of Iterative HFold and HotKnots on the HK-PK data set, we did not include the time and memory required to get the input structures to Iterative HFold. Since we only run HotKnots V2.0 partially to produce hotspots it does not take as long as running HotKnots and does not consume as much memory. For example, for the 400 nucleotides long RNA sequence in our data set (A.tum.RNaseP), it only takes 0.5 seconds time and 4 MB of memory to produce the hotspots. (The time required to get the hotspots for all RNA sequences in this data set is provided in Additional file 4.) We also note that since calculating hotspots and running Iterative HFold are done sequentially, the memory consumption is calculated as the maximum of the two, so the memory consumption of Iterative HFold for this sequence is still the same even including the memory needed for calculating hotspots. As we can see based on this example, even including time and memory requirements of calculating hotspots, Iterative HFold is still faster than HotKnots and uses less memory.\n\nWe also compared Iterative HFold with IPknot [42]. While IPknot is faster than Iterative HFold and uses less memory, we found that for the HK-PK and IP-pk168 data sets, Iterative HFold provides significantly more accurate predictions of pseudoknotted structures, compared with IPknot. Based on our results on the HK-PK data set, Iterative HFold\u2019s performance with more than 5% information about the true pseudoknot-free structure, is better than that of IPknot with default settings (data shown in Additional file 3). We note that Sato et al. [42] find the performance of IPknot with predictions using \u201cNUPACK\u201d superior to all versions of IPknot, but since this model can be used for RNA sequences of length <80 nucleotides, we did not compare our results with this version of IPknot. Among all different versions of IPknot we tested, we found all but \u03b31=1 and \u03b32=1 setting producing similar confidence intervals for all but the HK-PK-free data sets, for which \u03b31=4 and \u03b32=8 produces the best result (data shown in Additional file 2). While running parameter refinement with one iteration improved the confidence intervals in the HK-PK data set, it did not result in any improvement in accuracy in the rest of our data sets as in many cases IPknot failed to produce results. We note that our results on the IP-pk168 data set with different weight parameters perfectly match the results of Sato et al. [42].\n\nA disadvantage of IPknot over Iterative HFold is that being an MEA-based method, IPknot does not produce free energy of the predicted structure. Also to get the best prediction, the user needs to provide some guidance as to what type of structure to predict for the given sequence, e.g., whether pseudoknot-free or pseudoknotted.\n\nSimilar to HotKnots, the ShapeKnots method of Hajdin et al. [47] is a heuristic algorithm for prediction of pseudoknotted structures. This method incorporates SHAPE reactivity data as a pseudo energy term into the prediction method. SHAPE reactivity data is only available for a limited number of RNA sequences, so we cannot compare Iterative HFold with ShapeKnots on our data set. Therefore, we use data set of Hajdin et al. to compare these two methods. In their data set Hajdin et al. have 18 RNA sequences in their training set and 6 RNA sequences in their test set. We run Iterative HFold with hotspots for each RNA sequence and choose the lowest energy structure as the final output of our program. For Shapeknots, we use the sensitivity and positive predictive values reported in the work of Hajdin et al. [47] to compare with Iterative HFold. Table 5 shows the results of this comparison. In all but one sequence of the test set, Iterative HFold obtains higher accuracy than ShapeKnots. The exception is the HIV-1 5\u2019 pseudoknot domain; Hajdin et al. note that the accepted structure of HIV-1 5\u2019 pseudoknot domain is based on a SHAPE directed prediction and thus an accuracy comparison between ShapeKnots and Iterative HFold may be biased towards ShapeKnots. In the training set, however, Iterative HFold does not perform as well as ShapeKnots. This might be because parameters of ShapeKnots were tuned on the training set to achieve the highest possible accuracy. Since both the training and test data sets are small, we cannot make more general statements about the significance of the differences in accuracy between the two methods.\n\nTo further investigate which input structures are good to use when Gbig is not known, we use the first 50 suboptimal structures produced by SimFold (including the MFE structure). Then for each RNA sequence we run our methods on all 50 suboptimal structures and choose the one with the lowest free energy as the final result for that RNA sequence. With this approach, the bootstrap 95% percentile confidence interval of average F-measure of HFold and Iterative HFold is (61.80%, 80.63%) and (67.70%, 79.57%) respectively for pseudoknotted structures and (77.17%, 82.35%) and (76.27%, 81.46%) respectively for pseudoknot-free structures. The permutation test indicates that the difference between these results and the corresponding results when input structures are hotspots is not significant. We also test the significance of results of HFold with first 50 suboptimal structures versus Iterative HFold with the same input structures and Iterative HFold with hotspots for both pseudoknotted and pseudoknot-free structures. Although the bootstrap 95% percentile confidence intervals for average F-measures seem different, the permutation test indicates that the difference is not significant. Similarly, results of Iterative HFold with the first 50 suboptimal structures are not significantly better or worse than the result of HFold with hotspots as input structures for both pseudoknotted and pseudoknot-free structures.\n\nIn this paper we use the HotKnots V2.0 DP09 [36] energy parameters in our implementation of Iterative HFold. To investigate the degree to which the energy model may be causing mis-predictions by HotKnots V2.0 or Iterative HFold, we considered the degree to which the maximum accuracy structures produced by these methods, i.e., the structure with highest F-measure, is better than the minimum free energy structures. Table 6 presents the difference in bootstrap 95% percentile confidence intervals of average F-measure. If we choose the maximum accuracy structure among the 20 output structures predicted by HotKnots for each RNA sequence, the bootstrap 95% percentile confidence intervals of average F-measure of HotKnots will increase to (84.50%, 91.48%) for pseudoknotted structures of the HK-PK data set (vs. (73.6%, 83.35%) when choosing the lowest energy structure) and (88.32%, 91.08%) for pseudoknot-free structures of the HK-PK-free data set (vs. (76.74%, 81.95%) when choosing the lowest energy structure).\n\nSimilarly, if we compare the maximum accuracy structure output by Iterative HFold with the minimum free energy structure, whether given HotKnots hotspots or the first 50 suboptimal structures to Iterative HFold as input, the bootstrap 95% percentile confidence intervals of average F-measure also show improvement - see Table 6. The difference in improvements is significant in all but one case, namely Iterative HFold on hotspots structures as input for pseudoknotted structures of the HK-PK data set. We conclude that improvements on the energy parameter values for pseudoknotted structures may further improve accuracy of both HotKnots and Iterative HFold.\n\nIn this work we present Iterative HFold, a fast and robust iterative algorithm that matches the accuracy of the best existing pseudoknot prediction methods. Iterative HFold is significantly more accurate than IPknot while matching the accuracy of HotKnots on the HK-PK data set. Iterative HFold is superior to both IPknot and HotKnots on the IP-pk168 data set. Moreover both Iterative HFold and IPknot use less memory and run much faster than HotKnots on long sequences.\n\nIterative HFold also has lower rate of accuracy deterioration than HFold with loss of information about the true pseudoknot-free structure, so it is more robust than HFold. This is particularly helpful when the given input structure may be unreliable and/or limited information about the true pseudoknot-free structure is available. Iterative HFold is also more accurate than ShapeKnots [47] on the test set of Hajdin et al. [47].\n\nIn this work, we compared two different ways to generate pseudoknot-free input structures for input to Iterative HFold, namely the first 50 suboptimal structures produced by SimFold, and HotKnots hotspots. On the HK-PK and HK-PK-free data sets, accuracy of Iterative HFold is not significantly different on each of these. An alternative approach that may be worth exploring in future work would be to use the most highly probable base pairs, as calculated using the partition function [43]. Even better may be to calculate base pair probabilities for base pairs of pseudoknotted RNA structures; however this requires \u0398(n5) time. Since HFold finds minimum free energy structure in O(n3) time, conditional on the given input structure, we are currently investigating ways to develop an O(n3)-time partition function version of HFold that can produce pseudoknotted base pair probabilities that are conditional on the given input structure.\n\nComparing accuracy of the minimum free energy structures with the maximum accuracy structures in this work, we found that, on average, the minimum free energy structure has significantly poorer F-measure than the maximum accuracy structure. This suggests that an improved energy model for pseudoknotted structure prediction may improve accuracy of prediction algorithms for pseudoknotted structures.\n\nAnother direction for future work can be to use Iterative HFold for structure prediction of two interacting RNA molecules. Iterative HFold may be well suited for this purpose because, given input structures for each individual input molecule, it allows for modification of these input structures as it explores potential base pairing interactions between the two molecules.\n\nIterative HFold and all data used in this work are freely available at http://www.cs.ubc.ca/~hjabbari/software.php.\n\nThe authors declare that they have no competing interests.\n\nHJ designed and implemented the algorithms, acquired, analyzed and interpreted the data and drafted the manuscript. AC supervised the research, participated in analysis of data and in revising the manuscript. Both authors read and approved the final manuscript."}