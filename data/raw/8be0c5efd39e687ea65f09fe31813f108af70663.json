{"title": "CSAX: Characterizing Systematic Anomalies in eXpression Data", "body": "T he development in the 1990s of techniques for genome-wide monitoring of expression data (Lockhart et al., 1996; Shalon et al., 1996) has had a dramatic impact on the field of molecular medicine. Precision diagnostics based on expression array signatures are increasingly moving into the clinic (Mehta et al., 2011; Glas et al., 2006) . However, methods for designing microarray-based diagnostics or discovering disease subtypes require a reasonable number of samples representing each patient class (Slonim, 2002) . There are techniques for boosting the signal when relatively few samples are available (Tusher et al., 2001; Dougherty, 2001) , but these don't eliminate the need for a representative set of samples that fully characterize the molecular variability underlying the phenotypes of interest. For rare diseases or genetically heterogeneous disorders, another analysis paradigm is needed. Here we demonstrate that by characterizing the expression patterns of ''normal'' samples, it is often possible to identify abnormal samples even when each abnormality is one-of-a-kind.\n\nThe problem of determining which samples to flag as abnormal, given only normal training data, is related to the computational field of anomaly detection, sometimes called outlier detection. Anomaly detection is an active research area in both statistics and data mining (Chandola et al., 2009) . It is regularly applied to such problems as spam detection, identifying potential credit-card theft, verifying online identities, and correcting errors in census data.\n\nSeveral previous efforts explicitly apply anomaly detection to bioinformatics problems, including correction in genome annotation (Mikkelsen et al., 2005) and identifying changes in the steady-state behavior of stochastic gene regulatory networks (Kim and Gelenbe, 2009) . A related approach by Torkamani and Schork (2009) identifies genes whose expression pattern is unusual in a given cellular context. For gene expression microarray data, the task of identifying differentially expressed genes has been viewed in the framework of outlier detection (Mpindi et al., 2011; Li et al., 2007; Ghosh, 2010; Karrila et al., 2011) , as has the problem of identifying array artifacts (Sauer et al., 2005) . Perhaps the closest approach to ours is that of Tomlins et al. (2005) , who use outlier detection to identify common translocations in cancer, but the outliers still refer to individual genes rather than samples.\n\nThe underlying machine learning problem, that of identifying ''abnormal'' samples given only ''normal'' samples as training data, is a challenging one. Microarray data is particularly ill-suited for anomaly detection, as for many other machine learning problems, because of its noise level, the dimensionality of a typical data set (hundreds of samples but tens of thousands of genes), and the expectation that only a small fraction of those genes may provide any information about the classification of the samples.\n\nFortunately, other characteristics make the problem potentially tractable. We expect meaningful expression changes to reflect unusual regulation in specific functional pathways. We can therefore use prior knowledge about the relationships between genes to identify anomalous examples. Such information has the added advantage that it may provide hints to the underlying cause of the detected anomalies.\n\nTo evaluate the utility of such an approach, we created a compendium of data sets for anomaly detection from published microarray classification data sets. On this compendium, we compare several state-of-theart methods for anomaly detection, including CSAX, a novel approach that we designed to boost the signal from the prior method most robust to irrelevant features (Noto et al., 2011) while identifying the gene sets that best distinguish each anomalous sample. Our results show that in many cases, anomaly detection can both identify unusual samples and produce meaningful information about the nature of the anomalous data.\n\nThere is also a question of what abnormalities we can expect to identify. For example, a single abnormal sample characterized by abnormal expression of a single gene could not possibly be detected by any method-the data are simply too noisy. Our method is applicable when a sizable number of genes' expression levels are sufficiently different. We characterize the classes of anomalies we can expect to detect, and we discuss how clinical intuition might be applied to identify anomalies suitable for these methods. Our inspiration for this work came from prenatal and neonatal genomics, where recognizing and interpreting rare developmental abnormalities is crucial. We therefore conclude with a case study illustrating how our methods can contribute in this setting.\n\nWe assembled a compendium of 28 anomaly detection tasks from published gene expression classification studies that involve at least two classes of samples (e.g., healthy vs. disease). We convert these to anomaly detection tasks by (i) designating one class as the ''anomalous'' class, and all samples from the other classes as the ''normal'' class, which may therefore be quite heterogeneous; (ii) creating a training set from a random subset of normal microarrays; and (iii) creating a test set from the remaining samples ( Fig. 1) . We created our compendium from suitably sized data sets with at least two clearly defined classes found in GEO, combined with a testbed of expression classification data sets assembled elsewhere for the development of computational methods (see Acknowledgments section). The compendium includes all the data sets with which we experimented that had previouly been released publicly (Supplementary Material, available online at www.liebertonline.com/cmb).\n\nIn most envisioned applications, such as diagnosing rare developmental disorders, abnormalities are likely to be one of a kind. However, in each data set in this compendium, we have a collection of relatively similar anomalies, and we know which samples we should expect to identify as anomalous. We therefore use this compendium as a ''gold standard'' data set to evaluate the accuracy of our methods.\n\n2.2.1. Prior methods. There are many existing methods for anomaly detection in high-dimensional data. The most successful general approaches include density-based methods such as the local outlier factor (LOF) (Breunig et al., 2000) , which identifies outliers by comparing their distances from their nearest neighbors to the typical distances between nearby training examples, and one-class support vector machines (SVMs) (Sch\u00f6lkopf et al., 2000) . To compare the approaches described below to one-class support vector machines (Sch\u00f6lkopf et al., 2000) , we use the LIBSVM (Chang and Lin, 2001) implementation with default settings. Preliminary investigation showed that results were not sensitive to a wide range of parameter settings (data not shown).\n\nTo compare our approach to LOF (Breunig et al., 2000) , we use our own implementation. LOF requires the specification of a single parameter, MinPts, which is the size of the neighborhood of microarrays. Following a suggestion in the original presentation of LOF (Breunig et al., 2000) , we compute the LOF using all possible values of MinPts and take the maximum LOF. Source code and documentation for our implementation can be found in the Supplementary Material. To create an anomaly detection task from a microarray study with two classes of samples, A and B, we randomly select a portion of the A samples for the test set and use the remainder for training. The task is then to identify samples from class B after training on samples from class A alone.\n\nNOTO ET AL.\n\nHowever, neither of these prior methods is especially well suited for handling the dimensions of expression microarray data. We recently developed an anomaly-detection method called feature regression and classification, or FRaC (Noto et al., 2010 (Noto et al., , 2011 . FRaC learns relationships among gene expression in the training data and measures their reliability. It uses those models to estimate the likelihood of test set expression. The extent to which a test set gene's expression is considered anomalous is measured by the log-loss of its likelihood, according to those models. Anomaly scores for samples are computed by summing anomaly scores over all genes. FRaC is known to be robust to large numbers of irrelevant variables (Noto et al., 2011) , making it well suited for identifying outliers in expression data.\n\nBecause FRaC forms the core of our new method below, we give a brief summary here. Given a training set and an unlabeled test example, FRaC does the following for all genes i:\n\n1. Infer a predictive model C i of the expression of gene i from the training data. The model will use the expression of some of the other genes to make its predictions. For this step, we use an e-SVR (support vector regression) model with a linear kernel, the e parameter (in the loss function) set to zero, and the C parameter (for regularization) set to 1. Preliminary experiments with expression anomaly detection showed that FRaC is not very sensitive to these choices, and these settings prove to work well (data not shown). 2. Use held-aside training data (i.e., not used in the previous step) to estimate the accuracy of the model by building a model E i of the predictive error. We use leave-one-out cross-validation to sample the predictive error, and we model E i as a normal distribution N (l\u201a r), where l and r are set to the sample mean and standard deviation, respectively. 3. Use the predictive model C i to predict the expression of gene i in the unlabeled example. 4. Compute the likelihood of the error of the prediction using the error model E i . 5. The anomaly score we assign to gene i is the log loss, or surprisal, of the likelihood computed in the previous step.\n\nThe anomaly score for the test sample is computed as the sum of the anomaly scores for each gene. We use our own implementation of FRaC; the source code and documentation are available in the Supplementary Material.\n\nA new method for expression anomaly detection. All of the above methods classify samples as outliers, but do not explicitly provide information about the nature of each anomaly. Instead, our goal is to identify gene sets or pathways in which a sample is particularly anomalous. We therefore developed a robust method, Characterizing Systematic Anomalies in eXpression data (CSAX), for doing so, taking advantage of FRaC's robustness to irrelevant variables.\n\nCSAX uses FRaC to compute an anomaly score for each gene and uses Gene Set Enrichment Analysis (GSEA) (Subramanian et al., 2005; Mootha et al., 2003) to find gene sets containing many genes whose expressions are particularly surprising. GSEA is implemented in Java and available Online. We use the Java archive (gsea2-2.07.jar) and run the ''preranked'' version of GSEA (xtools.gsea .GseaPreranked) on gene sets with at least 7 and at most 500 genes, with 1000 permutations and a weighted scoring scheme (see GSEA documentation). GSEA in this case takes as input a list of genes, ranked by their anomaly scores, and a collection of gene sets. The output of GSEA is a table, listing each gene set, its enrichment score (see Subramanian et al., 2005; Mootha et al., 2003, for details) , and other statistics, including a normalized version of the enrichment score that accounts for gene set size.\n\nThis approach alone, which we call FRaC + enrichment, has the important advantage of identifying the gene sets that may best explain an anomaly, one of the primary goals of our research. However, applying this method to test set microarrays that come from the normal class will also identify gene sets that are statistically enriched, even though these sets are effectively random and depend on how accurately the training set represents the true distribution of the normal class. Specifically, when the training set is too small to capture the full diversity of the normal sample space, there will be false positive results. For the envisioned applications, we need to better distinguish the results characterizing normal test samples from those characterizing anomalies.\n\nWe therefore use bagging to address this effect: over multiple iterations, we take a random subset of the training set and run FRaC and GSEA on it. This process produces multiple GSEA enrichment rankings for each gene set. The gene sets that best explain a true difference between an unlabeled microarray and the training set will appear at or near the top of GSEA's ranked list over multiple iterations of bagging, whereas CHARACTERIZING ANOMALOUS EXPRESSION the gene sets that are only enriched because their genes are misrepresented in the training set (because of the small sample size) are less likely to do so.\n\nThe remaining challenges are to select the informative gene sets from the GSEA output lists and to combine their enrichment scores into a single anomaly score. A single gene set may not be enough by itself to fully characterize an anomaly, so we must consider multiple gene sets, but we only want the most informative ones-those that are ranked highly in GSEA's output tables. The method that we use first considers the collection of rankings for each gene set and computes its median; for example, if a gene set appears in the #1 position more often than not, its median rank will be 1.\n\nFormally, let G be our collection of G gene sets, and B be the number of bagging iterations. Let r b (g) be the ranking (i.e., 1\u201a 2\u201a . . .) of gene set g in the bth iteration of bagging, as ranked by GSEA (the ranked position is a function of enrichment score and gene set size). Let V (g) be the median of all the rankings of gene set g, that is,\n\n(1)\n\nWe consider the gene sets with the best median rankings (lowest values of V) to be the most informative ones. Let M be the G gene sets in G, ordered by their median ranking V, that is, M 1 is the gene set g with the lowest V (g), and\n\nWe also run FRaC and GSEA on the entire training set (as opposed to the iterations of bagging). Let ES(g) be the enrichment score calculated by GSEA for gene set g on the full training set. We define ES(g) = 0 for any gene set g that does not appear in the table.\n\nTo compute an anomaly score, we combine the enrichment scores of each gene set, discounted by their position in M as\n\nThe single parameter c controls how many of the highest-ranking gene sets are included in the computation of the anomaly score, and, by extension, how many genes influence the predictions.\n\nIn our experiments, we set c = 0.95. Overall, we observe similar performance for different values of c (results displayed in Supplementary Materials online). In our experiments, we perform B = 40 iterations of bagging and use the G = 1, 079 reactome pathways as gene sets (Croft et al., 2011) , except where noted. Source code and documentation for CSAX can be found in the online Supplementary Material.\n\nThe goal of any anomaly detection approach is to assign a high anomaly score to unlabeled samples that are not in the normal class. To measure the success of each anomaly detection method on a compendium data set, we construct a receiver operating characteristic (ROC) curve (Spackman, 1989) from the test set labels (normal or anomalous) and the method's predicted anomaly scores and calculate the area under the curve (AUC). The AUC can be viewed as the likelihood that an anomaly detector assigns a higher anomaly score to a test set anomaly than it does to a test set normal. Thus, higher AUCs are better, the best possible score being 1.0. The AUC is a common performance measure that is independent of both the number and proportion of anomalies in the test set.\n\nFor each data set in our compendium, we create an anomaly detection task (section 2.1) by randomly selecting 75% of the normal samples for training. The remaining 25% of the normal sampless and all anomalous samples make up the test set. We repeat this process 20 times and report an average AUC for each anomaly detection method for each data set.\n\nWe compare the performance of CSAX to that of two top-performing anomaly detection methods: local outlier factor (LOF) (Breunig et al., 2000) and one-class support vector machines (SVMs) (Sch\u00f6lkopf et al., 2000) . We also compare against the performance of our own method, FRaC (Noto et al., 2011) , as well as to a method consisting of performing enrichment analysis on genes ranked by their FRaC scores (which we call FRaC + enrichment), but without the bagging and weighting components of CSAX.\n\nNOTO ET AL.\n\nTo further demonstrate the utility of CSAX, we applied it to two developmental data sets. One is a collection of published expression data (Pietrzyk et al., 2013) from the blood of infants born below 32 weeks' gestational age. In this data set, the ''abnormal'' samples came from infants who developed bronchopulmonary dysplasia, retinopathy of prematurity, periventricular leukomalacia, or any combination of these; the controls were infants born at the same ages but whose clinical course did not include any of these three complications of preterm birth.\n\nThe second set combines data from several of our own studies of gene expression in second trimester amniotic fluid supernatant samples (Koide et al., 2011; Slonim et al., 2009; Hui et al., 2012 Hui et al., , 2013 Edlow et al., 2014; Massingham et al., 2014) . The abnormal samples include those from fetuses with trisomy 18, trisomy 21, Turner syndrome, twin-twin transfusion syndrome, or obese mothers; the controls are all control samples from these same studies.\n\nOur team recently created the DFLAT gene set collection (Wick et al., 2014) , a project in which we assembled developmentally relevant gene annotation using the Gene Ontology framework (Blake et al., 2012) , specifically for the purpose of interpreting gene expression data from fetal and neonatal samples. Here we used CSAX with the DFLAT gene sets to analyze these two studies of fetal and neonatal expression.\n\nThe AUC scores of CSAX, FRaC, FRaC + enrichment, LOF, and SVMs on our compendium are shown in Table 1 . Each of the methods performs best on some data set. If we average the AUC scores over all the data sets, FRaC and CSAX are tied for the best performance. Overall, FRaC has the highest AUC (or is tied for highest AUC) on the largest number of data sets (14). Yet none of FRaC, SVMs, or LOF directly implicates specific gene sets as contributing to the identification of anomalous samples. (FRaC + enrichment does identify gene sets, but the gene sets implicated by FRaC + enrichment are not necessarily the same as those identified by CSAX. Furthermore, anomaly detection accuracy is better with CSAX than with FRaC + enrichment on average and on 19 of 28 compendium data sets.) CSAX also performs well and identifies the gene sets that are most surprisingly dysregulated. These can provide valuable information about the pathways disrupted in the anomalous samples.\n\nFor example, the ''bild'' data set consists of human mammary epithelial cells in which exogenous oncogenes (either myc, ras, E2F3, b-catenin, or src) are expressed. The src pathway was selected as the anomalous class for the compendium because it had the fewest samples. CSAX's most anomalous pathway across all src samples is ''NCAM signaling for neurite out-growth,'' with a median rank of 2, meaning that this pathway was ranked either first or second in at least half the bagging trials. The next two top pathways, both with median rank 3, were ''Signaling by FGFR'' and ''Downstream signaling of activated FGFR.'' FGFR signaling is mediated by src (Sandilands et al., 2007) . NCAM binds to FGFR-1, and its role in cell migration depends on both FGFR-1 and src activation (Francavilla et al., 2009) , showing that src activation in the anomalous samples produces anomalous gene sets reflecting the direct effects of src expression. These low median rank scores suggest that there is remarkable consistency across the different test samples.\n\nAs another example, the ''leukemia'' data set distinguishes between acute myeloid (''normal'') and acute lymphoblastic leukemia (''anomalous'') samples. The top gene set identified by CSAX, with a median rank of 5, is ''Regulation of signaling by CBL.'' CBL, an oncogene known to be translocated or mutated in many acute myeloid leukemias, has more recently been discovered to play a broader role in many myeloid neoplasms (Kales et al., 2010) .\n\nThe variation in performance across the compendium seems to depend strongly on characteristics of individual data sets. For example, on the ''leukemia'' data, where differential expression is known to be substantial and widespread, all five methods perform well, while on the ''diabetes'' data set, known to have only subtle expression differences between the normal and anomalous classes (Mootha et al., 2003) , all methods perform poorly. We would like the ability to predict which anomalous expression patterns should be detectable by these methods. Accordingly, we sought to characterize the difficulty of each compendium data set.\n\nWe found no reliable way to characterize the difficulty of a data set using only the training data. Given our compendium of gold-standard data, however, we can still learn about characteristics of solvable problems using what we know about the test data. We can then apply this information to help us predict the utility of anomaly detection in applications where we don't know the right answer.\n\nWe discovered that the ratio between the median distance separating the training data from an anomalous example and the median distance between the training data and a test-set normal example is an excellent predictor of the eventual performance of an anomaly detector, regardless of which anomaly detector we use. We refer to this measure as the relative anomaly aggregate distance (RAAD). Formally,\n\nwhere X is the training set, Q a are the test set anomalous instances, Q n are the test set normal instances, and jxqj indicates the vector distance between a training and test set instance (i.e., each gene's expression is one component of a high-dimensional vector). We use the l 1 norm (''Manhattan'' distance) when computing vector distance because it is intuitive-the total distance is the sum of differences in gene One-class SVMs (Sch\u00f6lkopf et al., 2000) , LOF (Breunig et al., 2000) , FRaC (Noto et al., 2011) , FRaC + enrichment (as defined in the text), and CSAX. A different random subset of the normal class is chosen as the training data for each replicate. ''Best AUC'' shows a count of the number of data sets in which the method has or is tied for the highest AUC of the five (shown in boldface). ''Average AUC'' averages the AUC scores over all the data sets for that method. We also include the RAAD score for each set (see section 3.2).\n\nNOTO ET AL.\n\nexpression between two microarrays. The scatterplot in Figure 2 shows the relationship between RAAD and performance using FRaC. In real applications, where the test data labels are unknown, clinicians' intuition about the degree of expression variation one might expect among the normal class and among the types of envisioned anomalies can be used to estimate whether anomaly detection methods are likely to be helpful. Further, a small test set can be used to estimate the RAAD score, helping to determine the value of obtaining and analyzing additional samples.\n\nWe applied CSAX to the developmental data sets described in section 2.4. The RAAD scores for the preterm and amniotic fluid data sets were 1.045 and 0.98, respectively. We therefore suspected that it would be impossible to predict abnormalities accurately given the normal amniotic fluid data, and that the presence of preterm complications could be predicted with only moderate accuracy. This hypothesis proved correct. The preterm data set had a CSAX AUC of 0.606 (compared to 0.580, 0.498, and 0.574 with LOF, SVM, and FRaC, respectively); the amniotic fluid data, a CSAX AUC of 0.534 (compared to 0.572, 0.534, and 0.540 with LOF, SVM, and FRaC, respectively). Yet despite the limited overall prediction accuracy, we found the gene sets CSAX highlighted for individuals or groups of samples to be very informative. 3.3.1. Blood from preterm neonates. Only a single neonatal sample had retinopathy of prematurity (ROP) but no other complications. The top gene sets in this sample, with median ranks of 1 and 2 respectively, were ''platelet degranulation'' and ''platelet activation.'' ROP, which can lead to vision defects and even blindness, is caused by disordered retinal vascularization. There is an ongoing debate in the literature about whether platelets play a role in the pathogenesis of ROP and what that role might be ( Jensen et al., 2011; Vinekar et al., 2010) . Our observation of disrupted expression relationships among genes involved in platelet activation in an individual with ROP may provide valuable evidence about the molecular mechanisms of this process. Our samples also included 14 infants with periventricular leukomalacia (PVL), a type of ischemic brain injury that can lead to cerebral palsy. Glutamate-mediated defects in calcium signaling play a significant role in oligodendrocyte damage in PVL (Butt, 2006) and offer the potential for protective therapeutic intervention (Follett et al., 2004) . CSAX highlighted dysregulation of calcium signaling or homeostasis pathways in six individuals with PVL. Such analyses may not only confirm the role of these pathways, but could identify individuals who might be candidates for treatments targeting this process.\n\n3.3.2. Amniotic fluid in aneuploidy and maternal obesity. In the amniotic fluid data set, overall AUC is no better than chance, and indeed CSAX is not the best predictor. The poor RAAD and AUC scores for this data set make sense because the controls are highly variable, including samples collected over a period of more than 6 years. Nonetheless, the gene sets describing the abnormal samples appear to be informative.\n\nThe most dysregulated pathway over all abnormal samples together was ''regulation of chromosome segregation,'' a fitting summary of a data set where 16 of 38 abnormal samples were from fetuses with chromosomal aneupoidy. The most dysregulated pathways in trisomy 21 samples relate to neural development, heart development, and vision; Down syndrome patients are known to have developmental abnormalities in all these systems (Korenberg et al., 1990; McCullough et al., 2013) . In trisomy 18, tooth development, immune processes, and glucocorticoid metabolism were among the top ten gene sets, again consistent with prior knowledge about the phenotype (Pont et al., 2006; Turner and O'Herlihy, 1984; Van Dyke and Allen, 1990 ).\n\nThe impact of maternal obesity on fetal development is an active area of research. The top two gene sets implicated by CSAX in these samples overall are ''stem cell development'' and ''stem cell differentiation.'' Also highly ranked are ''glucose metabolic process'' and several gene sets pertaining to nervous system development, including neuronal stem cell maintenance and Notch signaling. Dysregulation of neural stem cells has been noted in the fetal brains of mice fed a high-fat diet (Niculescu and Lupu, 2009; Stachowiak et al., 2013) . Additionally, expression of genes involved in Notch signaling, required for neural stem cell development, is known to be disrupted in the brains of offspring of mice fed high fat diets (Yu et al., 2014) .\n\nIn individual samples we see different processes coming to the fore. One sample featured disruption of lipid and cholesterol transport pathways; in another, axonogenesis was most affected. In two other samples, the top pathways implicated oxidative stress and inflammation. The original analysis of the samples from obese and lean mothers (Edlow et al., 2014) noted that Apolipoprotein D (APOD) is the most upregulated gene in fetuses of obese women. The ApoD protein has been demonstrated to regulate inflammatory response (Do Carmo et al., 2008) and to exert neuroprotective and neurotrophic effects in a rodent model of excitotoxic brain injury, possibly by protecting against oxidative stress (He et al., 2009; Franz et al., 1999; Bajo-Graneras et al., 2011) . However, until now, the link between increased expression of APOD and increased oxidative stress in second trimester fetuses of obese women has been only speculative; traditional analyses of these same samples sought but did not find evidence of this connection. Our novel observation may shed light on molecular mechanisms underlying the increased expression of APOD noted in these fetuses, demonstrating how CSAX may provide new insights into the molecular etiology of pathological conditions.\n\nFinally, because maternal BMI is positively correlated with maternal systemic, placental, and neonatal inflammation (Aye et al., 2014) , and increased age also correlates positively with systemic inflammation (Franceschi et al., 2000) , we reviewed these two patients' clinical characteristics. These two samples are from the patient with the highest maternal age (46 in a cohort with age range 31-46) and one with unusually high BMI (39.5; cohort BMI range: 30.47-39.71). These results strongly suggest that CSAX is identifying valid characteristics of particular samples.\n\nNOTO ET AL.\n\nWe have shown that it is often possible to detect and characterize anomalous expression data given training data from normal samples only, and that the two methods designed with expression data in mind perform best, albeit with different strengths. FRaC learns reliable relationships between genes' expression patterns from the training data, and identifies anomalies when these patterns break down. This method is therefore entirely data-driven; it does not rely on prior knowledge about gene sets. Yet it makes sense that many clinically important conditions would be characterized by a breakdown in the expected relationships between genes' expression patterns. So it is perhaps not surprising that FRaC is particularly effective.\n\nOn average, CSAX is about as accurate as FRaC (Table 1) , but it has two very important differences: it identifies gene sets that may help to explain the nature of each anomaly, and it uses fewer gene expression features in its predictions (because of the discount parameter c in Eq. 2), instead gaining power from using known gene sets to integrate prior knowledge about gene relationships into the anomaly detection process. We find it revealing that CSAX also outperforms the simple combination of running enrichment analysis on the FRaC anomaly scores (''FRaC + enrichment''). This result suggests that CSAX's bagging and weighting steps succeed in providing the desired robustness.\n\nThe identification of gene sets with known functional roles associated with an abnormal sample is one of the primary goals of our work. It provides insight into the nature of the abnormality, and allows experts to follow up by ordering relevant tests. The fact that the performance of CSAX is comparable to that of FRaC while using fewer genes is evidence that the gene sets identified by our method are indeed relevant, because in general the use of fewer features hurts performance.\n\nWe also observed that performance depends less on the computational method used than on the difficulty of the data set itself. While the RAAD score is useful for characterizing the difficulty of anomalies whose classification is already known, in most cases such data will not be available. Thus, clinical intuition about the nature of anticipated anomalies will need to come into play. If the anomalous samples are likely to be no more different from the normal samples than the normal samples are from each other, no method is likely to succeed. Prior knowledge about expression variability and heterogeneity of the samples under consideration is expected to be helpful here.\n\nWe note that as the cost of sequencing continues to decrease, genome-wide studies of expression are shifting away from microarrays toward RNA-seq approaches. However, there is no reason that CSAX cannot be applied in an RNA-seq setting. Indeed, it might be even more powerful, as changes in the relative abundance of different isoforms can be integrated into the analysis. Future work should therefore include demonstrating CSAX's power to identify systematic anomalies in RNA-seq data.\n\nOverall, we have demonstrated that in many biomedically interesting cases, it is indeed possible to identify and characterize individual anomalous samples from their expression patterns. Such one-of-a-kind analyses are crucial steps as we move toward the era of precision medicine."}