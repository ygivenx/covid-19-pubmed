{"title": "Local risk perception enhances epidemic control", "body": "As outbreaks emerge, public health agencies often implement a variety of pharmaceutical and non-pharmaceutical interventions to prevent epidemic expansion, including vaccination and medical prophylaxis, school closures and other social distancing measures, and information campaigns to promote awareness, hygienic precautions and voluntary isolation [1\u20134]. However, such measures require population adherence and are often hindered by failure to take recommended actions [5]. Around the globe, for example, seasonal influenza vaccine coverage falls significantly below the 75% baseline recommended by the World Health Organization, but varies widely between countries and across age groups [6]. In the USA, 2015-2016 uptake was only 59.3% in children and 41.7% in adults [7]. For measles, routine childhood vaccination is declining in Texas and other areas of the United States where personal belief and other non-medical vaccination exemptions are allowed [8\u201310]. Parental decision-making regarding childhood vaccines is complex and context dependent [11], but likely influenced by false claims regarding vaccine safety, low perceived risks of infectious diseases, and other forms of misinformation from the \u201canti-vaxxer\u201d movement [8, 11\u201313]. Recently, there have been calls for a special government commission on vaccine safety, despite overwhelming scientific consensus that vaccines are both safe and effective [12, 14\u201316].\n\nAs outbreaks unfold, people can take a variety precautionary measures to avoid infection, including immunization and social distancing [1, 17\u201319]. They often judge personal risk based on their impressions of overall disease prevalence and severity [2, 20\u201323]. When infection risk appears low, small risks of adverse effects from the vaccine can seem relatively important and cause vaccine coverage to drop below levels required to control transmission. A variety of other factors can influence the perceived utility of disease prevention, including epidemiological news and rumors, costs of vaccination and other control measures, trust in health professionals, government agencies, media and non-official information sources, as well as societal pressure to ensure the health of one\u2019s children [24\u201329].\n\nStudies have shown that media reports about outbreaks that specify numbers of cases, hospitalizations or deaths, can influence avoidance behavior and contact patterns at both individual and community levels. In some cases, oversimplified or erroneous media reports regarding flawed vaccines can trigger panic and increases in vaccine hesitancy [30\u201333]. For both seasonal and pandemic influenza, such interactions between vaccination decision-making and transmission dynamics can profoundly shape the course of epidemics [20, 34\u201336].\n\nIndividual intervention decisions can have far-reaching effects. For example, vaccination protects not only the immunized individual, but also social contacts who might have been infected by the individual. Social distancing decisions may break chains of transmission by protecting the decision-maker and more generally disrupting social dynamics. Following [37, 38], we refer to this indirect protection as a herd effect. Although previously equated to the reduction in incidence in the unimmunized population [38], we quantify the herd effect of an intervention effort by estimating the number of infections averted per vaccine administered (or per individual social distancing action). The general phenomenon in which individual intervention actions reduce the risk of infection to others has also been called vaccination efficiency, vaccination effectiveness, herd immunity, and indirect protection [37\u201340].\n\nThe magnitude of the herd effect will critically depend on contact patterns [41, 42]. Measures taken by gregarious individuals may have greater immediate benefits than those taken by solitary individuals, with downstream epidemiological consequences modulated by the full social network [43, 44]. Contact patterns may also influence the decision-making process itself, by constraining epidemiological perspectives. When gauging infection risk, individuals may consider global information (e.g., from news media) or local first-hand encounters with disease (e.g., infected acquaintances, friends or family members) [30, 31]. While traditional compartmental models assume homogeneity in both epidemiological risks and intervention benefits, network-based models provide a tractable framework for studying the complex interplay between contact networks, intervention decision making and disease transmission [34, 45\u201351].\n\nHere, we investigate the epidemiological impacts of different decision paradigms using a network-based SIR epidemic model, in which individuals also make vaccination or social distancing choices based on their perceived epidemiological risks. Depending on the decision model, they estimate either overall disease prevalence, their number of infected social contacts, or their fraction of infected social contacts. When the perceived threat is sufficiently high, they take a measure that immediately affords full protection for the duration of the epidemic. We compare the efficacy of these three different paradigms across a range of diseases in a realistically heterogeneous network, and show that the most naive model\u2013simply counting one\u2019s infected contacts\u2013affords the most epidemiological protection using the least amount of resources (e.g., vaccinations or economic costs associated with social distancing).\n\nWe model contact patterns in the population using an exponential network with N = 10000 nodes and mean number of contacts \u03bc = 10 [54], generated according to the configuration model [55], unless otherwise is specified. We assume that this network constrains both disease transmission and local risk perceptions, when individuals monitor infected social contacts. To evaluate the impact of network topology, we also analyze the SIR-intervention dynamics on a homogeneous random graph (all nodes have same degree) and Barab\u00e1si-Albert scale-free network [56], with degree distributions constrained to achieve the same epidemic threshold as the focal exponential network. All three networks share Tc=\u2329k\u232a\u2329k2\u232a-\u2329k\u232a=0.056 where \u2329k\u232a and \u2329k2\u232a are the average degree and squared degree in the network, respectively.\n\nWe model SIR transmission dynamics of a flu-like disease using chain-binomial stochastic simulations [41, 53]. Epidemics begin at time t = 0 by infecting a single randomly chosen node in an otherwise completely susceptible population and terminate when there are no remaining infected individuals. Individuals remain infectious for l = 7 days before recovering with full immunity to future infection [57, 58]. Infected individuals transmit disease to each susceptible contact at a rate \u03b2. Immunized and recovered individuals are assumed to be fully resistant to infection. Results are averages over 500 simulations.\n\nThe basic reproduction number (R0) is the expected number of secondary cases when a single case of disease is introduced into a naive population, and is related to the epidemic growth rate. To study the impact of transmission rate on the vaccination-epidemiological dynamics, we consider R0 values ranging between one and ten, which spans the range for many common human pathogens, including influenza, Ebola, SARS, Pertussis, HIV/AIDS, Mumps, Rubella, Polio, Smallpox, Diphtheria, etc [52, 59\u201366]. For each value of R0, we determine the corresponding \u03b2 using [45]\nR0=T(\u27e8k2\u27e9-\u27e8k\u27e9\u27e8k\u27e9),(1)\nwhere T = 1 \u2212 (1 \u2212 \u03b2)l is the transmissibility over the entire infectious period, also known as the secondary attack rate [67].\n\nIn the first model, local prevalence, individuals assess infection risk by tracking the fraction of their social contacts that are currently infected. The probability that a susceptible individual i vaccinates at time t is given by\nvlp(i,t)=1-(1-T)\u03b7i(t)ki\u00d7\u27e8k\u27e9(2)\nwhere \u03b7i(t) is the number of neighbors of i that are infected at time t, ki is the total number of neighbors (degree) of i, and \u2329k\u232a is the average degree of the network.\n\nIn the second model, local count, individuals track their number rather than proportion of infected neighbors, and decide to vaccinate according to\nvlc(i,t)=1-(1-T)\u03b7i(t).(3)\n\nLocal prevalence is arguably a less plausible strategy than local count, given that the decisions require the additional knowledge of total number of contacts (degree) of each individual.\n\nThe global prevalence model assumes that individuals base their vaccination decisions on the epidemiological state of the entire population, as given by\nvg(i,t)=1-(1-T)I(t)N\u00d7\u27e8k\u27e9,(4)\nwhere I(t) is the total number of infected individuals in the population at time t and N is the size of the population. This assumes general knowledge of the evolving dynamics of the epidemic, perhaps through news, social media or public health messaging.\n\nThe mean degree (\u2329k\u232a) appears in the global prevalence and local prevalence as a normalizer. If node i has the average degree (ki = \u2329k\u232a) and its local prevalence mirrors global prevalence (\u03b7i(t)\u2329k\u232a=I(t)N), then it will have the same probability of vaccinating across all three models.\n\nIn all three models, we assume that individuals will vaccinate with a probability equal to their perceived real-time probability of being infected. For example, if an individual\u2019s perception of infection in the immediate future is 25%, then a precautionary measure will be taken with probability 0.25. The local count model comes closest to estimating actual risk of infection. Specifically, vlc is the probability that any currently infected contact will transmit disease to the focal node at some point during his or her infections period. This exactly estimates risk if all infected contacts were just infected and at the beginning of their infectious period, but overestimates risk if some are nearing recovery. (S1 Fig illustrates how vaccination decisions change under each of these models as disease prevalence increases.).\n\nTo assess the indirect and direct protection afforded by a given decision strategy D at a given R0, we calculate a quantity we call the herd effect, given by\nH(D,R0)=\u27e8C0(R0)\u27e9-\u27e8CD(R0)\u27e9\u27e8VD(R0)\u27e9,(5)\nwhere \u2329C0(R0)\u232a and \u2329CD(R0)\u232a are the expected total number infections in epidemics without vaccination and with vaccination decision strategy D, respectively, and \u2329VD(R0)\u232a is the expected total number of individuals vaccinated under D. We estimate these expected values by averaging over 500 simulations with the specified R0 and decision model. Barring extreme stochasticity, we expect H > 0 for any reasonably protective vaccine strategy. When H is between zero and one, more vaccines are given than infections averted, suggesting that vaccines may be mistimed or misplaced. This could happen, for example, if risk is underestimated early in the epidemic and overestimated late in the epidemic. An H near one indicates that approximately one infection is averted for every vaccine given. Note that this is an average, and does not necessarily mean that every vaccination prevents infection of the recipient. If each vaccine averts, on average, greater than one infection (H > 1), then the value of H corresponds to the level of indirect protection achieved by the decision strategy.\n\nThe decision models yield distinct vaccine adoption and disease transmission dynamics (Fig 2). As disease begins to spread, individuals perceive increasing risks and vaccinate according to the decision model, thereby protecting themselves and interrupting potential chains of transmission to others. While all three strategies reduce the total number of infections, the local count strategy affords the greatest and most efficient protection of the three. Under the global prevalence strategy, perceived risk is homogeneous. As cases mount, the vaccination rate rises synchronously throughout the population, arguably resulting in too much too late vaccine coverage.\n\nThe local strategies avert more infections with fewer vaccinations than the global strategy. As epidemics unfold, risk is both heterogeneous and dynamic, with some portions of the network experiencing greater forces of infection than others. Local decision-making allows earlier detection and response to increasing personal risk, and prevents unnecessary vaccination in lower risk settings, both prior to and following epidemic waves. The local count strategy is more protective than the local prevalence strategy. By tracking the number rather than proportion of infected contacts, individuals more accurately assess the local force of infection. For example, compare a solitary individual with just two social contacts and a gregarious individual with 20. If they both have two infected contacts, then their risk of infection will be similar (assuming that time spent with each contact is sufficient for transmission). Under local count, their perceived risk and consequent vaccination probability will be identical; under local prevalence, the solitary individual will perceive higher risk (i.e., 100% of contacts infected) than the gregarious individual. Under all models, overall vaccine coverage increases as R0 increases, with the global prevalence achieving near universal coverage by R0 = 5.\n\nThe relative and absolute impacts of each strategy are remarkably robust to the transmissibility of the pathogen (Fig 3). Without vaccines, the expected epidemic size increases non-linearly with R0, reaching almost 100% by R0 = 10 (Fig 3A). All of the vaccine strategies avert a large and increasing fraction of cases, as R0 increases. In fact, the total epidemic size is non-monotonic, with slightly more expected infections around R0 = 4 than around R0 = 10. The local count strategy consistently yields the greatest protection, followed by local prevalence.\n\nThe decision models result in dramatically different vaccination rates, with the global prevalence strategy leading to near universal vaccination, consistently more than double the coverage produced by the local count strategy (Fig 3B). The population-level protection afforded by the local count strategy exhibits a non-trivial trend with R0 (Fig 3C). Between R0 = 1 and R0 = 2, its impact grows logarithmically from less than one infection averted per vaccinator to nearly two infections averted per vaccinator. Thereafter, the indirect benefits continue to grow slowly, reaching three infections averted per vaccinator when R0 = 9.\n\nTo explore the dynamic interactions between behavior and epidemiology in the three models, we consider individual nodes based on their degree (number of contacts). In general, the higher the degree of a node, the higher their risk for becoming infected and infecting others, and the greater the number of local infections they could potentially perceive when making vaccination decisions. Indeed, across all decision models, higher degree individuals vaccinate earlier, in terms of the fraction of the population infected at time of vaccination (Fig 4A, bottom). However, the fraction of individuals vaccinated in each degree class does not necessarily increase with degree (Fig 4A, top). Local count is the only strategy under which vaccination coverage monotonically increases with degree. Under global decision-making, coverage is inversely related to degree, and under local prevalence, coverage peaks for moderately connected individuals. By the time individuals choose to vaccinate under either of the two suboptimal strategies, their local risk of infection is already quite high (Fig 4A, middle), particularly for more gregarious individuals. Although the vaccinating individuals are immediately protected, comparable individuals (of the same degree class and local risk) who stochastically fail to make the same low probability vaccination decision are likely to become infected. Consequently, the risk of infection increases steeply with degree under all models except local count (Fig 4B). In a sensitivity analysis, we find that these qualitative results are robust to our assumptions about the efficacy of the vaccine, the time lag between an individual deciding to vaccinate and becoming protected against infection, the size of the network and the duration of the infectious period (S3 Fig).\n\nFinally, we consider the impact of the underlying contact network on the interplay between transmission and vaccination dynamics (Fig 5). We compare our focal exponential network to a uniform random network in which all nodes have the same degree and a Barab\u00e1si-Albert scale-free network. The local count strategy robustly affords the most efficient population-level protection, averting the maximum number of infections (or nearly maximum in the case of the scale-free network and low R0) with the fewest vaccines.\n\nPublic health interventions and individual-level adherence decisions can profoundly influence the fate of unfolding epidemics. In this study, we assume that individuals have access to a fully protective measure, such as self-isolation, medical prophylaxis, or an immediately and completely efficacious vaccine. They continuously make real-time risk assessments and thereby decide whether or not to adopt the intervention, based on either direct knowledge of infected friends and family (number or fraction of infected social contacts) or indirect information about population-level prevalence, perhaps gleaned through news media.\n\nOf the three decision models, global risk assessments prove least effective across a large range of disease scenarios (R0 ranging from one to ten). Nearly all non-infected individuals eventually vaccinate, yet the total cases more than double those occurring under the alternative strategies. There is a mismatch between risk and action. Risk is highly variable in time and space, given the heterogeneity of the underlying contact network and branching nature of transmission. Yet, the global model assumes that perceived risk and the consequent likelihood of adherence is homogeneous throughout the network, though variable in time. By the time global prevalence triggers wide-spread action, the highest risk individuals have already been exposed and the lowest risk individuals may still not, and might never, require protection.\n\nIn contrast, when individuals make decisions based on local risk assessments, the intervention efforts more closely track the epidemiological dynamics. Tallying infected contacts rather than estimating the fraction of infected contacts provides a more accurate indication of real-time risk and results in more efficient intervention. Assuming that all social contacts are equally likely to transmit disease, two out of three infected contacts carries the same immediate risk as two out of ten. The advantage of local risk assessment stems from two sources of variation in risk. First, disease transmission is an inherently local process in which risk aggregates around currently infected individuals. Second, this is magnified in realistically heterogeneous networks, by the concentration of risk around the center (most connected individuals) of the network.\n\nAlthough several prior studies have also explored the epidemiological impacts of local and globally-informed vaccination decisions [48\u201351], ours is the first to consider a decision-model based on counts rather than fractions of infected contacts and to systematically compare three different decision paradigms across a range of network structures. Massaro et al. model two networks\u2013the epidemiological contact network through which disease spreads and the social network through which risk information spreads. The more similar the two networks, the greater the individual and population-level protection achieved by vaccination [49]. This is consistent with our finding that locally-sourced decisions provide greater protection than globally-sourced decisions. Bagnoli et al. compare the local fraction strategy across contact networks with different degree distributions, and likewise found that the herd effect is magnified by heterogeneity in degree. [48].\n\nGiven infinite resources, all three of the decision paradigms would markedly diminish an emerging outbreak. However, interventions may be constrained by limited supplies or lack of population access to medical countermeasures, such as vaccines or antimicrobials. Even social distancing measures, such as self-isolation, may be limited by economic necessity\u2014the need to go to work, school or daycare\u2014or care-giving obligations for extended family. While such limitations should be formally analyzed, our simple analysis suggests that the best paradigm for averting infections also requires the fewest resources. For example, for a flu-like R0 of two, compare the local count strategy, where individuals protect themselves as their number of infected friends and family climb, to the global strategy, where decisions are based on population prevalence. For every individual that takes action, almost two infections are averted under the local strategy whereas less than one infection is averted under the global strategy. Local counting results in far fewer total infections (3% versus 13%) while requiring far less intervention resources (23% versus 60% of individuals taking protective action).\n\nSeveral studies suggest that immunizing or isolating interventions should target the most connected individuals in a population [42\u201344, 52]. However, we rarely know the full contact network of a population. As proxies, we can target populations subgroups that tend to have high numbers of potentially disease-spreading contacts, such as young and school-aged children or health-care workers. We can also use biased sampling to identify highly connected individuals, such as the random acquaintance strategy in which random individuals are asked to name one of their social contact; individuals with more contacts are more likely to be named [68\u201371]. In a sense, the winning paradigm of our study\u2014counting infected contacts\u2014similarly biases interventions efforts towards more connected parts of the network. The more connected one is, the more likely one is to have several infected contacts.\n\nThe model is intentionally simplistic, providing a best case scenario for each of the three strategies. We assume that resources are unlimited, protection is immediate and complete, and adherence probabilities perfectly mirror perceived risks. Furthermore, depending on the decision paradigm, individuals fairly accurately estimate the infectiousness of the disease, their number or fraction of infected social contacts, or the population average risk of infection. The model also assumes that individuals are short-sighted and make reactive decisions to avert immediate threat. We conjecture that the qualitative results of our analysis\u2014the optimality of assessing risk based on the numbers of infected friends and family\u2014are robust for a large class of \u2018on-the-fly\u2019 interventions that afford relatively rapid protection in the heat of an epidemic, but may not apply to preventative measures taken early in an outbreak or those with long efficacy lags. (For example, see alternative models presented in S1 and S2 Figs).\n\nAs a final caveat, we highlight our assumption that all edges (contacts) in our networks are equally likely to transmit disease. In reality, contacts can be highly heterogeneous, with household and health care contacts far more likely to transmit disease than casual social acquaintances. Our results should be robust when such heterogeneity is distributed randomly throughout the network. However, if individuals with more contacts tend to spend less time with each one, then epidemiological risk may be more homogeneous throughout the network and the advantage of the local decision strategies reduced. Although we do not model this scenario directly, we considered a homogeneous network where all individuals have the same number of contacts. This is roughly equivalent to mass action models that assume homogeneous contact rates and complete mixing [54]. The local strategies still prevail, but their relative efficiency is reduced, with far more vaccines required to achieve the same benefit (Fig 5). Conversely, in a network with greater heterogeneity (scale-free), the advantages of the local strategies are magnified.\n\nThis study prompts two practical questions. First, how do people actually make intervention decisions? Perhaps individuals fall nicely into one of these three decision-making camps. More likely, individual risk assessments are constrained by historical inertia [21, 24, 34, 46, 72], influenced by decisions of friends and family [1, 3, 10, 26, 28, 46], and integrate information from a combination of local and global data sources of variable reliability. Realistic decision models, driven by sociological survey data, can elucidate vaccine campaign failures and identify key pressure points for increasing uptake. Second, how can we streamline intervention campaigns to achieve efficient, rather than universal, adherence? This study reminds us that more intervention is not necessarily better intervention. The decision paradigm that most reduced transmission also required the least resources. Given the simplicity of our model, we do not suggest that public health agencies should promote \u2018infection-counting\u2019. Rather, we conclude that public health agencies should prioritize local disease surveillance and risk communications efforts and believe that data-driven models can be instrumental in designing effective outbreak information campaigns."}