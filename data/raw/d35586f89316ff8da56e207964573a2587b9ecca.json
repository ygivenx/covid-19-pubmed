{"title": "Integration of Disciplines and of Basin-Based, Transboundary Health Systems 264 10.12.2 Main Water-Borne Diseases: Links to Water Management 266 10", "body": "This chapter is not intended to provide an extensive review of water-borne diseases, since there are already excellent examples of these in the literature. Rather, the intention is to call atten tion to particular aspects of the principal water-borne diseases and related water management issues. The emphasis is often on controversial aspects which it is hoped will stimulate an open, undogmatic, and fruitful discussion on possibilities and cur rent and future challenges for ecohydrology in relation to human health.\n\nEcological integrity is central to health (Epstein, 1999) . Pollution, disturbed environments, habitat loss, and climate change promote disease emergence in a number of ways. Threats to human health arising from man's interaction with aquatic ecosystems can originate from multiple factors, which can be broadly grouped into the following major categories:\n\n\u2022 natural biological cycles in which humans can act as hosts of pathogenic microorganisms (protozoans, bacteria, etc.); \u2022 consequences of the management of aquatic resources (e.g., wetlands drainage or creation, aquaculture, and dam construction); \u2022 effects of water pollution (chemical, microbiological, radio active, and thermal) on man and on the physiology of individual organisms; and \u2022 the impact of global changes affecting climate and hydrolo gical cycles (e.g., habitat degradation, warming, increased rainfall, and storms).\n\nClearly, these are interlinked and specific case studies are likely to present evidence of more than one causal factor. Thus, an effort has been made to integrate these different topics into sections covering the most relevant factors related to diseases that can be considered indicators of determined hydrological processes.\n\nGlobally, approximately 19% of deaths due to infectious dis eases are water related. This amounts to 3.4 million deaths per year, 75% of which are caused by diarrhea, a disease killing around 2 million people every year, mostly children in devel oping countries (WWD, 2001) . Thus, it is crucial to develop an integrated water and health management system, as well as the tools required to identify and predict interconnected trends in the evolution of aquatic ecosystems and diseases. Although the importance of integrating natural sciences with socioeconomic research is stressed and recommended in every forum dealing with sustainable use of natural resources, human health, one of the most valuable public goods, is seldom included as a significant issue in coastal or basin management programs.\n\nA frequent goal of cooperation between socioeconomic and natural sciences research is the evaluation of the sustainability of resource use and the vulnerability of the coastal zone. The Seven Step Assessment Framework of the International Panel on Climate Change (IPCC, 1994) is the customary tool used for this purpose (Figure 1) . Similarly, the Health Map program from the World Health Organization (WHO) provides criteria and a software platform for linking epidemiological data with layers of geographic information (WHO and UNICEF, 1993) . However, these two types of research programs mostly lack any substantial interaction. Ecohydrology can provide the conceptual framework for establishing such links. This involves a scale (the river basin and the coastal zone), an integrative process (flooding dynamics), and an integrative tool such as digital elevation models (DEM) of the study area (Figure 1) .\n\nHigh-resolution topography is essential for data integra tion in low-lying areas. For this purpose, a closer interaction of socioeconomic studies, climate, hydrology, ecology, micro biology, biogeochemistry, molecular biology, and medicine is required, as exemplified in the case of cholera (discussed in Section 10.12.2.3.1). Further, it is necessary to generate a common language to facilitate and promote inter-and transdisciplinary communication. Several concepts related to disease dynamics, such as outbreak, epidemics, and pan demics, are commonly used in a qualitative way. Yet, the creation of interdisciplinary databanks or the compilation of information from diverse sources (e.g., hydrological events and outbreak intensity) including historical ones would ben efit from objective category definitions. In the following sections, some examples are dealt with, which will appear in this chapter and in other related literature.\n\nIt is considered that an epidemic occurs when new cases in a given human population, during a given period, sub stantially exceed what is expected, based on recent experience (the number of new cases in the population during a speci fied period of time is called the 'incidence rate'). An epidemic may be restricted to one locality (an outbreak), be more general (the usual 'epidemic'), or even global (pandemic). Common diseases that occur at a constant but relatively low rate in the population are said to be 'endemic'. An example of an endemic disease is malaria in some parts of Africa, where a large portion of the population is expected to contract malaria at some point in their lifetime. These somewhat subjective definitions require more precisionand a wider diffusion among the populationwhen, for Aquatic Ecosystems, Human Health, and Ecohydrology 265 Figure 1 Integration of socioeconomic, ecological, and medical research within the ecohydrology framework.\n\nexample, public funds have to be allocated for prevention, alleviation, or fight against determined diseases or for insur ance policies. An increasing number of direct or indirect cases of water-borne diseases are due to global warming, increasing frequency and intensity of storms, flood control, and environmental management (dam construction, irriga tion, use of fertilizers, etc.), and this has greatly widened the spectrum of stakeholders with an interest in the use of water and its impact on health. This underlines the need for agree ment on and diffusion of definitions and criteria between users and managers to facilitate the quantification of impacts of disease, ecological damage, and poor sanitation, as well as for cost-benefit analysis of proposed prevention or remedia tion measures. The global burden of disease analysis (WHO, 2009) pro vides a comprehensive and comparable appraisal of mortality and loss of health due to diseases and injuries, and risk factors for all regions of the world. The overall burden of disease is assessed using the disability-adjusted life year (DALY), a timebased measure that combines years of life lost due to premature mortality and years of life lost due to time lived in states of less than full health. Worldwide, about 82 million DALYs per year are due to water-borne diseases (Pruess et al., 2002) . A relevant specific example is the definition and evaluation of the impact of disease related to drinking water quality. This concerns the presence of chemicals or pathogenic microorganisms that are transmitted when contaminated drinking water is directly con sumed. If contaminated drinking water is used in the preparation of food, it can be the source of food-borne disease through consumption of the same microorganisms, often in the form of gastrointestinal illnesses. According to the WHO (WHO, 2004a) , diarrheal disease accounts for an estimated 4.1% of the total DALY global burden of disease and is respon sible for the deaths of 1.8 million people every year. It is estimated that 88% of that burden is attributable to unsafe water supply, sanitation, and hygiene.\n\nAt the national level, surveillance systems are the primary source of data concerning the scope and effects of water-borne diseases on persons. These data can be organized to provide information for political and administrative units such as counties or federal states, and/or geomorphological units, that is, basins. In the United States, since 1971, the Centers of Disease Control and Prevention (CDC), Environmental Protection Agency, and the Council of State and Territorial Epidemiologists have maintained a collaborative surveillance system which monitors the occurrence and causes of water borne-disease outbreaks (WBDOs) (Calderon et al., 2002 ). The surveillance system includes data for outbreaks associated with drinking water and recreational water. State, territorial, and local public health departments are primarily responsible for detecting and investigating WBDOs and voluntarily reporting them to CDC on a standard form. The unit of analysis for the WBDO surveillance system is an outbreak, not an individual case of a water-borne disease. Two criteria must be met for an event to be defined as a WBDO. First, more than two persons must have experienced a similar illness after either ingestion of drinking water or exposure to water encountered in recreational or occupational settings. This cri terion is waived for single cases of laboratory-confirmed primary amebic meningoencephalitis and for single cases of chemical poisoning if water-quality data indicate contamina tion by the chemical. Second, epidemiologic evidence must implicate water as the probable source of the illness.\n\nThe integration of national information on water-borne disease incidence into collaborative regional, transboundary basin databank networks of open access is crucial to allow a fair and efficient implementation of water management regula tions related to, for example, dam operation and international irrigation agreements. This is particularly relevant in tropical countries where large river basins (e.g., Amazon, Nile, Mekong, Indus, Ganges, and Yarlong-Brahmaputra) represent the main source of income, water, and food for millions of people. The rivers originating in the Tibetan Plateau ( Figure 2 ) are particu larly relevant as they flow through several, densely populated tropical and subtropical countries with quite different degrees of development.\n\nIn general, water-borne disease can be caused by protozoa, viruses, or bacteria, many of which are intestinal parasites. In the following tables, some relevant examples of various disease types are grouped and summarized, including those which mostly affect developing countries, in many cases in tropical and subtropical regions. In the following sections, diseases have been selected that are relevant in terms of numerical incidence, water management, and changes in land use, parti cularly under the ecohydrological approach. These are malaria, schistosomiasis, lymphatic filariasis, onchocerciasis, cholera, spotted fever, and those illnesses induced by toxins produced during cyanobacteria blooms due to increased nutrient loads. We will provide a general overview of these diseases, stressing the links to the global water crisis, possible contributions of ecohydrology, and challenges to its classical approach. Parasitic infections, particularly malaria and schistosomiasis, represent some of the most universal health problems. The WHO estimates that 200 million people are infected and another 600 million people are at risk of infection (WHO, 2007) . In fact, only malaria accounts for more cases of disease than schis tosomiasis, and both are closely related to water management (WHO, 1993) and will be extensively treated in this chapter.\n\nWater scarcity and uncoordinated water management go hand in hand with poverty and disease. Russel (1961) explains the links clearly:\n\nBilharziasis and malaria are both debilitating diseases and debility is not conducive to good farming. Throughout history, malaria and bilharziasis have interfered with the use of arid land and indeed, calcified eggs of bilharzia worms were found in the kidneys of two mummies of the 20th dynasty -1250-1000 B.C. There is a crucial chain reaction that in some instances has contributed to the virtual abandonment of irrigation systems: the more debility, the less canal maintenance, therefore the more Anopheles mosquitoes and the more snails transmitting more malaria and more bilharziasis, thus leading to more debility, and so on\u2026. (Russel, 1961: 253) . Table 1 provides a summary of relevant water-borne diseases produced by protozoan parasites. In this section, we will con centrate on malaria, currently still the world's most important parasitic disease.\n\nToday, malaria is one of the world's deadliest diseases and occurs mostly in tropical and subtropical countries, being transmitted from one person to another through the bite of female Anopheles mosquitoes. The WHO estimates that there are 300-500 million cases of malaria, with over 1 million deaths each year (WHO, 2001a) . T he main burden of malaria (more than 90%) is in Africa, south of the Sahara. Two-thirds of the remaining burden affects six countries: Brazil, Colombia, India, Solomon Islands, Sri Lanka, and Vietnam. The ecology of the disease is closely associated with the availability of water, as the larval stage of mosquitoes develops in different kinds of water bodies. The mosquito species vary considerably in their water-ecological require ments (sunlit or shaded, with or without aquatic vegetation, stagnant or slowly streaming, and fresh or brackish; discussed in Section 10.12.4.3.2.1), and this, to a great extent, determines the ecology of the disease. In many places, the nat ural habitat sustains intense malaria transmission; in others, the development of water resources (irrigation, dams, and urban water supply) has exacerbated the intensity of transmission and caused the disease to spread. In yet others, for example, the Central Asian Republics of the Commonwealth of Independent States, malaria has returned as a result of a breakdown in water management and maintenance problems of local irrigation systems (WHO, 1999) .\n\nClimate change (global warming) appears to be moving the altitudinal limits of malaria to higher elevations, for example, in the East African highlands and Madagascar. Further, in some of the tropical regions of the developing world, the incidence of malaria has increased in recent years as the mosquito and the malaria parasite it transmits have evolved more resistance to Sewage, nontreated drinking water, flies in water supply (hand-to-mouth) Untreated water, poor disinfection, pipe leaks, groundwater pollution, sharing of water source by humans and wildlife. Beavers and muskrats create ponds that act as reservoirs for Giardia (oral-fecal, hand-to-mouth) Encephalitozoon intestinalis has been detected in groundwater Chills, period fever attacks; debility, spleen and liver enlargement; anemia, jaundice; clogging of brain vessels can lead to death Flu-like symptoms, watery diarrhea, loss of appetite, substantial loss of weight, bloating, increased gas, and nausea Abdominal pain, fatigue, weight loss, diarrhea, bloating, and fever Diarrhea, bloating abdominal discomfort, and flatulence Diarrhea and wasting in immunocompromised individuals alternatives to dichlorodiphenyltrichloroethane (DDT) and to the medications used to prevent or treat the disease. In some regions (e.g., South Africa), DDT is again increasingly used to control mosquitoes (Thurow, 2001) . In general, land reclama tion for agriculture, deforestation, and changes in land use are probably the principal causes of the climatic and habitat changes responsible for these developments. Yet, it should be borne in mind that it was the drainage of wetlands for agricul tural purposes in the nineteenth century which contributed most significantly to the eradication of malaria in Europe (Reiter, 2000) . These are crucial aspects to be carefully evaluated when wetland creation and management policy are being considered as an ecohydrological tool, for example, for sequestration of nutri ents in estuaries and for preventing toxic algal blooms. These issues will be discussed extensively in the following section (also discussed in Section 10.12.5.2). It is often erroneously thought that larvae of malariatransmitting mosquitoes can only develop in freshwater. It is also frequently forgotten that malaria is not restricted to the tropics, and that only in 1975 did the WHO declare that Europe was free of malaria. About 200 years ago, malaria was a leading cause of death in many marshland commu nities along the coast of southern England. There, extensive salt marshes provided high-quality grazing for sheep and cattle, but were also a favored habitat for Anopheles atroparvus, a highly effective malaria vector, which prefers to breed in brackish water along river estuaries and in the presence of abundant algae. Until the nineteenth century, malaria was a major mortality factor in The Netherlands. However, by the end of that century transmission had dropped precipitously in the more prosperous countries of North Europe. A major factor contributing to this decline was that the mosquito habitat had been eliminated by improved drainage and extensive land reclamation. Major epidemics still occurred in Russia and Poland in the 1920s, with high death rates reaching regions near the Arctic Circle (Wolanski et al., 2004 and references therein) .\n\nToday, malaria is again common in many parts of Central America, northern South America, tropical and subtropical Asia, some Mediterranean countries, and many of the republics of the former USSR. This spread of the disease has been attrib uted to, among other factors, forest clearance, irrigation, ecological change, population increase, deterioration of public health services, resistance of mosquitoes to insecticides, and resistance of the malarial parasite to antimalarial drugs (Reiter, 2000) . Thus, policies on wetland creation or restoration must take account of not only the benefits of the reestablishment of lost ecological services, but also the potential consequences of increased areas of slow-flowing or stagnant waters on disease vector proliferation, particularly under a scenario of increasing temperatures. The related ecohydrological concepts of system robustness and flushing dynamics can make a major contribu tion to the integrated analysis and handling of this issue, seeking equilibrium between the necessary water residence time, for example, efficient nutrient sequestration, and the minimization of mosquito reproduction. The choice cannot be formulated as 'mosquitoes in the basin' or 'toxic algal blooms in the estuary'.\n\nThere are techniques such as 'runneling' that have been used with varying success to control mosquito proliferation in cre ated or natural wetlands. As mosquitoes can be vectors for several other diseases besides malaria, this will be treated in a separate section (discussed below in Section 10.12.4.3.2.2).\n\nTable 2 provides a summary of relevant water-borne diseases produced by worm infections. In this section, we will concen trate on schistosomiasis, lymphatic filariasis, and river Table 2 Main water-borne diseases produced by worms blindness because of their strong links to water management measures, such as irrigation and dam operation schemes.\n\nSchistosomiasis is considered the second most important para sitic infection after malaria in terms of public health and economic impact. It is a chronic debilitating disease that is estimated to affect between 200 and 300 million people in 79 countries. As many as 600 million live in endemic areas. Also known as bilharzia, bilharziosis, or snail fever, it is caused by several species of fluke (trematode) of the genus Schistosoma. (Gryseels et al., 2006; Figure 3) . Infection with any of the five species of schistosome worms is rarely fatal. Although it has a low mortality rate, schistosomiasis is often a chronic illness that can damage internal organs and, in children, impair growth and cognitive development. The urinary form of schis tosomiasis is associated with increased risks for bladder cancer in adults (Hodder et al., 2000) . Human infections are most common in Asia, Africa, South America, or the Middle East, especially in areas where the water contains numerous fresh water snails, which are intermediate hosts, that is, may carry the parasite. However, trematodes can be found anywhere human waste is used as fertilizer.\n\nThe disease affects many people in developing countries, particularly children who may acquire the disease by swim ming or playing in infected water, and field workers in arid or semiarid regions where agriculture depends heavily on irrigation. First infection with schistosomiasis usually occurs during the early school years and is a frequent cause of absen teeism. It is not uncommon for 85% of a school's student population to be infected in some highly endemic areas in Africa. In addition to its effect on children, schistosomiasis has a major impact on the agricultural workforce and on national economic productivity. In Egypt, where 20% of the people are infected, economic losses due to lost work are estimated to exceed $500 million a year (Anonymous, 2009a) .\n\nDevelopment, both planned and unplanned, has resulted in a number of changes in the epidemiology of the disease that threaten to increase its spread and the number of people infected, reduce economic productivity, and compromise development gains. Water development schemes, including dam building and irrigation systems, with slow water flows and aquatic vegetation, have created new breeding sites for snails. Intensive agriculture has encouraged people to migrate to urban and peri-urban areas that are ill-prepared to meet their needs for sanitation and water. In these areas, snail-infested streams and canals are often the most convenient water sources. New agricultural systems that emphasize irrigation, double cropping, and other intensive cultivation practices have increased farmers' exposure to infection.\n\nThe emergence or reemergence of schistosomiasis as a result of large-scale hydroprojects has been reported from the Egyptian Aswan High Dam (Khalil, 1949; Strickland, 1982) , the Sudanese Gezira-Managil Dam (Amin, 1977; Omer, 1978 (Teklehaimanot and Fletcher, 1990) . In China, the Danling Dam in the province of Sichuan and the Huangshi Dam in the province of Hunan have all had adverse effects by increasing local schistosome transmis sion (Zhang and Guo, 2006) . However, not all dam regions suffer from schistosomiasis. For example, when the Ertan Dam in the province of Sichuan became operational, local schistoso miasis control centers collaborated with dam management offices and government ministries to actively monitor and pre vent the spreading of schistosome worms. As a result of these efforts, potential schistosome transmissions in the Ertan region were successfully averted (Gu et al., 2001) . Schistosomiasis infection in humans, the definitive hosts, is caused mainly by three species of flatworm, namely Schistosoma haematobium, S. japonicum, and S. mansoni. Infection occurs when free-swimming larvae penetrate human skin. The larvae develop in freshwater snails, which serve as intermediate hosts for the parasite. Humans are infected when they enter larvaeinfested water for domestic, occupational, and recreational purposes and the larvae of the parasite penetrate the unbroken skin. The life cycle is continued when people infected with schistosome worms deposit urine or fecally borne eggs into the water. The disease particularly affects children who may acquire the disease by swimming or playing in infected water (Hodder et al., 2000) .\n\nThe life cycle of S. mansoni provides a simplified example for all species of schistosomes and helps understand the potential contribution of water management to snail proliferation. After the eggs of the human-dwelling parasite are emitted in the feces, into the water, the ripe miracidium hatches out of the egg. The miracidium searches for a suitable freshwater snail to act as an intermediate host and penetrates it. Following this, the parasite develops, via a so-called mother-sporocyst and daughter-sporocyst generation, into the cercaria. The purpose of the growth in the snail is the numerical multiplication of the parasite. A single miracidium can produce several thousand cercaria, each one of which is capable of infecting humans. The cercaria propel themselves in water with the aid of their bifurcated tail and actively seek out their final host. When they recognize human skin, they penetrate it within a very short time. Following a migration through the body within the bloodstream, they develop into sexually mature adults. The larvae enter through the skin, migrate via the blood vessels, and mature in the lungs. From there they travel to the veins of the upper or lower intestine or bladder and, if they find a partner of the opposite sex, they reproduce. There are specific host/parasite combinations that lead to typical forms of bilhar ziasis in endemic areas in different regions of the world, frequently associated with a particular economic activity. There are also region-specific control measures with positive and negative consequences or side effects (Mannesmann and Fuchs, 2003) as discussed in Section 10.12.2.2.1.1.\n\nIn these regions, the snail Bulinus truncatus, B. globosus, and B. forskali can be hosts of S. haematobium, which produces uro genital bilharziasis (Lang, 1996) . The two clearest examples of large-scale irrigation systems spreading schistosomiasis are found in Africa, especially in the Nile Valley. In Upper Egypt south of Cairo, it has been known for a long time that the shift from basin irrigation by the floodwaters of the Nile to perennial irrigation results in a dramatic increase in schistosomiasis. Basin irrigation allows the land to dry out seasonally, killing almost all snails. Under perennial irrigation, the land is wet all year round. Soon after the construction of Aswan Low Dam, four locations that changed irrigation methods in the mid-1930s experienced a surge in S. haematobium infections (Khalil and Abdel Azim, 1938; Khalil, 1949) . Infection rates increased from 2-11% in 1934 to 44-75% in 1937. Urinary schistosomiasis had a pre valence at 60% in areas of perennial irrigation in Upper Egypt and only 5% in areas with basin irrigation (Scott, 1937) . In the 1950s, prevalence ranged from 56% to 68% in three districts with perennial irrigation, while in two districts with basin irriga tion, it was 9% and 13% (Wright, 1973) .\n\nIn the 1970s, after the construction of the Aswan High Dam, the Nile Delta became a major breeding habitat for the snail hosts of both urinary and intestinal schistosomiasis. Irrigation canals and drains ( Figure 4 ) harbored stable populations of these snails throughout the year. This resulted from the elimina tion in these canals of the so-called 'winter closure'. Before the construction of the dam, the closure was enforced for about 40 days, during which the canals were closed and dried up, and the silt deposited on their beds during the Nile flood was dredged out together with the snails and aquatic weeds (Malek, 1975) .\n\nThe other large-scale Nile valley irrigation system impli cated in schistosomiasis transmission is the Gezira irrigation scheme in the Sudan. The major increase in prevalence of schistosomiasis in Gezira came after 1960, when the cropping rotation changed to include 'winter' wheat. Farmers kept the canals filled with water from March to May, when they were previously dry (Fenwick, 1989) . Another factor was the creation of the adjoining Managil extension irrigation system which left tenants without adequate water supplies or sanitation facilities. Also, there was an influx of migrant laborers in the original Gezira scheme, who lived near irrigation canals, under very poor sanitary conditions, leading to the propagation of further water-borne diseases (Tameim et al., 1985) .\n\nIn North Africa and the Middle East, research has demon strated the association of even small-scale irrigation plans, decentralized at the village level, with increases in schistoso miasis transmission. Malek (1962) reports that in Sudanese villages along the Nile, north of Khartoum, prevalence of urin ary schistosomiasis in children was 11-12%, compared to an average of less than 2% in other areas. Wright (1973) reports that in the rural area around Baghdad, Iraq, prevalence of schistosomiasis increased from 10% to 25% following the installation of lift pumps.\n\n10.12.2.2.1.2 Asia In East and Southeast Asia, intensification and expansion of irrigated rice production systems over the past decades have increased the habitats for snail and Schistosoma. The host/para site combinations Tricula aperta/S. mekongi and Oncomelania hupensi/S. japonicum produce intestinal bilharziasis predomi nantly in rural communities living close to irrigation ditches. The association of Asian schistosomiasis with rice-growing areas has been reported by different authors. However, in many cases, rice fields themselves did not seem to be breeding habitats; rather snails found in the rice fields appeared to have spread from nearby irrigation canals. Cattle and water buffalo can also be important reservoir hosts. Various methods have been applied to substantially reduce schistosomiasis in rice agriculture, which will be discussed later in Section 10.12.4.3.1.\n\nIn this part of the world, it is mainly the combination of S. mansoni with Biomphalaria glabrata snails that causes bilhar ziasis. Brazil, with 25 million people living in the endemic areas and 3 million infected, is the most affected country in the Americas (Chitsulo et al., 2000) . However, it is not obvious to what extent hydrological factors, including large dams or irrigation systems, contribute to spreading schistosomiasis in Brazil. The African slave trade was probably responsible for the introduction of schistosomiasis in Brazil soon after the country was discovered by European explorers, and internal migration was responsible for spreading it from seashore to interior. Nowadays, schistosomiasis transmission occurs over a vast endemic region, from Maranh\u00e3o to Esp\u00edrito Santo, and Minas Gerais, and there are further areas with a high risk of endemic expansion (Araujo, 1986; Paraense, 1986) . There are also iso lated foci in the Federal District and in the states of Par\u00e1, Goi\u00e1s, Rio de Janeiro, S\u00e3o Paulo, Paran\u00e1, and Rio Grande do Sul.\n\nSome examples from the literature point to patterns of labor and household migration as significant factors in the incidence of disease in Brazil, probably more than irrigation schemes. Cases of disease importation from endemic areas have been registered over almost the entire country, mainly in the states that are considered migration destination areas, such as Rond\u00f4nia (Coura and Amaral, 2004) . A study involving 23 irrigation projects in the semiarid region of five northeastern states of Brazil (Coutinho et al., 1992) found that schistoso miasis transmission was not a major problem in the areas studied. Socioeconomic-sanitary analysis identified the pre sence of migrant farm workers coming from endemic areas of schistosomiasis and living in poor sanitary conditions in the irrigation areas as a main factor of epidemiological importance. However, continued epidemiological surveillance is essential in all irrigated areas of northeastern Brazil if schistosomiasis control is to be maintained, as well as improvement in the water supply and sanitation measures for migrant workers (Coutinho et al., 1992) .\n\nThe potential association between irrigation levels and the occurrence and spread of S. mansoni infection was investigated (Martins and Barreto, 2003) in the State of Bahia, where two forms of irrigation have been developed. The first is capital intensive and mechanized, requiring little manual labor. The second is labor intensive and characterized by limited mechan ization. According to the study, the municipalities with the largest irrigated areas are not the ones with the highest S. mansoni infection rates. In most of these counties, irrigation is capital-and technology intensive. According to these find ings, unlike Africa, irrigation in the State of Bahia has had little impact on the spatial profile of the schistosomiasis endemism.\n\nRegarding the impact of schistosomiasis on labor-intensive irrigation schemes, some research points to the importance of the household in disease transmission, as a result of the cluster ing of domestic activities associated with water collection, storage, and usage. Such activities can result in the sharing of water-contact sites and water-contact behavior, which expose all members of the household to an increased risk of infection. In previous studies in Brazil (Bethony et al., 2004) , it was deter mined that shared residence accounted for 28% of the variance in Schistosoma fecal egg excretion rates. Further, shared residence accounted for 30% of the variation in total water contacts per week. It also accounted for a large proportion of the variation in individual water-contact behavior: for example, agricultural con tacts (63%), washing limbs (56%), or bathing (41%). These results implicate the household as an important composite measure of the complex relationships between socioeconomic, environmental, and behavioral factors that influence water-con tact behavior and, therefore, the transmission of schistosomiasis. These results also support the idea of focusing on safe water supply and household density in the implementation of schis tosomiasis prevention and control measures.\n\nThe role of aquatic animals in maintaining the schistosome life cycle in Brazil requires further clarification. The influence of S. mansoni on a population of the water rat, Nectomys squamipes, was studied at Sumidouro, Rio de Janeiro, and Brazil (D' Andrea et al., 2000) . The population dynamics of parasites was studied. Water contamination (i.e., the source of miraci dia), abundance of the intermediate host, and rodent migration were found to be related to schistosome prevalence. The N. squamipes population was not obviously influenced by the infection, as shown by the high number of reproductive infected females, high longevity of infected individuals, and the absence of a relationship between recruitment or survivorship rates and the intensity of schistosome infection. The data indicate that N. squamipes can increase transmission of S. mansoni in endemic areas and carry it to noninfected areas. Furthermore, this rodent can be used as an indicator of trans mission foci.\n\nIn the Caribbean, B. glabrata can be found in shallow ponds with abundant vegetation or with fallen banana leaves. It has been also found in drains around banana plantations on the West Indian island of St. Lucia (Sturrock, 1975) .\n\nThis is a mosquito-borne parasitic worm infection, a debilitating parasitic disease, which affects 170 million people in the tropical and subtropical areas of Southeast Asia, South America, Africa, and the islands of the Pacific. While filariasis is rarely fatal, it is the second leading cause of permanent and long-term disability in the world. A person with the disease tends to have more bacterial infections in the skin and lymph system. This causes hardening and thickening of the skin, which in its most dramatic form is expressed in the symptoms of elephantiasis, the accumu lation of lymph, usually in legs. It is not a killer disease, but causes severe debilitation and social stigma. The WHO has named filariasis one of only six 'potentially eradicable' infectious diseases and has embarked upon a 20-year campaign to eradi cate the disease. In addition to consistent long-term treatment by oral medicines, eradication efforts focus on controlling the pro liferation of mosquitoes in aquatic environments, which will help to reduce the transmission of lymphatic filariasis, as well as that of malaria, which is prevalent in many of the same communities in Africa (CDC, 2005) .\n\nOnchocerciasis or river blindness is the world's second leading infectious cause of blindness. It is found in 36 countries in Africa as well as in Guatemala, southern Mexico, some areas of Venezuela, small areas in Brazil, Colombia, and Ecuador, and in the Arabian Peninsula. A total of 18 million people are affected worldwide. The disease is caused by Onchocerca volvulus, a parasitic worm that breeds in water and that can live for up to 14 years in the human body. Controlling insect breeding sites in rivers is one of the pillars of prevention. The disease is trans mitted person to person by bite of a blackfly (Simulium), which breeds solely in fast-flowing waters. Symptoms of the disease in a person usually begin to show 1-3 years after infection. Each adult female worm, which can be more than half a meter in length, produces millions of microscopic young worms (micro filaria). The microfilaria migrate through the skin and, upon death, cause intense itching and depigmentation of the skin (leopard skin), lymphadenitis, resulting in hanging groins and elephantiasis of the genitals, serious visual impairment, and blindness when they reach the eye. The disease blinds between 10% and 30% of its victims and seriously undermines the economic productivity of communities in endemic areas (WHO, 2001b; Figure 5 ). Figure 5 Onchocerciasis also affects the development of exposed children. Their school performance is affected by the unrelenting itching associated with this disease. Many youth are deprived of their childhood as they are often forced to guide and look after elderly relatives blinded by the disease. Photo credit: Bill VanderDecker In: http://www.pqmd.org/cms/node/116\n\nUnlike malaria and schistosomiasis, transmission of river blindness is usually found along fast rivers or streams with white-water rapids and cascades. The species of blackflies, which transmit this blinding parasite, require well-aerated, high-velocity flow to deposit their eggs, usually on rocks or overhanging vegetation. The larval stages are filter feeders and need large flows passing their habitat to obtain sufficient food and oxygen for development. In many parts of Africa, people living near rivers migrate out of the fertile river valleys because of the painful bites of the flies and the eventual blindness resulting from this parasite (Kim and Merritt, 1990) .\n\nRiver blindness has historically plagued the fertile valleys of West Africa, but it was the arrival of Europeans that unleashed the full force of the disease upon the region's inhabitants. Traditional taboos had kept people from settling along river banks or visiting streams in broad daylight, when blackflies are most active. White colonists, however, insisted on recreating the riverside towns they remembered from home. By removing longstanding cultural prohibitions, they made onchocerciasis more prevalent than it had been before. By the 1970s, several hundred thousand people had been blinded by the disease. Also tragically for the region, the most fertile farmlandan area roughly the size of Michiganwas abandoned due to the risk of contracting the disease (Wong, 2008) .\n\nCurrently, river blindness has been eliminated as a major public health problem in West African countries. Despite success in West Africa, 109 million people remain at risk of contracting river blindness in the 19 countries of Central, Eastern, and Southern Africa (Anonymous, 2007) . Due to the tight connec tions between the dynamics of this disease and changes in flow velocity, we will return to it in Section 10.12.3.3 in the discus sion of the effect of dams on human health. Table 3 provides a summary of relevant water-borne diseases produced by bacteria. We will concentrate on cholera and other Vibrio illnesses for the reasons explained below.\n\nThe case of cholera has been considered paradigmatic of the links between global climate change and infectious diseases. It offers an excellent example of how information about environ mental factors permits better understanding of disease virulence, transmission, and epidemiology. Therefore, and due to the links to wetlands and other coastal ecosystems, aquaculture, and water management in megacities, this disease will be discussed in detail in this and the following sections, in relation to the dynamics of its causative agent in aquatic ecosystems.\n\nCholera is still an important cause of morbidity and mor tality in many countries in Asia, Africa, and Latin America due to lack of safe water supply and poor hygienic practices (Colwell, 1996) . Cholera is endemic in the Ganges and Brahmaputra deltas. It was originally endemic to the Indian subcontinent but spread worldwide along the trade routes, and mostly affects developing countries, particularly in coastal zones. In the last \u223c200 years, there have been seven pandemics and there is evidence of accelerated change of Vibrio and disease dynamics as consequence of environmental changes and increased global connectivity (Faruque et al., 2003) . The cur rent pandemic, which started in 1961, is the most extensive in geographic spread and duration. Cholera epidemics were reported from over 90 countries during 1994, the largest scale ever recorded in human history (WHO, 1998) .\n\nVibrio cholerae, a Gram-negative comma-shaped gammapro teobacterium, is the causative agent of cholera ( Figure 6 ). Vibrios are aquatic bacteria of marine and estuarine origin but can survive and be pathogenic in freshwater ecosystems. Apart from V. cholerae, some other vibrios (V. parahaemolyticus, V. vulnificus, etc.) are also responsible for incidences of diarrhea, gastroenteritis, necrotizing fasciitis, and septicemia, which afflict human populations (Table 3 ) all over the world (Chakraborty et al., 1997) . Besides, many vibrios can also cause diseases in fish, shrimp, corals, and other aquatic organisms (Thompson et al., 2004) .\n\nThere are convergent approaches to the investigation of coral and human diseases. These include the research into the Figure 6 The causative agent of cholera, Vibrio cholerae, is a faculta tively anaerobic bacterium, 0.5-0.8 \u00b5m to 1.5-2.5 \u00b5m, and a natural inhabitant of temperate/tropical estuaries, salt marshes, mangroves, coastal waters, and reefs. Photo credit: Moredun Animal Health, LTD/ Science Photo Library/Photo Researchers, Inc.\n\nsame bacteria genus (Vibrio), responsible for coral bleaching and for cholera, the use of remote sensing of ocean-surface temperature, climate research, and an emerging common cur rent of epidemiological thinking. Traditionally, the association between water temperature and coral bleaching has been stressed, and only recently it has been discovered that this is probably triggered by a Vibrio bacterium, and that it could be transmitted by a coral-feeding worm, acting as 'vector'. It is the first time a vector has been found for a coral disease (Rosenberg and Falkovitz, 2004) . Table 3 Main water-borne illnesses produced by bacteria At the same time, the study of cholera disease has begun to encompass marine and estuarine research. The association of V. cholerae with plankton was established only recently, allow ing analysis of patterns of cholera epidemics, especially in those regions where it is endemic. The sporadic and erratic nature of cholera epidemics can now be related to climate-ocean coupling events, such as El Ni\u00f1o (Colwell, 1996) . Since zoo plankton has been shown to harbor the bacterium and zooplankton blooms follow phytoplankton blooms, remote sensing can be employed to determine the relationship between cases of cholera and ocean chlorophyll concentration, as well as sea-surface temperature, ocean height, nutrient con centrations, salinity, and turbidity.\n\nDuring each pandemic, cholera has struck coastal regions before spreading inland. The principal agents responsible for cholera epidemics are the O1 and O139 serogroups of V. cholerae, of more than 200 serogroups so far identified. Within the O1 serogroup, the classical biotype caused the pre vious six pandemics, while the El Tor biotype is associated with the present seventh pandemic. A coupling of Vibrio dynamics to that of aquatic, brackish ecosystems is strongly suggested by the marked cholera seasonality in coastal villages of the Bay of Bengal (Colwell, 1996) . The role of coastal areas in maintain ing endemicity is clearly a significant feature of cholera ecology. However, it was mainly laboratory research that provided evi dence for the existence of aquatic environmental reservoirs where V. cholerae survives for long periods of time and from which a toxigenic form may emerge to support epidemic con ditions (Miller et al., 1984 (Miller et al., , 1985 (Miller et al., , 1986 Barua and Greenough, 1992) . The O139 serogroup emerged in the coastal zone in 1992 through a natural genetic alteration of the O1 El Tor biotype. A survey in Bangladesh established that this strain was mainly found in southern coastal marshes (Faruque et al., 2003) . However, systematic, interdisciplinary field studies on the relationship between habitat characteristics and Vibrio diversity and virulence are scarce. Little has been done to widely monitor V. cholerae and study its ecology from a basin perspec tive in different related coastal environments such as mangroves, marshes, and estuaries, despite clear evidence that this could be one significant step forward for early warning and understanding human vulnerability to the disease (Collins, 2003) .\n\nAs early as 1884, Robert Koch suggested that the Bay of Bengal, especially the Sundarban mangrove forest, was the main source of cholera, noting that the combination of a brackish, organic-matter-rich environment, with a high den sity of human population represented the ideal conditions for the proliferation of V. cholerae (Koch, 1884) . However, since then, there have been no extensive surveys of this transbound ary ecosystem (Bangladesh and India), which represents the largest unitary mangrove and marsh system worldwide (Akhtaruzzam, 2004) . Difficult access, cyclones, floods, and the difficulty of obtaining funding for long-term research have precluded the systematic spatiotemporal monitoring of these habitats. Most of the few available works are based on one-site samplings and do not provide information on seasonal trends.\n\nPlankton is a significant marine reservoir of V. (Huq and Colwell, 1995) . In most cases, phytoplankton and zooplank ton are spatially and temporally associated (Kiorboe and Nielsen, 1994) and their abundance can be estimated by remote sensing, which has been related to cholera incidence in the Bay of Bengal region by Lobitz et al. (2000) . Living zooplankton can be a reservoir for vibrios, which attach them selves to the zooplankton's chitinaceous exoskeleton (Kaneko and Colwell, 1975) . Nevertheless, Watkins and Cabelli (1985) found that growth and survival of V. parahaemolyticus was more stimulated by addition of pulverized chitin, than by living zooplankton, which however had a greater effect than the addition of sewage or other nutrients. In addition to salinity, nutrients, and plankton, suspended particle load and sediment resuspension also influence the Vibrio amount in the estuary. Recent investigations (Lara, unpublished results) on seston size fractionation in Sunderbans waters showed that the largest amounts of chitin and cultivable Vibrio spp. were generally present in the fractions correspond ing to micro-, nanoplankton, microdetritus, and silt/clay particles, and not in zooplankton. It is still an open question whether the Vibrio serotypes O1 and O139, as well as the viable but not cultivable, and nonviable forms are preferen tially associated with determined seston size classes or wetland ecosystem compartments.\n\nBetter understanding of Vibrio diversity in aquatic environ ments such as estuaries, marshes, and mangroves can lead to new insights into their genetic expression and co-regulation in the environment where they interact with each other. However, most Vibrio studies treat species of pathogenic importance (e.g., V. cholerae, V. parahaemolyticus, and V. vulnificus) and not the diversity of the genus itself. A further key issue is the compre hension of the seasonality, life cycle, and dormant phases of bacterial population in nature. The environmental persistence of V. cholerae may be facilitated by entering a dormant state in which it remains viable but becomes nonculturable (VBNC) in conventional laboratory media (Colwell et al., 1985) . The V. cholerae cells attached to plankton enter into the VBNC state as survival strategy (Colwell and Huq, 1994) . Therefore, the detection of the nonculturable state is crucial to understanding V. cholerae ecology. However, the mechanisms that cause the organism to associate with plankton or other particles, to form biofilms, or to enter dormant or free-swimming phases are not yet completely understood.\n\nIn the Karnaphuli Estuary, Bangladesh, recent studies (Lara, unpublished) showed that suspended particulate matter (SPM) other than zooplankton contained significant amounts of chitin, especially in the size class <20 \u00b5m. The quantitative contribution of respectively nano-or bacterioplankton, microdetritus of biological origin, or resuspended sediment particles to the chitin pool in that size class is still unknown. Particle load together with salinity significantly influenced estuarine Vibrio distribution. We compared the microbial landscape dur ing a pre-monsoon situation and after a strong cyclone: the amount of cultivable Vibrio, and its relative contribution to total aerobic bacteria, increased dramatically after the cyclone. Amounts of SPM also increased and there were higher salinities along the estuary. Sediment resuspension and salt intrusion can thus strongly influence the abundance and distribution of estuarine Vibrio population.\n\nThe above findings call attention on essential questions relating estuarine dynamics and human health: Are vibrios in sediment part of a benthic community with its own character istics or do they basically consist of a fraction of a pelagic population reaching the sediment after sedimentation of the particles to which they are attached? Nair et al. (1988) also addressed the role of sediments as a possible Vibrio reservoir in freshwater environments in Calcutta. In Florida, there was a predominance of non-O1 V. cholerae infections at the time the organisms flourished in the sediment (Williams and LaRock, 1985) , which was detected down to 15-cm depth. Higher sedi ment Vibrio concentrations were associated with organic matter flocs occurring after the seasonal phytoplankton productivity maximum and during the zooplankton decline. This suggested that the flourishing of Vibrio in the sediments was related to the presence of organic matter input from plankton detritus. Thus, although plankton itself is an important aquatic Vibrio reser voir, its relevance for fueling benthic Vibrio seasonal cycles has probably been overlooked. The relevance of seasonally driven sediment resuspension in relation to annual cholera cycles in endemic regions deserves more attention. The incorporation of particle-bound vibrios and porewater nutrients into the water column could favor a sharp Vibrio increase, even at otherwise unfavorable salinities (Singleton et al., 1982) .\n\nFuture studies should investigate the links between the spatiotemporal estuarine variability and the ecology, diversity, and spreading mechanisms of vibrios including V. cholerae.\n\nA key question is how and to what extent these microorganisms persist in the transition from a brackish to a freshwater envir onment, involving strong gradients in salinity, pH, inorganic nutrients, dissolved and particulate organic matter, turbidity, plankton, and wetland vegetation. Further, an ecohydrological research approach should focus on how the distribution of the above factors influences the relative abundance of V. cholerae compared to the total Vibrio population and other bacterial groups in aquatic environments of West Bengal, including water and sediment compartments.\n\nThere have been efforts to predict cholera outbreaks through models relating disease incidence and environmental variables such as seawater temperature, chlorophyll content, height of the ocean surface, and rainfall, as well as by remote sensing (e.g., Lobitz et al., 2000) . Recently, an empirical model relating multiyear data of the number of cholera cases, rainfall, and chlorophyll was able to successfully reproduce outbreaks of cholera in Kolkata and Matlab over the time span of the data set (Magny et al., 2008 ). Yet, these authors stated that a finer temporal resolution (submonthly) in environmental data col lection was needed to improve mechanistic models and account for short-term variability, especially for the Kolkata region.\n\nThere is also evidence that cholera cases increased following a rise in ocean-surface temperature. However, a direct correla tion exists only for the spring peak, while during the rest of the year there are lags and even an inverse correlation between the two variables (Colwell, 1996) . Simple (lag) correlations between the seasonality of cholera and that of climate variables such as monsoon rainfall merely confirm that cholera is seaso nal (Bouma and Pascual, 2001) . These authors hypothesized that there would be two different aquatic habitats: the marineestuary type and the inland water bodies, with potentially different driving factors.\n\nAlthough much has been speculated about possible ocean/ land interactions based on empirical correlations, the causal links between ocean parameters and cholera incidence in ripar ian inland villages are tenuous, as discussed in the following. Zooplankton in freshwater has been considered a main trans mission means of V. cholerae to humans . Although tidal transport of Vibrio-carrying marine zooplankton toward the inland is likely and has been proposed by these authors as a possible infection source, until now there have been no studies demonstrating that marine copepods survive long enough to represent an infection source in freshwater, which is what people drink finally, and not seawater.\n\nSimultaneous variation of two parameters does not imply causality and, although the existing mechanistic models can be useful as predictive tools, they have not significantly contributed to explaining the reasons for cholera endemicity or the existence of bimodal and unimodal occurrence patterns in the Indian subcontinent. For example, sea-surface tempera ture in the Bay of Bengal shows a bimodal cycle similar to the seasonal pattern of cholera in Dhaka, Bangladesh (Colwell, 1996; Figure 7) , and is therefore often used, directly or through covarying parameters, with success for such models. However, this seems to mask the fact that strong unimodal patterns are observed elsewhere in India (e.g., North Bengal and Vellore; Jesudason et al., 2000; Bouma and Pascual, 2001) without any obvious relationship to the marine environment or even to temperature and rainfall.\n\nSeveral studies found that the effect of rainfall on cholera incidence does not show any univocal pattern (Glass et al., 1982; Bouma and Pascual, 2001; Ruiz-Moreno et al., 2007) . Even in Dhaka, which has a strong bimodal seasonality, there is no clear relationship between rainfall and cholera. The number of cases peaks before the monsoon (high rainfall period) and at its end, with a strong decrease in the middle of the monsoon. Recently, Hashizume et al. (2008) showed that the weekly number of cholera cases in the period 1996-2002 in Dhaka did not show any direct relationship to rainfall, and suggested that river levelbelow flooding levelalso plays a role. River discharge is controlled not only by rainfall but also by snow melting in the Himalayas and can control the survival of the bacterium through determining salinity and pH levels (Bouma and Pascual, 2001) . Hashizume et al. (2008) stated that, because of the observed and potential effects of chemical changes in surface waters due to rainfall on Vibrio survival and toxicity, it is necessary to quantify the level of V. cholerae in aquatic environments at the same time as measuring rainfall and river levels ( Table 4) .\n\nThis section deals with examples of diseases derived from or influenced by high nutrient loads, particularly those derived from toxic algal blooms, as well as with the general effect of global changes in nutrient cycles on parasitic infectious diseases According to toxin type and exposure: skin irritation, stomach cramps, vomiting, nausea, diarrhea, fever, sore throat, headache, muscle and joint pain, liver damage, and kidney disease In the body nitrate is reduced to nitrite, which reacts with hemoglobin forming methemoglobin, and reducing blood ability to carry oxygen; affects mostly infants and old persons (PIDs). Although arsenicosis affects millions of people, parti cularly in Bangladesh, the problem arises from using water from wells reaching layers where groundwater naturally con tains high As levels and there is, to date, no obvious way that ecohydrological methods could help solve this problem. For this reason, we will not discuss this disease further in this chapter.\n\nEutrophication in water reservoirs or semi-enclosed water bodies leads to the formation of intensive phytoplankton blooms. During recent years, both the incidence and intensity of such blooms appear to be increasing, when examined at the global scale. This increasing severity of algal blooms may be a consequence of increasing levels of nutrient enrichment as a result of sewage disposal, increased agricultural runoff, and changes in hydrological regimes potentially related to climate change (UNEP, 2002) . Blooms caused by toxic cyanobacteria (harmful algal blooms) lead to outbreaks of disease and dete riorated recreational and aesthetic values, causing both economic losses and illness and death of both humans and animals.\n\nIn evolutionary terms, cyanobacteria are one of the oldest organisms on Earth, dating back to more than 3000 Ma (Schopf, 2000) . They are oxygenic photosynthetic prokaryotes possessing the ability to synthesize chlorophyll a as their photosynthetic pigment. The nitrogen-to-phosphorus ratio (N:P) has been frequently used as a key indicator in predicting algal biomass and compositions, and its seasonal succession in lentic systems (Tilman, 1982; Kilham, 1990) . Smith (1983) pointed out that bloom-forming cyanobacteria had a tendency to dominate in a lake when the N:P ratio was less than 29. The significance of the N:P ratio as a critical factor, however, is still controversial, due to the variability of the other chemical char acteristics and phytoplankton composition within a geographic region. For example, cyanobacteria blooms can be induced by increases in the phosphorus concentration instead of by a decrease in the N:P ratio (Trimbee and Prepas, 1987; Sheffer et al., 1997) .\n\nCyanobacteria ( Figure 8 ) produce a variety of toxic com pounds known as cyanotoxins. The impacts of cyanotoxins on human health have been of increasing concern, as the impacts of cyanobacterial blooms on water supplies as well as nearshore marine ecosystems have become better understood. Outbreaks of poisoning from cyanobacterial blooms can be catastrophic, such as the death of 50 dialysis patients following exposure to inadequately treated water from the Tabocas Reservoir in Brazil (Pouria et al., 1998) or the hospitalization of 140 children and 10 adults who drank cyanobacterially contaminated water impounded by the Solomon Dam in Australia (Hawkins et al., 1985) . Cyanobacterial toxins have also been implicated in mortality in wild fisheries and terres trial mammals, and can accumulate in the ecosystem . Toxins are classified by how they affect the human body (WHO, 2001c): hepatotoxins (which affect the liver) are produced by some strains of the cyanobacteria Microcystis, Anabaena, Oscillatoria, Nodularia, Nostoc, Cylindrospermopsis, and Umezakia. Neurotoxins (which affect the nervous system) are produced by some strains of Aphanizomenon and Oscilatoria. Cyanobacteria from the species Cylindroapermopsis raciborski may also produce toxic alkaloids, causing gastrointestinal symptoms or kidney disease in humans. Not all cyanobacteria of these species form toxins and it is likely that there are other as-yet unrecognized toxins. Further, cyanobacteria produce a wide range of secondary metabolites, among which new cya notoxins continue to be found.\n\nBesides the recognized effects of the toxins mentioned above, a recent study opened up a discussion about possible new causes of known neurodegenerative illnesses. Cyanobacterial strains were found to produce the neurotoxic nonprotein amino acid, \u03b2-N-methylamino-L-alanine (BMAA) (Cox et al., 2003 (Cox et al., , 2005 . The BMAA is considered a possible causative agent of human motor neuron disease, amyotrophic lateral sclerosis parkinsonism/dementia complex (ALS/PDC), and has been found to accumulate in brain tissues of patients with progressive neurodegenerative illness (Murch et al., 2004) . This was first detected in humans as a consequence of dietary habits and biomagnification in terrestrial ecosystems in Guam (Cox et al., 2003) . However, sometime later, BMAA was detected in aquatic ecosystems, such as in seawater in the area of a Trichodesmium bloom and in freshwater and brackish waterbodies (Metcalf et al., 2008) . Cox et al. (2005) isolated BMAA in several species of free-living cyanobacteria.\n\nPossible implications of these findings (Cox et al., 2005; Ince and Codd, 2005) are that BMAA of cyanobacterial origin might occur in diverse natural and controlled environments where massive cyanobacterial populations occur. Because these environments can include waterbodies used for drinking and recreational use, BMAA in drinking water may contribute to chronic intoxication. This may involve incorporation of the neurotoxin into an endogenous protein reservoir with slow release (Murch et al., 2004) and a possible lag between expo sure and effect of years or decades. Since protein-associated BMAA can accumulate within food chains, it is possible that biomagnification of BMAA occurs in marine ecosystems in a way similar to that in terrestrial ecosystems (Banack et al., 2007) . Thus, production of BMAA by marine cyanobacteria may represent another route of human exposure to this neuro toxin. Cox stated that the BMAA produced by the algae may act as a slow toxin. For these reasons, it would be advisable to monitor BMAA concentrations in drinking waters contami nated by cyanobacterial blooms and in fish and animals that may be ingesting the microbes, even at low environmental densities. This can be particularly relevant in semiarid or arid regions that are highly dependent for their drinking water supply on reservoirs, in which cyanobacteria can regularly occur on a seasonal basis, normally in summer.\n\nFertilizer use, widespread cultivation of leguminous crops, and fossil fuel burning have produced strong changes in the global N cycle (Galloway et al., 2004) . More than half of all N fertili zers ever used in Earth's history has been applied in the past two decades (Howarth et al., 2002) . Moreover, increased N loading in the environment often occurs together with that of phosphorus. In freshwater ecosystems in particular, a com bined increase in both N and P is highly likely to drive eutrophication and associated significant ecological change. McKenzie and Townsend (2007) reviewed direct and indirect evidence that changing global nutrient cycles are influencing the dynamics and incidence of PIDs ( Figure 9 ). Some of the disease agents discussed earlier in this chapter could react particularly sensitively to increased N and P loads. Although generalizations are difficult, the evidence presented by these authors, together with past reviews by Lafferty (1997) and Townsend et al. (2003) , suggests a trend in which most asso ciations between increased nutrients and disease are positive.\n\nA parasite or pathogen may respond to nutrients directly, that is, without requiring an intermediate or vector host; or an inter mediate or vector host may respond to nutrients, mediating the overall disease response. There can be an increase in vector host population density as a result of increased primary productivity, or a decrease in population due to some disturbance related to nutrient addition, in both cases resulting in changes in transmis sion success of the parasite or pathogen (Anderson and May, 1978; Dobson, 1990; Arneberg et al., 1998) .\n\nBesides the above-mentioned increase in cyanobacterial blooms, increased nutrients could particularly affect ecological processes associated with, for example, malaria, schistomiasis, cholera, and filariasis, leading to a higher occurrence of these diseases. For example, vector-borne pathogens that cause malaria and schistosomiasis involve intermediate hosts (mos quitoes and snails) whose growth and reproduction depend on algae or weed abundance in their respective environments.\n\nWhere N additions cause greater plant growth and/or changes in plant species composition, the density of these intermediate hosts is also likely to be affected, with cascading consequences for the risk of disease. Lafferty (1997) reviewed parasitic responses to a suite of environmental changes and found that, in most cases, eutrophi cation caused an increase in parasite abundance. Johnson and Carpenter (2008) suggested that planorbid snails in nutrient-rich environments grow faster. Larger individuals are able to produce significantly more trematode cercariae at a faster rate. The avail able evidence suggests that, in general, nutrient additions should favor trematode development and increase disease risks.\n\nIn the case of cholera, the bacteria display a strong associa tion with marine plankton, and, therefore, factors that cause increases in plankton primary productivity can also increase the prevalence of V. cholerae. Thus, nitrogen-based eutrophication of coastal regions (NRC, 2000) has been linked to increased cholera risks (Epstein, 1993; Colwell and Huq, 2001) , prob ably as an indirect response to plankton dynamics.\n\nChanges in the N cycle are not globally uniform (Galloway et al., 2004) . The largest changes have occurred in industria lized countries but the focus of global change is shifting to tropical and subtropical countries, where greatest relative changes in the N cycle over the next 50 years are expected (Galloway et al., 2004; Dentener, 2006) . For example, the booming soybean agriculture in Brazil in the last decade is leading to rapid increases in regional N deposition and nutrient loading to aquatic ecosystems (Martinelli et al., 2006) . Similar increases are occurring throughout tropical and subtropical portions of Asia and Central America. These same regions harbor the greatest diversity of human PIDs (Guernier et al., 2004) , including those that currently cause the majority of PIDrelated human deaths (WHO, 2004b) . Thus, the next decades will probably bring an increase in the potential for nutrients, especially N, to affect parasitic and infectious diseases in these regions. The changes in temperature and rainfall regime in temperate regions and the changes in land use resultant from them or from market shifts can exacerbate that potential.\n\nDiseases produced by viral infections can emerge, reemerge, and be transmitted by several different, but often interlinked, mechanisms involving tight interactions between man and domestic and wild animals sharing artificial or natural aquatic systems. Table 5 summarizes some viral diseases of worldwide relevance. In the following section, we will focus on avian influenza due its multiple and complex connections with the dynamics and use of wetlands by man and animals.\n\n10.12.2.5.1 Influenza: Human and animal links between artificial and natural wetlands Nutrient reduction in wastewaters or surface waters is a prior ity for reducing risks to human health. Nevertheless, from the point of aqua-and agriculture, the nutrients contained in wastewater are a valuable resource, in particular in arid and semiarid regions. Wastewater form has been used for aquaculture, for example, in duck ponds, in several countries, mainly in Asia, for centuries to produce human food. Organizations such as WHO, Food and Agriculture Organization (FAO), etc., have developed guidelines for the safe use of wastewater, excreta, and gray water in agriculture and aquaculture in order to provide a basis for the develop ment and implementation of health risk assessment and management approaches, including standards and regula tions, to address hazards associated with human waste-fed aquaculture (Edwards, 2008) . However, wastes and fecally polluted surface water are often used without any pretreat ment or assessment of the presence of pathogens. Various hazards are associated with waste-fed aquaculture: excretarelated pathogens (bacteria, helminths, protozoans, and viruses), skin irritants, vectors that transmit pathogens, and toxic chemicals.\n\nWastewater systems were also developed independently in India from the 1930s, in China from the 1950s, and in Vietnam from the 1960s onward, but they were designed primarily for aquaculture, not to treat wastewater. Few engineered waste water-fed aquaculture systems have been developed recently. Systems primarily engineered to treat wastewater that incorpo rated aquaculture were developed in Germany from the end of the nineteenth century, but only the Munich system remains, and only for tertiary wastewater treatment and currently as a bird sanctuary (Edwards, 2008) . In this, the following aspects in the dynamics of bird popu lations are of ecohydrological and biomedical relevance. During migratory movements, birds carry pathogens that can be transmitted between species at breeding, wintering, and stopover places where numerous birds of various species are concentrated, such as wetlands. A study by Jourdain et al. (2007) focused on bird migration routes to the Camargue in relation to risk of pathogen dispersion into western Mediterranean wetlands. They considered two pathogens clo sely associated with wild birds: avian influenza (AI) virus and West Nile virus (WNV). The AI viruses have a water-borne transmission, and ducks are their main natural reservoirs (Easterday et al., 1997; Alexander, 2000) ; WNV has a vectorborne transmission, and passerines are believed to play a major role in the amplification cycle (Hurlbut, 1956; Malkinson and Banet, 2002) . Despite different transmission cycles and ecology, both viruses are known to be carried by reservoir birds during migration and have been associated with emer ging disease transmission risk for humans and domestic animals (Rappole et al., 2000; Reed et al., 2003; Olsen et al., 2006) . Environmental conditions, avifauna abundance, and diversity, as well as the interactions among birds from different species and departure sites in stopover wetlands, may be of key importance in terms of virus communication (Hudson et al., 2002) .\n\nFor water-transmitted pathogens such as AI viruses, the risk of transmission may be associated with the number of ducks congregated on the same water body, particularly in autumn and winter. This crowding of wintering species, in addition to the permanent presence of a transient population of birds using wetlands to stop off during migration, could provide the conditions for the circulation and rapid dissemi nation of AI viruses. For vector-transmitted pathogens such as WNV, transmission possibilities depend both on reservoir bird density and on the dispersion capability and activity periods of the arthropod vectors. The risk for interspecific transmission of disease is particularly problematic when wild and domestic species are involved. Ducks are the aquatic birds most likely to come in contact with free-range poultry, especially because the presence of congeners can induce migrating wild ducks to make a stopover (Jourdain et al., 2007) .\n\nThe study by Jourdain et al. (2007) showed that western Mediterranean wetlands are a hub for birds from several differ ent origins in Central Asia, Siberia, northern and Eastern Europe, western Africa, and the Mediterranean basin. As exam ple for the potential of wetlands for introduction or reemersion of these viruses, they state that WNV dispersion by birds migrat ing from sub-Saharan Africa might explain why an outbreak occurred in 2000 in the Camargue, even though the virus had not been observed there since the 1960s.\n\nBesides migration, breeding ducks in the aquaculture ponds can increase virus circulation between ducks, water, sediment, fish, and man. In a study (Markwell and Shortridge, 1982) of the occurrence and persistence of influ enza viruses (Hong Kong type) within domestic duck communities, the virus was isolated throughout the year from feces or pond water or both, indicating a cycle of water-borne transmission. Infection was asymptomatic and virus persistence in the duck community appeared to be dependent upon the continual introduction of ducklings sus ceptible to infection onto virus-contaminated water, since the feces of ducks 70-80 days old were generally virus-free despite the ducks' exposure to the virus in pond water. The normal practice of raising ducks of different ages on the same farm, where the water supplies are shared (Figure 10) , appears to be instrumental in maintaining a large reservoir of influenza viruses in the duck communities.\n\nDomestic ducks may act as a silent reservoir for the H5N1 AI virus. The concern is greatest in rural areas of affected countries, where traditional free-range ducks, chickens, and wildlife frequently share the same water source. Domestic ducks can harbor the virus for long periods and without showing any sign of illness. An altered role for domestic ducks is further supported by evidence that the H5N1 virus circulating in parts of Asia has increased its virulence in chick ens and mice (a laboratory model for mammals), and has expanded its host range to include larger mammals (e.g., cats and tigers), not previously considered susceptible to infection (FAO, 2004) .\n\nThe assessment of respective roles of routes and timing of wild waterbird migration and poultry imports is of utmost importance in order to objectively identify the origin and pos sible evolution of an outbreak in a determined country. For example, the avian flu outbreak in Nigeria in 2006 may have been caused by the supply of infected live poultry including day-old chicks from different sources, including East Asia and Turkey, and not by wild waterbirds. This is supported by sam plings of 5000 wild waterbirds in African wetlands, in which no evidence of the H5N1 virus was found, indicting that wild birds probably played a relatively minor role in the spread of AI in that region. Northward migration of wild birds from Africa to Europe in the northern spring of 2006 did not cause any major outbreaks. Nor do wild birds seem to play a role in Indonesia, where H5N1 has been present for some years and several cases of human infections have been recorded. However, although not many major outbreaks took place in Europe in 2006, there is evidence to suggest that wild birds did play a significant role in spreading the disease on the European continent (AIWEB, 2006).\n\nUseand Scarcityon Human Health: Some Examples from Aquaculture, Megacities, Dams, and Intensive Agriculture\n\nAquaculture in or close to wetlands is increasing worldwide. Besides being responsible for massive wetland destruction, aqua culture itself faces serious problems, arising from several diseases that can affect shrimp ponds. Among the groups of microorgan isms that cause serious losses in shrimp culture, the best known are bacteria because of the devastating economic effects they have on the affected farms. As mentioned before, Vibrio organ isms attach themselves preferentially to chitin surfaces, such as in zooplankton and shrimp exoskeletons. Bacterial diseases, mainly due to Vibrio, have been frequently reported in penaeid shrimp culture systems. At least 14 Vibrio species are implicated in disease outbreaks in shrimp, including Vibrio harveyi, V. alginolyticus, V. vulnificus, V. parahaemolyticus, and V. cholerae (non-O1) (Venkateswara, 2008 ; Figure 11 ).\n\nVibrios can produce different chitinases to degrade various chitin types (Svitil et al., 1997) in marine, estuarine, and Figure 11 Example of Vibrio disease affecting shrimp. In such severe cases, extensively melanized black blisters can be seen on the carapace/ abdomen of the infected animals. Copyright National Institute of Oceanography, Dona Paula, Goa, India, 1998.\n\nPond and irrigation canal next to live poultry markets. In http://www.eastwestcenter.org/index.php?id=5518&print=1 freshwater environments. Further, Meibom et al. (2005) found that V. cholerae can acquire new genetic material by natural transformation during growth on chitin. Thus, natural compe tence occurring in chitin-attached bacterial communities can act as a powerful driver of V. cholerae evolution, which could be accelerated by environmental events such as high nutrient input, giving rise to copepod blooms. It is still unclear whether growth on a determined type of chitin substrateand the production of the corresponding specific chitinasespromotes the capture of external genetic material by vibrios. This empha sizes the need for biogeochemical characterization of different aquatic microhabitats, such as different types of chitin-contain ing particulate matter, besides living zooplankton, in environmental studies of Vibrio diversity and virulence. As organic-matter-rich aquatic environments contain multiple microbial strains and species and high concentrations of bac teriophage and free DNA, horizontal gene transfer (HGT) provides the most likely explanation for why Vibrionaceae have developed high levels of genomic diversity (Meibom et al., 2005) . Interestingly, the cholera toxin gene (ctx) is a phage-mediated mobile genetic element that is transferrable to genetically closely related bacterial strains. In the aquatic environment, vibriophages can regulate seasonal disease out breaks, for example, seasonal cholera epidemics in Dhaka were inversely correlated with the prevalence of environmental cho lera phages (Faruque et al., 2005) .\n\nThe V. cholerae (non-O1) is frequently isolated from sewage, estuarine waters, and seafood in cholera-endemic and noncholera-endemic countries. It has been associated with sporadic episodes of diarrhea worldwide, but has not caused pandemics. Interestingly, in 1990, there was the first report of an epidemic of diarrhea caused by V. cholerae non-O1 that produces heatstable toxin, affecting Khmers in a camp in Thailand. In con trast to the V. cholerae O1 isolated from the same camp, in 93% of the cases, the non-O1 were resistant to three or more anti biotics (Bagchi et al., 1993) . This calls attention to several important aspects in relation to threats to human health. The fact that the toxin is heat stable could imply a higher diarrhea risk for humans consuming cultured seafood as cooking would not completely eliminate toxin activity. Its higher resistance to antibiotics compared with V. cholerae O1 potentially increases the disease hazards associated with these non-O1 strains. Further, as mentioned previously, the abundance of chitinac eous substrate can favor mutations. Thus, just as V. cholerae O1 evolved from a nonpathogenic to a pandemic-causing form (Faruque et al., 2003) , it cannot be excluded that the high individual density of aquaculturein the same way as megacitiescould be favoring the emergence of new and highly pathogenic Vibrio types.\n\nIn many of the world's cities, water management and sanitation are in crisis and will dramatically worsen with the continuing growth of cities and slums. Sewage pollution is the largest and most common type of pollution and one of the most common causes of illnesses. Illnesses caused by sewage pollution are estimated to affect the health of more than 120 million people at any one time. Contaminated water, inadequate sanitation, and poor hygiene cause over 80% of all disease in developing countries; diarrhea is the world's second most serious killer of children, but paradoxically in 90% of cases it could be easily prevented or treated. Pollution of water sources by sewage contributes to 4 billion cases of diarrhea in the world each year, killing some 2.2 million children under the age of 5. Poor sanitation currently affects 2.5 billion people, 40% of the world's population, who lack access to even the most minimal toilet facilities. The number of people without sanita tion will double to almost 5 billion in 2025, as the world becomes more urbanized (Anonymous, 2002) .\n\nSome 160 000 people are moving to cities from the country side every day. At least 600 million people in Africa, Asia, and Latin America now live in squatter settlements without any sanitation whatsoever. The pollution of rivers and groundwater by sewage spreads disease and causes environmental degrada tion. In Latin America, as a whole, only 2% of sewage receives any treatment. In Asia, the level of sewage in rivers is 50 times higher than the United Nations (UN) guidelines. Levels of suspended solids in Asia's rivers almost quadrupled since the late 1970s. Every minute 1.1 million liters of raw sewage are dumped into the Ganges River (Vidal, 2002) .\n\nMost megacities are in Asia. Dhaka's population rose from 250 000 in the early 1970s to \u223c12 million today, including the metropolitan area, and will probably reach 23 million in 2015. In the same time, Kolkata's population grew from 3 to 5 million; including the metropolitan region, its population is 13 million and is predicted to reach 17 million in 2015. Pakistan experienced one of the highest growth rates of popu lation worldwide: it quadrupled in only 60 years to over 170 million in 2008 (PRB, 2008) . According to the World Bank, Karachi is one of the fastest-growing megacities of the world and is expected to rank seventh by the year 2015 (Kamal, 2005) . The country faces a serious situation in terms of water availability, depletion, and pollution of its water bodies and irrigation systems as well as a severe degradation of its coastal ecosystems. This complex and multifaceted setting will be clo sely analyzed in the following sections.\n\nIt has been reported that at least 12 of the 18 towns of the city are supplied with water unfit for human consumption, in most cases infected with Escherichia coli. Only around 30% of the total sewerage generated by Karachi at present is treated. The E. coli, found in human feces, and other bacteria found in drinking water could cause life-threatening diseases, including diarrhea and cholera. The bulk of the drinking water concerned is taken from the Indus River. Bacteria easily enter the drinking water as the pipelines are rusted and leaking (IRIN, 2004) . Lowintensity seismic activity, though normally not felt by people, probably further damages worn-out pipelines. Additionally, due to the water shortages, the pipelines remain empty for a considerable amount of time daily, during which time they develop negative pressure and absorb moisture and sewage that has leaked from the nearby, similarly worn-out sewers. Additionally, after rains, rainwater mixes with sewage and gar bage can enter the pipelines through the leaks to contaminate the drinking water supply, making people vulnerable to numer ous health hazards (Hasan, 2008) .\n\nKarachi is situated in a desert. However, in a study by Sheikh et al. (1997) the analysis of microbiological data for the period 1990-96 showed the permanent presence of cholerawith seasonal periodicityin Karachi. Cholera cases peak each year between May and August in both epidemic and nonepidemic years. Both V. cholera O1 and O139 serogroups were involved in the outbreaks in 1993 and 1994; O139 disappeared in 1996. The role of rain in disease seasonality and incidence is not clear. Rainfall is scarce and sporadic, usually only between June and August. In 1994, the city could have been flooded, with wide spread overflowing sewers, whereas, in 1993, there was virtually no rain at all. Cholera appears each year before the rains, and epidemic years in the 1990-96 data set appear to have occurred independently of rainfall.\n\nLike most enteric diseases in an endemic setting, cholera in Karachi is a disease of young children. The mean age of patients with acute cholera in Karachi closely resembles that in the rest of the Indian subcontinent where social conditions are com parable. Despite this association with poverty, 9% of the patients in the study were admitted to expensive private rooms in good hospitals. This shows that, in a city with a sanitary infrastructure like that of Karachi, personal wealth affords no protection (Sheikh et al.. 1997) . Visitors and tourists are also at risk. In the same context, despite the common perception that bottled water was safe and pure, microbiologi cal tests showed that about 35% of 3500 samples of water supplied in many bottled brands tested all over the city was unfit for human consumption (Hasan, 2008) .\n\nAccording to the same above-mentioned study, in 1993, the new strain of V. cholerae, serogroup O139, established itself in Karachi and during 1993 and Karachi experienced over lapping, but distinct epidemics of both strains. The serogroup O139 never wholly replaced serogroup O1, and by 1996 it had disappeared. At that time, it was still unclear whether the dis appearance would be permanent, or whether O139 would reemerge in subsequent epidemic years. Karachi is in a semi desert area, and the strain may not be able to maintain itself outside the human host (Sheikh et al., 1997) . This strain has also shown diminished ability to maintain its epidemic potential in Bangladesh, and it has been suggested that one reason for this may be that it is less able to persist long term in the aquatic environment (Faruque et al., 1996) . However, years later, in July 2002 and June 2003, cholera outbreaks were detected by a diarrhea surveillance system in a fisher village near Karachi (Siddiqui et al., 2006) . The first outbreak was caused by V. cholerae O139 and the second one by serotype O1. It would be erroneous to conclude that, because of the relatively small number of persons affected, these cases are not relevant in terms of public health. On the contrary, they should be considered extremely valuable indicators of environmental change, especially of aquatic systems, which provide an early warning of possible future trends for policymakers and sanitar ians. Water source was a risk factor only in the first outbreak: a reservoir in the village containing brackish water was only used for washing utensils and clothes and for bathing. Only illness caused by V. cholerae O139 was associated with the use of reservoir water, while O1 cases were not. Washing the clothes of infected persons may have introduced the pathogen into the reservoir. This implies that V. cholerae O139 was probably able to survive for a time outside the body and in water long enough to infect other people. This may be partly because the water was salty and that V. cholerae is a salt-loving bacterium.\n\nIn summary, fecal pollution, increased nutrients, turbidity, and sodium content create favorable conditions for the propagation of V. cholerae in Pakistan's coastal zone, megacities, and irrigation systems. When the increasing pollu tantchemical and microbiologicalload reaches the coastal region, it encounters a disturbed wetland ecosystem (discussed in Section 10.12.3.3.2), where vibrios could potentially multi ply and mutate to new pathogenic types. A close regular surveillance of vibrios at basin level, including in the coastal region, rivers, and channels, and in humans is essential in this region, which has the potential to become an epidemic center. Further, restoration of riparian forests and wetlands habitat should be a priority to avoid further habitat loss, and potential host shifts, although salinization would probably preclude the reinstallation of the same species existent before dam building and population explosion.\n\nThe Hoogly River is the most important source for the water supply of Kolkata. Through an agreement with Bangladesh, only a determined amount of water from the Ganges can be diverted into the Hooghly River during the dry season. Although this does not increase the amount of pollution in the river, it does increase its concentration. During the mon soon, rubbish and feces are washed out from the city into the ground and into the river (Karthe, 2002) . Around 30% of the water supply is lost through leakages in the obsolete distribu tion network, reservoirs, and public water tap connections. However, the disposal of sewage is an even greater threat to human health. Reduced capacity of the inadequate sewer net work, aggravated by obstruction caused by mud or garbage, as well as flooding during the monsoon produces pollution of surface and groundwater with enteric bacteria.\n\nAs in Karachi, interruptions or shortages in the water supply produce a negative pressure in the pipelines, which then absorb polluted water that had leaked from sewers and the surface, especially during the monsoon season. Before and after the monsoon, water quality increases, that is, bacterial load decreases. Following several cholera epidemics, the chlor ination of unfiltered water supply began in 1963. This reduced cholera incidence, but supply of potable water to many parts of the city is still insufficient. People in shanties frequently get untreated water from hydrants, or from the river (Hensgens, 2005) . Cholera seasonality in Kolkata is further discussed in Section 10.12.3.3.1.\n\nThe situation in London 150 years ago resembled current conditions in many megacities in developing countries. By 1851, half of the population of Britain was living in townsthe first society in human history to do so. Over the previous 70 years, Britain's population had risen at an unpre cedented rate. Large towns were desperately unhealthy, with death from sickness at a level not seen since the Black Death (Daunton, 2004) . London had a large scavenger class living off the refuse of the citya group so numerous that it could have formed the fifth largest city in England. New epidemics affected the citiescholera and typhoid were carried by polluted water, typhus was spread by lice, and 'summer diarrhea' was caused by swarms of flies feeding on horse manure and human waste. London suffered from recurring epidemics of cholera and in 1853-54 more than 10 000 Londoners were killed by the disease (Johnson, 2006) .\n\nThe frequent occurrence of cholera in London gave impetus to legislation, enabling the Metropolitan Board to begin work on sewers and street improvements. By 1866 most of London was connected to a sewer network brilliantly devised by Joseph Bazalgette (BBC, 2009) . The flow of foul water from old sewers and underground rivers was intercepted and diverted along new, low-level sewers, built behind embankments on the river front and taken to new treatment works. By 1870, both the Albert and the Victoria Embankments had been opened. The Victoria Embankment protected Bazalgette's low-level sewer from the hydraulic pressure from the Thames Estuary. The Chelsea Embankment was completed in 1874. The Public Health Act of 1875 required local authorities to implement building regulations, or bylaws, which insisted that each house should be self-contained, with its own sanitation and water. This change in the design of housing complemented the public investment in sewers and water supply. Cholera never reappeared in London after that.\n\nLondon was the largest city on the planet in 1854, but now it is on the small side, in comparison to, for example, Mexico City, S\u00e3o Paulo, or Mumbai. Massive shantytowns have exploded at the margins of today's megacities. In such places, the water-borne diseasesincluding cholerathat plagued Victorian London are still widespread, thanks to insufficient public health and sanitation resources. Worldwide, up to a billion people live in shantytowns and according to some projections this will increase to a quarter of the world's popula tion by 2030 (Johnson, 2006) .\n\nDespite enormous progress in the molecular biology of V. cholera, still little is known about basic forces, such as spatial biogeochemical gradients, seasonal rainfall variations, or cyclones, driving its abundance, diversity, and virulence in the basins of rivers and estuaries of the Indian subcontinent. The most recent detailed studies on seasonal variations of estuarine salinity and related urban cholera incidence are from the 1950s (Chatterjee and Gupta, 1959) . These compare the river systems Kolkata-Hoogly (a main branch of the Ganges) and London-Thames (data from the nineteenth century), and are discussed in Miller et al. (1982) . An important aspect of the 1950s data is that minute but clearly delimited salinity oscillations (e.g., 0.01-0.15 and 0.05-1 ppt) in the Hoogly River tightly correlate with cholera incidence in Kolkata. Several authors reported significantly higher salinity ranges for the growth and persistence of V. cholerae in the environ ment, for example, 2.5-30 ppt (Miller et al., 1984) or 5-25 ppt (Singleton et al., 1982; Louis et al., 2003; Randa et al., 2004) . Salinities <1 ppt were considered suboptimal (Miller et al., 1984) . However, Kolkata's data clearly indicate cholera out breaks at much lower salinities. Such oscillations could also be a proxy of other processes occurring at basin level, which were responsible for triggering the cholera outbreaks. Vibrio survival at low salinities can be facilitated by adsorption onto algae, zooplankton, or by high nutrient concentrations. Unfortunately, this information mostly originated from stag nant water bodies or short-term investigations (e.g., Islam et al., 1994, 2007 and references therein) , but no studies are available about the seasonality of hydrology, biogeochemistry, and Vibrio dynamics in flowing waters of the large rivers in this region through which vibrios most likely spread from the coastal zone toward inland habitats.\n\nSince the 1950s, seven large dams for irrigation purposes have been constructed in India. The Farakka Barrage, complete in 1975, diverts the Ganges River water into the Hooghly River during the dry season to flush out the accumulating silt in the port of Calcutta. It cuts off Bangladesh's water supply, elevating salinity, and has affected fisheries, caused desertification, and hindered navigation, and poses a threat to water quality and public health (Wolf, 2001) . There is evidence of changes in cholera seasonality due to hydrologic disturbances. Before the 1970s, the peak cholera season in Dhaka was November-February; now it is September-November. In Kolkata, season ality has changed twice since the mid-1950s (NICED, 1978 . These shifts may be related to changes in salinity, particle load, and associated estuarine biogeochemistry due to, for example, the construction of the Farakka Barrage on the river Ganges (Mirza, 1998) or increased melting of Himalayan glaciers (UNEP, 2007) . More that 25 years ago, Miller et al. (1982) postulated that dam construction in India could influence Vibrio dynamics by salt intrusion. These aspects deserve further investigation; apart from the 1950s data, there are no other published data series systematically relating these parameters in the rivers of the region with cholera incidence. This informa tion is essential in order to evaluate the transboundary effects of dam construction and water management. Dam construc tion in India has reduced riverine discharge in Bangladesh, inducing desertification in its northern sector and facilitating salt intrusion into its estuaries, particularly in the southwestern region (Wolf, 2001; Adel, 2005) . This resulted in changes in land use from rice cultivation to shrimp farming in the southern Bay of Bengal (Gebauer, 2007) (discussed in Section 10.12.3.1). Salinization of inland water bodies can facilitate the spreading of the halophilic Vibrio organisms and affect drinking water availability. On the other hand, global warming increases glacier melting and associated riverine runoff. Both factors, in a frame of increasing intensity and frequency of cyclones and flooding events, create an extremely complex situation in the coastal zone that could result in shifts in seasonal cholera patterns.\n\nDespite the different overall climatic setting of Pakistan as com pared to India and Bangladesh, increasing water needs in Pakistan are leading to a similar situation in the coastal zone, including increased cholera incidence. The common factors are the halophilic character of Vibrio cholerae and other vibrios and the salinization of estuaries and inland waters. Water needs for irrigation of desertic and semidesertic areas, as well as for drinking water supplies, mainly for Karachi and Islamabad, have led to the construction of several dams along the Indus River. Within the Sindh province, there are three major barrages on the Indus-Guddu, Sukkur, and Kotri. Severe reduction of water flow below the Kotri Barrage started affecting environments in the area from 1960s onward, with the following consequences in the river basin: (1) drying up and death of riparian forests, Figure 12 The Indus Delta faces major degradation threats, whose major cause is the reduction in the flow of freshwater from the Indus River. As the delta dries up and the mangrove forests decline, the sea is slowly sweeping in.\n\nwhich occurred soon after 1970; (2) reduction of the area under fruit and vegetable crops; (3) destruction of natural pastures causing a reduction in animal populations; and (4) desertifica tion leading to a shifting of human settlements. In the coastal region, intrusion of seawater in the river bed to a distance of 80 km upstream from the shore, with percolation of saline water from the riverine areas into groundwater of adjoining irrigated areas, has turned shallow water lenses brackish ( Figure 12) . Another reason for accelerated salinization in the Indus River is the saline water discharges from the Salinity Control And Reclamation Program in the North-West Frontier Province, Punjab, and India (Hasan, 2008) .\n\nAlong the coast, the increase in salinity of seawater along the whole coastline of Sindh has resulted in damage to man groves, colonization by other halophilic species, and the abandonment of \u223c6500 ha of land reserved for shrimp farming by the Government of Sindh.\n\nSea shrimp can survive within salinity range of 17-27 of water, but in the space of 5 years , salinity rose beyond the tolerance limit. Water salinity in sea creeks and estuaries increased from \u223c25 to over 35 ppt, making estuaries inhabitable for some shrimp and other species of commercial interest. In conditions of low salinity, shrimp farming could have been established all along 320 km of seacoast. Sea fish and prawn catch has declined considerably and severe erosion due to reduced sediment load occurs along the coast. In the coastal region, the livelihood of fishing communities and the fishing industry as a whole depends on ecosystem integrity. However, this has already been devastated by reclamation of former marine areas, and of mangrove marshes and mudflats. It desperately needs to be protected, for no city that destroys the ecology of the region where it is situated can be sustainable. The South Asian tsunami gave ample proof of this and so did the flooding of Karachi, much of which is the result of reclama tion from mangrove marshes, creeks, and natural drainage channels for elite real estate (Hasan, 2008) .\n\nIn addition to the deeply disturbed aquatic ecosystems described above, only 2% of cities with a population of over 10 000 have wastewater-treatment facilities. Of the wastewater generated daily, 36% is used in agriculture and 64% is disposed of into rivers or the Arabian Sea (IWMI, 2003) . Directly or indirectly, 90% of the people of Sindh, in rural or urban regions, drink water from the Indus. Salt content at Kotri reaches 0.60 ppt in winter months, and supplies to Karachi range from 0.25 to 0.60 ppt (Panhwar, 2000) . The combina tion of a riverine environment with increasing salinity, growing populations, lack of sanitation, input of untreated sewage, drinking water contaminated with enteric bacteria, and rela tively high sodium content is very similar to that in London during the cholera epidemics in the nineteenth century (see Section 10.12.3.2.4). Recently, a cholera outbreak in Mirpur Khas, a district of Sindh province, has been reported (Anonymous, 2008) . Scientists at the University of Health Sciences found out that around 50% of the patients were affected by cholera instead, as was previously thought, by gastroenteritis. The authorities have been requested to pay particular attention to this outbreak of cholera, which could spread to the other areas of the province. Mirpur Khas has a population of \u223c357 000, has successful agriculture, and is con nected to the Indus via irrigation canals. The irrigation system of Pakistan has been considered \"one of the largest contagious systems of the world\" by Gachal et al. (2007) .\n\nThe reservoir formed by the Three Gorges Dam (TGD) is the largest in the world at over 600 km in length. Studies about the impact of parasite dynamics have been restricted to medically important species such as Schistosoma japonica (Zheng et al., 2002) . These studies have focused on the distribution of the intermediate host Oncomelania hupensis within the TGD area and associated downstream water bodies. Before construction of the dam, neither O. hupensis nor S. japonica occurred in the reservoir region. However, it is widely predicted that the dam will lead to the introduction of S. japonica into the TGD region, while downstream both positive and negative effects on schistosomiasis transmission will occur (Zheng et al., 2002) . Nevertheless, a survey of the recently filled reservoir (Jobin, 2005) concluded that because of the very steep shoreline along most of its length and subsequent narrow photic zone, which provides only a limited area for the growth of plants, there was little chance of O. hupensis, principally a marshland snail, becoming established. However, these unfavorable topo graphic conditions do not preclude other mollusk species colonizing the shoreline (Morley, 2007) . For example, former gravel quarries converted into lakes have a steep-sided profile with a narrow discontinuous zone of plant life but support a diverse molluskan-trematode community (Adam and Lewis, 1993; Morley et al., 2004) .\n\nRiver blindness is an important parasitic disease around tropi cal dams in Africa, along the Red Sea in Arabia, in Central America, and in parts of South America. The rapids of the upper Nile River used to be a classic focus of this blinding parasite, spread by the bite of a species of blackfly, which breeds in white-water habitats and on dam spillways.\n\nIn Uganda (Jobin, 1999) , the history of river blindness can be traced to the Owen Falls Dam in the upper Nile River. This dam flooded out Owen Falls and also Ripon Falls near the outlet of Lake Victoria. The history of the impact from the Owen Falls Dam on onchocerciasis over the last 50 years shows the importance of optimal water current velocity regulation for the avoidance of reduction of this and other water-borne dis eases such as schistosomiasis.\n\nPrior to construction of the Owen Falls Dam (Figure 13 ), river blindness was endemic among the Buganda people, downstream along the Nile. In 1950, the prevalence of the parasite was 65%. To protect the workers, weekly applications of DDT were made at the outlet of Lake Victoria, treating the entire flow during the construction phase, and eliminating the blackflies for at least 50 km downstream. After dam completion in 1954 and discontinuation of DDT applications, the black flies did not return to their former habitats downstream of the dam. By 1974, the prevalence of the parasite had decreased to 0.2% among the populations along the river. The fact that blackfly populations did not return to former levels indicates that there must have been a change in the basic habitat condi tions in the river. The dam had two major hydraulic effects on the river: one effect of turbine operation is a reduction of velocities downstream. The preferred range of water velocity for breeding of the East African species of blackfly involved in river blindness is between 0.5 and 3 m s \u22121 . At present, the mean velocities downstream of Owen Falls Dam are between 0.4 and 0.5 m s \u22121 , slightly less than the required velocities. Prior to dam construction, the mean velocity was roughly twice the present, and thus highly suitable for blackfly breeding. Yet, the major ecohydrologic effect of the dam reservoir was the complete submergence of Owen Falls and Ripon Falls upstream of the dam. These falls were preferential sites for blackfly breeding, and their permanent submergence eliminated the breeding completely.\n\nIn West Africa, dam construction has led to a significant switch in dominant water-borne diseases. The Volta River Basin extends over six West African countries (43% in Burkina Faso, 42% in Ghana, and 15% in Togo, Benin, Cote d'Ivoire, and Mali) and covers an area of about 400 000 km 2 . The Volta Lake is the largest man-made lake in the world, created after the construction of the Akosombo Dam in 1965. The primary purpose of the project was to supply cheap electricity to smelt aluminum, other significant uses being transportation, fishery, water supply (commercial and domestic purposes), tourism, and irrigation. Construction of the Volta Lake led to the resettlement of about 80 000 people from several hundreds of villages. In the other riparian countries of the basin, small and larges dams have been built by governments, nongovernmental organizations (NGOs), and local people to secure food produc tion after the severe droughts that occurred in the 1970s and 1980s. In the Nakambe sub-basin (Burkina Faso) alone, more that 600 small dams have been built, mostly during that period (Barry et al., 2005) .\n\nThere have been serious health issues associated with the Volta Lake, in particular with two major diseases: schistosomia sis and river blindness. Before the creation of the Volta Lake, schistosomiasis was endemic in Ghana; but endemicity was low along the Volta River. According to an epidemiological survey done in 1960-61 before the lake was formed, infection rates of schistosomiasis in the area had been 1-5%, mostly affecting children. In the Asukwakwaw area, north of the Akosombo Dam, the prevalence of onchocerciasis is now almost 90%. Principal public health impacts of the formation of the lake have included reduced prevalence of river blindness, but increased incidence of urinary schistosomiasis and a mas sive increase in malaria, as discussed in the following paragraphs.\n\nThe dam virtually halted the rate of flow in the Volta River, increasing stagnant water conditions and consequently creating ideal breeding grounds for carriers of water-borne diseases. In the period following the construction of the dam at Akosombo, there has been a steady decline in agricultural productivity along the lake and the associated tributaries (Gyau-Boakye, 2001). The land surrounding Lake Volta is not nearly as fertile as the for merly cultivated land residing underneath the lake, and intensive agricultural activity has quickly exhausted the already inade quate soils. Without the periodic floodings that brought nutrients to the soil, before the natural river flow was halted by the dam, upstream agricultural systems are also losing soil ferti lity (Van De Giesen et al., 2001) . The growth of commercially intensive agriculture has produced a rise in fertilizer runoff into the river. This, along with runoff from nearby cattle stocks and sewage pollution, has caused eutrophication of the river waters (Gyau-Boakye, 2001) . This nutrient enrichment, in combination with the low water movement, has allowed for the invasion of aquatic weeds (Cerratophyllum) (Fobil and Attaquayefio, 2003) . These weeds, associated with the aquatic snail, the 'intermediate host', together with mass migration into the fishing commu nities from regions in which the disease was endemic, have led to a great increase in the prevalence of schistosomiasis in many localities around the lake.\n\nThe presence of aquatic weeds along the lake and within tributaries has resulted in even greater devastation to local human health as they provide an excellent habitat not only for snails but also for mosquitoes (Gyau-Boakye, 2001) . Before the construction of the Akosombo and Kpong Dams, malaria was not much of a problem along the swift-flowing Volta River, but, when it became a stagnant lake, it became a greater public health problem in lakeside villages. By 1979, urinary schisto somiasis had increased to become the most prevalent disease in the area, affecting some 75% of lakeside residents (Gitlitz, 1993) and reaching a prevalence rate of 90% among children in certain localities. The problem of schistosomiasis in the lake basin must be seen as embracing both the lake and the Volta Delta. The migratory habits of the fishermen ensure the spread of the disease from endemic areas to other areas. In particular, resettlement villages have showed an increase in disease pre valence since the establishment of Lake Volta, and a village's likelihood of infection corresponds to its proximity to the Lake. Previously, the population in the basin generally lived away from the main watercourses because of the threat from water borne diseases. Children and fishermen have been especially hard hit by this rise of disease prevalence (Zakhary, 1997) . Additionally, the degradation of aquatic habitat has resulted in the decline of shrimp and clam populations. The physical health of local communities has declined as a result of this loss of shellfish populations, as they provided an essential source of dietary protein (Fobil and Attaquayefio, 2003) .\n\nConversely, while leading to a dramatic increase in schisto somiasis, the lake has flooded out the riparian forests which constituted a breeding place for a species of tsetse fly, Glossina spp. from the Palpalis group, the vector of protozoan Trypanosoma brucei gambiense, which causes the western African trypanosomiases (sleeping sickness) in people. The lake has also inundated and eliminated the major breeding sites of the onchocerciasis blackfly in rapidly flowing streams and rivers north of the Akosombo Dam. The construction of the second dam at Kpong also eliminated the breeding sites downstream of Akosombo and therefore stopped the transmis sion of river blindness in the vicinity. The main benefit to health because of the construction of the Akosombo Dam in 1965 and the Kpong Dam in 1981 is undoubtedly the reduc tion of the incidence of onchocerciasis in the Volta Basin. About 60 000 fishermen living mostly in isolated villages around the lake were exposed to the riverine disease and did not have access to health facilities (Jobin, 2005) .\n\nIncreased global demand for biofuels has incentivized sugar cane plantation in Brazil, giving rise to several social and environmental modifications (Martinelli and Filoso, 2008) . The widespread occurrence of generalist animal species in sugarcane areas has been associated with public health pro blems. For instance, the population increase of the semiaquatic rodent, capybara (Hydrochoerus hydrochaeris), in the Piracicaba River Basin has led to the spread of Brazilian spotted fever (BSF) (Labruna et al., 2004) . The BSF is the most important tick-borne disease in Brazil and is caused by the bacterium, Rickettsia rickettsii, and transmitted by the tick, Amblyomma cajennense, its main vector, and capybaras serve as host for the ticks (Estrada et al., 2006) . R. rickettsii infections can cause a wide range of clinical manifestations, ranging from asympto matic or mild febrile illness to overwhelming and fatal disease. Failure in diagnosis and delayed therapy have contributed to hidden mortality, frequently a result of atypical fulminant forms of the disease (Gon\u00e7alves da Costa et al., 2006 ) and physician's lack of knowledge about the disease, which is exa cerbated by the difficulty of adequate confirmatory laboratory tests during its acute phase. Mortality can reach 40% of the infection cases. The BSF has been known in Brazil since 1929. During the period between 1940 and the 1980s there was a marked drop in the number of reported cases of BSF in Brazil, as well as in the United States (Angerami et al., 2006) . However, since the 1980s an apparent reemergence of the disease has been observed with an increase in the number of reported cases in the southeast of Brazil (Angerami et al., 2006) . Rickettsial diseases have been considered emerging zoo noses worldwide (Raoult and Roux, 1997) and should no longer be classified as rare diseases in Brazil.\n\nDespite the still moderate number of BSF cases, its increasing trend, together with high mortality rates, reflects and calls atten tion to deep changes in land use and habitat structure in Brazil. Increased fertilizer use, pollution, and soil erosion have caused deterioration of aquatic systems. As colluvium sediments are transported downhill across the landscape from sugarcane fields, they are deposited onto wetlands, and into small streams, rivers, and reservoirs. Deposition affects water quality, and ecosystem biodiversity (Politano and Pissarra, 2005) and functions. High rates of N export into rivers draining watersheds heavily culti vated with sugarcane in Brazil, such as the Piracicaba and Mogi river basins, have been reported (Filoso et al., 2003) . The indus trial processing of sugarcane for production of sugar and ethanol is another source of pollution for aquatic systems with poten tially harmful effects for human health. Waste products (vinasse) are rich in organic matter, and increase the biochemical oxygen demand (BOD) of waters receiving these effluents, often causing anoxia (Ballester et al., 1999) . With the boom of ethanol pro duction in Brazil in the early 1980s, new legislation was enacted to ban the direct discharge of vinasse into surface waters. Since then, nutrient and carbon-rich vinasse has been mixed with wastewater from washing sugarcane and is recycled back to sugarcane fields as organic fertilizer (Gunkel et al., 2007) , although this practice is still far from generalized. As a conse quence, high nutrient concentrations in these effluents also contribute to the problem by enhancing algal blooms and pro moting eutrophication of surface waters (Matsumura-Tundisi and Tundisi, 2005) .\n\nThe increase and dispersion of the capybara population and the associated health risk is most likely due to a strong anthro pogenic habitat modification caused by extensive monoculture. Paradoxically, this situation could be aggravated by current efforts to restore aquatic ecosystems. Typical capybara habitat is com posed of two main components: water and a patch of forest or woodland. In S\u00e3o Paulo state, capybaras and ticks share a habitat component, the riparian vegetation called gallery forest. These forests form as corridors along rivers or wetlands and project into landscapes that are otherwise only sparsely wooded, such as savannas, grasslands, or deserts. The boundary between gallery forest and the surrounding woodland or grassland is usually very abrupt, with the ecotone being only a few meters wide. In S\u00e3o Paulo state, capybaras shelter in the gallery forest and feed in the sugarcane fields adjacent to the ecotone ( Figure 14) .\n\nThus, the abundant food and lack of predators in this new habitat have led to a strong population increase (Labruna, 2009 ). In the 1950s, the capybara was considered in danger of extinction in S\u00e3o Paulo state, where population can reach densities 60 times higher than in natural environments in some areas, such as the extended wetlands of Pantanal (Verdade and Ferraz, 2006) . This offers optimum conditions for the increase in the tick and Rickettsia population.\n\nFurther, the capybara is a protected species and is gradually adapting to aquatic urban habitats with a larger spectrum of possible vertebrate hosts for ticks ( Figure 15 ). Capybaras have been observed in the outskirts of S\u00e3o Paulo city along the highly polluted Pinheiros River (Labruna, 2009) , which flows through the fourth largest metropolitan area worldwide, with \u223c11 million inhabitants. Presently, a substantial cleanup pro gram for this river is underway and an increase of secondary vegetation and fragmented, regenerated systems is expected. With this, a further expansion of capybaras, ticks, and BSF toward anthropogenically modified habitats, including urban and suburban areas close to water sources such as rivers and lakes, is likely.\n\nIn addition, it has recently been reported (Meireles et al., 2007) that capybaras in the S\u00e3o Paulo state were infected by Cryptosporidium parvum, which is a protozoan pathogen that causes a diarrheal illness called cryptosporidiosis, an acute short-term infection that can become severe and chronic in children and immunocompromised individuals. Despite not being identified until 1976 (Meisel et al., 1976; Nime et al., 1976) , it is one of the most common water-borne diseases and is found worldwide, being spread by direct ingestion of con taminated water or food and through recreational water activities. The finding of zoonotic C. parvum infection in this Figure 14 Aerial photo of a sugarcane plantation and a small water body with highly fragmented remains of riparian forest, Brazil. Photo credit: Geraldo Arruda, Jr. semiaquatic mammal that inhabits anthroponotic habitats raises the concern that human water supplies in Brazil may be contaminated with Cryptosporidium oocysts from wildlife.\n\nCryptosporidiosis is the most significant water-borne dis ease associated with the public water supply in Western Europe. When contamination occurs, it has the potential to infect very large numbers of people. Some notable outbreaks of cryptos poridiosis have been associated with heavy rainfall events. In this chapter and elsewhere (Despommier et al., 2007 and references therein) , there are indications that the boundaries between ecological systems play a role in some of the most important emerging infectious diseases, with a correspondence between ecotonal processes and the ecological and evolution ary processes responsible for zoonotic and vector-borne infections. Terrestrial ecotones include forest-edge habitats, fragmented forest landscapes, and forest-grassland interfaces. Terrestrial-aquatic ecotones are found in riparian habitats, riverine landscapes, freshwater and estuarine wetlands, and in the coastal zone. Anthropogenic ecotones can include crop land/pasture-natural habitat and settlement-natural habitat, and a combination of these.\n\nProcesses in ecotones can contribute to the shifts or changes in hosts, vectors, or pathogens that produce disease emergence. These dynamics are associated with changes in land cover/use and with the changing nature of the land-water interface. Anthropogenic influences can intensify ecotonal processes by increasing their geographic extent and overlap. Various ecotone features can contribute to disease emergence. Animals congre gate in ecotones. Populations of species that normally are members of distinct ecological communities from different habitats or ecosystems overlap in ecotones, facilitating patho gen spillover. Host-vector hyperabundance increases the potential for pathogens to achieve critical threshold density. Enhanced dispersal conditions facilitate dispersal at a higher rate or over longer distances, along linear habitats defined by habitat edges, such as riverine or gallery forest, and flowing water in streams or rivers themselves. Cropland-forest-river transitions appear particularly relevant as sensitive indicators of change in this context. For example, the transition between fragmented riparian habitats such as degraded gallery forests and, for example, sugarcane fields seems to be a priority sector for the control of rickettsia-related diseases since capybaras must cross the ecotone to feed on sugarcane, as described else where in this article.\n\nFurther, nutrient pollution, degradation of riparian habitat, and the loss of ecological functions involving assimilation of nutrients and pathogens, combined with high concentrations of domestic fowl and their waste, are commonly associated with human settlement/aquatic-terrestrial ecotones. The emer gence of AI involved the mixing of three different communities: wild migratory waterfowl (wetlands), wild local birds, and domestic fowl (ponds), and, later, also pigs. Like influenza, the emergence of Japanese encephalitis has involved transmis sion in the spatial area of overlap of human settlements, agriculture, and natural habitat (Despommier et al., 2007) . While waterbirds and wetland habitat are implicated in influ enza, nonaquatic wild birds and irrigation systems provide the vector habitat for encephalitis. The intensification and expan sion of irrigated rice production systems in Southeast Asia over the past 20 years have made an important contribution to the spread of this disease, which is produced by a mosquito-borne virus (see Table 5 ). The flooding of the fields at the start of each cropping cycle leads to a sizable increase in the mosquito population. Domestic pigs and wild birds are reservoirs of the virus and transmission to humans may cause severe symptoms. Japanese encephalitis is a leading cause of viral encephalitis in Asia with 30 000-50 000 clinical cases reported annually (WHO, 2001d) .\n\nIn general, research in ecotoneparticularly terrestrialaquatic dynamicscan provide vital information about changes in climate, river hydrology, sea level (Cohen and Lara, 2003) , and land use (Lara et al., 2002) . A strengthened integration of ecological and biomedical monitoring is essen tial for successfully restoring ecological functions and enhancing environmental and human health. Globally, the surveillance of locally and regionally relevant ecotones could provide evidence of disease emergence related to environmen tal change. In this context, restoration of lost ecological functions, such as nutrient sequestration by wetland creation or regeneration of riparian vegetation, must be accompanied by careful monitoring of other changes in the surrounding land scape and in the connectivity between basin processes and land use. Created or regenerated aquatic systemsindependently of their purposewill increment existing ecotonal processes or generate new ones. Thus, surveillance of the created/recovered/ enhanced system ecological functions should include at least those disease agents (host, vectors, or pathogens) , which according to the present knowledge would have a higher prob ability of proliferation under modified or changing conditions (e.g., mosquito larvae in temperate wetlands and snails in tropical regions).\n\nFloods and droughts will intensify with climate change and affect health through the spread of disease resulting from habi tat modification, with high risk of rapid increase in diarrheal and other diseases (Lipp et al., 2002; IPCC, 2007) . There are many pathways through which hydrologically relevant events can affect health; notably when a river or stream bursts its banks producing changes in mosquito abundance (malaria, and dengue), or contamination of surface water with human or animal waste such as, for example, rodent urine (leptospiro sis). Flooding may become more intense with climate change and can result in the spread of disease. Conversely, droughts can produce changes in vector abundance if, for example, a vector breeds in ponds left in dried-up riverbeds (Noji, 1997; Menne et al., 1999) . Coastal ecosystems and their basins are rapidly changing due to anthropogenic pressure and global warming, also inducing changes in patterns of resource use (Lara et al., 2002) . Integrative, comparative approaches are needed for the understanding of functional links between basin structure; morphology of different estuaries, marshes, and mangroves; flooding and biogeochemical regimes (Lara and Cohen, 2006) ; pathogen life cycles; and disease incidence (Wolanski et al., 2004; Lara et al., 2009) .\n\nFor improved prediction of the dispersal of inundation waters, formation of drought ponds, or preventive identifica tion of vulnerable locations or sectors that could be used as drainage areas, it is crucial to have a detailed knowledge of the regional and local topography. The elaboration of highresolution topographic models (DEM) of basins in connection with hydrology, meteorology, and biogeochemistry data will also allow the assessment of vulnerability descriptors such as soil moisture potential, salinity, or organic matter content, which can be crucial state parameters for the development of microorganisms and/or disease vectors.\n\nHowever, precisely in tropical coastal areas, where the impact of climate change on vector-transmitted diseases is of high concern, there is frequently a lack of topographic informa tion with an adequate resolution for low-lying sectors. In vulnerable regions, the combination of risks to both food and water can exacerbate the impact of even minor weather extremes (floods and droughts) on the households affected (Webb and Iskandarani, 1998) .\n\nA methodological approach including wetland basin microtopography and its relation with inundation dynamics and estuarine biogeochemistry is necessary for vulnerability assess ment and risk management. The use of geographic information systems (GISs) provides an excellent basis for network coopera tion at the interfaces between environmental and biomedical research, adding a critical componenthuman healthto coastal management research. This is a major concern for the WHO, which also has set a priority on the link between GIS and disease surveillance (WHO, 2000) . Through the joint WHO/United Nations Children's Fund (UNICEF) program Health Map, specific GIS software was developed for that purpose, combining a standar dized geographic database, a data manager, and a mapping interface. However, although these concerns are closely linked to the subject matter of ecohydrology, they are not usually included in interdisciplinary research projects dealing with, for example, coastal wetlands.\n\nClearly, the only way to concretely reduce vulnerability is to ensure that infrastructure is in place for the removal of solid waste and wastewater and the supply of potable water. No sanitation technology is safe when covered by floodwaters, as fecal matter mixes with floodwaters and is spread wherever the floodwaters run (Lara et al., 2009) . Consideration should also be given to the deterioration of groundwater quality caused by salinity intrusion due to climate change and rising sea levels (e.g., Sherif and Singh, 1999) .\n\nThus, as stated in Section 10.12.1.1, such health issues clearly require a basin approach, that is, considering basins as a natural unit of territorial management. However, a usual shortcoming of GIS-derived vulnerability studies is that data sources from official institutions are most frequently based on municipalities or counties as an administrative unit, whose limits do not necessarily coincide with basin boundaries. Thus, this vision of the relationship between climate and sealevel change and effect on human health converges with Zalewski's (2002) statement that: as a consequence, the issue of water quality at the basin scale cannot be resolved without a profound understanding of the effects of hydrology on biotic processes and of biota on hydrology. The frame work for developing the principles of ecohydrology is logically the water basin scale. (Zalewski, 2002: 825) \n\nCreation of wetlands for nutrient sequestration from surface waters requires the inclusion of measures for control of locally major and regionally relevant disease vectors such as snails or mosquitoes. The latter are relevant for disease transmission in several climatic zones besides the tropics, and global warming is widening their habitats with severe consequences for human health (e.g., the dengue outbreak in Argentina in 2009) and will therefore be treated with some detail. Early methods of managing salt-marsh mosquitoes have primarily focused on maximizing the reduction of mosquito populations, with mini mizing environmental impact as a secondary consideration. However, in the last few decades, there have been attempts to apply diverse water management models to marsh systems, especially in terms of vector control and habitat modification (Dale and Hulsman, 1990; Wolfe, 1996) using programs with minimal environmental impacts. The success of these programs requires a thorough knowledge of mosquito developmental conditions, as well as potential impacts on adjoining ecosys tems. A deep knowledge of the local microtopography and tidal regimes is critical. Marsh drainage and hydrological linkage to the tidal source are essential in the determination of what type of wetland occurs where, and for the development of appro priate wetland management measures. Elevation of a few centimeters is more critical in the coastal wetlands than that of hundreds of meters in the mountains.\n\nIn this section we cover not only well-established methods for mosquito control, but a series of successful methods for snail control derived from good agriculture practice, basically from techniques for rice cultivation. Ecohydrology can contri bute to and learn from these experiences.\n\nWater management, molluskicides, and chemotherapy have been the main instruments for preventing or treating schisto somiasis. Biological control of snails through predators such as ducks, fish, turtles, crustaceans, water rats, leeches, and aquatic insects have been also used, as yet with very limited success.\n\nAn interesting lesson on the potential for improved water management to reduce vector proliferation from the 1960s can be drawn from the experience in the Baluchi Irrigation Scheme in then Tanganyika (Sturrock, 1965) . This system was remark ably clear of snails, although several species occurred in small numbers. Several factors may account for this. First, the water flow in the canal system was very rapid when it was in use, but the canals were completely dried out in the dry season. Second, silt and vegetation were dug out of the canals twice a year. Third, a complex system of rice husbandry was used in which the rice fields were ploughed, manured, and subjected to a program of alternate drying and flooding. Consequently, neither the canal system nor the rice fields contained much in the way of snail habitats. Snails were confined to temporary pool sites, filled with rain or seepage water. All these schemes were built on land with an appreciable slope and with relatively porous soils. Even when irrigation was in progress, the field canals were not always in use and dried out rapidly. While snails are often able to withstand limited periods of drought, it is unlikely that any large snail populations could develop under these conditions in any one season. Furthermore, on five of these schemes, field canals were often re-routed from season to season so that the establishment of suitable snail habitats was rendered even more unlikely. Mobarak (1982) reported that after 1970 prevalence of urinary schistosomiasis in Upper Egypt reversed a previous downward trend and began to increase again because of the shift from basin to perennial irrigation. However, in any case, increased use of parenteral antischistosomal therapy (PAT, injections of antimony-based drugs) was bringing schistoso miasis under control in Egypt. In the northern part of Upper Egypt, prevalence dropped from 29.4% in 1977 to 11.5% in 1983, while further south, prevalence reportedly fell from 26. 4% in 1980 4% in to 16% in 1983 4% in (WHO, 1985 . Most experts agreed that applying the proper combination of sanitary engi neering, water control management, snail control, infection surveillance, and treatment drugs can avert adverse effects of irrigation on schistosomiasis. Moreover, there was an impres sion that even without water control measures and environmental sanitation, chemotherapy with or without treat ing water to kill snails would adequately control schistosomiasis transmission. Fenwick (1989) noted that in the newer Rahad Irrigation Scheme, east of the Gezira plain in the Sudan, because of the use of drugs and snail control, the incidence of schistosomiasis remained very low, despite very poor sanitary conditions. It was predicted, however, that relax ing control measures would cause a surge in schistosomiasis. Although oral drugs started to be used in Egypt in the 1970s, PAT use continued into the mid-1980s. Praziquantel, which also has a high cure rate for S. mansoni, became available in Egypt in 1982 and has been the treatment of choice there since the late 1980s. Although the massive PAT campaigns were successful in strongly reducing disease incidence, a study by Frank et al. (2000) concludes that the intensity, widespread geographical coverage, and duration of the campaigns, together with unsafe injection practices (inappropriate sterilization pro cedures), have been responsible for the nationwide spread of hepatitis C in Egypt in recent decades. The authors state that the enormous dimension of Egypt's schistosomiasis problem and the sheer size of the antischistosomiasis effort, combined with the characteristics of PAT, provided an effective mechanism for a massive increase and establishment of hepatitis C virus in the Egyptian population. According to these authors, this is \"the world's largest iatrogenic transmission of blood-borne patho gens known to date.\" Moreover, it is probable that the heavy reliance on an effective chemical treatment also allowed the continuation of water management schemes that were contri buting to the maintenance of large numbers of snails in aquatic environments. The evolution of the schistosomiasis problem in Egypt and Sudan described above highlights the importance of developing water management programs able to keep vector proliferation under control. This lesson is also highly relevant to the construction of large-scale reservoirs and irrigation facil ities as in the case of the Three Gorges Dam.\n\nIn Israel, Biomphalaria alexandrina was eradicated through a combination of factors including chemical applications. As in all cases, snails return some time after the application of mol luskicides. Some combined measures used for the control of snail vectors have been successful, such as increasing water currents to over 20 cm s \u22121 , rapid emptying and drying up of water reservoirs, and weekly deflection of infested water courses along different routes (Saliternik, 1979) .\n\nAs stated previously, the success of chemotherapy in treating this disease and of molluskicides for eradicating snails does not imply that preventive measures should not be taken for avoid ing vector proliferation based on knowledge of their ecohydrological setting. All vector snails require water, at least for breeding. The management of water bodies is therefore a potentially powerful control method. For example, in the case of rice cultivation there are opportunities for vector control by changing the aquatic habitat of the snail in a way compatible with maximum crop production. Infection of humans mostly takes place not in the rice field itself, but in irrigation canals and surrounding living quarters. Different hydrological and rice husbandry approaches have been used in various countries. However, generalizations should be made with care because each snail species has its own preferences and tolerances regard ing shade, water velocity, the steepness of canal walls, and drought tolerance.\n\nRice cultivation by itself can be used as an environmental method of snail control in that it brings about ecological changes that can reduce snail habitat. The Philippines has promoted more intensive scientific methods of rice cultivation to control schistosomiasis (Hairston and Santos, 1961) . Snail control is achieved at different stages of rice growing in a number of different ways, for example, by deep plowing, which turns over the soil and buries the snails; or by draining the ricefield at harvest and keeping it dry until the next crop, which kills the snails and prevents them from breeding.\n\nIn Japan, S. japonicum eradication was accomplished by treatment, sanitation, control of animal reservoir host, educa tion, and elimination of most of the snail colonies (Garcia, 1988) . The steepness of the walls of irrigation channels was increased and later they were lined with concrete and main tained clear of silt, vegetation, and debris to supplement the eradication of snails in the ricefields, which resulted from intensive cultivation.\n\nExtensive rice-growing areas in China's mainland have been cleared of Oncomelania snails (Garcia, 1988) . The measures taken have included digging new water channels parallel to the existing snail-infested streams and using the excavated soil to fill the old ones, clearing streambeds, and removing vegetation. Where the soil structure permits, the banks have been made steeper. In the Philippines, similar measures have been taken as in China; in addition, converting undrainable swampy areas into fishponds and improving agricultural prac tices have successfully controlled snails in limited areas. Thus, an integrated approach to drainage problems can result in increased production while reducing health risks.\n\nIn the ecohydrology approach, it is essential to consider the whole basin in management policies, especially when a disease agent can be transmitted by different species of the same host (in this case a snail) that is differentially distributed along altitude gradients in river basins. Both B. truncatus and Planorbarius metidjensis are intermediate hosts of S. haematobium in southwestern Morocco. A basin investigation (Yacoubi et al., 2007) in five rivers identified sites colonized by these species and compared the habitats in which they were found. The P. metidjensis was observed in the upper valleys of three rivers, whereas B. truncatus was found in sites of lower altitude. A component analysis demonstrated that altitude (from 4 to 1380 m), water pH (from 5.9 to 9.2), and electric conductivity (from 120 to 6020 \u03bcS cm \u22121 ) were the main descriptors of environment. The P. metidjensis was associated to high altitude and low electric conductivity. However, B. truncatus was asso ciated to being found in lower altitude sites with medium electric conductivity in water.\n\nIt has been mentioned above that periodic canal or field drying had been used successfully for snail control. Nevertheless, before a control plan is adopted and implemen ted, the effects of drying out have to be monitored and thoroughly understood for each snail species: snails that are capable of undergoing diapause can circumvent unfavorable environmental conditions, including long periods of drought. Cooper et al. (1992) found that diapause influenced the sus ceptibility of Biomphalaria glabrata snails to S. mansoni infection. Juvenile snails exposed just prior to diapause, or immediately following a diapause period of 3 weeks, were highly susceptible to infection by S. mansoni miracidia. However, snails that underwent diapause produced compar able or only slightly fewer cercariae than did nondiapausing snails. These studies indicate that diapause in B. glabrata does little to decrease a snail's ability to act as an intermediate host for S. mansoni or to interrupt the development of the parasite. For these reasons, great attention should be given to diapausing snail populations when planning programs for mollusk control.\n\nThus, for snail control, it is important that not only the agricultural field but also irrigation and drainage channels, as well as the water source, be considered part of the agroecosys tem. This parallels the ecohydrology approach that considers the whole basin, from the river source to the wetlands, estuar ine, and coastal zone as an integrated management unit. Both agricultural and ecohydrological models should converge in a new synthesis integrating their own tools with practices based on traditional knowledge, socioeconomical cost-benefit analysis of vector eradication, and agri-and/or aquacultural production.\n\nThe type of wetland management approach, particularly when restoration or creation is planned, will require previous surveys of the mosquito species and their habitat types, locally and at basin level. In the following sections, we present a summary of main species/habitat combinations for different hydrological settings extracted from Anonymous (2009b) .\n\nRelatively few mosquito species breed in running waters, such as streams. Larvae can be flushed out when stream volume increases, and to remain in the stream requires a large amount of energy. The tropical genus, Chagasia, and some Anopheles species are stream breeders. Stream breeders will find vegeta tion along banks with which to anchor themselves or attempt to remain away from the main flow of the stream by seeking isolated eddies.\n\nTransient water sources, such as flooded areas and ditches, are used as breeding grounds for species whose eggs can with stand desiccation and whose life cycles require alternating periods of wet and dry, such as Aedes and Psorophora. The quality of transient water changes with time, which can result in a succession of different species using the same pool. Transient waters include woodland pools created by spring rains (Aedes stimulans), fresh floodwater (Aedes canadensis), and tidal floodwater (Aedes sollicitans).\n\nPermanent or semipermanent waters support characteristic aquatic vegetation. Cattail, rushes, and sedges are typical fresh water swamp vegetation. Genera associated with permanent water are Anopheles, Culex, Culiseta, Coquillettidia, and Uranotaenia, whose eggs are not desiccant resistant and must be laid directly on the water. Aedes adults will oviposit near the edge of the swamp, or within tussocks of vegetation, requiring later flooding of the eggs for hatching. As with transient waters, there are seasonal changes in the vegetation, water quality, and mosquito species present. Permanent waters can include fresh water swamps, such as, for example, tussock (Aedes abserratus) or cattail swamps (Coquillettidia perturbans), as well as brackish water swamps with salt marshes (Culex salinarius). Besides nat ural environments, polluted water with floating debris can be a habitat for species such as Culex pipiens.\n\nContainer water habitat can be found in both natural set tings, such as water held by plants to artificial settings and water found in tires. Container water is characteristically clear and many container species now also use artificial sites as they provide insulation against the weather and are more numerous (Aedes aegypti and Aedes albopictus). Increasing dengue incidence in not only tropical but also subtropical countries requires a thorough elimination of such urban, man-made microhabitats.\n\nThere are various techniques for mosquito control based on different principles. All involve modification of the hydrologi cal setting, ranging from total wetland drainage to an increase in their tidal flooding. A summary of these methods, including parallel grid ditching, open marsh water management, and runneling, is presented in the following paragraphs.\n\nParallel grid ditching consists in the physical removal of water from intertidal marshes and was one of the first largescale forms of mosquito control (Lesser (2007) ; Figure 16 ). Parallel grid ditches were dug in salt marshes, spacing these ditches about 45 m apart to remove standing surface water where mosquitoes might breed.\n\nExtensive ditching programs for mosquito control in North America were only moderately effective, since many breeding potholes were not drained dry, and there were long-term nega tive effects on wildlife and salt-marsh ecosystems. Many nonmosquito breeding wetlands that provided wildlife habitat were unnecessarily drained and salt-marsh vegetation commu nities were changed into fragmented wetlands. Birds were particularly affected through the draining of larger natural ponds. By the early 1960s, there was an increasing awareness of wetland values and functions, and the value of parallel grid ditching was questioned.\n\nUnderstanding of the drawbacks of the parallel grid-ditching technique led to the development of a new mosquito control source-reduction technique called open marsh water manage ment (OMWM). It started in the late 1960s and was further optimized until the early 1980s. The goals of OMWM are:\n\n(1) control of salt-marsh mosquitoes; (2) reduction of insecti cide applications; and (3) habitat enhancement for salt-marsh fish and wildlife (Ferrigno and Jobbins, 1968; Hruby et al., 1985) . The OMWM method involves the selective installation of small, shallow ponds and interconnecting ditches superim posed on known mosquito-breeding habitats ( Figure 17 ). This aims to eliminate wet-dry-wet cycles necessary for determined species and any newly created permanent water habitats are unattractive for mosquito egg deposition. This simultaneously improves habitats for mosquito-eating larvivorous fishes which can quickly invade, via tidal flooding, any newly created OMWM pond or ditch.\n\nScattered mosquito breeding depressions and sheetwater habitats are connected through pond and ditch excavations to allow unimpeded water flow and predatory fish movement, while isolated potholes are often filled with natural soils to eliminate these smaller-sized breeding depressions (Lesser, 2007 ; Figure 17 ). The increase of tidal inundation frequency and predation by fish significantly reduce mosquito density.\n\nRunneling is an effective method for controlling mosqui toes that breed in intertidal salt marshes through a type of habitat modification using shallow channels. This technique is based on OMWM principles (Wolfe, 1996) . It increases tidal frequency to a marsh and removes surface sheet water from low-lying areas high on the marsh. Runnels are linked to the tidal source, promoting tidal exchange between graded regions of the marsh. They are conceived to allow transport of lowamplitude tides to areas of salt marsh in a way so that pools do not form, even after spring tides. Runnels are shallow Figure 17 The OMWM system, involving the selective installation of small, shallow ponds and interconnecting ditches superimposed on known mosquito-breeding habitats.\n\n(<30 cm deep) spoon-shaped channels constructed along nat ural drainage lines on the salt marsh ( Figure 18 ) to a maximum gradient of 1:1000 (Hulsman et al., 1989) . Due to the slight slope, runnels enable slow water movement even during lowamplitude tides.\n\nThe net result is a reduction in mosquito breeding areas, the modification of pools and edges for egg conditioning (the process involving flooding and drying events that prepares mosquito eggs for hatching), and larval development. There are few apparent negative impacts at the modified site (Hulsman et al., 1989; Dale and Hulsman, 1990; Dale et al., 1993; Latchford, 1997) . Further, like OMWM, they allow water to drain from trap pools and permit predatory fish to gain access to the mosquito larvae, at least during high tide.\n\nIn comparison to grid ditching and OMWM, runneling is an environment-oriented approach to salt-marsh management for mosquito control that aims to alter the salt marsh as little as possible, while causing significant reductions in mosquito numbers. The main difference between the three approaches lies in the magnitude of the habitat modification. Ditching involves the greatest alteration to the marsh, and runneling the least. Runneling has a lesser effect on the estuarine environ ment as a whole than does either ditching or OMWM.\n\n10.12.5 Conclusions 10.12.5.1 Some Reflections on Dams, Water Scarcity, Ecohydrology, and Health\n\nAlthough the construction of reservoirs is controversial, the rising demand for water by an increasing human population makes more dams inevitable (Jobin, 1999) . In a review, Morley (2007) calls attention of the fact that most parasitological studies in relation to reservoir construction have been focused on schistosomiasis and other tropical diseases of humans (Stanley and Alpers, 1975; Jobin, 1999) . In comparison, the impact of reservoir construction on indigenous aquatic parasite fauna of wildlife has been a subject largely ignored by the scientific community. However, reservoir formation can have profound effects on the parasite fauna of fish, birds in the reservoir, as well as up-and downstream of it. Changes in host-parasite relationships and switches between animal and human hosts can occur (Morley, 2007 and references therein) . The role of parasites in environmental monitoring is increas ingly recognized (Lafferty, 1997; Lafferty and Kuris, 2005) . Thus, the surveillance of the effects of reservoirs on parasite fauna of aquatic wildlife may provide important general infor mation on both short-and long-term changes that occur within and downstream of new reservoirs during the maturation pro cess of the reservoir.\n\nThe above-described cases that show the effect of dam con struction on onchocerciacis and schistosomiasis call attention to the need to evaluate changes in flow power and velocity downstream of proposed dams, in order to assess their likely health impact. Ecohydrological measures are required to improve the operation of existing dams to provide more effective control of disease vectors (see Section 10.12.2.2.3). The modeling of the effect of controlled flooding pulses on the plankton dynamics in the Guadiana Estuary (Wolanski et al., 2006) is an outstanding example of the potential of the appli cation of ecohydrological principles for the control of toxic algal blooms.\n\nIn arid and semiarid regions, the quality of water in artificial reservoirs is essential to human health, particularly in climati cally unstable regions. For example, recent El Ni\u00f1o/La Ni\u00f1a-Southern Oscillation teleconnections have produced a pro longed drought of \u223c3 years in South Argentina. This has interrupted a period of about 30 years of rainfall significantly above the historical average and produced a decline to critical levels in the reserves of drinking water reservoirs, which like other water bodies in the region, have suffered from recurrent summer algal blooms (Kopprio et al., 2008) . However, the perception that cyanobacteria can represent a threat to human health only in connection with acute events such as blooms should be widened to consider the possibility of neurologic damage as consequence of chronic exposition to toxins such as BMAA via long-term ingestion of water or aquatic fauna. This should be taken into account when developing schemes for preventing cyanobacterial blooms by manipulating natural predator communities. The reduction of the nutrient load input to the water reservoir probably remains the best preven tive measure to prevent harmful algal blooms. Water treatment should be regularly checked and improved to remove the organisms and their toxins from drinking-water supplies, where appropriate. Water treatment by flocculation and sedi mentation, followed by sand filtration, is supposed to remove live cyanobacterial cells and debris. However, there is evidence that plants that are not working properly can actually increase cell counts of algae with potential toxicity (in this case, Anabaena circinalis and Microcystis aeruginosa) in the treated water (Echenique et al., 2006) .\n\nThroughout this chapter, examples have been referred to of actual and potential conflicts of interest between alternative uses of aquatic systems, for example, between the desire to restore degraded wetlands and the need to protect health of the human population living nearby. A relevant example of policy conflicts in an industrialized country is the experience of the Tennessee Valley Authority (TVA), where health concerns in the past gave rise to management measures that conflict with modern recreational interests (Bos, 1999) . The meeting report of the ninth meeting of the WHO/FAO/United Nations Environment Programme (UNEP) Panel of Experts on Environmental Management for Vector Control in 1989 includes the following passage:\n\nAs national and regional priorities change, so do policies, and there must therefore always be a provision for their reconsideration and modification. Sometimes, though, the acute problems that led to the original priority setting might have become latent rather than have disappeared completely, and while public awareness and political pressure favour a policy change, the original goals of such policies should not be ignored. This was well illustrated by the water man agement policies including mosquito control established by the TVA in the 1930s. The standards of mosquito control maintained by TVA equalled those maintained in privately owned river impoundments under prevailing public health regulations. The measures included the programmed fluctuation of water levels in the reservoirs, a practice that played a key role in reducing Anopheles populations and eradicating malaria transmission from the Valley. New uses of the reservoirs, including recreation and the promotion of nature conservation had led to a conflict of interests. For recreation, stable water levels during summer and early autumn were required; con servation of certain fish species and of waterfowl required higher water levels in spring to promote fish spawning and the rapid growth of aquatic vegetation for the fowl. Such changes in water manage ment regimes would without doubt result in increased mosquito populations, yet the potential risk for the reintroduction of vectorborne disease was not appreciated after three generations of malaria free experience. In recent years much interest has been directed towards the protection and establishment of wetlands, without pay ing sufficient attention to their mosquito breeding potential. Consequently, TVA has been faced with a conflict of new policy directives concerning wetlands, existing mosquito control policies and state regulations for impounded water. The use of constructed (artificial) wetlands for the treatment of domestic waste water and its processing for reuse is of particular concern, since these could pro duce large quantities of potential disease vectors and they are often sited close to populated areas (PEEM/WHO, 1991: 17-18). This stresses the necessity of harmonizing policies of reservoir management for vector control with other policies concerned with land use patterns, to ensure that areas of potential risk, such as artificial wetlands, are planned away from areas of human habitation.\n\nPresently we face a complex environmental situation that seems to be changing at a much faster rate than our current capacity to revise and renew our intellectual schemes or to generate integrated management structures capable to enhance both ecosystem and human health. Take, for example, the case of influenza virus. The loss of wetlands around the globe may force many wild birds onto alternative sites like farm ponds and paddy fields, bringing them into direct contact with domestic fowl and humans and providing greater opportu nities for the spread of the H5N1 virus (Anonymous, 2006) . Poor planning in response to development pressures has led to the increasing loss or degradation of wild ecosystems which are the natural habitats for wild birds. The displaced wild birds increasingly seek to feed and live in areas populated by domestic poultry and humans. Thus, wetland creation must also consider these factors, since they will attract migratory birds if located near their routes. Despite this being considered an enrichment of landscape ecology in terms of diversity, recreational value, landscape beauty, etc., the risk of increasing transmission of emerging diseases must be dispassionately considered. An increase in biodiversity does include not only those species humans like, but also the diversity of vectors capable of transmitting diseases. The distance of the wetlands to be created from populated centers, the direction of prevail ing winds, and other transport mechanisms should be carefully taken into account. This issue of 'ecohealth' highlights the interplay between agriculture, animal (domestic and wildlife) and human health, the integral health of aquatic ecosystems, and sociocultural factors. Nutrient reduction in wastewaters or surface waters is a priority for reducing risks to human health, as well as for the reduction of disease vectors in surface waters. Exploration of phytotechnologies relying on direct belowground absorption of nutrients by plant root biomass could provide alternatives to construction of open wetlands in places where this might involve disease vector proliferation."}