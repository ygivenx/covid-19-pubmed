{"title": "Crude incidence in two-phase designs in the presence of competing risks", "body": "In many longitudinal studies, some information might not be measured/available for the whole cohort, in fact biomarkers/additional covariates, or even outcome, might be ascertained only in selected subsamples. These studies are part of a broad category termed two-phase studies [1], in fact they imply two sampling phases: the first one being usually a random sample from the target population, ending up in the entire cohort (phase I sample), and the second one applying some kind of sampling (e.g. efficient or of convenience) to collect additional information or the selection of subjects with no missing data (phase II sample). Common examples of efficient second phase sampling include the nested case-control and the case-cohort designs [2\u20135]. In other situations the outcome itself is collected only for a subsample [6]. Two-phase sampling, or more generally, multiphase sampling, is a general design that includes any valid probability sample of the data, in which each subsampling can depend on all the currently observed data at each step [7]. The actual sampling probabilities will depend on the specific design. The acknowledgement of these sampling phases, even in the commonly applied designs, can be very useful to improve efficiency and to allow flexibility in the analysis (e.g. different time-scales or different models can be applied) by using information available for the whole cohort [8].\n\nEfficient designs are particularly useful to identify new biomarkers when the combination between large cohorts and expensive new technologies make it infeasible to measure the biomarkers on the entire cohort. The Women\u2019s Health Initiative program, for example, stored serum and plasma from participants and used them for specialized studies [9]. Also the Cardiovascular Health Study collected DNA from most participants to study different genetic factors underlying cardiovascular or other diseases and only subsets of the cohort have been genotyped in different projects [10].\n\nIn our first motivating clinical example, the aim was to evaluate the role of different genetic polymorphisms on treatment failure due to relapse in childhood acute lymphoblastic leukemia (ALL) using clinical information and biological samples available from a clinical trial that enrolled nearly 2000 patients. In this situation, a parsimonious use of these specimens motivated the choice of an efficient/optimal two-phase sampling design [11]. We present also a further application where the aim was to estimate engagement to care of HIV patients in resource limited settings. Here the outcome itself was missing in a group of patients due to possibly informative loss to follow-up. The outcome was tracked in a random sample of those lost to follow-up to obtain a valid estimate of engagement to care [12].\n\nFor two-phase studies, appropriate weighted survival estimates have been derived, both in the presence of additional covariates measured in the second phase [7, 13, 14], as well as in cohorts where the outcome/follow-up is not available for everyone [15]. A Cox model adapted for two-phase designs has also been derived [14]. However no estimator of cumulative incidence accounting for competing events in the general framework of two-phase designs has been proposed, while it has been developed for specific designs, such as nested case-control studies [16, 17]. This is relevant in the presence of multiple types of events, such as relapse and (toxic) death in cancer patients, as in the motivating examples presented here, where estimation of event type specific quantities are needed for evaluating outcome.\n\nThe aim of this paper is to develop a non parametric estimator of the crude incidence of events accounting for possible competing events in the general framework of two-phase designs, where subgroups of analysis might be defined according to explanatory variables ascertained in the phase II sample, or the outcome itself assessed only in the second phase sample.\n\nIn the Methods section we propose a weighted crude incidence estimator for application in two-phase designs. The theoretical properties of the proposed method are derived in appendix and investigated through simulations under different scenarios, which results are reported in Results section. In this section we also report the examples on childhood ALL and HIV patients. Conclusions is dedicated to the discussion.\n\nLet T be the failure time variable and suppose there are K possible causes of failure denoted by \u03b5=1,2,\u2026K. Let the cause-specific hazard function of the kth event be: \n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$\\lambda_{k}(t)={\\lim}_{dt \\rightarrow 0} \\frac{1}{dt}P(t\\leq T< t+dt;\\varepsilon=k|T\\geq t) $$ \\end{document}\u03bbk(t)=limdt\u219201dtP(t\u2264T<t+dt;\u03b5=k|T\u2265t) and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\Lambda _{k}(t)={\\int _{0}^{t}} \\lambda _{k}(s)ds$\\end{document}\u039bk(t)=\u222b0t\u03bbk(s)ds. Define \n(1)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ F_{k}(t)=P(T\\leq t;\\varepsilon =k)   $$ \\end{document}Fk(t)=P(T\u2264t;\u03b5=k)\n\nas the probability that a failure due to cause k occurs by time t, that is the quantity that we aim to estimate. Define also \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$S(t)=P(T>t)=1-\\sum _{k} F_{k}(t)$\\end{document}S(t)=P(T>t)=1\u2212\u2211kFk(t) as the probability of surviving from any cause of failure.\n\nA convenient representation of the crude incidence function (1) as product limit estimator naturally arises starting from the subdistribution hazard introduced by Gray [18] and defined as: \n(2)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\begin{aligned}  \\lambda_{k}^{*}(t)&={\\lim}_{dt \\rightarrow 0} \\frac{1}{dt}P\\{t\\leq T< t+dt;\\varepsilon\\\\ &=k|T\\geq t\\cup (T < t;\\varepsilon \\neq k)\\} \\end{aligned}  $$ \\end{document}\u03bbk\u2217(t)=limdt\u219201dtP{t\u2264T<t+dt;\u03b5=k|T\u2265t\u222a(T<t;\u03b5\u2260k)}\n\nThis hazard has been shown to be very useful to compare the crude cumulative hazard functions in different groups, since it restores a one-to-one relationship between the hazard and the cumulative probability of a particular failure type: , with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\Lambda _{k}^{*}(t)={\\int _{0}^{t}} \\lambda _{k}^{*}(s)ds$\\end{document}\u039bk\u2217(t)=\u222b0t\u03bbk\u2217(s)ds and where the product integral notation  is used to suggest a limit of finite products \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\prod $\\end{document}\u220f [18, 19]. Of note, the one-to-one relationship between the hazard and the cumulative probability is not satisfied from the cause-specific hazard in the presence of competing events [20]. The subdistribution hazard can be thought as the hazard of an artificial variable \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$T^{*}_{k}=T\\cdot I\\left \\{ \\varepsilon =k\\right \\} +\\infty \\cdot I\\left \\{ \\varepsilon \\neq k \\right \\}$\\end{document}Tk\u2217=T\u00b7I\u03b5=k+\u221e\u00b7I\u03b5\u2260k that extends to infinity the time to event k when another competing event is observed. In fact, for any finite t, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$T^{*}_{k}\\leq t$\\end{document}Tk\u2217\u2264t is equivalent to T\u2264t and \u03b5=k; thus, given definition (1), \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$P\\left (T^{*}_{k}\\leq t\\right) = F_{k}(t)$\\end{document}PTk\u2217\u2264t=Fk(t). The definition of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$T^{*}_{k}$\\end{document}Tk\u2217 is consistent with the argument that when an event other than k occurs as first, the latter will never be observed as first and thus the corresponding time is infinity.\n\nLet (Ti,\u03b5i,Ci,Zi), with i=1\u2026N, be N independent replicates of (T,\u03b5,C,Z), where C is the censoring time and Z a vector of covariates. We will refer to these N subjects as the phase I sample. Define X= min(T,C) and \u0394=I(T\u2264C). We will assume that failure and censoring times are conditionally independent, T\u22a5C|Z. Let Yi(t)=I(Xi\u2265t), Nik(t)=I(Xi\u2264t,\u0394i\u03b5i=k) and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$N_{i \\cdot }(t)=\\sum _{k=1}^{K} N_{\\textit {ik}}(t)$\\end{document}Ni\u00b7(t)=\u2211k=1KNik(t), where I(\u00b7) is the indicator function. Define G(t)=P(C>t) as the probability to remaining uncensored up to t.\n\nSuppose that complete information on (Xi,\u0394i\u03b5i,Zi) is available only for a subset n<N of subjects drawn based on a possibly complex sampling design and let \u03bei indicate whether subject i is selected into this sample. We will refer to the \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$n=\\sum _{i}\\xi _{i}$\\end{document}n=\u2211i\u03bei subjects as the phase II sample, even if multiple phases of sampling could actually be involved to obtain the final complete sample [7]. Let \u03c0i=P(\u03bei=1|Xi,\u0394i\u03b5i,Zi) being the inclusion probability of subject i for the phase II sample, conditional on being selected at the first phase. In a random sample this probability is equal for every subject. However sampling is often stratified on some variables to increase efficiency; in this case, the probability to be selected for the phase II sample is common for all subjects in the same stratum and differs between strata. In particular, it is usually higher for the more informative strata (e.g. strata including subjects with the event of interest as in case-control studies). For nested case-control designs the sampling probability of cases will be 1, while the one of controls might be derived as the probability that individual i is ever selected as control, following Samuelsen [4]. We denote the pairwise sampling probability for any two subjects (i,j, with i\u2260j) by \u03c0ij=P(\u03bei=1,\u03bej=1|Xi,\u0394i\u03b5i,Zi,Xj,\u0394j\u03b5j,Zj). As commonly assumed in survey theory, the sampling method should have the following properties: the sampling probabilities \u03c0i and \u03c0ij must be non zero for all i,j in the population and must be known for each i,j in the sample [7].\n\nUnder a two-phase design it is common to be interested in estimating survival in subgroups related to variables ascertained only in phase II sample (i.e. biomarkers). Another possible situation is that, instead of covariates, the outcome itself is not available for the whole cohort. Thus, in both cases an estimate of the incidence of event using only the phase II sample is very useful. The total number of events of type k up to t and the total number of persons at risk at time t for the entire phase I sample can be estimated from the phase II sample (accounting for the sample design) by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {N}_{\\cdot k}(t)=\\sum _{i=1}^{N} [\\!\\xi _{i} N_{\\textit {ik}}(t)/\\pi _{i}]$\\end{document}N^\u00b7k(t)=\u2211i=1N[\u03beiNik(t)/\u03c0i] and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}_{\\cdot }(t)=\\sum _{i=1}^{N} [\\!\\xi _{i} Y_{i}(t)/\\pi _{i}]$\\end{document}\u0176\u00b7(t)=\u2211i=1N[\u03beiYi(t)/\u03c0i], respectively. Note that these estimates are valid under general sampling designs, where \u03c0i and \u03c0ij, the so-called \u2018design weights\u2019, are known for the observations actually sampled [21].\n\nThe estimate of the overall survival has been shown by several authors in different contexts of complex sampling [13\u201315]: \n(3)\n\nwhere the overall hazard can be obtained by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }(t)=\\sum _{k=1}^{K} \\hat {\\Lambda }_{k}(t)$\\end{document}\u039b^(t)=\u2211k=1K\u039b^k(t) and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }_{k}(t)= {\\int _{0}^{t}} \\hat {N}_{\\cdot k}(ds)/\\hat {Y}_{\\cdot }(s)$\\end{document}\u039b^k(t)=\u222b0tN^\u00b7k(ds)/\u0176\u00b7(s) [22]. It has been shown that \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N}[\\!\\hat {\\Lambda }(t)-\\Lambda (t)]$\\end{document}N[\u039b^(t)\u2212\u039b(t)] converges weakly to a zero-mean Gaussian process [14, 15].\n\nThe goal is to estimate the crude incidence of a given cause k, , using the phase II sample, which is also called subdistribution function and is the probability that a failure due to cause k occurs within t [23, 24]. The estimate of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}${\\Lambda }_{k}^{*}(t)$\\end{document}\u039bk\u2217(t) is based on the count of events due to cause k and the count of subjects at risk for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$T^{*}_{k}$\\end{document}Tk\u2217, denoted by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}_{\\cdot k}^{*}(s)$\\end{document}\u0176\u00b7k\u2217(s) (see Appendix A.1): \n(4)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$\\hat{Y}^{*}_{\\cdot k}(s)= \\sum_{i=1}^{N} \\frac{\\xi_{i}}{\\pi_{i}} Y_{i}(s) + \\sum_{i=1}^{N} \\frac{\\xi_{i}}{\\pi_{i}} \\left[ \\sum_{l\\neq k} N_{il}(s^{-})\\cdot \\hat{G}(s^{-}|X_{i}^{-})\\right]  $$ \\end{document}\u0176\u00b7k\u2217(s)=\u2211i=1N\u03bei\u03c0iYi(s)+\u2211i=1N\u03bei\u03c0i\u2211l\u2260kNil(s\u2212)\u00b7\u011c(s\u2212|Xi\u2212)\n\nThe estimate of the cumulative subdistribution hazard in (2) can now be estimated, using only the phase II sample, by: \n(5)\n\nNote the complement of Fk(t) can be thought as the survival probability of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$T^{*}_{k}$\\end{document}Tk\u2217 [18, 20, 25], thus a product limit type estimator can be directly derived as: \n(6)\n\nInterestingly, this estimator is algebraically equivalent to the Aalen-Johansen type estimator, shown by [18] for random sampling, and in the Appendix A.2 for general sampling: \n(7)\n\nIt is easy to see that in the absence of competing events, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}^{*}_{\\cdot k}(s)$\\end{document}\u0176\u00b7k\u2217(s) in (4) degenerates to the usual risk set \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}_{\\cdot }(s)$\\end{document}\u0176\u00b7(s), thus \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }_{k}^{*}(t)=\\hat {\\Lambda }(t)$\\end{document}\u039b^k\u2217(t)=\u039b^(t) and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}_{k}(t)$\\end{document}F^k(t) equals the complement of 1 of the weighted Kaplan-Meier estimator for two-phase studies [13]. Under no censoring, the weight \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {G}(s^{-}|X_{i})$\\end{document}\u011c(s\u2212|Xi) becomes 1 and the risk set \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$Y^{*}_{\\cdot k}$\\end{document}Y\u00b7k\u2217 is eroded in time only by events of type k, therefore \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}_{k}(t)$\\end{document}F^k(t) degenerates into the proportion of events of type k estimated by the phase II sample (weighted number of events of type k out of the estimated total size of the cohort, phase I). If every subject in phase I is sampled (\u03bei=1 \u2200i), then (5) becomes the standard subdistribution cumulative hazard [19, 20] and (6) the standard estimator of the crude incidence.\n\nFor simplicity of notation, in (6) we estimated the overall incidence regardless of covariates, but the estimator can also be applied on subgroups defined by Z. The censoring probability G(t) should also be estimated in subgroups defined by Z. The overall estimator is reasonable when we make the more restrictive assumption T\u22a5C, otherwise separate estimators conditional on Z would be more appropriate (and eventually an average, weighted on the frequencies of Z, between the conditional estimates).\n\nFollowing Breslow and Wellner [26], we can express \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N}\\left [\\hat {\\Lambda }^{*}_{k}(t)-\\Lambda ^{*}_{k}(t)\\right ]=\\sqrt {N}\\left [\\tilde {\\Lambda }^{*}_{k}(t)-\\Lambda ^{*}_{k}(t)\\right ]+ \\sqrt {N}\\left [\\hat {\\Lambda }^{*}_{k}(t)-\\tilde {\\Lambda }^{*}_{k}(t)\\right ]$\\end{document}N\u039b^k\u2217(t)\u2212\u039bk\u2217(t)=N\u039b~k\u2217(t)\u2212\u039bk\u2217(t)+N\u039b^k\u2217(t)\u2212\u039b~k\u2217(t) where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\tilde {\\Lambda }^{*}_{k}(t)$\\end{document}\u039b~k\u2217(t) represents the crude cumulative incidence estimator that we would have obtained if complete information (Xi,\u0394i\u03b5i,Zi) was known for all the subjects in phase I sample (i=1\u2026N) [18]. The two terms are asymptotically independent [14, 26]. The first term converges weakly to a zero-mean Gaussian process [19] with covariance that we denote as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sigma _{k\\medskip I}^{2}(t)$\\end{document}\u03c3kI2(t). By the arguments in Appendix A.3, the second term converges weakly to a zero-mean Gaussian process with covariance \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sigma _{k\\medskip II}^{2}(t)$\\end{document}\u03c3kII2(t). Hence, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N}\\left [\\hat {\\Lambda }^{*}_{k}(t)-\\Lambda ^{*}_{k}(t)\\right ]$\\end{document}N\u039b^k\u2217(t)\u2212\u039bk\u2217(t) converges weakly to a zero-mean Gaussian process with covariance being the sum of the contribution of each sampling phase: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}${\\sigma _{k}^{2}}(t)=\\sigma _{k\\medskip I}^{2}(t)+\\sigma _{k\\medskip II}^{2}(t)$\\end{document}\u03c3k2(t)=\u03c3kI2(t)+\u03c3kII2(t). The first one represents the irreducible minimum uncertainty that would remain if everyone in phase I would be sampled and the second one accounts for the fact that complete information is available only in the phase II sample [13, 14, 26].\n\nEach contribution to the variance can be estimated by the influence function approach [27]. The influence function of an estimator describes how the estimator changes when single observations are added or removed from the data and has the property that the difference between the estimate and the population quantity can be expressed as the sum of influence functions over all the subjects in the sample. By denoting with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$z_{\\textit {ik}}^{*}(t)$\\end{document}zik\u2217(t) the influence function of subject i on \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }^{*}_{k}(t)$\\end{document}\u039b^k\u2217(t) we have that [28]: \n(8)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\hat{\\Lambda}_{k}^{*}(t)-\\Lambda^{*}_{k}(t)=\\sum_{i=1}^{N} z_{ik}^{*}(t)+o(1/\\sqrt{N})  $$ \\end{document}\u039b^k\u2217(t)\u2212\u039bk\u2217(t)=\u2211i=1Nzik\u2217(t)+o(1/N)\n\nThe influence function of subject i on \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }^{*}_{k}(t)$\\end{document}\u039b^k\u2217(t) has been derived in Appendix A.4.\n\nBy using the Horvitz-Thomposon variance [29] on the weighted influence function, the contribution of the variance of phase II will be: \n(9)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\begin{aligned} \\hat{\\sigma}_{k\\medskip II}^{2}(t) &=\\hat{var}\\left[\\sum_{i=1}^{N} \\frac{\\xi_{i}}{\\pi_{i}} z_{ik}^{*}(t)\\right]=\\\\ &=\\overset{n}{\\underset{i=1}{\\sum}} \\sum_{j=1}^{n} \\left[\\frac{z_{ik}^{*}(t)\\cdot z_{jk}^{*}(t)}{\\pi_{i}\\cdot \\pi_{j}} - \\frac{z_{ik}^{*}(t)\\cdot z_{jk}^{*}(t)}{\\pi_{ij}}\\right]  \\end{aligned}  $$ \\end{document}\u03c3^kII2(t)=var^\u2211i=1N\u03bei\u03c0izik\u2217(t)==\u2211i=1n\u2211j=1nzik\u2217(t)\u00b7zjk\u2217(t)\u03c0i\u00b7\u03c0j\u2212zik\u2217(t)\u00b7zjk\u2217(t)\u03c0ij\n\nFor phase I, the variance \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\sigma }_{k\\medskip I}^{2}(t) $\\end{document}\u03c3^kI2(t) can also be estimated using (9) by setting sampling probabilities to 1 [13].\n\nGiven the one-to-one relationship between Fk(t) and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\Lambda _{k}^{*}(t)$\\end{document}\u039bk\u2217(t), the variance of the crude cumulative incidence (6) can now be estimated as: \n(10)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\hat{var}\\left[\\hat{F}_{k}(t)\\right]=\\left[1-\\hat{F}_{k}(t)\\right]^{2}\\cdot\\hat{\\sigma}_{k}^{2}(t)  $$ \\end{document}var^F^k(t)=1\u2212F^k(t)2\u00b7\u03c3^k2(t)\n\nIn analogy with the survival estimate for two-phase designs, we derived confidence intervals for (6) on the logarithm scale by: \n(11)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\exp \\left\\{\\log[\\hat{F}_{k}(t)] \\pm q_{\\alpha/2}\\frac{1-\\hat{F}_{k}(t)}{\\hat{F}_{k}(t)} \\hat{\\sigma}_{k}(t)\\right\\}  $$ \\end{document}explog[F^k(t)]\u00b1q\u03b1/21\u2212F^k(t)F^k(t)\u03c3^k(t)\n\nwhere q\u03b1/2 denotes the \u03b1/2 quantile of the standard Gaussian distribution.\n\nBy using suitable weights for both study design and censoring, any software allowing for time dependent weights can be used to derive the modified risk set and to estimate the crude cumulative incidence function (6). These weights have been implemented in R in function crprep in the mstate package [30] and in STATA in the stcrprep function. However, any software can be used to derive the ingredients for the modified risk set in (4) and these can be used to estimate (6) and its variance by the Horvitz-Thompson approach.\n\nThe complete code to compute this estimate has been developed in R software [31] using the survey package [32] and is available at [33]. An example of the application of this function is given in the subsection Genotype ascertained on a subset of a clinical trial cohort.\n\nWe considered two competing events with independent latent times T1 and T2 and constant marginal hazard of 0.1, the crude incidences are then \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$F_{1}(t)=F_{2}(t)=\\frac {1}{2}(1-e^{-0.1t})$\\end{document}F1(t)=F2(t)=12(1\u2212e\u22120.1t). We focused on the crude incidence of event 1 up to t=2 units of time (i.e. years). This implies a fraction of 82 % with no events at t=2 (administrative censoring) and a crude incidence of about 9 %. The independence between the latent times T1 and T2 is not restrictive given the non identifiability issue [34]. The censoring time followed an uniform distribution on ranges (0.5,30.5) and (0.5,10.5), leading to around 5 % and 15 % censored before t=2, respectively.\n\nWe drew B=1000 random first-phase samples of size N=1000, from which we sampled a phase II sample according to different study designs: \nrandom sample, with n=50,100 units;case-control sampling: we randomly sampled n/2 individuals among those who experienced event 1 (cases) up to time 2 and n/2 individuals among the others (controls), with n=50,100 units;stratified sampling: we considered the phase I sample divided into 4 strata defined by the variable Z={0,1} (with frequencies 70 % and 30 % for Z=0 and Z=1, respectively) and the occurrence or not of event 1 up to time 2. The hazard rates were assumed to be 0.08 and 0.2 with Z=0 and with Z=1, respectively. An equal number of subjects (n/4) were sampled for each strata (balanced sampling), with n=50,100 units.nested case-control design: we selected all cases and m controls for each case with no events at the time of event of the case, fixing m=1,2. Under this design we cannot fix a total sample size a priori, but we expect around 90 events and 90\u00b7m controls. Sampling probabilities for each included subject were derived according to Samuelsen [4].\n\nB = 1000 was chosen in order to get a \u00b15 % level of accuracy in the estimate of the crude incidence (F1(t),t>0.3) in about 95 % of the samples. For each sample, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}_{1}(t)$\\end{document}F^1(t) has been computed by (6), with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }_{1}^{*}(dt)$\\end{document}\u039b^1\u2217(dt) estimated by (5), and it has been compared with F1(t) in order to assess bias in each sample: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}_{1b}(t)-F_{1}(t)$\\end{document}F^1b(t)\u2212F1(t), b=1\u2026B. Bias has been computed and reported for 20 different time points t=0.1,0.2,\u2026,2. For each simulation, we also computed standard error of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}_{1}(t)$\\end{document}F^1(t) according to (10) and the 95 % confidence interval (CI) of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}_{1}(t)$\\end{document}F^1(t) on the logarithm scale (11) to evaluate coverage and length.\n\nFigure 1 compares the average of the estimated standard error of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}_{1}(t)$\\end{document}F^1(t) in each simulation with the empirical standard error at the 20 different times of observation in the four different scenarios with random censoring of 15 %. They were found to be very close in all scenarios, as expected.\n\n\nFigure 2 reports the distribution of bias in each one of the 1000 simulated samples under random (panel a), case-control (panel b), stratified (panel c) and nested case-control sampling (m=1, panel d). Bias fluctuates around 0 in each scenario, but it has more variability in the random sampling compared to other scenarios, resulting also in a higher mean value of absolute bias over the B simulations (still always lower than 0.2 %). The lower performance of the estimator in the first scenario is due to the fact that random sampling is not a convenient design in the simulated setting. In fact, in phase I cohort we expect around 90 events of type 1 (incidence of 9 % and sample size of 1000), thus if we randomly sample 100 subjects from the phase I cohort, we expect to observe only 9 events (in phase II sample). With such a small number of events, unbiasedness is in fact not sufficient to ensure a reasonable behaviour and to get enough information on event incidence. To address this issue, the other study designs (scenarios 2, 3, and 4) are indeed thought to guarantee to sample more events of type 1. Thus we recommend adopting efficient designs accounting for the event of interest. Relative and standardized biases were always lower than 6 % (data not shown). The mean square error, not shown, slightly increases with time, in fact variability is increasing in time (as confirmed by the empirical standard error of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}_{1}(t)$\\end{document}F^1(t) and by Fig. 2). The average length of the confidence interval was consistently increasing with time, ranging between 7 % and 12 % in the random sampling and between 2 % and 4 % in the case-control, stratified and nested case-control sampling (data not shown). This comparison underscores the advantages of a careful selection of the subsample.\n\n\nFigure 3 reports results on coverage for the random, case-control, stratified and nested case-control sampling. The coverage was very close to the nominal value of 95 %, ranging mostly within a minimum of 94 % and a maximum of 97 %, except for very early times in the random setting.\n\n\nIn the same setting, we also considered a longer follow-up time, t = 50, with around 500 events of type 1 expected in phase I sample (under no censoring), and confirmed the performance of our estimator in a scenario with higher variability, with similar results for the different sampling schemes (data not shown).\n\nA study on childhood ALL evaluated the role of a genetic polymorphism (glutathione S-transferase- \u03b8, GST-T1) on treatment failure due to relapse (in different sites), in the presence of a competing event (toxic death). GST-T1 is a common genetic polymorphism in Caucasians, with 13\u201326 % of individuals displaying a homozygous deletion of the gene (null genotype). Subjects carrying the null variants fail to express the GST-T1 enzyme, that is involved in drug metabolism. Clinical information were available for a cohort of 1999 consecutive patients (mainly European Caucasians, aged between 1 and 17 years, median age: 5 years) newly diagnosed with ALL in the Italian Associazione Italiana di Ematologia Pediatrica centers between September 2000 and July 2006. Biological samples stored at diagnosis were available, but genotype was ascertained only in a subgroup (phase II sample) for an efficient use of specimens [11, 13]. The interest was to evaluate incidence at different relapse sites by GST-T1, that can only be estimated using phase II data. In order to select the subgroup to be genotyped we adopted an optimal strategy that is carefully described in [11, 13]. Briefly, sampling was done after classifying patients into 6 strata according to the event of interest (relapse/no relapse) and to 3 groups, defined by prognostic features in the treatment protocol, that modulate the intensity of treatment, we will call them treatment protocols (Table 1). Strata were not defined based on the competing event death due to toxicity- 58 events - for efficiency reasons given that the event of interest was relapse. Patients were sampled at random without replacement from the 6 strata, with the sampling from each stratum conducted independently (stratified sampling) and with higher probability in the more informative strata according to an optimal design [13]. The full cohort of 1999 patients represents the phase I sample, for which clinical information are available, while genotype is ascertained in the phase II sample only (n=601).\n\n\nRelapses were classified according to the site, in particular we distinguished relapses involving bone-marrow (BM) from the others (extramedullary). We estimated the crude incidence of BM relapse by GST-T1 deletion using (6) and (10) and found higher relapse incidence for patients with GST-T1 deletion, with 5-year crude incidence of 19.3 % (95 % CI: 13.4\u221227.7 %) versus 12.4 % (95 % CI: 10.7\u221214.4 % for non deleted patients, Fig. 4 panel a). This was derived accounting for the competing risk of other sites of relapse as well as for death due to toxicity.\n\n\nWe report here the R code used to compute these estimates:library(survey)d.std<-twophase(id=list(~upn,~upn), subset=~!is.na(GST_T),strata=list(NULL,~interaction(rel,elfin)),data=dat)GSTse<-svycr(Surv(time,event>0)~GST_T,etype=\u201cBMrelapse\u201d,d.std,se=TRUE)\n\nThe twophase function in the survey package describes the design and produces a survey object [32]. The svycr function, available at [33], performs the estimate of crude incidence by the influence approach and uses 3 variables: time is the time of event, event the censoring indicator (1 if an event of any type is observed and 0 otherwise) and BMrelapse indicates whether a BM relapse is observed or not. Details on the survey package can be found in [7, 32].\n\nThe right panel of Fig. 4 represents the incidence of extramedullary relapses by GST-T1 showing that the difference in relapse incidence between GST-T1 deleted and other patients is mainly due to relapse involving the BM, that represents the most relevant type of relapse in childhood ALL. A Cox model adapted for two-phase design [14], when applied to the cause specific hazard of BM relapse, gives an hazard ratio (HR) of 1.53 (95 % CI 0.98\u20132.37) for GST-T1 deleted patients versus non deleted; after adjusting for relevant factors (treatment protocol, gender, age), the HR dropped to 1.38 (95 % CI 0.90\u20132.13). For extramedullary relapses the HR was 1.22 (95 % CI 0.60\u20132.49). Of note, in order to compare patients with and without deletion of the GST-T1 gene, we used a cause-specific model, thus we actually compared the cause-specific hazard of relapse. In fact, a subdistribution model accounting for the two-phase design is not available. This would be useful to compare the actual incidences of relapse in the two groups, however the cause-specific model is still very useful to address the impact of the genotype on relapse by an aetiological point of view.\n\nIn the evaluation of the effectiveness of the global effort to provide antiretroviral therapy (ART) for HIV-infected patients in resource limited settings, the estimate of the number of patients who continue to access care after starting ART is essential. This estimate is hampered, however, by the fact that some patients die shortly after their last visit to clinic - a group of individuals who cannot be considered as \u201cstopping care\u201d nor censored for the event of stopping care. In addition, the number of patients who are starting care is large and a high fraction have unknown outcomes (i.e., are lost to follow-up), generating informative censoring. Given that lost patients could reasonably be not in care, but they could also have changed clinic or be dead, one approach to obtain outcomes estimates has been to identify a numerically small, but random, sample of those who are lost [15], intensively seeking their outcomes, and using them to correct outcomes among the lost.\n\nTo illustrate, a cohort of 13,321 HIV-infected adult patients, who initiated ART treatment, were followed from ART initiation to either death, disengagement or administrative database closure (see Fig. 5). Among them, 2451 patients were lost to follow-up [35], defined as not being seen at the clinic for at least 90 days (after the last return visit). A tracker went into the community to determine the outcome of a random subsample of 428 among the 2451 lost patients and got information on 306 patients (110 patient were found to be in care in other clinics, 80 died while in care and 116 were found to be not treated/disengaged) [12]. The 10,870 patients no lost to follow-up and the 306 tracked patients can been considered as the second phase sample of the whole cohort, stratified on lost to follow-up.\n\n\nWe used the methods developed in the Methods section to estimate crude cumulative incidence, where the 306 tracked patients represented the 2451 lost patients by the sampling probability 306/2451, while the other 10,870 had sampling weight one. The crude incidence estimate of disengagement is reported in Fig. 6, the curve starts to rise after 90 days from ART start, that is the earliest possible time of disengagement, by definition. At 1 year, disengagement resulted 6.8 % (CI 95 % 5.7\u20138.2 %). This was subject to a strong influence of the competing event death in care that resulted 7.7 % (CI 95 % 6.8\u20138.9 %) at 1 year. A na\u00efve (but less expensive) approach to deal with informative censoring would be to treat all lost patients as events or, contrarily, as censored observations. We plotted the two corresponding curves in Fig. 6, obtaining estimates of crude incidence at 1 year since ART treatment of 18.5 % and 0.2 %, respectively. We can consider that the true incidence will lie between these two estimates (that are however quite far in this context), as in fact it does the estimate we got by tracking a random sample of lost patients and using the proposed estimator.\n\n\nThe R code to compute the proposed estimate of crude cumulative incidence is available at [33]. The results of simulations presented in the Simulations section and the related code are also available at [33].\n\nWe have derived an estimator for cumulative incidence of events based on the subdistribution hazard accounting for competing risks under a general sampling design from an infinite target population. The estimator shows good performance in simulations under different scenarios and the variance, derived by the influence function of the subdistribution hazard and the Horvitz-Thompson theory, was very close to the empirical variance, therefore we expect it to be very close to the one obtainable by replicate weights (e.g. bootstrap) [7]. Confidence intervals, derived on the log scale, provided good coverage in simulations, but alternative confidence intervals might also be considered such as the complementary log-log transformation [36]. The proposed estimator was used to estimate incidence of relapse by genotype in a cohort of childhood ALL patients, where the genotype was ascertained only on a subsample of the cohort chosen by an optimal sampling approach based on relapse as the event of interest. Interestingly, we can also analyze the incidence of the competing event (toxic death) or of the combined endpoint (relapse or toxic death), but the efficiency could be lower unless the subsampling is adapted to this new endpoint by including a further strata on toxic death in the sampling process. This is particularly important since toxic death is a rare event in this context. We should also remember to avoid random sampling when the event of interest is rare, as discussed in the Simulations section.\n\nIn the second case, we dealt with a missing data problem, in which the outcome itself was not available for everybody, since some patients were lost to follow-up. A subsample of lost patients had been tracked to ascertain the outcome, but if this tracking was not possible, a more basic/na\u00efve approach to deal with this informative censoring could have been to identify the variables affecting missingness, post-stratify the sample in homogeneous strata and use the missing probabilities for each strata as sort of sampling weights to adjust the incidence estimate. This approach would make an important assumption of missing at random that might be not appropriate and cannot be tested [7, 15, 21, 37]. However this underlines how the proposed estimator could be applied also in the presence of missing data.\n\nThe code to compute this estimate has been developed in R software [31] under the survey package [32] and is available at [33]. The survey package is a flexible package for complex surveys including also two-phase studies. It provides flexible functions to describe the design of the study and to derive sampling fraction accordingly. The package includes functions to estimate survival and to perform a weighted Cox model with standard error properly adjusted for the design and with the possibility to use general weights, as calibrated weights. Our function takes advantage of the facilities of the package (see an example of use in Genotype ascertained on a subset of a clinical trial cohort).\n\nIn order to recover the representativeness of the subcohort (phase II) for the entire cohort, we used weights related to the inverse of the probability to be sampled, similarly to the weights of Barlow for case-cohort studies [38]. More general weights can be used, such as calibration weights [7, 39, 40]. The use of calibration weights is advantageous when there is availability of phase I variables that are strongly related to the additional variables ascertained in phase II. This would provide results more representative of phase I data and increase precision. When phase II variables are common genetic polymorphisms, as in our first example, it is unlikely to find any strong relation between phase I and II variables, therefore no big advantage would be expected by calibration.\n\nThe estimator can also be extended to a situation where an individual may move among a finite number of states to estimate the Aalen-Johansen probabilities of transition among each state in a multistate framework [41] in the presence of general sampling design.\n\nIn order to derive a model-based estimate of incidence (adjusted for possible covariates) two main approaches have been followed in the context of competing risk, the first one based on the cause-specific hazard inspired by Benichou and Gail [16, 42, 43] and the other one based on the subdistribution hazard [19, 44]. The crude cumulative estimator developed by Kovalchik and Pfeiffer [45] for two-phase studies for finite population follows the first approach, and the Cox model for two-phase designs [14] could be used to extend it for infinite population. Under this model we can estimate the effect of a covariate on the cause-specific hazard to address its impact on the event by an aetiological point of view. However it is well known that this does not reflect the impact of the variable on the crude cumulative incidence. The latter effect, even if affected by the incidence of the other competing events, could still be of interest for a public health prospective. Future work will concern the development of a regression model to assess the effect of a covariate on the crude cumulative incidence. The Fine and Gray regression model [19] could be extended to complex sampling by weighting the estimating function of the parameter of interest and working out their influence function.\n\nThe risk set for the usual survival time T at s is commonly obtained in standard analysis by counting the observed times greater then s. It can be also written as: \n(12)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\hat{Y}_{\\cdot}(s)=\\hat{P}(T>s^{-})\\hat{P}(C>s^{-})={\\hat{Y}_{\\cdot}(0)} \\hat{S}(s^{-})\\hat{G}(s^{-})  $$ \\end{document}\u0176\u00b7(s)=P^(T>s\u2212)P^(C>s\u2212)=\u0176\u00b7(0)\u015c(s\u2212)\u011c(s\u2212)\n\nwhere \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {G}(s)$\\end{document}\u011c(s) is the probability to be free of censoring up to s and is estimated considering censored observations as events and viceversa according to (3). This can proved also in the case of a two-phase design by the following: \n(13)\n\nwhere \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {N}_{\\cdot }^{c}(t)=\\sum _{i=1}^{N} \\left [\\xi _{i} I(X_{i}\\le t,\\Delta _{i}=0)/\\pi _{i}\\right ]$\\end{document}N^\u00b7c(t)=\u2211i=1N\u03beiI(Xi\u2264t,\u0394i=0)/\u03c0i denotes the number of censoring up to time t and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {N}_{\\cdot \\cdot }(t)=\\sum _{i=1}^{n} \\hat {N}_{\\textit {i}\\cdot }(t)$\\end{document}N^\u00b7\u00b7(t)=\u2211i=1nN^i\u00b7(t) the total count of events observed up to time t.\n\nThe derivation of the risk set for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$T^{*}_{k}$\\end{document}Tk\u2217 at s can be obtained by: \n(14)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ {{\\begin{aligned} \\hat{Y}^{*}_{\\cdot k}(s)&=\\hat{P}\\left(T^{*}_{k}>s^{-}\\right)\\hat{P}(C>s^{-})={\\hat{Y}_{\\cdot}(0)} \\cdot \\left[1-\\hat{F}_{k}(s^{-})\\right] \\hat{G}(s^{-})=\\\\ &={\\hat{Y}_{\\cdot}(0)} \\cdot\\left[\\hat{S}(s^{-})+\\sum_{l\\neq k}\\hat{F}_{l}(s^{-})\\right]\\cdot \\hat{G}(s^{-})=\\\\ &=\\hat{Y}_{\\cdot}(s)+{\\hat{Y}_{\\cdot}(0)} \\cdot\\sum_{l\\neq k}\\hat{F}_{l}(s^{-})\\cdot\\hat{G}(s^{-}) \\end{aligned}}}  $$ \\end{document}\u0176\u00b7k\u2217(s)=P^Tk\u2217>s\u2212P^(C>s\u2212)=\u0176\u00b7(0)\u00b71\u2212F^k(s\u2212)\u011c(s\u2212)==\u0176\u00b7(0)\u00b7\u015c(s\u2212)+\u2211l\u2260kF^l(s\u2212)\u00b7\u011c(s\u2212)==\u0176\u00b7(s)+\u0176\u00b7(0)\u00b7\u2211l\u2260kF^l(s\u2212)\u00b7\u011c(s\u2212)\n\nBy writing \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}_{l}(s^{-})$\\end{document}F^l(s\u2212) as empirical cumulative distribution function \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}_{l}(s^{-})=\\frac {1}{\\hat {Y}_{\\cdot }(0)}\\sum _{i=1}^{N} \\frac {\\xi _{i}}{\\pi _{i}}\\frac {I(X_{i}\\le s^{-};\\varepsilon _{i}=l)}{\\hat {G}(X_{i}^{-}\\wedge s^{-})} $\\end{document}F^l(s\u2212)=1\u0176\u00b7(0)\u2211i=1N\u03bei\u03c0iI(Xi\u2264s\u2212;\u03b5i=l)\u011c(Xi\u2212\u2227s\u2212) [25, 46], the risk set becomes: \n(15)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\begin{aligned} \\hat{Y}^{*}_{\\cdot k}(s)&={\\hat{Y}_{\\cdot}(s)}+\\sum_{l\\neq k}\\sum_{i=1}^{N}\\frac{\\xi_{i}}{\\pi_{i}}I(X_{i}\\le s^{-};\\varepsilon_{i}=l)\\frac{\\hat{G}(s^{-})}{\\hat{G}\\left(X_{i}^{-}\\wedge s^{-}\\right)} \\end{aligned}  $$ \\end{document}\u0176\u00b7k\u2217(s)=\u0176\u00b7(s)+\u2211l\u2260k\u2211i=1N\u03bei\u03c0iI(Xi\u2264s\u2212;\u03b5i=l)\u011c(s\u2212)\u011cXi\u2212\u2227s\u2212\n\nthat can be simplified to \n(16)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\sum_{i=1}^{N} \\frac{\\xi_{i}}{\\pi_{i}} Y_{i}(s) +\\sum_{i=1}^{N} \\frac{\\xi_{i}}{\\pi_{i}} \\left[ \\sum_{l\\neq k} N_{il}(s^{-})\\cdot \\hat{G}\\left(s^{-}|X_{i}^{-}\\right)\\right]  $$ \\end{document}\u2211i=1N\u03bei\u03c0iYi(s)+\u2211i=1N\u03bei\u03c0i\u2211l\u2260kNil(s\u2212)\u00b7\u011cs\u2212|Xi\u2212\n\nthat is equivalent to (4).\n\nThe first summation estimates the usual total number of subjects at risk at s, where the condition Xi= min(Ti,Ci)\u2265s is satisfied. This in fact implies \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\min (T_{\\textit {ki}}^{*},C_{i})\\geq s$\\end{document}min(Tki\u2217,Ci)\u2265s, i.e. being at risk for T implies being also at risk for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$T^{*}_{k}$\\end{document}Tk\u2217. The second summation estimates the number of subjects who had other events before s, satisfying the condition Xi= min(Ti,Ci)<s, \u0394i=1 and \u03b5i\u2260k which implies \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$T_{\\textit {ki}}^{*}=\\infty > s$\\end{document}Tki\u2217=\u221e>s and completes the number at risk at s for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$T^{*}_{k}$\\end{document}Tk\u2217. While the first part is exposed to censoring, the contribute of each subject observed to fail of cause l\u2260k, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sum _{l\\neq k} N_{\\textit {il}}(s^{-})$\\end{document}\u2211l\u2260kNil(s\u2212), would remain equal to 1 up to \u221e, thus ignoring possible censoring, given that Ci is (usually) not observable if Ti<Ci. A possible way to deal with this inconsistency is to mimic the presence of random censoring acting on the infinite times, by weighting the unitary contributions \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sum _{l\\neq k}N_{\\textit {il}}(s^{-})$\\end{document}\u2211l\u2260kNil(s\u2212) by the estimate \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {G}(s^{-}|X_{i}^{-})$\\end{document}\u011c(s\u2212|Xi\u2212) of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$P(C>s^{-}|C>X_{i}^{-})=G(s^{-}|X_{i})$\\end{document}P(C>s\u2212|C>Xi\u2212)=G(s\u2212|Xi), where G(t)=P(C>t) is estimated by \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\label {eq:G}\\hat {G}(t)=\\prod _{s\\leq t} \\left [1- \\frac {\\sum _{i=1}^{N}\\xi _{i} {N_{i}^{c}}(ds)/\\pi _{i}}{\\sum _{i=1}^{N}\\xi _{i} Y_{i}(s)/\\pi _{i}}\\right ]$\\end{document}\u011c(t)=\u220fs\u2264t1\u2212\u2211i=1N\u03beiNic(ds)/\u03c0i\u2211i=1N\u03beiYi(s)/\u03c0i, with \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}${N_{i}^{c}}(s)=I(X_{i}\\leq s,\\Delta _{i}=0)$\\end{document}Nic(s)=I(Xi\u2264s,\u0394i=0). This weight assumes value 1 before Xi and decreases afterword according to the censoring distribution.\n\nOf note, an alternative expression for \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}^{*}_{\\cdot k}(s)$\\end{document}\u0176\u00b7k\u2217(s) derives substituting \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}_{\\cdot }(0)\\hat {G}(s^{-})=\\frac {\\hat {Y}_{\\cdot }(s)}{\\hat {S}(s^{-})}$\\end{document}\u0176\u00b7(0)\u011c(s\u2212)=\u0176\u00b7(s)\u015c(s\u2212) from (12) in (14): \n(17)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$  \\hat{Y}^{*}_{\\cdot k}(s)={\\hat{Y}_{\\cdot}(0)}\\hat{G}(s^{-}) \\cdot\\left[1-\\hat{F}_{k}(s^{-})\\right]={\\hat{Y}_{\\cdot}(s)} \\frac{\\left[1-\\hat{F}_{k}(s^{-})\\right]}{\\hat{S}(s^{-})}  $$ \\end{document}\u0176\u00b7k\u2217(s)=\u0176\u00b7(0)\u011c(s\u2212)\u00b71\u2212F^k(s\u2212)=\u0176\u00b7(s)1\u2212F^k(s\u2212)\u015c(s\u2212)\n\nThis shows as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}_{\\cdot }(s)$\\end{document}\u0176\u00b7(s) is upweighted by a multiplier that gets greater as the action of competing events gets larger, accounting for the fact that subjects that experienced events of type l\u2260k will never experience event k as first.\n\nThe equality between the cumulative incidence of the artificial variable T\u2217 in (6) and the Aalen-Johansen type estimator (that for the purpose of this proof will be denoted as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}^{AJ}_{k}(t)$\\end{document}F^kAJ(t)) holds true if and only if, \u2200t: \n(18)\n\nwhich can be proved by induction. Both quantities are step functions, changing value at each occurrence of type k events. At the time t where the first event of type k is observed, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }_{k}(dt)=\\hat {\\Lambda }^{*}_{k}(dt)$\\end{document}\u039b^k(dt)=\u039b^k\u2217(dt) being from (4) \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}_{\\cdot }(t)=\\hat {Y}_{\\cdot k}^{*}(t)$\\end{document}\u0176\u00b7(t)=\u0176\u00b7k\u2217(t). If this was the first event overall, then \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {S}(0)=1$\\end{document}\u015c(0)=1 and Eq. 18 is satisfied, otherwise \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}^{AJ}_{k}(t)=[\\!1-1/\\hat {Y}_{\\cdot }(0)]\\cdot 1/[\\!\\hat {Y}_{\\cdot }(0)-1]=1/\\hat {Y}_{\\cdot }(0)=1-[\\!1-1/\\hat {Y}_{\\cdot }(0)]=\\hat {F}_{k}(t)$\\end{document}F^kAJ(t)=[1\u22121/\u0176\u00b7(0)]\u00b71/[\u0176\u00b7(0)\u22121]=1/\u0176\u00b7(0)=1\u2212[1\u22121/\u0176\u00b7(0)]=F^k(t).\n\nNow, assuming that (18) holds true for a given t\u2212, this implies \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {F}^{AJ}_{k}(t)=\\hat {F}_{k}(t)$\\end{document}F^kAJ(t)=F^k(t) if and only if, from (18): \n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$\\begin{aligned} \\hat{F}^{AJ}_{k}(t^{-})+\\hat{S}(t^{-})\\hat{\\Lambda}_{k}(dt)& = 1-(1-\\hat{F}_{k}(t^{-}))\\left(1-\\hat{\\Lambda}^{*}_{k}(dt) \\right) \\end{aligned} $$ \\end{document}F^kAJ(t\u2212)+\u015c(t\u2212)\u039b^k(dt)=1\u2212(1\u2212F^k(t\u2212))1\u2212\u039b^k\u2217(dt) and using the equality at t\u2212: \n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$\\begin{aligned} \\hat{F}_{k}(t^{-})+\\hat{S}(t^{-})\\hat{\\Lambda}_{k}(dt) &=\\hat{F}_{k}(t^{-})+\\left[1-\\hat{F}_{k}(t^{-})\\right]\\hat{\\Lambda}^{*}_{k}(dt)\\\\ \\hat{S}(t^{-})\\hat{\\Lambda}_{k}(dt) &= \\left[1-\\hat{F}_{k}(t^{-})\\right]\\hat{\\Lambda}^{*}_{k}(dt)\\\\ \\hat{\\Lambda}_{k}(dt)& = \\frac{1-\\hat{F}_{k}(t^{-})}{\\hat{S}(t^{-})}\\hat{\\Lambda}^{*}_{k}(dt)\\\\ \\frac{\\hat{N}_{k}(dt)}{\\hat{Y}_{\\cdot}(t)} &=\\frac{1-\\hat{F}_{k}(t^{-})}{\\hat{S}(t^{-})}\\frac{\\hat{N}_{k}(dt)}{\\hat{Y}^{*}_{\\cdot k}(t)} \\\\ \\hat{Y}^{*}_{\\cdot k}(t) & = \\hat{Y}_{\\cdot}(t) \\cdot \\frac{1-\\hat{F}_{k}(t^{-})}{\\hat{S}(t^{-})} \\end{aligned} $$ \\end{document}F^k(t\u2212)+\u015c(t\u2212)\u039b^k(dt)=F^k(t\u2212)+1\u2212F^k(t\u2212)\u039b^k\u2217(dt)\u015c(t\u2212)\u039b^k(dt)=1\u2212F^k(t\u2212)\u039b^k\u2217(dt)\u039b^k(dt)=1\u2212F^k(t\u2212)\u015c(t\u2212)\u039b^k\u2217(dt)N^k(dt)\u0176\u00b7(t)=1\u2212F^k(t\u2212)\u015c(t\u2212)N^k(dt)\u0176\u00b7k\u2217(t)\u0176\u00b7k\u2217(t)=\u0176\u00b7(t)\u00b71\u2212F^k(t\u2212)\u015c(t\u2212)\n\nThat is proved by (17).\n\nLin showed that the normalised Horvitz-Thompson estimators of the number of events \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N}\\left [\\hat {N}_{\\cdot }(t)-N_{\\cdot }(t)\\right ]$\\end{document}NN^\u00b7(t)\u2212N\u00b7(t), number at risk \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N}\\left [\\hat {Y}_{\\cdot }(t)-Y_{\\cdot }(t)\\right ]$\\end{document}N\u0176\u00b7(t)\u2212Y\u00b7(t), cumulative hazard \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N}[\\hat {\\Lambda }(t)-\\Lambda (t)]$\\end{document}N[\u039b^(t)\u2212\u039b(t)] and survival function \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N}\\left [\\hat {S}(t)-S(t)\\right ]$\\end{document}N\u015c(t)\u2212S(t) (and analogously \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N}\\left [\\hat {G}(t)-G(t)\\right ]$\\end{document}N\u011c(t)\u2212G(t)) are asymptotically multivariate zero-mean normal [14]. Firstly, we concentrate on the normalised Horvitz-Thompson estimators of the modified at risk process: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N} \\left [\\hat {Y}^{*}_{\\cdot k}(t)-Y^{*}_{\\cdot k}(t)\\right ]=\\sqrt {N}\\sum _{i=1}^{N}\\frac {\\xi _{i}-\\pi _{i}}{\\pi _{i}}Y^{*}_{\\cdot k}(t) =\\sqrt {N}\\sum _{i=1}^{N} \\frac {\\xi _{i}-\\pi _{i}}{\\pi _{i}}Y_{\\cdot k}(t)+\\sqrt {N}\\sum _{i=1}^{N}\\frac {\\xi _{i}-\\pi _{i}}{\\pi _{i}}\\sum _{l\\neq k}N_{i l}(t^{-}) \\hat {G}(t^{-}|X_{i})$\\end{document}N\u0176\u00b7k\u2217(t)\u2212Y\u00b7k\u2217(t)=N\u2211i=1N\u03bei\u2212\u03c0i\u03c0iY\u00b7k\u2217(t)=N\u2211i=1N\u03bei\u2212\u03c0i\u03c0iY\u00b7k(t)+N\u2211i=1N\u03bei\u2212\u03c0i\u03c0i\u2211l\u2260kNil(t\u2212)\u011c(t\u2212|Xi). The first term represents the estimator of the number at risk, that Lin showed to be asymptotically multivariate zero-mean normal [14]. We concentrate now on the second term: \n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $${\\fontsize{8.8pt}{9.6pt}{\\begin{aligned} &\\sqrt{N}\\sum_{i=1}^{N} \\left[ \\frac{\\xi_{i}}{\\pi_{i}} \\cdot \\sum_{l\\neq k} N_{i l}(t^{-}) \\hat{G}(t^{-}|X_{i}) -\\sum_{l\\neq k} N_{i l}(t^{-}) \\hat{G}(t^{-}|X_{i}) \\right]= \\\\&=\\sqrt{N}\\sum_{i=1}^{N} \\left[\\hat{G}(t^{-}|X_{i})\\left\\lbrace \\frac{\\xi_{i}}{\\pi_{i}} \\sum_{l\\neq k} N_{i l}(t^{-}) -\\sum_{l\\neq k} N_{il}(t^{-})\\right\\rbrace\\right]=\\\\ &=\\sqrt{N}\\left[\\hat{G}(t^{-}|X_{i})\\left\\lbrace \\sum_{l\\neq k} \\hat{N}_{\\cdot l}(t^{-}) - \\sum_{l\\neq k} \\sum_{i=1}^{N} N_{i l}(t^{-})\\right\\rbrace\\right]= \\\\ &=\\sqrt{N}\\int_{0}^{t^{-}}\\hat{G}(s^{-}|X_{i})\\left\\lbrace \\sum_{l\\neq k} \\hat{N}_{\\cdot l}(ds{-}) - \\sum_{l\\neq k} \\sum_{i=1}^{N} N_{i l}(ds^{-})\\right\\rbrace=\\\\ &=\\sqrt{N}\\int_{0}^{t^{-}} G(t^{-}|X_{i})\\left\\lbrace \\sum_{l\\neq k} \\hat{N}_{\\cdot l}(ds{-}) - \\sum_{l\\neq k} \\sum_{i=1}^{N} N_{i l}(ds^{-})\\right\\rbrace+\\\\ &\\qquad+o_{p}(1) \\end{aligned}}} $$ \\end{document}N\u2211i=1N\u03bei\u03c0i\u00b7\u2211l\u2260kNil(t\u2212)\u011c(t\u2212|Xi)\u2212\u2211l\u2260kNil(t\u2212)\u011c(t\u2212|Xi)==N\u2211i=1N\u011c(t\u2212|Xi)\u03bei\u03c0i\u2211l\u2260kNil(t\u2212)\u2212\u2211l\u2260kNil(t\u2212)==N\u011c(t\u2212|Xi)\u2211l\u2260kN^\u00b7l(t\u2212)\u2212\u2211l\u2260k\u2211i=1NNil(t\u2212)==N\u222b0t\u2212\u011c(s\u2212|Xi)\u2211l\u2260kN^\u00b7l(ds\u2212)\u2212\u2211l\u2260k\u2211i=1NNil(ds\u2212)==N\u222b0t\u2212G(t\u2212|Xi)\u2211l\u2260kN^\u00b7l(ds\u2212)\u2212\u2211l\u2260k\u2211i=1NNil(ds\u2212)++op(1) that using Lemma 1 in [14] also converges to a zero-mean Gaussian process.\n\nWe want to prove that also \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N}\\left [\\hat {\\Lambda }^{*}_{k}(t)-\\Lambda ^{*}_{k}(t)\\right ]=\\sqrt {N}\\left [\\tilde {\\Lambda }^{*}_{k}(t)-\\Lambda ^{*}_{k}(t)\\right ] +\\sqrt {N}\\left [\\hat {\\Lambda }^{*}_{k}(t)-\\tilde {\\Lambda }^{*}_{k}(t)\\right ]$\\end{document}N\u039b^k\u2217(t)\u2212\u039bk\u2217(t)=N\u039b~k\u2217(t)\u2212\u039bk\u2217(t)+N\u039b^k\u2217(t)\u2212\u039b~k\u2217(t) converges to a zero-mean normal, where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\tilde {\\Lambda }^{*}_{k}(t)$\\end{document}\u039b~k\u2217(t) represents the crude cumulative incidence estimator that we would have obtained if complete information (Xi,\u0394i\u03b5i,Zi) was known for all the subjects in phase I sample (i=1\u2026N) [18]. Fine and Gray proved that the first term converges weakly to a zero-mean Gaussian process [19].\n\nThe second term results: \n\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $${\\fontsize{8.6pt}{9.6pt}{\\begin{aligned} \\sqrt{N}&\\left[\\hat{\\Lambda}^{*}_{k}(t)-\\tilde{\\Lambda}^{*}_{k}(t)\\right]= \\sqrt{N}\\left[\\int_{0}^{t}\\frac{\\hat{N}_{k}(ds)}{\\hat{Y}^{*}_{\\cdot k}(s)}-{\\int_{0}^{t}}\\frac{N_{k}(ds)}{Y^{*}_{\\cdot k}(s)}\\right]=\\\\ & =\\sqrt{N}\\left[\\int_{0}^{t}\\frac{\\hat{N}_{k}(ds)}{\\hat{Y}^{*}_{\\cdot k}(s)}-{\\int_{0}^{t}}\\frac{N_{k}(ds)}{Y^{*}_{\\cdot k}(s)} +{\\int_{0}^{t}}\\frac{{N}_{k}(ds)}{\\hat{Y}^{*}_{\\cdot k}(s)} -{\\int_{0}^{t}}\\frac{{N}_{k}(ds)}{\\hat{Y}^{*}_{\\cdot k}(s)}\\right]=\\\\ & =\\sqrt{N}\\left[\\int_{0}^{t} \\frac{\\hat{N}_{k}(ds)-N_{k}(ds)}{\\hat{Y}^{*}_{\\cdot k}(s)} - {\\int_{0}^{t}}\\frac{N_{k}(ds)\\left[\\hat{Y}^{*}_{\\cdot k}(s)-Y^{*}_{\\cdot k}(s)\\right]}{\\hat{Y}^{*}_{\\cdot k}(s)Y^{*}_{\\cdot k}(s)}\\right]. \\end{aligned}}} $$ \\end{document}N\u039b^k\u2217(t)\u2212\u039b~k\u2217(t)=N\u222b0tN^k(ds)\u0176\u00b7k\u2217(s)\u2212\u222b0tNk(ds)Y\u00b7k\u2217(s)==N\u222b0tN^k(ds)\u0176\u00b7k\u2217(s)\u2212\u222b0tNk(ds)Y\u00b7k\u2217(s)+\u222b0tNk(ds)\u0176\u00b7k\u2217(s)\u2212\u222b0tNk(ds)\u0176\u00b7k\u2217(s)==N\u222b0tN^k(ds)\u2212Nk(ds)\u0176\u00b7k\u2217(s)\u2212\u222b0tNk(ds)\u0176\u00b7k\u2217(s)\u2212Y\u00b7k\u2217(s)\u0176\u00b7k\u2217(s)Y\u00b7k\u2217(s).\n\nIt then follows that also \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\sqrt {N}\\left [\\hat {\\Lambda }^{*}_{k}(t)-\\tilde {\\Lambda }^{*}_{k}(t)\\right ]$\\end{document}N\u039b^k\u2217(t)\u2212\u039b~k\u2217(t) converges weakly to a zero-mean Gaussian process.\n\nThe estimator \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }_{k}^{*}(t)$\\end{document}\u039b^k\u2217(t) can be expressed as a differentiable function g of the estimated total number of events of type k and total number at risk for T\u2217 up to t: \n(19)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\begin{aligned} \\hat{\\Lambda}^{*}_{k}(t)=g(\\hat{N}_{\\cdot k}(dt),\\hat{Y}^{*}_{\\cdot k}(t))&={\\int_{0}^{t}}\\frac{ \\hat{N}_{\\cdot k}(ds)}{\\hat{Y}_{\\cdot k}^{*}(s)}=\\\\ &={\\int_{0}^{t}}\\frac{\\sum_{i=1}^{N} \\xi_{i} \\cdot N_{ik}(ds)w_{i}}{\\sum_{i=1}^{N} \\xi_{i} \\cdot Y_{ik}^{*}(s)w_{i}} \\end{aligned}  $$ \\end{document}\u039b^k\u2217(t)=g(N^\u00b7k(dt),\u0176\u00b7k\u2217(t))=\u222b0tN^\u00b7k(ds)\u0176\u00b7k\u2217(s)==\u222b0t\u2211i=1N\u03bei\u00b7Nik(ds)wi\u2211i=1N\u03bei\u00b7Yik\u2217(s)wi\n\nwhere wi=1/\u03c0i and \u03bei indicates whether subject i is withdrawn in the phase II sample.\n\nThe difference between the true and estimated cumulative hazard can be expressed as a sum of influence functions: \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }_{k}^{*}(t)-\\Lambda ^{*}_{k}(t)=\\sum _{i=1}^{N} z_{\\textit {ik}}^{*}+o(1/\\sqrt {N})$\\end{document}\u039b^k\u2217(t)\u2212\u039bk\u2217(t)=\u2211i=1Nzik\u2217+o(1/N), where \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$z_{\\textit {ik}}^{*}$\\end{document}zik\u2217 is the influence function of the ith subject. Demnati and Rao [27] proved that we can express the influence function of subject i as \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$z_{\\textit {ik}}^{*}(t)=\\frac {\\partial g \\left (\\hat {N}_{\\cdot k}(dt),\\hat {Y}^{*}_{\\cdot k}(t)\\right)}{\\partial w_{i}}$\\end{document}zik\u2217(t)=\u2202gN^\u00b7k(dt),\u0176\u00b7k\u2217(t)\u2202wi. The influence function of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }^{*}_{k}(t)$\\end{document}\u039b^k\u2217(t) of the ith subject can thus be derived as: \n(20)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ z_{ik}^{*}(t)={\\int_{0}^{t}} \\frac{N_{ik}(ds)\\hat{Y}^{*}_{\\cdot k}(s)-\\frac{\\partial \\hat{Y}^{*}_{\\cdot k}(s)}{\\partial w_{i}} \\hat{N}_{\\cdot k}(ds)}{\\hat{Y}^{*}_{\\cdot k}(s)^{2}}  $$ \\end{document}zik\u2217(t)=\u222b0tNik(ds)\u0176\u00b7k\u2217(s)\u2212\u2202\u0176\u00b7k\u2217(s)\u2202wiN^\u00b7k(ds)\u0176\u00b7k\u2217(s)2\n\nBeing \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}^{*}_{\\cdot k}(s)=\\sum _{i=1}^{N} \\xi _{i} w_{i}\\cdot \\left [ Y_{i}(s)+\\frac {I(X_{i}\\le s^{-};\\varepsilon _{i}\\neq k)\\hat {G}(s^{-})}{\\hat {G}(X_{i}^{-}\\wedge s^{-})} \\right ]$\\end{document}\u0176\u00b7k\u2217(s)=\u2211i=1N\u03beiwi\u00b7Yi(s)+I(Xi\u2264s\u2212;\u03b5i\u2260k)\u011c(s\u2212)\u011c(Xi\u2212\u2227s\u2212) and being , the derivative of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}^{*}_{\\cdot k}(s)$\\end{document}\u0176\u00b7k\u2217(s) with respect to wi results:\n\n(21)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\begin{aligned} \\frac{\\partial \\hat{Y}^{*}_{\\cdot k}(s)}{\\partial w_{i}}&= \\frac{\\partial \\left\\{ \\xi_{i} w_{i}\\cdot\\left[ Y_{i}(s)+\\frac{I(X_{i}\\le s^{-};\\varepsilon_{i}\\neq k)\\hat{G}(s^{-})}{\\hat{G}\\left(X_{i}^{-}\\wedge s^{-}\\right)} \\right]+ \\underset{j\\neq i}{\\sum} \\xi_{j} w_{j}\\cdot\\left[Y_{j}(s)+\\frac{I(X_{j}\\le s^{-};\\varepsilon_{j}\\neq k)\\hat{G}(s^{-})}{\\hat{G}\\left(X_{j}^{-}\\wedge s^{-}\\right)}\\right]\\right\\}}{\\partial w_{i}}=\\\\ & =\\xi_{i}Y_{i}(s)+\\xi_{i}\\frac{\\partial \\left[w_{i} \\frac{I(X_{i}\\le s^{-};\\varepsilon_{i}\\neq k) \\hat{G}(s^{-})}{\\hat{G}\\left(X_{i}^{-}\\wedge s^{-}\\right)}\\right]}{\\partial w_{i}} +\\frac{\\partial \\left[\\underset{j\\neq i}\\sum \\frac{\\xi_{j} w_{j} I(X_{j}\\le s^{-};\\varepsilon_{j}\\neq k)\\hat{G}(s^{-})}{\\hat{G}\\left(X_{j}^{-}\\wedge s^{-}\\right)}\\right]}{\\partial w_{i}}=\\\\ &=\\xi_{i}Y_{i}(s)+\\xi_{i}\\frac{I(X_{i}\\le s^{-};\\varepsilon_{i}\\neq k)\\hat{G}(s^{-})}{\\hat{G}\\left(X_{i}^{-}\\wedge s^{-}\\right)}+ \\sum_{j=1}^{N}\\xi_{j} w_{j} I(X_{j}\\le s^{-};\\varepsilon_{j}\\neq k)\\frac{\\partial}{\\partial w_{i}} \\left[\\frac{\\hat{G}(s^{-})}{\\hat{G}\\left(X_{j}^{-}\\wedge s^{-}\\right)} \\right]. \\end{aligned}  $$ \\end{document}\u2202\u0176\u00b7k\u2217(s)\u2202wi=\u2202\u03beiwi\u00b7Yi(s)+I(Xi\u2264s\u2212;\u03b5i\u2260k)\u011c(s\u2212)\u011cXi\u2212\u2227s\u2212+\u2211j\u2260i\u03bejwj\u00b7Yj(s)+I(Xj\u2264s\u2212;\u03b5j\u2260k)\u011c(s\u2212)\u011cXj\u2212\u2227s\u2212\u2202wi==\u03beiYi(s)+\u03bei\u2202wiI(Xi\u2264s\u2212;\u03b5i\u2260k)\u011c(s\u2212)\u011cXi\u2212\u2227s\u2212\u2202wi+\u2202\u2211j\u2260i\u03bejwjI(Xj\u2264s\u2212;\u03b5j\u2260k)\u011c(s\u2212)\u011cXj\u2212\u2227s\u2212\u2202wi==\u03beiYi(s)+\u03beiI(Xi\u2264s\u2212;\u03b5i\u2260k)\u011c(s\u2212)\u011cXi\u2212\u2227s\u2212+\u2211j=1N\u03bejwjI(Xj\u2264s\u2212;\u03b5j\u2260k)\u2202\u2202wi\u011c(s\u2212)\u011cXj\u2212\u2227s\u2212.\n\nPlease note that the last addendum accounts for the fact that \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {G}(t)$\\end{document}\u011c(t) is estimated using information of subject i. For v\u2264u: \n(22)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\begin{aligned} \\frac{\\partial}{\\partial w_{i}}\\left[ \\frac{\\hat{G}(u)}{\\hat{G}(v)}\\right]=\\,&\\frac{\\hat{G}(u){\\int_{0}^{u}} \\frac{d{N_{i}^{c}}(s)-\\hat{\\lambda}^{c}(s)Y_{i}(s)}{\\hat{Y}_{\\cdot}(s)}\\hat{G}(v)-\\hat{G}(v){\\int_{0}^{v}} \\frac{d{N_{i}^{c}}(s)-\\hat{\\lambda}^{c}(s)Y_{i}(s)}{\\hat{Y}_{\\cdot}(s)}\\hat{G}(u)}{\\hat{G}(v)^{2}}=\\\\ =\\,&\\frac{\\hat{G}(u)\\hat{G}(v)\\int_{v^{+}}^{u} \\frac{d{N_{i}^{c}}(s)-\\hat{\\lambda}^{c}(s)Y_{i}(s)}{\\hat{Y}_{\\cdot}(s)}}{\\hat{G}(v)^{2}} =\\frac{\\hat{G}(u)\\int_{v^{+}}^{u} \\frac{d{N_{i}^{c}}(s)-\\hat{\\lambda}^{c}(s)Y_{i}(s)}{\\hat{Y}_{\\cdot}(s)}}{\\hat{G}(v)} \\end{aligned}  $$ \\end{document}\u2202\u2202wi\u011c(u)\u011c(v)=\u011c(u)\u222b0udNic(s)\u2212\u03bb^c(s)Yi(s)\u0176\u00b7(s)\u011c(v)\u2212\u011c(v)\u222b0vdNic(s)\u2212\u03bb^c(s)Yi(s)\u0176\u00b7(s)\u011c(u)\u011c(v)2==\u011c(u)\u011c(v)\u222bv+udNic(s)\u2212\u03bb^c(s)Yi(s)\u0176\u00b7(s)\u011c(v)2=\u011c(u)\u222bv+udNic(s)\u2212\u03bb^c(s)Yi(s)\u0176\u00b7(s)\u011c(v)\n\nwhere the superscript c indicates the quantities related to the censoring process, i.e. \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}${N_{i}^{c}}(u)=I(X_{i}\\leq u,\\Delta _{i}=0)$\\end{document}Nic(u)=I(Xi\u2264u,\u0394i=0) is the indicator of censoring for subject i up to time u and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\lambda }^{c}(u)=\\hat {N}_{\\cdot }^{c}(du)/\\hat {Y}_{\\cdot }(u)$\\end{document}\u03bb^c(u)=N^\u00b7c(du)/\u0176\u00b7(u) the instantaneous hazard of censoring. The derivative of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {Y}^{*}_{\\cdot k}(u)$\\end{document}\u0176\u00b7k\u2217(u) becomes: \n(23)\\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document} $$ \\begin{aligned} & \\frac{\\partial \\hat{Y}^{*}_{\\cdot k}(s)}{\\partial w_{i}}=\\\\&Y_{i}(s)+ I(X_{i}\\le s^{-};\\varepsilon_{i}\\neq k) \\cdot\\frac{\\hat{G}(s^{-})}{\\hat{G}\\left(X_{i}^{-}\\wedge s^{-}\\right)} +\\sum_{j=1}^{N}\\xi_{j} w_{j} I(X_{j}\\le s^{-};\\varepsilon_{j}\\neq k)\\frac{\\hat{G}(s^{-})}{\\hat{G}\\left(X_{j}^{-}\\wedge s^{-}\\right)}\\left[\\int_{X_{j}}^{s^{-}} \\frac{{N_{i}^{c}}(du)-\\hat{\\lambda}^{c}(u)Y_{i}(u)}{\\hat{Y}_{\\cdot} (u)}\\right] \\end{aligned}  $$ \\end{document}\u2202\u0176\u00b7k\u2217(s)\u2202wi=Yi(s)+I(Xi\u2264s\u2212;\u03b5i\u2260k)\u00b7\u011c(s\u2212)\u011cXi\u2212\u2227s\u2212+\u2211j=1N\u03bejwjI(Xj\u2264s\u2212;\u03b5j\u2260k)\u011c(s\u2212)\u011cXj\u2212\u2227s\u2212\u222bXjs\u2212Nic(du)\u2212\u03bb^c(u)Yi(u)\u0176\u00b7(u)\n\nThus, the influence function of \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$\\hat {\\Lambda }^{*}_{k}(t)$\\end{document}\u039b^k\u2217(t) of the ith subject results: \n(24)\n\nwhere wj=1/\u03c0j. By defining \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}${M_{i}^{c}}(s,t)={\\int _{s}^{t}} \\frac {{N_{i}^{c}}(du)-\\hat {\\lambda }^{c}(u)Y_{i}(u)}{\\hat {Y}_{\\cdot } (u)}$\\end{document}Mic(s,t)=\u222bstNic(du)\u2212\u03bb^c(u)Yi(u)\u0176\u00b7(u) as the influence function of subject i on censoring, \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$v_{j}=\\frac {\\xi _{j}}{\\pi _{j}} \\sum _{l \\neq k}N_{\\textit {jl}}(s^{-})\\hat {G}(s^{-}|X_{j}^{-})$\\end{document}vj=\u03bej\u03c0j\u2211l\u2260kNjl(s\u2212)\u011c(s\u2212|Xj\u2212), and \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$M_{\\textit {ik}}(s)=\\left [N_{\\textit {ik}}(s)-\\hat {\\Lambda }_{k}^{*}(s)Y^{*}_{\\textit {ik}}(s)\\right ]/\\hat {Y}^{*}_{\\cdot k}(s)$\\end{document}Mik(s)=Nik(s)\u2212\u039b^k\u2217(s)Yik\u2217(s)/\u0176\u00b7k\u2217(s).\n\nThus it can be reduced as: \n"}