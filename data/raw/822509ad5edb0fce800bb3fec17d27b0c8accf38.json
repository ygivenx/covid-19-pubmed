{"title": "Financial volatility trading using a self-organising neural-fuzzy semantic network and option straddle-based approach", "body": "Volatility modeling and forecasting (Poon, 2005) is imperative to financial market investors. In finance and econometrics, volatility is defined as the intensity of the fluctuations in the expected return of an investment or the variations in the market's pricing of a financial asset. Financial volatility forecasts allow the prudent investors to adjust or hedge their investment portfolios to mitigate investment risk and to customize their trading strategies in anticipation of the forthcoming financial market movements.\n\nInvestment risk refers to an extensive set of factors or events that erodes the financial value of an investment (Poon, 2005) . This includes credit risk (i.e. loss due to a debtor's non-payment) and liquidity risk due to the market's small capitalization. Hence, financial volatility is one indication of investment risk and is often viewed as a risk metric (Holton, 2003) . Financial volatility forecasting is important as volatility is often used as a proxy to measure financial or market risk caused by the underlying uncertainties of the financial market movements (which can have significant positive or negative effects on the values of investment portfolios) due to a myriad of factors. These factors may include recessions, wars, structural changes in the economy, tax law changes, interest rate hikes, inflation pressures, investor anxiety and even changes in consumer preferences. Furthermore, when viewed as a measure of market uncertainty, financial volatility is a key input in many investment decisions and portfolio creations (Aizenman & Marion, 1999; Chan, Karceski, & Lakonishok, 1999) . The extensive body of research on volatility modeling and forecasting (Anderson, Bollerslev, & Lange, 1999; Blair, Poon, & Taylor, 2001; Engle, 2002; Hamid, 2004; Noh, Engle, & Kane, 1994; Poon & Granger, 2003) has reflected the importance of financial volatility to investment decision-making (Busse, 1999; Galeotti & Schiantarelli, 1994; Okuyama & Francis, 2006) , security valuation (De Santis, Gerard, & Hillion, 1997; Hsu, 2000) , risk management (Christoffersen & Diebold, 2000; Granger, 2002) as well as monetary policy making (Nasar, 1992) . Volatility is also a key component in the pricing of derivative securities such as equity options (Duan & Simonato, 2001; Figlewski, 1997; Hull & White, 1987; Noh et al., 1994) , where there has been an exponential growth in the trading volume in recent years due to the extensive use of derivatives instruments as hedging and risk management tools. In addition, national policy makers, financial regulators and central banks often relied on estimates of financial volatility to assess the effectiveness of regulatory measures on the financial markets (Poon & Granger, 2003) . Given its widespread importance, it is therefore not surprising that financial volatility has emerged as a key asset class in today's financial markets. That is, sophisticated investors can trade in financial instruments defined on market volatility. For example, the VIX index 1 (Chicago Board Options Exchange) introduced in 2003 by the Chicago Board Options Exchange (CBOE) is based on the short term volatilities of options issued on the S&P 500 index, which tracks the stock performances of 500 large-cap corporations trading on the US stock markets (i.e. NYSE and Nasdaq). The creation of the VIX volatility index allows a savvy investor to leverage on his estimates of the fluctuations of the financial market movements through the use of futures contracts to achieve investment profits during rising, falling and side-ways markets.\n\nHence, given the extensive applications of volatility forecasting, the research on financial volatility modeling and prediction has been the primary focus of academics and practitioners of financial econometrics over the years. Excellent reviews and research of the subject are reported in Knight and Stephen (2002) , Poon and Granger (2003) , Hans Franses and McAleer (2002) and Poon (2005) . In brief, there are three general notions (measures) of financial volatility in the literature, namely historical volatility, implied volatility and model-based volatility. Historical volatility (HV) is backward-looking and is generally computed from a time-series of the continuously compounded returns of the underlying security or asset. In this measure, the compounded investment return r c (t) of the underlying security is computed daily and it is defined as r c (t) = log (c(t)/c(t \u00c0 1)), where c(t) denotes the current closing valuation of the financial security and c(t \u00c0 1) refers to the price level of the previous trading day. This corresponds to the day-on-day change in the financial valuation of the underlying security. Subsequently, the volatility HV(t) for a trading day t is defined as the statistical deviation or weighted deviation of the returns time-series {r c (t \u00c0 n + 1) jn = 1,. . . ,N}, where N denotes the length of the historical price path considered in the computation of the volatility measure.\n\nImplied volatility (IV), on the other hand, is forward-looking as it is derived from the observed (traded) prices of the options issued on the underlying financial instrument. That is, as implied volatility is based on the current market prices of the options, it contains all the forward expectations of the investors about the likely future price path of the underlying security. The implied volatility of an option contract is defined as the financial volatility that produces the traded (market) price of the option based on a selected option pricing model. In practice, the black-scholes model (Black & Scholes, 1973) and its variants (Gencay & Gibson, 2007; Grace, 2000) are often used to price the options traded in the derivatives markets. Empirically, it has been observed that the computed IVs of the options issued on the same underlier and with the same time to maturity often exhibit a nonlinear relationship known as the volatility smile (Derman & Kani, 1994; Dupire, 1994) with respect to the different strike prices of the options. This is generally regarded as evidence that an underlier's implied financial volatility is not constant, but instead, depends on factors such as the price level of the underlying security and the exercise prices of the options. For these reasons, at-the-money (ATM) or nearly ATM options are often used as the reference entities to compute the implied volatilities in financial volatility modeling and prediction studies (Poon & Granger, 2003) .\n\nIn contrast to HV and IV, model-based volatility (MV) is often derived using the autoregressive conditional heteroskedasticity (ARCH) and generalized ARCH (GARCH) family of continuous time process models (Bollerslev, 1986; Engle, 1982) . Within the ARCH and GARCH frameworks, the objective is to model the continuously compounded investment returns time-series {r c (t)} of an underlying financial instrument using a predictable conditional mean model l(t) and a stochastic conditional variance model that defines the innovations e(t) of the returns time-series, i.e. r c (t) = l(t) + e(t), such that\n\na i r c \u00f0t \u00c0 i\u00de \u00f0autoregressive model\u00de e\u00f0t\u00de \u00bc r\u00f0t\u00dez\u00f0t\u00de \u00f0stochastic innovation model\u00de \u00f0 1\u00de\n\nwhere t denotes the current trading day; / is a constant; N 1 is the order of the regressive model; z(t) $ N(0, 1) is a Gaussian-distributed random variable; and the (conditional) variance r 2 (t) of the innovations of the time-series {r c (t)} is modeled as an autoregressive process of previous innovations and variances, i.e. r 2 \u00f0t\u00de \u00bc j \u00fe X N 2 i\u00bc1 b i e 2 \u00f0t \u00c0 i\u00de \u00fe X N 3 i\u00bc1 c i r 2 \u00f0t \u00c0 i\u00de \u00f0GARCH model\u00de \u00f02\u00de where j is a modeling constant; and {N 2 , N 3 } are the orders of the GARCH model. The coefficients {/, a i , j,b i , c i } of the modeling process defined in Eqs. (1) and (2) are generally obtained via maximum likelihood estimation. The time-varying model-based volatility MV(t) of the underlying financial asset is subsequently defined to be the identified conditional deviation r(t).\n\nOne of the most important stylized facts of financial volatility is the presence of volatility clustering or volatility persistency in historically observed data, i.e. high volatility is often followed by periods of high volatility and low volatility by periods of low volatility (Bollerslev & Engel, 1993) . This empirical observation about financial volatility has deep implications for volatility forecasting, and supports the notion that current and past values of volatility can be used to predict future volatility levels. In this paper, the use of a self-organising neural-fuzzy semantic network named the evolving fuzzy semantic memory (eFSM) model (Tung & Quek, 2008; Tung & Quek, 2010 ) that employs the notion of incremental sequential learning (Ratcliff, 1990) to model and forecast the volatility levels of the Hang Seng Index 2 (HSI) across a five-year period spanning 1 VIX is the ticker symbol for the Chicago Board Options Exchange (CBOE) Volatility Index, which shows the market's expectation of the 30-day volatility. VIX values greater than 30 are generally associated with a large amount of volatility as a result of investor fear or uncertainty, while values below 20 generally correspond to tranquil periods in the markets. 2 The Hang Seng Index (HSI) is a capitalization-weighted stock market index in the Hong Kong Stock Exchange (HKSE). It is used to record and monitor daily changes of the 43 largest companies of the Hong Kong stock market and is the main indicator of the overall market performance in Hong Kong. These 43 companies represent about 65% of capitalization on the HKSE. from 2002 to 2006 is investigated. The computed volatility forecasts are subsequently used to capitalize on the movements of the Hong Kong stock market by performing straddle trading 3 using an automated option trading system that is based on the moving-averages convergence/divergence (MACD) (Colby, 2002; Pring, 2002) principle. There are two primary motivations to this piece of work. They are:\n\n(1) to develop an intelligent trading system endowed with humanlike information processing capabilities and a logical reasoning schema to support the decision-making process of a human trader in performing financial volatility trading, and (2) to address the lagging (reactive) nature of the MACD trading rule and to enhance its timeliness in spotting trading opportunities by introducing forward-looking (forecasting) capability to the computation of the underlying trend signals. These are explained as follows.\n\nWhen employing technical analysis for security trading, a human trader typically analyzes the historical financial (price) data that is available and attempts to identify the salient/recurring patterns that correlate to profitable trades. Such information is then used to detect future trading opportunities, constituting the human approach to financial trend modeling and judgemental forecasting (Lawrence & O'Connor, 1992) . However, current technical volatility modeling and forecasting methods (a comprehensive review can be found in Section 3 of Poon & Granger (2003) ) are often based on statistical or continuous time finance theories that are generally mathematically convoluted, which erodes their intuitiveness to a human investor. The proposed use of eFSM as a semantic neural-fuzzy based approach to the modeling and projection of financial volatility trends, on the other hand, bridges the knowledge chasm as it enables a human investor to examine the inherent trend information extracted from the historical observations via highly interpretable IF-THEN fuzzy rules. Moreover, since high frequency financial data is inherently noisy, eFSM can mitigate the effects of the noise artifacts on the computed volatility predictions as it employs Gaussian-shaped fuzzy sets to model (generalize) the characteristics of the past volatility fluctuations. This helps to preserve the salient patterns and predictable trends of the financial volatility time-series. Furthermore, the self-organising eFSM can spot financial trends in huge amounts of data that may not be immediately apparent to a human trader.\n\nIn addition, empirical studies have sufficiently shown that financial (market) volatility is time-varying and non-stationary (Mele & Fornari, 2000) . eFSM addresses this issue by employing a set of brain-inspired learning mechanisms that functionally mimics the information processing of the human hippocampus, a brain construct located in the medial temporal lobe of the human brain that is vital for the acquisition and continuous on-going organization of the human semantic memories (Kandel, Kupfermann, & Iversen, 2000) . This enables eFSM to construct a more robust and adaptive forecasting model in contrast to many existing neuralfuzzy modeling techniques. Furthermore, eFSM employs the compositional-rule-of-inference (CRI) schema (Zadeh, 1994) , a logical fuzzy reasoning scheme that mimics the human reasoning process, to define its computations. From a human trader's perspective, this provides added credence to the computed volatility projections. Lastly, as the MACD trading rule employs historical time-indexed data to obtain the trending signals, the resultant trading decisions computed from these signals are inevitably time-delayed. Therefore, the use of eFSM as a model to forecast the future HSI volatility levels and the subsequent use of such forward projections in the computation of the MACD trading decisions help to address the lagging nature of the MACD trading rule. This paper is organized as follows. Section 2 briefly presents the eFSM neural-fuzzy semantic memory model and its learning mechanisms. Section 3 then introduces the technical concepts behind the trading of option straddles and the use of the MACD principle for financial volatility trading. Following that, Section 4 describes the HSI data set used by eFSM to model and forecast the volatility levels of the Hong Kong stock market. Subsequently, the trading results based on the use of these forecasts for the capitalization of the Hong Kong financial market uncertainties with a MACD-driven straddle trading system are presented and analyzed. Section 5 concludes the paper.\n\nThe evolving fuzzy semantic memory (eFSM) model (Tung & Quek, 2008 employed in this work is essentially a neuralfuzzy system (Nauck, Klawonn, & Kruse, 1997 ) that consists of five layers of computing nodes as shown in Fig. 1 . Neural-fuzzy (or neuro-fuzzy) systems are the realizations of the functionality of fuzzy systems using neural networks, and they are regarded as universal data-mining tools that possess a strong capability to derive the intrinsic relationships between the observed numerical inputs and outputs of the training data presented (Lin & Lee, 1996) . The main advantage of a neural-fuzzy system is its ability to model the characteristics or solutions of a given problem using a set of IF-THEN fuzzy rules instead of low-level complex mathematical expressions. From Fig. 1 , the structure of the eFSM model employed for the modeling and projection of the Hang Seng Index volatility implements the Mamdani fuzzy model (Mamdani, 1977) , a system of knowledge representation that is characterized by a set of linguistic IF-THEN fuzzy rules R k (k = 1,. . ., K) of the form described by Eq. (3). \n\nwhere X = [x 1 , . . ., x i , . . . , x I ] T and Y = [y 1 , . . ., y m , . . . , y M ] T denotes the inputs and outputs of eFSM respectively; I is the number of inputs; M is the number of outputs; IL \u00f0i;j i \u00dek (j i = 1,. . ., J i , k = 1,. . ., K) denotes the j i th fuzzy set of input x i in rule R k ; OL \u00f0lm;m\u00dek (l m = 1,. . ., L m ) is the l m th fuzzy set of output y m in the consequent of R k ; K is the number of fuzzy rules; and J i and L m is the number of fuzzy sets of x i and y m , respectively. In eFSM, K, J i and L m varied according to the changes in the underlying data generating process to be modeled. In this paper, the underlying process refers to the Hong Kong financial market uncertainties that give rise to the volatilities of the Hang Seng Index. The computing structure of the eFSM model evolves dynamically with the arrival of each training data presented. The learning mechanisms of eFSM are designed to functionally emulate the information processing capabilities of the human hippocampus (see Section 2.1). Prior to the start of the learning process, there are no computing nodes in layers 2, 3 and 4 of eFSM (i.e. no fuzzy rules). New fuzzy rules are dynamically added and old rules that no longer describe the current data characteristics observed are removed during the learning phase. Together, the set of resultant fuzzy rules describes the salient associative mappings between the inputs and outputs of the underlying process being modeled. The form of knowledge representation described in Eq. (3) is also known as linguistic fuzzy modeling (LFM) (Casillas, Cordn, Herrera, & Magdalena, 2003) , and best approximates the semantic knowledge (e.g., long-established knowledge about objects, facts, and word meanings etc.) representation embodied in the human mind (Toth, 1997) . With respect to the task of financial volatility modeling and forecasting, this knowledge representation scheme enhances the interpretability of the eFSM computing structure (by defining the neural connectionisms of eFSM as human comprehensible IF-THEN fuzzy rules) and helps a human trader to develop a better understanding of the underlying characteristics of the observed volatility of the Hang Seng Index movements. This directly enables the human investor to analyze and study the volatility trends in the Hong Kong stock market and to make better and informed trading decisions to maximize his investment profits.\n\nOver the last decade, neural-fuzzy systems have been successfully deployed to solve many modeling problems (Chong, Quek, & Loh, 2009; Juang & Lin, 2001; Quek, Tan, & Sagar, 2001; Quek, Wandy, & Ng, 2010; Talei, Chua, & Quek, 2010; Tan, Quek, Ng, & Ravzi, 2008; Tong, Wang, & Tang, 2000; Tung, Quek, & Cheng, 2004; Wai & Lin, 1998) . However, the complex and dynamic nature of real-world applications demanded that neural-fuzzy systems be able to adapt their structures, parameters and ultimately evolve their intelligence to continuously address the non-stationary characteristics of the underlying data generating processes. The usefulness of existing neural-fuzzy systems such as ANFIS , POPFNN (Ang & Quek, 2005; Quek & Zhou, 1996) , HyFIS (Kim & Kasabov, 1999) , EFuNN (Kasabov, 2001) , SOFNNGA (Leng, McGinnity, & Prasad, 2006) , RPOP-TVR (Wong, Cho, & Quek, 2009) , FASCOM (Goh, Lim, & Quek, 2009 ) and FITSK (Quah & Quek, 2006) are, however, generally constrained to static environments as their training/rule generation procedures unrealistically assumed that the characteristics of the underlying data generating processes being modeled do not change with time. Hence, these systems often employed batched 4 or pseudo-incremental 5 learning approaches to construct (i.e. identify and tune) their respective fuzzy rule (knowledge) bases and are ill-equipped for the modeling of more complex time-varying processes. These neural-fuzzy systems lacked the capability to acquire any new information that emerges after the training of the embedded fuzzy model has been completed. Attempts to adapt to the changing underlying process generally require re-training to rebuild the entire neural-fuzzy system since incremental learning of the new patterns (information) will modify the trained fuzzy model in such a way that the originally learned but possibly still valid knowledge is forgotten or replaced. That is, the newly emerging information ''catastrophically\" erased the fuzzy model's memory of the previously learned knowledge (French, 2003) , and the resultant phenomenon of degraded computing performances is known as the stability-plasticity dilemma (Grossberg, 1982) .\n\nIn contrast, humans are often observed to learn new things prolifically and spontaneously without forgetting the old information (McClelland, McNaughton, & O'Reilly, 1995) . This phenomenon is referred to as sequential learning in machine learning research (McCloskey & Cohen, 1989) . Hence, the learning mechanisms of eFSM are modeled after certain information processing capabilities of the human brain (specifically the hippocampus) to enable it to robustly organize the knowledge extracted from the data observations presented. Particularly, the human hippocampal formation is capable of a neurogenesis process (Kempermann, Wiskott, & Gage, 2004 ) that has been regarded as the primary mechanism used to 4 In batch learning, it is assumed that all the training data has been collected and is available to the training process. Training generally involves cycling through the collected data a number of epochs to separately identify and tune a fuzzy model that provides a fitting description to the characteristics of the observed training data. 5 Pseudo-incremental learning refers to the arrival of the training data one at a time. The training process generally responds by applying the rule generation procedure to the current training data prior to the arrival of the next data sample. However, a copy of the observed data is usually kept for the parameter adaptation phase to optimize the parameters of the fuzzy model or to perform rule pruning to identify a compact rule-base.\n\nresolve the learning stability-plasticity dilemma in the human brain (Wiskott, Rasch, & Kempermann, 2006) during the acquisition of the human semantic memories 6 (Eichenbaum, 2004) . Furthermore, empirical evidences have established that the human hippocampus and its surrounding cortices are directly involved in the detection of input novelty and associative novelty to facilitate the recognition of information (Brown & Aggleton, 2001; Nyberg, 2005) , which plays a critical role in updating the human representation of the changing world (O'Keefe & Nadel, 1978) . These information processing capabilities are generally ascribed to two complementary functions of the human hippocampus; namely, as a recall comparator (Vinogradova, 2001) and as a novelty/familiarity detector (Clark & Gronlund, 1996) . Therefore, to computationally mimic facets of how the human hippocampus performs the sequential learning of information, the rule-generating procedure of the eFSM model is designed based on its recall comparator as well as the novelty/familiarity detection principles. Details of this rulegenerating procedure are reported in Tung and Quek (2008) .\n\nIn addition, neuroscientists have also established at the neurological level that the human hippocampus maintains its acquired knowledge using two primary synaptic mechanisms: i.e. long-term potentiation (LTP) (Whitlock, Heynen, Shuler, & Bear, 2006) and long-term depression (LTD) (Bear & Abraham, 1996) . LTP is the strengthening of the synaptic connection between two repeatedly intensely excited neurons and is responsible for the learning/reinforcement of memory traces in the hippocampal formation. LTD, on the other hand, is the weakening of the synaptic connection between two neurons due to persistent weak excitations. Thus, it is regarded as the main mechanism of 'forgetting'. Hence, the human hippocampus possesses highly evolved and elegant mechanisms to maintain up-to-date memory traces. Computationally, the eFSM model mimics these neural mechanisms via the use of fuzzy rule potentials with the LTP and LTD concepts (see Section 2.3) to construct a set of evolving IF-THEN Mamdani fuzzy rules to model non-stationary data generating processes.\n\nThe following describes the computational process employed by the eFSM model. Each layer performs a specific function with respect to the CRI reasoning schema.\n\nLayer 1 (Input layer): Each node represents an input variable to eFSM. The set of layer 1 nodes IV i (i = 1,. . . , I) acts as singleton fuzzifiers and directly transmits the input vector X to layer 2. This is described in Eq. (4).\n\nwhere IV i (x i ) denotes the output of node IV i given the input x i .\n\nLayer 2 (Antecedent layer): This layer encapsulates the input fuzzy sets in the antecedents of the fuzzy rules generated by the eFSM model (see Eq.\n\n(3)). The fuzzy sets (representations) denote the generalized concepts elicited from the training data. In this paper, Gaussian-shaped fuzzy sets are used. The membership value IL i;j i \u00f0x i \u00de of input x i to the j i th fuzzy set of IV i (denoted as IL i;j i ) is given by Eq. (5).\n\nwhere l i;j i denotes the Gaussian membership function of IL i;j i ; and \u00f0q i;j i ; h i;j i \u00de are the center and standard deviation of the Gaussian membership function respectively. Layer 3 (Rule layer): This is the rule-base of the eFSM model which contains the Mamdani-typed fuzzy rules dynamically de-rived from the training data. The firing of a fuzzy rule R k is computed as Eq. (6).\n\nwhere l \u00f0i;j i \u00dek denotes the Gaussian membership function of the input fuzzy set (representation) IL i;j i that is an antecedent of R k . Layer 4 (Consequent layer): This layer consists of the output fuzzy sets (representations) that formed the consequents of the fuzzy rules in eFSM. Each output fuzzy set OL lm;m is represented as a Gaussian membership function l lm;m defined by center q lm;m and standard deviation h lm;m . As more than one fuzzy rule may have the same expected consequent, the activation of an output fuzzy set OL lm;m is defined as Eq. (7).\n\nwhere R lm;m denotes the set of fuzzy rules in eFSM that shares the same consequent OL lm;m . Layer 5 (Output layer): Each node in this layer corresponds to an output variable of the eFSM model. The function of an output node OV m (m = 1,. . . , M) is to combine the activations and inferred results of all its output fuzzy sets in layer 4 to produce a response y m (X) to the input vector X. This is described in Eq. (8).\n\nwhere OL lm;m \u00f0R lm;m \u00de \u00bc OL lm ;m \u00f0R lm;m \u00de= P Lm lm\u00bc1 OL lm ;m \u00f0R lm;m \u00de; and CO lm;m \u00f0l lm;m ; X\u00de is the inferred consequent output of the fuzzy set OL lm;m (represented by l lm ;m ) due to the activation of the eFSM rule-base by input X. The inferred consequent outputs in eFSM are essentially computed based on a fusion of the Mamdani as well as the Takagi-Sugeno (TS) (Takagi & Sugeno, 1985) fuzzy models (Tung & Quek, 2009 ). This ensures that when compared with existing Mamdanibased neural-fuzzy systems, the eFSM model is able to deliver a better performance in time-series modeling and prediction tasks. Subsequently, the computed output y m (X) of OV m is the weighted sum of the set of inferred consequent outputs from all the output fuzzy sets of OV m . Following that, the output of eFSM to the input X is defined as Y = [y 1 (X), . . . , y m (X), . . ., y M (X)] T . Although the eFSM model employs a set of learning mechanisms that is inspired by the human hippocampus, its computing structure remains similar to that of the well-established generic self-organising fuzzy neural network (GenSoFNN) (Tung & Quek, 2002) . Hence, the procedure of mapping the CRI schema onto eFSM to define its computational process described in Eqs. (4)-(8) shall not be repeated here. The interested reader may refer to Tung et al. (2004) on how such mapping is performed. Similar to GenS-oFNN, eFSM may also take on other forms of fuzzy reasoning schema such as truth-value restriction (Mantaras, 1990) , approximate analogical reasoning (Turksen & Zhong, 1990) and yager reasoning (Yager, Keller, & Tahani, 1992) . The reader may refer to Tung and Quek (2005) , Tung and Quek (2006) and Oentaryo, Pasquier and Quek (2008) for more details.\n\nThe backward connections (dashed arrows in Fig. 1 ) from layer 5 to layer 3 via layer 4 are activated during the structural learning of the eFSM model (i.e. identification of the fuzzy rules) and the computation of the fuzzy rule potentials (see Section 2.3) based on the observed training pattern pair (X, D), where D is the defined (target) output vector (or experience) in respond to the input stimulus X. This is described as follows.\n\nLayer 5: The set of layer 5 nodes OV m , m = 1,. . . , M, directly transmits the defined output vector D to layer 4. That is (see Eq. (9)),\n\nwhere d m is the mth target output for eFSM with respect to the input X. Layer 4: During structural learning or computation of the fuzzy rule potentials, layer 4 nodes perform an operation similar to the layer 2 nodes. That is, the membership value OL lm;m \u00f0d m \u00de of desired output d m to the l m th fuzzy set of OV m is given by Eq. (10).\n\nwhere l lm;m denotes the Gaussian membership function of OL lm ;m that is defined by center q lm ;m and standard deviation h lm;m .\n\nLayer 3: The backward activation of a fuzzy rule R k is defined as Eq. (11).\n\nwhere l \u00f0lm ;m\u00dek denotes the membership function of the output fuzzy set OL lm;m that is a consequent of R k .\n\nIn the eFSM model, the addition of a new fuzzy rule is governed by its rule-generating procedure that is derived from the observed functions of the human hippocampus as a recall comparator and novelty/familiarity detector. This resolves the stability-plasticity dilemma of eFSM as a knowledge learning system. However, obsolete fuzzy rules that no longer describe the observed data characteristics due to changes in the underlying data generating process have to be pruned from eFSM in order to maintain a compact and current rule (knowledge) base. This is achieved via the use of fuzzy rule potentials and the LTP and LTD concepts introduced in Section 2.1. The potential P k of a fuzzy rule R k in eFSM defines its importance/influence in the entire rule (knowledge) base of the system. Hence, a fuzzy rule with a high potential is significant in describing or generalizing the characteristics of a large chunk of recently encountered training patterns. Each rule in eFSM has a fuzzy rule potential that is continuously computed based on the LTP and LTD principles. The potential P new of a newly created fuzzy rule is defined as unity, and P k is updated based on the current training data pair (X(t), D(t)) using Eq. (12).\n\nwhere P k (t) is the potential of rule R k prior to the presentation of the training pair (X(t), D(t)); and R k (X(t)) and R back k \u00f0D\u00f0t\u00de\u00de are as defined in Eqs. (6) and (11), respectively. Hence, the significance (potential) of the associativity of a fuzzy rule in eFSM is enhanced or reinforced if its input conditions and expected consequents are similar to the information expressed in the training pair (X(t), D(t)). This functionally mimics the LTP mechanism observed in the human hippocampus.\n\nIn a changing environment, the training data used to construct the fuzzy rules is only temporally relevant. Existing fuzzy rules in the eFSM model may become obsolete and no longer reflect the current knowledge as the dynamics of the underlying data generating process changes. Hence, a forgetting mechanism is employed to systematically remove the unwanted rules (memory associations) from eFSM. This reduces the complexity of the fuzzy rulebase and maintains a set of up-to-date fuzzy rules that describes the current characteristics of the underlying process being modeled. Forgetting is simulated by reducing the potentials of the fuzzy rules according to their current values. This is described in Eq. (13).\n\nwhere k is the forgetting rate. This generates exponential forgetting and results in a decay of the significance of a fuzzy rule R k in eFSM. Rule R k is removed from the rule-base of eFSM if its potential falls below a fraction of that assigned for a newly created fuzzy rule,\n\ni.e. P k (t + 1) < tP new . In this paper, t and k are pre-defined as 0.25 and 0.99 respectively. Combining Eqs. (12) and (13), the overall potential of a fuzzy rule R k in eFSM is defined as Eq. (14).\n\nHence, if a fuzzy rule is deemed important, its LTP component will be significant and contributes to a high rule potential. This eventually keeps the fuzzy rule within the rule-base of eFSM. On the other hand, if a fuzzy rule has become insignificant due to changes in the underlying process, then LTD will be dominant in the computation of its rule potential. This subsequently results in a low fuzzy rule potential and the rule is removed if its potential falls below the pre-determined threshold tP new .\n\nThis section introduces the technical concepts behind option straddles and the moving-averages convergence/divergence (MACD) trading principle, and describes how they are used for financial volatility trading to capitalize on the uncertainties in the Hong Kong stock market.\n\nAn option is a contract between two parties -a buyer (holder of the option) and a seller (writer of the option) -that gives the buyer of the traded option the right, but not the obligation, to purchase or sell an underlying physical or financial asset at a future date and at a pre-agreed price. Options provide a means to manage financial risks and are playing an increasingly important role in modern financial markets (Chance, 2004) . From a financial perspective, having the right to buy or sell an asset without the obligation to complete the transaction has economic value. Therefore, options are traded as an asset in the financial markets. Options belong to a class of financial products generally referred to as derivative securities whose returns are derived from those of other financial instruments, in this case, the underlying physical or financial assets for which the options are issued (Boyle & Boyle, 2001) . Options are traded openly on derivative markets such as the Chicago Board Options Exchange and the Chicago Mercantile Exchange or overthe-counter privately between two parties. In the option markets, the price of a traded option depends on several factors. These include the price of the underlier (which determines the intrinsic value of the option), time to maturity of the option contract (which influences its time value), market volatility of the underlying asset, the current risk-free interest rate, the strike (exercise) price of the option and the type of option contract (i.e. American or European contract). In this paper, the options issued on the Hang Seng Index are European contracts and all future discussions are based on such European options.\n\nThe price dynamics of a Call (right to buy) and Put (right to sell) option are illustrated in Fig. 2 . In addition, the intrinsic value and the profit/loss (P/L) functions are shown together with the respective option prices to indicate the lower-bound valuations and the returns of investment of the two options with respect to the changing underlying asset price S 0 . For an at-the-money (ATM) Call option, a denotes the market (purchase) price of the option. Hence, a trader stands to lose at most a capital equivalent to a should the option expires at-the-money or out-of-the-money (OTM); i.e. S T 6 X, where S T is the price of the underlier at the time the option expires. However, if the price of the underlier increases above the exercise (strike) price of the Call option, the option will become in-the-money (ITM). If the Call option expires as in-the-money, its value is derived from the difference of the underlier price and the strike price; i.e. C T = S T \u00c0 X, where C T is the value of the Call option at expiration. Hence, the overall profit/loss (P/L) to a trader for investing in the Call option is computed as P/L = max (0, S T \u00c0 X) \u00c0 a. This is reflected as the P/L function in Fig. 2(a) . The price dynamics, intrinsic value and profit/loss functions for a Put option are analyzed in a similar way. From Fig. 2(b) , the label b denotes the capital invested in buying a Put option that is at-the-money. For a Put option, as the price of the underlier decreases, the value of the option increases and vice versa. When the price of the underlying asset is zero, the maximum theoretical price of a Put option is X (i.e. no investor will pay more to receive a lesser payout). The profit/loss to an investor for investing in a Put option is determined by P/L = max (0, X \u00c0 S T ) \u00c0 b. Hence, a trader loses at most the capital of b if the ATM Put option that he has bought expires with no value (i.e. max (0,X \u00c0 S T ) = 0jX 6 S T ). On the other hand, he will breakeven on his investment if the Put option expires with a value of b (i.e. {b = X \u00c0 S T jS T < X}). When the value of the Put option exceeds b, a profit is made on the investment.\n\nIn the derivatives markets, a straddle is an option trading strategy with which an investor simultaneously holds a position in both a Call and a Put option with the same strike price and expiration date. Fig. 3 depicts the expected profit/loss to a trader who invests in an ATM straddle with respect to the changing underlying asset price. 7 The cost of the Call, Put and resultant straddle are denoted as a, b and c, respectively. Straddles are a good strategy to pursue if an investor believes that an underlier's price will move significantly (i.e. high price volatility), but is unsure as to in which direction the price will move. As shown in Fig. 3 , the underlying asset price must move significantly if the investor is to make a profit from buying (longing) the ATM straddle. If there is only a small movement in the underlier's price occurring in either direction (i.e. low price volatility), the investor will experience a loss as the value of the straddle is less than the capital outlay of c to purchase it. The investment on the straddle is said to break-even when the value of the straddle equals to its acquisition price c = a + b. On the other hand, the reverse is true for selling (shorting) the ATM straddle. That is, a trader will suffer a loss if he sells a straddle and the underlier's price subsequently experienced high volatility or encountered a large price movement in either direction. A profit is possible only if the price of the underlying asset does not deviate too far from the strike price of the straddle sold (i.e. low price volatility). Hence, an intelligent straddle trading system is proposed in this paper to capitalize on the financial volatility of the Hong Kong stock market. Such a trading system will long (short) a straddle defined on the 7 It is assumed here that a Put option costs more than a Call option. This could be due to a bearish market where the price of the underlying asset is expected to fall. The reverse may be true for a bullish market where the underlier's price is expected to rise. Nevertheless, the technicalities of straddle trading outlined here apply for both scenarios.\n\nHang Seng Index when high (low) volatility of the index movement is expected.\n\nThe moving-averages convergence/divergence (MACD) technique is a momentum oscillator (Appel, 1985; Colby, 2002) employed to perform technical analysis on financial time-series to predict trend changes for security trading. The primary mechanism of MACD is to use moving averages (which are lagging indicators) to track the movements in a financial data time-series such as a stock market index or the price of a financial asset. The use of moving averages attenuates or smoothes the spurious oscillations (rapid reversals of trends) and helps to identify the general movements of a time-series. Commonly, MACD is defined as the difference (see Eq. (15)) between the 12-days exponential moving average (i.e. EMA 12 ) and the 26-days exponential moving average (EMA 26 ) of a time-series, although other time periods may also be used. That is,\n\nand the exponential moving average (EMA) of a price/index data series P is computed as Eq. (16):\n\nwhere EMA n (t) is the current n-days EMA of the data series P; EMA n (t \u00c0 1) is the previously computed EMA; p(t) is the current observed value of P; and k = 2/(1 + n) is the smoothing constant. EMA 12 and EMA 26 are also popularly known as the fast and slow signals of the MACD trading rule, as the former tracks a shorter historical time frame and is therefore more responsive to recent movements of the data series than the latter. Hence, a more generic definition is MACD = EMA Fast \u00c0 EMA Slow . Fig. 4 depicts the fast and slow EMA for the stock price of Merrill Lynch Co. from 26 August to 22 November 1999. In the top half of the figure, the fast EMA (EMA 12 ) for the stock price of Merrill Lynch Co. is shown as the solid line, while the slow EMA (EMA 26 ) is denoted by the dashed line. In Fig. 4 , the vertical bars denote the daily trading ranges of the stock price of Merrill Lynch Co. and the left and right ridges on the bars reflect the opening and closing stock prices, respectively.\n\nThe daily closing stock prices are used to compute the 12-and 26-days EMA that are overlaid on the price plot. As one can observe from the figure, both the fast and slow EMA are lagging indicators as the EMA signals captured the trend reversals much later after the direction of the stock price of Merrill Lynch Co. has changed. From Eq. (15), MACD tracks the difference between the fast and slow EMA. MACD is positive when EMA 12 is above EMA 26 and vice versa. The MACD for the stock price of Merrill Lynch Co. is represented as a thick solid line in the lower half of Fig. 4 . A crossover between the two EMA signals occurs when one rises over (falls under) the other. This is reflected by the three instances when the MACD signal cuts the zero reference line. MACD is often referred to as a momentum oscillator as the MACD signal oscillates above and below the zero reference line, and an increasing difference between the two EMA signals reflects a faster rate-of-change of one signal over the other. Hence, if the fast signal (EMA 12 ) is rising quicker than the slow signal (EMA 26 ), a positive (bullish) momentum is captured by computing the MACD. Conversely, if the fast signal is falling more swiftly than the slow signal, a negative (bearish) momentum is observed.\n\nWith a technical understanding of the MACD principle, one can construct an autonomous trading system to buy/sell an asset by identifying the crossover points between the fast and slow EMA. Hence, such a trading system would recommend a buy if EMA 12 rises above EMA 26 or sell if the reverse happens. However, the lagging nature of the two EMA signals often causes the crossover points to be detected some time after the trend reversals have occurred. Since the objective for constructing an autonomous trading system is to assist a human trader to maximize the possibility of profitable trades by using and analyzing market information to determine a trading position in anticipation of the price/trend changes (Cheng, Quek, & Mah, 2007; Guo, 2001) , the delayed trading signals from the MACD trading rule are not very useful in this case.\n\nIn addition, the MACD trading rule with the zero reference line as a trigger is also susceptible to whipsaws when the MACD signal oscillates rapidly around the reference line. This generates false or insignificant trading signals and incurs unnecessary trading costs. Hence, the 9-days EMA of the MACD signal is often used as the trigger line for the MACD trading rule as it attenuates the oscillations and smoothes the MACD signal. The EMA 9 of the MACD signal (i.e. MACD_EMA 9 ) is shown as the thin solid line in the bottom half of Fig. 4 . The MACD histogram is depicted as the bar plot and illustrates the differences between the MACD signal and its EMA 9 trigger line. This formulation of the MACD trading rule is often referred to as MACD (12, 26, 9) , where the respective historical time frames for the fast and slow EMA signals as well as the trigger for the MACD signal are clearly specified. With MACD (12, 26, 9) , a buy (sell) signal is generated whenever the MACD signal crosses above (falls below) its EMA 9 trigger line. As observed from Fig. 4 , the trading signals generated by MACD (12, 26, 9) are much closer to the lows and highs of the stock price plot. Empirical studies have further validated and confirmed the shorter delays of the trading signals generated by such a process (Elder, 1993; Murphy, 1996) .\n\nIn this paper, the MACD principle described above is employed in an intelligent straddle trading system to perform financial volatility trading so as to capitalize on the uncertainties of the Hong Kong stock market movements. The proposed straddle trading system is part of a trading framework modeled after the work of Moody and his colleagues (Moody & Saffell, 2001; Moody, Wu, Liao, & Saffell, 1998) , where a technical analysis approach has been applied for security trading and portfolio optimization. The straddle trading framework is depicted as Fig. 5 .\n\nAt the core of this trading framework is the proposed straddle trading system that operates on the known (observed) values of the input financial data series (in this case the financial volatility measures of the Hong Kong stock market) to derive the trading decisions for the buying and selling of the option straddles issued on the underlying Hang Seng Index (HSI). The HSI is the main indicator of the stock market performance in Hong Kong and its fluctuations therefore served as a proxy to the financial volatility of the Hong Kong stock market. The performance of the straddle trading system is subsequently evaluated by analyzing the investment returns r(t) from the straddle trades that were performed, which eventually defined the overall financial profit or loss R achieved by the system that is inclusive of the trading costs d incurred.\n\nSpecifically, the straddle trading system in Fig. 5 consists of two individual modules: the volatility projection module (VPM) and the trade decision module (TDM). As described earlier, the MACD trading rule employs the notion of moving averages that subsequently results in the generation of delayed trading signals. In order to address this inherent limitation of the MACD trading rule for the proposed straddle trading system, the predicted future values of the volatility measure of HSI are employed in the computation of the fast and slow EMA signals. Let Y = {y(t), y(t \u00c0 1), y(t \u00c0 2), . . .} denotes the time-ordered sequence of the financial volatility measures (i.e. historical, implied or model-based volatilities) characterizing the movements of the observed Hang Seng Index up to the current time t. Since Y is a regularly-sampled time-series with no missing value, the prediction of the immediate future value of Y (i.e. y(t + 1)) given the observed historical values of the time-series (i.e. y(t), y(t \u00c0 1), y(t \u00c0 2), . . .) can be formulated as an autoregressive problem f as shown in Eq. (17).\n\ny\u00f0t \u00fe 1\u00de \u00bc f \u00f0y\u00f0t\u00de; y\u00f0t \u00c0 1\u00de; . . . ; y\u00f0t \u00c0 n \u00fe 1\u00de\u00de\n\nwhere\u0177\u00f0t \u00fe 1\u00de denotes the predicted immediate future value of the time-series Y; and n is the modeling horizon or embedding dimension (Packard, Crutchfield, Farmer, & Shaw, 1980; Vitrano & Povinelli, 2001 ) that defines the number of past values and the delays to be used for the prediction. The prediction objective is therefore to minimize the error (difference) between\u0177\u00f0t \u00fe 1\u00de and the subsequently observed actual time-series value y(t + 1). In financial time-series prediction or financial forecasting, the autoregressive problem f as shown in Eq. (17) has been optimized via various techniques (e.g. statistical regression, stochastic regression, neural networks, fuzzy systems, support vector machines and evolutionary computations) for stock price modeling and prediction (Ang & Quek, 2006; Saad, Prokhorov, & Wunsch, 1998) , forecasting of financial variables (Noh et al., 1994; Refenes, Burgess, & Bentz, 1997) , equity returns (Apte & Hong, 1994; Kuan & Liu, 1995) and stock market indices (Chen, Leung, & Daouk, 2003; Yang & Yang, 2003) , as well as the optimization of portfolio composition and trading strategy (Moody & Saffell, 2001) . In this paper, the eFSM model that employs a set of human hippocampal-inspired learning mechanisms is used as a forecasting system to predict the future volatility measure of the Hang Seng Index. The volatility forecasts, when used in the computations of the fast and slow moving averages of the corresponding HSI volatility time-series, will enable the MACD trading rule to generate forward-looking trading signals. That is, the MACD trading rule will make a recommendation to buy (short-sell) an ATM straddle in order to profit from its increased (decreased) valuation whenever high (low) volatility in the Hong Kong stock market is expected. This approach directly addresses the problem of delayed trading signals inherent in the original formulation of the MACD trading rule. The predicted future volatility level\u0177\u00f0t \u00fe 1\u00de of the HSI is subsequently forwarded to the trade decision module (TDM) of the proposed straddle trading system (Fig. 5) to compute the trading decision TD(t) that is defined as Eq. (18) Hence, on any trading day t, the proposed trading system can issue a sell, buy or no trading recommendation to a human trader. For simplicity, in this paper, the trading system is allowed to have at most one open trading position. That is, the trading system may have short-sold an ATM straddle when the HSI volatility is expected to be low or bought an ATM straddle if the HSI volatility is expected to increase. Otherwise, the trading system would be in a neutral position with no exposure to the fluctuations of the Hong Kong stock market. The status (focus) of the proposed trading system on trading day t is denoted by F(t) such that On the last trading day (i.e. end of the simulation/trading period), the trading system will close any existing open position where F(t \u00c0 1) 2 {\u00c01, 1} to return to a neutral position (i.e. F(t) = 0) and computes the profit/loss (return r s (t)) on the last straddle trade as well as the overall profit/loss R for the entire trading (simulation) period. To account for the profit/loss r s (t) of trading an option straddle s, the trading system needs to monitor the initial and final economic values of the straddle that was traded. Let V s,0 denotes the initial value of the ATM straddle s when the trading system first bought or sold it, and V s,1 denotes the final value of the straddle s when the trading system closes its position on it (i.e. reversing its open position). The profit/loss r s (t) of trading a straddle s is computed only when the trading system returns to a neutral trading position from a short-sold or longed position as shown in Fig. 7 . Computationally, the profit/loss or return r s (t) for a straddle trade s performed by the proposed trading system is defined by \n\nBuy ATM straddle at least one month from expiration. Set ( ) 1.\n\nShort-sell ATM straddle at least one month from expiration. Set ( ) 1. Eq. (20) and the overall profit/loss R for the trading period is defined by Eq. (21) respectively. That is,\n\nwhere d is the transaction cost in percent of the total value of the HSI options transacted; S denotes the total number of straddle trades performed during the simulated trading period; and the values V s,0 and V s,1 of a straddle s referred to the aggregated market prices of the underlying ATM Call and ATM Put option on the HSI at the time of buying (selling) and selling (buying) of the straddle respectively. Hence, the objective of the proposed straddle trading system is to capitalize on the volatility of the HSI to maximize the total trading return R. In this paper, d is defined as 1% of the total economic value of the options transacted and Eq. (20) accounts for two different ways of computing the transaction cost of performing a straddle trade, i.e. (1) when the trading system closes its open position on the straddle, and (2) when the straddle expires and the trading system subsequently returns to a neutral trading position. The transaction cost for the former scenario is d(V s,0 + V s,1 ) since the ATM straddle s is transacted twice at value V s,0 and V s,1 , respectively, while the transaction cost for the latter scenario is d(V s,0 ) since settlement is automatically performed when the straddle expired. With respect to Fig. 6 , the trade decision module (TDM) of the proposed straddle trading system has to derive one of three different sets of trade decisions, namely TD Short (t), TD Neutral (t) and TD Long (t), depending on the trading scenario encountered. That is, TDM is to recommend the appropriate trading action TD Short (t) when the trading system (i.e. trader) is in a short-sold position, the trading action TD Neutral (t) when the trading system is in a neutral position, and the trading action TD Long (t) when the trading system is in a longed position, respectively. Each of these three sets of trade decisions contains two or three types of trading actions, i.e. sell ATM straddle, no trading and buy ATM straddle as described in Eq. (18). The breakdowns of the various trade decisions are presented as follows.\n\n(a) Trader has short-sold (shorted) an ATM straddle (i.e. F(t \u00c0 1) = \u00c01): The trade decision module has to decide on the appropriate trading action (denoted as TD Short (t)) for the current trading day t based on the conditions described in Eq. (22).\n\nwhere d MACD\u00f0t \u00fe 1\u00de is the difference between the projected fast and slow EMA of the Hang Seng Index volatility time series (denoted as d EMA Fast \u00f0t \u00fe 1\u00de and d EMA Slow \u00f0t \u00fe 1\u00de respectively in Fig. 6 ); and d MACD EMA\u00f0t \u00fe 1\u00de is the trigger line for the MACD trading rule to generate the straddle trading signals as described in Section 3.2. (b) Trader is in a neutral position (i.e. F(t \u00c0 1) = 0): The TDM of the proposed straddle trading system has to decide whether it is now an appropriate time to trade an ATM straddle and the trading action to be performed is derived according to Eqs. \n\nWhen d MACD EMA\u00f0t \u00fe 1\u00de < 0:\n\nWhen d MACD EMA\u00f0t \u00fe 1\u00de \u00bc 0:\n\nHence, one can observe that a no trading band of 80-120% of the trigger line d MACD EMA\u00f0t \u00fe 1\u00de is defined to prevent false trading signals being generated due to whipsaws. This reduces the detrimental effects of accruing unnecessary transaction costs from the excessive trading of the option straddles. (c) Trader has bought (longed) an ATM straddle (i.e. F(t \u00c0 1) = 1):\n\nThe trade decision module decides whether to sell off the straddle or to maintain the holding position based on Eq.\n\n(26). That is, Therefore, the proposed straddle trading system will hold onto the longed position if the HSI volatility is expected to increase or change minimally. Otherwise, the trading system will sell off the option straddle and returns to the neutral position.\n\nIn addition, Fig. 6 shows that the trade decision module (TDM) of the proposed straddle trading system may activate an exit strategy whenever the trader has an open longed or short-sold position on an ATM straddle (i.e. F(t \u00c0 1) 2 {\u00c01, 1}). As straddle trading is a highly leveraged financial activity and carries a certain amount of risk (especially with an open short-sold position), such an exit strategy helps to lock-in big trading profits as well as serves as a stop-loss mechanism if the market conditions turned unfavorable. The condition to trigger the exit strategy can be: (C1) the value of the longed (shorted) straddle s has been below (above) the initial traded straddle value V s,0 for 5 consecutive trading days, or (C2) the current value V s (t) of the traded straddle (as compared to V s,0 ) has declined sharply, or (C3) the value V s (t) of the traded straddle has increased significantly. Conditions (C2) and (C3) prevent excessive losses and locks in big profits from the straddle trade respectively. The exit conditions are mathematically defined in Eqs. (27) \n\nHence, according to Eqs. (28) and (29), the proposed trading system will apply the exit strategy to close its open position on the ATM straddle whenever the traded straddle experienced a 5% decline in its market value or has achieved a 10% gain in its traded price. This limits the downside risk while allowing the trader to reap significant profits from the correct projections of the Hong Kong stock market volatility. On the other hand, condition (C1) ensures that the trader is not in a losing position (albeit a small one) for a prolonged period of time. In summary, the above discussion presents the computational mechanisms (trading strategy) of the proposed intelligent straddle trading system that consists of a volatility prediction module based on the eFSM semantic neural-fuzzy network and the MACD-driven trade decision module that generates the trading signals for the straddle trades. The next section evaluates the performance of the straddle trading system using real-life data obtained from the Hong Kong Stock Exchange (HKSE). \n\nThe raw dataset used in this research consists of the daily closing information of the Hang Seng Index (HSI) options across a 5year period spanning from 02 January 2002 to 29 December 2006, which corresponds to a total of 1237 trading days. The information in the dataset includes the expiry dates, strike prices, daily settlements and the daily black-scholes implied volatilities of all the live European-styled options issued on the HSI, as well as the recorded closing levels of the Hong Kong bourse (i.e. the HSI) during the observation period. All the information is obtained via the Hong Kong Exchange Corporation (Hong Kong Exchange). From the daily closing levels of the HSI and the information recorded in the options dataset, the three volatility measures of the Hong Kong stock market, namely the historical volatility (HV), implied volatility (IV) and model-based volatility (MV) as described in Section 1, are computed. These respective volatility measures subsequently formed three different time-ordered data series. The HV timeseries is obtained via Eq. (30), which uses the 30-days historical standard deviation of the log-returns series {r c (t)} as a proxy to the implicit HSI volatility. That is (see Eq. (30)),\n\nwhere r 30 (t) denotes the historical standard deviation of the logreturns of the past 30 trading days (i.e. r c (t), . . ., r c (t \u00c0 29)). The computed historical volatility measure HV(t) for trading day t has been annualized with a normalizing factor of ffiffiffiffiffiffiffiffi ffi 252 p as there is approximately 252 trading days in a calender year.\n\nThe IV time-series, on the other hand, is derived from the observed closing values of the HSI European options. At each trading day t, the first-in-the-money (FITM) and first-out-of-the-money (FOTM) Call and Put options with at least two months to expiration are identified. The average of the implied volatilities of these four options is the approximated at-the-money (ATM) IV measure. Hence, from Eq. (31), IV(t) of the HSI at trading day t is defined as \n\nwhere IV FITM(Call) (t), IV FITM(Put) (t), IV FOTM(Call) (t) and IV FOTM(Put) (t) denote the black-scholes implied volatility for the FITM and FOTM Call and Put options respectively on trading day t. Lastly, the model-based volatility (MV) of the HSI is estimated from the log-return series {r c (t)} of the Hang Seng Index (HSI) using the composite conditional mean and conditional variance financial time-series model based on the autoregressive (AR) and the GARCH (Bollerslev, 1986) processes (see Eqs. (1) and (2)). The HV, IV and MV based timeseries of the HSI fluctuations are depicted in Fig. 8 . As one can observe from the plots of the three volatility measures, the Hong Kong stock market has experienced greater fluctuations and higher volatilities in the first half (i.e. Jan 2002 to mid 2004) as compared to the later half of the 5-year observation period. This could be due to the post September-11 effects (where there were a lot of uncertainties and fears about the strength of the US economy after the terrorist attacks and the related fallout on the health of the global economy), as well as the SARS (Severe Acute Respiratory Syndrome) outbreak in Asia in early 2003 that greatly eroded investors' confidence in the Asian stock markets. Nevertheless, it is important to note that the volatility time-series derived from the three different measures generally displayed similar macro volatility trends across the 5-year period, although there are significant differences in the amplitude of the fluctuations as well as conflicting pockets of volatility trends.\n\nIn this paper, the eFSM neural-fuzzy model is employed as a robust volatility forecasting system to predict the future volatility levels of the Hang Seng Index (HSI) given the past volatility observations. This constitutes the volatility projection module (VPM) of the proposed intelligent straddle trading system. eFSM possesses several desirable attributes such as (1) base to continuously address the non-stationary characteristics of the Hong Kong stock market; (2) highly formalized human-like information computations; and (3) a transparent structure that can be interpreted by a human trader via a set of linguistic IF-THEN semantic fuzzy rules to understand the volatility trends in the Hong Kong financial market. For this research, it is assumed that the future volatility level y(t + 1) of HSI can be approximated from the volatilities observed for the past ten trading days (i.e. two trading weeks). That is, from Eq. (17),\n\ny\u00f0t \u00fe 1\u00de \u00bc f VPM \u00f0y\u00f0t\u00de; y\u00f0t \u00c0 1\u00de; . . . ; y\u00f0t \u00c0 9\u00de\u00de \u00f032\u00de\n\nwhere\u0177\u00f0t \u00fe 1\u00de denotes the predicted value of y(t + 1); and f VPM is the nonlinear regression function to be approximated by the eFSM model. Hence, there are ten inputs to the eFSM-based VPM and a single output which is the predicted volatility for the next trading day (t + 1). The structure of the eFSM-based VPM is illustrated as Fig. 9 . In this paper, the eFSM model is employed to construct a modeling and prediction system for the HV and IV time-series only. That is, only the HV and IV data-series are used to evaluate the trend modeling and prediction capabilities of the eFSM model. The MV time-series, which is derived using the conditional mean and conditional variance financial time-series model based on the AR and GARCH processes, will be directly used to study the trading performances of the proposed straddle trading system. The computed trading profit/loss based on the use of the MV time-series subsequently serves as a benchmark to the trading results obtained with counterpart straddle trading systems employing the eFSM-based HV and IV projection modules. No forecasting system is constructed for the MV time-series. This is because empirically, it is not necessary to model the composite AR and GARCH processes which in turn trace the dynamics of the HSI returns time-series to derive the model-based volatility (MV) estimates.\n\nSubsequently, the HV and IV-based time-series are partitioned into two mutually exclusive segments, i.e. a training set and a test set. The training set consists of documented volatility data observed for the initial two years (i.e. Jan 2002 to Dec 2003) while the test set contains data recorded for the remaining three years (i.e. Jan 2004 to Dec 2006) of the observation period. The eFSM volatility modeling and prediction system is trained using information in the training set and its forecasting accuracies duly assessed using the withheld test set. Four measures are adopted to track the modeling and forecasting capabilities of the eFSM-based VPM. They are, namely: (1) the pearson correlation index (denoted as PC) (Rodgers & Nicewander, 1988) ; (2) the mean squared error (MSE) (Lehmann & Casella, 1998) ; (3) the average relative variance (ARV); and (4) the mean absolute percentage error (MAPE) measures. The pearson correlation index PC, with a range of [\u00c01, +1], is a measure of the linearity of the predicted and actual volatility trends. That is, a correlation of +1 indicates a perfect positive correlation, which means that both the predicted and actual HSI volatilities move in the same direction together. The MSE, ARV and MAPE measures, on the other hand, tracks the forecast accuracies of the predicted to the actual observed HSI volatility levels. The MSE, ARV and MAPE measures are mathematically defined in Eqs. (33)-(35), respectively.\n\nARV \u00bc P N i\u00bc1 y \u00f0i\u00de \u00c0\u0177 \u00f0i\u00de \u00c0 \u00c1 2 P N i\u00bc1 \u00f0y \u00f0i\u00de \u00c0 y\u00de 2 \u00f034\u00de\n\nwhere y (i) denotes the actual observed HSI volatility level for trading day i in the test set;\u0177 \u00f0i\u00de is the corresponding predicted volatility computed by the eFSM-based VPM; y \u00bc 1=N P N i\u00bc1 y \u00f0i\u00de represents the baseline mean output prediction; and N denotes the number of trading days in the test set. Of the performance indicators specified in Eqs. Fig. 9 . Volatility projection module of the proposed straddle trading system, where z \u00c01 is a delay element.\n\naccuracies of the eFSM model to the mean output predictor. Lastly, MAPE tracks the mean absolute error in percent between the actual and the eFSM forecasted values across all volatility observations in the HV and IV time-series. To capture the overall volatility modeling and forecasting capabilities of the eFSM-based VPM, the various measures are combined into a performance index PI such that\n\nThe modeling (recall) and forecasting (generalization) results of the eFSM-based VPM on the historical volatility (HV) time-series are depicted as Fig. 10 . For both the recall and generalization assessments, the eFSM model has been trained using the training set defined earlier. In recall, the trained eFSM model is assessed using inputs from the training set (i.e. to determine how well it has learnt the volatility trend information in the training data) while for generalization, the eFSM model is evaluated with the unseen inputs from the test set. The tracking measures and the performance indices for the recall and generalization tasks are presented with the result plots. From Fig. 10 , one can observe that the eFSM model is able to capture the historical volatility trends in the training set relatively well (refer to Recall results for the period [2002] [2003] . This is reflected by a high pearson correlation (PC) value of 0.964 as well as a low mean squared error MSE of 0.699. This small modeling error is also tracked by MAPE, which indicated that on average, the error expected of the predicted historical volatility level for each trading day in the training set is approximately 3.4% of its true (subsequently observed) value. The ARV measure also showed that eFSM performed superbly when compared to the baseline mean output predictor. The forecasting capability of the eFSM model is subsequently evaluated using the withheld test set. As observed, the accuracy of the predicted volatility levels for trading days of 2004-2006 that constitutes the test set degrades when compared to the recall performance of eFSM on the training set. This is indi-cated by the larger MSE, ARV and MAPE values. Specifically, the mean expected forecast error for the historical volatility level of each trading day in the test period has increased to approximately 5%. On examination, the lower forecast performance of eFSM on the test set is due to significant prediction errors at two prominent durations in the test period. These durations are denoted as subperiod 'a' and 'b' respectively in Fig. 10 . Subperiod 'a' is characterized by a series of intense fluctuations in the HV data-series, and this could have contributed to the large prediction errors by the eFSM-based volatility projection module. On the other hand, the poor performance by eFSM at subperiod 'b' could be due to the lack of similar trends in the training set. It is observed that at subperiod 'b', there is a significant increase in the volatility of the Hong Kong financial market as shown by the sharp rapid rise from trough to peak of the volatility curve. However, similar volatility trends in the training set have a smaller magnitude of increase and this is followed by a rapid fall. Hence, this could have caused eFSM to forecast a plunge in the volatility level, leading to significant prediction errors in the result plot.\n\nThe task of modeling and forecasting the historical volatility measures of the HSI is subsequently repeated using other modeling techniques. They are, namely: (1) a 3-layered back-propagation trained feed-forward neural network with 20 hidden nodes (FFNN-BP); (2) a radial basis function (RBF) network (Moody & Darken, 1989 ) with 40 hidden nodes; (3) the cerebellar model articulation controller (CMAC) (Albus, 1975) neural network; (4) HyFIS (Kim & Kasabov, 1999) ; and (5) the ANFIS network. These computational methods replaced the eFSM model as the function approximator in the VPM illustrated in Fig. 9 . The benchmarking techniques are selected based on their established performances in time-series modeling and prediction. determined to obtain credible results for comparison with those achieved with the eFSM model. For FFNN-BP, linear activation functions are used for the single output as well as the 20 hidden nodes, while the HyFIS network employs a configuration of 4 fuzzy partitions per input dimension that subsequently results in 154 trained fuzzy rules. The ANFIS network, on the other hand, is implemented as part of the MatLAB fuzzy logic toolbox (MatLAB Fuzzy Logic Toolbox) and employs subtractive clustering for its structure identification process that generates a total of 11 Takagi-Sugeno (TS) functional fuzzy rules. Lastly, the RBF network employs 40 hidden nodes with Gaussian basis functions as local models to learn the volatility trends in the training set and the CMAC structure is defined with 5 memory cells per input dimension. For CMAC, a total of 93036 memory cells are populated after the training process. In addition, the volatility modeling and prediction tasks are repeated ten times with the FFNN-BP model and the average result reported in Table 1 in order to address the issue of differing results due to the random initialization of the network's weight matrix. Table 1 clearly showed that with the exception of the FFNN-BP model, the rest of the benchmarking systems are able to achieve a good modeling (recall) performance on the training set of the HV time-series. Specifically, the ANFIS and CMAC networks are able to produce more superior results than the eFSM model. This is likely due to the use of linear functions to model the desired output volatility levels as in the case of ANFIS and the use of local models and precise scalar outputs to learn the complex volatility trends in CMAC. The FFNN-BP model, on the other hand, performed poorly in the recall task due to significant modeling errors as indicated by the various accuracy measures. The conflicting and complex volatility trends were not adequately captured by FFNN-BP, which uses a set of globally tuned weights to model the characteristics of the training set. Meanwhile, the HyFIS and RBF networks obtained just marginally poorer recall performances on the training set of the HV time-series as compared to the eFSM model. However, with respect to the generalization task, Table 1 revealed that there are significant degradations in the prediction accuracies of the benchmarking techniques. Noticeably, ANFIS and CMAC produced the poorest results amongst all the evaluated modeling techniques. For ANFIS, this is due to the functional (linear) computation of the predicted volatility levels based on the presented inputs using the Takagi-Sugeno (TS) fuzzy model, which tends to 'over-extrapolate' its forecasts around subperiod 'a' (see Fig. 10 ) that is characterized by a series of small but intense volatility fluctuations in the Hong Kong stock market. The CMAC network, on the other hand, had poor generalization performance for the unseen volatility trends in the test set as it employed discrete (and uniformly spaced) partitions to define its memory surface. This caused many untrained (or under-trained) memory cells to be accessed and resulted in poor volatility forecasts. Meanwhile, the FFNN-BP model, as expected, returned another set of disappointing results for the generalization task as it had earlier failed to properly model the volatility trends of the training set. The remaining two benchmarking systems, namely HyFIS and RBF, performed better than the three techniques discussed above. A plausible reason is the use of Gaussian-shaped fuzzy sets in Hy-FIS to model both the input and output clusters of the volatility data space, and the use of Gaussian radial basis functions in the RBF network to define the local models employed to model the volatility fluctuations. This equips the two modeling techniques with better generalization capabilities for the unseen volatility trends in the test set. However, the results in Table 1 have clearly shown that the forecasting (generalization) performance of the eFSM model compared favorably to all the benchmarking techniques. Specifically, eFSM achieved the highest performance index (PI) of 0.438 amongst all the evaluated modeling techniques and also had the smallest prediction errors as indicated by the various accuracy measures. This superior performance is possibly due to the use of Gaussian-shaped fuzzy sets to model the volatility trends in the training set as well as the learning and computational processes of the eFSM model.\n\nIn addition, the brain-inspired learning process of the eFSM model elicits a set of highly interpretable linguistic fuzzy rules from the volatility data in the HV training set. The LTP and LTDbased mechanisms (Section 2.3) ensures a compact rule-base and enables eFSM to extract the salient data structures present in the training data. Such fuzzy rules enable a human trader to understand the volatility fluctuations of the Hang Seng Index and help him to make informed trading decisions. Fig. 11 depicts the set of input-output fuzzy sets extracted from the trained structure of the eFSM model. Appropriate linguistic labels with the associated semantic meanings have been attached to these fuzzy sets to describe the resultant set of 94 trained fuzzy rules. This compares favorably against the FFNN-BP, RBF and CMAC techniques, which do not allow any meaningful interpretation of the acquired knowledge via their trained structures. On the other hand, although the HyFIS and ANFIS networks are neural-fuzzy systems like the eFSM model, there are deficiencies inherent to these two techniques that hinder the efforts of a human trader to decipher their acquired knowledge. Specifically, the training process of Hy-FIS causes excessive and unconstrained overlapping of its computed fuzzy sets, which makes assigning proper semantic meanings to these fuzzy sets difficult. The ANFIS network, on the other hand, employs the TS fuzzy model that computes with functional consequents. This subsequently reduces the transparency and interpretability of its fuzzy rule-base.\n\nThe Hang Seng Index (HSI) volatility modeling and forecasting task is subsequently repeated using the IV time-series. Fig. 12 illustrates the modeling and forecasting results of the eFSM-based VPM. The training and test sets of the IV time-series are constructed in a manner similar to that for the HV measure. From  Fig. 12 , one can observe that the eFSM model has achieved considerably consistent results across the recall and generalization tasks. That is, there is only a slight degradation in performance as indicated by the respective performance indices PI. Specifically, the expected error for each volatility projection increased from approximately 2.6% for the recall assessment using the training set to about 3.8% for the generalization evaluation using the test set. This increase in forecasting error on the test set is plausibly due to noticeable wayward projections occurring at subperiods 'c' and 'd' denoted in Fig. 12 . In addition, when compared to the HV modeling and forecasting results depicted in Fig. 10 , one can easily conclude that the eFSM model has achieved a better overall performance in volatility projections using the IV time-series data. This could be attributed to the fact that the IV time-series has smaller volatility fluctuations and simpler trend dynamics than the HV-based data.\n\nSimilar to what was performed in Section 4.2, the modeling (recall) and forecasting (generalization) evaluations are repeated using the FFNN-BP, RBF, CMAC, HyFIS and ANFIS, techniques. Again, the network structure and learning parameters of the various benchmarking techniques have been empirically determined to obtain a set of credible results for comparison with the performance of the eFSM model. Specifically, the FFNN-BP network has 20 hidden nodes and linear activation functions for the single output as well as the hidden nodes, and the HyFIS model employs 4 fuzzy sets per input that identifies 78 trained fuzzy rules. The ANFIS network derives 8 TS functional fuzzy rules while RBF uses 40 local models to learn the volatility trends in the IV training set. Similar to the previous set of experiments, the CMAC structure is defined with 5 memory cells per input dimension and there is a total of 45020 populated cells after the training process. The respective benchmarking results are subsequently tabulated as Table 2 .\n\nOne can observe from the results listed in Table 2 that for the recall task, the HyFIS, ANFIS and RBF networks reported better modeling performances than eFSM. In fact, they are the top three performers amongst all the evaluated techniques. This could be due to the fact that HyFIS and ANFIS (for the input space only) employed Gaussian fuzzy sets to model the characteristics of the IV fluctuations, while the RBF network uses Gaussian radial basis functions to define the local models employed to learn the volatility trends in the IV training set. recall assessment as they may have failed to adequately capture the inherent characteristics of the training set. However, when called upon to generate volatility forecasts using data from the test set, the results in Table 2 showed that there are marked degradations in the performances of the benchmarking techniques. Particularly, there are major declines in the performance indices (see PI readings in Table 2 ) reported by the HyFIS, RBF and CMAC networks, and also a significant increase in the forecast errors for the volatility projections computed by these techniques as indicated by the MSE, ARV and MAPE measures. Such degraded performances can be explained by the significantly different volatility levels encountered in the test period as compared to the volatility levels in the training set of the IV time-series. Specifically, the implied volatility of the HSI fluctuated between 16% to 36% between 2002 to 2003, while the years 2004 to 2006 see the same volatility measure within the range of 11% to 26%. Hence, to the HyFIS, RBF and CMAC networks, there are significantly lower volatility levels in the test set that they have not encountered during the training phase. This causes large forecasting errors in the volatility projections computed by the three networks. On the other hand, FFNN-BP, ANFIS and eFSM performed considerably better than the previous three benchmarking techniques on the IV test set. This is due to the use of a linear activation function for the output node in FFNN-BP, the linear consequent function in the TS fuzzy model of the ANFIS network, and the computation of the output of the eFSM model via a fusion of the Mamdani and TS fuzzy models. More importantly, Table 2 has shown that eFSM has a better forecasting capability than the FFNN-BP and ANFIS networks, as it is able to sufficiently capture the volatility fluctuations in the training set using the brain-inspired LTP and LTD learning mechanisms and to sensibly extend the acquired knowledge to derive projections for the unseen test set.\n\nThis section presents the trading results of the proposed intelligent straddle trading system based on the use of the MACD trading rule and the computed HV and IV forecasts from Sections 4.2 and 4.3. The simulated trading duration is defined as the last three years (i.e. Jan 2004 to Dec 2006) of the observation period. As benchmark, the MV time-series is directly employed to study the performance of the straddle trading system and the computed trading profit/loss serves as a baseline comparison to the trading results of counterpart trading systems employing the HV and IV projections. In addition, the performances of trading systems employing the eFSM-based volatility projection module (VPM) are also evaluated against the results of traders with a hypothetic Perfect-Predictor (PP) VPM. That is, with respect to Eq. (32), the PPbased VPM generates perfect forecast of\u0177\u00f0t \u00fe 1\u00de \u00bc y\u00f0t \u00fe 1\u00de. Table 3 lists the various trading results.\n\nSpecifically, two different aspects of the trading performances of the various straddle trading systems evaluated are reported in Table 3 . They are: (1) the mean and standard deviation of the profit/loss e r s \u00f0t\u00de (in percent) for each straddle trade performed, and (2) the overall profit/loss e R (in percent) achieved by a trading system for the simulation period to the total investments committed. e R may also be interpreted as the return on every unit Hong Kong dollar committed to the straddle trades during the trading period. The results are expressed in percentages to facilitate the comparison of the trading performances for the various counterpart trading systems employing different HSI volatility measures and the eFSM or PP-based VPM. With respect to Eqs. (20) and (21) \n\nwhere r s (t) is the computed return (profit/loss) for the traded straddle s; the value V s,0 denotes the initial investment committed by the evaluated trading system to take an open (longed or shorted) position on the straddle s; and S is the total number of straddle trades performed during the simulated trading period. From Table 3 , one can observe that regardless of the volatility measure used, the trading gains achieved by the proposed straddle trading system employing the PP-based VPM are significantly positive after accounting for the 1% transaction cost. This is reflected by the large positive gains for the expected profit/lossr s \u00f0t\u00de for each straddle trade and the overall return e R under the PP-VPM column. The results clearly demonstrated that the capability to predict (project) the daily HSI volatility levels from past historic observations can help a human trader to enhance his investment profits when trading the HSI straddles. In addition, the positive gains recorded by the various trading systems employing either the eFSM or PP-based volatility projection module (VPM) indicated that the trading strategy adopted by the trade decision module (TDM) of the proposed straddle trading framework is technically viable in capitalizing the uncertainties of the Hong Kong stock market for financial volatility trading. That is, the proposed straddle trading system can help a human trader to generate investment profit gains via straddle trading during rising, falling or side-way market conditions. Hence, considerable profits can be realized by the implemented trading framework. Individually, each of the three volatility measures produced different degree of trading return. Table 3 showed that the highest profit gains are consistently achieved by trading systems employing the implied volatility (IV) measure. Trading systems adopting the HV measure as a proxy to the implicit HSI volatility, meanwhile, have the lowest trading returns amongst all the evaluated systems. A plausible reason is that implied volatility (IV) is a forward projection of the price path of the underlying asset, which in this case, is the fluctuation of the Hang Seng Index. The statistically based HV measure, on the other hand, is backward-looking and could be less sensitive to information contributing to the existing market sentiments. Hence, the IV measure, which is derived from current option price data, may be a more accurate indicator of the anticipated movements of the HSI than the HV measure and subsequently results in much higher trading returns. Lastly, the profit gains of trading systems employing the model-based volatility (MV) measure obtained via the composite AR and GARCH processes fall between those achieved by counterpart systems employing the HV and IV measures.\n\nTo further demonstrate the viability of the proposed straddle trading framework, the simple average uncompounded daily rate of return DR achieved by the various trading systems for each unit of dollar committed to a straddle trade during the simulated trading period is computed. With respect to Eq. (37), the simple average uncompounded daily return DR is defined as in Eq. (39).\n\nwhere S denotes the number of straddle trades performed during the simulated trading period; and e r s \u00f0t\u00de and T s is the respective profit/loss (in percent) and the duration (in trading days) for the straddle trade s. Essentially, DR denotes the expected daily rate of return when a trader has an open straddle position. Table 4 lists the computed simple average daily return DR of the various trading systems employing different HSI volatility measures with either the eFSM or Perfect-Predictor (PP) based VPM. As comparison, the daily returns of the evaluated trading systems are duly benchmarked to the simple daily interest rate enjoyed by a holder of a Hong Kong time deposit of less than HK$100,000 over the same 3 years duration. According to information obtained from the HKMA, the average annual return for such Hong Kong dollar time deposit from January 2004 to December 2006 is 1.67%. This works out to an uncompounded daily return of approximately 0.0046% on a Hong Kong dollar. From Table 4 , one can clearly observe that the uncompounded daily returns derived from the straddle trades using the proposed straddle trading framework (regardless of the volatility measures employed) are significantly higher than the interest rate offered by a Hong Kong dollar time deposit.\n\nIn this paper, an intelligent straddle trading system (framework) that consists of a volatility projection module (VPM) and a trade decision module (TDM) is proposed for financial volatility trading via the buying and selling of option straddles to help a human trader capitalizes on the underlying uncertainties of the Hong Kong stock market. Three different measures are employed to quantify the implicit volatility of the Hong Kong financial market. They are, namely: (1) the historical volatility (HV), (2) implied volatility (IV) and (3) model-based volatility (MV) of the Hang Seng Index (HSI). These measures subsequently formed three timeordered volatility data series characterizing the fluctuations of the HSI.\n\nAt the core of the proposed straddle trading system is the trade decision module (TDM) that employs the well-established movingaverages convergence/divergence (MACD) principle with the various volatility time-series to generate the trading signals (in the form of trade decisions) in response to the different trading scenarios encountered by a human trader. However, the MACD trading rule inherently generates time-delayed trading signals due to the use of moving averages, which are lagging trend indicators. This drawback is intuitively addressed by employing a volatility projection module (VPM) that forecasts the future volatility levels of the HSI prior to the activation of TDM. The VPM is realized by a selforganising neural-fuzzy semantic network named the evolving fuzzy semantic memory (eFSM) model. eFSM approximates a nonlinear regression function that forecasts the future HSI volatility levels based on historically observed fluctuations. The computing structure of the eFSM model evolves dynamically with the arrival of each training data presented. The learning mechanisms of eFSM are designed to functionally emulate the information processing capabilities of the human hippocampus where prior to the start of the learning process, there are no fuzzy rules in the eFSM structure. New fuzzy rules are dynamically added and old rules that no longer describe the current data characteristics observed are removed based on the long-term potentiation (LTP) and long-term depression (LTD) mechanisms observed in the human brain during the learning phase. This allows the eFSM model to continuously address the non-stationary characteristics of the Hong Kong stock market. In addition, the computations of eFSM mimics the human way of reasoning and the trained structure of the eFSM model can be interpreted by a human trader as a set of linguistic fuzzy semantic rules. These desirable attributes provided added credence to the computed volatility projections. The volatility modeling and forecasting performances of eFSM are encouraging when subsequently benchmarked to several well-known computational intelligence based modeling techniques such as the ANFIS, HyFIS and CMAC neural networks.\n\nLastly, the performance of the proposed straddle trading system is evaluated using the three different volatility measures and reallife data from the Hong Kong Stock Exchange (HKSE). The results clearly demonstrated that the ability to forecast the future volatility of the Hong Kong financial market can help a human trader to enhance his investment profits when trading the HSI straddles. More importantly, the observed trading results indicated that the trading strategy adopted by the trade decision module (TDM) of the proposed straddle trading framework is technically viable in capitalizing the uncertainties of the Hong Kong stock market for financial volatility trading and achieved a significant return over the interest rate offered by a Hong Kong time deposit account. "}