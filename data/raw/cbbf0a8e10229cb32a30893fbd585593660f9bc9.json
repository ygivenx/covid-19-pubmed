{"title": "When even the 'best-laid' plans go wrong Strategic risk communication for new and emerging risks", "body": "When even the 'best-laid' plans go wrong Strategic risk communication for new and emerging risks\n\nA fter ploughing over a mouse's nest in his field, a farmer laments, \"But Mousie, thou art no thy-lane [not alone], in proving foresight may be vain; The best-laid schemes o' mice an' men gang aft agley [often go wrong], an' lea'e us nought but grief an' pain, for promis'd joy!\" (Williams, 1952) . The farmer's words, penned by eighteenth century poet Robert Burns, aptly summarize one of the primary challenges facing risk managers: despite best intentions and efforts to eliminate negative consequences, technological progress creates new and unforeseen hazards. Such is the nature of risk and, some might say, the cost of progress.\n\nThe delicate balance between risks and benefits is evident today in ongoing public debates about biotechnology, gene therapy and now nanotechnology. Scientists and engineers are abuzz with excitement about the substantial promise of nanotechnology to improve food, agricultural, medical and security systems; yet we already see growing public concern about the real and potential ethical implications associated with this new technology, the possibilities of its misuse and other unforeseen risks or consequences. Popular media accounts and bestselling novels do their part in fuelling the public's perceptions of risks and hazards, but, as with any emerging technology, a shortage of public knowledge and a great deal of uncertainty about the science also exists. It is equally likely, however, that scientists are as much 'in the dark' about how individuals, groups and other stakeholders will respond to the new and emerging risks of nanotechnology and other technologies, as the public is ignorant about the science. T oday, it is essentially a truism in risk communication that pushing technological advances without considering public input runs the risk of triggering backlash or opposition. For some scientists, perhaps a more bitter pill to swallow is that even the best efforts to communicate and involve the public in decisions about how to implement new technologies safely are no guarantee of public acceptance or even agreement with the scientists. Fessenden-Raden and colleagues included the following admonition in an article about risk communication: \"No matter how accurate it is, risk information may be misperceived or rejected if those who give information are unaware of the complex, interactive nature of risk communication and the various factors affecting the reception of the risk message\" (Fessenden-Raden et al, 1987) .\n\nA substantial body of research now supports the finding that scientists and nonscientists calculate risk differently (Slovic, 2000) , with non-scientists focusing more on values and qualitative factors. Because of these different approaches to and perspectives of risk, breakdowns in risk communication occur frequently, which has prompted a fair amount of study into i m p r o v i n g the risk communication process. In this regard, the 'co-orientation' factor has become increasingly important. This refers to the degree to which individuals' or groups' perceptions are similar or differ and to the degree to which these perceptions are correct. Building on early work by Newcomb (1953) Risk communication, in essence, is therefore defined as an iterative coorientation process among scientists and non-scientists about risk assessment, risk characterization, risk management and risk policy. This holds true for a range of topics: from discussing the risks and benefits of new and emerging technologies, such as nanotechnology, to providing guidelines for preventing exposure to recent health risks, such as severe acute respiratory syndrome, to implementing international health campaigns to reduce the transmission of infectious diseases, such as AIDS or tuberculosis. Risk communication encompasses characteristics of the sender and receiver, and it entails both purposeful and unintentional messages about risk. It is multidirectional, and it occurs at individual, group, organizational, community and societal levels. The next few paragraphs address the nature of risk communication, including some of the challenges facing risk communicators today, and review some common and other, more promising, risk-communication strategies. F irst and foremost, risk communication is a matter of building trust. One problem of modern societies is that we are not quick to accept risks, neither as individuals nor as societies, which has led to our complex systems of risk management. Instead of feeling more at ease, however, our society has been growing more concerned about risks in recent decades (Slovic, 1993) . We can see a corollary in a widely documented decrease in the public's confidence in institutions that are responsible for risk management (Laird, 1989) . The reversal of this trend may lie in the revival of trust. Common sense tells us that trust is essential, yet some argue that its role has been largely under-appreciated in risk management efforts (Slovic, 1993) .\n\nIn The Homeless Mind, Berger et al (1973) argued that the principle carriers of modernization-technology and bureaucracy-have dislodged human consciousness, causing us to feel alienated from each other and deprived of sure footing. Modern human consciousness-'the homeless mind'passes from place to place, from topic to topic, never fully knowing one before encountering another. Our conceptions of trust and risk are entwined with these consequences of modernization. Consider first technological progress. Few would deny that technology has benefited humankind, yet many would strongly argue that these benefits have come with costs. Although society and individuals have learned to live with some risks, technological progress has brought about others that are harder to accept, such as nuclear weapons and waste from nuclear power, toxic waste from chemical manufacturing, groundwater contamination from fertilizers, acid precipitation from electric utilities, and even perhaps global climate change due to refrigerants and aerosols in the earth's atmosphere. Technological progress has increased human life span and decreased infant mortality rates, but this adds to the strain on human and natural resources and increases our dependency on technology to solve the accompanying problems of famine, waste and resource depletion.\n\nTo manage technology and society, we rely on bureaucracies. The division of labour is an offspring of modernization, and we have become increasingly dependent on one another, directly or indirectly, to manage our affairs (Freudenburg, 1993) . As populations expand and new needs arise, bureaucracies move further away from our direct and immediate contact and become more abstract to us. At the same time, they demand more reliance on strangers and unfamiliar systems to protect us from risk. To ease our conscience, we construct additional bureaucracies to manage the ones in existence. In a sense, this build-up and ensuing redundancy are 'stand-ins' for the security we may feel is lacking in modern societies.\n\nThe growth of technology and the bureaucracy to manage it has also made us more vulnerable to risk-and aware of this vulnerability. While making the unimaginable possible, technology has also made us increasingly dependent on impersonal bureaucracies to manage those technologies and their potential risks to human and environmental health (Covello & Mumpower, 1985) . Freudenburg (1993) coined the term 'recreancy' to describe the relationship between modernization, trust and riskmeaning the potential for failure by institutions or institutional agents to carry out their responsibilities and to merit society's trust.\n\nResearch suggests that fear of risk coupled with distrust of risk management can increase or amplify public concerns about technologies and fuel ensuing controversies (Kasperson, 1992; Slovic, 1993) . This may hold especially true in modern democratic systems, which are envisioned as providing forums for multiple voices to be heard. The ubiquitous presence of the mass media is another potentially exacerbating factor: never before has society had such an 'up close and personal' view of the fallibility of systems and those managing them, as well as the vulnerability of the public to human error (Dandoy, 1990 ).\n\nT o rebuild and/or supplement this waning sense of security, risk managers try various approaches or 'fixes', to use Heberlein's term (Heberlein 1974 ). Heberlein suggested that society has three options, or fixes, to reduce the probability of loss: technological, structural and cognitive. Technological fixes bypass humans altogether by modifying surroundings instead of people or social structures. Structural fixes modify human behaviour by regulating social settings or the 'structures' in which the behaviour occurs. Cognitive fixes go 'straight to the head', so to speak, by targeting the attitudes, beliefs and values that affect human behaviour.\n\nThe technical fix is apparent in the construction of dams or levees, which extend a sense of security (although some would argue a false sense) to river communities and people living in flood plains. Technological fixes, in addition to cognitive ones, are evident in the incinerators and landfills, often enthusiastically described as 'state-of-the-art', to manage our flow of waste. Technological approaches are also apparent in efforts to locate 'locally unwanted land uses', such as mobile telephone towers on the outskirts of communities where less citizen opposition is expected. As we can imagine, however, technological fixes alone rarely suffice. Efforts to bypass people, especially in matters involving resource allocation or perceived involuntary risk, can create controversies and protests. For example, food irradiation, which has been approved by the US government for various food products to reduce pathogens and food-borne illness, has also generated The growth of technology and the bureaucracy to manage it has also made us more vulnerable to risk-and aware of this vulnerability Common sense tells us that trust is essential, yet some argue that its role has been largely under-appreciated in risk management efforts special issue S63 concern and controversy among consumer advocacy groups who view the procedure as an involuntary risk that could be hazardous to human and environmental health. Finally, people can simply choose to ignore or circumvent certain technical fixes, such as individuals who do not cook their meat to suggested temperatures or continue to smoke unfiltered cigarettes despite the higher risks of contracting lung cancer.\n\nStructural fixes include the array of regulations and procedures passed to ensure fairness and 'due process' in risk-based decision making. Such fixes include safety devices, such as airport metal detectors and automobile seatbelts, and regulations, such as seatbelt laws or speed limits. Efforts by law enforcement agencies to detect fraudulent cases and abuse of pain medication prescriptions is another example of a structural fix to the risks of drug addiction and abuse. But, just as many people continue to speed or refuse to 'buckle up', so too do structural fixes have their shortcomings, as not everyone follows such regulations. In addition, some structural fixes can backfire, such as when doctors are reluctant to prescribe strong pain killers to patients for fear of prosecution and, consequently, do not adequately reduce their patients' suffering (Smith, 2004) .\n\nCognitive fixes use promotional and educational campaigns, and strategies to target audiences and promote changes in attitudes and behaviour. These include public relations efforts to build or rebuild trust in the systems or individuals, as well as public health campaigns, science literacy efforts and various other risk communication strategies. Cognitive fixes are the most challenging to accomplish due to the difficulty associated with any attempt to change attitudes and behaviours, yet many would agree that they are also appealing because of their ability to effect long-term change and potentially empower individuals in decision making. E ffective risk communication as a cognitive fix is not a matter of simply passing information on to the public, however. In fact, such simple risk messages that are used to meet the information needs of nontechnical or lay audiences face several challenges. The intended audience may have a limited understanding of science and technology (National Science Board, 2002), it may not take the time to read or process the content of the message and instead fall back on heuristics or 'rules of thumb' (Tversky & Kahneman, 1974) , or it may be exposed to competing messages or other sources that give contradictory information about risk (Krimsky & Plough, 1988) . These challenges can occur on the societal level, such as how to address environmental problems, as well as on the personal level, such as whether to vaccinate one's children against transmittable diseases.\n\nMany people would also take exception to the idea of a cognitive fix because it implies a deficiency on the part of non-scientists. A related concept is the 'deficit model', which is a common and traditional way of looking at communication between scientists and nonscientists (Durant et al, 1992; Ziman, 1984) . This model essentially argues that the public lacks adequate scientific information on which to base their judgments, which is why public perceptions of risk are often at odds with scientific assessments. To remedy this, proponents argue that we need to educate lay people to think more like scientists, so that they will become more receptive to the scientists' arguments. Although few people would argue against having greater scientific literacy or a general understanding of scientific concepts among the public, focusing entirely on 'fixing' a deficit diminishes the role that nonscientists can play in risk characterizations. Being acutely aware of risks in the context of their everyday lives, non-scientists often provide unique insight into risk assessments, which at times may even lead to better risk characterizations (Stern & Fineberg, 1996 (Scherer, 1991) . Proactive risk communication calls attention to a potential or existing issue, suggests an agenda for discussion, and recommends a format for information exchange. Advantages of proactive communication include its potential to allow for more balanced and meaningful discussions. By its very nature, it can also alert people to a risk they did not know existed, which can help them to take precautionary measures to avoid exposure. Some might also consider this a disadvantage, particularly when the experts think that the risk in question does not pose a significant danger to human health or the environment. Reactive risk communication, in comparison, occurs only after the public or the media draw attention to a specific issue, or in response to a crisis. A considerable difference exists, however, between reactive risk communication following a crisis situation and reactive risk communication after an organization has been viewed as 'stonewalling' or avoiding public comment, with the latter incurring much more damage to that organization's perceived trust and Pre-1979 Asian poster promoting youth vaccination for smallpox and measles. \u00a9 Centers for Disease Control and Prevention, Atlanta, GA, USA special issue S64 credibility. Other disadvantages of reactive risk communication are the danger that science can become less relevant when issues become emotionally charged, the tendency of people to disbelieve or discredit delayed information and the fact that communicators are placed in defensive positions. Reactive risk communication can also sometimes come too late to help or protect individuals or their families from harm, such as when US postal workers died in 2001 after exposure to anthrax spores in the mailroom. Unfortunately, not all risks can be avoided or detected. Generally speaking, however, proactive risk communication yields greater potential for building trust among individuals and risk management, as well as for satisfying legal and ethical obligations. For example, controlling antimicrobial resistance will require ongoing proactive risk communication with, among others, healthcare professionals, patients, pharmaceutical companies, food producers and consumers. While proactive risk communication can work to reduce the need for antibiotics and the spread of resistant strains of bacteria, reactive risk communication will probably be necessary as the inevitable cases of illness arise.\n\nThe specific methods used to communicate risk and involve the public also vary widely. Face-to-face risk communication can entail holding a single public hearing during an environmental permitting process or conducting a series of intense, deliberative workshops with targeted audiences. Massmediated risk communication can involve scientists or government agencies issuing press statements, holding press conferences or giving interviews. Just as the specific avenues of risk communication vary, so too do the reasons behind them. Some efforts are used primarily to inform and educate, others actively seek public input, and still others seek consensus. The main concern here is matching objectives with methods and ensuring that participants understand their part in the overall process. A final consideration relates to the degree of control over the message. Senders of risk communication information have much less control over the ultimate messages when they rely on news media to propagate them, although the potential reach is much greater. By contrast, control is much greater in face-to-face settings or other direct forms of communication. Table 1 provides an overview of some common methods of risk communication and lists some advantages and disadvantages of each. With these considerations in mind, the next section examines four approaches towards providing risk information: persuasive, balanced, dialectical and narrative. F irst, conventional risk communication efforts that are used to educate lay audiences resemble persuasive models. Typically these models are one-sided approaches that try to convince audiences to change their attitudes or behaviours about a particular issue or set of issues in a particular direction (Krimsky & Plough, 1988) . Because of their explicit intent to change people's attitudes and behaviours, persuasive approaches are sometimes also referred to as advocacy approaches. Just as countless studies have examined the factors mitigating the impact of persuasive messages, numerous studies have also shown that conventional approaches to risk communication need to account for psychological factors (Tversky & Kahneman, 1974; Slovic, 2000; Weinstein, 1989 ), sociological influences (Kasperson, 1992 Freudenberg, 1993) and cultural determinants (Douglas, 1985) .\n\nSecond, for risks that entail trade-offs or uncertainty, the balanced model of risk communication is often a preferred strategy. Rather than advocating a particular perspective, the balanced model presents all sides as equally as possible before allowing individuals to make up their own minds. One example would be when a paediatrician counsels parents about the risks and benefits of vaccinating their children against certain childhood diseases. The balanced model resembles the 'journalistic' or reportorial approach, which claims to present 'just the facts' of a story without editorializing one way or the other. Some have argued that presenting disadvantages alongside advantages may alert audiences to previously unknown risks and make them more concerned about them (Kasperson, 1992) . Another drawback to balanced messages lies in the assumption that lay audiences can evaluate the information critically; in truth, they may not know how to choose between sides (Nelkin, 1987) . Still, some research suggests that balanced information can result in a greater appreciation for the complexities of the technologies and sometimes even promote more positive perceptions of those technologies (McComas & Scherer, 1999) .\n\nThe third approach is the dialectical model (Juanillo & Scherer, 1995) . It derives its name from dialectics, a mode of argument that uses a series of questions and answers to probe through possibilities and weigh contradictory facts and opinions with a view to their resolution. Rather than merely presenting many sides of the issue as with using the balanced approach, the dialectical approach to risk communication helps stakeholders evaluate the scientific and technical merits of the information. It encourages lay audiences to probe the broader questions related to risk to gain a greater understanding of the complexity of the issues and to put the risks into perspective with the costs, benefits and tradeoffs. For example, dialectical messages related to the risks of vaccinating children would explicitly encourage parents and caregivers to weigh the benefits and drawbacks of vaccinating their children in relation to the benefits and drawbacks of not vaccinating their children. To assist in their evaluation and help them consider alternatives, messages would suggest questions that parents and caregivers should ask themselves, as well as their doctors or other medical experts. In this fashion, the dialectical approach seeks to engage audiences in the content, while equipping them with the tools to understand and evaluate the information so that they can make informed judgements (Yankelovich, 1991) . Recent research on value-focused thinking in risk communication represents a similar rationale in terms of eliciting informed judgements about risk, rather than cursory responses (Arvai et al, 2001) .\n\nThe fourth strategy for providing risk information uses narratives. Telling stories to convey meaning is arguably as old as human communication; however, research examining the use of narratives as a risk communication tactic is relatively new. The narrative approach is a reflective strategy that attests to the power that stories, anecdotes and case studies hold in helping individuals relate to or 'see themselves' in a situation. Carefully selected narratives can provide useful illustrations or personal examples that are potentially easier to recall than impersonal facts or numbers. Research on the effectiveness of narratives when compared to other approaches is mixed, however, with some studies suggesting that narratives enhance knowledge and memory and other studies failing to show clear differences between narrative strategies and more traditional fact sheets (Golding et al, 1992; Kearney & DeYoung, 1995) . T he advent of new technologies, and their risks and benefits, continue to stimulate scientific, public and political debate, as they arguably have for many centuries. Among the main challenges facing risk managers today is distrust of or scepticism towards individuals and institutions that manage risk. Building trust is difficult, but not impossible, and will require long-term commitment towards openness and honesty, as well as a sensitivity towards, and appreciation of, public values and opinions. Traditional risk communication efforts were often too quick to 'talk down' non-scientists or dismiss their arguments as 'irrational' when they disagreed with the scientists' conclusions. By contrast, today's more enlightened efforts seek to engage the public in the creation, dissemination and evaluation of risk messages. Rather than viewing risk communication as simply a one-time event, effective risk communicators understand the likelihood that additional interactions will be required; consequently, today's efforts to improve relationships and increase trust will help to lay the groundwork for positive future interactions."}