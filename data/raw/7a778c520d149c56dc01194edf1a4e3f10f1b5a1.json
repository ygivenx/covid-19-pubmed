{"title": "Infrared Thermography and Soft Computing for Diabetic Foot Assessment", "body": "Medical infrared thermography (MIT) is a technology which has its roots dating back to 400 BC when, change in body heat was considered as an indication of an underlying medical condition [1] . The following section is a briefing of infrared thermography and related terms.\n\nInfrared thermography is a graphical representation of heat.\n\nThermogram: The picture produced by infrared thermography, using photographic film sensitive to infrared radiation or the record produced by a thermograph.\n\nRadiation: Transfer of energy through electromagnetic waves.\n\nThe types of thermography are contact thermography (using liquid crystals), remote sensing thermography (using IR optical and detector system) and computer assisted thermography (using modern robust thermal imaging cameras) [1] [2] [3] . Different types of imaging methods based on infrared radiation are static, dynamic (DAT, subtraction), dynamic (active), TTM (thermal texture mapping), multispectral/hyperspectral, multimodality, and sensor fusion.\n\nMedical infrared thermography (MIT) has gained importance in the recent years because of the following factors:\n\n1. Thermal imaging is less sensitive to light and hence poor illumination does not pose any adverse effect on the image. 2. Temperature as a tool for diagnosis has shown promising results in the early detection of many diseases like breast cancer, rheumatoid arthritis, osteoarthritis, Raynaud's syndrome, and so on.\n\n3. Surface temperature distribution of an object under study can be easily obtained over a wide area in just one click of a thermal imager. 4. The patients are not subject to any harmful radiation from the imaging equipment as infrared thermography is noninvasive, noncontact, and nonradiant. 5. With the improvements in thermal sensing equipment and software image processing capabilities, computer aided diagnostic system is feasible and accurate.\n\nInfrared radiation is an electromagnetic wave emitted by any object above absolute zero. It is just next to the visible spectra in the electromagnetic spectrum with its wavelength in the range 0.7 to 1000 \u03bcm.\n\nThe important characteristics of thermal infrared images are resolution, noise, spectrum, and dynamic range. Fig. 1 shows the thermal infrared sensing detectors (focal plane array) of dimension 320 \u00c2 240 producing a thermal image of 320 \u00c2 240 pixels. The thermal infrared image is shown in Fig. 2 . Each pixel in the image shows the surface temperature detected at that point. Thus the image represents the temperature distribution across the surface of the object imaged. The variation in temperature is depicted using different colors as seen in the temperature scale.\n\nHere dark color represents lower temperature and light color higher temperature.\n\nHorizontal number of pixels 1 1 \n\nNoise in the thermal image limits the camera sensitivity to detect targets of weak contrast. This is characterized by noise equivalent temperature difference (NETD) and minimum resolvable temperature difference (MRTD).\n\nGood sensitivity and pixel count ensures that the image contains good thermal and spatial detail and hence good diagnostic ability.\n\nThe entire spectral band of Infrared is subdivided into five regions based on the wavelength range. The wavelength of near infrared (NIR) is between 0.7 and 1.0 \u03bcm, short wave infrared is between 1 and 3 \u03bcm, mid wave infrared between 3 and 5 \u03bcm, long wave infrared between 8 and 14 \u03bcm and very long wave infrared having wavelength > 14 upto 1000 \u03bcm.\n\nThe spectrum we are concerned lies in the long wave infrared (LWIR) region corresponding to 8-14 \u03bcm as human body radiates most at 10 \u03bcm.\n\nHigher temperatures mean higher wavelengths and thus in the thermal infrared image, hot areas are shown bright and at very high temperatures, the region is shown as white because of the emission of green and blue light at higher wavelengths. Human skin has an emissivity in the range of 0.98 which matches the emissivity of a perfect blackbody. Hence a modern day thermal imager with high sensitivity to infrared radiation can effectively measure the temperature of the object imaged. Also it has been shown that there is a correlation between the temperature of the object and the infrared energy radiated from the surface of the object.\n\nIt represents the capability of the camera to maintain the finer radiometric measurements even when the temperature spans a large range in the image captured. So a captured thermal infrared image should not have temperatures varying by >30\u00b0C as pointed out in Ref. [3] . The nominal for medical infrared thermography is 12 bits per pixel. The typical characteristics of a thermal image and testing of the same is explained by Houdas and Ring [4] .\n\nRing [5] has studied the development of temperature measurement in medicine and the use of thermography to visualize the spatial and temporal patterns of surface temperature of man in states of health and disease over a period of 25 years. During 1934 to 1936, Hardy [6, 7] studied the physiological role of infrared emission from human body and proposed that human skin can be considered as a blackbody radiator. This heat radiation from the body surface can be detected through the use of a thermal imaging camera. Ring et al. has presented in detail the physics behind infrared thermal imaging in Ref. [8] . Thermal infrared imaging works by capturing the infrared radiation emitted from various regions of the body as temperature readings spontaneously. Every part of the body has a specific thermal pattern associated with it based on the microcirculation near skin surface. Thus thermal imaging can be used to monitor the changes in the temperature profile of a particular region with respect to time.\n\nThe quantification of medical infrared thermal images for early diagnosis of human pathological conditions has been attempted by many researchers as presented in Ref. [9] . The list of diseases where digital infrared thermal imaging (DITI) is used is given in Table 1 .\n\nThere are many successful computational techniques in diagnosis and detection of medical conditions such as breast cancer [10] as shown in Fig. 3A and B, diabetic foot and osteoarthritis, in effectively screening potential severe acute respiratory syndrome (SARS) patients, in the analysis of cortical perfusion during ischemic strokes, in the segmentation of the eye and cornea and also in the detection of glaucoma from ocular thermographic images as observed in Ref. [11] . A typical diagnostic system using medical infrared thermography, image processing, and soft computing is shown in Fig. 4 . An IR thermal image captures the infrared energy radiated from the surface of the skin or any other object above absolute zero. The salient feature of thermography is its ability to image the thermovascular appearance of the skin and not the structure and anatomy of the human body which is done by many other medical imaging modalities. Jones and Plassman [12] details the journey of the improvements in thermal imagers, how an IR image is formed, processed, and analyzed for detective the changes in response to different stimuli like cool temperatures. Izhar in his thesis [13] describes the registration and analysis of thermal images in medicine. Oliver Faust et al. [14] have given a review of algorithms used for computer aided diagnosis systems using thermography. But most of these do not make use of soft computing techniques for the processing of the infrared thermal images. Herry and Frize in their work [15] present techniques to de-noise the infrared images, to remove the background from the infrared images to identify the regions of interest and statistical analysis of the ROIs to classify normal and abnormal temperatures. \n\nThis chapter focuses on the use of medical infrared thermography and soft computing particularly deep learning for diabetic foot assessment. Diabetic foot complications are a major cause of concern for diabetic patients as it affects mobility and quality of life. At present, any patient suffering from diabetes for five or more years in the case of type 1 diabetes and patients diagnosed with type 2 should undergo foot evaluation to prevent any foot complication such as ulcer or peripheral neuropathy. This requires the patient to visit the foot evaluation clinic in regular periods usually 3 months in the case of at risk patients, 6 months with patients involving other diabetic complications and peripheral arterial disease and 1 year for regular foot evaluation. This is cumbersome looking at the money and time involved. Many patients avoid or ignore the visit. This later converts to foot or toe amputation which can be avoided if computer aided diagnosis system is available at home as an app in mobile or for telemedicine purposes. For such a system, image processing has to be done automatically and abnormality has to be detected immediately that suggests treatment or visiting the clinic. This is where machine learning comes into play as image processing for the extraction of abnormal regions, grading the level of complication and for decision making to suggest further action such as suggesting the patient to visit the foot evaluation clinic and get the treatment done or later for telemedicine. Hence we studied the surface temperature distribution (STD) patterns in the plantar foot of both diabetic and healthy subjects to establish the differences in temperature capable to early diagnosis of the complication and we are looking forward to building a diagnostic system to detect and assess diabetic foot complications early to prevent amputation.\n\nThe broad objective of this research is to design an intelligent system to auto detect the onset and assessment of foot complications caused by diabetes and to improve the early diagnosis of the same. It is based on the analysis of IR thermal images of the regions of interest of the foot. The main objectives are\n\n(1) Study of surface temperature distribution in the plantar foot of diabetic and normal subjects to evaluate the potential of thermography for early diagnosis of type 1 and type 2 diabetic complications. (2) Design of an automated intelligent assessment system for diabetic foot complications using the aid of digital image processing techniques and artificial neural networks. (3) Correlation between the existing clinical methods for foot evaluation and the evaluation done by thermography will be carried out to establish the usefulness and accuracy of the system built.\n\nBagavathiappan et al. [17] have studied the correlation between diabetic neuropathy and plantar foot temperature proving the capability of thermography in detecting diabetic neuropathy. Br\u00e5nemark et al. [18] observed the temperature distribution patterns of hands and feet for both nondiabetic and diabetic subjects. Bharara et al. [19] formed a healing wound index based on the thermal profile of foot wound of diabetic patients. This helps in studying the healing pattern of the diabetic foot complication to suggest treatment. Peregrina-Barreto et al. [20] studied the temperature pattern of diabetic patients and have analyzed the same using angiosome concept. They have divided the entire foot into four regions corresponding to four angiosomes, a concept derived by Nagase et al. Estimated temperature difference between the left and right foot was calculated to carry out the analysis. Also, the classification of the thermal patterns is done for each of the four regions based on seven classes derived. They concluded that the estimated temperature difference did not show any difference useful for analysis and that the HSE (hot spot estimator) was capable of detecting hot spots which would turn out to be ulcer later which the ETD (estimated temperature difference) was not able to. Hernandez-Contreras et al. [21] were able to observe the butterfly pattern associated with nondiabetic subjects. They formulated an index called the TCI (thermal change index) based on the temperature readings of the corresponding angiosomes of diabetic and nondiabetic subjects. They concluded that a change of 1\u00b0C was sufficient to identify various thermal classes. No statistical analysis was done for the data. Liu et al. [22] were able to detect abnormal regions in the foot of diabetic patients using the temperature difference between the ipsilateral and contralateral foot with a cutoff of 2.2\u00b0C. Automatic segmentation and registration of the foot was carried out and then the temperature difference between the left and right foot was calculated. But the methodology followed to calculate the temperature difference was not explained. In this work, a new methodology is proposed to analyze accurately the temperature distribution in healthy and diabetic subjects. Renero-C [23] has observed abrupt changes in temperature using thermography to detect possible diabetic foot ulcer formations. Gatt et al. [24] demonstrate that the probability of complications of PAD, neuropathy, and/or neuroischaemia being present increases as the temperature of these regions rises. A narrative review on the various techniques used for diabetic foot complications based on asymmetry analysis, stress test and temperature distribution analysis is given by Hernandez-Contreras et al. [25] .\n\nThe work done so far is shown in the flow chart (Fig. 5) . \n\nSixty-two diabetic patients (38 male and 24 female) and with diabetes mellitus, and 20 nondiabetic subjects with an average age of 42 years, standard deviation 12 years. Few patients had or was having diabetic foot complications and other patients had healthy foot. We imaged the diabetic subjects at the Karnataka Institute of Endocrinology and Research (KIER), Bangalore, India after taking informed consent for the study. KIER's Institutional Ethical Committee approved the study. So, all ethical considerations were met.\n\n\u2022 Adult male or female, 18 years of age or over.\n\n\u2022 Diagnosed with type 1 or type 2 diabetes. \u2022 Is healthy without diabetes. \u2022 Currently receiving treatment for a diagnosis of diabetic foot ulcer or have had an active foot ulcer healed within the last 6 months. \u2022 Is willing and able to provide informed consent indicating that they understand the purpose and procedures required for the study.\n\n\u2022 Subjects who do not meet the inclusion criteria.\n\n\u2022 Is currently enrolled in another clinical trial.\n\nImage acquisition protocol plays an important role in infrared thermography.IR thermal image or the thermogram acquisition should be done in a controlled environment after considering the various factors briefed in Ref. [26] . IR thermal image acquisition of human foot is discussed in Ref. [27] where the different imaging setups for thermal infrared image acquisition of foot and its influence on the accuracy of the segmentation of the foot for further analysis to detect diabetic foot ulcer is analyzed.\n\nThe healthy subjects were imaged in the college laboratory and the diabetic subjects were imaged at KIER (Karnataka Institute of Endocrinology and Research, Bangalore). Informed consent was taken from all the patients involved in the study.\n\nThe thermal images of healthy foot are segmented using the method (Otsu thresholding followed by morphological processing) explained by Sudha et al. [27] . For diabetic patients, active contours without edges method for segmentation given by Chan and Vese [28] is used.\n\nIf the segmented region extends beyond the edges of foot, it is removed using morphological processing. The morphological operation used is closing.\n\nFor colder toes and for diabetic patients with amputation, the aforesaid methods do not work well. For such images, roipoly function in MATLAB is used to interactively segment the left and the right foot approximated by a polygon. This morphological processing is similar to the process discussed in Ref. [29] by Zohora et al.\n\nBut the problem in the segmentation method [27] was the segmentation of the toes region when it was cold and when the subjects had existing complications like ulcer. Hence we explored another acquisition procedure where we had cut two holes in the polyurethane foam with density 30 kg/m 3 at the bottom of the foam. This made sure that patients need not insert their foot in the holes as required previously but to just keep the foam on the ankle region from the top when the subjects are lying in supine position as seen in Fig. 6 . The foot is segmented automatically using a mask fixed in position for the left foot and right foot as shown in Fig. 7A and B. Then supplying this mask to the active contours function, the foot is segmented as shown in Fig. 7C .\n\nThe main advantage of using a left and right mask for segmentation is to automate the process of segmentation of the foot for all images contained in a folder. All the images obtained on a particular day are saved in the same folder. We have written a matlab script to read the images, save it in a variable and using the mask defined. This saves lot of time and energy when compared to manual or semiautomated segmentation where human intervention is required to define the initial contour for segmentation. The segmented foot is also saved in the same folder with the same filename as the thermal image with \"_mask\" added to the filename.\n\nNow the segmented feet are not the exact same mirror images of each other since both are not aligned with respect to each other as can be seen in Fig. 8A . The left and right foot has to be aligned to do the comparison of the temperature values. Hence, both the foot has to be registered to do the same. This is done using the following process. The mirror image of the segmented right foot is computed. Using this as the reference image, the left foot is registered. The registered left foot can be seen in Fig. 8B as magenta colored foot\n\nOnce we have the segmented foot, the next step is the extraction of ROI to perform the analysis.\n\nFor this process we have split each plantar foot into six regions-the hallux or the bigger toe, other toes region (corresponding to the 2nd to the 5th toe), the plantar arch region, lateral foot region in the middle and the heel-inner and outer regions similar to that given by Hernandez-Contreras [30] . The regions are shown in Fig. 9 . A bounding box is drawn around each of the foot to separate them.\n\nFor each of the regions in the bounding box, the mean temperature, the max temperature, the mean temperature difference and correlation between the corresponding regions of each foot are computed for further analysis.\n\nStatistical features such as mean temperature difference (MTD) and correlation between the corresponding pixels in the left and right foot are extracted after careful processing to take into account that the left and right feet are mirror images of each other. A hot region in diabetic patients is a characteristic feature of inflammation or the presence of ulcer. Fig. 10A shows the extracted hot regions as white patches. Fig. 10B shows the infrared image of a diabetic patient. The gray color in Fig. 10C The multilevel threshold that works best for extracting the cold regions is calculated using the following formulas (Eqs. 2,3).\n\nThe difference in the regions extracted by the built in multithresholding function and our method can be easily visualized from Fig. 10C , D and G, H.\n\nThe features extracted are analyzed for each of the six regions. Table 2 shows the MTD for four diabetic and four healthy subjects. Table 3 shows the correlation between the corresponding left and right foot regions.\n\nThe correlation coefficient \"r\" is calculated between the corresponding regions (matrix A) of the left foot and right foot (matrix B) using the formula given in Eq. (4): \n\nwhere A\u0305 \u00bc mean (A) and B\u0305 \u00bcmean (B). m and n are the size of the region given as m \u00c2 n pixels. This is a valuable measure as it represents a spike in some temperature reading in the region being analyzed. Thus correlation between the left and right foot regions for diabetic subjects remain low in all the diabetic subjects analyzed. It was in the range of 0.4 to 0.8, low correlation in the region where there is an underlying complication present or building up. So this ensures that the most problematic region is not missed.\n\nNeural networks are efficient in handling many of the issues faced by other architectures such as images corrupted by noise, degraded, and distorted images. Both similarity and dissimilarity between images can be figured out by neural nets. Also, the effective use of parallel processing can be leveraged to neural network architecture with much ease, hence reducing computation time. Features extracted from medical images are very subjective. As features are not hand crafted and learning happens in an unsupervised manner, it is very suitable to avoid any bias in reading the temperature values. Also, the ability to learn new features automatically enhances the accuracy of classification.\n\nDeep learning is effective when we have a huge dataset which is very much limited in the case of medical domain and particularly with thermal imaging. For such small datasets, it is still possible to use Deep Convolutional Neural Networks which was pretrained on large datasets using natural images. The power of CNNs can be leveraged to small datasets using the concept of transfer learning as pointed out in Ref. [31] . We have explored the use of pretrained deep learning convolutional neural network (CNN) model called the Mobilenet model [32] to classify the foot images as healthy, diabetic without complications and diabetic with complications. Training a deep learning model from scratch will take days. But a pretrained model can be retrained for our own problem in few hours. It took just few seconds for our problem on a 1060 GPU. The evaluation/classification time taken on the machine for a single image is 0.05 s on an average. We have used the Tensorflow library and the mobilenet architecture for the same. This is a preliminary study to evaluate and understand the applicability of CNN model to thermal infrared images and it has shown promising results. Fig. 11 shows the steps involved in the using the pretrained model for our classification problem. Fig. 12 shows the three classes of images that the model is trained on: the diabetic with complications, diabetic without complications and healthy subjects without diabetes.\n\nOut of the 62 images captured from diabetic patients, 50 patients were without existing complications and 12 were with existing complications. There were 20 images in the healthy category.\n\nData augmentation: As this is a very small dataset, we considered augmenting the dataset with more data and since this is medical data, we cannot synthesize new data. Hence, we considered taking the different palette images for any given image. For example for a single image taken from a diabetic patient, the images in rainbow palette, hot metal, and ironbow palette were taken. Thus we have three different images for the original image. This gave a threefold increase in the number of images. Thus the total images in Diabetic without complications is 150, diabetic with complications is 36 and healthy is 60. There has been success in using various soft computing techniques such as ANN, Na\u00efve Bayes, SVM and k-Nearest Neighbour for classification of thermograms as shown by Dey et al. [33] . The work in Ref. [34] highlights the use of convolutional neural network for segmenting the pressure areas to reconstruct the shoe last surface for designing shoes for diabetic foot.\n\nWe would be validating the results with the classification results obtained from clinical data.\n\nEven though there is a reappraisal of MIT, there are many challenges posed to this technology. The challenges are briefed in the following section.\n\nThere are no generic databases of thermal infrared images for various medical complications which are readily available for researchers to explore in comparison to visual images. Hence thermal image acquisition is a very important initial step to carry out any research on thermal infrared images.\n\nAccurate segmentation of the ROI and hence early detection of any abnormality in the human physiology from a thermal/infrared image is possible with accurate measurement of temperature. Accurate measurement of temperature is a direct result of good quality image acquired under controlled environmental conditions which captures all the essential details required for the analysis. Hence image acquisition plays a very important role in medical image analysis. This is clearly evident in the research work presented by Sudha et al. [27] where the thermal image acquisition of foot is carried out to segment the foot from the background. In this paper, authors have analyzed three different setups for acquiring thermal images of the foot and have discussed the influence of these on the accuracy of segmentation. The results show that acquisition protocol influences the result of image processing and hence has a pivotal role to play when it comes to efficient use of infrared thermography in medical image analysis. The thermal imager selected for the medical image analysis should have high sensitivity to pick up those minute differences in temperature that suggests an abnormality.\n\nA whole lot of factors that influence the use of infrared thermography in humans have been classified in the review [26] as environmental, individual and technical factors. These factors should be taken into consideration for the effective processing of the thermal infrared images. Often it is very difficult to take care of all these factors while using infrared thermography. The most influential being the ambient temperature, relative humidity, source radiation, camera features, ROI selection, statistical analysis, medical history, metabolic rate, skin blood flow, intake factors and physical activity. Temperature measurements should ideally be accurate to within a AE 2% margin in order to get the best results.\n\nA detailed discussion of the challenges to medical infrared imaging is presented in Ref. [3] . Thermal reflections and occlusions are a problem with thermal infrared images. The identification and suppression of these reflections is explained in Ref. [35] .\n\nOne important factor when it comes to image processing these days which is not included in the previous set of factors is the hardware requirements. With the advancement of technology and software computing capabilities, there is a compelling need to improve the features of the underlying hardware to support high dimensionality as is the case of deep learning systems. This is becoming a basic requirement in the case of image processing using deep learning architectures. Graphical processing units (GPU) with parallel architectures are the way forward for deep learning systems built to analyze thermal images. Since deep learning is very computationally intensive, we will need a fast CPU with many cores.\n\nFor infrared thermography to be effective the amount of heat that still exists after the heating or cooling of the object under study should also be considered.\n\nThe research challenges in medical infrared imaging are as follows:\n\n\u2022 Stability and sensitivity of IR imaging systems. \u2022 Understanding of body thermal patterns.\n\n\u2022 Advanced IR image processing methods are required. \u2022 Design of CAD systems built on soft computing techniques and efficient feature extraction methods should be explored.\n\nThe chapter by Dey et al. [36] \"Thermal imaging in medical science\" gives a brief review of the current research activity in thermal imaging of breast cancer and future perspectives in MIT. Some of the recommended are\n\n\u2022 Development of an intelligent breast thermography diagnostic system based on neural network. \u2022 Improvement in processing, segmentation, and classification of thermal images should be carried out. \u2022 Advancements in image fusion techniques for better understanding of thermal image is required. \u2022 Improvement in terms of sensitivity and specificity of thermography in diagnosing various medical conditions is required. \u2022 Automation of edge detection and object identification is still a difficult and challenging task. \u2022 Security in transmission of thermal images has to be studied. The work by Dey et al. [37] can be considered for watermarking the images. \u2022 Removal of noise to improve accuracy in medical diagnosis should be researched.\n\nIt is clearly evident that medical infrared thermography and soft computing will revolutionize the way healthcare is provided to people in the future. Telemedicine will also gain importance with the use of this technology. Gunes [38] studied the systems for dimensional affect recognition in multiple modalities including thermal signals represented as thermal image and found out that thermal imaging could be used to classify pretended and evoked facial expressions of positive and negative affective states.\n\nFollowing are the issues to be addressed in building intelligent diagnostic systems by Deeplearning architectures for automated analysis of medical thermal images.\n\na. Building a large database to cater to the needs of the deep learning system is difficult.\n\nSo data augmentation and other techniques to synthesize data have to be evaluated and suitable technique should be considered. b. Gathering of expert knowledge to form the fuzzy rules for feature selection has to be carefully done to effectively classify the images.\n\nc. Lack of medical and bio-thermal knowledge has to be covered by discussion with medical experts. d. Reproducibility of the images is a great concern due to the large set of factors involved. e. Takes long time for the entire process from thermal image acquisition stage to the classification stage as it required repeated capturing of images in particular time gaps. f. Identifying the best deep learning architecture for good accuracy in classification.\n\nThe performance of the segmentation algorithm is evaluated using Jaccard index, RFN (rate of false negatives) and RFP (rate of false positives).\n\nJaccard index is a similarity coefficient which measures the similarity of sets based on the formula:\n\nwhere GT represents the ground truth (manually segmented image in our case) and SI represents the segmented image (using morphological operations).\n\nRFN and RFP is calculated using the formula\n\nwhere FN is false negative (foreground/white pixels included as background/black pixels or omitted foreground pixels), FP is false positive (black/background pixels included as white/ foreground pixels), TN is true negative (background/black pixels identified correctly) and TP is true positive (foreground/white pixels identified correctly).\n\nThe segmentation method proposed here and performance evaluation of the method is implemented in MATLAB R2016a. The evaluation of our segmentation method for 15 diabetic subject images based on the three measures is given in Table 4 .\n\nFrom Table 4 , it can be observed that the segmentation of the foot from the background is comparable with the ground truth. But there is still scope for reducing the False Positives, False Negatives, and the Jaccard Index. High FPs is a result of white pixels which should not be part of the segmented result as in the case of image 3 in the table. This is because the toes are cold and the temperature of the background matches with the other part of the foot and hence it becomes part of the segmented image making the count of white/foreground pixels to increase. Also, FNs in image 8 is high because of cold foot with temperatures merging with the background. Thus, the count of black/background pixels increase which contribute to higher FNs. To improve the accuracy further, we are planning to explore the use of deep learning for the segmentation task also.\n\nThe outcome of the analysis done is as follows:\n\n\u2022 The STD is symmetrical across all the corresponding regions in left and right foot in healthy subjects. \u2022 The temperature is considerably high at the region 3 (plantar arch) owing to the butterfly pattern and is at least 1.5\u00b0C higher compared to the other regions for a particular foot. This is vice versa in the case of patients with diabetic foot complications where the temperature was higher in the region of complication. \u2022 The temperature difference of 2.2\u00b0C was observed in the presence of foot complication. \u2022 Correlation coefficients between the left and right foot is >0.8 in the case of healthy subjects and it is less in the range of 0.4 to 0.7 in most of the diabetic subjects. Since this range is mutually exclusive between the diabetic and healthy subjects, correlation coefficient is a very good indicator of abnormal thermal pattern. When the patient has good diabetic control, then the correlation is equivalent to that of healthy subject as can be seen in the first two diabetic subjects in Table 3 . \u2022 The right foot had the maximum temperature in the regions 1, 2, and 3 compared to the left foot in all the subjects both healthy and diabetic. This explains why right foot is the most common site for diabetic foot problems. Plantar foot temperature varies in diabetic foot due to thermoregulation problems related to neuropathy and/or ischemia, and also in case of inflammation. There is a wider variation in diabetic patients compared to healthy subjects. Region 3 shows the maximum temperature in two nondiabetic subjects as expected in the arch region where a butterfly pattern is a characteristic of healthy foot as shown in Fig. 13 .\n\nThere was significant difference in temperature in the regions corresponding to each foot whenever there is an abnormality. Registration is approximate in the sense that when the big toe is amputated, the bounding box heights differ and hence the regions are not properly segmented. The hot and cold regions extracted from the images suggest the location of an underlying inflammation or the extent of inflammation if present already in the case of ulcer or the presence of neuropathy. The isolation of these regions will help the doctor in identifying the underlying angiosome for assisting in therapy or surgery. The dataset used is small and it has to be built with more images so that the analysis is more accurate. The next step is to build such a dataset. Segmentation of the foot from the background posed problems in the case of diabetic patients when the toes were cold. Hence we are looking forward to build a deep learning network to do the segmentation.\n\nA typical output from the classification of a test image using the CNN classifier is shown in Fig. 14. This shows that the image given to the model is classified as a diabetic foot without any complication with a probability of 87.43% which is very high compared to the next two predictions which is healthy with 7.73% and diabetic with complication with 4.82%. This clearly shows that the model is able to distinguish between different categories with greater confidence. This prediction is correct for the given image. Similarly by testing all the images, we got an average accuracy of 91% for each of the classes. This is really amazing given the fact that thermal imaging is totally different from any other imaging modality and the model is pretrained on natural images ($1,42,000 images).\n\nThis preliminary study assures us that we could use deep learning for our problem also. We are planning to build such a model from scratch to have more control over the parameters to fine tune the classification and to quantify the level of complication as different categories.\n\nIn the days to come our focus would be on the following:\n\n\u2022 Explore the use of deep learning for segmentation of the foot from background.\n\n\u2022 Build a mathematical classification model based on the quantification of risk of ulcer formation. \u2022 Build a software system using all the image processing and classification work carried out for the early diagnosis and quantification of the diabetic foot complications. \u2022 Correlate with the existing clinical foot evaluation methods to evaluate the system built and its applicability for use as a home monitoring tool for diabetic foot. \u2022 Develop a mobile application capable of using as an adjunct tool for telemedicine and home monitoring of diabetic foot complication.\n\nMedical Infrared Thermography being noninvasive and noncontact has the special ability to diagnose human physiology due to heat transfer in skin tissues. With the special characteristics and advantages of thermal imaging, computer aided diagnosis systems are becoming more and more accurate and effective. The advancements in image processing, feature extraction and selection and soft computing techniques like deep learning in combination with improvements in parallel computing architectures have paved way for more interest and importance to research in this imaging modality. The soft computing techniques used mostly are artificial neural networks, SVM and genetic algorithm with texture based features for most of the classification task. But the most effective ones are the mean temperature difference and correlation. With more computing power and capability of the recent systems and the reappraisal of thermography in medicine, we shall see more advances in deep learning in the years to come. Thermography is being recognized as an adjunct tool for detecting abnormality in the temperature profile of patients to uncover an underlying disease or inflammation. The advantage of being noncontact and noninvasive makes it a safe diagnostic imaging technique. This chapter emphasizes the use of existing soft computing techniques coupled with the specific characteristics of infrared thermography making it more efficient and safe. The authors' current work on automated foot thermal image analysis for diabetic foot assessment is also discussed and future research directions are also given."}