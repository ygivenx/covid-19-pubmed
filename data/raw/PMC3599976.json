{"title": "A mixed integer linear programming model to reconstruct phylogenies from single nucleotide polymorphism haplotypes under the maximum parsimony criterion", "body": "\u2013 The Phylogeny Estimation Problem (PEP)\n\noptimizef(T)s.t.g(H,T)=1T\u2208T,\n\nwhere T a phylogeny of\nH,T the set of all possible phylogenies of\nH,f:T\u2192R a function modeling the selected criterion of phylogeny estimation, and\ng:H\u00d7T\u2192R is a characteristic function equal to one if a phylogeny T is compatible (according to the selected criterion) for the set\nH. A specific optimization problem is completely characterized by defining the functions f and g, and the phylogeny T\u2217 that optimizes f and satisfies g is referred to as optimal.\n\nOne of the classic criteria for phylogeny estimation is the parsimony criterion, which assumes that one taxon evolves from another by means of small changes and that the most plausible phylogeny will be that requiring the smallest number of changes. That evolution proceeds by small rather than smallest changes is due to the fact that the neighborhood of possible alleles that are selected at each instant of the life of a taxon is finite and, perhaps more important, that the selective forces acting on the taxon may not be constant throughout its evolution\n[12,13]. Over the long term (periods of environmental change, including the intracellular environment), the accumulation of small changes will not generally correspond to the smallest possible set of changes consistent with the observed final sequences. Nevertheless, it is plausible to believe, at least for well-conserved molecular regions where mutations are reasonably rare and unlikely to have occurred repeatedly at any given variant locus, that the process of approximating small changes with smallest changes could provide a good approximation to the true evolutionary process of the observed set of taxa\n[14]. Such an assumption is likely to be reasonable, for example, in intraspecies phylogenetics, where few generations have elapsed since the observed taxa shared a common ancestor and thus the expected number of mutations per locus is much less than one. When such assumtions hold, a phylogeny of\nH is defined to be optimal under the parsimony criterion if it satisfies the following requirements: (i) it has the shortest length, i.e., the minimum sum of the edge weights, and (ii) it is such that, for each pair of distinct haplotypes\nhi,hj\u2208H, the sum of the edge weights belonging to the path from hi to hj in T\u2217 is not smaller than the observed number of changes between hi and hj[11]. The first condition imposes the assumption that the smallest number of mutations consistent with the observed sequences is a good approximation to the true accumulated set of mutations; the second condition correlates the edge weights to the observed data.\n\nThe parsimony assumption can be considered accurate in the limit of low mutation rates or short time scales, making it a reasonable model for situations such as analysis of intraspecies variation where little time is presumed to have elapsed since the existence of a common ancestor of all observed taxa. Maximum parsimony also remains valuable as a model for novel methodology development in phylogenetics because of its relative simplicity and amenity to theoretical analysis. Novel computational strategies, such as those developed in this paper, might therefore productively be developed and analyzed in the context of maximum parsimony before being extended to more complicated models of phylogenetics.\n\nFinding the phylogeny that satisfies the parsimony criterion involves solving a specific version of the PEP, called the Most Parsimonious Phylogeny Estimation Problem (MPPEP). Some of the variants of the MPPEP, see e.g.,\n[15,16], can be solved in polynomial time, however, in the most general case, the problem is\nNP-hard\n[11,17] and this fact has justified the development of a number of exact and approximate solution approaches, such those described in\n[11,17,18]. Some recent versions of the MPPEP, such as the Most Parsimonious Phylogeny Estimation Problem from SNP haplotypes (MPPEP-SNP) investigated in this article, play a fundamental role in providing predictions of practical use in several medical bioinformatics applications, such as disease association studies\n[19] or reconstruction of tumor phylogenies\n[20,21]. In these contexts, it would be highly desirable to have the most accurate inferences possible for specific applications, but this in turn would imply to have algorithms able to exactly solve instances of such versions. As regards the MPPEP-SNP, the literature describes some (rare) circumstances for which it is possible to solve the problem in polynomial time (see Section Methods). Unfortunately, in the general case the MPPEP-SNP is\nNP-hard and solving provably to optimality therefore generally requires the use of exact approaches based on implicit enumeration algorithms, similar to the mixed integer programming strategies described in\n[1,2,22].\n\nIn this article, we explore the prospects for improving on the implicit enumeration strategy of\n[1,2] using a novel problem formulation and a series of additional constraints to more precisely bound the solution space and accelerate implicit enumeration of possible optimal phylogenies. We present a formulation for the problem based on an adaptation of\n[23]\u2019s mixed integer formulation for the Steiner tree problem extended with a number of preprocessing techniques and reduction rules to further decrease its size. We then show that it is possible to exploit the high symmetry inherent in most instances of the problem, through a series of strengthening valid inequalities, to eliminate redundant solutions and reduce the practical search space. We demonstrate through a series of empirical tests on real and artificial data that these novel insights into the symmetry of the problem often leads to significant reductions in the gap between the optimal solution and its non-integral linear programming bound relative to the prior art as well as often substantially faster processing of moderately hard problem instances. More generally, the work provides an indication of the conditions under which such an optimal enumeration approach is likely to be feasible, suggesting that these strategies are usable for relatively large numbers of taxa, although with stricter limits on numbers of variable sites. The work thus provides methodology suitable for provably optimal solution of some harder instances that resist all prior approaches. In future work, it may provide useful guidance for strategies and prospects of similar optimization methods for other variants of phylogeny inference.\n\nThe Most Parsimonious Phylogeny Estimation Problem from SNP haplotypes (MPPEP-SNP).Given a set\nH of n haplotypes having m alleles each, find the minimum cardinality haplotype set\nH\u2032 to be added to\nH so that the phylogeny\nT\u00af\u22c6 has minimum length.\n\nIf the haplotype set\nH\u2032 is empty, i.e., if\nG=(H,E) is connected, then MPPEP-SNP can be solved in polynomial time as the minimum spanning tree is a (optimal) solution to the MPPEP-SNP. Similarly, if the input haplotype set\nH satisfies the perfect phylogeny condition i.e., the requirement that each allele changes only once throughout the optimal phylogeny (see\n[19]), then the MPPEP-SNP can be still solved in polynomial time\n[26-28]. Unfortunately, it is possible to prove that in the general case the MPPEP-SNP is\nNP-hard (see\n[1,22]). In fact, the binary nature of the SNP haplotypes allows us to interpret a generic haplotype\nhi\u2208H as a vertex of a m-dimensional unit hypercube, its s-th allele as the s-th coordinate of the vertex hi, and the set\nH\u2032 as the set of Steiner vertices of the unit hypercube. Hence the MPPEP-SNP can be seen as particular case of the Steiner tree problem in a graph, a notorious\nNP-hard combinatorial optimization problem\n[29].\n\nFinding the optimal solutions to the MPPEP-SNP is fundamental to validating the parsimony criterion, i.e., to verify whether, for a given instance of MPPEP-SNP, the results predicted by the criterion match the experimental ones. Unfortunately, the\nNP-hardness of the MPPEP-SNP limits the size of the instances analyzable to the optimum, which in turn affects the ability to validate the parsimony criterion, hence the practical utility of the predictions themselves. In order to address this concern, in the following section we shall develop an integer programming model able to provide optimal solutions to real instances of the MPPEP-SNP.\n\nBasic Model\n\n(1a)min\u2211i,j\u2208V:i\u2260j\u2211s\u2208Szijs\n\n(1b)s.t.xis=hi(s)\u2200s\u2208S,i\u2208H\n\n(1c)xis\u2264ui\u2200s\u2208S,i\u2208V\n\n(1d)zijs\u2265+xis\u2212xjs+yij\u22121\u2200s\u2208S,i,j\u2208V:i\u2260j\n\n(1e)zijs\u2265\u2212xis+xjs+yij\u22121\u2200s\u2208S,i,j\u2208V:i\u2260j\n\n(1f)\u2211s\u2208Szijs=yij\u2200i,j\u2208V:i\u2260j\n\n(1g)yij\u2264ui\u2200i,j\u2208V:i\u2260j\n\n(1h)yij\u2264uj\u2200i,j\u2208V:i\u2260j\n\n(1i)\u2211j\u2208V:i\u2260jyij\u2265ui\u2200i\u2208V\n\n(1j)\u2211i,j\u2208C:i\u2260jyij\u2264\u2211i\u2208Cui\u22121\u2200C\u2282V:C\u2229VH\u2260\u2205\n\n(1k)\u2211i,j\u2208V:i\u2260jyij=\u2211i\u2208Vui\u22121\n\n(1l)\u2211i\u2208Qui=n+LB\n\n(1m)ui,xis,zijs,yij\u2208{0,1}.\n\nThe objective function (1a) aims at minimizing the length of the optimal phylogeny. Constraints (1b) impose that the coordinates of the first n vertices in V are exactly the ones of the input haplotype set\nH. Constraints (1c) impose that the s-th coordinate of vertex ui, i \u2208 V, can assume value 1 only if vertex ui is considered in the optimal solution to the problem. Constraints (1d)-(1e) force variables\nzijs to be one if in the optimal solution to the problem there exist a pair of adjacent vertices ij \u2208 V having a different value at the s-th coordinate. Constraints (1f) impose that in an optimal solution to the problem two distinct vertices ij \u2208 V can be adjacent only if\ndhihj=1. Constraints (1g)-(1h) impose that in the optimal solution to the problem variable yij may assume value 1 only if both vertices i and j are considered. Vice versa, constraints (1i) impose that if in the optimal solution to the problem a vertex ui, i \u2208 V, is considered then at least one variable yij must assume value 1. Constraints (1j) and (1k) impose the Generalized Subtour Elimination Constraints (GSEC)\n[23]. Finally, constraints (1l) impose that the first n + LBvertices in V have to be considered in the optimal solution to the problem.\n\nNote that Formulation 1 can be easily extended to the case in which the haplotypes are represented by multi-character data, i.e., sequences over an alphabet \u03a3 = {0,1,2,\u2026,\u03b3}. In fact, in such a case it is sufficient to replace each character c in the haplotype by a binary \u03b3 -vector \u03bd such that the s-th coordinate of \u03bd is equal to 1 if the character c is equal to s, s \u2208 \u03a3, and 0 otherwise. For example, if the generic haplotype were, for example, the string \u2329AACGT\u232a, then it could be represented as \u23291000 1000 0100 0010 0001\u232a.\n\nReduced Model\n\n(2a)min\u2211i,j\u2208V:i,j\u2208Z\u2211s\u2208\u015cwszijs\n\n(2b)s.t.xis\u2264ui\u2200s\u2208\u015c,i\u2208R\n\n(2c)\u2211s\u2032\u2208\u015c:s\u2032\u2260szijs\u2032+hi(s)\u2212xjs\u22641\u2200s\u2208\u015c,i\u2208VH,j\u2208VH\u2032\n\n(2d)\u2211s\u2032\u2208\u015c:s\u2032\u2260szijs\u2032\u2212hi(s)+xjs\u22641\u2200s\u2208\u015c,i\u2208VH,j\u2208VH\u2032\n\n(2e)\u2211s\u2032\u2208\u015c:s\u2032\u2260szijs\u2032+xis\u2212xjs\u22641\u2200s\u2208\u015c,i,j\u2208VH\u2032:i,j\u2208Z\n\n(2f)\u2211s\u2032\u2208\u015c:s\u2032\u2260szijs\u2032\u2212xis+xjs\u22641\u2200s\u2208\u015c,i,j\u2208VH\u2032:i,j\u2208Z\n\n(2g)\u2211s\u2208\u015czijs\u22641\u2200i,j\u2208V\u2216R:i,j\u2208Z\n\n(2h)\u2211s\u2208\u015czijs\u2264ui\u2200i\u2208R,j\u2208V:i,j\u2208Z\n\n(2i)\u2211s\u2208\u015czijs\u2264uj\u2200j\u2208R,i\u2208V:i,j\u2208Z\n\n(2j)\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015czijs\u22651\u2200i\u2208Q\n\n(2k)\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015czijs\u2265ui\u2200i\u2208R\n\n(2l)\u2211i,j\u2208C:i,j\u2208Z\u2211s\u2208\u015czijs\u2264\u2211i\u2208C:i\u2208Rui+|CH|\u22121\u2200C\u2282V:C\u2229VH\u2260\u2205\n\n(2m)\u2211i,j\u2208V:i,j\u2208Z\u2211s\u2208\u015czijs=n+LB+\u2211i\u2208Rui\u22121\n\n(2n)ui,xis,zijs,yij\u2208{0,1}.\n\nNote that in Formulation 2 variables\nxis and\nzijs cannot be relaxed anymore.\n\nConstraints\n\n(3)ui+1\u2264ui\u2200i\u2208V\u2216(Q\u222a{n+UB})\n\nare valid for Formulation 2.\n\nIn a feasible solution to the problem variable ui, i \u2208 V\u2216(Q \u222a {n + UB}), can assume only value 0 or 1. If ui = 0, constraint (3) reduces to ui + 1 \u2264 0 which is trivially valid for Formulation 2. If ui = 1, constraint (3) reduces to ui + 1 \u2264 1 which is again valid. \u25a1\n\nConstraints (3) impose an ordering on the variables ui, i \u2208 R, so that vertex ui + 1 can be considered in the optimal solution to the problem only if vertex ui has been already considered.\n\nConstraints\n\n(4)\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015czijs\u22652ui\u2200i\u2208R\n\nare valid for Formulation 2.\n\nIn a feasible solution to the problem a vertex ui,\ni\u2208VH\u2032, cannot be a terminal vertex. In fact, if such a condition held, a cheaper solution could be obtained by dropping ui from\nT\u00af\u22c6, contradicting the optimality of\nT\u00af\u22c6 itself. Hence, the degree of any vertex in\nVH\u2032 must be at least 2. Now, in a feasible solution to the problem variables ui \u2208 {0,1}. If ui = 0, constraint (4) reduces to \n\n\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015czijs\u22650\n\n which is trivially valid. Vice versa, if ui = 1, constraint (4) reduces to \n\n\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015czijs\u22652\n\n which is again valid for the above arguments. \u25a1\n\nConstraints \n\n(5)+xis2\u2212xjs2\u22642(1\u2212zijs1)\u2212\u2211s\u2208\u015c:s\u2260s1zijs\u2200s1,s2\u2208\u015c:s1\u2260s2,i,j\u2208VH\u2032:i,j\u2208Z\n\n(6)\u2212xis2+xjs2\u22642(1\u2212zijs1)\u2212\u2211s\u2208\u015c:s\u2260s1zijs\u2200s1,s2\u2208\u015c:s1\u2260s2,i,j\u2208VH\u2032:i,j\u2208Z\n\nare valid for Formulation 2.\n\nAs observed in the previous proposition, in a feasible solution to the problem\n\u2211s\u2208\u015czijs,\ni,j\u2208VH\u2032, i,j\u2208Z, can assume only value 0 or 1. If\n\u2211s\u2208\u015czijs=0, then constraint (5) (respectively constraint (6)) reduces to\n+xis2\u2212xjs2\u22642 (respectively\n\u2212xis2+xjs2\u22642), which is trivially valid due to the integrality of variables\nxis. If\n\u2211s\u2208\u015czijs=1, then either\n\u2211s\u2208\u015c:s\u2260s1zijs=1 or\nzijs1=1. If\n\u2211s\u2208\u015c:s\u2260s1zijs=1 then constraint (5), (respectively constraint (6)) reduces to\n+xis2\u2212xjs2\u22641 (respectively\n\u2212xis2+xjs2\u22641), which is trivially valid. If\nzijs1=1 then constraint (5) (respectively constraint (6)) reduces to\n+xis2\u2212xjs2\u22640 (respectively\n\u2212xis2+xjs2\u22640), which is again valid. \u25a1\n\nSimilar arguments can be used to prove the following proposition:\n\nConstraints\n\n(7)+hi(s2)\u2212xjs2\u22642(1\u2212zijs1)\u2212\u2211s\u2208\u015c:s\u2260s1zijs\u2200s1,s2\u2208\u015c:s1\u2260s2,i\u2208VH,j\u2208VH\u2032\n\n(8)\u2212hi(s2)+xjs2\u22642(1\u2212zijs1)\u2212\u2211s\u2208\u015c:s\u2260s1zijs\u2200s1,s2\u2208\u015c:s1\u2260s2,i\u2208VH,j\u2208VH\u2032\n\nare valid for Formulation 2.\n\nGiven an input haplotype set\nH and a pair of non-adjacent haplotypes hi and hj, there exit multiple equivalent paths that may connect hi and hj in the unary hypercube. This characteristic constitutes the principal class of symmetries for the MPPEP-SNP and may lead to poor relaxations for the problem. For example, suppose that the input haplotype set\nH is constituted by haplotypes h1 = \u232900\u232a and h2 = \u232911\u232a. Then a possible solution to the instance may consist either of a star centered in haplotype h3 = \u232910\u232a or a star centered in haplotype h3 = \u232901\u232a(see Figure\n1). Note that both solutions are feasible and optimal for the specific instance. A possible strategy to break this class of symmetries consists of imposing the following constraints:\n\nConstraints\n\n(9)\u2211p=1s2s\u2212pxip\u2264\u2211p=1s2s\u2212pxi+1p\u2200s\u2208\u015c,i\u2208VH\u2032\u2216R\n\n(10)\u2211p=1s2s\u2212pxip\u2264\u2211p=1s2s\u2212pxi+1p+\u2211p=1s2s\u2212p(1\u2212ui+1)\u2200s\u2208\u015c,i\u2208R\u2216{n+UB}\n\nare valid for Formulation 2.\n\nThe statement trivially follows from the integrality of variables\nxis and from constraints (2b). \u25a1\n\nConstraints (9)-(10) impose an ordering on the coordinates of the vertices in\nVH\u2032 by means of the smallest big-M possible, i.e., a power of 2. Note that the distinction between constraints (9) and (10) is necessary, as in principle vertices in R may not be needed in the optimal solution to the problem.\n\nConstraints\n\n(11)\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015czijs\u2265\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015cz(i+1)js\u2200i\u2208VH\u2032\u2216{n+UB}\n\nare valid for Formulation 2.\n\nIn a feasible solution to the problem, the sum\n\u2211s\u2208\u015czijs,\ni,j\u2208VH\u2032, i,j\u2208Z, can assume only value 0 or 1. If\n\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015cz(i+1)js=0, constraint (11) reduces to\n\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015czijs\u22650 which is trivially valid. Vice versa, If\n\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015cz(i+1)js=1, constraint (11) reduces to\n\u2211j\u2208V:j\u2208Z\u2211s\u2208\u015czijs\u22651 which is again valid due to Propositions 1 and 2. \u25a1\n\nProposition 6 forces vertices in\nVH\u2032 to be sorted according to a decreasing degree order. In this way, it is possible to avoid the occurrence of symmetric solutions to the problem differing just for the degree of the Steiner vertices (see e.g., Figure\n2).\n\nLet\nQ3={i,j\u2208VH:dij\u22653} and k \u2208 V, k \u2209 Q3. Then the following proposition holds:\n\nConstraints\n\n(12)\u2211s\u2208Sziks+\u2211s\u2208Szkjs\u22641\u2200i,j\u2208Q3\n\nare valid for Formulation 2.\n\nIn a feasible solution to the problem the path between two distinct haplotypes\nhi,hj\u2208H cannot be shorter than the distance\ndhihj. Hence, if the distance between hiand hjis greater or equal to three, vertices i and j cannot be adjacent to a same vertex k, i.e., only one of the two sums\n\u2211s\u2208Sziks or\n\u2211s\u2208Szjks can be equal to 1. \u25a1\n\nNote that if k \u2208 R then (12) can be strengthened by replacing the right-hand-side by uk. Moreover, Proposition 7 can be generalized as follows. Consider the sets\nQd={i,j\u2208VH:dij\u2265d}, d \u2208 {3,4,\u2026,m}, C \u2282 V such that 2 \u2264 |C| \u2264 d \u2212 1 and C \u2229 Qd = \u2205, and a path p that involves only vertices in C. Denote pk the k-th vertex in p. Then the following proposition holds:\n\nThe family of constraints\n\n(13)\u2211s\u2208Szip1s+\u2211k=1|C|\u22121\u2211s\u2208Szpkpk+1s+\u2211s\u2208Szp|C|js\u2264|C|\u2200i,j\u2208Kd,\n\ncalled forbidden path constraints, are valid for Formulation 2.\n\nSimilarly to Proposition 7, in a feasible solution to the problem the path p between two distinct haplotypes\nhi,hj\u2208H cannot be shorter than the distance\ndhihj. Hence, if the distance between hi and hj is greater or equal to d, at most |C| vertices can belong to p. \u25a1\n\nWe implemented Formulations 1 and 2 by means of Mosel 64 bit 3.2.0 of Xpress-MP, Optimizer version 22, running on a Pentium 4, 3.2 GHz, equipped with 2 GByte RAM and operating system Gentoo release 7 (kernel linux 2.6.17). In both formulations, we computed the overall solution time to solve a generic instance of the problem as the sum of the preprocessing time due to the implementation of\n[22]\u2019s reduction rules plus the solution time taken by the Optimizer to find the optimal solution to the instance. In preliminary experiments, we observed that Formulation 2 has two main advantages with respect to Formulation 1, namely: it requires much less memory to load the model (at least 27% RAM less in the analyzed instances) and it is characterized by faster linear relaxations at each node of the search tree. As result, Formulation 2 allows potentially the analysis of larger instances than Formulation 1 and may be characterized by faster solution times. Hence, we preferred to use Formulation 2 in our experiments.\n\nWe considered two different implementations of Formulation\n2, namely: the GESC-based Reduced Model\n(GSEC-RM) and the Flow-based Reduced Model (Flow-\nRM). The GESC-RM consists of Formulation 2 strengthened\nby the valid inequalities previously described. The\nFlow-RM consists of Formulation 2 strengthened by the\nvalid inequalities and such that the GSEC are replaced\nby a multi-commodity flows. Specifically, by denoting\nfijq\nas a decision variable equal to one if there exists a flow\nfrom vertex 1 to vertex\nq\u2208VH\npassing through edge\n(i,j\u2208E\u00af\nand 0 otherwise, the Flow-RM can be obtained by replacing constraints\n2l) with: \n\n(14)fjiq+fijq\u2264\u2211s\u2208Szijs\u2200q\u2208VH:q\u22601,i,j\u2208V:i,j\u2208Z\n\n(15)\u2211i\u2208V:i\u22601f1iq=1\u2200q\u2208VH:q\u22601\n\n(16)\u2211j\u2208V:i\u2260jfijq\u2212\u2211j\u2208V:i\u2260jfjiq=0\u2200q\u2208VH:q\u22601,i\u2208V:i\u2209{1,q}\n\n(17)\u2211i\u2208V:i\u2260qfiqq\u2212\u2211i\u2208V:i\u2260qfqiq=1\u2200q\u2208VH:q\u22601\n\n(18)fijq\u22650\u2200q\u2208VH:q\u22601,i,j\u2208V:i,j\u2208Z.\n\nIn preliminary experiments we observed that the Flow-RM outperforms the GESC-RM in terms of solution time. This fact is mainly due to the computational overhead introduced by the GSEC separation oracle which seems to be not compensated by the size of the analyzed instances. Hence, we did not consider the GESC-RM any further in our experiments.\n\nDuring the runtime, we enabled the Xpress-MP automatic cuts and the Xpress-MP pre-solving strategy. Moreover, we also tested a number of generic primal heuristics for the Steiner tree problem to generate a first primal bound to the MPPEP-SNP (see, e.g.,\n[34]). Unfortunately, in preliminary experiments we observed that the use of such heuristics interferes negatively with the Xpress Optimizer, by delaying the solution time of the analyzed instances. Hence, we disabled the used of the generic primal heuristics and enabled the use of the Xpress-MP primal heuristic instead. The source code of the algorithm can be downloaded at\nhttp://homepages.ulb.ac.be/~dacatanz/Site/Software_files/iMPPEP.zip.\n\nWhen using the Flow-RM, the valid inequalities (3)-(12) are loaded together with the reduced model. On the contrary, the valid inequalities (13) are dynamically generated by means of a separation oracle working as follows. Before loading the reduced model, we precompute the sets Qd, for all d \u2208 {3,4,\u2026,m}. Let\n(u\u00af,x\u00af,z\u00af) be the current fractional solution at a given node of the search tree and, for all d \u2208 {3,4,\u2026,m}, consider a pair of vertices i,j\u2208Qd. Then, the forbidden path constraints (13) are violated if there exists a path p having internal vertices in C \u2282 V, 2 \u2264 |C| \u2264 d \u2212 1, C \u2229 Qd = \u2205, and such that \n\n(19)\u2211s\u2208Sz\u00afip1s+\u2211k=1|C|\u22121\u2211s\u2208Sz\u00afpkpk+1s+\u2211s\u2208Sz\u00afp|C|js>|C|.\n\nNote that searching for the most violated constraint (19) is in general\nNP-hard as it involves solving a longest path problem on the weighted graph\nG\u00afz\u00afV\u2216Qd, i.e., the graph\nG\u00af whose edges are weighted by variables\nz\u00af and whose vertex set is restricted to (V\u2216Qd) \u222a {i,j}. In order to have a fast separation oracle for the forbidden path constraints we do not solve exactly (19) but we use a heuristic approach instead. Specifically, we first sort edges of\nE\u00af in decreasing order according to their weights and we select two distinct vertices v1,v2 \u2208 V\u2216Qd such that edge (v1,v2) has the largest weight. Subsequently, we set C = {v1,v2}, mark v1 and v2 as visited, and build a simple path from vertex i to vertex j passing by v1 and v2. If p is such that (19) is satisfied then we add the constraint \n\n(20)\u2211s\u2208Szip1s+\u2211k=1|C|\u22121\u2211s\u2208Szpkpk+1s+\u2211s\u2208Szp|C|js\u2264|C|\n\nto the formulation; otherwise, we select a different pair of vertices in V\u2216Qd and iterate this procedure until either 10 distinct paths have been generated or all possible pairs of vertices in V\u2216Qd have been selected. If all vertices have been selected but less than 10 distinct paths have been generated, then we select a larger subset of V\u2216Qd (e.g., a triplet of vertices) and we iterate again the previous steps. It is easy to realize that this procedure may potentially generate all the possible paths violating (13). However, we stop the procedure after generating 10 paths or after considering subset C containing more than 5 vertices as we observed in preliminary experiments that this strategy provides the best trade-off between speed and tightness of the cut.\n\nIn preliminary experiments we observed that the standard branching strategy implemented in the Xpress-MP Optimizer is not appropriate for the problem as it is not able to exploit the dissimilarity of the weights ws in the objective function. This inconveniently leads to formulations characterized by slow solution times. To improve this aspect we implemented a different strategy consisting of branching on the following constraints: \n\n(21)\u2211i,j\u2208V:i,j\u2208Zzijs\u2264\u03b1\u2200s\u2208S\n\nor \n\n(22)\u2211i,j\u2208V:i,j\u2208Zzijs>\u03b1,\u2200s\u2208S\n\nwhere \u03b1 \u2208 {1,2,\u2026,q} and\nq=min{\u2211k\u2208VHhk(s),n/2}. Constraints (21)-(22) limit the number of changes along a phylogeny with respect to a given coordinate\ns\u2208S and tend to be more effective when the weights ws are very dissimilar among them. This branching strategy can be implemented by introducing a decision variable \n\n\u03b2\u03b1s=1if the overall number of changes at coordinates\u2208SofT\u00af\u22c6is equal to\u03b10otherwise,\n\nfor all\ns\u2208S and \u03b1 \u2208 {1,2,\u2026,q}, and by adding the following constraints \n\n\u2211i,j\u2208V:i,j\u2208Zzijs=\u2211\u03b1=1q\u03b2\u03b1s\u2200s\u2208S\u2211\u03b1=1q\u03b2\u03b1s=1\u2200s\u2208S.\n\nWe observed that even better runtime performance can be obtained by sorting the coordinates of the input haplotypes in decreasing way according to the weights ws and by branching first on variables\n\u03b2\u03b1s, then on variables ui, and subsequently on variables\nxis and finally on variables\nzijs.\n\nIn order to obtain a measure of the performance of the Flow-RM, we compared\n[1]\u2019s polynomial-size formulation versus the Flow-RM on\n[1]\u2019s real instances of the MPPEP-SNP, namely: Human chromosome Y constituted by 150 haplotypes having 49 SNPs each; bacterial DNA constituted by 17 haplotypes having 1510 SNPs each; Chimpanzee mitochondrial DNA constituted by 24 haplotypes having 1041 SNPs each; Chimpanzee chromosome Y constituted by 24 haplotypes having 1041 SNPs each; and a set of four Human mitochondrial DNA from HapMap\n[35] constituted by 40 haplotypes having 52 SNPs each, 395 haplotypes having 830 SNPs each, 13 haplotypes having 390 SNPs each, and 44 haplotypes having 405 SNPs each, respectively. Such instances consist only of non-recombining data (Y chromosome, mitochondrial, and bacterial DNA) and can be downloaded at\nhttp://homepages.ulb.ac.be/~dacatanz/Site/Software_files/iMPPEP.zip.\n\nTable\n1 shows the results obtained by such comparison. Specifically, the fourth and fifth columns refer to the gaps (expressed in percentage) of the respective formulations, i.e., to the difference between the optimal value to a specific instance and the value of linear relaxation at the root node of the search tree, divided by the optimal value. The table shows that, excluding the cases in which the solution to a specific instance was trivially a minimum spanning tree (see e.g., Human chromosome Y, Chimpanzee mtDNA, and Chimpanzee chromosome Y), the Flow-RM is always characterized by (sometimes dramatically) smaller gaps. This fact derives on the one hand from the tightness of the Flow-RM with respect to\n[1]\u2019s polynomial-size formulation and on the other hand from the efficiency of the strengthening valid inequalities previously described. The poor relaxations of their formulation led\n[1] to propose an alternative and faster exact approach to solution of the MPPEP-SNP based on the brute-force enumeration of all possible Steiner vertices necessary to solve a specific instance of the problem. To speed up the computation, the brute-force enumeration algorithm makes use of a set of reduction rules based on Buneman graph enumeration to decrease the number of Steiner vertices to be considered. Interestingly, despite the differences in terms of implementation language between the two programs (namely, Mosel for the Flow-RM and C++ for\n[1]\u2019s brute-force enumeration algorithm), the Flow-RM proved to be competitive with\n[1]\u2019s enumeration algorithm, being able to solve almost all the considered instances within 1 second computing time. Only in two cases, namely Human mtDNA 40\u00d752 and Human mtDNA 395\u00d7830, the Flow-RM needed more than 5 minutes to find the corresponding optimal solutions. The deterioration of the runtime performance in those instances is mainly due to the overhead necessary to load the formulation (that in both cases is considerably bigger than in the other instances) and to an intensive use of the separation oracle for the forbidden path constraints. Possibly, a more thorough implementation of the separation oracle and the use of more performing languages (e.g., C++) could help in speeding up computations in those instances at least. \n\nInterestingly, sometimes in real applications the number of haplotypes can be much bigger than the number of SNPs. Hence, it is important to test the ability of an exact algorithm to tackle instances of the MPPEP-SNP containing e.g., hundreds haplotypes.\n[1] observed that their brute force enumeration algorithm is able to tackle instances of the problem containing up to 270 haplotypes having up to 9 SNPs each within 12 hours computing time. Unfortunately, the authors also observed that their algorithm is unable to solve larger instances of the MPPEP-SNP, no matter the maximum runtime considered. In this context, the Flow-RM makes the difference, being able to tackle instances of the MPPEP-SNP having up to 300 haplotypes and 10 SNPs within 3 hours computing time. To show this result, we considered a number of random instances of the problem containing 100, 150, 200, 250, and 300 haplotypes, respectively. Fixing the number of haplotypes n\u2208{100,150,200,250,300}, we created an instance of the problem by generating at random n strings of length 10 over the alphabet \u03a3={0,1}. During the generation process, we randomly selected the number of SNPs equal to 1 in a given haplotype, and subsequently we randomly chose the sites of the haplotype to be set to 1. We iterated the instance generation process 10 times for a fixed value of n, obtaining eventually an overall number of 50 random instances of the MPPEP-SNP downloadable at\nhttp://homepages.ulb.ac.be/~dacatanz/Site/Software_files/iMPPEP.zip.\n\nThe results obtained in our experiments are shown in Table\n2. Specifically, the column \u201cTime\u201d refers to the solution time (expressed in seconds) necessary to solve exactly a specific instance of the MPPEP-SNP. Analogously, the column \u201cNodes\u201d refers to the number of explored nodes in the search tree needed to solve exactly the instance. The table does not report on the performance of\n[1]\u2019s enumeration algorithm, as their algorithm never found the optimal solution to the analyzed instances within the limit runtime of 3 hours. As a general trend, the table shows that the considered instances can be exactly solved within 1 hour computing time. The only exceptions are constituted by the 7th instance of the group 150\u00d710, the 9th instance of the group 200\u00d710, the 2th instance of the group 250\u00d710, and 3th instance of the group 300\u00d710which needed 8719.65, 4600.69, 7757.98, and 5371.05 seconds, respectively, to be solved. These instances are much more sparse than the others, are characterized by smaller reduction ratios, and tend to have more degenerate relaxations than the other instances. The presence of these factors might explain the loss of performance of the Flow-RM. \n\nThe results showed that the integrality gaps are usually very low, ranging from 0% to 4.63% and assuming in average a value about 1%, confirming once again the tightness of the Flow-RM and the efficiency of the strengthening valid inequalities.\n\nFinally, we also tested the performance of the Flow-RM on a set of 5 HapMap Human mitochondrial DNA instances of the MPPEP-SNP that were not solvable by using\n[1]\u2019s brute-force enumeration algorithm, namely: f1 constituted by 63 haplotypes having 16569 SNPs each, i2 constituted by 40 haplotypes having 977 SNPs each, k3 constituted by 100 haplotypes having 757 SNPs each, m4 constituted by 26 haplotypes having 48 SNPs each, and p5 constituted by 21 haplotypes having 16548 SNPs each. Such instances can be downloaded at the same address and consist only of non-recombining data (Y chromosome, mitochondrial, and bacterial DNA).\n\nA part from m4, all the remaining instances gave rise to too large formulations (several hundreds Mbytes RAM) to be handled by the Xpress Optimizer. Hence, instead of analyzing entirely each instance we decomposed it into contiguous SNP blocks and analyzed the most difficult block separately. In more in detail, we define\nHr to be the haplotype matrix obtained by the application of\n[1]\u2019s reduction rules, we sorted the columns of\nHr according to an increasing ordering of the weights ws,\ns\u2208\u015c; subsequently, we considered the submatrices obtained by taking k contiguous SNPs (or k-block) in\n\u015c,k \u2208 {10,13,15}. We did not consider greater values for k as we observed that k = 15 was already a threshold after which the haplotype submatrix gave rise to too large formulations. For each k-block\nB in\nHr we considered the hamming distance\ndhihj=\u2211s\u2208B|hi(s)\u2212hj(s)| between each pair of distinct haplotypes in\nHr, and chose the k-block maximizing the sum\n\u2211hi,hj\u2208Hr,hi<hjdhihj. Finally, we assumed three hours as maximum runtime per instance.\n\nTable\n3 shows the results obtained in our experiments. As for Table\n2, the columns \u201cTime\u201d and \u201cNodes\u201d refer to the solution time (expressed in seconds) and to the number of nodes in the search tree necessary to solve exactly a specific instance of the MPPEP-SNP, respectively. In such a case, the values in the columns \u201cGap\u201d refers to the gap between the best primal bound found within the limit time and the root relaxation and \u201cNodes\u201d refers to the number of nodes explored in the tree search within the limit time.\n\nTable\n3 shows that, apart from the instances f1 and m4, the Flow-RM was unable to exactly solve, within the limit time, the considered instances for values of k \u2208 {13,15}. Specifically, The Flow-RM exactly solved in less than a minute the instance f1 when considering values of k \u2208 {10,13} ; in 20 minutes the instance i2 when considering k = 10 ; in less than 3 minutes the instance k3 when considering k = 10; and the instance m4 in 5 seconds. In contrast, the Flow-RM was unable to solve the instance p5, regardless of the value of k considered. In fact, already when considering k = 10, the Xpress Optimizer took more than 12 hours to exactly solve the instance p5 and explored over 10 million nodes in the search tree. A more detailed analysis of the instance showed that, despite the presence of the strengthening valid inequalities, p5 is characterized by highly fractional relaxations. This fact implies the existence of equivalent optimal solutions to the instance that, on the one hand, delay the finding of a primal bound and, on the other hand, force the Optimizer to explore many more nodes in the tree search. This situation in more pronounced in p5 but also occurs in the instances i2 and k3. To improve the tightness of the formulation we tried to include in the Flow-RM also classical facets and strengthening valid inequalities for the Steiner tree problem in a graph (see\n[23,36-38]). However, we did not observe any benefit from the inclusion. We suspect that the presence of highly fractional solutions to the problem could be caused both by poor lower bounds on the number of Steiner vertices considered in the Flow-RM and by the existence of a number of non trivial classes of symmetries still present in the problem. Investigating such issues warrants future research efforts.\n\nIn order to measure the performance of the model on multi-state character data we also considered\n[2] set of instances of the MPPEP-SNP. Specifically, we considered the following instances: a set of 41 sequences of O.rufipogon DNA (red rice) having 1043 sites each; 80 human mtDNA sequences having 245 sites each; 50 HIV-1 reverse transcriptase amino acid sequences having 176 sites each; a set of 500 sequences of mtDNA from the NCBI BLASTN best aligned taxa having 3000 sites each; a set of 500 sequences of mtDNA from the NCBI BLASTN best aligned taxa having 5000 sites each; and a set of 500 sequences of mtDNA from the NCBI BLASTN best aligned taxa having 10000 sites each. When running the same experiments described in\n[2] we registered a very poor performance for the Flow-RM, mainly due to the large dimension of the considered instances and the presence of symmetries despite the use of constraints (13)-(15). We observed that the combination of these two factors increased the runtime performance of the Flow-RM of 2-3 orders of magnitude with respect to\n[2] approach. However, we also observed that when performing\n[2]\u2019s \u201cwindow analysis\u201d (i.e., when decomposing into blocks of 10 SNPs the input matrix) the Flow-RM performed better than\n[2]\u2019s, being characterized by an average solution time of 8.27 seconds. This fact suggests that, when considering instances constituted by less than a dozen sites, an exact approach entirely based on integer programming may perform better than the implicit enumeration of the vertices of the generalized Buneman graph. Vice-versa, for larger instances the implicit enumeration of the vertices of the generalized Buneman graph appears more suitable.\n\nIn this article we investigated the Most Parsimonious Phylogeny Estimation Problem from Single Nucleotide Polymorphism (SNP) haplotypes (MPPEP-SNP), a recent version of the phylogeny estimation problem that arises when input data consist of SNPs extracted from a given population of individuals. The MPPEP-SNP is\nNP-hard and this fact has justified the development of exact and approximate solution approaches such as those described in\n[1,19,22,26-28]. We explored the prospects for improving on the strategy of\n[1,2] using a novel problem formulation and a series of additional constraints to more precisely bound the solution space and accelerate implicit enumeration of possible optimal phylogenies. We present a formulation for the problem based on an adaptation of\n[23]\u2019s mixed integer formulation for the Steiner tree problem extended with a number of preprocessing techniques and reduction rules to further decrease its size. We then show that it is possible to exploit the high symmetry inherent in most instances of the problem, through a series of strengthening valid inequalities, to eliminate redundant solutions and reduce the practical search space. We demonstrate through a series of empirical tests on real and artificial data that these novel insights into the symmetry of the problem often leads to significant reductions in the gap between the optimal solution and its non-integral linear programming bound relative to the prior art as well as often substantially faster processing of moderately hard problem instances. More generally, the work provides an indication of the conditions under which such an optimal enumeration approach is likely to be feasible, suggesting that these strategies are usable for relatively large numbers of taxa, although with stricter limits on numbers of variable sites. The work thus provides methodology suitable for provably optimal solution of some harder instances that resist all prior approaches. Our results may provide also useful guidance for strategies and prospects of similar optimization methods for other variants of phylogeny inference. In fact, if appropriately adapted, some of the results we presented here (e.g., symmetry breaking strategies) can be generalized with respect to other phylogenetic estimation criteria (e.g., the likelihood criterion) and provide important computational benefits.\n\nThe authors declare that they have no competing interests.\n\nThe authors equally contributed to conceive the work and write the article. DC implemented the algorithms and performed computations. All authors read and approved the final manuscript."}